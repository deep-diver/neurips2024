[{"type": "text", "text": "Online Learning of Delayed Choices ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Recep Yusuf Bekci University of Waterloo Waterloo, Canada recep.bekci@uwaterloo.ca ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Choice models are essential for understanding decision-making processes in domains like online advertising, product recommendations, and assortment optimization. The Multinomial Logit (MNL) model is particularly versatile in selecting products or advertisements for display. However, challenges arise with unknown MNL parameters and delayed feedback, requiring sellers to learn customers\u2032 choice behavior and make dynamic decisions with biased knowledge due to delays. We address these challenges by developing an algorithm that handles delayed feedback, balancing exploration and exploitation using confidence bounds and optimism. We first consider a censored setting where a threshold for considering feedback is imposed by business requirements. Our algorithm demonstrates a $\\tilde{O}(\\sqrt{N T})$ regret, with a matching lower bound up to a logarithmic term. Furthermore, we extend our analysis to environments with non-thresholded delays, achieving a $\\tilde{O}(\\sqrt{N T})$ regret. To validate our approach, we conduct experiments that confirm the effectiveness of our algorithm. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The ability to model and understand consumer choices between discrete alternatives is critical for various business applications, such as online advertising, product recommendations, and assortment optimization. Businesses need to present the most appealing set of options to consumers to maximize engagement and revenue. However, the task of optimizing what content or products are shown to a customer during their browsing session is complex due to the interplay between alternatives that customers face. Each alternative can act as a substitute or competitor to others, impacting the customer's final decision. Traditional multi-armed bandit (MAB) models, which are widely used for decision-making problems, fall short in scenarios where a subset of alternatives must be presented, and the customer's choice among these influences future decisions. ", "page_idx": 0}, {"type": "text", "text": "Multinomial choice (MNL) models have emerged as powerful tools for capturing and predicting consumer behavior among a finite set of alternatives. These models estimate the utilities of different options and the probabilities of their selection. However, when the MNL parameters are unknown and no historical data is available\u2014as is often the case with newly introduced products or advertisements\u2014the learning process becomes even more challenging. This complexity is further exacerbated when the feedback on decisions is delayed, requiring the learner to dynamically adjust decisions based on limited and potentially biased information. ", "page_idx": 0}, {"type": "text", "text": "One of the fundamental challenges in this setting is the delay in receiving feedback from customers. Unlike immediate responses in classical MAB problems, customers in e-commerce environments often take hours or even days to make decisions, as highlighted by Vernade et al. [2020] and Chapelle [2014]. This delay in feedback complicates the learning process, as it must adapt to new information that arrives sporadically and potentially long after the initial interaction. ", "page_idx": 0}, {"type": "text", "text": "In this paper, we address the dual challenges of unknown MNL parameters and delayed feedback by developing algorithms that balances exploration and exploitation through the use of confidence bounds and the principle of optimism in the face of uncertainty. We focus on two settings in receiving delay: the thresholded and the non-thresholded settings. ", "page_idx": 1}, {"type": "text", "text": "In thresholded settings, feedback is only considered if it is received within a predetermined time frame set by business requirements. This constraint ensures operational stability and efficiency by ignoring excessively delayed responses that may no longer be relevant. For these settings, we introduce the Delayed Multinomial Logit Bandit (DEMBA) algorithm, specifically designed to handle potentially censored delayed feedback effectively. ", "page_idx": 1}, {"type": "text", "text": "In contrast, non-thresholded settings allow the learner to consider all feedback regardless of delay, potentially leading to better accuracy in decision making in long-term but at the cost of increased bias in the learning process. For such environments, we propose the Patient Delayed Multinomial Logit Bandit (PA-DEMBA) algorithm, which adapts its learning strategy to accommodate all feedback, irrespective of the delay. ", "page_idx": 1}, {"type": "text", "text": "Contributions. Our main contributions are two novel bandit algorithms: we develop DEMBA, for thresholded feedback settings, and PA-DEMBA, an algorithm designed for non-thresholded feedback environments. Both algorithms effectively learn from delayed and censored choices using confidence intervals. We provide a comprehensive regret analysis for both DEMBA and PA-DEMBA, demonstrating an $\\tilde{O}(\\sqrt{N T})$ regret bound and a matching lower bound up to a logarithmic term. Additionally, through detailed computational experiments, we validate the performance and robustness of our algorithms in various scenarios. ", "page_idx": 1}, {"type": "text", "text": "Organization. The remainder of this paper is organized as follows. In Section 2, we review the related work on choice modeling and delayed feedback in online learning. Section 3 details the problem formulation and the specific challenges addressed by our approach. Our main algorithm DEMBA is presented in Section 4. We analyze the regret bounds of this algorithm in Section 5, providing theoretical guarantees for its performance. PA-DEMBA algorithm for non-thresholded delays is presented in Section 6. In Section 7, we conduct experiments to demonstrate the effectiveness of our proposed algorithms. Finally, Section 8 concludes the paper and outlines potential directions for future research. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Delayed feedback is a crucial aspect of online learning environments, especially in domains like online advertising and e-commerce, where decision making involves a consideration period, or in healthcare, where the effects of actions take time to manifest. Consequently, research interest in bandits with delayed feedback has surged in recent years. ", "page_idx": 1}, {"type": "text", "text": "In their seminal work, Joulani et al. [2013] studied online learning scenarios with stochastic delayed feedback. Their work laid the foundation for understanding how delays impact learning performance. Similarly, Chapelle [2014] examined delayed conversions in display advertising, highlighting the practical challenges faced in real-world applications. Further, Vernade et al. [2017] focused on delays specifically in the context of delayed conversions, providing insights into handling delays with known distributions. ", "page_idx": 1}, {"type": "text", "text": "Expanding on this, Pike-Burke et al. [2018] explored bandits with delayed, aggregated, and anonymous feedback, which adds another layer of complexity by considering multiple types of delays. Zhou et al. [2019] extended this exploration to generalized linear contextual bandits with delayed feedback. Vernade et al. [2020] investigated linear bandits with stochastic thresholded delays. Additionally, Gael et al. [2020] tackled multi-armed bandits with arm-dependent stochastic delays, focusing on the challenges of non-uniform delays across different choices. Moreover, Cesa-Bianchi et al. [2022] considered composite and anonymous delayed feedback within non-stochastic bandits, further enriching the literature on delayed feedback mechanisms. Tang et al. [2024] studied delayed multi-armed bandits (MAB) with reward-dependent delays in clinical trials, while Lancewicki et al. [2021] explored both reward-dependent and reward-independent delay settings. Flaspohler et al. [2021] investigated delayed learning in weather forecasting, and Grover et al. [2018] addressed the best arm identification problem with delayed feedback. Thune et al. [2019] examined non-stochastic MABs with unrestricted delays, and Cesa-Bianchi et al. [2016] considered cooperation between different agents in delayed settings. Tang et al. [2021] explored scenarios where past actions impact future arm rewards, and Yang et al. [2024] addressed general sequential decision-making problems with delayed feedback. Despite this rich body of work, the solutions developed for MABs do not directly apply to our setting, where assortment feedback in discrete choice models presents additional complexities. In particular, delayed feedback affects both item value estimation and assortment composition, making our problem significantly more challenging than those where only arm rewards areupdated. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "When focusing specifically on generalized linear bandits with delays, we note key contributions such as Howson et al. [2023] and Blanchet et al. [2024] who explored generalized linear bandits with delayed feedback, demonstrating the efficacy of these models in more complex, non-linear settings. Multinomial bandits, which address decision making where multiple items are offered simultaneously, present a unique challenge due to the interactions between items. This complexity distinguishes our problem from other online learning models. Specifically, for generalized linear bandits, we note that when the assortment has more than one item, our problem cannot be addressed by solutions designed for generalized linear models due to the complexity of interactions among multiple choices which makes the action space more complicated. ", "page_idx": 2}, {"type": "text", "text": "In terms of online learning with choice models, significant progress has been made in understanding and optimizing MNL parameters. Agrawal et al. [2017] developed a Thompson sampling algorithm for learning MNL parameters for assortment optimization, while Agrawal et al. [2019] proposed a UCB algorithm for the same purpose. Dong et al. [2020] adapted this problem by introducing switch costs, addressing practical constraints in dynamic environments. Further, Agarwal et al. [2020] studied the problem for best arm identification, extending the framework to multiple pulls, which is a generalization of the dueling bandits problem. Other notable works include Wang et al. [2018] and Chen et al. [2021], who worked on dynamic assortment allocation under uncapacitated MNL models, and Perivier and Goyal [2022], who investigated joint pricing and assortment optimization with MNL demand processes. ", "page_idx": 2}, {"type": "text", "text": "To the best of our knowledge, our work is the first to address online learning of delayed choices in this context. Specifically, we propose the Delayed Multinomial Logit Bandit (DEMBA) algorithm for thresholded feedback settings and the Patient Delayed Multinomial Logit Bandit (PA-DEMBA) algorithm for non-thresholded settings. These algorithms effectively learn from delayed and censored choices using confidence intervals, providing robust solutions for dynamic and uncertain environments where feedback is not immediately available. Our approach not only advances the theoretical understanding of delayed feedback in online learning but also offers practical insights for applications in e-commerce and online advertising. ", "page_idx": 2}, {"type": "text", "text": "3 Problem Setup ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We consider a capacitated selection problem faced by a seller over $T$ rounds. The items to be selected, referred to as products, can be new retail products or services such as advertisements. There are $N$ products available to potentially be shown to the customer. The set of products selected in a given round is called an assortment, denoted as $S_{t}$ for round $t$ ,where $S_{t}\\subset\\{1,\\ldots,N\\}$ and $|S_{t}|\\stackrel{*}{\\leq}K$ Here, $K$ represents the capacity, indicating the maximum number of items the seller can show at any given time. ", "page_idx": 2}, {"type": "text", "text": "Upon encountering the assortment, the customer makes a choice $a_{t}$ among the options: (i) rejecting the browsing options provided $(a_{t}=0)$ 0, (i) browsing and purchasing/selecting an option $(a_{t}=i,i\\in S_{t})$ \uff0c and (i) browsing but not purchasing/selecting an option $(a_{t}=0d)$ . If option $i$ is chosen, the seller earns a reward $r_{i}$ , with $r_{i}\\in[0,1]$ for $i\\in[N]$ and $r_{0}=r_{0d}=0$ ", "page_idx": 2}, {"type": "text", "text": "Customer choice probabilities are determined by the Multinomial Logit (MNL) model as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{P}(a_{t}=i|S_{t}=S)=\\left\\{\\frac{v_{i}}{v_{0}+v_{0}a+\\sum_{j\\in S}v_{j}}\\quad i f\\;i\\in S\\cup\\{0,0d\\}\\right.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $v_{i}$ denotes the (unknown) attraction parameter of option $i$ . Without loss of generality we assume that attraction parameters are normalized such that $v_{0}=1$ . In parallel with the real applications, we also assume that not browsing is the most common choice, i.e. $v_{i}\\leq v_{0}$ ", "page_idx": 2}, {"type": "text", "text": "It is important to note that not purchasing/selecting is different from tracking conversions. Specifically, if the customer browses the given assortment, we can track if the customer decides not to purchase, similar to choosing an option to purchase (e.g., by closing the pop-up or following specific behavioral click-through patterns). ", "page_idx": 3}, {"type": "text", "text": "If the customer's choice is $a_{t}\\,=\\,0$ , the seller receives this choice immediately. Otherwise, the customer's choice is revealed to the seller after a delay $d_{t}\\,\\in\\,\\mathbb{N}$ $d_{t}$ is sampled from a unknown distribution $f_{d}$ and independent from $a_{t}$ . Moreover, delays longer than a certain threshold $\\mu$ is censored or ignored by the seller in the learning process. This threshold is set based on the seller's operational requirements. We later extend our solution to the patient learner setting without a threshold, i.e. $\\mu\\to\\infty$ ", "page_idx": 3}, {"type": "text", "text": "We define $a_{i,t}$ as the demand for option $i$ at time $t$ .We have ", "page_idx": 3}, {"type": "equation", "text": "$$\na_{i,t}={\\left\\{\\begin{array}{l l}{1,}&{i f\\ a_{t}=i,}\\\\ {0,}&{o t h e r w i s e.}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We also define $c_{i,s,t}\\in\\{0,1\\}$ as the censoring variable of product $i$ at period $t$ that is sold at period $s$ The censoring variable is determined as: ", "page_idx": 3}, {"type": "equation", "text": "$$\nc_{i,s,t}=\\mathbb{I}(d_{s}\\leq t-s\\mathrm{~and~}d_{s}\\leq\\mu).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We define the feedback observed by the seller as $o_{i,s,t}\\in\\{0,1\\}$ and $o_{i,s,t}=c_{i,s,t}a_{i,s}$ . The expected fraction of observed feedback is denoted as $\\begin{array}{r}{\\psi_{\\mu}:=\\sum_{s=0}^{\\mu}\\dot{f}_{d}(s)}\\end{array}$ ", "page_idx": 3}, {"type": "text", "text": "The sequence of events at round $t$ can be summarized as follows: ", "page_idx": 3}, {"type": "text", "text": "1. The seller selects an assortment $S_{t}$   \n2. The customer interacts with the medium(view the page or encounter with the pop-up) and makes a decision $a_{t}$   \n3. The environment returns a reward $r_{i}$ \uff0c $i\\in[N]$ , and samples a delay $d_{t}$   \n4. Rewards of certain previous actions and/or if the customer rejected to browse revealed to the seller as Oi,s,t. ", "page_idx": 3}, {"type": "text", "text": "The expected reward of the seller given assortment $S$ and atraction parameter set $v$ is given by ", "page_idx": 3}, {"type": "equation", "text": "$$\nR(S;v)=\\sum_{i\\in S}r_{i}\\cdot{\\frac{v_{i}}{1+v_{0d}+\\sum_{j\\in S}v_{j}}}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The goal of the seller is to sequentially learn customer preferences and find a policy to minimize cumulative expected regret, defined as: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{Reg}(T,\\pi)=\\sum_{t=1}^{T}R(S^{\\ast};\\psi_{\\mu}v)-R(S_{t}^{\\pi};\\psi_{\\mu}v),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $S^{*}=\\arg\\operatorname*{max}_{S\\subset\\{1,...,N\\},|S|\\leq K}R(S;\\psi_{\\mu})$ maximizes the expected reward of the clairvoyant and $v=\\{v_{0d},v_{1},\\ldots,v_{N}\\}$ is the ground truth attraction parameter set. ", "page_idx": 3}, {"type": "text", "text": "4 Delayed MNL Bandit (DEMBA) Algorithm ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we introduce the Delayed MNL Bandit (DEMBA) algorithm. DEMBA leverages an epoch-based learning method, where epochs are explicitly defined by immediate no-purchase decisions. Specifically, when a no-purchase decision is made by the customer, the current epoch is closed, and a new one begins. Throughout each epoch, customer selections are observed, and parameter updates occur upon encountering a no-purchase outcome. ", "page_idx": 3}, {"type": "text", "text": "Our approach adopts the principle of optimism in the face of uncertainty [Auer et al., 2002] for parameter estimation, generating optimistic estimations using upper confidence bounds for product attraction parameters and a lower confidence bound for the no-purchase option. This results in an optimistic revenue function, guiding decision-making under uncertainty by balancing exploration and exploitation. ", "page_idx": 3}, {"type": "text", "text": "We build our optimistic estimates on biased observations. The total observed preference given to product $i$ until epoch $\\tau$ is denoted as $\\tilde{v}_{i,\\tau}$ and can be calculated as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\tilde{v}_{i,\\tau}=\\sum_{s=1}^{t_{\\tau}^{e n d}}o_{i,s,t_{\\tau}^{e n d}},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\tau$ is the current epoch and $t_{\\tau}^{e n d}$ is the last period of epoch $\\tau$ ", "page_idx": 4}, {"type": "text", "text": "We count how many times a particular product $i$ is offered in the assortment until epoch $\\tau$ using the set $E_{\\tau}(i)$ which is the set of epochs during which $i$ is offered, i.e. $E_{\\tau}(i)=\\{e\\leq\\tau\\,\\colon i\\in S_{e}\\}$ . Then, we estimate attraction parameters by ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{v}_{i,\\tau}=\\frac{\\tilde{v}_{i,\\tau}}{|E_{\\tau}(i)|}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "$\\hat{v}_{i,\\tau}$ is a biased estimator due to delay and thresholding, i.e. $\\mathbb{E}[\\hat{v}_{i,\\tau}]\\neq v_{i}$ . We consider this bias in our estimation and build our concentration around $\\psi_{\\mu}v_{i}$ . We state our concentration result in the following lemma. ", "page_idx": 4}, {"type": "text", "text": "Lemma 4.1With probability at least $1-O(N^{-2}T^{-1})$ foreveryepoch $\\tau\\in\\{1,\\ldots\\}$ andoption $i\\in\\{0d,1,\\ldots,N\\}$ we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{|\\hat{v}_{i,\\tau}-\\psi_{\\mu}v_{i}|\\leq\\Delta_{i,\\tau},}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Sketch of the proof. Note that $\\hat{v}_{i,\\tau}$ is a biased estimator and defined as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{v}_{i,\\tau}=\\frac{\\tilde{v}_{i,\\tau}}{|E_{\\tau}(i)|}=\\frac{\\sum_{s=1}^{t_{\\tau}^{e n d}}o_{i,s,t_{\\tau}^{e n d}}}{|E_{\\tau}(i)|},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $|E_{\\tau}(i)|$ is the total number of epochs during which product $i$ is shown to the customer and $\\sum_{s=1}^{t_{\\tau}^{e n d}}o_{i,s,t_{\\tau}^{e n d}}$ is the total observed sales of product $i\\ne0d$ or is the total observed delayed no selections. ", "page_idx": 4}, {"type": "text", "text": "We analyze the concentration around $\\psi_{\\mu}v_{i}$ ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{v}_{i,\\tau}-\\psi_{\\mu}v_{i}\\rvert=\\left\\lvert\\frac{\\sum_{s=1}^{t_{r}^{m d}}{\\boldsymbol{\\sigma}_{i,s,t}}\\boldsymbol{\\epsilon}_{r}^{s t a}}{\\lvert E_{\\tau}(t)\\rvert}-\\psi_{\\mu}v_{i}\\right\\rvert}\\\\ &{\\ =\\left\\lvert\\frac{\\sum_{s=1}^{t_{r}^{m d}-\\mu}{\\boldsymbol{\\mu}_{i,s}}\\mathbb{I}(d_{s}\\leq\\mu)+\\sum_{s=t_{r}^{m d}-\\mu+1}^{t_{r}^{m d}}a_{i,s}\\mathbb{I}(d_{s}\\leq\\boldsymbol{t}_{\\tau}^{e n d}-s)}{\\lvert E_{\\tau}(i)\\rvert}-\\psi_{\\mu}v_{i}\\right\\rvert}\\\\ &{\\ =\\left\\lvert\\frac{\\sum_{s=1}^{t_{r}^{m d}}a_{i,s}\\mathbb{I}(d_{s}\\leq\\mu)+\\sum_{s=t_{r}^{m d}-\\mu+1}^{t_{r}^{m d}}a_{i,s}\\mathbb{I}(\\lvert d_{s}\\leq\\boldsymbol{t}_{\\tau}^{e n d}-s)-\\mathbb{I}(d_{s}\\leq\\mu))}{\\lvert E_{\\tau}(i)\\rvert}-\\psi_{\\mu}v_{i}\\right\\rvert}\\\\ &{\\ \\leq\\left\\lvert\\frac{\\sum_{s=1}^{t_{r}^{m d}}a_{i,s}\\mathbb{I}(d_{s}\\leq\\mu)}{\\lvert E_{\\tau}(i)\\rvert}-\\psi_{\\mu}v_{i}\\right\\rvert+\\left\\lvert\\frac{\\sum_{s=t_{r}^{m d}-\\mu+1}^{t_{r}^{m d}}a_{i,s}(1-\\mathbb{I}(d_{s}\\leq\\mu))}{\\lvert E_{\\tau}(i)\\rvert}\\right\\rvert,\\qquad(1)}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where the second equality follows from decomposing the observations into those before and after the threshold, the third equality rearranges the terms, and the last inequality uses the triangle inequality. ", "page_idx": 4}, {"type": "text", "text": "For the first term in the decomposition (1), we have ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\sum_{s=1}^{t_{e n d}^{e n d}}a_{i,s}\\mathbb{I}(d_{s}\\leq\\mu)}{|E_{\\tau}(i)|}-\\psi_{\\mu}v_{i}\\biggr|=\\left|\\frac{\\sum_{s=1}^{t_{e n d}^{e n d}}a_{i,s}\\mathbb{I}(d_{s}\\leq\\mu)}{|E_{\\tau}(i)|}-\\frac{\\psi_{\\mu}\\sum_{s=1}^{t_{e n d}^{e n d}}a_{i,s}}{|E_{\\tau}(i)|}+\\frac{\\psi_{\\mu}\\sum_{s=1}^{t_{e n d}^{e n d}}a_{i,s}}{|E_{\\tau}(i)|}-\\psi_{\\mu}v_{i}\\right|}\\\\ &{\\qquad\\qquad\\qquad\\leq\\left|\\frac{\\sum_{s=1}^{t_{e n d}^{e n d}}a_{i,s}\\mathbb{I}(d_{s}\\leq\\mu)}{|E_{\\tau}(i)|}-\\frac{\\psi_{\\mu}\\sum_{s=1}^{t_{e n d}^{e n d}}a_{i,s}}{|E_{\\tau}(i)|}\\right|+\\left|\\frac{\\psi_{\\mu}\\sum_{s=1}^{t_{e n d}^{e n d}}a_{i,s}}{|E_{\\tau}(i)|}-\\psi_{\\mu}v_{i}\\right|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\underset{\\leq\\left|E_{\\tau}^{\\epsilon\\ n d}\\right|}{\\overbrace{\\sum_{s=1}^{t_{e n d}^{e n d}}\\mathbb{I}(d_{s}\\leq\\mu)}^{(a)}-\\psi_{\\mu}\\right|}+\\left|\\frac{\\sum_{s=1}^{t_{e n d}^{e n d}}a_{i,s}}{|E_{\\tau}(i)|}-v_{i}\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We bound the first term (a) using Hoeffding's inequality: ", "page_idx": 5}, {"type": "equation", "text": "$$\n(a)\\leq\\sqrt{\\frac{\\log(N T)}{|E_{\\tau}(i)|}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "For part $(b)$ , we make use of the Chernoff bound from Theorem A.1 and handle two cases based $\\begin{array}{r}{\\zeta\\,=\\,(v_{i}+1)\\sqrt{\\frac{6\\log(N T)}{v_{i}|E_{\\tau}(i)|}}}\\end{array}$ The detailed proof is provided in Appendix A. The result can be summarized as foliows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left|\\frac{\\sum_{s=1}^{t_{\\tau}^{e n d}}a_{i,s}}{|E_{\\tau}(i)|}-v_{i}\\right|\\leq\\sqrt{\\frac{48\\hat{v}_{i,\\tau}\\log(N T)}{|E_{\\tau}(i)|}}+\\frac{48\\log(N T)}{|E_{\\tau}(i)|}\\right)\\geq1-\\frac{4}{N^{2}T}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Combining the bounds for both terms, we establish the concentration result stated in Lemma 4.1. ", "page_idx": 5}, {"type": "text", "text": "Using the concentration result for the attraction parameters, we construct upper confidence bounds for each product at each epoch: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\bar{v}_{i,\\tau}=\\hat{v}_{i,\\tau}+\\Delta_{i,\\tau},}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "and for the delayed no-purchase option, we construct a lower confidence bound: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\underline{{v}}_{0d,\\tau}=\\hat{v}_{0d,\\tau}-\\Delta_{0d,\\tau},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\Delta_{i,\\tau}=\\sqrt{\\frac{(48\\hat{v}_{i,\\tau}+1)\\log(N T)}{|E_{\\tau}(i)|}}+\\frac{48\\log(N T)+\\mu}{|E_{\\tau}(i)|}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We use the optimistic parameter estimations to construct an optimistic revenue function ", "page_idx": 5}, {"type": "equation", "text": "$$\nR(S;\\bar{v})=\\sum_{i\\in S}r_{i}\\frac{\\bar{v}_{i,\\tau}}{1+\\underline{{v}}_{o d,\\tau}+\\sum_{j\\in S}\\bar{v}_{j,\\tau}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Our algorithm DEMBA suggests the assortment according to the optimistic revenue function $R(S;\\bar{v})$ and updates parameters according to feedback received with delay. The pseudocode of DEMBA is given in Algorithm 1. ", "page_idx": 5}, {"type": "text", "text": "Computational complexity. The computational complexity of the DEMBA algorithm involves several key components. The most intensive step is computing the assortment $S_{\\tau}$ by maximizing the revenue function $R(S;\\bar{v})$ . For this step, polynomial-time solutions with $O(N^{2})$ complexity are available, as demonstrated by Rusmevichientong et al. [2010] and Davis et al. [2013]. Updating observed preferences $\\tilde{v}_{i,\\tau}$ involves summing over previous observations, with a complexity of $O(N(t_{\\tau}^{s t a r t}-t_{\\tau}^{e n d}))$ . The process of updating sets $E_{\\tau}(i)$ and estimations $\\hat{v}_{i,\\tau}$ and the confidence bounds adds $O(N)$ operations per epoch. Given that $\\tau\\leq t$ and $t\\leq T$ , the overall computational complexity across all rounds $T$ is $O(\\mathbf{\\dot{{T}}}N^{2}+N T^{2})$ ", "page_idx": 5}, {"type": "table", "img_path": "gC3BzNwqQp/tmp/f2d05be926b70785bb3ac7f90212cf8306f03cc5b780a351c7b4f8cc22a1f695.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "5 Regret Analysis ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Our main result is given in the following theorem. ", "page_idx": 6}, {"type": "text", "text": "Theorem 5.1 Let $\\pi^{D E M B A}$ be the policy produced by Algorithm $^{\\,l}$ Lusing $\\begin{array}{r l}{\\Delta_{i,\\tau}}&{{}=}\\end{array}$ $\\begin{array}{r}{\\sqrt{\\frac{\\left(48\\hat{v}_{i,\\tau}+1\\right)\\log\\left(N T\\right)}{\\left|E_{\\tau}\\left(i\\right)\\right|}}+\\frac{48\\log\\left(N T\\right)+\\mu}{\\left|E_{\\tau}\\left(i\\right)\\right|}}\\end{array}$ Then, $\\pi^{D E M B A}$ satisiess $\\begin{array}{r l}&{R e g(T,\\pi^{D E M B A})\\leq(1+\\mu)\\log(T)+K\\sqrt{73T\\log(N T)}+48K\\log(T)(\\log(N T)+\\mu)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\;73\\sqrt{N T\\log(N T)}+48\\log^{2}(N T).}\\end{array}$ ", "page_idx": 6}, {"type": "text", "text": "The bound can be further simplified to $\\tilde{O}\\left(\\sqrt{N T}\\right)$ by omitting logarithmic terms. ", "page_idx": 6}, {"type": "text", "text": "Sketch of the proof. The proof of Theorem 5.1 consists of several steps. First, we use the definition of the optimistic revenue function $R(S;\\bar{v})$ and show that it provides an upper bound on the true revenue function $R(S;\\psi_{\\mu}v)$ . This is achieved by leveraging Lemma B.1, which ensures that the estimated attraction parameters are close to their true values with high probability. ", "page_idx": 6}, {"type": "text", "text": "We start by expressing the regret in terms of the epochs: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathsf{R e g}(T,\\pi)=\\mathbb{E}\\left[\\sum_{\\tau=1}^{\\bar{\\tau}}|\\mathcal{H}_{\\tau}|\\left(R(S^{\\ast};\\psi_{\\mu}v)-R(S_{\\tau};\\psi_{\\mu}v)\\right)\\right],\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\varkappa_{\\tau}$ is the duration of epoch $\\tau$ . Given that the epoch duration follows a geometric distribution, we simplify the expected regret using the law of total expectations. ", "page_idx": 6}, {"type": "text", "text": "Next, we decompose the regret into two parts: one that occurs with high probability (event $\\mathcal{E}_{\\tau}^{C}$ )and one that occurs with low probability (event $\\mathcal{E}_{\\tau}$ ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\Delta R_{\\tau}]=\\mathbb{E}\\left[\\Delta R_{\\tau}\\mathbb{I}(\\mathcal{E}_{\\tau-1})+\\Delta R_{\\tau}\\mathbb{I}(\\mathcal{E}_{\\tau-1}^{C})\\right].\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "We bound the contribution of the low-probability event by $(N+1)\\mathbb{P}(\\mathcal{E}\\tau-1)$ , which is small due to our concentration results. ", "page_idx": 6}, {"type": "text", "text": "For the high-probability event, we show that the difference between the optimistic and true revenues isbounded by $\\Delta_{i,\\tau}$ . Applying Lemma B.1, we can then bound the regret for each epoch: ", "page_idx": 6}, {"type": "equation", "text": "$$\nR_{\\tau}]\\leq(N+1)\\mathbb{P}(\\mathcal{E}\\tau-1)+\\mathbb{E}\\left[\\left(1+\\psi_{\\mu}v_{0d}+\\sum_{j\\in S_{\\tau}}\\psi_{\\mu}v_{j}\\right)\\left(R(S_{\\tau};\\bar{v}_{\\tau})-R(S_{\\tau};\\psi_{\\mu}v)\\right)\\mathbb{I}(\\mathcal{E}_{\\tau-1}^{C})\\right].\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Summing over all epochs and using the properties of the epoch duration, we show that the total regret isbounded by $\\tilde{O}(\\sqrt{N T})$ .\u53e3 ", "page_idx": 6}, {"type": "text", "text": "The full detailed proof is provided in Appendix B. ", "page_idx": 7}, {"type": "text", "text": "Next, we provide a lower bound result for the regret in the following theorem: ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.2 For any policy $\\pi$ suppose $K\\leq N/4,T\\geq1,$ and $\\psi_{\\mu}\\in(0,1)$ . There exists a universal constant $c>0$ such that ", "page_idx": 7}, {"type": "equation", "text": "$$\nR e g(T,\\pi)\\geq c\\operatorname*{min}\\left\\{T,\\sqrt{\\frac{T N}{\\psi_{\\mu}}}\\right\\}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The proof of Theorem 5.2 is deferred to Appendix C. This theorem establishes a lower bound on the regret, showing that no policy can achieve a better regret rate than $\\Omega({\\sqrt{N T}})$ ", "page_idx": 7}, {"type": "text", "text": "Remark 5.3 The effect of the threshold $\\mu$ in the upper bound appears only in logarithmic terms, suggesting that the regret increases with larger $\\mu$ In contrast, in the lower bound, $\\psi_{\\mu}$ appears in the square root and the denominator, indicating that the regret decreases with larger $\\mu$ It is important to notethat $\\mu$ is determined by business conditions and is typically fixed. We conjecture that the upper bound is not tight concerning $\\mu,$ indicating potential areas for future improvement in the analysis. ", "page_idx": 7}, {"type": "text", "text": "6  Non-Thresholded Setting: The Patient Learner ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we modify our algorithm for environments that do not apply a threshold for delays. We refer to the seller in this setting as the patient learner. The patient learner is assumed to have knowledge of the expected delay. This assumption is consistent with existing literature (see e.g. Joulani et al. [2013], Blanchet et al. [2024]). ", "page_idx": 7}, {"type": "text", "text": "We build our concentration result as follows: ", "page_idx": 7}, {"type": "text", "text": "Lemma 6.1 With probability at least $1-O(N^{-2}T^{-1})$ we have ", "page_idx": 7}, {"type": "equation", "text": "$$\n|\\hat{v}_{i,\\tau}-v_{i}|\\leq\\sqrt{\\frac{48\\hat{v}_{i,\\tau}\\log(N T)}{|E_{i}(\\tau)|}}+\\frac{48\\log(N T)}{|E_{i}(\\tau)|}+\\frac{\\mathbb{E}\\left[d_{s}\\right]}{|E_{i}(\\tau)|}+\\frac{\\sqrt{6\\mathbb{E}\\left[d_{s}\\right]\\log(N T)}}{|E_{i}(\\tau)|}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The proof is deferred to the Appendix. According to Lemma 6.1, we modify Algorithm 1 by changing $\\Delta_{i,\\tau}$ ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\tilde{\\Delta}_{i,\\tau}=\\sqrt{\\frac{48\\hat{v}_{i,\\tau}\\log(N T)}{|E_{i}(\\tau)|}}+\\frac{48\\log(N T)}{|E_{i}(\\tau)|}+\\frac{\\mathbb{E}\\left[d_{s}\\right]}{|E_{i}(\\tau)|}+\\frac{\\sqrt{6\\mathbb{E}\\left[d_{s}\\right]\\log(N T)}}{|E_{i}(\\tau)|}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "We then state the regret result of the modified algorithm: ", "page_idx": 7}, {"type": "text", "text": "Theorem 6.2 Let $\\pi^{P A-D E M B A}$ be the policy produced byAlgorithm $^{\\,l}$ using $\\tilde{\\Delta}_{i,\\tau}$ . \u03c0PA-DEMBA satisfies ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R e g(T,\\pi^{P A-D E M B A})\\leq\\log(T)+K\\sqrt{48T\\log(N T)}}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\left(K+1\\right)\\!\\left(48+\\mathbb{E}\\left[d_{s}\\right]+\\sqrt{6\\mathbb{E}\\left[d_{s}\\right]}\\right)\\log^{2}(N T)+72\\sqrt{N T\\log(N T)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Remark6.3 In the non-thresholded setting, the term with $\\psi_{\\mu}$ disappears since $\\operatorname{lim}_{\\mu\\to\\infty}\\psi_{\\mu}=1$ This implies that the regret in this setting does not depend on $\\psi_{\\mu}$ providing a potentially tighter bound compared to the thresholded case. However, new terms involving $\\mathbb{E}\\left[d_{s}\\right]$ are introduced. Asymptotically, both the thresholded and non-thresholded regret bounds simplify to $\\tilde{O}(\\sqrt{N T})$ with the differences primarily refected in the constants,and both bounds approach the lower bound. ", "page_idx": 7}, {"type": "text", "text": "Remark 6.4 Incorporating the skewness or variance of the delay distribution can improve the regret upper bound in practice, particularly in the non-thresholded setting. For instance, distributions with faster decay rates, such as Gaussian distributions, may lead to better regret performance compared to long-tail distributions. This would involve using techniques like Bernstein-type inequalities or making assumptions about tail behavior (e.g., sub-exponential tails). However, in the current analysis, we focus on the expectation of the delay,and further improvements based onskewness are left for future work.The asymptotic regret bound remains $O(\\sqrt{N T})$ independentof skewness. ", "page_idx": 7}, {"type": "image", "img_path": "gC3BzNwqQp/tmp/74687815accbe7ef33bc6d5ac520a14af454875af946b05f558073af8eb0aa54.jpg", "img_caption": [], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 1: Simulation results of DEMBA algorithm with benchmarks. Top row: geometric delays. Bottom row: uniform delays. Left: $\\mathbb{E}[d_{s}]=500$ $\\mu=100$ ;Middle $\\mathbb{E}[d_{s}]^{-}=100$ \uff0c $\\mu=100$ ; Right: $\\mathbb{E}[d_{s}]=100$ $\\mu=500$ . Results are averaged over 100 independent runs. ", "page_idx": 8}, {"type": "text", "text": "7 Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We conducted two sets of experiments to evaluate the performance of our algorithms. Our benchmark is an explore-then-exploit (EXP) algorithm, which explores by offering random assortments until a pre-specified time and then offers the optimized assortment based on the collected data. We tuned the exploration duration of the EXP algorithm and used the three best-performing durations in our comparisons. ", "page_idx": 8}, {"type": "text", "text": "We used $N=10$ $K=4$ and $p_{i}=1$ for all $i\\in\\{1,\\ldots,N\\}$ . The atraction parameters were set as: ", "page_idx": 8}, {"type": "equation", "text": "$$\nv_{i}=\\left\\{\\!\\!\\begin{array}{l l}{0.25+\\epsilon}&{i f\\quad i\\in\\{1,2,9,10\\}}\\\\ {0.25}&{o t h e r w i s e,}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Where $\\epsilon$ represents the contrast between products. With this setting the optimal assortment is $\\{1,2,9,10\\}$ ", "page_idx": 8}, {"type": "text", "text": "In the first set of experiments, we tested our algorithm in two different delay settings: geometrically distributed and uniformly distributed delays. We set $\\epsilon=0.05$ and used three cases in each distribution with increasing $\\psi_{\\mu}$ values: $\\mathbb{E}[d_{s}]\\,=\\,500$ \uff0c $\\mu\\,=\\,100$ $\\mathbb{E}[d_{s}]\\,=\\,100$ \uff0c $\\mu\\,=\\,100$ ; and $\\mathbb{E}[d_{s}]\\,=\\,100$ $\\mu\\,=\\,500$ . The results of this experiment are shown in Figure 1. We observed that the DEMBA algorithm learns effectively and performs better than our benchmarks in all settings. Learning becomes more difficult as $\\psi_{\\mu}$ decreases due to increased censorship and information loss from thresholding. With uniform delays, the learning is more challenging due to the heavy tail of the distribution. The gaps between DEMBA and the benchmarks increase with higher $\\psi_{\\mu}$ , suggesting better utilization of information by DEMBA. ", "page_idx": 8}, {"type": "text", "text": "In our second set of experiments, we tested how the contrast parameter $\\epsilon$ affects learning and how the PA-DEMBA algorithm performs. We used geometric delays with $\\mathbb{E}[d_{s}]=100$ and $\\mu=100$ for the first experiment and $\\mathbb{E}[\\bar{d}_{s}]=100$ for the second experiment. The results are shown in Figure 2. On the left-hand side, we observe that when the number of rounds is low (and thus the amount of learning is limited), lower contrast values lead to better results. As the number of rounds (and therefore the amount of learning) increases, as expected, higher contrast simplifies the learning problem, as indicated by lower regret curves. Furthermore, on ther right hand side, the PA-DEMBA algorithm demonstrated robust performance, effectively managing the challenges posed by the non-thresholded setting. ", "page_idx": 8}, {"type": "image", "img_path": "gC3BzNwqQp/tmp/2fe467b1f043c11d834403189029a2db014ab5efd87b3aa49ea88704e58016cc.jpg", "img_caption": ["Figure 2: Left: Performance change of DEMBA algorithm with different contrast levels. Right: PADEMBA and benchmarks with non-thresholded delays. Results are averaged over 100 independent runs. "], "img_footnote": [], "page_idx": 9}, {"type": "image", "img_path": "gC3BzNwqQp/tmp/574d6c5dbf05080e274f7d6640c03329ae5d2805150fa96224ded5e51d981517.jpg", "img_caption": ["Figure 3: Comparison with MNL-Bandit. Left: no delay; Middle $\\mathbb{E}[d_{s}]=50$ ;Right: $\\mathbb{E}[d_{s}]=100$ Results are averaged over 100 independent runs. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "In our third set of experiments, we compare DEMBA algorithm and EXP benchmarks with MNLBandit algorihm from Agrawal et al. [2019]. While MNL-Bandit learns customer preferences similarly to DEMBA, it does not account for potential delays in the feedback. In this experiment, we considered $\\mu=500$ and we applied a geometric delay distribution with no delay, $\\mathbb{E}[\\bar{d}_{s}]=50$ and $\\mathbb{E}[d_{s}]=100$ . We observed that when there is no delay, the performance of MNL-Bandit and DEMBA is almost identical. However, as the delay increases, the performance of MNL-Bandit deteriorates, clearly indicating that it fails to handle delayed feedback. ", "page_idx": 9}, {"type": "text", "text": "8 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work provides the first solution and analysis for delayed choice modeling and online assortment optimization. We introduced two novel algorithms, DEMBA for thresholded feedback settings and PA-DEMBA for non-thresholded settings, demonstrating their effectiveness through theoretical guarantees and comprehensive experiments. Our algorithms address the dual challenges of unknown Multinomial Logit (MNL) parameters and delayed feedback, achieving sub-linear regret bounds. ", "page_idx": 9}, {"type": "text", "text": "Lastly, we discuss future work. Our lower bound suggest an improvement on regret by considering the delay distribution via $\\psi_{\\mu}$ . This would require learning the delay distribution itself, adding more complexity. Moreover, it could be interesting to explore scenarios where no-purchase decisions are indistinguishable from delayed purchases, such as settings where tracking no purchases is not possible. Additionally, it would be worthwhile to consider multi-level choice settings where customer preferences and rewards are revealed to the seller in multiple stages with delays between each stage. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "I would like to thank the anonymous referees for their valuable feedback, which has helped to improve this paper. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "A. Agarwal, N. Johnson, and S.Agarwal. Choice bandits. Advances in neural information processing systems, 33:18399-18410, 2020.   \nS. Agrawal, V. Avadhanula, V. Goyal, and A. Zeevi. Thompson sampling for the mnl-bandit. In Conference on Learning Theory, pages 76-78. PMLR, 2017.   \nS. Agrawal, V. Avadhanula, V. Goyal, and A. Zeevi. Mnl-bandit: A dynamic learning approach to assortment selection. Operations Research, 67(5):1453-1485, 2019.   \nP. Auer, N. Cesa-Bianchi, and P Fischer. Finite-time analysis of the multiarmed bandit problem. Machine learning, 47:235-256, 2002.   \nJ. Blanchet, R. Xu, and Z. Zhou. Delay-adaptive learning in generalized linear contextual bandits. Mathematics of Operations Research, 49(1):326-345, 2024.   \nN. Cesa-Bianchi, C. Gentile, Y. Mansour, and A. Minora. Delay and cooperation in nonstochastic bandits. In Conference on Learning Theory, pages 605-622. PMLR, 2016.   \nN. Cesa-Bianchi, T. Cesari, R. Colomboni, C. Gentile, and Y. Mansour. Nonstochastic bandits with composite anonymous feedback. The Journal of Machine Learning Research, 23(1):12713-12736, 2022.   \nO. Chapelle. Modeling delayed feedback in display advertising. In Proceedings of the 2Oth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1097-1105, 2014.   \nX. Chen and Y. Wang. A note on a tight lower bound for capacitated mnl-bandit assortment selection models. Operations Research Letters, 46(5):534-537, 2018.   \nX. Chen, Y. Wang, and Y. Zhou. Optimal policy for dynamic assortment planning under multinomial logit models. Mathematics of Operations Research, 46(4):1639-1657, 2021.   \nJ. Davis, G. Gallgo, and H. Topaloglu. Assortment planning under the multinomial logit model with totally unimodular constraint structures. 2013.   \nK. Dong, Y. Li, Q. Zhang, and Y. Zhou. Multinomial logit bandit with low switching cost. In International Conference on Machine Learning, pages 2607-2615. PMLR, 2020.   \nG. E. Flaspohler, F. Orabona, J. Cohen, S. Mouatadid, M. Oprescu, P. Orenstein, and L. Mackey. Onlinelearning with optimism and delay. In International Conference on Machine Learning, pages 3363-3373. PMLR, 2021.   \nM. A. Gael, C. Vernade, A. Carpentier, and M. Valko. Stochastic bandits with arm-dependent delays. In International Conference on Machine Learning, pages 3348-3356. PMLR, 2020.   \nA. Grover, T. Markov, P. Attia, N. Jin, N. Perkins, B. Cheong, M. Chen, Z. Yang, S. Harris, W. Chueh, et al. Best arm identification in multi-armed bandits with delayed feedback. In International Conference on Artificial Intelligence and Statistics, pages 833-842. PMLR, 2018.   \nB. Howson, C. Pike-Burke, and S. Filippi. Delayed feedback in generalised linear bandits revisited. In International Conference on Artificial Intelligence and Statistics, pages 6095-6119. PMLR, 2023.   \nP. Joulani, A. Gyorgy, and C. Szepesvari. Online learning under delayed feedback. In International Conference on Machine Learning, pages 1453-1461. PMLR, 2013.   \nT. Lancewicki, S. Segal, T. Koren, and Y. Mansour. Stochastic multi-armed bandits with unrestricted delay distributions. In International Conference on Machine Learning, pages 5969-5978. PMLR, 2021.   \nT. Lattimore and C. Szepesvari. Bandit algorithms. Cambridge University Press, 2020.   \nM. Mitzenmacher and E. Upfal, Probability and computing: Randomization and probabilistic techniques in algorithms and data analysis. Cambridge university press, 2017.   \nN. Perivier and V. Goyal. Dynamic pricing and assortment under a contextual mnl demand. Advances in Neural Information Processing Systems, 35:3461-3474, 2022.   \nC. Pike-Burke, S. Agrawal, C. Szepesvari, and S. Grunewalder. Bandits with delayed, aggregated anonymous feedback. In International Conference on Machine Learning, pages 4105-4113. PMLR, 2018.   \nP. Rusmevichientong, Z.-J. M. Shen, and D. B. Shmoys. Dynamic assortment optimization with a multinomial logit choice model and capacity constraint. Operations research, 58(6):1666-1680, 2010.   \nW. Tang, C.-J. Ho, and Y. Liu. Bandit learning with delayed impact of actions. Advances in Neural Information Processing Systems, 34:26804-26817, 2021.   \nY. Tang, Y. Wang, and Z. Zheng. Stochastic multi-armed bandits with strongly reward-dependent delays. In International Conference on Artificial Intelligence and Statistics, pages 3043-3051. PMLR, 2024.   \nT. S. Thune, N. Cesa-Bianchi, and Y. Seldin. Nonstochastic multiarmed bandits with unrestricted delays. Advances in Neural Information Processing Systems, 32, 2019.   \nC. Vernade, O. Cappe, and V. Perchet. Stochastic bandit models for delayed conversions. arXiv preprint arXiv:1706.09186, 2017.   \nC. Vernade, A. Carpentier, T. Lattimore, G. Zappella, B. Ermis, and M. Brueckner. Linear bandits with stochastic delayed feedback. In International Conference on Machine Learning, pages 9712-9721. PMLR, 2020.   \nY. Wang, X. Chen, and Y. Zhou. Near-optimal policies for dynamic multinomial logit assortment selection models. Advances in neural information processing systems, 31, 2018.   \nY. Yang, H. Zhong, T. Wu, B. Liu, L. Wang, and S. S. Du. A reduction-based framework for sequential decision making with delayed feedback. Advances in Neural Information Processing Systems, 36, 2024.   \nZ. Zhou, R. Xu, and J. Blanchet. Learning in generalized linear contextual bandits with stochastic delays. Advances in Neural Information Processing Systems, 32, 2019. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Proof of Lemma 4.1 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "We begin by providing an instrumental theorem that will be useful to establish concentration results ", "page_idx": 12}, {"type": "text", "text": "Theorem A.1 (Theorem 5 of Agrawal et al. [2019]) Consider $n$ i.i.d. geometric random variables $X_{1},\\ldots,X_{n}$ withparameter $p,$ i.e.for any $i$ ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathbb{P}(X_{i}=m)=(1-p)^{m}p\\quad\\forall m=\\{0,1,2,\\dots\\},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "and let $\\begin{array}{r}{\\mu=\\mathbb{E}(X_{i})=\\frac{1-p}{p}\\leq1}\\end{array}$ and $\\textstyle{\\bar{X}}={\\frac{1}{n}}\\sum_{i=1}^{n}X_{i}$ For any $\\zeta>0$ we have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\bar{X}>(1+\\zeta)\\mu)\\le\\exp\\left(-\\frac{n\\mu\\zeta^{2}}{2(1+\\zeta)(1+\\mu)^{2}}\\right).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "We now provide the proof of Lemma 4.1 that is crucial for our subsequent analysis. Proof of Lemma 4.1. Note that $\\hat{v}_{i,\\tau}$ is a biased estimator and defined as ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\hat{v}_{i,\\tau}=\\frac{\\tilde{v}_{i,\\tau}}{|E_{\\tau}(i)|}=\\frac{\\sum_{s=1}^{t_{\\tau}^{e n d}}o_{i,s,t_{\\tau}^{e n d}}}{|E_{\\tau}(i)|},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "$|E_{\\tau}(i)|$ $i$ $\\sum_{s=1}^{t_{\\tau}^{e n d}}o_{i,s,t_{\\tau}^{e n d}}$ is the total observed sales of product $i\\neq0d$ or is the total observed delayed no selections. ", "page_idx": 12}, {"type": "text", "text": "Let $t$ be the current period, i.e. $t=t_{\\tau}^{e n d}+1$ . We have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\widehat{\\nu}_{i,\\tau}-\\psi_{\\mu}v_{i}|=\\left|\\frac{\\sum_{s=1}^{t-1}\\alpha_{i,s}[-1}{|E_{\\tau}(i)|}-\\psi_{\\mu}v_{i}\\right|}\\\\ &{\\qquad\\qquad=\\left|\\frac{\\sum_{s=1}^{t-\\mu-1}a_{i,s}\\mathbb{I}(d_{s}\\leq\\mu)+\\sum_{s=t-\\mu}^{t-1}a_{i,s}\\mathbb{I}(d_{s}\\leq t-s)}{|E_{\\tau}(i)|}-\\psi_{\\mu}v_{i}\\right|}\\\\ &{\\qquad\\qquad=\\left|\\frac{\\sum_{s=1}^{t-1}a_{i,s}\\mathbb{I}(d_{s}\\leq\\mu)+\\sum_{s=t-\\mu}^{t-1}a_{i,s}\\mathbb{I}(\\mathbb{I}(d_{s}\\leq t-s)-\\mathbb{I}(d_{s}\\leq\\mu))}{|E_{\\tau}(i)|}-\\psi_{\\mu}v_{i}\\right|}\\\\ &{\\qquad\\qquad\\leq\\left|\\frac{\\sum_{s=1}^{t-1}a_{i,s}\\mathbb{I}(d_{s}\\leq\\mu)}{|E_{\\tau}(i)|}-\\psi_{\\mu}v_{i}\\right|+\\left|\\frac{\\sum_{s=t-\\mu}^{t-1}a_{i,s}\\mathbb{I}(d_{s}\\leq\\mu))}{|E_{\\tau}(i)|}\\right|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where the second equality follows from the decomposition of old observations before the threshold and recent observations, the third equality is rearrangement of the values and the last inequality follows from triangle inequality. ", "page_idx": 12}, {"type": "text", "text": "For the first element of (5), we have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\frac{\\sum_{s=1}^{t-1}a_{i,s}\\mathbb{I}\\left(d_{s}\\leq\\mu\\right)}{\\left|E_{\\tau}(i)\\right|}-\\psi_{\\mu}v_{i}\\right|=\\left|\\frac{\\sum_{s=1}^{t-1}a_{i,s}\\mathbb{I}\\left(d_{s}\\leq\\mu\\right)}{\\left|E_{\\tau}(i)\\right|}-\\frac{\\psi_{\\mu}\\sum_{s=1}^{t-1}a_{i,s}}{\\left|E_{\\tau}(i)\\right|}+\\frac{\\psi_{\\mu}\\sum_{s=1}^{t-1}a_{i,s}}{\\left|E_{\\tau}(i)\\right|}-\\psi_{\\mu}v_{i}\\right|}&{}\\\\ {\\leq\\left|\\frac{\\sum_{s=1}^{t-1}a_{i,s}\\mathbb{I}\\left(d_{s}\\leq\\mu\\right)}{\\left|E_{\\tau}(i)\\right|}-\\frac{\\psi_{\\mu}\\sum_{s=1}^{t-1}a_{i,s}}{\\left|E_{\\tau}(i)\\right|}\\right|+\\left|\\frac{\\psi_{\\mu}\\sum_{s=1}^{t-1}a_{i,s}}{\\left|E_{\\tau}(i)\\right|}-\\psi_{\\mu}v_{i}\\right|}&{}\\\\ {\\leq\\left|\\frac{\\mathbb{I}(d)}{\\left|E_{\\tau}(i)\\right|}-\\psi_{\\mu}\\right|+\\left|\\frac{\\mathbb{I}}{\\left|E_{\\tau}(i)\\right|}-v_{i}\\right|}&{~~~~~~~~~~~~~~}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "We have ", "page_idx": 12}, {"type": "equation", "text": "$$\n(a)\\leq\\sqrt{\\frac{\\log(N T)}{|E_{\\tau}(i)|}},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "by Hoeffding's inequality. ", "page_idx": 12}, {"type": "text", "text": "For part $(b)$ , we make use of the Chernoff bound from Theorem A.1 in two cases according to $\\begin{array}{r}{\\zeta=(v_{i}+1)\\sqrt{\\frac{6\\log(N T)}{v_{i}|E_{\\tau}(i)|}}}\\end{array}$ ", "page_idx": 13}, {"type": "text", "text": "Case $I\\;\\zeta\\leq{\\frac{1}{2}}$ : We have from Theorem A.1 ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}\\left(\\frac{\\sum_{s=1}^{t-1}a_{i,s}}{|E_{\\tau}(i)|}-v_{i}>\\zeta v_{i}\\right)\\le\\frac{1}{N^{2}T^{2}},}\\\\ {\\mathbb{P}\\left(\\frac{\\sum_{s=1}^{t-1}a_{i,s}}{|E_{\\tau}(i)|}-v_{i}<-\\zeta v_{i}\\right)\\le\\frac{1}{N^{2}T^{2}},}\\\\ {\\mathbb{P}\\left(\\left|\\frac{\\sum_{s=1}^{t-1}a_{i,s}}{|E_{\\tau}(i)|}-v_{i}\\right|>(v_{i}+1)\\sqrt{\\frac{6v_{i}\\log(N T)}{|E_{\\tau}(i)|}}\\right)\\le\\frac{2}{N^{2}T^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Therefore, we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left|\\frac{\\sum_{s=1}^{t-1}a_{i,s}}{|E_{\\tau}(i)|}-v_{i}\\right|>\\sqrt{\\frac{24v_{i}\\log(N T)}{|E_{\\tau}(i)|}}\\right)\\leq\\frac{2}{N^{2}T^{2}}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We shall generalize the result at 8 in two cases for substituting $v_{i}$ With $\\hat{v}_{i,\\tau}$ in the concentration radius and upper bounding the new bound utilizing $v_{i}$ ", "page_idx": 13}, {"type": "text", "text": "For $\\hat{v}_{i,\\tau}$ , we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\hat{v}_{i,\\tau}-v_{i}<-v_{i}\\frac{1}{2})\\leq\\frac{1}{N^{2}T^{2}},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "hence, ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{P}(2\\hat{v}_{i,\\tau}\\leq v_{i})\\leq\\frac{1}{N^{2}T^{2}}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Combining this with 8, we get ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left|\\frac{\\sum_{s=1}^{t-1}a_{i,s}}{|E_{\\tau}(i)|}-v_{i}\\right|>\\sqrt{\\frac{48\\hat{v}_{i,\\tau}\\log(N T)}{|E_{\\tau}(i)|}}\\right)\\leq\\frac{3}{N^{2}T^{2}}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "For upper bounding 9 using $v_{i}$ ,wehave ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\hat{v}_{i,\\tau}-v_{i}>v_{i}\\frac{1}{2})\\leq\\frac{1}{N^{2}T^{2}},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "hence ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\frac{3v_{i}}{2}\\leq\\hat{v}_{i,\\tau})\\leq\\frac{1}{N^{2}T^{2}}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Therefore, we conclude ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left|\\frac{\\sum_{s=1}^{t-1}a_{i,s}}{|E_{\\tau}(i)|}-v_{i}\\right|>\\sqrt{\\frac{72v_{i}\\log(N T)}{|E_{\\tau}(i)|}}\\right)\\leq\\frac{3}{N^{2}T^{2}}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Case $2\\,\\zeta>\\frac{1}{2}$ : We have $2\\zeta^{2}\\geq\\frac{1}{2}$ . Let $\\zeta^{\\prime}=2\\zeta^{2}$ . We have by Theorem A.1 ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\mathbb{P}\\left(\\left|\\frac{\\displaystyle\\sum_{s=1}^{t-1}a_{i,s}}{\\displaystyle|E_{\\tau}(i)|}-v_{i}\\right|>\\zeta^{\\prime}v_{i}\\right)\\leq\\exp\\left(-\\frac{\\displaystyle|E_{\\tau}(i)|v_{i}\\zeta^{\\prime2}}{2(1+\\zeta^{\\prime})(1+v_{i})^{2}}\\right)}\\\\ &{}&{\\leq\\exp\\left(-\\frac{\\displaystyle|E_{\\tau}(i)|v_{i}\\zeta^{\\prime}}{6(1+v_{i})^{2}}\\right),\\ \\ \\ \\ }\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "substituting the value of $\\zeta^{\\prime}$ , we get ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left|\\frac{\\sum_{s=1}^{t-1}a_{i,s}}{|E_{\\tau}(i)|}-v_{i}\\right|>\\frac{48\\log(N T)}{|E_{\\tau}(i)|}\\right)\\leq\\frac{1}{N^{2}T^{2}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Combining 9 and 11, and applying union bound we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left|\\frac{\\sum_{s=1}^{t-1}a_{i,s}}{|E_{\\tau}(i)|}-v_{i}\\right|\\le\\sqrt{\\frac{48\\hat{v}_{i,\\tau}\\log(N T)}{|E_{\\tau}(i)|}}+\\frac{48\\log(N T)}{|E_{\\tau}(i)|}\\right)\\ge1-\\frac{4}{N^{2}T}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Additionally, combining 9, 10 and 11, and applying union bound we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(\\left|\\frac{\\sum_{s=1}^{t-1}a_{i,s}}{|E_{\\tau}(i)|}-v_{i}\\right|>\\sqrt{\\frac{72v_{i}\\log(N T)}{|E_{\\tau}(i)|}}+\\frac{48\\log(N T)}{|E_{\\tau}(i)|}\\right)}\\\\ &{\\geq\\mathbb{P}\\left(\\left|\\frac{\\sum_{s=1}^{t-1}a_{i,s}}{|E_{\\tau}(i)|}-v_{i}\\right|\\leq\\sqrt{\\frac{48\\hat{v}_{i,\\tau}\\log(N T)}{|E_{\\tau}(i)|}}+\\frac{48\\log(N T)}{|E_{\\tau}(i)|}\\right)\\geq1-\\frac{4}{N^{2}T}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We can bound the second element of (1) as ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left|\\frac{\\sum_{s=t-\\mu}^{t-1}a_{i,s}\\bigl(1-\\mathbb{I}(d_{s}\\leq\\mu)\\bigr)}{|E_{\\tau}(i)|}\\right|\\leq\\frac{\\mu}{|E_{\\tau}(i)|}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Combining (7), (12) and (14) gives the result ", "page_idx": 14}, {"type": "text", "text": "\u53e3", "page_idx": 14}, {"type": "text", "text": "BProof of Theorem 5.1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We begin with establishing a key result that will be instrumental in our main proof. ", "page_idx": 14}, {"type": "text", "text": "Lemma B.1 Let $S^{*}$ represent the optimal assortment when the MNL parameters are given by $v$ Also, let $S_{\\tau}$ denote the assortment applied by the policy at epoch $\\tau$ .For any parameter set w distinct from v the followinghold. ", "page_idx": 14}, {"type": "text", "text": "ProofofLemma $B.1$ . Note that the proof of Part i. mostly resembles Lemma A.3 in Agrawal et al.   \n[2019], and we write the whole proof here for being self-contained. ", "page_idx": 14}, {"type": "text", "text": "Proof of Part i. Let $v^{j}$ be identical to $v$ except for the $j^{t h}$ element, which is increased to $w_{j}$ . We aim to show that for any $j\\in S^{*}$ ,if $v_{j}$ is increased to $w_{j}$ , then $R(S^{*};v^{j})\\geq R(S^{*};v)$ . This suffices to prove $R(S^{*};w)\\geq R(S^{*};v)$ ", "page_idx": 14}, {"type": "text", "text": "Define $\\textstyle T:=\\sum_{i\\in S^{*}\\backslash j}r_{i}v_{i}$ and $\\begin{array}{r}{V:=1+\\sum_{i\\in S^{*}\\backslash j}v_{i}}\\end{array}$ If there exists a $j\\in S^{*}$ such that $r_{j}<R(S^{*})$ removingproduct $j$ from the assortment yields higher expected revenue, contradicting the optimality of $S^{*}$ .Therefore, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{r_{j}\\geq R(S^{*};v)}\\\\ &{\\quad=\\cfrac{\\sum_{i\\in S^{*}}r_{i}v_{i}}{1+\\sum_{i\\in S^{*}}v_{i}}}\\\\ &{\\quad=\\cfrac{\\sum_{i\\in S^{*}\\setminus j}r_{i}v_{i}+r_{j}v_{j}}{1+\\sum_{i\\in S^{*}\\setminus j}v_{i}+v_{j}}}\\\\ &{\\quad=\\cfrac{T+r_{j}v_{j}}{V+v_{j}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "for all $j\\in S^{*}$ . Rearranging terms, we get ", "page_idx": 15}, {"type": "equation", "text": "$$\nr_{j}V\\geq T.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "To have $R(S^{*};v^{j})\\geq R(S^{*};v)$ , we need to show that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{T+r_{j}w_{j}}{V+w_{j}}\\geq\\frac{T+r_{j}v_{j}}{V+v_{j}},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "which is equivalent to ", "page_idx": 15}, {"type": "equation", "text": "$$\nT v_{j}+r_{j}V w_{j}\\geq T w_{j}+r_{j}V v_{j}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Rearranging terms, we get ", "page_idx": 15}, {"type": "equation", "text": "$$\nr_{j}V(w_{j}-v_{j})\\geq T(w_{j}-v_{j}),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "which holds thanks to (15). Moreover, the case for $i=0d$ holds trivially which concludes our proof. Proof of Part i. We have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{R(S_{\\tau};w)-R(S_{\\tau};v)=\\sum_{i\\in S_{e}}r_{i}\\frac{w_{i}}{1+{v_{0}}d+\\sum_{j\\in S_{e}}w_{j}}-\\sum_{i\\in S_{e}}r_{i}\\frac{v_{i}}{1+{v_{0}}d+\\sum_{j\\in S_{e}}v_{j}}}}\\\\ &{\\leq\\sum_{i\\in S_{e}}r_{i}\\frac{w_{i}}{1+{v_{0}}d+\\sum_{j\\in S_{e}}w_{j}}-\\sum_{i\\in S_{e}}r_{i}\\frac{v_{i}}{1+{v_{0}}d+\\sum_{j\\in S_{e}}w_{j}}}\\\\ &{=\\frac{\\sum_{i\\in S_{e}}r_{i}(w_{i}-v_{i})}{\\left(1+{v_{0}}d+\\sum_{j\\in S_{e}}w_{j}\\right)}}\\\\ &{\\leq\\frac{\\sum_{i\\in S_{e}}(w_{i}-v_{i})}{1+{v_{0}}d+\\sum_{j\\in S_{e}}v_{j}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the second inequality follows from $r_{i}\\leq1,\\forall i\\in[N]$ ", "page_idx": 15}, {"type": "text", "text": "\u53e3", "page_idx": 15}, {"type": "text", "text": "Now, we provide the proof of Theorem 5.1. ", "page_idx": 15}, {"type": "text", "text": "Proof of Theorem 5.1. We have ", "page_idx": 15}, {"type": "equation", "text": "$$\nR(S_{\\tau};\\bar{v}_{\\tau})\\geq R(S^{*};\\bar{v}_{\\tau})\\geq R(S^{*};\\psi_{\\mu}v),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the first inequality holds thanks to the definition of $S_{\\tau}$ and the second inequality follows from Lemma B.1 with probability at least $1-O(N^{-1}T^{-1})$ ", "page_idx": 15}, {"type": "text", "text": "We have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathsf{R e g}(T,\\pi)=\\mathbb{E}\\left[\\sum_{\\tau=1}^{\\bar{\\tau}}|\\mathcal{H}_{\\tau}|\\left(R(S^{\\ast};\\psi_{\\mu}v)-R(S_{\\tau};\\psi_{\\mu}v)\\right)\\right],\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\varkappa_{\\tau}$ is the duration oepch $\\tau$ and $\\begin{array}{r}{|\\mathcal{H}_{\\tau}|\\;\\sim\\;G e o m(\\frac{1}{1+\\psi_{\\mu}v_{0d}+\\sum_{j\\in S_{\\tau}}\\psi_{\\mu}v_{j}})}\\end{array}$ then $\\mathbb{E}[|\\mathcal{H}_{\\tau}|~|~\\$ $\\begin{array}{r}{S_{\\tau}]=1+\\psi_{\\mu}v_{0d}+\\sum_{j\\in S_{\\tau}}\\psi_{\\mu}v_{j}}\\end{array}$ Since is determined by the history of policy $(\\mathcal{F}_{\\tau-1})$ , we have $\\begin{array}{r}{\\mathbb{E}[|{\\mathcal{H}}_{\\tau}|\\ |\\ {\\mathcal{F}}_{\\tau-1}]=1+\\psi_{\\mu}v_{0d}+\\sum_{j\\in S_{\\tau}}\\psi_{\\mu}v_{j}}\\end{array}$ . Therefore the regret is equal to ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathsf{R e g}(T,\\pi)=\\mathbb{E}\\left[\\sum_{\\tau=1}^{\\bar{\\tau}}\\mathbb{E}\\left[\\left|\\mathcal{H}_{\\tau}\\right|(R(S^{\\ast};\\psi_{\\mu}\\upsilon)-R(S_{\\tau};\\psi_{\\mu}\\upsilon))\\mid\\mathcal{F}_{\\tau-1}\\right]\\right],\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and by the law of total expectations ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathsf{R e g}(T,\\pi)=\\mathbb{E}\\left[\\sum_{\\tau=1}^{\\tau}\\left(1+\\psi_{\\mu}v_{0d}+\\sum_{j\\in S_{\\tau}}\\psi_{\\mu}v_{j}\\right)(R(S^{*};\\psi_{\\mu}v)-R(S_{\\tau};\\psi_{\\mu}v))\\right].\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Let the epoch based regret be $\\Delta R_{\\tau}$ , we can write it as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\Delta R_{\\tau}=\\left(1+\\psi_{\\mu}v_{0d}+\\sum_{j\\in S_{\\tau}}\\psi_{\\mu}v_{j}\\right)\\left(R(S^{*};\\psi_{\\mu}v)-R(S_{\\tau};\\psi_{\\mu}v)\\right),\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "then the regret can be written in the form of ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathrm{Reg}(T,\\pi)=\\mathbb{E}\\left[\\sum_{\\tau=1}^{\\bar{\\tau}}\\Delta R_{\\tau}\\right].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We define event $\\mathcal{E}$ , for all $\\tau$ as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\tau}:=\\bigcup_{i=1}^{N}\\left\\{\\left|\\overline{{v}}_{i,\\tau}-\\psi_{\\mu}v_{i}\\right|>\\Delta_{\\tau}\\right\\}\\cup\\left\\{\\left|\\psi_{\\mu}v_{0d}-\\underline{{v}}_{0d,\\tau}\\right|>\\Delta_{\\tau}\\right\\}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The event $\\mathcal{E}_{\\tau}$ is a low probability event. We will analyze the regret according to the event separately: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\Delta R_{\\tau}]=\\mathbb{E}\\left[\\Delta R_{\\tau}\\mathbb{I}(\\mathcal{E}_{\\tau-1})+\\Delta R_{\\tau}\\mathbb{I}(\\mathcal{E}_{\\tau-1}^{C})\\right].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We have $\\Delta R_{\\tau}\\leq N+1$ and hence ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\Delta R_{\\tau}]\\leq(N+1)\\mathbb{P}(\\mathcal{E}_{\\tau-1})+\\mathbb{E}\\left[\\Delta R_{\\tau}\\mathbb{I}(\\mathcal{E}_{\\tau-1}^{C})\\right].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We have by (16) that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathfrak{L}[\\Delta R_{\\tau}]\\leq(N+1)\\mathbb{P}(\\mathcal{E}_{\\tau-1})+\\mathbb{E}\\left[\\left(1+\\psi_{\\mu}v_{0d}+\\sum_{j\\in S_{\\tau}}\\psi_{\\mu}v_{j}\\right)\\left(R_{\\tau}(S_{\\tau};\\bar{v}_{\\tau})-R(S_{\\tau};\\psi_{\\mu}v)\\right)\\mathbb{I}(\\mathcal{E}_{\\tau-1}^{C})\\right].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Then, by Lemma B.1 we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Bigg(1+\\phi_{\\operatorname*{max}}+\\sum_{\\substack{j=0}}^{\\infty}\\mathrm{e}_{j}\\mathrm{e}_{i}\\Bigg)\\Bigg(R(S;\\varepsilon,\\theta_{\\operatorname*{max}})-R(S;\\theta_{\\operatorname*{max}})\\mathrm{e}_{j}\\Bigg)[(E_{\\varepsilon-1}^{\\top})}\\\\ &{\\leq\\Bigg(1+\\phi_{\\operatorname*{max}}+\\sum_{\\substack{j=0}}^{\\infty}\\mathrm{e}_{j}\\mathrm{e}_{i}\\Bigg)\\Bigg)\\left(R(S;\\theta_{\\operatorname*{max}})-R(S;\\theta_{\\operatorname*{max}})\\mathrm{e}_{j}\\right)}\\\\ &{=\\Bigg(1+\\phi_{\\operatorname*{max}}+\\sum_{\\substack{j=0}}^{\\infty}\\mathrm{e}_{j}\\mathrm{e}_{i}\\Bigg)\\Bigg(\\frac{\\sum_{k\\in\\mathbb{N}_{\\theta_{\\operatorname*{max}}}}r_{k}\\mathrm{e}_{i}}{1+\\sum_{k\\in\\mathbb{N}_{\\theta_{\\operatorname*{max}}}}\\mathrm{e}_{j}\\mathrm{e}_{i}}-\\frac{\\sum_{k\\in\\mathbb{N}_{\\theta_{\\operatorname*{max}}}}r_{k}\\mathrm{e}_{i}}{1+\\sum_{k\\in\\mathbb{N}_{\\theta_{\\operatorname*{max}}}}\\mathrm{e}_{j}\\mathrm{e}_{i}}}\\\\ &{\\qquad+\\frac{\\sum_{k\\in\\mathbb{N}_{\\theta_{\\operatorname*{max}}}}r_{k}\\mathrm{e}_{i}}{1+\\sum_{k\\in\\mathbb{N}_{\\theta_{\\operatorname*{max}}}}\\mathrm{e}_{j}\\mathrm{e}_{k}}-\\frac{\\sum_{k\\in\\mathbb{N}_{\\theta_{\\operatorname*{max}}}}r_{k}\\mathrm{e}_{i}}{1+\\sum_{k\\in\\mathbb{N}_{\\theta_{\\operatorname*{max}}}}\\mathrm{e}_{j}\\mathrm{e}_{i}}\\Bigg)}\\\\ &{\\leq\\Bigg(1+\\phi_{\\operatorname*{max}}+\\sum_{\\substack{j=0}}^{\\infty}\\mathrm{e}_{j}\\mathrm{e}_{i}\\Bigg)^{-\\frac{\\sum_{k\\in\\mathbb{N}_{\\theta_{\\operatorname*{max}}}}r_{k}\\mathrm{e}_{i}}{1+\\sum_{k\\in\\mathbb{N}_{\\theta_{\\operatorname*{max}}}}\\mathrm{e}_{j}\\mathrm{e}_{i}}}\\Bigg)}\\\\ &{\\leq\\Bigg(1+\\phi_{\\operatorname*{max}}+\\sum \n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Let $E_{i}$ be the number of periods that the product $i$ is offered. Then, the regret can be written as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{t e g}(T,\\pi)\\le\\mathbb{E}\\Bigg[\\displaystyle\\sum_{r=1}^{r}\\Bigg((N+1)\\mathbb{P}(\\xi_{r-1})+K\\Delta\\mathsf{a}_{0,r}+\\sum_{i\\in S^{r}}\\Delta_{i,r}\\Bigg)\\Bigg]}\\\\ &{\\le\\mathbb{E}\\Bigg[\\displaystyle\\sum_{r=1}^{r}\\Bigg(\\frac{N+1}{N T^{2}}+K\\sqrt{\\frac{(2\\mathsf{D}\\alpha_{0,i}+1)\\log(N T)}{\\tau}}+\\frac{4\\mathsf{K}(\\log(N T)+\\mu)}{\\tau}}\\\\ &{\\phantom{2p c}+\\displaystyle\\sum_{\\ell\\in S^{r}}\\Bigg(\\sqrt{\\frac{(2\\mathsf{D}\\alpha_{0,i}+1)\\log(N T)}{|E_{\\ell}(i)|}}+\\frac{4\\mathsf{K}\\log(N T)+\\mu}{|E_{\\ell}(i)|}\\Bigg)\\Bigg)\\Bigg]}\\\\ &{\\le\\mathsf{L e g}(T)+K\\sqrt{\\frac{(\\mathsf{D}\\alpha_{0,i}-1)}{2(\\mathsf{K}\\tau)}\\mathsf{L e g}(N T)}+4\\mathsf{K}\\log(T)(\\log(N T)+\\mu)+\\tau3\\mathbb{E}\\left[\\displaystyle\\sum_{i=1}^{N}\\sqrt{\\mathsf{s}_{\\ell}|E_{i}\\log(N T)}\\right.}\\\\ &{\\quad\\left.+48\\log^{2}(N T)+\\mu\\log(T)}\\\\ &{\\le\\log(T)+K\\sqrt{\\Im T\\log(N T)}+48K\\log(T)(\\log(N T)+\\mu)+73\\sum_{i=1}^{N}\\sqrt{\\mathsf{s}_{\\ell}|E_{i}|\\log(N T)}}\\\\ &{\\quad+48\\log^{2}(N T)+\\mu\\log(T),}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the third inequality holds due to $\\bar{\\tau}\\le T,E_{i}\\le T$ and the fourth inequality holds due to Jensen's inequality. ", "page_idx": 17}, {"type": "text", "text": "Since, $\\begin{array}{r}{\\sum_{i=1}^{N}v_{i}\\mathbb{E}[E_{i}]\\leq T}\\end{array}$ , we conclude ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{{\\mathrm{Reg}}(T,\\pi)\\leq\\log(T)+K\\sqrt{73T\\log(N T)}+48K\\log(T)(\\log(N T)+\\mu)}\\\\ {+\\,73{\\sqrt{N T\\log(N T)}}+48\\log^{2}(N T)+\\mu\\log(T).\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "\u53e3", "page_idx": 17}, {"type": "text", "text": "C Proof of Theorem 5.2 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Before giving the proof of Theorem 5.2, we first give an instrumental Lemma in the main proof and its proof. ", "page_idx": 17}, {"type": "text", "text": "Lemma C.1 Let $P$ and $Q$ be categorical distributions with $\\mathbb{P}_{P}(X=i)=p_{i}$ and $\\mathbb{P}_{Q}(X=i)=q_{i}$ where $p_{i}=q_{i}+\\epsilon_{i}$ for all $i=1,\\dots,I$ Also, let the selected option be observed with bias $\\psi_{\\mu}$ .The Kullback-Leibler divergence between $P$ and $Q$ denotedby $D_{K L}(P\\parallel Q)$ , is given by ", "page_idx": 17}, {"type": "equation", "text": "$$\nD_{K L}(P\\parallel Q)=\\sum_{i=0}^{I}\\frac{\\psi_{\\mu}\\epsilon_{i}^{2}}{q_{i}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof of Lemma C.1. We have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\cal D}_{K L}(P\\parallel Q)=\\sum_{i=0}^{I}\\psi_{\\mu}(q_{i}+\\epsilon_{i})\\log\\left(\\frac{\\psi_{\\mu}(q_{i}+\\epsilon_{i})}{\\psi_{\\mu}q_{i}}\\right)}}\\\\ {{\\displaystyle\\qquad\\qquad\\leq\\sum_{i=0}^{I}\\psi_{\\mu}(q_{i}+\\epsilon_{i})\\frac{\\epsilon_{i}}{q_{i}}}}\\\\ {{\\displaystyle\\qquad=\\sum_{i=0}^{I}\\frac{\\psi_{\\mu}\\epsilon_{i}^{2}}{q_{i}},}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the inequality follows since $\\log(1+x)\\leq x$ for any $x>-1$ and the last equality holds since $\\textstyle\\sum_{i=0}^{I}\\epsilon_{i}=0$ ", "page_idx": 17}, {"type": "text", "text": "\u53e3", "page_idx": 17}, {"type": "text", "text": "Proof of Theorem 5.2. We set $p_{i}=1$ for all $i\\in[N]$ . Let $S$ be a subset of $N$ with $|S|=K$ . For attraction parameters, we set $v_{0}=1$ \uff0c $v_{0d}$ arbitrary in $[0,1]$ \uff0c $v_{i}=(1+\\epsilon)/K$ for $i\\in S$ and $v_{i}=1/K$ otherwise. ", "page_idx": 18}, {"type": "text", "text": "We denote all subsets of product set $[N]$ of size $K$ as $\\displaystyle{S_{K}}$ . We have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{S\\in S_{K}}R(S)=R(S^{*})=\\frac{1+\\epsilon}{2+v_{0d}+\\epsilon}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We employ the neighboring argument for assortment sets as described in Chen and Wang [2018]. For any arbitrary assortment $S_{t}$ ,wehave ", "page_idx": 18}, {"type": "equation", "text": "$$\nR(S_{t})=\\frac{1+(1-\\delta)\\epsilon}{2+v_{0d}+(1-\\delta)\\epsilon},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where 8is a measure of discrepancy from the optimal set S,. := 1 - Ss. ", "page_idx": 18}, {"type": "text", "text": "Then, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R(S^{*})-R(S_{t})=\\cfrac{1+\\epsilon}{2+v_{0d}+\\epsilon}-\\cfrac{1+(1-\\delta)\\epsilon}{2+v_{0d}+(1-\\delta)\\epsilon}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\cfrac{\\delta\\epsilon+\\delta\\epsilon v_{0d}}{(2+v_{0d}+\\epsilon)(2+v_{0d}+(1-\\delta)\\epsilon)}}\\\\ &{\\qquad\\qquad\\qquad\\geq\\cfrac{\\delta\\epsilon\\,(1+v_{0d})}{16}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For any arbitrary subset $S_{t}$ of $|S_{t}|\\,\\le\\,K$ , we can find $\\tilde{S}_{t}\\;\\in\\;S_{K}$ such that $S_{t}\\ \\subseteq\\ \\tilde{S}_{t}$ . We define $\\begin{array}{r}{\\tilde{N}_{i}:=\\sum_{t=1}^{T}1(i\\in\\tilde{S}_{t})}\\end{array}$ . We have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\Tilde{S}\\in\\Tilde{S}_{K}}{\\operatorname*{max}}\\sum_{\\Tilde{\\boldsymbol{\\pi}}_{S}}\\left[R(S)-R(S_{t})\\right]}\\\\ &{\\geq\\underset{\\Tilde{S}\\in\\Tilde{S}_{K}}{\\operatorname*{max}}\\sum_{\\Tilde{\\boldsymbol{\\pi}}_{S}}\\left[R(S)-R(\\Tilde{S}_{t})\\right]}\\\\ &{\\geq\\frac{1}{|S|}\\underset{S\\in\\Tilde{S}_{K}}{\\sum}\\underset{s_{0}\\in S_{K}}{\\sum}\\mathbb{E}_{S}\\left[R(S)-R(\\Tilde{S}_{t})\\right]}\\\\ &{\\geq\\frac{1}{16|S|}\\underset{S\\in\\Tilde{S}_{K}}{\\sum}\\underset{i\\Tilde{S}\\in\\mathcal{S}_{K}}{\\sum}\\mathbb{E}_{S}\\left[\\Tilde{N}_{i}\\right]\\frac{\\epsilon}{K}}\\\\ &{=\\frac{\\epsilon}{16}\\left(T-\\frac{1}{|S|}\\underset{S\\in\\mathcal{S}_{K}}{\\sum}\\underset{i\\Tilde{S}}{\\sum}\\underset{k=1}{\\sum}{\\sum}\\frac{\\mathbb{E}_{S}\\left[\\Tilde{N}_{i}\\right]}{K}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Let ${\\cal S}_{K-1}^{(i)}$ be all subsets of $[N]$ of size $K-1$ that do not include $i$ We have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\frac{1}{K|S_{K}|}\\sum_{S\\in S_{K}}\\sum_{i\\in S}\\mathbb{E}_{S_{1}\\cup S_{2}^{*}}\\left[\\tilde{N}_{i}\\right]=\\frac{1}{K|S_{K}|}\\sum_{i=1}^{N}\\sum_{S\\in S_{K}:i\\in S}\\mathbb{E}_{S}\\left[\\tilde{N}_{i}\\right]}}\\\\ &{}&{=\\frac{1}{K|S_{K}|}\\sum_{i=1}^{N}\\sum_{S^{\\prime}\\in S_{K-1}^{(i)}}\\mathbb{E}_{S^{\\prime}\\cup\\left\\{i\\right\\}}\\left[\\tilde{N}_{i}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We define probability measures $P$ and $Q$ through parameterizations $S^{\\prime}$ and $S^{\\prime}\\cup\\{i\\}$ respectively. We denote Total Variation(TV) distance between two probability measures as $T\\dot{V}({\\cal P},Q):=$ $\\operatorname*{sup}_{A}|P(A)-Q(A)|$ and Kullback-Leibler (KL) divergence as $D_{K L}(P\\parallel Q)$ . We have $0\\leq\\tilde{N}_{i}\\leq T$ ", "page_idx": 18}, {"type": "text", "text": "and ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\mathbb{E}_{P}[\\tilde{N_{i}}]-\\mathbb{E}_{Q}[\\tilde{N_{i}}]\\right|\\leq\\displaystyle\\sum_{j=0}^{T}j\\left|P(\\tilde{N_{i}}=j)-Q(\\tilde{N_{i}}=j)\\right|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq T\\displaystyle\\sum_{j=0}^{T}\\left|P(\\tilde{N_{i}}=j)-Q(\\tilde{N_{i}}=j)\\right|}\\\\ &{\\qquad\\qquad\\qquad\\leq T\\cdot T V(P,Q)}\\\\ &{\\qquad\\qquad\\qquad\\leq T\\cdot\\sqrt{\\displaystyle\\frac{1}{2}D_{K L}(P\\parallel Q)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the last inequality follows from Pinsker's Inequality. ", "page_idx": 19}, {"type": "text", "text": "We use (23) in (22) and we get ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{K|S_{K}|}\\sum_{S\\in S_{K}}\\sum_{i\\in S}\\mathbb{E}_{S}\\left[\\tilde{N}_{i}\\right]}\\\\ &{\\displaystyle\\leq\\frac{1}{K|S_{K}|}\\sum_{i=1}^{N}\\sum_{S^{\\prime}\\in S_{K-1}^{(i)}}\\left(\\mathbb{E}_{S^{\\prime}}\\left[\\tilde{N}_{i}\\right]+T\\cdot\\sqrt{\\frac{1}{2}D_{K L}(P_{S^{\\prime}}\\parallel P_{S^{\\prime}\\cup\\{i\\}})}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "For the first element of (24), we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\frac{1}{K|S_{K}|}\\displaystyle\\sum_{i=1}^{N}\\displaystyle\\sum_{\\boldsymbol{s}^{\\prime}\\in S_{K-1}^{(i)}}\\mathbb{E}_{\\boldsymbol{s}^{\\prime}}\\left[\\tilde{N}_{i}\\right]=\\displaystyle\\frac{1}{K|S_{K}|}\\displaystyle\\sum_{\\boldsymbol{s}^{\\prime}\\in S_{K-1}^{\\prime}}\\displaystyle\\sum_{i\\notin S^{\\prime}}\\mathbb{E}_{\\boldsymbol{s}^{\\prime}}\\left[\\tilde{N}_{i}\\right]}\\\\ {\\displaystyle}&{\\le\\displaystyle\\frac{1}{K|S_{K}|}\\displaystyle\\sum_{\\boldsymbol{s}^{\\prime}\\in S_{K-1}^{\\prime}}\\displaystyle\\sum_{i=1}^{N}\\mathbb{E}_{\\boldsymbol{s}^{\\prime}}\\left[\\tilde{N}_{i}\\right]}\\\\ {\\displaystyle}&{=\\displaystyle\\frac{|S_{K-1}|}{K|S_{K}|}T K}\\\\ {\\displaystyle}&{=\\displaystyle\\frac{T K}{N-K+1}}\\\\ {\\displaystyle}&{\\le\\frac{T}{3},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the last inequality follows from $K\\le N/4$ ", "page_idx": 19}, {"type": "text", "text": "For the second element of (24), we have that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\frac{T}{K|S_{K}|}\\sum_{i=1}^{N}\\sum_{s^{\\prime}\\in S_{K-1}^{(i)}}\\sqrt{\\frac{1}{2}D_{K L}(P_{S^{\\prime}}\\parallel P_{S^{\\prime}\\cup\\{i\\}})}}\\quad}&{}\\\\ &{\\leq\\frac{T|S_{K-1}|}{K|S_{K}|}\\sum_{i=1}^{N}\\operatorname*{max}_{s^{\\prime}\\in S_{K-1}^{(i)}}\\sqrt{\\frac{1}{2}D_{K L}(P_{S^{\\prime}}\\parallel P_{S^{\\prime}\\cup\\{i\\}})}}\\\\ &{=\\frac{T}{N-K+1}\\sum_{i=1}^{N}\\operatorname*{max}_{s^{\\prime}\\in S_{K-1}^{(i)}}\\sqrt{\\frac{1}{2}D_{K L}(P_{S^{\\prime}}\\parallel P_{S^{\\prime}\\cup\\{i\\}})}}\\\\ &{\\leq\\operatorname*{max}_{s^{\\prime}\\in S_{K-1}^{(i)}}T\\sqrt{\\frac{1}{2(N-K+1)}\\sum_{i\\notin S^{\\prime}}D_{K L}(P_{S^{\\prime}}\\parallel P_{S^{\\prime}\\cup\\{i\\}})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the first inequality is due to Holder's inequality and the second inequality follows from Jansen's inequality. ", "page_idx": 19}, {"type": "text", "text": "We have $D_{K L}(P_{S^{\\prime}}(\\cdot|S_{t})\\ \\ |\\ \\ P_{S^{\\prime}\\cup\\{i\\}}(\\cdot|S_{t}))\\;=\\;0$ for $i\\notin\\ S_{t}$ . For analyzing $i\\ \\in\\ S_{t}$ , we define $K^{\\prime}=|S_{t}|\\le K$ $J:=|S_{t}\\cap S^{\\prime}|\\le K-1$ and $\\begin{array}{r}{a=1+v_{0d}+\\frac{K^{\\prime}}{K}}\\end{array}$ ", "page_idx": 20}, {"type": "text", "text": "We have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{|p_{0}-q_{0}|=\\bigg|\\frac{1}{a+J\\epsilon/K}-\\frac{1}{a+(J+1)\\epsilon/K}\\bigg|}}\\\\ &{=\\frac{\\epsilon}{K(a^{2}+a J\\epsilon/K+a(J+1)\\epsilon/K+J(J+1)\\epsilon^{2}/K^{2})}}\\\\ &{\\le\\frac{\\epsilon}{K};}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\vert p_{0d}-q_{0d}\\vert=v_{0d}\\left\\vert\\cfrac{1}{a+J\\epsilon/K}-\\cfrac{1}{a+(J+1)\\epsilon/K}\\right\\vert}}\\\\ &{=\\cfrac{v_{0d}\\epsilon}{K(a^{2}+a J\\epsilon/K+a(J+1)\\epsilon/K+J(J+1)\\epsilon^{2}/K^{2})}}\\\\ &{\\le\\cfrac{v_{0d}\\epsilon}{K};}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|p_{j}-q_{j}\\right|\\leq\\displaystyle\\frac{1+\\epsilon}{K}\\left|\\frac{1}{a+J\\epsilon/K}-\\frac{1}{a+(J+1)\\epsilon/K}\\right|}\\\\ &{\\qquad\\qquad=\\displaystyle\\frac{\\epsilon+\\epsilon^{2}}{K^{2}(a^{2}+a J\\epsilon/K+a(J+1)\\epsilon/K+J(J+1)\\epsilon^{2}/K^{2})}}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\frac{2\\epsilon}{K^{2}}\\quad\\mathrm{for~}1\\leq j\\leq N\\mathrm{~and~}j\\neq i;}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\left|p_{i}-q_{i}\\right|\\le\\displaystyle\\frac{1}{K}\\left|\\frac{1}{a+J\\epsilon/K}-\\frac{1}{a+(J+1)\\epsilon/K}\\right|+\\frac{\\epsilon}{K}\\frac{1}{a+J\\epsilon/K}}}\\\\ &{\\le\\displaystyle\\frac{\\epsilon}{K^{2}}+\\frac{\\epsilon}{K}}\\\\ &{\\le\\displaystyle\\frac{2\\epsilon}{K}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We also have ", "page_idx": 20}, {"type": "equation", "text": "$$\nq_{0}=\\frac{1}{a+(J+1)\\epsilon/K}\\geq\\frac{1}{3+\\epsilon}\\geq\\frac{1}{3+1/2}\\geq\\frac{1}{4},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and ", "page_idx": 20}, {"type": "equation", "text": "$$\nq_{j}=\\frac{1+\\epsilon}{K(a+(J+1)\\epsilon/K)}\\geq\\frac{1+\\epsilon}{4K}\\geq\\frac{1}{4K}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Using these with Lemma C.1, we get ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{D_{K L}(P_{S^{\\prime}}(\\cdot|S_{t})\\ ||\\ P_{S^{\\prime}\\cup\\{i\\}}(\\cdot|S_{t}))\\le\\psi_{\\mu}\\left(\\displaystyle\\frac{4\\epsilon^{2}}{K^{2}}+\\displaystyle\\frac{4v_{0d}^{2}\\epsilon^{2}}{K^{2}}+\\displaystyle\\frac{4K\\cdot J\\cdot4\\epsilon^{2}}{K^{4}}+\\displaystyle\\frac{4K\\cdot4\\epsilon^{2}}{K^{2}}\\right)}&{}\\\\ {\\le\\psi_{\\mu}\\left(\\displaystyle\\frac{8\\epsilon^{2}}{K^{2}}+\\displaystyle\\frac{16\\epsilon_{1}^{2}}{K^{2}}+\\displaystyle\\frac{16\\epsilon_{1}^{2}}{K}\\right)}&{}\\\\ {\\le\\displaystyle\\frac{40\\psi_{\\mu}\\epsilon_{1}^{2}}{K}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Integrating this into (33), we obtain ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{s^{\\prime}\\in\\delta_{K-1}}{\\operatorname*{max}}T\\sqrt{\\frac{1}{2(N-K+1)}\\displaystyle\\sum_{i\\notin S^{\\prime}}D_{K L}(P_{S^{\\prime}}\\parallel P_{S^{\\prime}\\cup\\{i\\}})}}\\\\ &{\\leq\\underset{s^{\\prime}\\in\\delta_{K-1}}{\\operatorname*{max}}T\\sqrt{\\frac{1}{2(N-K+1)}\\displaystyle\\sum_{i\\notin S^{\\prime}}\\mathbb{E}_{s^{\\prime}}[\\tilde{N}_{i}]\\frac{40\\psi_{\\mu}\\epsilon^{2}}{K}}}\\\\ &{\\leq T\\sqrt{\\frac{1}{2(N-K+1)}\\displaystyle\\frac{40\\psi_{\\mu}\\epsilon^{2}}{K}\\displaystyle\\sum_{i=1}^{N}\\mathbb{E}_{s^{\\prime}}[\\tilde{N}_{i}]}}\\\\ &{\\leq T\\sqrt{\\frac{1}{2(N-K+1)}\\frac{40\\psi_{\\mu}\\epsilon^{2}}{K}}T K.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "For the final bound, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{S\\in S_{K}}{\\mathrm{max}}\\sum_{t=1}^{T}\\mathbb{E}_{S}\\left[R(S)-R(S_{t})\\right]}\\\\ &{\\geq\\frac{\\epsilon}{16}\\left(T-\\frac{1}{\\left|S_{K}\\right|}\\displaystyle\\sum_{S\\in S_{K}}\\displaystyle\\sum_{i\\in S}\\frac{\\mathbb{E}_{S}\\left[\\tilde{N}_{i}\\right]}{K}\\right)}\\\\ &{\\geq\\frac{\\epsilon}{16}\\left(T-\\frac{T}{3}-T\\sqrt{\\frac{1}{2\\left(N-K+1\\right)}\\frac{40\\psi_{\\mu}\\epsilon^{2}T K}{K}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where (38) follows from (21), (39) follows from (29) and (37). ", "page_idx": 21}, {"type": "text", "text": "Setting $\\epsilon_{1}=\\operatorname*{min}\\{\\sqrt{N/\\psi_{\\mu}T},0.5\\}$ gives the final bound. ", "page_idx": 21}, {"type": "text", "text": "\u53e3", "page_idx": 21}, {"type": "text", "text": "D Proof of Theorem 6.2 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We first provide an instrumental theorem that we will use to establish concentration results. ", "page_idx": 21}, {"type": "text", "text": "Theorem D.1 (Theorem 4.4 of Mitzenmacher and Upfal [2017]) Let $X_{1},\\ldots,X_{n}$ beindependent Poisson trials such that $\\mathbb{P}(X_{i}=1)=p_{i}$ Let $\\textstyle X=\\sum_{i=1}^{n^{-}}X_{i}$ Then,for $0<\\delta<1$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}(X\\geq(1+\\delta)\\mathbb{E}[X])\\leq\\exp(-\\mathbb{E}[X]\\delta^{2}/3).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof of Lemma 6.1. ", "page_idx": 21}, {"type": "text", "text": "We have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\hat{v}_{i,\\tau}-v_{i}|=\\left|\\frac{\\sum_{s=1}^{t-1}{\\sigma_{i,s,t-1}}}{|E_{i}(\\tau)|}-v_{i}\\right|}\\\\ {=\\left|\\frac{\\sum_{s=1}^{t-1}{a_{i,s}}\\mathbb{I}(d_{s}\\leq t-s)}{|E_{i}(\\tau)|}-v_{i}\\right|}\\\\ {=\\left|\\frac{\\sum_{s=1}^{t-1}{a_{i,s}}-\\sum_{s=1}^{t-1}{a_{i,s}}\\mathbb{I}(d_{s}>t-s)}{|E_{i}(\\tau)|}-v_{i}\\right|}\\\\ {\\leq\\left|\\frac{\\sum_{s=1}^{t-1}{a_{i,s}}}{|E_{i}(\\tau)|}-v_{i}\\right|+\\left|\\frac{\\sum_{s=1}^{t-1}\\mathbb{I}(d_{s}>t-s)}{|E_{i}(\\tau)|}\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The derivation of the bound for the first element of (41) parallels that of Lemma 4.1, thus, we omit the analysis, yielding ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\bigg|\\frac{\\sum_{s=1}^{t-1}a_{i,s}}{|E_{i}(\\tau)|}-v_{i}\\bigg|\\leq\\sqrt{\\frac{48\\hat{v}_{i,\\tau}\\log(N T)}{|E_{i}(\\tau)|}}+\\frac{48\\log(N T)}{|E_{i}(\\tau)|},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "with probability at least $1-\\frac{4}{N^{2}T}$ ", "page_idx": 22}, {"type": "text", "text": "For the second element of (41), we first bound the expected number of unobserved feedback until time $t$ Wehave ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{E}\\left[\\sum_{s=1}^{t-1}\\mathbb{I}(d_{s}>t-s)\\right]=\\sum_{s=1}^{t-1}\\mathbb{P}(d_{s}>t-s)=\\sum_{n=1}^{t-1}\\mathbb{P}(d_{t-n}>n)}}\\\\ &{\\le\\sum_{n=0}^{\\infty}\\mathbb{P}(d_{1}>n)=\\sum_{n=0}^{\\infty}\\sum_{m=n+1}^{\\infty}\\mathbb{P}(d_{1}=m)}\\\\ &{=\\displaystyle\\sum_{m=0}^{\\infty}\\sum_{n=0}^{m-1}\\mathbb{P}(d_{1}=m)=\\sum_{m=0}^{\\infty}m\\cdot\\mathbb{P}(d_{1}=m)}\\\\ &{=\\mathbb{E}[d_{s}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Then, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\quad}&{\\frac{\\sum_{s=1}^{t-1}\\mathbb{I}(d_{s}>t-s)}{|E_{i}(\\tau)|}\\Bigg|=\\frac{\\sum_{s=1}^{t-1}\\mathbb{I}(d_{s}>t-s)}{|E_{i}(\\tau)|}}\\\\ &{\\qquad\\qquad\\leq\\frac{(1+\\delta)\\mathbb{E}\\left[\\sum_{s=1}^{t-1}\\mathbb{I}(d_{s}>t-s)\\right]}{|E_{i}(\\tau)|}}\\\\ &{\\qquad\\qquad\\leq\\frac{(1+\\delta)\\mathbb{E}\\left[d_{s}\\right]}{|E_{i}(\\tau)|}}\\\\ &{\\qquad\\qquad\\leq\\frac{\\mathbb{E}\\left[d_{s}\\right]}{|E_{i}(\\tau)|}+\\frac{\\sqrt{6\\mathbb{E}\\left[d_{s}\\right]\\log(N T)}}{|E_{i}(\\tau)|}}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the first inequality follows by Theorem D.1 with probability at least $1\\,-\\,{\\frac{1}{N^{2}T^{2}}}$ by setting $\\begin{array}{r}{\\delta=\\sqrt{\\frac{6\\log(N T)}{\\mathbb{E}[d_{s}]}}}\\end{array}$ and the second inequality follows from 43. ", "page_idx": 22}, {"type": "text", "text": "Combining 42 and 47 gives the result ", "page_idx": 22}, {"type": "text", "text": "\u53e3", "page_idx": 22}, {"type": "text", "text": "Proof of Theorem 6.2. ", "page_idx": 22}, {"type": "text", "text": "We will proceed similarly to the proof of Theorem 5.1, but we provide a complete proof here for clarity and completeness. ", "page_idx": 22}, {"type": "text", "text": "We have ", "page_idx": 22}, {"type": "equation", "text": "$$\nR(S_{\\tau};\\bar{v}_{\\tau})\\geq R(S^{*};\\bar{v}_{\\tau})\\geq R(S^{*};v),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the first inequality holds thanks to the definition of $S_{\\tau}$ and the second inequality follows from Lemma B.1 with probability at least $1-O(N^{-1}T^{-1})$ ", "page_idx": 22}, {"type": "text", "text": "Similar to the proof of Theorem 5.1, we can write ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathsf{R e g}(T,\\pi)=\\mathbb{E}\\left[\\sum_{\\tau=1}^{\\bar{\\tau}}\\left(1+v_{0d}+\\sum_{j\\in S_{\\tau}}v_{j}\\right)\\left(R(S^{\\ast};v)-R(S_{\\tau};v)\\right)\\right].\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "And defining the epoch based regret be $\\Delta R_{\\tau}$ , we can write it as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\Delta R_{\\tau}=\\left(1+v_{0d}+\\sum_{j\\in S_{\\tau}}v_{j}\\right)\\left(R(S^{\\ast};v)-R(S_{\\tau};v)\\right),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "which will lead to ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathrm{Reg}(T,\\pi)=\\mathbb{E}\\left[\\sum_{\\tau=1}^{\\bar{\\tau}}\\Delta R_{\\tau}\\right].\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We define event $\\mathcal{E}$ , for all $\\tau$ as ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\tau}:=\\bigcup_{i=1}^{N}\\left\\{\\left|\\overline{{v}}_{i,\\tau}-v_{i}\\right|>\\Delta_{\\tau}\\right\\}\\cup\\left\\{\\left|v_{0d}-\\underline{{v}}_{0d,\\tau}\\right|>\\Delta_{\\tau}\\right\\}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Conditioning on the event and by (48), we can write ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\Delta R_{\\tau}]\\leq(N+1)\\mathbb{P}(\\mathcal{E}_{\\tau-1})+\\mathbb{E}\\left[\\left(1+v_{0d}+\\sum_{j\\in S_{\\tau}}v_{j}\\right)\\left(R_{\\tau}(S_{\\tau};\\bar{v}_{\\tau})-R(S_{\\tau};v)\\right)\\mathbb{I}(\\mathcal{E}_{\\tau-1}^{C})\\right].\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Then, by Lemma B.1 we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Bigg(1+\\operatorname*{max}_{j\\in\\mathcal{X}_{s}}\\Bigg)\\Bigg(H(S_{s},\\varepsilon_{w})-H(S_{s},\\varepsilon_{w})\\Bigg)|\\xi|_{\\mathcal{X}_{s}}^{\\varepsilon}\\Bigg)}\\\\ &{\\lesssim\\Bigg(1+\\operatorname*{max}_{j\\in\\mathcal{X}_{s}}\\frac{\\nabla L(S_{w},\\varepsilon_{w})}{\\mu(\\varepsilon_{w})}\\Bigg)\\Bigg(\\frac{\\nabla L(S_{w},\\varepsilon_{w})-H(S_{w},\\varepsilon_{w})}{1+\\mu(\\varepsilon_{w})}\\Bigg)}\\\\ &{=\\Bigg(1+\\operatorname*{max}_{j\\in\\mathcal{X}_{s}}\\frac{\\nabla L(S_{w},\\varepsilon_{w})}{\\mu(\\varepsilon_{w})}\\Bigg)\\Bigg(\\frac{\\nabla L(S_{w},\\varepsilon_{w}|\\nabla R_{s},\\varepsilon_{w})}{1+\\operatorname*{max}_{j\\in\\mathcal{X}_{s}}\\frac{\\nabla L(S_{w},\\varepsilon_{w})}{\\mu(\\varepsilon_{w})}-1+\\operatorname*{max}_{j\\in\\mathcal{X}_{s}}\\frac{\\nabla L(S_{w},\\varepsilon_{w})}{\\mu(\\varepsilon_{w})}}}\\\\ &{\\qquad+\\frac{\\sum_{j\\in\\mathcal{X}_{s}}\\nabla L(S_{w},\\varepsilon_{w})}{1+\\operatorname*{max}_{j\\in\\mathcal{X}_{s}}\\frac{\\nabla L(S_{w},\\varepsilon_{w})}{\\mu(\\varepsilon_{w})}-1+\\operatorname*{max}_{j\\in\\mathcal{X}_{s}}\\frac{\\nabla L(S_{w},\\varepsilon_{w})}{\\mu(\\varepsilon_{w})}}\\Bigg)}\\\\ &{\\leq\\Bigg(1+\\operatorname*{max}_{j\\in\\mathcal{Y}_{s}}\\frac{\\nabla L(S_{w},\\varepsilon_{w})}{\\mu(\\varepsilon_{w})}\\Bigg)\\Bigg(\\frac{\\sum_{j\\in\\mathcal{X}_{s}}\\nabla L(S_{w},\\varepsilon_{w})}{(1+\\operatorname*{max}_{j\\in\\mathcal{Y}_{s}}\\frac{\\nabla L(S_{w},\\varepsilon_{w})}{\\mu(\\varepsilon_{w})}+1)+\\operatorname*{max}_{j\\in\\mathcal{Y}_{s}}\\frac{\\nabla L(S_{w},\\varepsilon_{w})}{\\mu(\\varepsilon_{w})}}\\Bigg)}\\\\ &{\\leq\\Bigg(1+\\operatorname*{max}_{j\\in\\mathcal{X}_{s}}\\frac{\\nabla L(S_{w},\\varepsilon_{w})}{\\mu(\\varepsilon\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Let $E_{i}$ be the number of periods that the product $i$ is offered. Then, the regret can be written as ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{teg}(T,\\tau)\\leq\\mathbb{E}\\Bigg[\\frac{\\dot{\\gamma}}{\\sum_{t=1}^{T}}\\Bigg((N+1)\\mathbb{F}(\\xi_{-1})+K\\tilde{\\Delta}_{0,t}+\\sum_{i=F}\\tilde{\\Delta}_{i,t})\\Bigg]}\\\\ &{\\quad\\quad\\leq\\mathbb{E}\\Bigg[\\frac{\\dot{\\gamma}}{\\sum_{t=1}^{T}}\\Bigg(\\frac{N+1}{N T^{2}}+K\\sqrt{\\frac{48\\lambda_{t}}{1\\sqrt{\\Delta}}\\mathrm{te}(\\mathbb{N}T)}+\\frac{48K\\log(N T)}{\\vert E_{t}\\vert}+\\frac{K\\mathbb{E}[\\dot{\\delta}]_{i}}{\\vert E_{t}\\vert\\tau\\vert}\\Bigg)+\\frac{\\sqrt{65}\\vert\\hat{\\mathcal{A}}_{i}\\vert\\log(\\lambda_{t})}{\\vert E_{t}\\vert\\tau\\vert}}\\\\ &{\\quad\\quad\\quad+\\sum_{t=*}\\bigg(\\sqrt{\\frac{48\\lambda_{t}}{1\\sqrt{\\Delta}}\\mathrm{te}(\\mathbb{N}T)}+\\frac{48\\log(N T)}{\\vert E_{t}\\vert}+\\frac{\\mathbb{E}[\\dot{\\mu}]_{i}}{\\vert E_{t}\\vert\\tau\\vert}\\bigg)+\\frac{\\sqrt{65}\\vert\\hat{\\mathcal{A}}_{i}\\vert\\log(N T)}{\\vert E_{t}\\vert\\tau\\vert}\\bigg)\\Bigg]\\Bigg]}\\\\ &{\\quad\\quad\\leq\\log(T)+K\\sqrt{48T\\log(N T)}+K(48+\\mathbb{E}[\\dot{\\mu}]_{i}+\\sqrt{65}\\vert\\hat{\\mathcal{A}}_{i}\\vert)\\log^{2}(N T)}\\\\ &{\\quad\\quad\\quad+72\\mathbb{E}\\Bigg[\\sum_{t=1}^{N}\\sqrt{\\mathrm{te}\\tilde{\\Delta}_{t}\\log(N T)}\\Bigg]+(48+\\mathbb{E}[\\dot{\\mu}]_{i}+\\sqrt{65}\\vert\\hat{\\mathcal{A}}_{i}\\vert)\\log^{2}(N T)}\\\\ &{\\quad\\quad\\leq\\log(T)+K\\sqrt{4N T\\log(N T)}+(K+1)(48+\\mathbb{E}[\\dot{\\mu}]_{i})+\\sqrt{65}\\vert\\hat{\\mathcal{A}}_{i}\\vert)\\log^{2}(N T)}\\\\ &{\\quad\\quad\\quad+72\\sum_{t=1}^{N}\\sqrt{\\mathrm{te}\\tilde{\\Delta}_{t}\\log(N T)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the third inequality holds due to $\\bar{\\tau}\\leq T,E_{i}\\leq T$ and the fourth inequality holds due to Jensen's inequality. ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Reg}(T,\\pi)\\leq\\log(T)+K\\sqrt{48T\\log(N T)}+(K+1)(48+\\mathbb{E}\\left[d_{s}\\right]+\\sqrt{6\\mathbb{E}\\left[d_{s}\\right]})\\log^{2}(N T)}\\\\ &{\\phantom{=\\exp x}+72\\sqrt{N T\\log(N T)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "E Experimental Details ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We numerically evaluate our algorithms over 100 independently generated problem instances, with error bars representing standard errors in both Figure 1 and Figure 2. ", "page_idx": 24}, {"type": "text", "text": "The simulations were conducted on a server equipped with 4 Intel Xeon 6248 2.5GHz CPUs and 377 GB of RAM, running CentOS 7. The simulation code was developed in Python version 3.9.6. ", "page_idx": 24}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately refect the paper's contributions and scope? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 25}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should refect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 25}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 26}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The scripts for all experiments is provided. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 26}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: The necessary information is provided in the Experiments section and in the appendix as well as the scripts for experiments are provided. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 27}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 27}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: Error bars are reported and represent standard errors. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative errorrates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: Information provided in appendix. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 28}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 28}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: There is no societal impact of the work performed. The main application of the presented work is theoretical for sequential decision making. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 29}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properlyrespected? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: the paper does not use existing assets. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 29}, {"type": "text", "text": "\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 30}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose assetisused.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 30}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 30}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 30}]