[{"type": "text", "text": "Online Feature Updates Improve Online (Generalized) Label Shift Adaptation ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Ruihan Wu\\* \u2191 Siddhartha Datta\\* \u2191 Yi Su UC San Diego University of Oxford Google DeepMind ruw076@ucsd.edu siddhartha.datta@cs.ox.ac.uk yisumtv@google.com ", "page_idx": 0}, {"type": "text", "text": "Dheeraj Baby UC Santa Barbara dheeraj@ucsb.edu ", "page_idx": 0}, {"type": "text", "text": "Yu-Xiang Wang UC San Diego yuxiangw@ucsd.edu ", "page_idx": 0}, {"type": "text", "text": "Kilian Q. Weinberger Cornell University kilian@cornell.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "This paper addresses the prevalent issue of label shift in an online setting with missing labels, where data distributions change over time and obtaining timely labels is challenging. While existing methods primarily focus on adjusting or updating the final layer of a pre-trained classifier, we explore the untapped potential of enhancing feature representations using unlabeled data at test-time. Our novel method, Online Label Shift adaptation with Online Feature Updates (OLS-OFU), leverages self-supervised learning to refine the feature extraction process, thereby improving the prediction model. By carefully designing the algorithm, theoretically OLS-OFU maintains the similar online regret convergence to the results in the literature while taking the improved features into account. Empirically, it achieves substantial improvements over existing methods, which is as significant as the gains existing methods have over the baseline (i.e., without distribution shift adaptations). ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The effectiveness of most supervised learning models relies on a key assumption that the training data and test data share the same distribution. However, this assumption rarely holds in real-world scenarios, leading to the phenomenon of distribution shift [41, 2]. Previous research has primarily focused on understanding distribution shifts in offline or batch settings, where a single shift occurs between the training and test distributions [33, 45, 51, 52, 35]. In contrast, real-world applications often involve test data arriving in an online fashion, and the distribution shift can continuously evolve over time. Additionally, there is another challenging issue of missing and delayed feedback labels, stemming from the online setup, where gathering labels for the streaming data in a timely manner becomes a challenging task. ", "page_idx": 0}, {"type": "text", "text": "To tackle the distribution shift problem, prior work often relies on additional assumptions regarding the nature of the shift, such as label shift or covariate shift [43]. In this paper, we focus on the common (generalized) label shift problem in an online setting with missing labels [49] . Specifically, the learner is given a fixed set of labeled training data $D_{0}\\sim\\mathcal{P}^{\\mathrm{train}}$ in advance and trains a model $f_{0}$ During testtime, only a small batch of unlabelled test data $S_{t}\\sim\\mathcal{P}_{t}^{\\mathrm{test}}$ arrives in an online fashion $(t=1,2,\\cdots)$ For the olinelabel shift we assume the label distribution $\\mathcal{P}_{t}^{\\mathrm{test}}(y)$ may change over time $t$ While the conditional distribution remains the same, i.e. $\\mathcal{P}_{t}^{\\mathrm{test}}(x|y)\\stackrel{}{=}\\mathcal{P}^{\\mathrm{train}}(x|y)$ For example, employing MRI image classifiers for concussion detection becomes challenging as label shifts emerge from seasonal variations in the image distribution. A classifier trained during sking season may perform poorly when tested later, given the continuous change in image distribution between skiing and non-skiing seasons. In contrast to label shift, the generalized label shift relaxes the assumption of an unchanged conditional distribution on $x$ given $y$ . Instead, it assumes that there exists a transformation $h$ of the covariate, such that the conditional distribution $\\mathcal{P}_{t}^{\\mathrm{test}}(h(x)|y)=\\mathcal{P}^{\\mathrm{train}}(h(x)|y)$ stays the same. Reiterating our example, consider an MRI image classifier that undergoes training and testing at different clinics, each equipped with MRI machines of varying hardware and software versions. As a result, the images may display disparities in brightness, resolution, and other characteristics. However, a feature extractor $h$ exists, capable of mapping these variations to the same point in the transformed feature space, such that the conditional distribution $\\mathcal{P}(h(x)|y)$ remains the same. In both settings, the goal of the learner is to adapt to the (generalized) label shift within the non-stationary environment, continually adjusting the model's predictions in real-time. ", "page_idx": 0}, {"type": "image", "img_path": "HNH1ykRjXf/tmp/59f6eb3410d562f01927f739f4772a3da70ae1a58b115ffdfe1c742dc486e0a9.jpg", "img_caption": ["Figure 1: Overview of online distribution shift adaptation. We further assume $\\mathcal{P}_{t}^{\\mathrm{test}}(x|y)\\;=$ $\\bar{\\mathcal{P}}^{\\mathrm{train}}(x|y)$ for online label shift and assume the existence of an unknown feature mapping $h$ such that $\\begin{array}{r}{\\mathcal{\\dot{P}}_{t}^{\\mathrm{test}}(h(x)|y)=\\mathcal{P}^{\\mathrm{train}}(h(x)|y)}\\end{array}$ for online generalized label shift. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Existing algorithms for online label shift adaptation (OLS) primarily adopt one of two approaches: either directly reweighting of the pretrained classifier $f_{0}$ , or re-training only the final linear layer of $f_{0}$ \u2014 while keeping the feature extractor frozen. Recent work [46, 48, 36, 39] have demonstrated the potential for improving feature extractors, even during test-time and in the absence of labeled data. We hypothesize that a similar effect can be harnessed in the context of (generalized) label shift, leading to the idea of improving feature representation learning during testing. In online label shift, updating the feature extractor offers two potential advantages. First, it utilizes the additional unlabeled samples, hence enhancing the sample efficiency of the feature extractor. Second, it enables the feature extractor to adapt to label shift, which is crucial to the learning process as the optimal feature extractor may depend on the underlying label distribution. Particularly in generalized label shift scenarios, where the feature transformation $h$ is often unknown, the integration of extra unlabeled test samples facilitates the learning of $h$ ", "page_idx": 1}, {"type": "text", "text": "Building upon this insight, this paper introduces the Online Label Shift adaptation with Online Feature Updates (OLS-OFU) framework, aimed at enhancing feature representation learning in the context of online label shift adaptation. Specifically, each instantiation of OLS-OFU incorporates a selfsupervised learning method associated with a loss function denoted as $l_{\\mathrm{ssl}}$ for feature representation learning, and an online label shift adaptation (OLS) algorithm to effectively address distribution shift. By carefully checking the existing OLS methods and SSL methods, we identify three principles for algorithm design: maintain the theoretical guarantee, obey the underlying assumption of the existing OLS methods and fit the required condition of SSL techniques while avoiding heavy additional computational costs. Within the principles, OLS-OFU is designed as three main steps: at each time step, OLS-OFU first executes a revised OLS algorithm and then every $\\tau$ steps, OLS-OFU updates the feature extractor through self-supervised learning and subsequently refines the final linear layer. ", "page_idx": 1}, {"type": "text", "text": "In addition to its ease of implementation and seamless integration with existing OLS algorithms, OLS-OFU also shows strong theoretical guarantee and empirical performance. Theoretically, we demonstrate that OLS-OFU effectively reduces the loss of the overall algorithm by leveraging selfsupervised learning (SSL) techniques to enhance the feature extractor, thereby improving predictions for test samples at each time step $t$ . Empirical evaluations on various datasets, considering both online label shift and online generalized label shift scenarios, validate the effectiveness of OLS-OFU. Our OLS-OFU method achieves substantial improvements over existing OLS methods, which is as significant as the gains existing OLS methods have over the baseline (i.e., without distribution shift adaptations). This demonstrates that integrating online feature updates is as effective in solving online distribution shift as the fundamental online label shift method itself. Moreover, the improvement is consistent on various datasets, all existing OLS methods and the various choices of SSL techniques. This consistency underscoring its robustness across different scenarios and its generality to incorporate future OLS methods with more advanced online learning techniques and better SSL techniques. ", "page_idx": 1}, {"type": "text", "text": "2 Problem Setting & Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We start with some basic notations. Let $\\Delta^{K-1}$ be the probability simplex. Let $f:\\mathcal{X}\\to\\Delta^{K-1}$ denote a classifier. Given an input $x$ from domain $\\mathcal{X}$ \uff0c $f(x)$ outputs a probabilistic prediction over $K$ classes. For example, $f$ can be the output from the softmax operation after any neural network. If we reweight a model output from $f$ by a vector $p\\in\\mathbb{R}^{K}$ , we refer to this model as $g(\\cdot;f,p)$ with $g$ denotes the method of reweighting. For any two vectors $p$ and $q,p/q$ denotes the element-wise division. ", "page_idx": 2}, {"type": "text", "text": "Online distribution shift adaptation. The effectiveness of any machine learning model $f$ relies on a common assumption that the train data $D_{0}$ and test data $D_{\\mathrm{test}}$ are sampled from the same distribution, i.e., $\\mathcal{P}^{\\mathrm{train}}=\\bar{\\mathcal{P}^{\\mathrm{test}}}$ . However, this asumption is often violated in practice, which leads to distribution shift. This can be caused by various factors, such as data collection bias and changes in the data generation process. Moreover, once a well-trained model $f_{0}$ is deployed in the real world, it moves into the testing phase, which is composed of a sequence of periods or time steps. The test distribution at time step $t$ $\\mathcal{P}_{t}^{\\mathrm{test}}$ , from which test data $x_{t}$ is sampled, may vary over time. One example is that an MRI image classifier might be trained on MRI images collected during sking season (which may have a high frequency of head concussions) but tested afterward (when the frequency of concussion is lower). The test stage can last several months until the next classifier is trained. During this test period, the distribution of MRI images may undergo continuous changes, transitioning between non-skiing and skiing seasons. ", "page_idx": 2}, {"type": "text", "text": "As the test-time distribution changes over time, the challenge lies in how to adjust the model continuously from $f_{t-1}$ to $f_{t}$ in an online fashion to adapt to the current distribution $\\mathcal{P}_{t}^{\\mathrm{test}}$ . We call this problem online distribution shift adaptation and illustrate it in Figure 1. Given a total of $T$ steps in the online test stage, we define the average loss for any online algorithm $\\boldsymbol{\\mathcal{A}}$ through the loss of the sequence of models $f_{t},t\\in[T]$ that are produced from $\\boldsymbol{\\mathcal{A}}$ , i.e., ", "page_idx": 2}, {"type": "equation", "text": "$$\nL(\\mathcal{A};\\mathcal{P}_{1}^{\\mathrm{test}},\\cdot\\cdot\\cdot\\,,\\mathcal{P}_{T}^{\\mathrm{test}})=\\frac{1}{T}\\sum_{t=1}^{T}\\ell(f_{t};\\mathcal{P}_{t}^{\\mathrm{test}}),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\ell(f;\\mathcal{P})\\,=\\,\\mathbb{E}_{(x,y)\\sim\\mathcal{P}}\\ell_{\\mathrm{sup}}(f(x),y)$ and $\\ell_{\\mathrm{sup}}$ is the loss function, for example, 0-1 loss or cross-entropy loss for classification tasks. ", "page_idx": 2}, {"type": "text", "text": "In this paper, we consider the challenging scenario where at each time step $t$ only $a$ small batch of unlabeled samples $S_{t}=\\{x_{t}^{1},\\cdot\\cdot\\cdot,x_{t}^{B}\\}$ is received. We formalize the algorithm $\\boldsymbol{\\mathcal{A}}$ as: $\\forall t\\in[T]$ \uff0c ", "page_idx": 2}, {"type": "equation", "text": "$$\nf_{t}:=\\mathcal{A}\\left(\\{S_{1},\\cdot\\cdot\\cdot,S_{t-1}\\},\\{f_{1},\\cdot\\cdot\\cdot,f_{t-1}\\},D_{0},D_{0}^{\\prime}\\right).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "In contrast to the classical online learning setup, this scenario presents a significant challenge as classical online learning literature usually relies on having access to either full or partial knowledge of the loss at each time step, i.e., $\\ell_{\\mathrm{sup}}(f(x_{t}),y_{t})$ . In this setting, however, only a batch of unlabeled samples is provided at each time step and this lack of access to label information and loss values presents a significant challenge in accurately estimating the true loss defined in Equation 1. ", "page_idx": 2}, {"type": "text", "text": "Online label shift (OLS) adaptation. Online label shift assumes the marginal distribution of the label $\\mathcal{P}_{t}^{\\mathrm{test}}(y)$ changes over time, while the conditional distribution keeps invariant: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\forall t\\in[T],\\mathcal{P}_{t}^{\\mathrm{test}}(x|y)=\\mathcal{P}^{\\mathrm{train}}(x|y).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "This assumption is most typical when the label $y$ is the causal variable and the feature $x$ is the observation [43]. The aforementioned example of concussion detection from MRI images fits this scenario, where the presence or absence of a concussion (label) causes the observed MRI image features. Most previous methods tackle this problem through a non-trivial reduction to the classical online learning problem. Consequently, most of the online label shift algorithms [49, 7, 6] study the theoretical guarantee of the algorithm via the convergence of the regret function, which could be either static regret or dynamic regret. In previous studies, the hypothesis class $\\mathcal{F}$ of the prediction function $f$ is typically chosen in one of two ways: ", "page_idx": 2}, {"type": "text", "text": "1. $\\mathcal{F}$ is defined as a family of post-hoc reweightings of $f_{0}$ , with the parameter space comprising reweight vectors. Examples within this category include ROGD [49], FTH [49], and FLHFTL [6]. 2. $\\mathcal{F}$ is defined as a family of functions that share the same parameters in $f_{0}$ except the last linear layer, such as UOGD [7] and ATLAS [7]. ", "page_idx": 2}, {"type": "text", "text": "Notice that the existing OLS methods don't update the feature extractor at the online test stage, but focus on how to leverage advanced online learning techniques to update the remaining part of the model under certain theoretical guarantees. Our method will be orthogonal to them: it will focus on how to leverage the self-supervised learning techniques to update the feature extractor and, therefore, can improve each of them. Our empirical results in fact show that the improvement from the feature extractor update is as significant as the improvement from online learning techniques. ", "page_idx": 3}, {"type": "text", "text": "Online generalized label shift adaptation. In the context of MRI image classification, where head MRI images serve as the feature $x$ , variations in software or hardware across different clinics? MRI machines can introduce discrepancies in image characteristics like brightness, contrast, and resolution. In such scenarios, the conditional probability distribution $\\mathcal{P}(\\boldsymbol{x}|\\boldsymbol{y})$ is no longer invariant. However, when a feature extractor $h$ is robust enough, it can map images into a feature space where the images from different machines have the same distributions $\\mathcal{P}(\\boldsymbol{h}(\\boldsymbol{x})|\\boldsymbol{y})$ in the transformed feature space. The concept of generalized label shift, as introduced in Tachet des Combes et al. [47], formalizes this by postulating the existence of an unknown function $h$ , such that $\\mathcal{P}(h(x)|y)$ remains invariant. The primary challenge in this context is to find the underlying transformation $h$ . Building upon this, online generalized label shift assumes that there exists an unknown function $h$ such that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\forall t\\in[T],\\mathcal{P}_{t}^{\\mathrm{test}}(h(x)|y)=\\mathcal{P}^{\\mathrm{train}}(h(x)|y).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Thus, to apply the OLS methods for this more general problem, it is important to learn a proper feature extractor as this underlying function $h$ ", "page_idx": 3}, {"type": "text", "text": "Motivations of deploying self-supervised feature updates. As we reviewed above, OLS methods in the literature don't update the pretrained feature extractor in the online stage. However, the pretrained feature extractor in $f_{0}$ can be suboptimal for the online test stage in online (generalized) label shift adaptation, because of the three potential reasons: ", "page_idx": 3}, {"type": "text", "text": "1. The amount of pretrained data doesn't achieve the learning capacity of the feature extractor structure, i.e. learning with more data can improve the feature extractor.   \n2. The optimal feature extractors can be different for two different distributions. In our problem, the distribution shifts overtime and the optimal feature extractor can be dynamic too.   \n3. Particularly in online generalized label shift adaptation, the domain of the data can be dramatically changed between train and test, and the pretrained feature extractor could have unpredictable performancefor thetest data. ", "page_idx": 3}, {"type": "text", "text": "Fortunately, in online (generalized) label shift adaptation problem, the learner receives many unlabeled test samples $S_{1}\\cup\\cdot\\cdot\\cdot\\cup S_{t-1}$ before the prediction for time step t. On the other hand, self-supervised learning is very powerful for representation learning [18, 32, 30, 16, 37, 9, 23, 20, 24] and domain adaptation [46, 48, 36, 39]. In this paper, we will introduce how to deploy these self-supervised learning techniques to the existing OLS methods such that we can still enjoy the theoretical guarantees from online learning techniques and, more importantly, take the advantage of self-supervised learning to achieve better empirical performance. ", "page_idx": 3}, {"type": "text", "text": "3 Method ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this paper, we introduce a novel online label shift adaptation algorithm OLS-OFU, that leverages self-supervised learning (SSL) to improve representation learning and can be seamlessly integrated with any existing online label shift (OLS) method. By carefully designing how to place the SSL techniques, our algorithm maintains a similar theoretical guarantee from the existing OLS methods, obeys the underlying assumption in existing OLS methods that is important for the effectiveness, and fits the required condition of the SSL techniques while avoiding heavy additional time cost. Through the derived theoretical results, we further understand how the online learning techniques and SSL techniques contribute together to reduce the test loss in the online label shift adaptation problem. Lastly, we demonstrate how the SSL techniques help with the more challenging problem online generalized label shift adaptation. ", "page_idx": 3}, {"type": "text", "text": "3.1  Three Principles of Algorithm Design. ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To combine the step of feature extractor update with any OLS method, the most straightforward thought is to directly insert this step right before or after the step of original OLS in each time step; ", "page_idx": 3}, {"type": "text", "text": "see the summarization of the online process in Figure 1. Starting from this thought, there are three remaining questions before finalizing the algorithm: Q1: Inserting this step before or after the original OLS step, which option is better? Q2: Besides this feature extractor update step, are any other steps also necessary? Q3: How frequently (in terms of time step $t$ ) should we update the feature extractor? We are going to introduce three principles when designing our algorithm, which helps answer the three questions and together lead to our final design. ", "page_idx": 4}, {"type": "text", "text": "Principle 1: maintain the theoretical guarantee. One main advantage of existing OLS methods is that they have theoretical guarantees for the performance of any unknown label shifts in the online test stage. We would like to keep this advantage after deploying the feature extractor update step. By carefully checking the theoretical analysis of the existing OLS methods, we find that when we deploy the feature extractor update into ROGD, UOGD, or ATLAS, if we would like to update the feature extractor by the unlabeled test samples including $S_{t}$ , it is necessary to execute this update after the step of these OLS methods at time $t$ to maintain the similar theoretical guarantee. This is because the main idea of ROGD, UOGD, and ATLAS is to construct an unbiased estimator for the gradient $\\nabla_{f}\\ell(f_{t};\\mathcal{P})$ using a batch of samples $S_{t}\\sim\\ensuremath{\\mathcal{P}}_{t}^{\\mathrm{test}}$ . The estimator has the form of ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\sum_{y\\in\\mathcal{Y}}s_{t}[y]\\cdot\\nabla_{f}\\mathbb{E}_{(x,y)\\sim\\mathcal{P}^{\\mathrm{train}}}\\ell_{\\mathrm{sup}}(f_{t}(x),y),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $s_{t}$ is an unbiased estimator for the label marginal distribution $q_{t}$ and it depends on samples $S_{t}$ as constructed. If the feature extractor update according to $S_{t}$ happened before the step of ROGD, UOGD or ATLAS, $f_{t}$ would not be independent of $s_{t}$ in Equation 3 and this can break their main idea, as illustrated in the following proposition. ", "page_idx": 4}, {"type": "text", "text": "Proposition 1. If $f_{t}$ is not independent of the samples $S_{t}$ the gradient estimator in Equation 3 is not guaranteed to be an unbiased estimator of the gradient $\\nabla_{f}\\ell(f_{t};\\mathcal{P})$ ", "page_idx": 4}, {"type": "text", "text": "Thus, to maintain a similar theoretical guarantee after updating the feature extractor by the online test samples, we should insert the feature update involving $S_{t}$ after the step of original ROGD, UOGD or ATLAS, and this answers Q1. In the experiment, we will validate the necessity of this design. ", "page_idx": 4}, {"type": "text", "text": "Principle 2: obey the underlying assumption of the existing OLS methods. We find that the existing OLS methods ROGD, FTH, and FLHFTL opt for the hypothesis $f$ to be a post-hoc reweight of the pre-trained model $f_{0}$ : The underlying assumption behind this design is that $f_{0}$ is a good approximation of $\\mathcal{P}^{\\mathrm{train}}(y|x)$ Within this assumption, because $\\mathcal{P}^{\\mathrm{test}}(y|x)$ is a post-hoc reweight of $\\bar{\\mathcal{P}}^{\\mathrm{train}}(y|x)$ in the case of label shift [34, 49],reweighting such $f_{0}$ can approach $\\bar{\\mathcal{P}}^{\\mathrm{test}}(y|x)$ .Therefore, after updating the feature extractor, we expect that the base model, which is to be reweighted, still approximates the training distribution $\\mathcal{P}^{\\mathrm{train}}(y|x)$ . This can be done by $r e$ -training the linear layer under the training data after the feature extractor update, and this answers Q2. ", "page_idx": 4}, {"type": "text", "text": "Principle 3: fit the required condition of the SSL techniques while avoiding heavy additional computational costs. Given a set of unlabeled samples $S$ , we denote the loss of an SSL technique for a model $f$ as $\\ell_{\\mathrm{ssl}}(S;f)$ and the update to this model would be in the form of gradient descent: $\\theta^{\\mathrm{feat}}\\to\\theta^{\\mathrm{feat}}-\\eta\\cdot\\nabla_{\\theta^{\\mathrm{feat}}}\\ell_{\\mathrm{ssl}}(S;f)$ , where $\\eta$ is the learning rate. We notice that the batch size $|S|$ cannot be very small. Otherwise, the update can be too noisy due to the data variance or some types of SSL whose benefit replies on large batch sizes, such as contrastive learning [9, 23], would lose this benefit. However, online (generalized) label shift problem assumes we only have a small batch of unlabeled samples $S_{t}$ at time $t$ ; the batch size is set as 1 or 10 in the experiment of literature. Therefore, for the effectiveness of SSL techniques, instead of updating the feature extractor at each time step by $S_{t}$ , we opt to accumulate the sample batch $S_{\\tau c}\\cup\\cdot\\cdot\\cdot\\cup S_{\\tau(c+1)}$ and update the feature extractor once every $\\tau$ time steps, and we call it batch accumulation. ", "page_idx": 4}, {"type": "text", "text": "Besides the help of effectiveness, batch accumulation also helps with time efficiency. The existing OLS methods only involve the updates for the small reweighting vector or the linear layer and the time cost is low. However, updating the feature extractor and re-training the linear layer on the full training set, which are introduced in Principle 2, are much computationally heavier. For example, when we evaluated the methods in the experiment with ResNet18 on CIFAR10 dataset, one step of FLHFTL only took 0.069 second, while one step of FLHFTL together with feature extractor update and linear layer re-training took 17.1 seconds, which is 247 times. After applying batch accumulation andweselect $\\tau=100$ , the additional time costs will be reduced by $(\\tau-\\bar{1})/\\tau=99\\%$ ", "page_idx": 4}, {"type": "text", "text": "Batchaccumulation answers $Q_{3}-w e$ should update thefeature extractor every $\\tau$ stepsfor effectiveness and time effciency. We will study how batch accumulation helps in the experiments. ", "page_idx": 4}, {"type": "text", "text": "Require: An online label shift adaptation algorithm OLS, a self-supervised learning loss $\\ell_{\\mathrm{ssl}}$ .A   \npre-trained model $f_{0}$ and initialize $\\bar{f}_{1}=f_{1}^{\\prime\\prime}:=f_{0}$   \nfor $t=1,\\cdot\\cdot\\cdot,T$ do ", "page_idx": 5}, {"type": "text", "text": "Input at time $t$ : Samples $S_{1}\\cup\\cdot\\cdot\\cdot\\cup S_{t}$ , models $\\{f_{1},\\cdot\\cdot\\cdot,f_{t}\\}$ , train set $D_{0}$ , validation set $D_{0}^{\\prime}$ 1. Run the revised version of OLS,that is, OLS-R, and get $f_{t+1}^{\\prime}$ $t^{0}\\!/\\!_{0}\\tau\\neq0$ $f_{t+1}:=f_{t+1}^{\\prime}$ $f_{t+1}^{\\prime\\prime}:=f_{t}^{\\prime\\prime}$ bm $\\theta_{t}^{\\mathrm{feat}}$ $f_{t+1}^{\\prime}$ $\\theta_{t}^{\\mathrm{feat}}$ $f_{t+1}^{\\prime}$ $\\theta_{t+1}^{\\mathrm{feat}}$ $f_{t+1}^{\\prime\\prime}$ Output at time $t$ : For the reweighting OLS methods, denote the latest reweighting vector from Step 1 is $p_{t+1}$ and we define $f_{t+1}:=\\overline{{g(\\cdot;f_{t+1}^{\\prime\\prime},p_{t+1})}}$ ; else, we define $f_{t+1}:=f_{t+1}^{\\prime}$ end for ", "page_idx": 5}, {"type": "text", "text": "3.2 Online Label Shift Adaptation with Online Feature Updates ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We have discussed three principles and now we can finalize our algorithm Online Label Shift adaptation with Online Feature Updates (OLS-OFU; Algorithm 1), which requires a self-supervised learning loss $\\ell_{\\mathrm{ssl}}$ and one of existing OLS methods in the literature, which either reweights the offline pre-trained model $f_{0}$ or updates the last linear layer. In the training stage, we train $f_{0}$ by minimizing the supervised and self-supervised loss together defined on train data. In the test stage, OLS-OFU comprises three steps at each time step $t$ : (1) running the refined version of OLS, which we refer to as OLS-R, (2) updating the feature extractor, and (3) re-training the last linear layer. As suggested by Principle 3 in Section 3.1, steps (2-3) only run every $\\tau$ steps. We illustrate the details of these three steps are elaborated below. ", "page_idx": 5}, {"type": "text", "text": "(1) Running the Revised OLS. At the beginning of the time $t$ ,we use $f_{t}^{\\prime\\prime}$ to denote the model within the latest feature extractor and the re-trained linear model (using data $\\{S_{0},\\cdot\\cdot\\cdot,S_{t-1}\\})$ . The high level idea of our framework centers on substituting the pre-trained model $f_{0}$ used in existing OLS methods with our updated model $f_{t}^{\\prime\\prime}$ , which we call OLS-R. To provide an overview, we examine common OLS methods (FLHFTL, FTH, ROGD, UOGD, and ATLAS) and identify two primary use cases of $f_{0}$ . Firstly, all OLS methods rely on an unbiased estimator $s_{t}$ of the label distribution $q_{t}$ and $f_{0}$ is a part of the estimator. Secondly, the hypothesis $f$ is some weights of reweighting the $f_{0}$ output or only the last linear layer in $f_{0}$ is updated. We illustrate all revised OLS methods formally in Appendix C. We use $f_{t+1}^{\\prime}$ to denote the model after running the OLS-R. ", "page_idx": 5}, {"type": "text", "text": "(2) Updating the Feature Extractor. As guided by Principle 1 in Section 3.1, the step of updating the feature extractor should be after the Revised-OLS module (step (1)) for theoretical guarantees. We now introduce how to utilize theSSL loss $\\ell_{\\mathrm{ssl}}$ to update the feature extractor based on the accumulated batch of unlabeled test data $S_{\\tau c}\\cup\\cdot\\cdot\\cdot\\cup S_{\\tau(c+1)}$ at timestep $t=\\tau(c+1)$ . Specifically, let $\\theta_{t}^{\\mathrm{feat}}$ denote the parameters of the feature extractor in $f_{t+1}^{\\prime}$ . The update of $\\theta_{t+1}^{\\mathrm{feat}}$ is given by: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\theta_{t+1}^{\\mathrm{feat}}:=\\theta_{t}^{\\mathrm{feat}}-\\eta\\cdot\\nabla_{\\theta^{\\mathrm{feat}}}\\ell_{\\mathrm{ssl}}(S_{\\tau c}\\cup\\cdot\\cdot\\cdot\\cup S_{\\tau(c+1)};f_{t+1}^{\\prime}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Thenweuat featre $f_{t+1}^{\\prime}$ with $\\theta_{t+1}^{\\mathrm{feat}}$ (3) Re-training Last Linear Layer. Principle 2 in Section 3.1 suggests this step of re-training the last linear layer on the training distribution. The re-training starts from random initialization while thefeature extractormainsfrozenThe training objectivof $\\theta_{t+1}^{\\mathrm{linear}}$ is to minimize the average crosentropylosovr rain data $D_{0}$ Wedenote the model with thfroen faturexraetor $\\theta_{t+1}^{\\mathrm{feat}}$ $f(\\cdot|\\theta_{t+1}^{\\mathrm{feat}},\\theta^{\\mathrm{linear}})$ . The objective for re-training the lat linear layer can be writen a fllows: ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\theta_{t+1}^{\\mathrm{linear}}:=\\arg\\operatorname*{min}_{\\theta_{\\mathrm{linear}}}\\sum_{(x,y)\\in D_{0}}\\ell_{\\mathrm{ce}}\\bigg(f\\big(x|\\theta_{t+1}^{\\mathrm{feat}},\\theta^{\\mathrm{linear}}\\big),y\\bigg).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We calibrate the model $f(\\cdot|\\theta_{t+1}^{\\mathrm{feat}},\\theta_{t+1}^{\\mathrm{linear}})$ bytemperature calibration [1lusing thevalidation set $D_{0}^{\\prime}$ and denote the model after calibration as ft1. ", "page_idx": 5}, {"type": "text", "text": "Output at time $t$ Finally, we define $f_{t+1}$ for the next time step prediction. For the reweighting OLS methods (ROGD, FTH, FLHFTL), denote the latest reweighting vector from Step 1 as $p_{t+1}$ and define $f_{t+1}:=g(\\cdot;f_{t+1}^{\\prime\\prime},p_{t+1})$ . For those which optimize the last linear layer (UOGD, ATLAS), we define $f_{t+1}:=f_{t+1}^{\\prime}-\\mathrm{as}$ stated in Principle 2 in Section 3.2,the $f_{t}^{\\prime\\prime}$ including retrained last linear layer serves specially for the reweighting OLS method. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "The requirement of the training data. Notice that in step (3), we need the training data to retrain the linear classifier, which potentially brings the additional cost of memory and computation in the test time. As discussed in Principle 2 and lines 248-252, retraining the last linear layer is designed only for three previous OLS methods (ROGD, FTH, FLHFTL); our algorithm for two other OLS methods (UOGD and ATLAS) in the literature are independent of this step. As for ROGD, FTH, or FLHFTL, we interestingly find that OLS-OFU without this re-training step, which means that we update the feature extractor but reuse the pretrained linear classifier, still has a certain advantage over the original OLS methods - although more stored training data results in the more significant benefit of OLS-OFU. This suggests that in practice, if we reduce the amount of stored training data due to the memory or computational constraint, OLS-OFU is still effective. ", "page_idx": 6}, {"type": "text", "text": "3.3Performance Guarantee for Online Label Shift Adaptation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "One main advantage of the original OLS methods is that they exhibit theoretical guarantees in terms of regret convergence for online label shift settings. Next, we will show how OLS-OFU demonstrates analogous theoretical guarantees with the incorporation of additional online feature updates. Due to limited space, we illustrate the theoretical results pertaining to FLHFTL-OFU here, and present the results for ROGD-OFU, FTH-OFU, UOGD-OFU, and ATLAS-OFU in Appendix D. ", "page_idx": 6}, {"type": "text", "text": "Theorem 1. [Regret convergence for FLHFTL-OFU] Suppose we choose the OLS-R to be FLHFTL$R$ (Algorithm 6)from Baby et al. [6]. Let fht-ofu be the output at time step t - 1 from Algorithm I, thatis $g\\big(\\cdot;f_{t}^{\\prime\\prime},\\frac{\\tilde{q}_{t}}{q_{0}}\\big)$ . Under Assumptions 1 and 2 in Baby et al. [6], FLHFTL-OFU has the guarantee: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\ell(f_{t}^{\\mathrm{flhft1-ofu}};\\mathcal{P}_{t}^{\\mathrm{test}})\\right]\\leq\\mathbb{E}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\ell(g(\\cdot;f_{t}^{\\prime\\prime},\\frac{q_{t}}{q_{0}});\\mathcal{P}_{t}^{\\mathrm{test}})\\right]+O\\left(\\frac{K^{1/6}V_{T}^{1/3}}{T^{1/3}}+\\frac{K}{\\sqrt{T}}\\right),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Where $\\begin{array}{r}{V_{T}:=\\sum_{t=1}^{T}\\|q_{t}-q_{t-1}\\|_{1},}\\end{array}$ $K$ is the number of classes, and the expectation is taken w.t. randomnessintherevealedco-variates.Thisresultisattainedwithoutpriorknowledgeof $V_{T}$ ", "page_idx": 6}, {"type": "text", "text": "How do online feature updates contribute to the bound? We observe that the upper bound of the test loss has two terms. The first term is the loss of the model within the up-to-date feature extractor when the knowledge of label distribution $q_{t}$ is known. Any improvement from SSL could be reflected in this first term. The second term is to quantify the loss gap between the knowledge of label distribution $q_{t}$ and the estimation of the label distribution by the online learning technique. ", "page_idx": 6}, {"type": "text", "text": "When do online feature updates improve the guarantee from FLHFTL to FLHFTL-OFU? If we do not make any update to the feature extractor (i.e. $f_{t}^{\\prime\\prime}=f_{0},\\forall t)$ , the upper bound in Equation 6 would be naturally reduced to the theoretical guarantee of FLHFTL [6]. Moreover, in the following eventof $f_{t}^{\\prime\\prime}$ $\\mathit{\\Omega}_{\\downarrow}^{\\prime\\prime}\\left(t\\in\\left[T\\right]\\right)$ ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\ell(g(\\cdot;f_{t}^{\\prime\\prime},\\frac{q_{t}}{q_{0}});\\mathcal{P}_{t}^{\\mathrm{test}})\\right]<\\frac{1}{T}\\sum_{t=1}^{T}\\ell(g(\\cdot;f_{0},\\frac{q_{t}}{q_{0}});\\mathcal{P}_{t}^{\\mathrm{test}}),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "our theorem will guarantee that the loss of FLHFTL-OFU converges to a smaller value than the one of the original FLHFTL, resulting in a better upper bound. We substantiate this improvement through empirical evaluation in Section 4. ", "page_idx": 6}, {"type": "text", "text": "3.4  Online Feature Updates Improve Online Generalized Label Shift Adaptation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The generalized label shift is harder because the feature map $h$ is unknown and naively applying OLS methods might raise the challenge due to the violation of the label shift assumption. Fortunately, existing research in test-time training (TTT) [46, 48, 36, 39] demonstrates that feature updates driven by SSL align the source and target domains in feature space. When the source and target domains achieve perfect alignment, such feature extractor effectively serves as the feature map $h$ as assumed in generalized label shift. Therefore, the sequence of feature extractors in $f_{1},\\cdot\\cdot\\cdot,f_{T}$ generated by Algorithm 1 progressively approximates the underlying $h$ . This suggests that, compared to the original OLS, OLS-OFU experiences a milder violation of the label shift assumption within the feature space and is expected to have better performance in online generalized label shift settings. ", "page_idx": 6}, {"type": "image", "img_path": "HNH1ykRjXf/tmp/b184f49132567c115b1c45004d5d68f38d18a4ccd3d677e7b669bb03d994a274.jpg", "img_caption": ["(c) Results on three types of corruptions in CIFAR-10C (rotation degree prediction, Sinusoidal shift) Figure 2: Evaluation of OLS and OLS-OFU. "], "img_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "HNH1ykRjXf/tmp/0ba2066b7460141ffce31f5de286ec0c09bf479d8197eb7d4d73ab188dc92aa6.jpg", "table_caption": [], "table_footnote": ["Table 1: Average error/time (minutes) of 6 original OLS methods versus OLS-OFU with various frequency $\\tau$ in batch accumulation. The SSL in OLS-OFU is the rotation degree prediction. "], "page_idx": 7}, {"type": "text", "text": "4 Experiment ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we initiate OLS-OFU with three popular SSL techniques and empirically evaluate how OLS-OFU improves the original OLS methods on both online label shift and online generalized label shift on various datasets and shift patterns3. ", "page_idx": 7}, {"type": "text", "text": "4.1  Experiment Set-up ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Dataset and Label Shift Settings. For online label shift, we evaluate the efficacy of our algorithm on CIFAR-10 [29], STL10 [12], CINIC [13], and EuroSAT [25]. For each dataset, we split the original train set into the ofline train (i.e., $D_{0}$ ) and validation sets (i.e., $D_{0.}^{\\prime}$ )following a ratio of $4:1$ .Athe online test stage, unlabeled batches are sampled from the test set. For online generalized label shift, the ofline train and validation sets are the CIFAR-10 images. The test unlabeled batches are drawn from CIFAR-10C [26], a benchmark with the same objects as CIFAR-10 but with various types of corruption. We experiment with three types of corruptions with CIFAR-10C: Gaussian noise, Fog, and Pixelate. We follow Bai et al. [7] and Baby et al. [6] to simulate the online label distribution shift with two shift patterns: Sinusoidal shift and Bernoulli shift. We experiment with $T=1000$ and batchsize $B=10$ at each time step, following Baby et al. [6]. See more details of dataset set-up and online shift patterns in Appendix E.1. ", "page_idx": 7}, {"type": "table", "img_path": "HNH1ykRjXf/tmp/91a7cb297c45c77a38613b4b3c1763feac1a841d48eaae8da01829559e39c661.jpg", "table_caption": [], "table_footnote": ["Table 2: Ablation study on the order between OLS and the feature update step in OLS-OFU. "], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Evaluation Metr. We reprt the averae error during test, . $\\begin{array}{r}{\\frac{1}{T B}\\sum_{t=1}^{T}\\sum_{x_{t}\\in S_{t}}\\mathbb{1}\\left(f_{t}(x_{t})\\neq y_{t}\\right)}\\end{array}$   \nwhere $(x_{t},y_{t})\\sim\\mathcal{P}_{t}^{\\mathrm{test}}$ , to approximate $\\begin{array}{r}{\\frac{1}{T}\\sum_{t=1}^{T}\\ell(f_{t};\\mathcal{P}_{t}^{\\mathrm{test}})}\\end{array}$ for the ealuation eficiency. ", "page_idx": 8}, {"type": "text", "text": "Self-supervised learning methods in OLS-OFU. In the experiment, we narrow our focus on three particular SSL techniques in the evaluation for classification tasks: rotation degree prediction [16, 46], entropy minimization [18, 48] and MoCo [23, 10, 11]. It is important to note that this concept extends beyond these three SSL techniques, and the incorporation of more advanced SSL techniques to further elevate the performance. Appendix E.1 gives more details of these SSL techniques. ", "page_idx": 8}, {"type": "text", "text": "Set-ups of OLS methods, OLS-OFU and baselines. We perform an extensive evaluation of 6 OLS methods in the literature: FTFWH, FTH, ROGD, UOGD, ATLAS, and FLHFTL by following the implementation in Baby et al. [6]. We report the performance of our method OLS-OFU (Algorithm 1) applied on top of each OLS and 3 SSL methods introduced above. The frequency parameter $\\tau$ is fixed as 100 for most experiments unless we particularly mention it. Additionally, by following the setup in [49, 6], we report one baseline score Base, which uses the fixed pre-trained model $f_{0}$ to predict the labels at all time steps. ", "page_idx": 8}, {"type": "text", "text": "4.2 Results ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Main Results: comparison between OLS-OFU and OLS under online (generalized) label shift. Figure 2(a) shows the performance comparison between OLS-OFU, implemented with three SSL methods, and their corresponding OLS counterparts on CIFAR-10 under the scenario of classical online label shift. Figure 2(b) shows the results on three more datasets with SSL technique in OLS-OFU being rotation degree prediction. Figure 2(c) shows the results on CIFAR-10C datasets for evaluating methods on online generalized label shift. The online shift pattern in Figure 2 is the sinusoidal shift and similar results on the Bernoulli shift are in Appendix E.2. We have two main observations from the results. First, we find our OLS-OFU method achieves substantial improvements over existing OLS methods, which is as significant as to the gains existing OLS methods have over the baseline (i.e., without distribution shift adaptations). This demonstrates that integrating online feature updates is as effective in solving online distribution shifts as the fundamental online label shift method itself. Second, the improvement is consistent across all six original OLS methods and three SSL techniques on all datasets, which further demonstrates our OLS-OFU is general enough to incorporate future OLS methods and more advanced SSL techniques as well. ", "page_idx": 8}, {"type": "text", "text": "Validating Principle 1: ablation study on the order between OLS and the feature update step in OLS-OFU. We compare OLS-OFU with its other variant named OLS-OFU-difforder where we update SSL first and run OLS later (which violates Principle 1). We compare these two algorithms across all previous 6 OLS methods and two choices of batch accumulation $\\tau=1$ and $\\tau=100$ .The dataset is CIFAR-10, the SSL is rotation degree prediction and the shift pattern is the sinusoidal shift. We report the average error every $\\tau$ time step when the feature extractor is updated, so the order matters. From Table 2, we can observe that benefiting from Principle 1, the error OLS-OFU is consistently lower than OLS-OFU-difforder. This means that Principle 1 indeed is not only necessary for the correctness of theoretical guarantee but also plays an important role in practice. ", "page_idx": 8}, {"type": "text", "text": "Validating Principle 3: ablation study on frequency $\\tau$ in batch accumulation in OLS-OFU. In section 3.1, we introduce the batch accumulation to favor the effectiveness of the SSL and reduce the additional time cost of OLS-OFU compared with the original OLS methods. In Table 1, we evaluate OLS-OFU on CIFAR-10 with various $\\tau$ while initiating OLS-OFU with rotation degree prediction and compare the average error and time with OLS. We have these observations across all OLS (columns): 1. OLS-OFU with all $\\tau$ outperforms OLS; 2. The average error of OLS-OFU decreases from $\\tau=1$ ${w/o}$ batch accumulation) to $\\tau=100$ and starts to increase after and this is because the effectiveness of SSL benefits from $\\tau>1$ while larger $\\tau$ means less updates and hence hurts the long term performance; 3. the additional time cost of OLS-OFU with larger $\\tau$ is smaller and $\\tau=100$ gives a great balance of performance and time cost for all OLS (and SSL; the similar tables for other two SSL are presented in the Appendix E.3). From the results, we recommend $\\tau=100$ as a good starting point for choosing this parameter. ", "page_idx": 8}, {"type": "table", "img_path": "HNH1ykRjXf/tmp/1e8cfafe568f90af564e95ef7a6f11292abc9c799bea514890fa4addc022546e.jpg", "table_caption": [], "table_footnote": ["Table 3: The effectiveness of OLS-OFU versus the percentage of stored training data in step (3). "], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Ablation study on the amount of stored training data in step (3). We further study how the amount of training data stored influences the effectiveness of our OLS-OFU when the OLS is ROGD, FTH, or FLHFTL, which is dependent on step (3). We experiment with the CIFAR-10 dataset and the shift pattern of sinusoidal shift; the SSL is chosen as rotation degree prediction. The percentage of stored training data (out of the whole training set of size 10,0oo) is varied in $\\{100\\bar{\\%}$ $80\\%$ $\\bar{6}0\\%$ $40\\%$ $20\\%$ \uff0c $10\\bar{\\%}$ $5\\%,0\\%)$ .\uff0c $0\\%$ means that we still update the feature extractor but reuse the pretrained linear classifier. The results are reported in Table 3. We can observe that with less stored training data for retraining the last linear layer, the error of OLS-OFU would increase gradually. However, an important finding is that even with $0\\%$ stored training data, the error of OLS-OFU is still lower than the OLS without feature extractor updates. This can actually explained by the original test-time training papers [46, 48, 36, 39], where they only update the feature extractor without refining the last linear layer and still have substantial benefit. The results suggest that a large amount of stored training data is not necessary for the effectiveness of OLS-OFU, while more stored data can bring more benefits. ", "page_idx": 9}, {"type": "text", "text": "Empirical validation of Equation 7. In Section 3.3, we argued that when the inequality in Equation 7 holds, the loss of FLHFTL-OFU exhibits a tighter upper bound compared to FLHFTL. Figure 3 presents the RHS (corresponds to OLS) and LHS (corresponds to OLS-OFU with SSL loss as rotation degree prediction) of Equation 7. We perform the study over eight different settings and vary the domain shift and online shift patterns. It is evident that OLS-OFU yields improvements on the baseline of the regret as shown in Equation 7. Appendix E.4 validates this inequality for other SSL. ", "page_idx": 9}, {"type": "image", "img_path": "HNH1ykRjXf/tmp/d3d0f5464739d22dcb3f9bbedf963a0061a75c893a57ee30f21d8d64bfc12170.jpg", "img_caption": ["Figure 3: Empirical validation of Equation 7. Clean denotes the experiment on CIFAR-10, and others denote the corruption type. They are paired with two online shift patterns: Sinusoidal and Bernoulli. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "5  Conclusion and Future Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We focus on online (generalized) label shift adaptation and present a novel framework OLS-OFU, which harnesses the power of self-supervised learning to enhance feature representations dynamically during testing, leading to improved predictive models and better test time performance. ", "page_idx": 9}, {"type": "text", "text": "Discussion and future work. One promising direction is to extend the idea of this paper to online covariate shift, for example, the algorithm in Zhang et al. [53] freezes the feature extractor and only updates the linear layer. Another possible direction is to consider a more realistic domain shift scenario within the generalized label shift setting \u2014\u2014 domain shift types may vary over time or be even more challenging, such as shifting from cartoon images to realistic images. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "RW and KQW are supported by grants from LinkedIn, DARPA Geometries of Learning, and the National Science Foundation NSF (1934714). RW is also supported by grants from the National Science Foundation NSF (CIF-2402817, CNS-1804829), SaTC-2241100, CCF-2217058, AROMURI (W911NF2110317), and ONR under N00014-24-1-2304. YW and DB are partially supported by NSF Award #2134214. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1]  A. Alexandari, A. Kundaje, and A. Shrikumar. Maximum likelihood with bias-corrected calibration is hard-to-beat at label shift adaptation. In International Conference on Machine Learning, pages 222-232. PMLR, 2020.   \n[2] D. Amodei, C. Olah, J. Steinhardt, P. Christiano, J. Schulman, and D. Man\u00e9. Concrete problems in ai safety. arXiv preprint arXiv:1606.06565, 2016.   \n[3] E. Arazo, D. Ortego, P. Albert, N. E. O'Connor, and K. McGuinness. Pseudo-labeling and confirmation bias in deep semi-supervised learning. In 2020 International Joint Conference on Neural Networks (IJCNN). IEEE, 2020.   \n[4]  K. Azizzadenesheli, A. Liu, F. Yang, and A. Anandkumar. Regularized learning for domain adaptation under label shifts. In International Conference on Learning Representations, 2019.   \n[5] D. Baby and Y-X. Wang. Optimal dynamic regret in proper online learning with strongly convex losses and beyond. In International Conference on Artificial Intelligence and Statistics, pages 1805-1845. PMLR, 2022.   \n[6] D. Baby, S. Garg, T.-C. Yen, S. Balakrishnan, Z. C. Lipton, and Y.-X. Wang. Online label shift: Optimal dynamic regret meets practical algorithms. To appear at Advances in Neural Information Processing Systems, 2023.   \n[7]  Y. Bai, Y-J. Zhang, P. Zhao, M. Sugiyama, and Z.-H. Zhou. Adapting to online label shift with provable guarantees. Advances in Neural Information Processing Systems, 35:29960-29974, 2022.   \n[8]  O. Besbes, Y. Gur, and A. Zeevi. Non-stationary stochastic optimization. Operations research, 63(5):1227-1244, 2015.   \n[9] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton. A simple framework for contrastive learning of visual representations. In International conference on machine learning, pages 1597-1607. PMLR, 2020.   \n[10] X. Chen, H. Fan, R. Girshick, and K. He. Improved baselines with momentum contrastive learning. arXiv preprint arXiv:2003.04297, 2020.   \n[11] X. Chen, S. Xie, and K. He. An empirical study of training self-supervised vision transformers. In 2021 IEEE/CVF International Conference on Computer Vision (ICCV), pages 9620-9629, Los Alamitos, CA, USA, 0ct 2021. IEEE Computer Society. doi: 10.1109/ICCV48922.2021.00950. URL https : //doi.ieeecomputersociety.org/10. 1109/ICCV48922.2021. 00950.   \n[12] A. Coates, A. Ng, and H. Lee. An Analysis of Single Layer Networks in Unsupervised Feature Learning. In AISTATS, 2011. https: //cs.stanford.edu/\\~acoates/papers/ coatesleeng-aistats_2011.pdf.   \n[13] L. N. Darlow, E. J. Crowley, A. Antoniou, and A. J. Storkey. Cinic-10 is not imagenet or cifar-10, 2018.   \n[14] S. Garg, Y. Wu, S. Balakrishnan, and Z. C. Lipton. A unified view of label shift estimation. arXiv preprint arXiv:2003.07554, 2020.   \n[15] S. Garg, N. Erickson, J. Sharpnack, A. Smola, S. Balakrishnan, and Z. Lipton. Rlsbench: Domain adaptation under relaxed label shift. In International Conference on Machine Learning (ICML), 2023.   \n[16] S. Gidaris, P. Singh, and N. Komodakis. Unsupervised representation learning by predicting image rotations. In International Conference on Learning Representations, 2018. URL https : //openreview.net/forum?id=S1v4N2l0-.   \n[17]  Y. Grandvalet and Y. Bengio. Semi-supervised learning by entropy minimization. In L. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information Processing Systems, volume 17. MIT Press, 2004. URL https://proceedings.neurips.cc/paper_files/paper/2004/ file/96f2b50b5d3613adf9c27049b2a888c7-Paper.pdf.   \n[18]  Y. Grandvalet and Y. Bengio. Semi-supervised learning by entropy minimization. Advances in neural information processing systems, 17, 2004.   \n[19]  A. Gretton, A. Smola, J. Huang, M. Schmitfull, K. Borgwardt, and B. Scholkopf. Covariate shift by kernel mean matching. Dataset shift in machine learning, 3(4):5, 2009.   \n[20] J-B. Grill, F. Strub, F. Altch\u00e9, C. Tallec, P. Richemond, E. Buchatskaya, C. Doersch, B. Avila Pires, Z. Guo, M. Gheshlaghi Azar, et al. Bootstrap your own latent-a new approach to self-supervised learning. Advances in neural information processing systems, 33: 21271-21284, 2020.   \n[21] C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger. On calibration of modern neural networks. In International conference on machine learning, pages 1321-1330. PMLR, 2017.   \n[22]  E. Hazan and C. Seshadhri. Adaptive algorithms for online decision problems. In Electronic colloquium on computational complexity (ECCC), volume 14, 2007.   \n[23] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick. Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9729-9738, 2020.   \n[24] K. He, X. Chen, S. Xie, Y. Li, P. Dollar, and R. Girshick. Masked autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 16000-16009, 2022.   \n[25] P. Helber, B. Bischke, A. Dengel, and D. Borth. Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 12(7):2217-2226, 2019. doi: 10.1109/JSTARS.2019. 2918242.   \n[26] D. Hendrycks and T. Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. arXiv preprint arXiv:1903.12261, 2019.   \n[27] J Hoffman, T. Darre, and K. Saenko. Continuous manifold based adaptation for evolving visual domains. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 867-874, 2014.   \n[28] J. Huang, A. Gretton, K. Borgwardt, B. Scholkopf, and A. Smola. Correcting sample selection biasbyblddatandvancennealinfomatprcesng ytol19,pa 601-608. Citeseer, 2006.   \n[29]  A. Krizhevsky, G. Hinton, et al. Learning multiple layers of features from tiny images. 2009.   \n[30] S. Laine and T. Aila. Temporal ensembling for semi-supervised learning. arXiv preprint arXiv:1610.02242, 2016.   \n[31] D.-H. Lee. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. ICML 2013 Workshop: Challenges in Representation Learning, 2013.   \n[32] D.-H. Lee et al. Pseudo-label: The simple and effcient semi-supervised learning method for deep neural networks. In Workshop on challenges in representation learning, ICML, volume 3, page 896. Atlanta, 2013.   \n[33] Y. Lin, Y. Lee, and G. Wahba. Support vector machines for classification in nonstandard situations. Machine learning, 46(1):i91-202, 2002.   \n[34] Z. Lipton, Y-X. Wang, and A. Smola. Detecting and correcting for label shift with black box predictors. In International Conference on Machine Learning, 2018.   \n[35] Z. Lipton, Y-X. Wang, and A. Smola. Detecting and correcting for label shift with black box predictors. In International conference on machine learning, pages 3122-3130. PMLR, 2018.   \n[36]  Y. Liu, P. Kothari, B. Van Delft, B. Bellot-Gurlet, T. Mordan, and A. Alahi. Ttt $^{++}$ : When does self-supervised test-time training fail or thrive? Advances in Neural Information Processing Systems, 34:21808-21820, 2021.   \n[37]  T. Miyato, S.-i. Maeda, M. Koyama, and S. Ishi. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. IEEE transactions on pattern analysis and machine intelligence, 41(8):1979-1993, 2018.   \n[38] R. T. Mullapudi, S. Chen, K. Zhang, D. Ramanan, and K. Fatahalian. Online model distillation for efficient video inference. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 3573-3582, 2019.   \n[39] S. Niu, J. Wu, Y. Zhang, Y. Chen, S. Zheng, P. Zhao, and M. Tan. Efficient test-time model adaptation without forgeting. In International conference on machine learning, pages 16888- 16905. PMLR, 2022.   \n[40] Y.-Y. Qian, Y. Bai, Z.-Y. Zhang, P. Zhao, and Z.-H. Zhou. Handling new class in online label shift. In 2023 IEEE International Conference on Data Mining (ICDM), pages 1283-1288. IEEE, 2023.   \n[41]  J. Quinonero-Candela, M. Sugiyama, N. D. Lawrence, and A. Schwaighofer. Dataset shift in machine learning. Mit Press, 2009.   \n[42]  M. Saerens, P. Latinne, and C. Decaestecker. Adjusting the outputs of a classifier to new a priori probabilities: a simple procedure. Neural Computation, 14(1):21-41, 2002.   \n[43] B. Scholkopf, D. Janzing, J. Peters, E. Sgouritsa, K. Zhang, and J. Mooij. On causal and anticausal learning. arXiv preprint arXiv: 1206.6471, 2012.   \n[44]  S. Shalev-Shwartz. 2012.   \n[45]  H. Shimodaira. Improving predictive inference under covariate shift by weighting the loglikelihood function. Journal of statistical planning and inference, 90(2):227-244, 2000.   \n[46] Y. Sun, X. Wang, Z. Liu, J. Miller, A. Efros, and M. Hardt. Test-time training with selfsupervision for generalization under distribution shifts. In International conference on machine learning, pages 9229-9248. PMLR, 2020.   \n[47] R. Tachet des Combes, H. Zhao, Y.-X. Wang, and G. J. Gordon. Domain adaptation with conditional distribution matching and generalized label shift. Advances in Neural Information Processing Systems, 33:19276-19289, 2020.   \n[48] D. Wang, E. Shelhamer, S. Liu, B. Olshausen, and T. Darrell. Tent: Fully test-time adaptation by entropy minimization. arXiv preprint arXiv:2006.10726, 2020.   \n[49] R. Wu, C. Guo, Y. Su, and K. Q. Weinberger. Online adaptation to label distribution shift. Advances in Neural Information Processing Systems, 34:11340-11351, 2021.   \n[50]  Q. Xie, M.-T. Luong, E. Hovy, and Q. V. Le. Self-training with noisy student improves imagenet classification. In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 10684-10695, 2020. doi: 10.1109/CVPR42600.2020.01070.   \n[51]  B. Zadrozny. Learning and evaluating classifiers under sample selection bias. In Proceedings of the Twenty-First International Conference on Machine Learning, page 114, 2004.   \n[52] K. Zhang, B. Scholkopf, K. Muandet, and Z. Wang. Domain adaptation under target and conditional shift. In International Conference on Machine Learning, pages 819-827. PMLR, 2013.   \n[53]  Y.-J. Zhang, Z.-Y. Zhang, P. Zhao, and M. Sugiyama. Adapting to continuous covariate shift via online density ratio estimation. arXiv preprint arXiv:2302.02552, 2023.   \n[54] P. Zhao, Y.-J. Zhang, L. Zhang, and Z.-H. Zhou. Adaptivity and non-stationarity: Problemdependent dynamic regret for online convex optimization. Journal of Machine Learning Research, 25(98):1 - 52, 2024. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Further Related Work ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Offline distribution shift and domain shift. Offline label shift and covariate shift have been studied for many years. Some early work [42, 33] assumes the knowledge of how the distribution is shifted. Later work [45, 51, 28, 19, 35, 1, 4, 14] relaxes this assumption and estimates this knowledge from unlabeled test data. A recent work by [15] considers a relaxed version of offline label shift problem where the class-conditionals can change between train and test domains in a restrictive way. Extending their results to the case of relaxed online version of generalized label shift is an interesting future direction. ", "page_idx": 13}, {"type": "text", "text": "Online distribution shift with provable guarantees. There has been several work modeling online distribution shift as the classic online learning problem [49, 7, 6, 53], which leverage the classical online learning algorithms [44, 8, 5] to bound the static or dynamic regret. Qian et al. [40] focuses on a special setting in online label shift, where there can be new classes occurring in the test stage. They handle the new class by unsupervised estimating the portion of unseen data. However, none of them updates the feature extractor in a deep learning model but only the last linear layer or the post-hoc linear reweighting vectors. Our proposed method OLS-OFU utilizes the deep learning SSL to improve the feature extractor, which brings better performance. ", "page_idx": 13}, {"type": "text", "text": "Domain shift adaptation within online streaming data. When we consider the most authentic online learning setup where the learner only receives the unlabeled samples, the most representative idea is test-time training [46, 48, 36, 39], which utilizes a (deep learning) self-supervised loss to online update the model. However, it focuses on how to adapt to a fixed domain shifted distribution from online streaming data and is not designed for how to adapt to continuous distribution changes during the test stage, while our algorithm concentrates the later problem. Besides test-time training, Hoffman et al. [27] and [38] study the online domain shift for specific visual applications. ", "page_idx": 13}, {"type": "text", "text": "B Proof of Proposition 1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The pro of Propsition  We  fies  write the deriation that $\\textstyle\\sum_{y\\in{\\mathcal{Y}}}s_{t}[y]$ $\\nabla_{f}\\mathbb{E}_{x\\sim\\mathcal{P}^{\\mathrm{train}}(\\cdot|y)}\\ell_{\\mathrm{sup}}(f_{t}(x),y)$ is an unbiased estimator of $\\nabla_{f}\\ell(f_{t};\\mathcal{P})$ When $f_{t}$ is indepen", "page_idx": 13}, {"type": "text", "text": "Algorithm 2 Revised ROGD for online feature updates ROGD-R. See the original version in Equation 7 and Equation 8 in [49]. ", "page_idx": 13}, {"type": "text", "text": "Require: Learning rate $\\eta$ ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "for $t=1,\\cdot\\cdot\\cdot,T$ do ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Input at time $t$ : Samples $S_{1}\\cup\\cdot\\cdot\\cdot\\cup S_{t}$ , models $\\{f_{1},\\cdots,f_{t}\\}$ , and intermediate model   \n$\\{f_{1}^{\\prime\\prime},\\cdot\\cdot\\cdot,f_{t}^{\\prime\\prime}\\}$ from step 3 in Algorithm 1, the validation set $D_{0}^{\\prime}$ , the training label marginal   \n$q_{0}:=\\mathcal{P}^{\\mathrm{train}}(y)$   \n1. Compute the unbiased estimator for label marginal distribution: $\\begin{array}{r}{s_{t}\\stackrel{}{=}\\frac{1}{|S_{t}|}\\sum_{x_{t}\\in S_{t}}C_{f_{t}^{\\prime\\prime},D_{0}^{\\prime}}^{-1}f_{t}^{\\prime\\prime}(x_{t})}\\end{array}$ $\\vartriangleright$ In the original ROGD, it is $f_{0}$ rather than $f_{t}^{\\prime\\prime}$   \n2. Grab the weight $p_{t}$ from $f_{t}$   \n3. Update $p_{t+1}:=\\mathrm{Proj}_{\\Delta^{K-1}}\\left[p_{t}-\\eta\\cdot J_{p}(p_{t})^{\\top}s_{t}\\right],$ where $\\begin{array}{r}{J_{p,f_{t}^{\\prime\\prime}}(p_{t})=\\frac{\\partial}{\\partial p}(1-\\mathrm{diag}(C_{f_{t}^{\\prime\\prime},D_{0},p}))|_{p=p_{t}}}\\end{array}$ , and let $f_{t+1}$ be a reweighting version of $f_{t}^{\\prime\\prime}$ by the weight $\\begin{array}{r}{\\bigg(\\frac{p_{t+1}[k]}{q_{0}[k]}:k=1,\\cdot\\cdot\\cdot K\\bigg)}\\end{array}$ $\\vartriangleright$ In the original ROGD, it is $f_{\\mathrm{0}}$ rather than $f_{t}^{\\prime\\prime}$   \nOutput at time t: ft+1- ", "page_idx": 13}, {"type": "text", "text": "end for ", "text_level": 1, "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\xi_{S_{t}}\\left[\\displaystyle\\sum_{y\\in\\mathcal{Y}}s_{t}[y]\\cdot\\nabla_{f}\\mathbb{E}_{x\\sim\\mathcal{P}^{\\mathrm{train}}(\\cdot|y)}\\ell_{\\mathrm{sup}}(f_{t}(x),y)\\right]=\\displaystyle\\sum_{y\\in\\mathcal{Y}}\\mathbb{E}_{s_{t}}\\left[s_{t}[y]\\cdot\\nabla_{f}\\mathbb{E}_{x\\sim\\mathcal{P}^{\\mathrm{train}}(\\cdot|y)}\\ell_{\\mathrm{sup}}(f_{t}(x),y)\\right]}&{}\\\\ {=\\displaystyle\\sum_{y\\in\\mathcal{Y}}\\mathbb{E}_{s_{t}}\\left[s_{t}[y]\\right]\\cdot\\nabla_{f}\\mathbb{E}_{x\\sim\\mathcal{P}^{\\mathrm{train}}(\\cdot|y)}\\ell_{\\mathrm{sup}}(f_{t}(x),y)}&{}\\\\ {=\\displaystyle\\sum_{y\\in\\mathcal{Y}}q_{t}[y]\\cdot\\nabla_{f}\\mathbb{E}_{x\\sim\\mathcal{P}^{\\mathrm{train}}(\\cdot|y)}\\ell_{\\mathrm{sup}}(f_{t}(x),y)}&{}\\\\ {=\\displaystyle\\sum_{y\\in\\mathcal{Y}}q_{t}[y]\\cdot\\nabla_{f}\\mathbb{E}_{x\\sim\\mathcal{P}^{\\mathrm{train}}(\\cdot|y)}\\ell_{\\mathrm{sup}}(f_{t}(x),y)}&{}\\\\ {=\\displaystyle\\sum_{y\\in\\mathcal{Y}}q_{t}[y]\\cdot\\nabla_{f}\\mathbb{E}_{x\\sim\\mathcal{P}_{t}^{\\mathrm{train}}(\\cdot|y)}\\ell_{\\mathrm{sup}}(f_{t}(x),y)}&{}\\\\ {=\\nabla_{f}\\ell(f_{t},\\mathcal{P}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The third equality is as how $s_{t}$ is constructed. The fourth equality holds by the label shift assumption. We can check the second equality: if $f_{t}$ is dependent of $S_{t}$ , the correctness of the second equality is not guaranteed and so is the overall unbiased property derivation. ", "page_idx": 14}, {"type": "text", "text": "C  The Revision for Previous Online Label Shift Adaptation Algorithms ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The revised algorithms to be used in the main algorithm OLS-OFU (Algorithm 1) are FTH-R (Algorithm 3), UOGD-R (Algorithm 4), ROGD-R (Algorithm 2), ATLAS-R (Algorithm 5), FLHFTLR (Algorithm 6). ", "page_idx": 14}, {"type": "text", "text": "D Theorems for OLS and Proofs ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this section, we present the theoretical results of FLHFTL-OFU, ROGD-OFU, FTH-OFU, UOGDOFU, ATLAS-OFU and their proofs. The proofs are mostly the same as the proofs for the original algorithms with small adjustments. As our results are not straight corollaries for the original theorems, we write the full proofs here for the completeness. ", "page_idx": 14}, {"type": "text", "text": "D.1Theorem for FLHFTL-OFU ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Before proving Theorem 2 (in Section 3.3 \uff09 we recall the assumption from Baby et al. [6] for convenience. We refer the reader to Baby et al. [6] for justifications and further details of the assumptions. ", "page_idx": 14}, {"type": "text", "text": "Assumption 1. Assume access to the true label marginals $q_{0}\\in\\Delta_{K}$ of the offine train data and the true confusionmatrix $C\\in\\mathbb{R}^{K\\times K}$ Further theminimum singular value $\\dot{\\sigma}_{m i n}(C)=\\Omega(1)$ boundedaway fromzero. ", "page_idx": 14}, {"type": "text", "text": "Algorithm 3 Revised FTH for online feature updates (FTH-R). See the original version in Equation 9 in [49]. ", "page_idx": 14}, {"type": "text", "text": "for $t=1,\\cdot\\cdot\\cdot\\,,T\\,{\\bf d o}$ Input at time $t$ : Samples $S_{1}\\cup\\cdot\\cdot\\cdot\\cup S_{t}$ , models $\\{f_{1},\\cdots,f_{t}\\}$ , and intermediate model $\\{\\bar{f_{1}^{\\prime\\prime}},\\cdot\\cdot\\cdot,f_{t}^{\\prime\\prime}\\}$ from step 3 in Algorithm 1, the validation set $D_{0}^{\\prime}$ , the train label marginal $q_{0}:=\\mathcal{P}^{\\mathrm{train}}(y)$ 1. Compute the unbiased estimator for label marginal distribution: $\\begin{array}{r}{s_{t}=\\overline{{|s_{t}|}}\\sum_{x_{t}\\in S_{t}}C_{f_{t},D_{0}^{\\prime}}^{-1}f_{t}^{\\prime\\prime}(x_{t})}\\end{array}$ $\\vartriangleright$ In the original FTL, it is $f_{0}$ rather than $f_{t}^{\\prime\\prime}$ 2. Compute $\\begin{array}{r}{p_{t+1}=\\frac{1}{t}\\sum_{\\tau=1}^{t}s_{\\tau}}\\end{array}$ 3. Let $f_{t+1}$ be a reweighting version of $f_{t}^{\\prime\\prime}$ by the weight $\\begin{array}{r}{\\bigg(\\frac{p_{t+1}[k]}{q_{0}[k]}:k=1,\\cdot\\cdot\\cdot K\\bigg)}\\end{array}$ $\\vartriangleright$ In the original FTL, it is $f_{\\mathrm{0}}$ rather than $f_{t}^{\\prime\\prime}$ Output at time t: ft+1-   \nend for ", "page_idx": 14}, {"type": "text", "text": "Algorithm 4 Revised UOGD for online feature updates (UOGD-R). See the original version in Equation 9 in [7]. ", "page_idx": 15}, {"type": "text", "text": "Require: The learning rate $\\eta$   \nfor $t=1,\\cdot\\cdot\\cdot,T$ do Input at time $t$ : Samples $S_{1}\\cup\\cdot\\cdot\\cdot\\cup S_{t}$ , models $\\{f_{1},\\cdots,f_{t}\\}$ , and intermediate model $\\{\\bar{f_{1}^{\\prime\\prime}},\\cdot\\cdot\\cdot,f_{t}^{\\prime\\prime}\\}$ from step 3 in Algorithm 1, the validation set $D_{0}^{\\prime}$ , the train label marginal $q_{0}:=\\mathcal{P}^{\\mathrm{train}}(y)$ 1. Compute the unbiased estimator for label marginal distribution: $\\begin{array}{r}{s_{t}=\\overline{{|s_{t}|}}\\sum_{x_{t}\\in S_{t}}C_{f_{t}^{\\prime\\prime},D_{0}^{\\prime}}^{-1}f_{t}^{\\prime\\prime}(x_{t})}\\end{array}$ $\\vartriangleright$ In the original UOGD, it is $f_{0}$ rather than $f_{t}^{\\prime\\prime}$ 2. Grab the weight $w_{t}$ from the last linear layer of $f_{t}$   \n3. Update $\\begin{array}{r}{w_{t+1}:=w_{t}-\\eta\\cdot\\frac{\\partial}{\\partial w}J_{w}(w_{t})^{\\top}s_{t}}\\end{array}$ where $\\begin{array}{r}{J_{w}(w_{t})=\\frac{\\partial}{\\partial w}(\\hat{R}_{t}^{1}(w),\\cdot\\cdot\\cdot,\\hat{R}_{t}^{K}(w))|_{w=w_{t}}}\\end{array}$ $\\begin{array}{r}{\\hat{R}_{t}^{k}(w)=\\frac{1}{|D_{0}^{k}|}\\sum_{(x,y)\\in D_{0}^{k}}\\ell_{\\mathrm{ce}}(f(x|\\theta_{t}^{\\mathrm{feat}},\\theta^{\\mathrm{linear}}=w),y)}\\end{array}$ \uff0c $D_{0}^{k}$ denotesthe st of data with label $k$ in $D_{0}$ \uff1a $\\vartriangleright$ In the original UOGD, it is $\\theta_{0}^{\\mathrm{feat}}$ rather than $\\theta_{t}^{\\mathrm{feat}}$ 4. Let $f_{t+1}$ be $f(\\cdot|\\theta_{t}^{\\mathrm{feat}},w_{t+1})$ Output at time t: $f_{t+1}^{\\prime}$   \nend for ", "page_idx": 15}, {"type": "text", "text": "Algorithm 5 Revised ATLAS for online feature updates (ATLAS-R). See the original version in Equation 9 in [7]. ", "page_idx": 15}, {"type": "text", "text": "Require: The learning rate pool $\\mathcal{H}$ with size N; Meta learning rate $\\varepsilon$ $\\because\\forall i\\in[N]$ $p_{1,i}=1/N$ and W1,z = Olinear. ", "page_idx": 15}, {"type": "text", "text": "for $t=1,\\cdot\\cdot\\cdot,T\\,\\cdot$ do Input at time $t$ : Samples $S_{1}\\cup\\cdot\\cdot\\cdot\\cup S_{t}$ , models $\\{f_{1},\\cdots,f_{t}\\}$ , and intermediate model $\\{\\bar{f_{1}^{\\prime\\prime}},\\cdot\\cdot\\cdot,f_{t}^{\\prime\\prime}\\}$ from step 3 in Algorithm 1, the validation set $D_{0}^{\\prime}$ , the train label marginal $q_{0}:=\\mathcal{P}^{\\mathrm{train}}(y)$ 1. Compute the unbiased estimator for label marginal distribution: $\\begin{array}{r}{s_{t}=\\overline{{|s_{t}|}}\\sum_{x_{t}\\in S_{t}}C_{f_{t},D_{0}^{\\prime}}^{-1}f_{t}^{\\prime\\prime}(x_{t})}\\end{array}$ $\\vartriangleright$ In the original ATLAS, it is $f_{0}$ rather than $f_{t}^{\\prime\\prime}$ for $i\\in[N]$ do 2. Updale $\\begin{array}{r}{w_{t+1,i}:=w_{t,i}-\\eta_{i}\\cdot\\frac{\\partial}{\\partial w}J_{w}(w_{t,i})^{\\top}s_{t}}\\end{array}$ where $\\begin{array}{r}{J_{w}(w_{t,i})=\\frac{\\partial}{\\partial w}(\\hat{R}_{t}^{1}(w),\\cdot\\cdot\\cdot\\cdot,\\hat{R}_{t}^{K}(w))|_{w=w_{t,i}}}\\end{array}$ $\\begin{array}{r}{\\hat{R}_{t}^{k}(w)=\\frac{1}{|D_{0}^{k}|}\\sum_{(x,y)\\in D_{0}^{k}}\\ell_{\\mathrm{ce}}(f(x|\\theta_{t}^{\\mathrm{feat}},w),y),D_{0}^{k}}\\end{array}$ with label $k$ in $D_{0}$ In the original ATLAS, it is Ofeat rather than Ofeat. end for 3. Update weight $p_{t+1}$ according to $\\begin{array}{r}{p_{p_{t,i}}\\propto\\exp(-\\varepsilon\\sum_{\\tau=1}^{t-1}\\hat{R}_{\\tau}(\\mathbf{w}_{\\tau,i}))}\\end{array}$   \n3. Compute $\\begin{array}{r}{w_{t+1}=\\sum_{i=1}^{N}p_{t+1,i}w_{t+1,i}}\\end{array}$ Let $f_{t+1}$ b $f(\\cdot|\\theta_{t}^{\\mathrm{feat}},w_{t+1})$ \uff0c Output at time t: ft+1.   \nend for ", "page_idx": 15}, {"type": "text", "text": "Algorithm 6 Revised FLHFTL for online feature updates (FLHFTL-R); See the original version in [6]. ", "page_idx": 15}, {"type": "text", "text": "Require: Online regression oracle ALG.   \nfor $t=1,\\cdot\\cdot\\cdot,T$ do Input at time $t$ :Samples $S_{1}{\\cup}{\\cdot}\\cdot{\\cup}S_{t}$ , models $\\{f_{1},\\cdot\\cdot\\cdot,f_{t}\\}$ , intermediate models $\\{f_{1}^{\\prime\\prime},\\cdot\\cdot\\cdot,f_{t}^{\\prime\\prime}\\}$ the validation set $D_{0}^{\\prime}$ , the train label marginal $q_{0}:=\\mathcal{P}^{\\mathrm{train}}(y)$ 1. Compute the unbiased estimator for label marginal distribution: $\\begin{array}{r l r l}{S_{t}}&{{}}&{=}&{{}}\\end{array}$ $\\begin{array}{r}{\\frac{1}{|S_{t}|}\\sum_{x_{t}\\in S_{t}}\\mathbf{\\bar{\\emph{C}}}_{f_{t}^{\\prime\\prime},D_{0}^{\\prime}}^{-1}f_{t}^{\\prime\\prime}(x_{t})\\triangleright}\\end{array}$ St Cfr,D f (ct ) In the riginal FLHFETL itis f rather than f'. 2. Compute ${\\tilde{q}}_{t+1}:=\\mathrm{ALG}(s_{1},\\cdot\\cdot\\cdot\\,,s_{t})$ 3. Let $f_{t+1}^{\\prime}$ be a reweighting version of $f_{t}^{\\prime\\prime}$ by the weight $\\begin{array}{r}{\\left(\\frac{\\tilde{q}_{t+1}[k]}{q_{0}[k]}:k=1,\\cdot\\cdot\\cdot K\\right)\\circ}\\end{array}$ In the original FLHFTL, it is $f_{0}$ rather than $f_{t}^{\\prime\\prime}$ Output at time $t$ \uff1a $f_{t+1}^{\\prime}$   \nend for ", "page_idx": 15}, {"type": "text", "text": "Assumption 2 (Lipschitzness of loss functions). Let $\\mathcal{D}$ beacompact andconvexdomain.Let $r_{t}$ be any probabilistic classifier.Assume that $L_{t}(p)\\,:=\\,E\\left[\\ell(g(\\cdot;r_{t},p/q_{0})|x_{t}\\right]$ is $G$ Lipschitz with $p\\in\\mathcal{D}\\subseteq\\Delta_{K}$ i.e, $L_{t}(p_{1})-L_{t}(p_{2})\\leq G\\|p_{1}-p_{2}\\|_{2}$ for any $p_{1},p_{2}\\in\\mathcal{D}$ . The constant $G$ need not be known aheadof time. ", "page_idx": 16}, {"type": "text", "text": "Theorem 2. [Regret convergence for FLHFTL-OFU] Suppose we choose the OLS-R to be FLHFTL$R$ (Algorthm 6)fromBabyetal.[6].Let $f_{t}^{\\mathrm{flhftl-ofu}}$ be the output at time stp $t-1$ from Algorithm I, that is $g\\big(\\cdot;f_{t}^{\\prime\\prime},\\frac{\\tilde{q}_{t}}{q_{0}}\\big)$ Let $\\sigma$ be the smalletamong the theminimumn singularvalues ofiverible confusion matrices $\\{C_{f_{1}^{\\prime\\prime},D_{0}^{\\prime}},\\cdot\\cdot\\cdot C_{f_{T}^{\\prime\\prime},D_{0}^{\\prime}}\\}$ ThenunderAssumptions $^{\\,l}$ and 2 in Baby et al. [6], FLHFTL-OFUhastheguaranteebelow: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\ell(f_{t}^{\\mathrm{Hhftl-ofu}};\\mathcal{P}_{t}^{\\mathrm{test}})\\right]\\leq\\mathbb{E}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\ell(g(\\cdot;f_{t}^{\\prime\\prime},\\frac{q_{t}}{q_{0}});\\mathcal{P}_{t}^{\\mathrm{test}})\\right]+O\\left(\\frac{K^{1/6}V_{T}^{1/3}}{\\sigma^{2/3}T^{1/3}}+\\frac{K}{\\sigma\\sqrt{T}}\\right),\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Wwhere $\\begin{array}{r}{V_{T}:=\\sum_{t=1}^{T}\\|q_{t}-q_{t-1}\\|_{1}}\\end{array}$ $K$ randomness in the revealed co-variates. This result is attained without prior knowledge of $V_{T}$ ", "page_idx": 16}, {"type": "text", "text": "Proof: The proof follows the similar idea in the original online regression algorithm FLHFTL [22] and its variants for solving online label shift problem in Baby et al. [6]. ", "page_idx": 16}, {"type": "text", "text": "The algorithm in Baby et al. [6] requires that the estimate $s_{t}$ in Line 1 of Algorithm 6 is unbiased estimate of the label marginal $q_{t}$ . Since $f_{t}^{\\prime\\prime}$ in Algorithm 6 is independent of the sample $S_{t}$ , and since we are working under the standard label shift assumption, due to Lipton et al. [35] we have that Cf,Do  es, f(ct)forms an unbiased estimate of Ea\\~Ppe If (\u00b1). Further, from Lipton et al. [35], the reciprocal of standard deviation of this estimate is bounded below by minimum of the singular values of confusion matrices $\\{C_{f_{1}^{\\prime\\prime},D_{0}^{\\prime}},\\cdot\\cdot\\cdot C_{f_{T}^{\\prime\\prime},D_{0}^{\\prime}}\\}$ ", "page_idx": 16}, {"type": "text", "text": "Let ${\\tilde{q}}_{t}$ be the estimate of the label marginal maintained by FLHFTL. By Lipschitzness, we have that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{E[\\ell(f_{t}^{\\mathrm{flhftl-ofu}};\\mathcal{P}_{t}^{\\mathrm{test}})-\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p/q_{0})]=E[L_{t}(\\tilde{q}_{t})]-E[L_{t}(q_{t})]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\le G\\cdot E[\\|\\tilde{q}_{t}-q_{t}\\|_{2}],}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the last line is via Assumption 2. ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{t=1}^{T}E[\\ell(f_{t}^{\\mathrm{Hhtl-oft}};\\mathcal{P}_{t}^{\\mathrm{tet}})-\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p/q_{0})\\big)\\leq\\sum_{t=1}^{T}G\\cdot E[\\|\\tilde{q}_{t}-q_{t}\\|_{2}]}}}&{}&{(11)}\\\\ &{\\leq\\sum_{t=1}^{T}G\\sqrt{E\\|\\tilde{q}_{t}-q_{t}\\|_{2}^{2}}}&{\\quad}&{(12)}\\\\ &{\\leq G\\sqrt{T\\sum_{t=1}^{T}E[\\|\\tilde{q}_{t}-q_{t}\\|_{2}^{2}]}}&{\\quad}&{(13)}\\\\ &{=\\bar{O}\\left(K^{1/6}T^{2/3}V_{T}^{1/3}(1/\\sigma_{m i n}^{2/3}(C))+\\sqrt{K T}/\\sigma_{m i n}(C)\\right)}&{\\quad}&{}\\\\ &{\\leq\\bar{O}\\left(K^{1/6}T^{2/3}V_{T}^{1/3}(1/\\sigma_{m i n}^{2/3}(C))+\\sqrt{K T}/\\sigma_{m i n}(C)\\right)}&{\\quad}&{.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the second line is due to Jensen's inequality, third line by Cauchy-Schwartz and last line by Proposition 16 in Baby et al. [6]. This finishes the proof. ", "page_idx": 16}, {"type": "text", "text": "D.2 Theorem for ROGD-OFU ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We state the assumptions first for the later theorems. These assumptions are similar to Assumption 1-3 in [49]. ", "page_idx": 16}, {"type": "text", "text": "Assumption 3. $\\forall\\mathcal{P}\\in\\{\\mathcal{P}^{\\mathrm{train}},\\mathcal{P}_{1}^{\\mathrm{test}},\\cdot\\cdot\\cdot,\\mathcal{P}_{T}^{\\mathrm{test}}\\},$ $\\mathrm{diag}(C_{f,\\mathcal{P}})$ is differentiable with respt $f$ ", "page_idx": 16}, {"type": "text", "text": "Assumption 4. $\\forall t\\in[T],\\,\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p/q_{0});\\mathcal{P}_{t}^{\\mathrm{test}})$ is convex in $p_{i}$ where $f_{t}^{\\prime\\prime}$ is defined in Algorithm 1. Assumption 5. $\\begin{array}{r}{\\operatorname*{sup}_{p\\in\\Delta^{K-1},i\\in[K],t\\in[T]}\\|\\nabla_{p}\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p/q_{0});\\mathcal{P}_{t}^{\\mathrm{test}})\\|_{2}}\\end{array}$ is finite and bounded by $L$ ", "page_idx": 17}, {"type": "text", "text": "Theorem 3 (Regret convergence for ROGD-OFU). If we run Algorithm 1 with ROGD-R (Algorithm 2) and $\\begin{array}{r}{\\eta=\\sqrt{\\frac{2}{T}}\\frac{1}{L}}\\end{array}$ , under Assumption 3, 4, 5, ROGD-OFU satisfies the guarante ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\ell(f_{t}^{\\mathrm{ogd-ofu}};\\mathcal{P}_{t}^{\\mathrm{test}})\\right]-\\operatorname*{min}_{p\\in\\Delta_{K}}\\mathbb{E}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p/q_{0});\\mathcal{P}_{t}^{\\mathrm{test}})\\right]\\leq\\sqrt{\\frac{2}{T}}L.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\ell(f_{t}^{\\mathrm{ogd}};\\mathcal{Q}_{t})\\right]-\\operatorname*{min}_{p\\in\\Delta_{K}}\\mathbb{E}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\ell(g(\\cdot;p,f_{0},q_{0});\\mathcal{Q}_{t})\\right]\\leq\\sqrt{\\frac{2}{T}}L.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof: The proof follows the similar idea in the original online leanring algorithm online gradient descent (OGD) [44] and the ROGD in Wu et al. [49]. For any fixed $p$ ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle(f_{t}^{\\mathrm{rogd-ofu}};\\mathcal{P}_{t}^{\\mathrm{test}})-\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p/q_{0});\\mathcal{P}_{t}^{\\mathrm{test}})=\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p_{t}/q_{0});\\mathcal{P}_{t}^{\\mathrm{test}})-\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p/q_{0});\\mathcal{P}_{t}^{\\mathrm{test}})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq(p_{t}-p)\\cdot\\nabla_{p}\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p_{t}/q_{0});\\mathcal{P}_{t}^{\\mathrm{test}})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=(p_{t}-p)\\cdot J_{p,f_{t}^{\\prime\\prime}}(p_{t})^{\\top}\\mathbb{E}_{S_{t}}[s_{t}|S_{1},\\cdot\\cdot\\cdot,S_{t-1}]}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}_{S_{t}}[(p_{t}-p)\\cdot J_{p,f_{t}^{\\prime\\prime}}(p_{t})^{\\top}s_{t}|S_{1},\\cdot\\cdot\\cdot,S_{t-1}],}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the last inequality hols by the fact that $(p_{t}-p)\\cdot J_{p,f_{t}^{\\prime\\prime}}(p_{t})^{\\top}$ is independent of $\\{S_{1},\\cdot\\cdot\\cdot,S_{t-1}\\}$ To bound $(p_{t}-p)\\cdot J_{p,f_{t}^{\\prime\\prime}}(p_{t})^{\\top}s_{t}$ ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|p_{t+1}-p\\|_{2}^{2}=\\|\\mathrm{Prof}_{\\Delta^{K-1}}(p_{t}-\\eta\\cdot J_{p,f_{t}^{\\prime\\prime}}(p_{t})^{\\top}s_{t})-p\\|_{2}^{2}}\\\\ &{\\qquad\\qquad\\leq\\|p_{t}-\\eta\\cdot J_{p,f_{t}^{\\prime\\prime}}(p_{t})^{\\top}s_{t}-p\\|_{2}^{2}}\\\\ &{\\qquad\\qquad=\\|p_{t}-p\\|_{2}^{2}+\\eta^{2}\\|J_{p,f_{t}^{\\prime\\prime}}(p_{t})^{\\top}s_{t}\\|_{2}^{2}-2\\eta(p_{t}-p)\\cdot(J_{p,f_{t}^{\\prime\\prime}}(p_{t})^{\\top}s_{t}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This implies ", "page_idx": 17}, {"type": "equation", "text": "$$\n(p_{t}-p)\\cdot(J_{p,f_{t}^{\\prime\\prime}}(p_{t})^{\\top}s_{t})\\leq\\frac{1}{2\\eta}(\\|p_{t}-p\\|_{2}^{2}-\\|p_{t+1}-p\\|_{2}^{2})+\\frac{\\eta}{2}\\|J_{p,f_{t}^{\\prime\\prime}}(p_{t})^{\\top}s_{t}\\|_{2}^{2}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Thus ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathbb{E}_{S_{1},\\cdots,S_{T}}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\ell(f_{t}^{\\mathrm{rogd-ofd}}\\cdot\\mathcal{P}_{t}^{\\mathrm{test}})-\\frac{1}{T}\\sum_{t=1}^{T}\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p/q_{0});\\mathcal{P}_{t}^{\\mathrm{test}})\\right]}\\\\ &{\\displaystyle\\le\\mathbb{E}_{S_{1},\\cdots,S_{T}}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\frac{1}{2\\eta}(\\|p_{t}-p\\|_{2}^{2}-\\|p_{t+1}-p\\|_{2}^{2})+\\frac{\\eta}{2}\\|J_{p,f_{t}^{\\prime\\prime}}(p_{t})^{\\top}s_{t}\\|_{2}^{2}\\right]}\\\\ &{\\displaystyle\\le\\frac{1}{2\\eta T}\\|p_{1}-p\\|_{2}^{2}+\\frac{\\eta}{2T}\\sum_{t=1}^{T}\\mathbb{E}_{S_{1},\\cdots,S_{t}}[\\|J_{p,f_{t}^{\\prime\\prime}}(p_{t})^{\\top}s_{t}\\|_{2}^{2}]}\\\\ &{\\displaystyle\\le\\frac{1}{\\eta T}+\\frac{\\eta L^{2}}{2}=\\sqrt{\\frac{2}{T}}L.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This bound holds for any p. Thus, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathfrak{c}_{S_{1},\\cdots,S_{T}}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\ell(f_{t}^{\\mathrm{rogd-ofu}};\\mathcal{P}_{t}^{\\mathrm{test}})\\right]-\\operatorname*{min}_{p\\in\\Delta^{K-1}}\\mathbb{E}_{S_{1},\\cdots,S_{T}}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p/q_{0});\\mathcal{P}_{t}^{\\mathrm{test}})\\right]\\le\\sqrt{\\frac{2}{T}}L^{\\mathrm{id}}(\\lambda).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "D.3Theorem for FTH-OFU ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We begin with two assumptions. ", "page_idx": 17}, {"type": "text", "text": "Assumption 6. For any $\\mathcal{P}^{\\mathrm{test}}\\,s.t.\\,\\,\\mathcal{P}^{\\mathrm{test}}(x|y)=\\mathcal{P}^{\\mathrm{train}}(x|y),$ denote $q_{t}:=(\\mathcal{P}_{t}^{\\mathrm{test}}(y=k):k\\in[K])$ and then ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\lVert q_{t}-\\arg\\operatorname*{min}_{p\\in\\Delta^{K-1}}\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p/q_{0});\\mathcal{P}^{\\mathrm{test}})\\rVert\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Assumption7 $\\begin{array}{r}{\\colon\\forall\\mathcal{P}^{\\mathrm{test}}\\,s.t.\\ \\mathcal{P}^{\\mathrm{test}}(x|y)=\\mathcal{P}^{\\mathrm{train}}(x|y),\\,\\operatorname*{sup}_{p}\\|\\nabla_{p}\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p/q_{0});\\mathcal{P}^{\\mathrm{test}})\\|\\le L}\\end{array}$ ", "page_idx": 18}, {"type": "text", "text": "Theorem 4 (Regret convergence for FTH-OFU). If we run Algorithm $^{\\,l}$ with FTH- $R$ (Algorithm 3) and assume $\\sigma$ is no larger than theminimum singularvalue of invertible confusionmatrices $\\{C_{f_{1}^{\\prime\\prime},D_{0}^{\\prime}},\\cdot\\cdot\\cdot C_{f_{T}^{\\prime\\prime},D_{0}^{\\prime}}\\}$ underAssumption $^{6}$ and 7 with $\\delta=0$ FTH-OFU satisfies the guarantee that withprobabilityat least $1-2K T^{-7}$ over samples $S_{1}\\cup\\cdot\\cdot\\cdot\\cup S_{T}$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{1}{T}\\sum_{t=1}^{T}\\ell(f_{t}^{\\mathrm{fth-ofu}};\\mathcal{P}_{t}^{\\mathrm{test}})-\\operatorname*{min}_{p\\in\\Delta_{K}}\\frac{1}{T}\\sum_{t=1}^{T}\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p/q_{0});\\mathcal{P}_{t}^{\\mathrm{test}})\\le O\\left(\\frac{\\log T}{T}+\\frac{1}{\\sigma}\\sqrt{\\frac{K\\log T}{T}}\\right),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $K$ is the number of classes. ", "page_idx": 18}, {"type": "text", "text": "Proof: The proof follows the similar idea in the original online leanring algorithm FTL [44] and the FTH in $\\mathrm{Wu}$ et al. [49]. Denote $q_{t}:=(\\mathcal{P}_{t}^{\\mathrm{test}}(y=k)\\dot{:}k\\in[K])$ . By the Hoeffding and union bound, wehave ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\forall t\\leq T,\\|p_{t+1}-\\frac{1}{t}\\sum_{\\tau=1}^{t}q_{\\tau}\\|\\leq\\sqrt{K}\\varepsilon_{t}\\right)\\geq1-\\sum_{t=1}^{T}2M\\exp\\left(-2\\varepsilon_{t}^{2}t/\\sigma^{2}\\right).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "This implie that with probability a least $\\begin{array}{r}{1-\\sum_{t=1}^{T}2M\\exp{\\left(-2\\varepsilon_{t}^{2}t/\\sigma^{2}\\right)},\\forall p,}\\end{array}$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\xi(\\rho_{t};\\hat{p}_{t}^{t w_{1}})-\\sum_{t=1}^{T}\\xi(g(\\cdot;\\hat{f}_{t}^{\\prime\\prime},p_{t}^{\\prime\\prime}/q_{0});\\hat{p}_{t}^{t w_{1}})}\\\\ &{\\le\\displaystyle\\sum_{t=1}^{T}\\xi(g(\\cdot;\\hat{f}_{t}^{\\prime\\prime},\\frac{1}{t}\\frac{1}{r-1};q,\\cdot;\\hat{\\rho}_{t}^{t w_{1}})-\\sum_{t=1}^{T}\\xi(g(\\cdot;\\hat{f}_{t}^{\\prime\\prime},p/q_{0});\\hat{p}_{t}^{t w_{1}})+L\\sqrt{M}\\cdot\\sum_{t=1}^{T}\\varepsilon_{t}}\\\\ &{\\le\\displaystyle\\sum_{t=1}^{T}\\xi(g(\\cdot;\\hat{f}_{t}^{\\prime\\prime},\\frac{1}{t}-\\frac{1}{r-1};q,\\cdot)\\cdot\\hat{p}_{t}^{t w_{1}})-\\sum_{t=1}^{T}\\xi(g(\\cdot;\\hat{f}_{t}^{\\prime\\prime},\\frac{1}{t}\\frac{t}{r-1};q,\\cdot)\\cdot\\hat{p}_{t}^{t w_{1}})+L\\sqrt{M}\\cdot\\sum_{t=1}^{T}\\varepsilon_{t}}\\\\ &{\\lesssim\\displaystyle\\sum_{t=1}^{T}L\\left\\|\\frac{1}{t-1}\\frac{t-1}{r-1}-\\frac{1}{t}\\frac{1}{r-1}q,\\right\\|+L\\sqrt{M}\\cdot\\sum_{t=1}^{T}\\varepsilon_{t}}\\\\ &{\\lesssim\\displaystyle\\sum_{t=1}^{T}\\frac{L}{t}\\left\\|\\frac{1}{t-1}\\frac{t-1}{q}-\\hat{q}_{t}\\right\\|+L\\sqrt{M}\\cdot\\sum_{t=1}^{T}\\varepsilon_{t}}\\\\ &{\\lesssim\\displaystyle\\sum_{t=1}^{T}\\frac{L}{t}\\left\\|\\frac{1}{t-1}\\frac{t-1}{q},\\cdot\\hat{q}_{t}-\\hat{q}_{t}\\right\\|+L\\sqrt{M}\\cdot\\sum_{t=1}^{T}\\varepsilon_{t}}\\\\ &{\\leq\\displaystyle\\sum_{t=1}^{T}\\frac{2L}{t}+L\\sqrt{M}\\cdot\\sum_{t=1}^{T}\\varepsilon_{t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "If we take $\\begin{array}{r}{\\varepsilon_{t}=2\\sigma\\sqrt{\\frac{\\ln T}{T}}}\\end{array}$ , the above is equivalent to: with probability at least $1-2K T^{-7}$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{1}{T}\\sum_{t=1}^{T}\\ell(p_{t};\\mathcal{P}_{t}^{\\mathrm{test}})-\\operatorname*{min}_{p}\\frac{1}{T}\\sum_{t=1}^{T}\\ell(g(\\cdot;f_{t}^{\\prime\\prime},p/q_{0});\\mathcal{P}_{t}^{\\mathrm{test}})\\leq2L\\frac{\\ln T}{T}+4L\\sigma\\sqrt{\\frac{K\\ln T}{T}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "D.4 Theorems for UOGD-OFU and ATLAS-OFU ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Theorem 5. [Regret convergence for UOGD-OFU] Let $f(\\cdot;\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}},w)$ denote a network with the same $f_{t}^{\\prime\\prime}$ andalast inarlayewi wigh $w$ Let $f^{\\mathrm{uogd-ofu}}=f(\\cdot;\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}},w_{t})$ where $w_{t}$ is the weight maintained at round by Algorithm 4. If we run Algorithm 1 with UOGD in $I7J$ and let step size be $\\eta,$ then under the same assumptions as Lemma $^{\\,l}$ in [7], UOGD-OFU satisfies that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\boldsymbol{\\uptau}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\ell(f^{\\mathrm{uogd-ofu}};\\mathcal{P}_{t}^{\\mathrm{test}})-\\frac{1}{T}\\sum_{t=1}^{T}\\operatorname*{min}_{w\\in\\mathcal{W}}\\ell(f(\\cdot;\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}},w);\\mathcal{P}_{t}^{\\mathrm{test}})\\right]\\leq O\\left(\\frac{K\\eta}{\\sigma^{2}}+\\frac{1}{\\eta T}+\\sqrt{\\frac{V_{T,\\ell}}{T\\eta}}\\right),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Wwhere $\\begin{array}{r}{V_{T,\\ell}:=\\sum_{t=2}^{T}\\operatorname*{sup}_{w\\in\\mathcal{W}}|\\ell(f(\\cdot;\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}},w);\\mathcal{P}_{t}^{\\mathrm{test}})-\\ell(f(\\cdot;\\theta_{f_{t-1}^{\\prime\\prime}}^{\\mathrm{feat}},w);\\mathcal{P}_{t-1}^{\\mathrm{test}})|}\\end{array}$ $\\sigma$ deotes he i imum singular value of the invertible confusionmatrices $\\{C_{f_{1}^{\\prime\\prime},D_{0}^{\\prime}},\\cdot\\cdot\\cdot C_{f_{T}^{\\prime\\prime},D_{0}^{\\prime}}\\}$ and $K$ is the number of classes and the expectation is taken with respect to randomness in the revealed $c o$ -variates. ", "page_idx": 18}, {"type": "text", "text": "Proof Sketch: Recall that $\\ell(f(\\cdot;\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}},w);\\mathcal{P}_{t}^{\\mathrm{test}}):=E_{(x,y)\\sim\\mathcal{P}_{t}^{\\mathrm{test}}}\\ell_{\\mathrm{ce}}\\left(f(x|\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}},w),y\\right).$ ", "page_idx": 19}, {"type": "text", "text": "This guarantee follows from the arguments in Bai et al. [7] from two basic facts below: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\overrightharpoon{E_{((x,y)\\sim\\mathcal{P}_{t}^{\\mathrm{test}})}\\nabla_{w}\\ell_{\\mathrm{ce}}}\\left(f(x|\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}},w),y\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Hence we proceed to verify these two facts in our setup. Fact 1 is true because the cross-entropy loss is convex in any subset of the simplex and the last linear layer weights only defines an affine transformation which preserves convexity. ", "page_idx": 19}, {"type": "text", "text": "For fact 2, note that the $f_{t}^{\\prime\\prime}$ only uses the data until round $t-1$ . So by the same arguments in Bai et al. [7], using the BBSE estimator defined from the classifier $f_{t}^{\\prime\\prime}$ , the unbiased estimate of risk gradient can be defined. ", "page_idx": 19}, {"type": "text", "text": "Let $w_{t}$ be the weight of the last layer maintained by UOGD at round t. Let $u_{1:T}$ be any sequence in $\\mathcal{W}$ . Consequently we have for any round, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\ell(f^{\\mathrm{uogd-ofu}};\\mathcal{P}_{t}^{\\mathrm{test}})-\\ell(f(\\cdot;\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}},u_{t}))=\\ell(f(\\cdot;\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}},w_{t})-\\ell(f(\\cdot;\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}},u_{t}))}&{}\\\\ {\\leq\\langle\\nabla_{w}\\ell(f(\\cdot;\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}},w_{t}),w_{t}-u_{t}\\rangle}&{}\\\\ {=\\langle E[\\hat{G}_{t}(w_{t})|S_{1:t-1}],w_{t}-u_{t}\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Rest of the proof is identical to Bai et al. [7]. ", "page_idx": 19}, {"type": "text", "text": "Theorem 5 for UOGD-OLS shows a bound that depends on the learning rate and one can set up the learning carefully to get the optimal rate. However, this learning rate requires the prior information Oof $V_{T}$ , which is typically unknown during the learning process. ATLAS-OLS overcomes this issue by applying the same online ensembling framework [54] as the original ATLAS. Without knowing this prior information, ATLAS-OLS is able to achieve the same rate of upper bound too, which is stated in the following theorem. ", "page_idx": 19}, {"type": "text", "text": "Theorem 6 Regret convergence for ATLAS-OFU). Let $f(\\cdot;\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}},w)$ denote a network with the same featurexracoras thatof $f_{t}^{\\prime\\prime}$ and alat linearlayerwih weight $w$ Let $f^{\\mathrm{atlas-ofu}}=f(\\cdot;\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}},w_{t})$ \uff0c where $w_{t}$ is the weight maintained at round $t$ by Algorithm 5. If we run Algorithm $^{\\,l}$ with ATLAS in $I7J$ and set up the step size pol $\\begin{array}{r}{\\mathcal{H}=\\{\\eta_{i}=O\\left(\\frac{\\sigma}{\\sqrt{K T}}\\right)\\cdot2^{i-1}|i\\in[N]\\}\\,(N=1+\\lceil\\frac{1}{2}\\log_{2}(1+2T)\\rceil),}\\end{array}$ then under the same assumptions as Lemma $^{\\,l}$ in $I7J,$ 'ATLAS-OFU satisfies that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\boldsymbol{\\uptau}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\ell(f^{\\mathrm{atlas-ofu}};\\mathcal{P}_{t}^{\\mathrm{test}})-\\frac{1}{T}\\sum_{t=1}^{T}\\operatorname*{min}_{w\\in\\mathcal{W}}\\ell(f(\\cdot;\\theta_{f_{t+1}^{\\prime\\prime}}^{\\mathrm{feat}},w);\\mathcal{P}_{t}^{\\mathrm{test}})\\right]\\leq\\boldsymbol{O}\\left(\\left(\\frac{K^{1/3}}{\\sigma^{2/3}}+1\\right)\\frac{V_{T,\\ell}^{1/3}}{T^{1/3}}+\\sqrt{\\lambda_{1}(t+1)}\\frac{V_{T,\\ell}^{1/3}}{T^{1/3}}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Wwhere $\\begin{array}{r}{V_{T,\\ell}:=\\sum_{t=2}^{T}\\operatorname*{sup}_{w\\in\\mathcal{W}}|\\ell(f(\\cdot;\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}},w);\\mathcal{P}_{t}^{\\mathrm{test}})-\\ell(f(\\cdot;\\theta_{f_{t-1}^{\\prime\\prime}}^{\\mathrm{feat}},w);\\mathcal{P}_{t-1}^{\\mathrm{test}})|}\\end{array}$ $\\sigma$ imumsingularvalueof theinvertibleconfusionmatrices $\\{C_{f_{1}^{\\prime\\prime},D_{0}^{\\prime}},\\cdot\\cdot\\cdot C_{f_{T}^{\\prime\\prime},D_{0}^{\\prime}}\\}$ and $K$ is the number of classes and the expectation is taken with respect to randomness in the revealed co-variates. ", "page_idx": 19}, {"type": "text", "text": "The proof is similar to that of Theorem 5, which mainly follows the similar idea in the original online ensembling framework [54] and ATLAS [7], and hence omitted. ", "page_idx": 19}, {"type": "text", "text": "Discussion about the assumption. In the theorems for UOGD and ATLAS, the definition of $V_{T,\\ell}$ is shift severity from $\\mathcal{P}_{t}^{\\mathrm{test}}$ . However, in the theorems for UOGD-OFU and ATLAS-OFU above, $V_{T,\\ell}$ is shift severtyfrom both $\\mathcal{P}_{t}^{\\mathrm{test}}$ and $\\theta_{f_{t}^{\\prime\\prime}}^{\\mathrm{feat}}$ which can bemuchlarger This might leadtoharder convergence of the regret. ", "page_idx": 19}, {"type": "image", "img_path": "HNH1ykRjXf/tmp/19ae8ad9df11b6f19e143cc4d57f9a0c0ffce3a2f612b2309a20df773050fab2.jpg", "img_caption": ["Figure 4: Evaluation of OLS and OLS-OFU. "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "E  Additional experiments ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "E.1 Additional Details of Datasets, Online Shift Patterns, and SSL ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Severity of CIFAR-10C in the experiment. For each type of corruption in CIFAR-10C, we select a mild level of severity in the experiment section. Here we introduce the exact parameters of mild and high levels of severity for those corruptions. For Gaussian Noise, the severity level is 0.03. For Fog, the severity level is (0.75,2.5). For Pixelate, the severity level is 0.75. ", "page_idx": 20}, {"type": "text", "text": "Details of online shift patterns. Specifically, given two label distribution vectors $q$ and $q^{\\prime}$ , we simulate the label marginal distributions at time $t$ as a weighted combination of them: $q_{t}\\ :=$ $\\alpha_{t}q+(1-\\alpha_{t})q^{\\prime}$ . In Sinusoidal shift, $\\begin{array}{r}{\\alpha_{t}=\\sin\\frac{i\\pi}{L}}\\end{array}$ (periodic length $L=\\sqrt{T}$ \uff0c $i=t\\bmod L$ while in Bernoulli shift, $\\alpha_{t}$ is a random bit (either 0 or 1), where the bit switches $\\alpha_{t}=1-\\alpha_{t-1}$ with probability $\\begin{array}{r}{p=1-\\frac{1}{\\sqrt{T}}}\\end{array}$ .In our xperiments, we set the initial distribution vetor $q$ and $q^{\\prime}$ with $\\textstyle{\\frac{1}{K}}(1,\\cdot\\cdot\\cdot\\,,1)$ and $(1,0,\\cdots,0)$ . To sample the batch test data at time $t$ we first sample a batch of labels (not revealed to the learner) according to $q_{t}$ . Then given each label we can sample an image from the test set, and collect this batch of images without labels as $S_{t}$ ", "page_idx": 20}, {"type": "text", "text": "Details of self supervised learning techniques. rotation degree prediction involves initially rotating a given image by a specific degree from the set $\\{0,90,180,270\\}$ and the classifier is required to determine the degree by which the image has been rotated. Entropy minimization utilizes a minimum entropy regularizer, with the motivation that unlabeled examples are mostly beneficial when classes have a small overlap. $M o C o$ is a more advanced representation learning technique, using a query and momentum encoder to learn representations from unlabeled data by maximizing the similarity of positive pairs and minimizing the similarity of negative pairs. ", "page_idx": 20}, {"type": "table", "img_path": "HNH1ykRjXf/tmp/77b7ebf91f210e58a894d8c91622cc34fe0b42fcda77471d81cf50826debeb10.jpg", "table_caption": [], "table_footnote": ["Table 4: Average error / time (minutes) of 6 original OLS methods versus OLS-OFU with various frequency $\\tau$ in batch accumulation. The SSL in OLS-OFU is Entropy Minimization. "], "page_idx": 21}, {"type": "text", "text": "Their loss functions are as follow. When the SSL loss is rotation degree prediction, it requires another network $f^{\\mathrm{deg}}$ to predict the rotation degree, sharing the same feature extractor $\\theta^{\\mathrm{feat}}$ as $f_{0}$ but with a different set of downstream layers. Its SSL loss $\\ell_{\\mathrm{ssl}}(S;f)$ is defined as $\\begin{array}{r}{\\sum_{x\\in S}\\ell_{c e}(f^{\\mathrm{deg}}(R(x,i)),i)}\\end{array}$ \uff0c where $i$ is an integer uniformly sampled from [4], and $R(x,i)$ is to rotate $x$ with degree $\\mathrm{DL}[i]$ from a list of degrees $\\mathrm{DL}=[0,90,180,270]$ . Alternatively, if the SSL loss is entropy minimization, $\\ell_{\\mathrm{ssl}}(S;f)$ would be the entropy $\\begin{array}{r}{\\sum_{x\\in S}\\sum_{k=1}^{K}f(x)_{k}\\log f(x)_{k}}\\end{array}$ . Moreover, the SSL loss of MoCo would be a contrastive loss (InfoNCE) where the positive example $x^{\\prime}$ is an augmented version of $x$ and other samples in the same time step can be the negative examples. ", "page_idx": 21}, {"type": "text", "text": "E.2 Additional Results of OLS-OFU and Baselines ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Figure 2 has three subfigures, showing the results of OLS-OFU with three SSL on CIFAR-10, the results on three more datasets for evaluating online label shift, and the results on CIFAR-10C for evaluating online generalized label shift; the online shift patterns are Sinusoidal shift for all these figures in Figure 2. We show similar figures in Figure 4 but now the online shift patterns are Bernoulli shift. We can have the exact same observations from Figure 4: the improvements from original OLS methods to OLS-OFU are significant and consistent across 6 OLS methods, 3 SSL techniques, 4 datasets with online label shift and 3 datasets with online generalized label shift. ", "page_idx": 21}, {"type": "text", "text": "We also evaluate three SSL methods in OLS-OFU on CIFAR-10C with mild severity for two online shift patterns. In Figure 7, the improvement from OLS to OLS-OFU is very significant but OLS-OFU cannot outperform OFU. ", "page_idx": 21}, {"type": "text", "text": "E.3 Ablation Study on Frequency $\\tau$ in OLS-OFU for Entropy Minimization and MoCo ", "text_level": 1, "page_idx": 21}, {"type": "image", "img_path": "HNH1ykRjXf/tmp/3a8ff44171853ddeee03f9181c2c9495b1023a9194119ae95f4e4f48bdd4aec5.jpg", "img_caption": [], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "Table 1 in the main paper shows the ablation study on $\\tau$ when SSL is rotation degree prediction. Here we include Table 4 and Table 5 for the same ablation study on $\\tau$ but the SSL in OLF-OFU is Entropy Minimization and MoCoin two tables respectively. We have same observations as what we observed from Table 1: 1. OLSOFU with all $\\tau$ outperforms OLS; 2. The average error of OLS-OFU decreases from $\\tau\\,=\\,1$ $w/o$ batch accumulation\uff09 to $\\tau\\ =\\ 100$ and starts to increase after and this is because the effectiveness of SSL benefits from $\\tau>1$ while larger $\\tau$ means less updates and hence hurts the long term performance; 3. the additional time cost of OLS-OFU with larger $\\tau$ is smaller and $\\tau\\,=\\,100$ gives a great balance of performance and time cost. ", "page_idx": 21}, {"type": "text", "text": "Figure 5: Empirical examination for the holdness of Equation 7. Clean denotes the experiment on CIFAR-10 and others denotes the corruption type. They are paired with two online shift patterns: Sinusoidal and Bernoulli. ", "page_idx": 21}, {"type": "table", "img_path": "HNH1ykRjXf/tmp/7ccd77e0c9a398b69dcaa0f3159192bfc0b19511674232888863c1419c6b5a03.jpg", "table_caption": [], "table_footnote": ["Table 5: Average error / time (minutes) of 6 original OLS methods versus OLS-OFU with various frequency $\\tau$ in batch accumulation. The SSL in OLS-OFU is MoCo. "], "page_idx": 22}, {"type": "text", "text": "E.4 Empirical Validation of Equation 7 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Similar to Figure 3, as shown in Figure 5, it is evident that OLS-OFU with SSL chosen as Entropy Minimization and MoCo is able to yield improvements on the baseline of the regret as shown in Equation 7. ", "page_idx": 22}, {"type": "image", "img_path": "HNH1ykRjXf/tmp/d465fc721e72dd36716115fcd9348536a2714078a65e434a1e3a75a94ffdcde3.jpg", "img_caption": ["E.5  Self-training ", "Figure 6: Results on pseudo-labelling. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Pseudo labelling [31], a common self-training technique, generates pseudo labels for unlabelled data and uses them to update the model. Though we are not able to use ground-truth labels to compute feature extractor updates, we can use the model at time $t$ to make predictions with respect to the online samples at time $t$ , and train on the inputs with their assigned (pseudo) labels. An issue that arises in self-training is confirmation bias, where the model repeatedly overfits to incorrect pseudo-labels. As such, different methods can be used to select which samples will be pseudo-labelled and used in updating the model, e.g. using data augmentation [3], using regularization to induce confident lowentropy pseudo-labelling [17], using softmax thresholds to filter out noisy low-confidence predictions [50]. We make use of ensembles to identify noisy low-confidence/entropy pseudo-label predictions, though other various alternatives can also be used. In addition to OLS and OLS-OFU, we highlight the methods under comparison: ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "\u00b7 OLS-OFU $(\\ell_{\\mathrm{sup}}(\\cdot,y_{\\mathrm{ground-truth}}))$ : Instead of computing pseudo-labels, we make use of the correct ground-truth labels ground-truth. Recall $\\ell_{\\mathrm{sup}}$ is the supervised learning loss. We update the feature extractor with the supervised loss w.r.t. ground-truth labels $\\ell_{\\mathrm{sup}}(\\cdot,y_{\\mathrm{ground-truth}})$   \n\u00b7 OLS-OFU $(\\ell_{\\mathrm{ssl}}+\\ell_{\\mathrm{sup}}(\\cdot,y_{\\mathrm{ground-truth}}))$ : Instead of computing pseudo-labels, we make use of the correct ground-truth labels $y$ ground-truth. Recall $\\ell_{\\mathrm{ssl}}$ and $\\ell_{\\mathrm{sup}}$ are the self-supervised and supervised learning losses respectively. We update the feature extractor with both the self-supervised loss $\\ell_{\\mathrm{ssl}}$ as well as the supervised loss w.r.t. ground-truth labels $\\ell_{\\mathrm{sup}}(\\cdot,y_{\\mathrm{ground-truth}}).$   \n\u00b7 OLS-OFU $\\ell_{\\mathrm{ssl}}\\;+\\;\\ell_{\\mathrm{sup}}(\\cdot,$ Upseudo-lae(#samples=,#FU-samples=):Recall $\\ell_{\\mathrm{ssl}}$ and $\\ell_{\\mathrm{sup}}$ are the self-supervised and supervised learning losses respectively. We compute pseudo-labels $\\begin{array}{r l}{y_{\\mathrm{pseudo-label}}\\,\\!\\!}&{{}}\\end{array}$ 0, and update the feature extractor with both the self-supervised loss $\\ell_{\\mathrm{ssl}}$ as well as the supervised loss w.r.t. pseudo-labels $\\ell_{\\mathrm{sup}}(\\cdot,y_{\\mathrm{pseudo-label}})$ ", "page_idx": 23}, {"type": "text", "text": "How to compute pseudo-labels? We now describe the procedure to compute pseudo-labels for $\\ell_{\\mathrm{sup}}(\\cdot,y_{\\mathrm{p}},$ seudo-labe(#samples,#FU-samples-) The seed used to train our model is 4242, and we train an additional 4 models on seeds 4343, 4545, 4646, 4747. With this ensemble of 5 models, we keep sampling inputs at each online time step until we have #FU-samples samples, or we reach a limit of #samples samples. We accept an input when the agreement between the ensembles exceeds a threshold $e=1.0$ (i.e. we only accept samples where all 5 ensembles agree on the label of the online sample). In the default online learning setting, there are only #samples $=\\mathtt{10}$ , and therefore there may not be enough accepted samples to perform feature update with, thus we evaluate with a continuous sampling setup, where we sample #samples $\\mathtt{1}=\\mathtt{50}$ (and evaluate on all these samples), but only use the first 10 samples (#FU-samples $=\\mathtt{10}$ ) to perform the feature extractor update. ", "page_idx": 23}, {"type": "text", "text": "Results on pseudo-labelling. We report the results of OLS-OFU with $\\tau=1$ in this section. First, we find that OLS-OFU $(\\ell_{\\mathrm{ssl}}\\,+\\,\\ell_{\\mathrm{sup}}(\\cdot,y_{\\mathrm{ground-truth}}))$ attains the lowest error and is the lower bound we are attaining towards. Evaluating OLS-OFU $\\ell_{\\mathrm{ssl}}+\\ell_{\\mathrm{sup}}(\\cdot,\\upsilon$ pseudo-labl(#samples $=10_{:}$ #FU-sample $\\scriptstyle{\\mathrm{s}}=10)$ ), we find that the performance does not outperform OLS-OFU, and is not near OLS-OFU $\\mathcal{{l}}_{\\mathrm{ssl}}\\,+$ $\\ell_{\\mathrm{sup}}(\\cdot,y_{\\mathrm{ground-truth}}\\bar{)})$ . If we set the threshold $e$ too high, there may not be enough online samples to update the feature extractor. If we set the threshold $e$ too low, there may be too many incorrect labels and we incorrectly update our feature extractor. As such, we would like to sample more inputs at each online time step such that we can balance this tradeoff. We sample #samples $\\scriptstyle:=50$ at each online time step, and update with #FU-samples $\\leq~10$ . For fair comparison, we also show the comparable methods in both #samples $\\mathtt{:=}10$ \uff0c#FU-samples $\\mathtt{:=}10$ and #samples $\\mathtt{,}=\\mathtt{50}$ \uff0c#FU-samples $\\scriptstyle:=50$ settings. ", "page_idx": 23}, {"type": "text", "text": "With this sampling setup, we find that OLS-OFU $(\\ell_{\\mathrm{ssl}}+\\ell_{\\mathrm{sup}}(\\cdot,y)$ pseudo-label#samples $\\scriptstyle{\\mathrm{s}}=50$ #FU-samples $\\!\\!=\\!\\!10_{\\circ}$ can outperform both $O L S{\\cdot}O F U\\left(\\#s a m p\\,2e s\\,{=}\\,{\\it d}\\,0\\right)$ and OLS-OFU $(\\#s a m p\\wr e s=50)$ . Though it does not exceed neither OLS-OFU $(\\ell_{\\mathrm{ssl}}+\\ell_{\\mathrm{sup}}(\\cdot,y_{\\mathrm{ground-truth}}))$ for #samples $=\\!10$ nor #samples $\\mathtt{1}=\\mathtt{50}$ , it lowers the gap considerably. ", "page_idx": 23}, {"type": "image", "img_path": "HNH1ykRjXf/tmp/cea01c73780bd9d8557913ea4a9e2906004440f1f7d3a45e96a0effd0c4fe554.jpg", "img_caption": ["Figure 7: Results of two online shift patterns on CIFAR-10C and three SSL methods in OLS-OFU. "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately refect the paper's contributions and scope? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 25}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should refect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 25}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 26}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u00b7 Ihe answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 26}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : / /nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 27}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 27}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [No] ", "page_idx": 27}, {"type": "text", "text": "Justification: We reported a large range of experimental results, though error bars were not included. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative errorrates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce theexperiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We use A6000 GPU and report time cost evaluation. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 28}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] Justification: ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 28}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We use practical examples like MRI machine. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: No such models/data are used in this paper. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safetyfilters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 29}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properlyrespected? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: No new assets. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 29}, {"type": "text", "text": "\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 30}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA]   \nJustification: No new assets. Guidelines:   \n\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose assetis used.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] Justification: No such experiments. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 30}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] Justification: No human participants. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 30}]