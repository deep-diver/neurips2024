[{"figure_path": "DQD0DNRjxk/tables/tables_1_1.jpg", "caption": "Table 1: Comparison of 3DGS rendering and volume rendering methods.", "description": "This table compares two predominant approaches in 3D surface reconstruction: 3D Gaussian Splatting (3DGS) rendering and volume rendering.  It highlights the advantages and disadvantages of each method in terms of mathematical expression, rendering speed, memory consumption, and the quality of 3D surface representation.", "section": "1 Introduction"}, {"figure_path": "DQD0DNRjxk/tables/tables_7_1.jpg", "caption": "Table 2: Quantitative evaluation of novel view synthesis and surface reconstruction on the Waymo Open Scene dataset [32]. Using LiDAR data as ground truth, we calculated Chamfer Distance (C-D) values for reconstruction accuracy. Our method performs excellently in both novel view synthesis and surface reconstruction, outperforming other methods in Gaussian point usage, VRAM occupancy, and real-time rendering.", "description": "This table presents a quantitative comparison of different methods for novel view synthesis and surface reconstruction on the Waymo Open Scene dataset.  The metrics used include PSNR (peak signal-to-noise ratio), Chamfer Distance (a measure of geometric reconstruction error), memory usage (MB), GPU memory usage (GB), frames per second (FPS), and training time.  The results show that the proposed GVKF method outperforms existing state-of-the-art methods in terms of PSNR,  Chamfer Distance, memory and GPU usage and rendering speed.", "section": "4 Experiments"}, {"figure_path": "DQD0DNRjxk/tables/tables_8_1.jpg", "caption": "Table 3: Quantitative evaluation on the Tanks and Temples dataset [16] using F1 scores and training time as metrics. Our method outperforms all existing explicit methods in F1 scores and is comparable to implicit methods in reconstruction accuracy, with significantly reduced training time. These results highlight our method's efficiency and accuracy. Comparation of concurrent work GOF [44] is presented in Appendix A.4.", "description": "This table presents a quantitative comparison of different methods (both implicit and explicit) for 3D surface reconstruction on the Tanks and Temples dataset. The metrics used are F1 scores and training time. The results show that the proposed method outperforms existing explicit methods in terms of F1 scores and has comparable accuracy to implicit methods while significantly reducing training time.", "section": "4.2 Analysis"}, {"figure_path": "DQD0DNRjxk/tables/tables_8_2.jpg", "caption": "Table 7: Quantitative evaluation on the Mip-NeRF 360 [1]. All scene dataset is presented.", "description": "This table presents a quantitative comparison of different novel view synthesis methods on the Mip-NeRF 360 dataset.  The metrics used for comparison are PSNR (higher is better), SSIM (higher is better), and LPIPS (lower is better), providing a comprehensive assessment of the visual quality of the generated novel views.  The results are averaged across all scenes in the dataset.", "section": "4 Experiments"}, {"figure_path": "DQD0DNRjxk/tables/tables_9_1.jpg", "caption": "Table 6: Further ablation study on voxel Gaussian representation and SDF mapping. w/o voxel: We eliminate the using of MLPs and voxel grid, w/o sdf: we directly use linear assumption between opacity function and SDF function.", "description": "This table presents the results of an ablation study on the GVKF method.  The study investigates the impact of removing the voxel grid and the SDF mapping on the performance of the method, measured by PSNR, F1 score, memory usage, storage, training time and meshing time.  The results show that using both voxel grid and SDF mapping is beneficial for the performance of the method.", "section": "4.3 Ablation Study"}, {"figure_path": "DQD0DNRjxk/tables/tables_9_2.jpg", "caption": "Table 5: Influence of different voxel size.", "description": "This table presents the results of an ablation study on the effect of varying voxel grid sizes on the neural Gaussians.  It shows the initial number of voxels, the final number of voxels after training, the peak signal-to-noise ratio (PSNR), and the training time for different voxel sizes (1, 0.1, 0.01, and 0.001).  The data demonstrates the trade-off between training time and PSNR as the voxel size is reduced.", "section": "4 Experiments"}, {"figure_path": "DQD0DNRjxk/tables/tables_14_1.jpg", "caption": "Table 2: Quantitative evaluation of novel view synthesis and surface reconstruction on the Waymo Open Scene dataset [32]. Using LiDAR data as ground truth, we calculated Chamfer Distance (C-D) values for reconstruction accuracy. Our method performs excellently in both novel view synthesis and surface reconstruction, outperforming other methods in Gaussian point usage, VRAM occupancy, and real-time rendering.", "description": "This table presents a quantitative comparison of different methods for novel view synthesis and surface reconstruction using the Waymo Open Scene dataset.  The metrics used are PSNR (Peak Signal-to-Noise Ratio), Chamfer Distance (C-D), memory usage (MB), GPU memory usage (GB), Frames Per Second (FPS), and training time.  LiDAR data serves as the ground truth for evaluating reconstruction accuracy. The results demonstrate the superior performance of the proposed GVKF method in terms of PSNR, reduced Chamfer distance, lower memory consumption, higher FPS, and comparable training time.", "section": "4 Experiments"}, {"figure_path": "DQD0DNRjxk/tables/tables_16_1.jpg", "caption": "Table 8: NVS and storage comparation to GOF on Mip-NeRF 360 Dataset [1].", "description": "This table compares the performance of the proposed GVKF method with the GOF method on the Mip-NeRF 360 dataset in terms of novel view synthesis (NVS) quality and storage requirements.  The metrics used are PSNR (peak signal-to-noise ratio), SSIM (structural similarity index), LPIPS (learned perceptual image patch similarity), and storage size (in megabytes).  Higher PSNR and SSIM values indicate better image quality, while lower LPIPS values and smaller storage sizes represent improved performance.", "section": "4.2 Analysis"}, {"figure_path": "DQD0DNRjxk/tables/tables_16_2.jpg", "caption": "Table 3: Quantitative evaluation on the Tanks and Temples dataset [16] using F1 scores and training time as metrics. Our method outperforms all existing explicit methods in F1 scores and is comparable to implicit methods in reconstruction accuracy, with significantly reduced training time. These results highlight our method's efficiency and accuracy. Comparation of concurrent work GOF [44] is presented in Appendix A.4.", "description": "This table presents a quantitative comparison of the proposed GVKF method against several existing implicit and explicit methods for 3D surface reconstruction on the Tanks and Temples dataset.  The comparison focuses on F1 scores (a measure of reconstruction accuracy) and training time. The results show that GVKF outperforms explicit methods in terms of F1 score and is competitive with implicit methods while requiring significantly less training time.  A comparison to the concurrent work GOF [44] is available in the appendix.", "section": "4.2 Analysis"}]