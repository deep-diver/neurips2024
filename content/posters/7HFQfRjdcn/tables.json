[{"figure_path": "7HFQfRjdcn/tables/tables_7_1.jpg", "caption": "Table 1: Test RMSE for MLPs trained on 7 UCI benchmarks.", "description": "This table presents the test root mean squared error (RMSE) achieved by four different neural network parameterization methods (SP, WN, BN, and GmP) on seven regression datasets from the UCI machine learning repository.  Lower RMSE values indicate better performance.  The results show that GmP generally outperforms the other methods across most datasets.", "section": "4.2 Machine Learning Benchmarks"}, {"figure_path": "7HFQfRjdcn/tables/tables_8_1.jpg", "caption": "Table 2: Top-1 and top-5 validation accuracy (%) for VGG-6 trained on ImageNet32.", "description": "This table presents the Top-1 and Top-5 validation accuracy results for a VGG-6 model trained on the ImageNet32 dataset.  The results are broken down by different batch sizes (256, 512, and 1024) and different parameterization methods (SP, WN, WN+MBN, BN, GmP, and GmP+IMN).  The table allows for comparison of the performance of different parameterization techniques under varying batch sizes, highlighting potential differences in training stability and generalization.", "section": "4.2.2 ImageNet32 Classification with VGG"}, {"figure_path": "7HFQfRjdcn/tables/tables_8_2.jpg", "caption": "Table 3: Single-center-crop validation accuracy (%) for ResNet-18 trained on ImageNet (ILSVRC 2012).", "description": "This table presents the single-center-crop validation accuracy results for ResNet-18, a large residual neural network, trained on the full ImageNet dataset.  The results are categorized by three different parameterization methods: WN+MBN, BN, and GmP+IMN, showing the top-1 and top-5 validation accuracy for each.  The table highlights the superior performance of GmP+IMN, which demonstrates its effectiveness in large-scale residual network training.", "section": "4.2.3 ImageNet Classification with ResNet"}]