[{"figure_path": "YNRYWZHmKY/figures/figures_0_1.jpg", "caption": "Figure 1: Visualization of cross-attention maps when object mixture and missing occur.", "description": "This figure shows examples of image generation outputs from a text-to-image model when presented with prompts containing multiple objects.  The top row displays cross-attention maps which visualize the model's attention to different parts of the image during generation.  The bottom row shows the actual generated images.  The images illustrate two main issues:\n\n1. **Object Mixture:** The model blends features of different objects, creating a hybrid that doesn't accurately represent any of the objects in the prompt. For example, in the image with a lion and elephant prompt, a creature is generated that is part lion and part elephant. \n2. **Object Missing:** The model fails to generate one of the requested objects completely. For example, in the prompt with a chicken and a dog, the dog is missing from the generated image.  These issues highlight the challenges in accurately representing multiple objects during image generation when the model has to resolve the order in which they are named (a causal manner).", "section": "1 Introduction"}, {"figure_path": "YNRYWZHmKY/figures/figures_2_1.jpg", "caption": "Figure 2: Overview of the text-to-image generative model, including the details of the causal manner in attention mechanism. Because of the causal nature of the embedding, information is accumulated from the starting token through the end of the sequence, resulting in bias in the earlier token. To balance the critical information, we propose text embedding optimization for purifying the object token with equal weights within their corresponding embedding dimension.", "description": "This figure illustrates the architecture of a text-to-image diffusion model and highlights the causal manner in the text encoder's self-attention mechanism. The causal nature leads to information accumulation from the initial token to subsequent tokens, resulting in bias towards earlier tokens.  The figure shows how the input text is processed through a CLIP text encoder to generate text embeddings. These embeddings are then fed into a denoising UNet along with initial image noise to iteratively refine the generated image. A key part of the figure visualizes the causal self-attention mechanism showing how each token's embedding is influenced by the previous tokens.  The figure also introduces the proposed \"Text Embedding Balance Optimization (TEBOpt)\" as a method to mitigate this information bias by adjusting text embeddings for more balanced representation.", "section": "2 Preliminaries"}, {"figure_path": "YNRYWZHmKY/figures/figures_3_1.jpg", "caption": "Figure 3: Masking text embedding to identify the contribution of critical tokens, e.g., cat/dog, and special tokens, e.g., <sot>, <eot>, <pad>. The first row and the second row both contain cat and dog inside prompt but in different order. The analysis shows that special tokens contain general information about the given prompt. However, the cat/dog tokens carry more weight than the special tokens. In the last two columns, where one of the animal token embeddings is masked while retaining the special tokens' embedding, the generated image is predominantly influenced by the remaining animal's token embedding.", "description": "This figure shows the results of an experiment where different parts of the text embedding were masked to see how it affected the generated image.  The top row shows prompts where \"dog\" comes before \"cat\", and the bottom row shows the opposite. The first four columns show the full embedding, illustrating the bias towards the first-mentioned animal (a cat-dog mixture). The final two columns show the effect of masking either the cat or dog tokens, illustrating that the remaining token (and special tokens) strongly influences the generated image. This demonstrates the impact of causal masking in the text encoder.", "section": "3.1 Information bias in the text embedding"}, {"figure_path": "YNRYWZHmKY/figures/figures_6_1.jpg", "caption": "Figure 4: Qualitative comparison of all methods. Every prompt uses the same seed.", "description": "This figure shows a qualitative comparison of different text-to-image generation methods, including Stable Diffusion, Structure Diffusion, A&E, and SynGen, both with and without the proposed Text Embedding Balance Optimization (TEBOpt). Each row represents a different prompt, and each column shows the results of a different method. The prompts include pairs of objects, and the images generated show the effect of each method on the presence and mixture of those objects in the generated images. The overall visual comparison demonstrates the effectiveness of TEBOpt in reducing issues such as object mixtures and missing objects.", "section": "4.3 Qualitative results"}, {"figure_path": "YNRYWZHmKY/figures/figures_8_1.jpg", "caption": "Figure 6: (a) The cosine similarity of text embedding from single word. (b) The KL distance of cross-attention maps that are triggered by two words. The data is ordered by their text embedding similarity.", "description": "This figure shows two subfigures. Subfigure (a) is a heatmap showing the cosine similarity between different text embeddings (animal names). Warmer colors indicate higher similarity. Subfigure (b) is a bar chart showing the Kullback-Leibler (KL) distance between the cross-attention maps generated by pairs of words. The x-axis represents pairs of words, and the y-axis represents the KL distance. The words are ordered on the x-axis according to the cosine similarity of their embeddings shown in subfigure (a). This figure demonstrates that similar text embeddings lead to similar cross-attention maps, resulting in object mixture in the generated image.", "section": "3 Analysis and method"}, {"figure_path": "YNRYWZHmKY/figures/figures_12_1.jpg", "caption": "Figure 1: Visualization of cross-attention maps when object mixture and missing occur.", "description": "This figure shows examples of how the text embedding affects the generated images. The first image shows an ambiguous creature that blends features of both a lion and an elephant (object mixture). The second image shows an image where one of the objects is missing (object missing).", "section": "1 Introduction"}, {"figure_path": "YNRYWZHmKY/figures/figures_12_2.jpg", "caption": "Figure 1: Visualization of cross-attention maps when object mixture and missing occur.", "description": "This figure visually demonstrates the output of cross-attention maps in a text-to-image model when generating images with multiple objects.  The top row shows the prompt 'a lion and an elephant', resulting in an ambiguous creature that blends features of both. The bottom row shows the prompt 'a chicken and a dog', resulting in one object missing. This illustrates the problems of information bias and loss due to the causal nature of the self-attention mechanism in text encoders.", "section": "1 Introduction"}, {"figure_path": "YNRYWZHmKY/figures/figures_13_1.jpg", "caption": "Figure 1: Visualization of cross-attention maps when object mixture and missing occur.", "description": "The figure visualizes the cross-attention maps generated by a text-to-image diffusion model when presented with prompts containing multiple objects.  The top row shows the intended prompt \"a lion and an elephant.\" The model produces a cross-attention map exhibiting a mixture of both objects. The bottom row shows a prompt for \"a chicken and a dog.\" The resulting image has an object missing.  This illustrates the challenges of information loss and bias in text-to-image models that the paper seeks to address.", "section": "1 Introduction"}, {"figure_path": "YNRYWZHmKY/figures/figures_13_2.jpg", "caption": "Figure 1: Visualization of cross-attention maps when object mixture and missing occur.", "description": "This figure visualizes the cross-attention maps generated by a text-to-image model when the prompt contains multiple objects.  The first row shows a prompt with \"a lion and an elephant\", resulting in an image where the generated creature blends features of both. The second row shows a prompt with \"a chicken and a dog\", resulting in an image where one of the objects is missing entirely.  The figure highlights the issues of semantic interpretation and token embedding that lead to information mix-ups in text-to-image models.", "section": "1 Introduction"}, {"figure_path": "YNRYWZHmKY/figures/figures_16_1.jpg", "caption": "Figure 1: Visualization of cross-attention maps when object mixture and missing occur.", "description": "This figure visualizes the cross-attention maps generated by a text-to-image diffusion model when prompted with two objects.  The top row shows examples where the model generates a mixture of the two objects (e.g., a creature that blends features of a lion and an elephant). The bottom row shows examples of object missing, where only one of the requested objects is present in the generated image.", "section": "1 Introduction"}, {"figure_path": "YNRYWZHmKY/figures/figures_17_1.jpg", "caption": "Figure 2: Overview of the text-to-image generative model, including the details of the causal manner in attention mechanism. Because of the causal nature of the embedding, information is accumulated from the starting token through the end of the sequence, resulting in bias in the earlier token. To balance the critical information, we propose text embedding optimization for purifying the object token with equal weights within their corresponding embedding dimension.", "description": "This figure illustrates the architecture of a text-to-image generative model, focusing on the text encoder's causal manner and its impact on information accumulation and bias.  The causal manner, visualized in the lower part of the figure, shows that information from earlier tokens is propagated to subsequent tokens during self-attention calculations within the text encoder. This results in the first mentioned object having a stronger influence on the generated image. To address this issue, the authors propose a text embedding optimization technique to balance the information contribution of different tokens.", "section": "2 Preliminaries"}, {"figure_path": "YNRYWZHmKY/figures/figures_18_1.jpg", "caption": "Figure 2: Overview of the text-to-image generative model, including the details of the causal manner in attention mechanism. Because of the causal nature of the embedding, information is accumulated from the starting token through the end of the sequence, resulting in bias in the earlier token. To balance the critical information, we propose text embedding optimization for purifying the object token with equal weights within their corresponding embedding dimension.", "description": "This figure illustrates the text-to-image generation process, highlighting the causal manner in the text encoder's self-attention mechanism.  The causal nature of the embedding leads to information accumulation, biasing the model toward the first-mentioned object. The figure also introduces the proposed text embedding optimization (TEBOpt) method to address this bias by balancing the information from different tokens and equalizing the weights of their corresponding embeddings.", "section": "2 Preliminaries"}, {"figure_path": "YNRYWZHmKY/figures/figures_18_2.jpg", "caption": "Figure 1: Visualization of cross-attention maps when object mixture and missing occur.", "description": "This figure visually demonstrates the impact of the causal manner in text encoders on the generated images in text-to-image diffusion models.  It shows examples of \"object mixture\" (a single entity blending features from multiple objects described in the text prompt) and \"object missing\" (objects mentioned in the prompt failing to appear in the generated image). In the object mixture examples, the generated image is a blend of features from both a lion and an elephant, or a chicken and a dog. In the object missing examples, only one of the mentioned objects appears (a lion, or a chicken) while the other is absent.", "section": "1 Introduction"}, {"figure_path": "YNRYWZHmKY/figures/figures_19_1.jpg", "caption": "Figure 1: Visualization of cross-attention maps when object mixture and missing occur.", "description": "This figure visualizes the cross-attention maps generated by a text-to-image model for two different prompts: \"a lion and an elephant\" and \"a chicken and a dog\".  It demonstrates two common issues in text-to-image generation. In the case of \"a lion and an elephant\", an ambiguous creature blending features of both is generated (object mixture). In the case of \"a chicken and a dog\", one of the animals is missing entirely from the generated image (object missing).  The visualizations highlight how the model's attention mechanisms fail to accurately represent the objects specified in the prompt, leading to these problems.", "section": "1 Introduction"}]