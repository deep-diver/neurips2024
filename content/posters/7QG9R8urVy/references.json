{"references": [{"fullname_first_author": "Richard S. Sutton", "paper_title": "Reinforcement learning: An introduction", "publication_date": "2018", "reason": "It is a foundational textbook in reinforcement learning, providing the theoretical background and core concepts used throughout the field, including in offline reinforcement learning."}, {"fullname_first_author": "Scott Fujimoto", "paper_title": "Off-policy deep reinforcement learning without exploration", "publication_date": "2019-06-01", "reason": "This paper introduces a significant advancement in offline RL by addressing the exploration challenge, a major obstacle in applying RL to real-world problems with limited interaction."}, {"fullname_first_author": "Ilya Kostrikov", "paper_title": "Offline reinforcement learning with implicit Q-learning", "publication_date": "2022", "reason": "This work proposes a novel in-sample learning approach that is theoretically sound and empirically effective, offering a solution to overestimation issues in offline RL, a key problem tackled in the current paper."}, {"fullname_first_author": "Aviral Kumar", "paper_title": "Conservative Q-learning for offline reinforcement learning", "publication_date": "2020-12-01", "reason": "This work introduces a conservative approach to offline RL that addresses the problem of overestimation, a core challenge in offline RL and a focus of this paper's improvement."}, {"fullname_first_author": "Yi Ma", "paper_title": "Reining generalization in offline reinforcement learning via representation distinction", "publication_date": "2023", "reason": "This paper addresses the problem of generalization in offline RL, which is also a primary focus of the current paper, from the perspective of representation learning."}]}