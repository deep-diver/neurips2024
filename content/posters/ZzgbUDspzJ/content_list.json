[{"type": "text", "text": "Parameterized Approximation Schemes for Fair-Range Clustering ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zhen Zhang1,2, Xiaohong Chen1,2,\u2217, Limei ${\\bf L i u^{1,2}}$ , Jie Chen1,2, Junyu Huang3, Qilong Feng3,2\u2217 ", "page_idx": 0}, {"type": "text", "text": "1School of Advanced Interdisciplinary Studies, Hunan University of Technology and Business, Changsha 410205, China 2Xiangjiang Laboratory, Changsha 410205, China 3School of Computer Science and Engineering, Central South University, Changsha 410083, China zz@hutb.edu.cn, csu_cxh@163.com, seagullm@163.com, chemjay@hnu.edu.cn, junyuhuang@csu.edu.cn, csufeng@mail.csu.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Fair-range clustering extends classical clustering formulations by associating each data point with one or several demographic labels. It imposes lower and upper bound constraints on the number of opened facilities associated with each label, ensuring fair representation of all demographic groups by the opened facilities. In this paper we focus on the fair-range $k$ -median and $k$ -means problems in Euclidean spaces. We give $\\left(1+\\varepsilon\\right)$ -approximation algorithms with fixed-parameter tractable running times for both problems, parameterized by the numbers of opened facilities and demographic labels. For Euclidean metrics, these are the first parameterized approximation schemes for the problems, improving upon the previously known $O(1)$ -approximation ratios given by Thejaswi et al. (KDD 2022). ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Clustering is a common task in unsupervised learning, where we want to partition a given set of clients into disjoint cohesive clusters. Among the many formalizations of clustering, the $k$ -median and $k$ -means problems are perhaps the most prevalent ones, owing to the concise nature of their descriptions. Given a set of clients and facilities in a metric space along with a positive integer $k$ , the $k$ -median and $k$ -means problems aim to open at most $k$ facilities and connect each client to the nearest opened facility, such that the sum of the client-connection costs is minimized. In the $k$ -median problem, the connection cost of each client is its distance to the corresponding facility, while in the $k$ -means problem, it is the squared distance. Designing approximation algorithms for these problems remains a vibrant area of research. The current best approximation guarantees are the ratios of 2.613 [Gowda et al., 2023] for the $k$ -median problem and 9 [Ahmadian et al., 2020] for the $k$ -means problem. ", "page_idx": 0}, {"type": "text", "text": "In low-cost solutions to instances of the $k$ -median and $k$ -means problems, each opened facility is guaranteed to be close to the corresponding clients and can effectively serve as their representative points. This understanding underscores the important roles that the $k$ -median and $k$ -means problems play in data summarization [Moens et al., 1999, Girdhar and Dudek, 2012]. However, algorithms developed for these problems can often yield unfair summarization of socioeconomic data, as they prioritize minimizing the clustering costs over considering the distribution of demographic labels (e.g., gender, age, race) associated with the opened facilities [Kay et al., 2015]. Driven by this rationale, there has been considerable interest in fair-range clustering. Given a set of data points associated with demographic labels, fair-range clustering extends classical clustering formulations by imposing lower and upper bound constraints on the number of opened facilities associated with each label, thereby ensuring fairness across demographics. We can formally define the fair-range clustering problem as follows. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Definition 1 (fair-range clustering) An instance $(\\ell,k,\\mathcal{C},\\mathcal{F},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau)$ of the fair-range clustering problem is specified by positive integers $\\ell$ and $k$ , sets $\\mathcal{C}$ of clients and $\\mathcal{F}$ of facilities in a metric space, vectors $\\vec{\\alpha}=(\\alpha_{1},\\cdot\\cdot\\cdot,\\alpha_{\\ell})$ and $\\vec{\\beta}=(\\beta_{1},\\cdot\\cdot\\cdot,\\beta_{\\ell})$ of $\\ell$ positive integers satisfying $\\alpha_{t}\\leq\\beta_{t}$ for each $t\\in\\{1,\\cdot\\cdot\\cdot,\\ell\\}$ , and integer $\\rho\\geq1$ , where each $f\\in\\mathcal F$ is associated with a set $\\tau(f)\\subseteq\\{1,\\cdots\\,,\\ell\\}$ of demographic labels. A feasible solution to the instance is specified by a subset $\\mathcal{H}\\subseteq\\mathcal{F}$ of no more than $k$ facilities satisfying $|\\{f\\in\\mathcal{H}:t\\in\\tau(f)\\}|\\in[\\alpha_{t},\\beta_{t}]$ for each $t\\in\\{1,\\cdot\\cdot\\cdot\\,,\\ell\\}$ , and the cost of the solution is $\\begin{array}{r}{\\sum_{c\\in{\\mathcal{C}}}\\operatorname*{min}_{f\\in{\\mathcal{H}}}\\delta^{\\rho}(c,f)}\\end{array}$ , where $\\delta$ is the distance function. The goal of the fair-range clustering problem is to identify a feasible solution with minimum cost. We have $\\rho\\,=\\,1$ for the fair-range $k$ -median problem and $\\rho=2$ for the fair-range $k$ -means problem. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we focus on the fair-range $k$ -median (FkMed) and fair-range $k$ -means (FkMeans) problems. Despite their significance in applications requiring fair representations, the FkMed and FkMeans problems pose significantly greater computational challenges than classical clustering problems. As demonstrated by Thejaswi et al. [2021], designing polynomial-time algorithms with provable approximation guarantees for the FkMed and FkMeans problems is unlikely, as determining the existence of feasible solutions to their instances is NP-hard. For a simplified scenario where each facility is associated with a single demographic label, Thejaswi et al. [2021] showed that the FkMed and FkMeans problems can be reduced to the well known matroid clustering problem, which admits constant-factor approximation algorithms [Krishnaswamy et al., 2011, Li, 2011, Swamy, 2014, Friggstad and Zhang, 2016, Krishnaswamy et al., 2018], albeit with an $O(k)^{\\ell-1}$ multiplicative overhead in algorithmic running time. Hotegni et al. [2023] latter gave an improved reduction to the matroid clustering problem that eliminates the $O(k)^{\\ell-1}$ overhead. They further demonstrated that solving the FkMed and FkMeans problems in this simplified scenario can be achieved even more efficiently than solving matroid clustering problems, based on smaller-size linear programs. ", "page_idx": 1}, {"type": "text", "text": "In practical scenarios concerning clustering problems, the number of opened facilities (i.e., $k$ ) is often considerably smaller than the input size. Hence, assuming $k$ to be small and taking it as a fixed parameter is a commonly used way for simplifying these problems, as exemplified in [CohenAddad et al., 2019, Goyal and Jaiswal, 2023, Chen et al., 2024, Jaiswal et al., 2024]. Unfortunately, the FkMed and FkMeans problems have been demonstrated to remain challenging even with this simplification: When both $k$ and the number of demographic labels (i.e., $\\ell$ ) are fixed parameters, Thejaswi et al. [2022] established the W[2]-hardness of the FkMed and FkMeans problems, suggesting that exactly solving them in fixed-parameter tractable time (denoted as $\\mathrm{FPT}(k,\\ell)$ time, meaning $n^{O(1)}h(k,\\ell)$ for an input size of $n$ and a positive function $h$ ) is unlikely; Cohen-Addad et al. [2019] showed that the approximation ratios of $\\bar{\\mathrm{FPT}}(k,\\ell)$ -time algorithms, even for the case where $\\ell=1$ , cannot be better than $1+2e^{-1}$ for the FkMed problem and $\\bar{1}+8e^{-1}$ for the FkMeans problem. This matches the $\\mathrm{FPT}(k,\\ell)$ -time $(1+2e^{-1}+\\varepsilon)$ -approximation algorithm for the FkMed problem and $(1+8e^{-1}+\\varepsilon)$ -approximation algorithm for the FkMeans problem given by Thejaswi et al. [2022] for a simpler case considering only the lower bound constraint. Notably, the method for enumerating feasible constraint patterns given by Thejaswi et al. [2022] indicates that their algorithms can be effortlessly extended to accommodate the case involving both lower and upper bounds. ", "page_idx": 1}, {"type": "text", "text": "1.1 Our Results ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "The negative result presented by Thejaswi et al. [2022] suggests that we cannot hope to approximate the FkMeans problem with a ratio better than $1+8e^{-1}$ and the FkMed problem with a ratio better than $1+2e^{-\\dot{1}}$ in $\\mathrm{FPT}(k,\\ell)$ time. However, this does not exclude the possibility of achieving better approximations for these problems in the commonly encountered Euclidean spaces, as the negative result in Thejaswi et al. [2022] is derived within a general metric space. ", "page_idx": 1}, {"type": "text", "text": "Indeed, due to the prevalence of Euclidean data in real-world applications involving clustering, significant attention has been devoted to developing algorithms for related problems in Euclidean spaces. Specifically, it has been shown that the Euclidean $k$ -median and $k$ -means problems admit approximation schemes2 if $k$ is a fixed parameter and the opened facilities can be located arbitrarily within an Euclidean space [Kumar et al., 2010, Jaiswal et al., 2014, 2015, Bhattacharya et al., 2018, Ding and Xu, 2020]. These algorithms identify a subset of each client-cluster defined by an optimal solution and approximate the corresponding opened facility by the centroid of this subset. However, similar ideas are not applicable to the FkMed and FkMeans problems that involve finite sets of facilities and hard constraints on the labels of the opened facilities, since the centroids of the considered subsets are not guaranteed to be feasible as opened facilities. In this paper, we by-pass the centroid-based approach and take the first step towards exploring the properties of Euclidean metrics for the FkMed and FkMeans problems. This yields $\\mathrm{FPT}(k,\\ell)$ -time approximation schemes. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Theorem 1 Given an instance $(\\ell,k,\\mathcal{C},\\mathcal{F},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau)$ of fair-range clustering with $\\mathcal{C}\\cup\\mathcal{F}\\subset\\mathbb{R}^{d}$ and $\\rho\\,\\in\\,\\{1,2\\}$ along with a real number $\\varepsilon\\,\\in\\,(0,1)$ , there is a randomized $(1+\\varepsilon)$ -approximation algorithm running in $O(d\\log d)+2^{(k\\varepsilon^{-1})^{O(1)}+k\\ell}n^{O(1)}$ time, where $n=|{\\mathcal{C}}\\cup{\\mathcal{F}}|$ . ", "page_idx": 2}, {"type": "text", "text": "1.2 Other Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Constraints on the numbers of opened facilities associated with different labels were first introduced by Hajiaghayi et al. [2010, 2012], inspired by budget considerations for the deployment of servers in content distribution networks. From then on, related clustering problems have been widely explored. When we are provided with an upper bound constraint and each facility is associated with a single label, the problems represent special cases of the matroid clustering problems and directly motivate research into the latter [Krishnaswamy et al., 2011]. For the lower-bounded case, there are $\\mathrm{FPT}(k,\\ell)$ -time approximation algorithms for the $k$ -median and $k$ -means cost functions (given by Thejaswi et al. [2022], as previously mentioned), and a multi-swap local-search heuristic yields an $O(\\ell)$ -approximation for the $k$ -median cost function if each facility has a single label [Thejaswi et al., 2021, Zhang et al., 2024]. ", "page_idx": 2}, {"type": "text", "text": "In addition to the study of fair clustering problems that impose constraints on opened facilities, there has also been research focused on achieving group fairness through constraints on client-cluster assignments [Chierichetti et al., 2017, Bera et al., 2019, Bandyapadhyay et al., 2021, Dai et al., 2022, Wu et al., 2024]. Such group fairness constraints require that each cluster provides a fair representation of different demographic groups. ", "page_idx": 2}, {"type": "text", "text": "1.3 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "From now on we consider an instance $\\mathcal{T}=(\\ell,k,\\mathcal{C},\\mathcal{F},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau)$ of the fair-range clustering problem satisfying $\\rho\\in\\{1,2\\}$ , $|{\\mathcal{C}}\\cup{\\mathcal{F}}|=n$ , and $\\mathcal{C}\\cup\\mathcal{F}\\subset\\mathbb{R}^{d}$ , along with a constant $\\epsilon\\in(0,0.5)$ . Given an integer $i\\geq1$ and a set $\\mathcal{D}$ , define $[i]=\\{1,\\cdots\\,,i\\}$ , and let $[\\bar{D]}^{i}$ be the Cartesian product $\\mathcal{D}\\times\\cdot\\cdot\\times\\mathcal{D}$ . ", "page_idx": 2}, {"type": "text", "text": "Given a point $x$ and a set $\\mathcal{P}$ of points in an Euclidean space, let $\\begin{array}{r}{\\delta(x,\\mathcal{P})=\\operatorname*{min}_{p\\in\\mathcal{P}}||x-p||}\\end{array}$ denote the distance from $x$ to its nearest point in $\\mathcal{P}$ , and let $\\begin{array}{r}{\\delta^{i}(x,\\mathcal{P})=\\operatorname*{min}_{p\\in\\mathcal{P}}||x-\\bar{p}||^{i}}\\end{array}$ for each $i\\geq1$ . ", "page_idx": 2}, {"type": "text", "text": "The following algebraic fact will be used to analyze the running times of our algorithms. ", "page_idx": 2}, {"type": "text", "text": "Lemma 1 Given two real numbers s and $t$ greater than $^{\\,l}$ , we have $\\log^{t}s\\leq\\operatorname*{max}\\{s,t^{O(t)}\\}$ . ", "page_idx": 2}, {"type": "text", "text": "The following lemma extends triangle inequality3 to squared Euclidean metrics. ", "page_idx": 2}, {"type": "text", "text": "Lemma 2 Given three points $x$ , $y$ , and $z$ in an Euclidean space and a real number $\\gamma\\in(0,1]$ , we have $||x-z||^{2}\\leq(1+\\dot{\\gamma}^{-1})||x-y||^{2}+(1+\\gamma)||y-z||^{2}$ . ", "page_idx": 2}, {"type": "text", "text": "We will also consider the weighted version of the fair-range clustering problem, which can be defined as follows. ", "page_idx": 2}, {"type": "text", "text": "Definition 2 (weighted fair-range clustering) An instance $(\\ell,k,\\mathcal{C},\\mathcal{F},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau)$ of the fair-range clustering problem can be extended to its weighted version $(\\ell,k,\\mathcal{C},\\mathcal{F},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau,w)$ by associating each client $c\\in{\\mathcal{C}}$ with a weight $w(c)\\geq1$ . This extension changes the cost of a feasible solution $\\mathcal{H}\\subseteq\\mathcal{F}$ to $\\begin{array}{r}{\\sum_{c\\in{\\mathcal{C}}}w(c)\\operatorname*{min}_{f\\in{\\mathcal{H}}}\\delta^{\\rho}(c,f)}\\end{array}$ . ", "page_idx": 2}, {"type": "image", "img_path": "ZzgbUDspzJ/tmp/b93061edb35c867d7a78d65e4f6f9169967be9dfe697a768218916878540b73f.jpg", "img_caption": ["Figure 1: $(a)$ The client nearest to the opened facility $f^{*}$ is taken as the leader, around which an annular search space is constructed; $(b)$ the center point $f$ is opened in our solution. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "2 An Overview of Our Algorithms ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The $\\mathrm{FPT}(k,\\ell)$ -time approximation algorithms for the FkMed and FkMeans problems given by Thejaswi et al. [2022] follow the framework outlined in [Cohen-Addad et al., 2019]. This framework identifies the nearest client to each facility opened in the considered optimal solution as a \u201cleader\u201d and introduces a set of annuli centered at each leader. Each annulus is defined such that its outer radius is $1+\\varepsilon$ times its inner radius. The framework then enumerates the annuli to identify those that contain the facilities corresponding to the leaders and selects the opened facilities within these annuli, as illustrated in Figure $\\operatorname{l}-(a)$ . Intuitively, the definition of the annuli and triangle inequality imply an upper bound on the distances from the selected facilities to the optimal ones. Building upon this insight, Thejaswi et al. [2022] utilized a submodular maximization method to select facilities to be opened within the annuli and demonstrated constant-factor approximation ratios. ", "page_idx": 3}, {"type": "text", "text": "We similarly base our algorithms on the framework proposed by Cohen-Addad et al. [2019]. Our approach focuses on exploring the properties of Euclidean metrics to further refine the selection range of opened facilities. Specifically, we partition each annulus into a set of smaller cells; for each facility opened in the optimal solution, we take the center point of the cell containing it as the facility to be opened, as shown in Figure $\\left1\\!-\\!\\left(b\\right)$ . This process involves carefully balancing the number of cells, which affects the time required to identify the desired cells, against the sizes of the cells, which influence the distance from each facility opened in the optimal solution to the center point of the cell containing it, as well as our approximation ratio. We achieve this trade-off by constructing nets as defined below. ", "page_idx": 3}, {"type": "text", "text": "Definition 3 ( $\\gamma$ -net [Gupta et al., 2003]) Given a density parameter $\\gamma>0$ , a set $\\mathcal{P}\\subset\\mathbb{R}^{d}$ , and $a$ subset $\\mathcal{R}\\subseteq\\mathcal{P}$ , we call $\\mathcal{R}$ a $\\gamma$ -net of $\\mathcal{P}$ if each $p\\in\\mathcal{R}$ satisfies $\\delta(p,\\mathcal{R}\\backslash\\{p\\})\\geq\\gamma$ and each $p\\in\\mathcal{P}$ satisfies \u03b4(p, R) \u2264\u03b3. ", "page_idx": 3}, {"type": "text", "text": "We partition the annular search space into cells using a set of nets for the facilities. The trade-off between the number and sizes of the cells can be managed by adjusting the density parameters (i.e., the parameter $\\lambda$ in Definition 3). For each annulus centered around a leader and containing its corresponding facility (the one opened in the optimal solution), we estimate the demographic labels associated with this facility and identify the subset of facilities within the annulus that share these labels. A net is then constructed for this subset, using a density parameter carefully determined by the radius of the annulus. Given the Voronoi diagram defined by the net, Definition 3 suggests that the facility opened in the optimal solution is close to the center point of its corresponding Voronoi cell. By considering each member of all constructed nets as a candidate for an opened facility, we can ensure that the candidate set includes a subset closely approximating the optimal solution. ", "page_idx": 3}, {"type": "text", "text": "It remains to consider how to bound the running time within $\\mathrm{FPT}(k,\\ell)$ time. The algorithms given by Cohen-Addad et al. [2019] and Thejaswi et al. [2022] start with constructing a coreset, that is, a small weighted subset of the client set whose distribution closely approximates that of the full set. This facilitates the efficient identification of leaders by enumerating the coreset. In this paper, we face additional challenges in bounding the running time. For example, when partitioning the annuli into cells, the number of cells can depend exponentially on the spatial dimension. To ensure that we can deal with the FkMed and FkMeans problems in high-dimensional Euclidean spaces within $\\mathrm{FPT}(k,\\ell)$ time, we map the considered instance to a space of $O(\\log k\\!+\\!\\log\\log n)$ dimensions using a combination of the method for constructing coresets given by Chen [2009] and Johnson-Lindenstrauss transform. Combining this data-reduction technique with our net-based approach for selecting opened facilities, we give $\\mathrm{FPT}(k,\\ell)$ -time $(1+\\varepsilon)$ -approximation algorithms for the FkMed and FkMeans problems. ", "page_idx": 3}, {"type": "image", "img_path": "ZzgbUDspzJ/tmp/ad51e6b9906eb82ed2fc6ee3b615d4cb529f7c6d77b5d155b934e43fa737c4e3.jpg", "img_caption": ["Figure 2: Given a set $\\mathcal{C}\\subset\\mathbb{R}^{d}$ of clients, Algorithm 1 first maps it to $\\mathbb{R}^{d^{\\dagger}}$ using mapping $\\varphi_{1}:\\mathbb{R}^{d}\\rightarrow$ $\\mathbb{R}^{d^{\\dagger}}$ , and next constructs a coreset $\\mathcal{C}^{\\dagger}$ for $\\{\\varphi_{1}(c):c\\in\\mathcal{C}\\}$ . Finally, the algorithm maps $\\mathcal{C}^{\\dagger}$ to $\\mathbb{R}^{\\tilde{d}}$ using mapping $\\varphi_{2}:\\mathbb{R}^{d^{\\dagger}}\\rightarrow\\mathbb{R}^{\\tilde{d}}$ . "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "3 The Algorithms ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We now present our algorithms for the FkMed and FkMeans problems. In Section 3.1 we introduce our data-reduction method for decreasing the size of the considered instance. In Section 3.2 we construct annular search spaces for the facilities to be opened, using the leaders from the client set. Section 3.3 details the construction of nets for the facilities, based on which we provide approximation schemes in low-dimensional spaces. Finally, in Section 3.4, we show how to combine the data-reduction method with the algorithms designed for low-dimensional spaces to deal with high-dimensional instances of the FkMed and FkMeans problems. ", "page_idx": 4}, {"type": "text", "text": "3.1 Data Reduction ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section we map instance $\\mathcal{T}$ to a smaller weighted instance in a low-dimensional space. As mentioned in Section 2, we achieve this using the coreset-construction method given by Chen [2009] and Johnson\u2013Lindenstrauss transform, which are detailed in the following two lemmata. ", "page_idx": 4}, {"type": "text", "text": "Lemma 3 (Chen [2009]) Given a constant $\\epsilon\\;\\in\\;(0,0.5)$ , a set $\\mathcal{P}\\subset\\mathbb{R}^{d}$ , an integer $t\\,>\\,0$ , and an integer $\\rho\\,\\in\\,\\{1,2\\}$ , a subset $\\mathcal{P}^{\\dagger}\\subseteq\\mathcal{P}$ with a weight function $w:\\mathcal{P}^{\\dagger}\\,\\rightarrow\\,[1,+\\infty)$ satisfying $|\\mathcal{P}^{\\dagger}|\\leq d(t\\varepsilon^{-1}\\log|\\mathcal{P}|)^{O(1)}$ and $\\textstyle\\sum_{p\\in{\\mathcal{P}}^{\\dagger}}w(p)=|{\\mathcal{P}}|$ can be constructed in $O(|\\mathcal{P}|d t)$ time, such that each $\\mathcal{H}\\subset\\mathbb{R}^{d}$ with $\\vert\\mathcal{H}\\vert\\leq t$ satisfies $\\begin{array}{r}{\\sum_{p\\in\\mathcal{P}^{\\dagger}}w(p)\\delta^{\\rho}(p,\\mathcal{H})\\in[1-\\epsilon,1+\\epsilon]\\sum_{p\\in\\mathcal{P}}\\delta^{\\rho}(p,\\mathcal{H})}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "Lemma 4 (Johnson and Lindenstrauss [1984], Ailon and Chazelle [2009]) Given a constant $\\epsilon\\in$ $(0,0.5)$ and a set $\\mathcal{P}\\subset\\mathbb{R}^{d}$ , we can construct a mapping $\\varphi:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{\\tilde{d}}$ satisfying $\\tilde{d}={\\cal O}(\\epsilon^{-2}\\log|\\mathcal{P}|)$ and $||\\varphi(p_{1})-\\varphi(p_{2})||\\in[1,1+\\epsilon]||p_{1}-p_{2}||$ for each $p_{1},p_{2}\\in\\mathcal{P}$ in $O(d\\log d)+(\\epsilon^{-1}\\log|\\mathcal{P}|)^{O(1)}$ time. ", "page_idx": 4}, {"type": "text", "text": "The following lemma is a stronger version of Johnson\u2013Lindenstrauss transform, which preserves distances over a broader range through terminal embedding. Specifically, it modifies the condition \u201cfor each $p_{1},p_{2}\\in\\mathcal{P}^{\\ast}$ in Lemma 4 to \u201cfor each $p_{1}\\in\\mathcal{P}$ and $\\bar{p}_{2}\\in\\mathbb{R}^{d,\\bullet}$ . ", "page_idx": 4}, {"type": "text", "text": "Lemma 5 (Narayanan and Nelson [2019]) Given a constant $\\epsilon\\,\\in\\,(0,0.5)$ and a set $\\mathcal{P}\\subset\\mathbb{R}^{d}$ , we can construct a mapping $\\varphi:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{\\tilde{d}}$ satisfying $\\tilde{d}={\\cal O}(\\epsilon^{-2}\\log|\\mathcal{P}|)$ and $||\\varphi(p_{1})-\\varphi(p_{2})||\\,\\in$ $[1,1+\\epsilon]||p_{1}-p_{2}||$ for each $p_{1}\\in\\mathcal{P}$ and $p_{2}\\in\\mathbb{R}^{d}$ in $(|\\mathcal{P}|d)^{O(1)}$ time. ", "page_idx": 4}, {"type": "text", "text": "It can be assumed that each mapping $\\varphi:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{\\tilde{d}}$ constructed by Lemma 4 and Lemma 5 is injective. Such an assumption is made without loss of generality: We can create duplicates of the points in $\\mathbb{R}^{\\tilde{d}}$ that have multiple preimages under $\\varphi$ . This ensures that we can always differentiate $\\varphi(x)$ and $\\varphi(y)$ for any two distinct points $x$ and $y$ in $\\mathbb{R}^{d}$ , even if $\\varphi(x)$ and $\\varphi(y)$ have identical values across all dimensions. Distinguishing the images of the points from $\\mathbb{R}^{d}$ is essential in fair-range clustering problems because points with the same dimensional values can have different demographic labels. ", "page_idx": 4}, {"type": "text", "text": "Input: A constant $\\epsilon\\in(0,0.5)$ and an instance $(\\ell,k,\\mathcal{C},\\mathcal{F},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau)$ of the fair-range clustering problem satisfying $\\rho\\in\\{1,2\\}$ and $\\mathcal{C}\\cup\\mathcal{F}\\subset\\mathbb{R}^{d}$ ", "page_idx": 5}, {"type": "text", "text": "Output: A mapping $\\varphi:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{\\tilde{d}}$ and an instance $(\\ell,k,\\tilde{\\mathcal{C}},\\tilde{\\mathcal{F}},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau,w)$ of the weighted fair-range clustering problem satisfying $\\tilde{\\mathcal{C}}\\cup\\tilde{\\mathcal{F}}\\subset\\mathbb{R}^{\\tilde{d}}$ , $\\tilde{\\mathcal{F}}=\\{\\varphi(f):f\\in\\mathcal{F}\\}$ , and $\\tau(\\varphi(f)\\bar{)}=\\tau(f)$ for each $f\\in\\mathcal F$ ", "page_idx": 5}, {"type": "text", "text": "1 Let $\\varphi_{1}:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{d^{\\dagger}}$ be the mapping constructed by Lemma 4 with $(\\epsilon,{\\mathcal{C}}\\cup{\\mathcal{F}})$ as the input;   \n2 Let $\\mathcal{C}^{\\dagger}$ be the weighted set constructed by Lemma 3 with $(\\epsilon,\\{\\varphi_{1}(c):c\\in\\mathcal{C}\\},k,\\rho)$ as the input,   \nand let $w^{\\dagger}:{\\mathcal{C}}^{\\dagger}\\rightarrow[1,+\\infty)$ be the corresponding weight function;   \n3 Let $\\varphi_{2}:\\mathbb{R}^{d^{\\dagger}}\\rightarrow\\mathbb{R}^{\\tilde{d}}$ be the mapping constructed by Lemma 5 with $(\\epsilon,\\mathcal{C}^{\\dagger})$ as the input;   \n4 $\\varphi\\Leftarrow\\varphi_{2}\\circ\\varphi_{1}$ , $\\tilde{\\mathcal{C}}\\Leftarrow\\{\\varphi_{2}(c):c\\in\\mathcal{C}^{\\dagger}\\}$ , $\\tilde{\\mathcal{F}}\\Leftarrow\\{\\varphi(f):f\\in\\mathcal{F}\\}$ ;   \n5 return $\\varphi:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{\\tilde{d}}$ , $(\\ell,k,\\tilde{\\mathcal{C}},\\tilde{\\mathcal{F}},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau\\circ\\varphi^{-1},w^{\\dag}\\circ\\varphi_{2}^{-1}).$ ", "page_idx": 5}, {"type": "text", "text": "Our data-reduction method, which combines Lemma 3, Lemma 4, and Lemma 5, is presented in Algorithm 1 and illustrated in Figure 2 (this figure describes the processing flow of the clients). This algorithm first leverages Lemma 3 within the ${\\cal O}(\\log n)$ -dimensional space constructed by Lemma 4, such that the client set can be replaced with a coreset of size logarithmically dependent on $n$ and independent of $d$ . Next, to reduce dimensions while preserving the distances between any client in the coreset and any facility, Algorithm 1 uses Lemma 5 with the coreset as input to construct an $O(\\log k+\\log\\log\\dot{n})$ -dimensional space. The following lemma provides the performance guarantees of Algorithm 1. ", "page_idx": 5}, {"type": "text", "text": "Lemma 6 Given a constant $\\epsilon\\,\\in\\,(0,0.5)$ and an instance $(\\ell,k,\\mathcal{C},\\mathcal{F},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau)$ of the fair-range clustering problem with $\\rho\\in\\{1,2\\}$ , $|{\\mathcal{C}}\\cup{\\mathcal{F}}|=n$ , and $\\mathcal{C}\\cup\\mathcal{F}\\subset\\mathbb{R}^{d}$ , Algorithm 1 constructs a mapping $\\varphi:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{\\tilde{d}}$ and an instance $(\\ell,k,\\tilde{\\mathcal{C}},\\tilde{\\mathcal{F}},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau,w)$ of the weighted fair-range clustering problem in $O(d\\log d)+(n k\\epsilon^{-1})^{O(1)}$ time, which satisfy the following properties: ", "page_idx": 5}, {"type": "text", "text": "(i) $\\begin{array}{r}{\\sum_{c\\in\\tilde{c}}w(c)=|\\mathcal{C}|,}\\end{array}$   \n(ii) $w(c)\\geq1$ for each $c\\in\\tilde{\\mathcal{C}}$ ,   \n(iii) $|\\tilde{c}|\\leq(k\\epsilon^{-1}\\log n)^{O(1)}$ ,   \n(iv) $\\tilde{d}=\\epsilon^{-O(1)}(\\log k+\\log\\log n)$ , and   \n(v) $\\begin{array}{r}{\\sum_{c\\in\\widetilde{C}}w(c)\\delta^{\\rho}(c,\\{\\varphi(f)\\,:\\,f\\,\\in\\,\\mathcal{H}\\})\\,\\in\\,[1-\\epsilon,(1+\\epsilon)^{2\\rho+1}]\\sum_{c\\in\\mathcal{C}}\\delta^{\\rho}(c,\\mathcal{H})}\\end{array}$ for each $\\mathcal{H}\\subseteq\\mathcal{F}$ with $|\\mathcal{H}|\\leq k$ . ", "page_idx": 5}, {"type": "text", "text": "3.2 The Annular Search Spaces ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section we construct $k$ annular search spaces, each corresponding to one of the $k$ facilities to be opened. We first introduce some notations. Let $\\varphi:\\mathbb{R}^{d}\\,\\rightarrow\\,\\mathbb{R}^{\\tilde{d}}$ be the mapping and $\\tilde{\\mathcal{I}}=$ $(\\ell,k,\\tilde{\\mathcal{C}},\\tilde{\\mathcal{F}},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau,w)$ be the weighted instance constructed by Algorithm 1 with $(\\epsilon,\\mathcal{T})$ as the input, where $\\tilde{\\mathcal{C}}\\cup\\tilde{\\mathcal{F}}\\subset\\mathbb{R}^{\\tilde{d}}$ , $\\tilde{\\mathcal{F}}=\\,\\{\\varphi(f)\\,:\\,f\\,\\in\\,\\mathcal{F}\\}$ , and $\\tau(\\varphi(f))\\,=\\,\\tau(f)$ for each $f\\,\\in\\,{\\mathcal{F}}$ . Let $\\tilde{\\mathcal{H}}^{*}\\,=\\,\\{f_{1}^{*},\\cdot\\cdot\\cdot\\,,f_{k}^{*}\\}$ be an optimal solution to $\\tilde{\\mathcal{Z}}$ , and let $\\begin{array}{r}{o p t\\,=\\,\\sum_{c\\in\\tilde{\\mathcal{C}}}w(c)\\delta^{\\rho}(c,\\tilde{\\mathcal{H}}^{*})}\\end{array}$ denote its cost. For each $i\\in[k]$ , let $\\mathcal{L}_{i}\\,=\\,\\{f\\,\\in\\,\\tilde{\\mathcal{F}}\\,:\\,\\tau(f)\\,=\\,\\tau(f_{i}^{*})\\}$ denote the set of facilities that have the same demographic labels as $f_{i}^{*}$ , and let $\\tilde{\\mathcal{C}}_{i}^{*}\\;=\\;\\{c\\,\\in\\;\\tilde{\\mathcal{C}}\\,:\\,\\arg\\operatorname*{min}_{f\\in\\tilde{\\mathcal{H}}^{*}}\\,||f\\,-\\,c||^{\\rho}\\,=\\,f_{i}^{*}\\}$ be the cluster of clients defined by $f_{i}^{*}$ . Given the lower-bound constraint on the number of opened facilities, it may be the case that some facilities in $\\tilde{\\mathcal{H}}^{*}$ correspond to an empty cluster. We thus define $\\tilde{\\mathcal{H}}_{0}^{*}=\\{f\\in\\tilde{\\mathcal{H}}^{*}:\\tilde{\\mathcal{C}}_{i}^{*}=\\varnothing\\}$ and $\\tilde{\\mathcal{H}}_{1}^{*}=\\tilde{\\mathcal{H}}^{*}\\backslash\\tilde{\\mathcal{H}}_{0}^{*}$ . Let $k^{*}=|\\tilde{\\mathcal{H}}_{1}^{*}|$ . Without loss of generality, we can assume that $\\tilde{\\mathcal{H}}_{1}^{*}=\\{c_{1},\\cdots,c_{k^{*}}\\}$ . Let $\\begin{array}{r}{\\delta_{\\mathrm{max}}^{\\rho}=\\operatorname*{max}_{c\\in\\tilde{\\mathcal{C}}}\\delta^{\\rho}(c,\\tilde{\\mathcal{H}}_{1}^{*})}\\end{array}$ . We have ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\delta_{\\operatorname*{max}}^{\\rho}\\leq\\operatorname*{max}_{c\\in\\mathcal{\\tilde{C}}}w(c)\\delta^{\\rho}(c,\\tilde{\\mathcal{H}}_{1}^{*})\\leq\\sum_{c\\in\\mathcal{\\tilde{C}}}w(c)\\delta^{\\rho}(c,\\tilde{\\mathcal{H}}_{1}^{*})=\\sum_{c\\in\\mathcal{\\tilde{C}}}w(c)\\delta^{\\rho}(c,\\tilde{\\mathcal{H}}^{*})=o p t,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Input: A constant $\\epsilon\\in(0,0.5)$ , an instance $\\tilde{\\mathcal{Z}}=(\\ell,k,\\tilde{\\mathcal{C}},\\tilde{\\mathcal{F}},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau,w)$ of the weighted fair-range clustering problem, and a positive integer $n$ ", "page_idx": 6}, {"type": "image", "img_path": "ZzgbUDspzJ/tmp/2b7650f24d020f9d367f622112b90a4b60cc10a38016be77d096d6265865c736.jpg", "img_caption": [], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "where the first step is due to the fact that $w(c)\\geq1$ for each $c\\in\\tilde{\\mathcal{C}}$ (due to Lemma 6), and the third step follows from the definition of $\\tilde{\\mathcal{H}}_{1}^{*}$ . ", "page_idx": 6}, {"type": "text", "text": "Following the framework given by Cohen-Addad et al. [2019], we select opened facilities from a set of annuli centered around a group of leaders from $\\tilde{\\mathcal{C}}$ . For each $i\\in[k^{*}]$ , let $c_{i}$ denote the client from $\\tilde{\\mathcal{C}}$ nearest to $f_{i}^{*}$ , that is, the leader corresponding to $f_{i}^{*}$ . The definitions of $c_{i}$ and $\\delta_{\\mathrm{max}}^{\\rho}$ imply that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{i\\in[k^{*}]}||c_{i}-f_{i}^{*}||^{\\rho}\\leq\\delta_{\\operatorname*{max}}^{\\rho}<\\frac{1}{n}\\epsilon(1+\\epsilon)^{\\lceil\\epsilon^{-2}\\log n\\rceil}\\delta_{\\operatorname*{max}}^{\\rho}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Given a leader $c_{i}$ , inequality (2) provides an upper bound on its distance to $f_{i}^{*}$ , according to which we can define the maximum radius of the annular search spaces centered around the leaders. For each $i\\in[k^{*}]$ and $j\\in[\\lceil\\epsilon^{-2}\\log n\\rceil]$ , let $A^{*}(i,j)=\\{f\\in\\mathcal{L}_{i}:||f-c_{i}||^{\\rho}\\in(\\epsilon(1+\\epsilon)^{j-1}\\delta_{\\operatorname*{max}}^{\\rho}n^{-1},\\epsilon(1+$ $\\epsilon)^{j}\\delta_{\\mathrm{max}}^{\\bar{\\rho}}n^{-1}]\\}$ be the set of facilities from $\\mathcal{L}_{i}$ located in an annulus centered around $c_{i}$ , and let $\\bar{\\mathcal{A}}^{\\ast}(\\overrightharpoon{i,0})=\\bar{\\{f\\in\\mathcal{L}_{i}:||f-c_{i}||^{\\rho}\\leq\\epsilon\\delta_{\\operatorname*{max}}^{\\rho}n^{-1}\\}}$ . The definition of $A^{*}(i,j)$ and inequality (2) imply the existence of an integer $j\\in\\{0,\\cdots,\\lceil\\epsilon^{-2}\\log n\\rceil\\}$ satisfying $f_{i}^{*}\\in\\mathcal{A}^{*}(i,j)$ . Denote by $A_{i}^{*}$ such a set $A^{*}(i,j)$ containing $f_{i}^{*}$ . ", "page_idx": 6}, {"type": "text", "text": "Our method for constructing annular search spaces is presented in Algorithm 2. Since the collection $\\{\\mathcal{A}^{*}(1,0),\\cdots,\\mathcal{A}^{*}(k^{*},\\lceil\\epsilon^{-\\tilde{2}}\\log n\\rceil)\\}$ can be determined based on the values of $\\{\\mathcal{L}_{1},\\cdot\\cdot\\cdot,\\mathcal{L}_{k}\\},k^{*}$ , $\\delta_{\\mathrm{max}}^{\\rho}$ , and $\\{c_{1},\\cdot\\cdot\\cdot,c_{k^{*}}\\}$ , Algorithm 2 enumerates all possible values of these parameters in steps 3 and 6 to ensure that the collection can be captured. Given an integer $i\\;\\in\\;[k^{*}]$ and the sets $A^{*}(i,0),\\cdot\\cdot\\cdot\\,,\\mathcal{A}^{*}(i,\\lceil\\epsilon^{-2}\\log n\\rceil)$ , Algorithm 2 enumerates $[\\lceil\\epsilon^{-2}\\log n\\rceil]\\cup\\{0\\}$ in step 10 to find the integer $j$ with $\\mathcal{A}_{i}^{*}=\\mathcal{A}^{*}(i,j)$ . To avoid the case where the search spaces for the $k$ opened facilities intersect and the set of selected facilities contains duplicate elements, Algorithm 2 employs a colorcoding technique in steps 11-19 to eliminate any potential intersections. Specifically, Algorithm 2 associates each facility $f\\in\\tilde{\\mathcal F}$ with a random integer $\\eta(f)\\in[k]$ in step 12, and only selects facilities ", "page_idx": 6}, {"type": "text", "text": "Input: A constant $\\epsilon\\in(0,0.5)$ , an instance $\\tilde{\\mathcal{Z}}=(\\ell,k,\\tilde{\\mathcal{C}},\\tilde{\\mathcal{F}},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau,w)$ of the weighted fair-range clustering problem, and a positive integer $n$ ", "page_idx": 7}, {"type": "text", "text": "Output: A solution $\\mathcal{H}^{\\dagger}$ to $\\bar{\\mathcal{I}}$ ", "page_idx": 7}, {"type": "text", "text": "1 $\\mathbb{A}\\Leftarrow\\emptyset$ , $\\mathbb{H}\\Leftarrow\\emptyset$ ;   \n2 for each $s\\in[k^{k}]$ do   \n3 Let $\\mathbb{A}^{\\prime}$ be the collection constructed by Algorithm 2 with $(\\epsilon,\\tilde{\\mathcal{Z}},n)$ as the input;   \n4 $\\mathbb{A}\\Leftarrow\\mathbb{A}\\cup\\mathbb{A}^{\\prime}$   \n5 for each $\\{\\mathcal{A}_{1},\\cdots,\\mathcal{A}_{k}\\}\\in\\mathbb{A}$ with $A_{i}\\neq\\varnothing\\,\\forall\\,i\\in[k]$ do   \n6 Let ${\\mathcal{H}}=\\left\\{f_{1},\\cdot\\cdot\\cdot,f_{k}\\right\\}$ be an arbitrary set with $f_{i}\\in A_{i}$ for each $i\\in[k]$ ;   \n7 if $|\\{f\\in\\mathcal{H}:t\\in\\tau(f)\\}|\\in[\\alpha_{t},\\beta_{t}]$ for each $i\\in[k]$ then   \n8 for each $i\\in[k]$ do   \n9 if $|{\\mathcal{A}}_{i}|=\\mathrm{1}$ then   \n10 $\\ L\\ {\\mathcal{S}}_{i}\\Leftarrow A_{i}$ ;   \n11 else   \n12 Let $\\mathcal{S}_{i}$ be the $\\mathrm{max}_{x,y\\in A_{i}}\\,\\epsilon||x-y||$ -net of $A_{i}$ constructed by Lemma 8;   \n13 Let $\\mathbb{H}^{\\prime}$ be the collection constructed by transforming each tuple in $S_{1}\\times S_{2}\\times\\cdots\\times S_{k}$   \ninto a set;   \n14 $\\mathbb{H}\\Leftarrow\\mathbb{H}\\cup\\mathbb{H}^{\\prime}$ ;   \n15 return $\\begin{array}{r}{\\mathcal{H}^{\\dagger}\\Leftarrow\\arg\\operatorname*{min}_{\\mathcal{H}\\in\\mathbb{H}}\\sum_{c\\in\\tilde{c}}w(c)\\delta^{\\rho}(c,\\mathcal{H}).}\\end{array}$ ", "page_idx": 7}, {"type": "text", "text": "with $\\eta(f)\\;=\\;i$ when construct the $i$ -th search space for each $i~\\in~[k]$ in steps 14 and 17. The performance guarantees of this algorithm are presented in the following lemma. ", "page_idx": 7}, {"type": "text", "text": "Lemma 7 The following event occurs with a probability of no less than $k^{-k}$ : The collection A constructed by Algorithm 2 has an element $\\{\\mathcal{A}_{1},\\cdot\\cdot\\cdot,\\mathcal{A}_{k}\\}$ satisfying ${\\mathcal{A}}_{i}\\subseteq{\\mathcal{L}}_{i}$ and $|\\mathcal{A}_{i}|=1$ for each $i\\in[k]\\backslash[k^{*}]$ , $f_{i}^{*}\\in\\mathcal{A}_{i}\\subseteq\\mathcal{A}_{i}^{*}$ for each $i\\in[k^{*}]$ , and $\\bigcap_{i=1}^{k}{\\mathcal{A}}_{i}=\\emptyset$ . ", "page_idx": 7}, {"type": "text", "text": "3.3 The Algorithm in Low-Dimensional Spaces ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "As described in Section 2, we construct candidate solutions based on nets for the facilities. The following lemma states that we can construct small nets in near-linear time for sets located in a low-dimensional Euclidean space. ", "page_idx": 7}, {"type": "text", "text": "Lemma 8 (Har-Peled and Mendel [2006]) Given a density parameter $\\gamma>0$ and a set $\\mathcal{P}\\subset\\mathbb{R}^{d}$ , $a\\ \\gamma$ -net of $\\mathcal{P}$ of size at most $\\scriptstyle\\operatorname*{min}\\{|{\\mathcal{P}}|,\\gamma^{-d}\\operatorname*{max}_{p_{1},p_{2}\\in{\\mathcal{P}}}||{\\widehat{p}}_{1}\\ -\\ p_{2}||^{d}\\}$ can be constructed in $|{\\mathcal{P}}|\\log|{\\mathcal{P}}|2^{O(d)}$ time. ", "page_idx": 7}, {"type": "text", "text": "Our approach for solving the low-dimensional weighted instance $\\tilde{\\mathcal{I}}$ is built upon Algorithm 2 and Lemma 8, which is described in Algorithm 3. Since Algorithm 2 yields the desired search spaces (as stated in Lemma 7) with probability $k^{-k}$ , Algorithm 3 iteratively invokes it $k^{k}$ times, allowing the probability of successfully constructing the desired search spaces in at least one of the iterations to be boosted to a constant. Given $k$ sets $\\mathcal{A}_{1},\\cdot\\cdot\\cdot,\\mathcal{A}_{k}$ satisfying the statement in Lemma 7, Algorithm 3 constructs a net for each set of size more than 1, and adds the members of the net to the candidate set of opened facilities. Finally, the algorithm constructs a set of feasible solutions to $\\tilde{\\mathcal{I}}$ based on the candidates for opened facilities, and returns the one with the minimum cost among them. ", "page_idx": 7}, {"type": "text", "text": "Let $\\mathcal{H}^{\\dagger}$ be the solution given by Algorithm 3 with $(\\epsilon,\\tilde{\\mathcal{Z}},n)$ as the input. The following lemma says that $\\mathcal{H}^{\\dagger}$ is a $(1+O(\\epsilon^{\\frac{1}{\\rho}}))$ -approximation solution to $\\tilde{\\mathcal{I}}$ with high probability. ", "page_idx": 7}, {"type": "text", "text": "Lemma 9 The following event occurs with a probability of no less t\u221ahan $1\\ -\\ e^{-1}$ : $\\begin{array}{r}{\\sum_{c\\in\\mathcal{C}}w(c)\\delta^{\\rho}(c,\\ \\stackrel{\\cdot}{\\mathcal{H}}^{\\dagger})<(\\breve{1}+5\\epsilon)o p t}\\end{array}$ if $\\rho=1$ and $\\begin{array}{r}{\\sum_{c\\in\\bar{C}}w(c)\\delta^{\\rho}(c,\\mathcal{H}^{\\dagger})<(1+15\\sqrt{\\epsilon})o p}\\end{array}$ t if $\\rho=2$ . ", "page_idx": 7}, {"type": "text", "text": "By analyzing the time Algorithm 3 takes to construct the set of candidate solutions, as well as the size of this set, we can establish the following upper bound on the running time of Algorithm 3. ", "page_idx": 7}, {"type": "text", "text": "Lemma 10 Algorithm 3 runs in no more than $2^{(k\\epsilon^{-1})^{O(1)}+k\\ell}n^{O(1)}$ time. ", "page_idx": 7}, {"type": "text", "text": "Input: A constant $\\epsilon\\in(0,0.5)$ and an instance $\\mathcal{T}=(\\ell,k,\\mathcal{C},\\mathcal{F},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau)$ of the fair-range clustering problem satisfying $\\mathcal{C}\\cup\\mathcal{F}\\subset\\mathbb{R}^{d}$ ", "page_idx": 8}, {"type": "text", "text": "Output: A solution $\\mathcal{H}^{\\ddag}$ to $\\mathcal{T}$ ", "page_idx": 8}, {"type": "text", "text": "1 Let $\\bar{\\varphi}:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{\\tilde{d}}$ be the mapping and $\\tilde{\\mathcal{Z}}=(\\ell,k,\\tilde{\\mathcal{C}},\\tilde{\\mathcal{F}},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau,w)$ be the weighted instance constructed by Algorithm 1 with $(\\epsilon,\\mathcal{T})$ as the input; ", "page_idx": 8}, {"type": "text", "text": "2 Let $\\mathcal{H}^{\\dagger}$ be the solution to $\\tilde{\\mathcal{I}}$ constructed by Algorithm 3 with $(\\epsilon,\\tilde{\\mathcal{Z}},|\\mathcal{C}\\cup\\mathcal{F}|)$ as the input;   \n3 return $\\mathcal{H}^{\\ddag}\\Leftarrow\\{\\varphi^{-1}(f):f\\in\\mathcal{H}^{\\dagger}\\}$ . ", "page_idx": 8}, {"type": "text", "text": "3.4 Extensions to High-Dimensional Spaces ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We combine the data-reduction method given in Section 3.1 with the low-dimensional algorithm given in Section 3.3 to solve the FkMed and FkMeans problems in high-dimensional spaces, as detailed in Algorithm 4. Given the constant $\\epsilon\\in(0,0.5)$ and the instance $\\mathcal{T}=(\\ell,k,\\mathcal{C},\\mathcal{F},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau)$ of the fair-range clustering problem, the algorithm starts with constructing a mapping $\\varphi:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{\\tilde{d}}$ to a low-dimensional space and a small weighted instance $\\tilde{\\mathcal{Z}}\\,=\\,(\\ell,k,\\tilde{\\mathcal{C}},\\tilde{\\mathcal{F}},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau,w)$ satisfying $\\tilde{\\mathcal{C}}\\cup\\tilde{\\mathcal{F}}\\subset\\mathbb{R}^{\\tilde{d}}$ , $\\tilde{\\mathcal{F}}=\\{\\varphi(f):f\\in\\mathcal{F}\\}$ , and $\\tau(\\varphi(f))=\\tau(f)$ for each $f\\,\\in\\,{\\mathcal{F}}$ . It then constructs a solution to $\\tilde{\\mathcal{I}}$ using Algorithm 3, and returns the set of preimages of the facilities opened in this solution under $\\varphi$ . ", "page_idx": 8}, {"type": "text", "text": "We now analyze the performance guarantees of Algorithm 4 to show the correctness of Theorem 1. ", "page_idx": 8}, {"type": "text", "text": "Theorem 1 Given an instance $(\\ell,k,\\mathcal{C},\\mathcal{F},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau)$ of fair-range clustering with $\\mathcal{C}\\cup\\mathcal{F}\\subset\\mathbb{R}^{d}$ and $\\rho\\,\\in\\,\\{1,2\\}$ along with a real number $\\varepsilon\\,\\in\\,(0,1)$ , there is a randomized $(1+\\varepsilon)$ -approximation algorithm running in $O(d\\log d)+2^{(k\\varepsilon^{-1})^{O(1)}+k\\ell}n^{O(1)}$ time, where $n=|{\\mathcal{C}}\\cup{\\mathcal{F}}|$ . ", "page_idx": 8}, {"type": "text", "text": "Proof Let $\\mathcal{H}^{\\ddag}$ be the solution to $\\mathcal{T}$ returned by Algorithm 4, and let $\\mathcal{H}^{\\dagger}$ be the solution to $\\tilde{\\mathcal{I}}$ constructed by Algorithm 4 in step 2. Let $\\mathcal{H}^{*}$ be an optimal solution to $\\mathcal{T}$ and $\\tilde{\\mathcal{H}}^{*}$ be an optimal solution to $\\tilde{\\mathcal{I}}$ The optimality of H\u02dc for I\u02dc and Lemma 6 imply that ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{c\\in\\tilde{\\mathcal{C}}}w(c)\\delta^{\\rho}(c,\\tilde{\\mathcal{H}}^{*})\\leq\\displaystyle\\sum_{c\\in\\tilde{\\mathcal{C}}}w(c)\\delta^{\\rho}(c,\\{\\varphi(f):f\\in\\mathcal{H}^{*}\\})}\\\\ &{\\leq(1+\\epsilon)^{2\\rho+1}\\displaystyle\\sum_{c\\in\\mathcal{C}}\\delta^{\\rho}(c,\\mathcal{H}^{*}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "For the case where $\\rho=1$ , we can derive that inequality ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{c\\in\\mathcal{C}}\\delta^{\\rho}(c,\\mathcal{H}^{\\ddagger})\\leq\\frac{1}{1-\\epsilon}\\sum_{c\\in\\mathcal{C}}w(c)\\delta^{\\rho}(c,\\mathcal{H}^{\\dag})}&{}\\\\ {\\displaystyle<\\frac{1+5\\epsilon}{1-\\epsilon}\\sum_{c\\in\\mathcal{C}}w(c)\\delta^{\\rho}(c,\\tilde{\\mathcal{H}}^{\\ast})}&{}\\\\ {\\displaystyle\\leq\\frac{1+5\\epsilon}{1-\\epsilon}(1+\\epsilon)^{2\\rho+1}\\sum_{c\\in\\mathcal{C}}\\delta^{\\rho}(c,\\mathcal{H}^{\\ast})}&{}\\\\ {\\displaystyle<(1+44\\epsilon)\\sum_{c\\in\\mathcal{C}}\\delta^{\\rho}(c,\\mathcal{H}^{\\ast})}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "holds with a probability of no less than $1-e^{-1}$ , where the first step is due to the fact that $\\mathcal{H}^{\\dagger}=$ $\\{\\varphi(f):f\\in{\\dot{\\mathcal{H}}}^{\\ddag}\\}$ and Lemma 6, the second step follows from Lemma 9, the third step is due to inequality (3), and the last step follows from the fact that $\\epsilon\\in(0,0.5)$ . Similarly, we can conclude that inequality ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\sum_{c\\in\\mathcal{C}}\\delta^{\\rho}(c,\\mathcal{H}^{\\dag})\\leq\\frac{1}{1-\\epsilon}\\sum_{c\\in\\tilde{\\mathcal{C}}}w(c)\\delta^{\\rho}(c,\\mathcal{H}^{\\dag})\n$$", "text_format": "latex", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle<\\frac{1+15\\sqrt{\\epsilon}}{1-\\epsilon}\\sum_{c\\in\\tilde{\\mathcal{C}}}w(c)\\delta^{\\rho}(c,\\tilde{\\mathcal{H}}^{*})}\\\\ {\\displaystyle\\leq\\frac{1+15\\sqrt{\\epsilon}}{1-\\epsilon}(1+\\epsilon)^{2\\rho+1}\\sum_{c\\in\\mathcal{C}}\\delta^{\\rho}(c,\\mathcal{H}^{*})}\\\\ {\\displaystyle<(1+53\\sqrt{\\epsilon})\\sum_{c\\in\\mathcal{C}}\\delta^{\\rho}(c,\\mathcal{H}^{*})}\\end{array}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "holds with the same probability when $\\rho=2$ , where the second step is due to Lemma 9. We now consider the feasibility of $\\mathcal{H}^{\\ddag}$ . We have ", "page_idx": 9}, {"type": "equation", "text": "$$\n|\\{f\\in\\mathcal{H}^{\\sharp}:t\\in\\tau(f)\\}|=|\\{\\varphi(f):f\\in\\mathcal{H}^{\\sharp},t\\in\\tau(f)\\}|=|\\{f\\in\\mathcal{H}^{\\sharp}:t\\in\\tau(f)\\}|\\in[\\alpha_{t},\\beta_{t}],\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "where the first step is due to the assumption that each mapping constructed by Lemma 4 and Lemma 5 is injective, the second step follows from the fact that $\\mathcal{\\hat{H}}^{\\dagger}{=}\\,\\overline{{\\{\\varphi(f):f\\in\\mathcal{H}^{\\ddagger}\\}}}$ (as established in step 3 of Algorithm 4) and $\\tau(\\bar{\\varphi}(f))=\\tau(f)$ for each $f\\in\\mathcal F$ , and the last step follows from the feasibility of $\\mathcal{H}^{\\dagger}$ for $\\tilde{\\mathcal{I}}$ . This implies that $\\mathcal{H}^{\\ddag}$ is a feasible solution to $\\mathcal{T}$ . Combining this with inequality (4) and inequality (5), we know that Algo\u221arithm 4 is a randomized $(1+44\\epsilon)$ -approximation algorithm for the FkMed problem and a $(1+5\\bar{3}\\sqrt{\\epsilon})$ -approximation algorithm for the FkMeans problem. Moreover, Lemma 6 and Lemma 10 imply that this algorithm runs in $O(d\\log d)+2^{(k\\epsilon^{-1})^{\\bar{O}(1)}+k\\ell}n^{O(1)}$ time. $\\varepsilon\\,\\in\\,(0,1)$ ", "page_idx": 9}, {"type": "text", "text": "Given a constant , let $\\begin{array}{r}{\\epsilon=\\frac{\\varepsilon}{44}}\\end{array}$ for the FkMed problem and $\\begin{array}{r}{\\epsilon\\,=\\,(\\frac{\\varepsilon}{53})^{2}}\\end{array}$ for the FkMeans problem, then the argument above implies the existence of $(1+\\varepsilon)$ -approximation algorithms with running time $O(d\\log d)+2^{(k\\varepsilon^{-1})^{O(1)}+k\\ell}n^{O(1)}$ for both problems, as desired. \u25a1 ", "page_idx": 9}, {"type": "text", "text": "4 Conclusions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we consider the FkMed and FkMeans problems for the case where the numbers of opened facilities and demographic labels are fixed parameters. Based on a combination of a datareduction method and a space-partitioning approach for selecting opened facilities, we introduce $(1+\\varepsilon)$ -approximation algorithms in Euclidean spaces, representing the first parameterized approximation schemes for the problems. Given that coreset-construction methods were known for many constrained clustering problems incorporating additional constraints on instances, such as those related to capacities [Cohen-Addad and Li, 2019], group fairness [Bandyapadhyay et al., 2021], and robustness [Huang et al., 2023], an interesting direction for future work is to extend our techniques to deal with the FkMed and FkMeans problems in similar constrained settings. The additional constraints exacerbate the conflict between ensuring solution feasibility and minimizing solution cost, which makes the problems more challenging. Another promising avenue for exploration is to accelerate heuristic algorithms for fair-range clustering problems using the data-reduction methods proposed in this work, such as those given in [Thejaswi et al., 2022]. ", "page_idx": 9}, {"type": "text", "text": "5 Broader Impact ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Our work deals with fair-range clustering problems, providing algorithmic insights that can facilitate fair decision-making. While our algorithms have been shown to be \u201cfair\u201d according to specific definitions, it is essential to recognize that this fairness does not automatically warrant indiscriminate application. This underscores the need for careful consideration when implementing the algorithms proposed in this paper in real-world scenarios that prioritize fairness. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported by National Natural Science Foundation of China under Grant No. 62202161, Open Project of Xiangjiang Laboratory under Grant Nos. 22XJ03013 and 24XJJCYJ01, National Natural Science Foundation of China under Grant Nos. 62432016 and 62202160, Open Project of Xiangjiang Laboratory under Grant No. 22XJ02002, Natural Science Foundation of Hunan Province under Grant No. 2023JJ40240, and Central South University Research Programme of Advanced Interdisciplinary Studies under Grant No. 2023QYJC023. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Sara Ahmadian, Ashkan Norouzi-Fard, Ola Svensson, and Justin Ward. Better guarantees for $k$ -means and Euclidean $k$ -median by primal-dual algorithms. SIAM J. Comput., 49(4), 2020.   \nNir Ailon and Bernard Chazelle. The fast Johnson\u2013Lindenstrauss transform and approximate nearest neighbors. SIAM J. Comput., 39(1):302\u2013322, 2009.   \nSayan Bandyapadhyay, Fedor V. Fomin, and Kirill Simonov. On coresets for fair clustering in metric and Euclidean spaces and their applications. In Proceedings of the 48th International Colloquium on Automata, Languages, and Programming, volume 198, pages 23:1\u201323:15, 2021.   \nSuman Kalyan Bera, Deeparnab Chakrabarty, Nicolas Flores, and Maryam Negahbani. Fair algorithms for clustering. In Proceedings of the 32nd Annual Conference on Neural Information Processing Systems, pages 4955\u20134966, 2019.   \nAnup Bhattacharya, Ragesh Jaiswal, and Amit Kumar. Faster algorithms for the constrained $k$ -means problem. Theory Comput. Syst., 62(1):93\u2013115, 2018.   \nKe Chen. On coresets for $k$ -median and $k$ -means clustering in metric and Euclidean spaces and their applications. SIAM J. Comput., 39(3):923\u2013947, 2009.   \nXianrun Chen, Dachuan Xu, Yicheng Xu, and Yong Zhang. Parameterized approximation algorithms for sum of radii clustering and variants. In Proceedings of the 38th AAAI Conference on Artificial Intelligence, pages 20666\u201320673, 2024.   \nFlavio Chierichetti, Ravi Kumar, Silvio Lattanzi, and Sergei Vassilvitskii. Fair clustering through fairlets. In Proceedings of the 30th Annual Conference on Neural Information Processing Systems, pages 5029\u20135037, 2017.   \nVincent Cohen-Addad and Jason Li. On the fixed-parameter tractability of capacitated clustering. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming, volume 132, pages 41:1\u201341:14, 2019.   \nVincent Cohen-Addad, Anupam Gupta, Amit Kumar, Euiwoong Lee, and Jason Li. Tight FPT approximations for $k$ -median and $k$ -means. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming, volume 132, pages 42:1\u201342:14, 2019.   \nZhen Dai, Yury Makarychev, and Ali Vakilian. Fair representation clustering with several protected classes. In Proceedings of the 5th ACM Conference on Fairness, Accountability, and Transparency, pages 814\u2013823, 2022.   \nHu Ding and Jinhui Xu. A unified framework for clustering constrained data without locality property. Algorithmica, 82(4):808\u2013852, 2020.   \nZachary Friggstad and Yifeng Zhang. Tight analysis of a multiple-swap heurstic for budgeted redblue median. In Proceedings of the 43rd International Colloquium on Automata, Languages, and Programming, volume 55, pages 75:1\u201375:13, 2016.   \nYogesh A. Girdhar and Gregory Dudek. Efficient on-line data summarization using extremum summaries. In Proceeding of the 29th IEEE International Conference on Robotics and Automation, pages 3490\u20133496, 2012.   \nKishen N. Gowda, Thomas W. Pensyl, Aravind Srinivasan, and Khoa Trinh. Improved bi-point rounding algorithms and a golden barrier for $k$ -median. In Proceedings of the 34th ACM-SIAM Symposium on Discrete Algorithms, pages 987\u20131011, 2023.   \nDishant Goyal and Ragesh Jaiswal. Tight FPT approximation for socially fair clustering. Inf. Process. Lett., 182:106383, 2023.   \nAnupam Gupta, Robert Krauthgamer, and James R. Lee. Bounded geometries, fractals, and lowdistortion embeddings. In Proceeding of the 44th Symposium on Foundations of Computer Science, pages 534\u2013543, 2003.   \nMohammadTaghi Hajiaghayi, Rohit Khandekar, and Guy Kortsarz. Budgeted red-blue median and its generalizations. In Proceedings of the 18th Annual European Symposium on Algorithms, volume 6346, pages 314\u2013325, 2010.   \nMohammadTaghi Hajiaghayi, Rohit Khandekar, and Guy Kortsarz. Local search algorithms for the red-blue median problem. Algorithmica, 63(4):795\u2013814, 2012.   \nSariel Har-Peled and Manor Mendel. Fast construction of nets in low-dimensional metrics and their applications. SIAM J. Comput., 35(5):1148\u20131184, 2006.   \nS\u00e8djro S. Hotegni, Sepideh Mahabadi, and Ali Vakilian. Approximation algorithms for fair range clustering. In Proceedings of the 40th International Conference on Machine Learning, 2023.   \nLingxiao Huang, Shaofeng H.-C. Jiang, Jianing Lou, and Xuan Wu. Near-optimal coresets for robust clustering. In Proceedings of the 11th International Conference on Learning Representations, 2023.   \nRagesh Jaiswal, Amit Kumar, and Sandeep Sen. A simple $D^{2}$ -sampling based PTAS for $k$ -means and other clustering problems. Algorithmica, 70(1):22\u201346, 2014.   \nRagesh Jaiswal, Mehul Kumar, and Pulkit Yadav. Improved analysis of $D^{2}$ -sampling based PTAS for $k$ -means and other clustering problems. Inf. Process. Lett., 115(2):100\u2013103, 2015.   \nRagesh Jaiswal, Amit Kumar, and Jatin Yadav. FPT approximation for capacitated sum of radii. In Proceedings of the 15th Innovations in Theoretical Computer Science Conference, volume 287, pages 65:1\u201365:21, 2024.   \nWilliam B. Johnson and Joram Lindenstrauss. Extensions of Lipschitz mappings into a Hilbert space. Contemp. Math., 26:189\u2013206, 1984.   \nMatthew Kay, Cynthia Matuszek, and Sean A. Munson. Unequal representation and gender stereotypes in image search results for occupations. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, pages 3819\u20133828, 2015.   \nRavishankar Krishnaswamy, Amit Kumar, Viswanath Nagarajan, Yogish Sabharwal, and Barna Saha. The matroid median problem. In Proceedings of the 22nd Annual ACM-SIAM Symposium on Discrete Algorithms, pages 1117\u20131130, 2011.   \nRavishankar Krishnaswamy, Shi Li, and Sai Sandeep. Constant approximation for $k$ -median and $k$ -means with outliers via iterative rounding. In Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing, pages 646\u2013659, 2018.   \nAmit Kumar, Yogish Sabharwal, and Sandeep Sen. Linear-time approximation schemes for clustering problems in any dimensions. J. ACM, 57(2):5:1\u20135:32, 2010.   \nShi Li. A 1.488 approximation algorithm for the uncapacitated facility location problem. In The Proceedings of 38th International Colloquium on Automata, Languages and Programming, volume 6756, pages 77\u201388, 2011.   \nMarie-Francine Moens, Caroline Uyttendaele, and Jos Dumortier. Abstracting of legal cases: The potential of clustering based on the selection of representative objects. J. Am. Soc. Inf. Sci., 50(2): 151\u2013161, 1999.   \nShyam Narayanan and Jelani Nelson. Optimal terminal dimensionality reduction in Euclidean space. In Moses Charikar and Edith Cohen, editors, Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing, pages 1064\u20131069, 2019.   \nChaitanya Swamy. Improved approximation algorithms for matroid and knapsack median problems and applications. In Proceedings of the 17th International Workshop on Approximation Algorithms for Combinatorial Optimization Problems and 18th International Workshop on Randomization and Computation, volume 28, pages 403\u2013418, 2014.   \nSuhas Thejaswi, Bruno Ordozgoiti, and Aristides Gionis. Diversity-aware $k$ -median: Clustering with fair center representation. In Proceedings of the 32nd European Conference on Machine Learning and the 25th European Conference on Principles and Practice of Knowledge Discovery in Databases, volume 12976, pages 765\u2013780, 2021.   \nSuhas Thejaswi, Ameet Gadekar, Bruno Ordozgoiti, and Michal Osadnik. Clustering with fair-center representation: Parameterized approximation algorithms and heuristics. In Proceedings of the $28t h$ ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 1749\u20131759, 2022.   \nDi Wu, Qilong Feng, and Jianxin Wang. Approximation algorithms for fair $k$ -median problem without fairness violation. Theor. Comput. Sci., 985:114332, 2024.   \nZhen Zhang, Junfeng Yang, Limei Liu, Xuesong Xu, Guozhen Rong, and Qilong Feng. Towards a theoretical understanding of why local search works for clustering with fair-center representation. In Proceedings of the 38th AAAI Conference on Artificial Intelligence, pages 16953\u201316960, 2024. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Proof of Lemma 1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Lemma 1 Given two real numbers s and $t$ greater than $^{\\,l}$ , we have $\\log^{t}s\\leq\\operatorname*{max}\\{s,t^{O(t)}\\}$ . ", "page_idx": 13}, {"type": "text", "text": "Proof If t \u2265 lolgo lgo sg s , then we have $\\log s\\leq O(t\\log t)$ , and thus $\\log^{t}s\\leq t^{O(t)}$ . If $\\displaystyle t<{\\frac{\\log s}{\\log\\log s}}$ , then we have $\\log^{t}s<\\log^{\\frac{\\log s}{\\log\\log s}}s=s$ . Thus, Lemma 1 is true. \u25a1 ", "page_idx": 13}, {"type": "text", "text": "B Proof of Lemma 2 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Lemma 2 Given three points $x,\\,y_{:}$ , and $z$ in an Euclidean space and a real number $\\gamma\\in(0,1]$ , we have $||x-z||^{2}\\leq(1+\\bar{\\gamma}^{-1})||x-y||^{2}+(1+\\gamma)||y-z||^{2}.$ . ", "page_idx": 13}, {"type": "text", "text": "Proof Triangle inequality implies that $||x-z||\\leq||x-y||+||y-z||$ , and thus we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle||x-z||^{2}\\leq(||x-y||+||y-z||)^{2}}\\\\ {\\displaystyle=||x-y||^{2}+||y-z||^{2}+2\\frac{1}{\\sqrt{\\gamma}}||x-y||\\sqrt{\\gamma}||y-z||}\\\\ {\\displaystyle\\leq||x-y||^{2}+||y-z||^{2}+\\frac{1}{\\gamma}||x-y||^{2}+\\gamma||y-z||^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "This completes the proof of Lemma 2. ", "page_idx": 13}, {"type": "text", "text": "C Proof of Lemma 6 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Lemma 6 Given a constant $\\epsilon\\,\\in\\,(0,0.5)$ and an instance $(\\ell,k,\\mathcal{C},\\mathcal{F},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau)$ of the fair-range clustering problem with $\\rho\\in\\{1,2\\}$ , $|{\\mathcal{C}}\\cup{\\mathcal{F}}|=n$ , and $\\mathcal{C}\\cup\\mathcal{F}\\subset\\mathbb{R}^{d}$ , Algorithm 1 constructs a mapping $\\varphi:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{\\tilde{d}}$ and an instance $(\\ell,k,\\tilde{\\mathcal{C}},\\tilde{\\mathcal{F}},\\vec{\\alpha},\\vec{\\beta},\\rho,\\tau,w)$ of the weighted fair-range clustering problem in $O(d\\log d)+(n k\\epsilon^{-1})^{O(1)}$ time, which satisfy the following properties: ", "page_idx": 13}, {"type": "text", "text": "(i) $\\begin{array}{r}{\\sum_{c\\in\\tilde{c}}w(c)=|\\mathcal{C}|,}\\end{array}$ ,   \n(ii) $w(c)\\geq1$ for each $c\\in\\tilde{\\mathcal{C}}$ ,   \n(iii) $|\\tilde{c}|\\leq(k\\epsilon^{-1}\\log n)^{O(1)}$ ,   \n(iv) $\\tilde{d}=\\epsilon^{-O(1)}(\\log k+\\log\\log n),$ , and   \n(v) $\\begin{array}{r}{\\sum_{c\\in\\widetilde{C}}w(c)\\delta^{\\rho}(c,\\{\\varphi(f)\\,:\\,f\\,\\in\\,\\mathcal{H}\\})\\,\\in\\,[1-\\epsilon,(1+\\epsilon)^{2\\rho+1}]\\sum_{c\\in\\mathcal{C}}\\delta^{\\rho}(c,\\mathcal{H})}\\end{array}$ for each $\\mathcal{H}\\subseteq\\mathcal{F}$ with $|\\mathcal{H}|\\leq k$ . ", "page_idx": 13}, {"type": "text", "text": "Proof Algorithm 1 constructs a mapping $\\varphi_{1}:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{d^{\\dagger}}$ using Lemma 4 in step 1, a coreset $\\mathcal{C}^{\\dagger}$ along with the corresponding weight function $w^{\\dag}:\\mathcal{C}^{\\dag}\\to[1,+\\infty)$ using Lemma 3 in step 2, and a mapping $\\varphi_{2}:\\mathbb{R}^{d^{\\dagger}}\\rightarrow\\mathbb{R}^{\\tilde{d}}$ using Lemma 5 in step 3. ", "page_idx": 13}, {"type": "text", "text": "We begin by examining the first property of the output of Algorithm 1 stated in Lemma 6. We have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sum_{c\\in{\\tilde{C}}}w(c)=\\sum_{c\\in{\\mathcal{C}}^{\\dagger}}w^{\\dagger}(c)=|\\{\\varphi_{1}(c):c\\in{\\mathcal{C}}\\}|=|{\\mathcal{C}}|,\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the first step follows from the fact that $\\tilde{\\mathcal{C}}=\\{\\varphi_{2}(c):c\\in\\mathcal{C}^{\\dagger}\\}$ (due to step 4 of Algorithm 1) and $w$ is the composite mapping $w^{\\dagger}\\circ\\varphi_{2}^{-1}$ (due to step 5 of Algorithm 1), the second step follows from the fact that $\\mathcal{C}^{\\dagger}$ is the weighted set constructed by Lemma 3 with $\\{\\varphi_{1}(c):c\\in\\mathcal{C}\\}$ as the input set, and the last step is due to the assumption that the mappings constructed by Lemma 4 and Lemma 5 are injective. Equality (6) implies that the first property stated in Lemma 6 is true. ", "page_idx": 13}, {"type": "text", "text": "The second property stated in Lemma 6 follows directly from the fact that $w(c)\\,=\\,w^{\\dagger}(\\varphi_{2}^{-1}(c))$ for each $c\\in{\\tilde{\\mathcal{C}}}$ (as established in step 5 of Algorithm 1) and $w^{\\dagger}$ is a mapping to $\\lbrack1,+\\infty)$ (due to Lemma 3). ", "page_idx": 13}, {"type": "text", "text": "We now consider the third property stated in Lemma 6. This can be verified by ", "page_idx": 13}, {"type": "equation", "text": "$$\n|\\tilde{\\mathcal{C}}|=|\\mathcal{C}^{\\dagger}|\\leq d^{\\dagger}(k\\epsilon^{-1}\\log|\\mathcal{C}|)^{O(1)}=(k\\epsilon^{-1}\\log|\\mathcal{C}|)^{O(1)}\\log|\\mathcal{C}\\cup\\mathcal{F}|=(k\\epsilon^{-1}\\log n)^{O(1)},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the first step is due to the fact that $\\tilde{\\mathcal{C}}\\,=\\,\\{\\varphi_{2}(c)\\,:\\,c\\,\\in\\,\\mathcal{C}^{\\dagger}\\}$ (as established in step 4 of the algorithm) and the assumption that each mapping constructed by Lemma 5 is injective, the second step follows from Lemma 3, and the third step is due to the fact that $\\varphi_{1}:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{d^{\\dagger}}$ is the mapping constructed by Lemma 4 with $(\\epsilon,\\mathcal{C}\\cup\\mathcal{F})$ as the input. ", "page_idx": 14}, {"type": "text", "text": "Using inequality (7) and the fact that $\\varphi_{2}:\\mathbb{R}^{d^{\\dagger}}\\rightarrow\\mathbb{R}^{\\tilde{d}}$ is the mapping constructed by Lemma 5 with $(\\epsilon,\\mathcal{C}^{\\dagger})$ as the input, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\tilde{d}=\\epsilon^{-O(1)}\\log|\\mathcal{C}^{\\dagger}|\\leq\\epsilon^{-O(1)}\\log(k\\epsilon^{-1}\\log n)=\\epsilon^{-O(1)}(\\log k+\\log\\log n),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which implies that the fourth property stated in Lemma 6 is true. ", "page_idx": 14}, {"type": "text", "text": "Given a subset $\\mathcal{H}\\subseteq\\mathcal{F}$ with $|\\mathcal{H}|\\leq k$ , we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{c\\in\\bar{C}}w(c)\\delta^{\\rho}(c,\\{\\varphi(f):f\\in\\mathcal{H}\\})\\in[1,(1+\\epsilon)^{\\rho}]\\displaystyle\\sum_{c\\in\\mathcal{C}^{\\dagger}}w(c)\\delta^{\\rho}(c,\\{\\varphi_{1}(f):f\\in\\mathcal{H}\\})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\subseteq[1-\\epsilon,(1+\\epsilon)^{\\rho+1}]\\displaystyle\\sum_{c\\in\\mathcal{C}}\\delta^{\\rho}(\\varphi_{1}(c),\\{\\varphi_{1}(f):f\\in\\mathcal{H}\\})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\subseteq[1-\\epsilon,(1+\\epsilon)^{2\\rho+1}]\\displaystyle\\sum_{c\\in\\mathcal{C}}\\delta^{\\rho}(c,\\mathcal{H}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where the first step follows from Lemma 5 and the fact that $\\tilde{\\mathcal{C}}\\,=\\,\\{\\varphi_{2}(c)\\,:\\,c\\,\\in\\,\\mathcal{C}^{\\dagger}\\}$ and $\\varphi(f)=$ $\\varphi_{2}\\mathopen{}\\mathclose\\bgroup\\left(\\varphi_{1}\\mathopen{}\\mathclose\\bgroup\\left(f\\aftergroup\\egroup\\right)\\aftergroup\\egroup\\right)$ for each $f\\in\\mathcal F$ (due to step 4 of Algorithm 1), the second step follows from the fact that $\\mathcal{C}^{\\dagger}$ is a coreset of $\\{\\varphi_{1}(c):c\\in\\mathcal{C}\\}$ constructed by Lemma 3, and the last step is due to Lemma 4. This completes the proof of the last property stated in Lemma 6. ", "page_idx": 14}, {"type": "text", "text": "It remains to show the running time of Algorithm 1. Recall that the algorithm invokes Lemma 4 with $(\\epsilon,\\mathcal{C}\\cup\\mathcal{F})$ , invokes Lemma 3 with $(\\epsilon,\\{\\varphi_{1}(c):c\\in\\mathcal{C}\\},k,\\rho)$ , and invokes Lemma 5 with $(\\epsilon,\\mathcal{C}^{\\dagger})$ , where ${\\mathcal{C}}^{\\dagger}\\subseteq\\{\\varphi_{1}(c):c\\in{\\mathcal{C}}\\}\\subset\\mathbb{R}^{d^{\\dagger}}$ . Combining this with inequality (7), we can express the running time of Algorithm 1 as ", "page_idx": 14}, {"type": "equation", "text": "$$\nO(d\\log d+|\\mathcal{C}|d^{\\dagger}k)+(|\\mathcal{C}^{\\dagger}|d^{\\dagger})^{O(1)}+(\\epsilon^{-1}\\log|\\mathcal{C}\\cup\\mathcal{F}|)^{O(1)}\\le O(d\\log d)+(n k\\epsilon^{-1})^{O(1)},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "as desired. ", "page_idx": 14}, {"type": "text", "text": "D Proof of Lemma 7 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Lemma 7 The following event occurs with a probability of no less than $k^{-k}$ : The collection A constructed by Algorithm 2 has an element $\\{\\mathcal{A}_{1},\\cdot\\cdot\\cdot,\\mathcal{A}_{k}\\}$ satisfying ${\\mathcal{A}}_{i}\\subseteq{\\mathcal{L}}_{i}$ and $|\\mathcal{A}_{i}|=1$ for each $i\\in[k]\\backslash[k^{*}]$ , $f_{i}^{*}\\in\\mathcal{A}_{i}\\subseteq\\mathcal{A}_{i}^{*}$ for each $i\\in[k^{*}]$ , and $\\bigcap_{i=1}^{k}{\\mathcal{A}}_{i}=\\emptyset$ . ", "page_idx": 14}, {"type": "text", "text": "Proof For each $i\\in[k^{*}]$ , Algorithm 2 enumerates all possible values of $A^{*}(i,j)$ and all possible integers $j$ satisfying $A^{*}(i,j)=A_{i}^{*}$ . Additionally, it enumerate all possible values of ${\\mathcal{L}}_{i}$ for each $i\\in\\bar{[k]}\\backslash[k^{*}]$ . Consequently, the $k$ sets $A_{1}^{\\ast},\\cdot\\cdot\\cdot,\\mathscr{A}_{k^{\\ast}}^{\\ast},\\mathscr{L}_{k^{\\ast}+1},\\cdot\\cdot\\cdot,\\mathscr{L}_{k}$ are guaranteed to be captured by the algorithm. Given these $k$ sets, Algorithm 2 associates each facility $f$ with a random integer $\\eta(f)\\,\\in\\,[k]$ in step 12. It can be shown that equality $\\eta(f_{i}^{*})\\,=\\,i\\,\\forall\\,i\\,\\in\\,[k]$ holds with probability $k^{-k}$ . When this inequality is satisfied, the algorithm can construct a search space $A_{i}$ satisfying $f_{i}^{*}\\in\\mathcal{A}_{i}\\subseteq\\mathcal{A}_{i}^{*}$ for each $i\\in[k^{*}]$ by extracting the facilities with $\\eta(f)=i$ from $A_{i}^{*}$ in step 14, and find a facility $f\\in{\\mathcal{L}}_{i}$ with $\\eta(f)=i$ to construct a singleton set ${\\mathcal{A}}_{i}\\subseteq{\\mathcal{L}}_{i}$ for each $i\\in[k]\\backslash[k^{*}]$ in step 17. Moreover, the selected $k$ sets are disjoint, as the facilities in different sets are associated with different integers. Thus, Lemma 7 is true. \u25a1 ", "page_idx": 14}, {"type": "text", "text": "E Proof of Lemma 9 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Lemma 9 The following event occurs with a probability of no less t\u221ahan $1\\ -\\ e^{-1}$ : $\\begin{array}{r}{\\sum_{c\\in\\tilde{C}}w(c)\\delta^{\\rho}(c,\\overbar{\\mathcal{H}}^{\\dag})<(\\bar{1}+5\\epsilon)o p t\\,i f\\rho=1}\\end{array}$ and $\\begin{array}{r}{\\sum_{c\\in\\bar{C}}w(c)\\delta^{\\rho}(c,\\mathcal{H}^{\\dagger})<(1+15\\sqrt{\\epsilon})o p}\\end{array}$ t if $\\rho=2$ . ", "page_idx": 14}, {"type": "text", "text": "Proof Given that Algorithm 3 iteratively invokes Algorithm $2~k^{k}$ times to construct a collection A, the probability that there is an element $\\{\\mathcal{A}_{1},\\cdot\\cdot\\cdot,\\mathcal{A}_{k}\\}$ in A satisfying the properties stated in Lemma 7 is at least $1-(1-k^{-k})^{k^{k}}>1-e^{-1}$ . For the purpose of our analysis, we now assume that the collection A indeed contains such an element. Given an integer $i\\in[k]$ , let $\\boldsymbol{S}_{i}$ be the subset of $\\boldsymbol{A}_{i}$ constructed by Algorithm 3 in step 10 or step 12. We respectively consider the following three cases: (1) $|\\mathcal{A}_{i}|=1$ , (2) $|\\mathcal{A}_{i}|>1$ and $\\bar{\\mathcal{A}}_{i}\\subseteq\\mathcal{A}^{*}(\\bar{i},0)$ , and (3) $|\\mathcal{A}_{i}|>1$ and $A_{i}\\subseteq A^{*}(i,j)$ for an integer $j\\in[\\lceil\\epsilon^{-2}\\log n\\rceil]$ . ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "For case (1), Lemma 7 indicates that ", "page_idx": 15}, {"type": "equation", "text": "$$\nS_{i}=\\mathcal{A}_{i}=\\{f_{i}^{*}\\}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "if $i\\in[k^{*}]$ , and ", "page_idx": 15}, {"type": "equation", "text": "$$\nS_{i}=A_{i}\\subseteq\\mathcal{L}_{i}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "otherwise. ", "page_idx": 15}, {"type": "text", "text": "For the case where $|\\mathcal{A}_{i}|>1$ , Lemma 7 implies that $i\\in[k^{*}]$ . For case (2), it can be concluded that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\delta^{\\rho}(f_{i}^{*},S_{i})\\leq\\rho\\operatorname*{max}_{f\\in\\mathcal{A}_{i}}||f-c_{i}||^{\\rho}+\\rho||f_{i}^{*}-c_{i}||^{\\rho}\\leq2\\rho\\operatorname*{max}_{f\\in\\mathcal{A}_{i}}||f-c_{i}||^{\\rho}\\leq\\frac{2\\rho\\epsilon}{n}\\delta_{\\operatorname*{max}}^{\\rho}\\leq\\frac{2\\rho\\epsilon}{n}o p t\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "when $\\rho\\in\\{1,2\\}$ , where the first step is due to triangle inequality (for $\\rho=1$ ) and Lemma 2 (for $\\rho=2$ , with $\\gamma=1$ ), the second step follows from the fact that $f_{i}^{*}\\in A_{i}$ (as established by Lemma 7), the third step is due to the assumption that $A_{i}\\subseteq A^{*}(i,0)$ and the definition of $A^{*}(i,0)$ , and the last step is due to inequality (1). ", "page_idx": 15}, {"type": "text", "text": "We now consider case (3). In this scenario, $\\mathcal{S}_{i}$ is a $\\mathrm{max}_{x,y\\in A_{i}}\\,\\epsilon||x-y||$ -net of $A_{i}$ , and we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\delta^{\\rho}(f_{i}^{*},S_{i})\\leq\\epsilon^{\\rho}\\operatorname*{max}_{x,y\\in A_{i}}||x-y||^{\\rho}\\leq2\\rho\\epsilon^{\\rho}\\operatorname*{max}_{f\\in A_{i}}||f-c_{i}||^{\\rho}\\leq2\\rho\\epsilon^{\\rho}(1+\\epsilon)||f_{i}^{*}-c_{i}||^{\\rho}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "when $\\rho\\in\\{1,2\\}$ , where the first step follows from the fact that $f_{i}^{*}\\in A_{i}$ (due to Lemma 7) and the definition of nets, the second step follows from triangle inequality (for $\\rho=1\\$ ) and Lemma 2 (for $\\rho=2,$ ), and the last step follows from the assumption that an integer $j$ from $\\left[\\left[\\epsilon^{-2}\\log n\\right]\\right]$ satisfies $A_{i}\\subseteq A^{*}(i,j)$ and the fact that each $\\{x,y\\}\\subseteq{\\mathcal{A}}^{*}(i,j)$ satisfies $||x-c_{i}||^{\\rho}\\leq(1+\\epsilon)||y-c_{i}||^{\\rho}$ (due to the definition of $A^{*}(i,j))$ . ", "page_idx": 15}, {"type": "text", "text": "Let $\\mathbb{H}^{\\prime}$ be the set of candidate solution constructed based on the Cartesian product $S_{1}\\times S_{2}\\times\\cdot\\cdot\\times S_{k}$ in step 13 of Algorithm 3. Equality (8), equality (9), inequality (10), and inequality (11) suggest the existence of an element $\\{f_{1},\\cdot\\cdot\\cdot,f_{k}\\}$ of $\\mathbb{H}^{\\prime}$ satisfying ", "page_idx": 15}, {"type": "equation", "text": "$$\n||f_{i}-f_{i}^{*}||^{\\rho}\\leq\\operatorname*{max}\\{\\frac{2\\rho\\epsilon}{n}o p t,2\\rho\\epsilon^{\\rho}(1+\\epsilon)||f_{i}^{*}-c_{i}||^{\\rho}\\}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "for each $i\\in[k^{*}]$ and ", "page_idx": 15}, {"type": "equation", "text": "$$\nf_{i}\\in{\\mathcal{L}}_{i}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "for each $i\\in[k]\\backslash[k^{*}]$ . Thus, it can be shown that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\displaystyle\\sum_{i=1}^{k}\\sum_{e\\in\\mathcal{C}_{i}^{\\epsilon}}w(c)\\|f_{i}-f_{i}^{*}\\|^{p}=\\displaystyle\\sum_{i=1}^{k^{\\star}}\\sum_{e\\in\\mathcal{C}_{i}^{\\epsilon}}w(c)\\|f_{i}-f_{i}^{*}\\|^{p}}\\\\ {\\displaystyle\\leq\\sum_{i=1}^{k^{\\star}}\\sum_{e\\in\\mathcal{C}_{i}^{\\epsilon}}w(c)\\operatorname*{max}\\{\\displaystyle\\frac{2\\rho c}{n}\\phi_{d},2\\rho e^{\\theta}(1+\\epsilon)\\|f_{i}^{*}-c_{i}\\|^{p}\\}}\\\\ {\\displaystyle\\leq\\sum_{i=1}^{k^{\\star}}\\sum_{e\\in\\mathcal{C}_{i}^{\\epsilon}}w(c)\\left(\\frac{2\\rho c}{n}\\sigma_{d}+2\\rho e^{\\theta}(1+\\epsilon)\\|f_{i}^{*}-c_{i}\\|^{p}\\right)}\\\\ {\\displaystyle<2\\rho e\\cdot\\sigma p t+2\\rho e^{\\theta}(1+\\epsilon)\\sum_{i=1}^{k}\\sum_{e\\in\\mathcal{C}_{i}^{\\epsilon}}w(c)\\|f_{i}^{*}-c_{i}\\|^{p}}\\\\ {\\displaystyle=2\\rho e\\cdot\\sigma p t+2\\rho e^{\\theta}(1+\\epsilon)\\alpha\\|f_{i}^{*}-c_{i}^{\\epsilon}\\|^{p}}\\\\ {\\displaystyle<(2e+3\\rho e^{\\theta})\\sigma\\theta t,}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the first step is due to the fact that $\\tilde{\\mathcal{C}}_{i}^{*}=\\emptyset$ for each $i\\in[k]\\backslash[k^{*}]$ , the second step is due to inequality (12), the fourth step follows from the fact that $\\begin{array}{r}{\\sum_{i=1}^{k}\\sum_{c\\in\\tilde{\\mathcal{C}}_{i}^{*}}w(c)=\\sum_{c\\in\\tilde{\\mathcal{C}}}w(c)=|\\tilde{\\mathcal{C}}|<}\\end{array}$ $n$ (due to Lemma 6), and the last step follows from the fact that $\\epsilon\\in(0,0.5)$ . Consequently, for the case where $\\rho=2$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{c\\in\\mathcal{C}}w(c)\\delta^{\\mu}(c,\\{f_{1},\\cdots,f_{k}\\})=\\displaystyle\\sum_{i=1}^{k}\\sum_{c\\in\\mathcal{C}_{i}^{c}}w(c)\\delta^{\\mu}(c,\\{f_{1},\\cdots,f_{k}\\})}\\\\ {\\displaystyle}&{\\le\\displaystyle\\sum_{i=1}^{k}\\sum_{c\\in\\mathcal{C}_{i}^{c}}w(c)\\|c-f_{1}\\|^{\\mu}}\\\\ &{\\le\\displaystyle\\sum_{i=1}^{k}\\sum_{c\\in\\mathcal{C}_{i}^{c}}w(c)\\left((1+\\sqrt{c})\\|c-f_{1}\\|^{\\mu}+(1+\\displaystyle\\frac{1}{\\sqrt{c}})\\|f_{1}^{\\star}-f_{1}\\|^{\\mu}\\right)}\\\\ &{=\\displaystyle(1+\\sqrt{c})\\sigma\\mu+(1+\\displaystyle\\frac{1}{\\sqrt{c}})\\sum_{i=1}^{k}\\sum_{c\\in\\mathcal{C}_{i}^{c}}w(c)\\|f_{1}^{\\star}-f_{1}\\|^{\\mu}}\\\\ &{<\\left(1+\\sqrt{c}+(1+\\displaystyle\\frac{1}{\\sqrt{c}})(2\\rho+3\\rho e^{\\varepsilon})\\right)\\sigma\\mu}\\\\ &{<(1+15\\sqrt{c})\\sigma\\mu,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the third step is due to Lemma 2 (with $\\gamma=\\sqrt{\\epsilon})$ , the fourth step follows from the definition of $\\tilde{C}_{i}^{*}$ , the fifth step follows from inequality (14), and the last step is due to the fact that $\\epsilon\\in(0,0.5)$ . Replacing Lemma 2 used in the third step of inequality (15) with triangle inequality, we get ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\sum_{c\\in\\widetilde{\\mathcal{C}}}w(c)\\delta^{\\rho}(c,\\{f_{1},\\cdots,f_{k}\\})\\leq\\displaystyle\\sum_{i=1}^{k}\\sum_{c\\in\\widetilde{\\mathcal{C}}_{i}^{*}}w(c)\\left(||c-f_{i}^{*}||^{\\rho}+||f_{i}^{*}-f_{i}||^{\\rho}\\right)}}\\\\ {{\\displaystyle=o p t+\\sum_{i=1}^{k}\\sum_{c\\in\\widetilde{\\mathcal{C}}_{i}^{*}}w(c)||f_{i}^{*}-f_{i}||^{\\rho}}}\\\\ {{\\displaystyle<(1+5\\epsilon)o p t}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "for the case where $\\rho=1$ . ", "page_idx": 16}, {"type": "text", "text": "We now consider the feasibility of the solution $\\{f_{1},\\cdot\\cdot\\cdot,f_{k}\\}$ . We have ", "page_idx": 16}, {"type": "equation", "text": "$$\nf_{i}\\in S_{i}\\subseteq\\mathcal{A}_{i}\\subseteq\\mathcal{A}_{i}^{*}\\subseteq\\mathcal{L}_{i}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "for each $i\\in[k]^{*}$ due to Lemma 7 and the definition of $A_{i}^{*}$ . Moreover, relation (9) states that ", "page_idx": 16}, {"type": "equation", "text": "$$\nf_{i}\\in S_{i}\\subseteq{\\mathcal{L}}_{i}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "for each $i\\in[k]\\backslash[k]^{*}$ . Since $S_{1},\\cdot\\cdot\\cdot,S_{k}$ are $k$ disjoint sets (as established by Lemma 7, which states that $\\mathcal{A}_{1},\\cdot\\cdot\\cdot,\\mathcal{A}_{k}$ are disjoint), we know that the set $\\{f_{1},\\cdot\\cdot\\cdot,f_{k}\\}$ is distinct. Consequently, the fact that each $i\\in[k]$ satisfies $f_{i}\\in{\\mathcal{L}}_{i}$ implies that ", "page_idx": 16}, {"type": "equation", "text": "$$\n|\\{f\\in\\{f_{1},\\cdots,f_{k}\\}:t\\in\\tau(f)\\}|=|\\{f\\in\\tilde{\\mathcal{H}}^{*}:t\\in\\tau(f)\\}|\\in[\\alpha_{t},\\beta_{t}]\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "for each $t\\in[\\ell]$ , and thus $\\{f_{1},\\cdot\\cdot\\cdot,f_{k}\\}$ is a feasible solution to $\\tilde{\\mathcal{I}}$ . Combining this with inequality (15) and inequality (16), we complete the proof of Lemma 9. \u25a1 ", "page_idx": 16}, {"type": "text", "text": "F Proof of Lemma 10 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Lemma 10 Algorithm 3 runs in no more than $2^{(k\\epsilon^{-1})^{O(1)}+k\\ell}n^{O(1)}$ time. ", "page_idx": 16}, {"type": "text", "text": "Proof Let $\\mathbb{H}$ be the set of candidate solutions constructed by Algorithm 3, and let A be the collection formed by iteratively invoking Algorithm $2\\ k^{k}$ times. Observe that Algorithm 2 enumerates all possible values of $k^{*}$ , $\\mathrm{~\\boldmath~\\psi~},\\;\\{c_{1},\\cdots\\;,c_{k}\\}$ , $\\delta_{\\mathrm{max}}^{\\rho}$ , and $\\{{\\mathcal{L}}_{1},\\cdot\\cdot\\cdot,{\\mathcal{L}}_{k}\\}$ to guess the sets $\\{\\mathcal{A}^{\\ast}(1,0),\\dot{\\cdot}\\dot{\\cdot}\\cdot,\\mathcal{A}^{\\ast}(k^{\\ast},\\lceil\\epsilon^{-2}\\log n\\rceil)\\}$ and $\\{\\mathcal{L}_{k^{*}+1},\\cdot\\cdot\\cdot\\,,\\mathcal{L}_{k}\\}$ . Additionally, it enumerates $[[\\lceil\\epsilon^{-2}\\log n\\rceil]\\cup\\{0\\}]^{k}$ to determine the set $\\{\\mathcal{A}_{1}^{*},\\cdot\\cdot\\cdot,\\mathcal{A}_{k^{*}}^{*}\\}$ . Analyzing the possible values of these parameters yields ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\mathbb{A}|\\leq2^{k\\ell}k^{k+1}|\\tilde{\\mathcal{F}}||\\tilde{\\mathcal{C}}|^{k+1}(\\epsilon^{-2}\\log n+1)^{k}}\\\\ &{\\quad\\leq2^{k\\ell}(k\\epsilon^{-1}\\log n)^{O(k)}n}\\\\ &{\\quad\\leq2^{k\\ell}(k\\epsilon^{-1})^{O(k)}n^{O(1)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the second step follows from the fact that $\\tilde{\\mathcal{C}}=(k\\epsilon^{-1}\\log n)^{O(1)}$ (due to Lemma 6) and $|\\tilde{\\mathcal{F}}|<n$ , and the third step follows from Lemma 1 (with $s=n$ and $t=k$ ). ", "page_idx": 17}, {"type": "text", "text": "Let $\\{\\mathcal{A}_{1},\\cdot\\cdot\\cdot\\,,\\mathcal{A}_{k}\\}\\;\\in\\;\\mathbb{A}$ be the collection considered in one of the iterations of steps 8-13 of Algorithm 3. Let $S_{1},\\cdot\\cdot\\cdot,S_{k}$ be the subsets constructed in step 10 or step 12 and $\\mathbb{H}^{\\prime}$ be the set of candidate solutions constructed in step 13 during this iteration. For each $i\\in[k]$ with $|{\\cal S}_{i}|>1$ , ${\\mathbf{}}S_{i}$ is a $\\mathrm{max}_{x,y\\in A_{i}}\\,\\epsilon||x-y||$ -net of $A_{i}$ , which is constructed based on the maximum distance between the facilities from $\\boldsymbol{A}_{i}$ in step 12. Lemma 8 implies that constructing these nets takes no more than ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{k}2^{O(\\tilde{d})}|A_{i}|^{O(1)}\\leq2^{O(\\tilde{d})}|\\tilde{\\mathcal{F}}|^{O(1)}k\\leq2^{O(\\tilde{d})}n^{O(1)}k\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "time. Moreover, Lemma 8 and the fact that $\\boldsymbol{S}_{i}$ is a $\\mathrm{max}_{x,y\\in A_{i}}\\,\\epsilon||x-y||$ -net of $\\mathcal{A}_{i}$ for each $i\\in[k]$ with $|\\mathcal{S}_{i}|>1$ suggest that ", "page_idx": 17}, {"type": "equation", "text": "$$\n1\\leq|S_{i}|\\leq\\epsilon^{-\\tilde{d}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Inequality (19) leads to ", "page_idx": 17}, {"type": "equation", "text": "$$\n|\\mathbb{H}^{\\prime}|=\\prod_{i=1}^{k}|S_{i}|\\leq\\epsilon^{-k\\tilde{d}},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and thus we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n|\\mathbb{H}|\\leq\\epsilon^{-k\\tilde{d}}|\\mathbb{A}|.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Given the set $\\mathbb{H}$ of candidate solutions, Algorithm 3 takes $|\\tilde{\\mathcal{C}}|\\tilde{d k}|\\mathbb{H}|$ time to identify the solution with the minimum cost. Combining this with the time required for constructing nets in each iteration exhibited in inequality (18), we know that the running time of Algorithm 3 is upper-bounded by ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{2^{O(\\tilde{d})}n^{O(1)}k|\\mathbb{A}|+|\\tilde{\\mathcal{C}}|\\tilde{d}k|\\mathbb{H}|\\leq|\\mathbb{A}|k|k(2^{O(\\tilde{d})}n^{O(1)}+\\epsilon^{-k\\tilde{d}}|\\tilde{\\mathcal{C}}|\\tilde{d})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq2^{k\\ell}\\epsilon^{-O(k\\tilde{d})}n^{O(1)}(k\\epsilon^{-1})^{O(k)}}\\\\ &{\\qquad\\qquad\\qquad\\leq2^{k\\ell}n^{O(1)}(k\\epsilon^{-1})^{O(k)}(k\\log n)^{(k\\epsilon^{-1})^{O(1)}}}\\\\ &{\\qquad\\qquad\\qquad\\leq2^{k\\ell}n^{O(1)}(k\\epsilon^{-1})^{(k\\epsilon^{-1})^{O(1)}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=2^{(k\\epsilon^{-1})^{O(1)}}+k\\ell_{n}{^{O(1)}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the first step follows from inequality (20), the second step follows from the fact that $|\\tilde{\\mathcal{C}}|\\leq$ $(k\\epsilon^{-1}\\log n)^{O(1)}$ (due to Lemma 3) and inequality (17), the third step follows from the fact that $\\tilde{d}=\\epsilon^{-O(1)}(\\log k+\\log\\log n)$ (due to Lemma 3), and the fourth step is due to Lemma 1 (with $s=n$ and $t=(k\\epsilon^{-1})^{O(1)})$ . This completes the proof of Lemma 10. \u25a1 ", "page_idx": 17}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: The paper\u2019s contributions and scope have been accurately claimed in the abstract and introduction. ", "page_idx": 18}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: The limitation of the algorithms in the paper is that they consider $k$ and $\\ell$ as fixed parameters, which has been clearly discussed in the paper. ", "page_idx": 18}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: All the proofs are clearly provided. ", "page_idx": 18}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 18}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 18}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 18}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 18}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 18}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics. ", "page_idx": 19}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The potential societal impacts and negative societal impacts are discussed in the last section of the paper. ", "page_idx": 19}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 19}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 19}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 19}, {"type": "text", "text": "Justification: The paper does not use existing assets. ", "page_idx": 19}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] Justification: The paper does not release new assets. ", "page_idx": 19}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 19}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 19}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 19}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 19}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 19}]