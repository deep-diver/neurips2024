[{"figure_path": "1GpY0hsv2w/figures/figures_1_1.jpg", "caption": "Figure 1: Different planners (denoted as green modules) in existing methods of ObjectNav. (a) represents end-to-end learning methods, and (b) refers to modular methods. (c) denotes the proposed trajectory diffusion, which plans future sequence trajectory based on geometric semantic map.", "description": "This figure illustrates three different types of planners used in Object Goal Navigation. (a) shows an end-to-end learning method with implicit memory that makes single-step planning decisions based on current observations. (b) shows a modular method with geometric memory which also uses single-step planning, using a semantic map to help avoid redundant exploration. (c) introduces the proposed trajectory diffusion model, which leverages a sequence planner to generate a temporally coherent trajectory conditioned on the semantic map and goal.", "section": "1 Introduction"}, {"figure_path": "1GpY0hsv2w/figures/figures_3_1.jpg", "caption": "Figure 2: Frameworks of the trajectory diffusion (T-Diff). (a) refers to the process of dividing the collected data into data pairs. (b) shows the implementation structure of T-Diff. (c) illustrates the navigation process guided by trajectories generated by T-Diff.", "description": "This figure shows the architecture of the proposed Trajectory Diffusion model for object goal navigation. (a) illustrates how the collected data is divided into pairs of semantic maps and corresponding trajectory segments. (b) details the architecture of the T-Diff model, showing the input (noised latent trajectory), the transformer blocks used for processing, and the output (denoised trajectory).  The model incorporates a multi-head cross-attention mechanism to condition the trajectory generation on the semantic map and target object. (c) demonstrates how the T-Diff model is integrated into the navigation process, showing how the generated trajectory guides the agent.", "section": "4 Trajectory Diffusion"}, {"figure_path": "1GpY0hsv2w/figures/figures_5_1.jpg", "caption": "Figure 3: The impact of three hyper-parameters. (a) represents the impact of the length of generated trajectories k during training. (b) reflects the impact of maximum noise schedule Tmax in diffusion and denoising process of T-diff. (c) shows the impact of selected proportion of generated trajectory length for navigation performance.", "description": "This figure shows the impact of three hyperparameters on the performance of the Trajectory Diffusion model.  Specifically, it shows how varying the length of generated trajectories (k), the maximum noise schedule during training (Tmax), and the proportion of the generated trajectory used for navigation (kg/k) affects success rate (SR), success weighted by path length (SPL), mean squared error (MSE) between generated and actual trajectories, and distance to goal (DTS).", "section": "5.2 Evaluation Results"}, {"figure_path": "1GpY0hsv2w/figures/figures_8_1.jpg", "caption": "Figure 6: More visualizations. At each timestep, we visualize RGB observation, local semantic map along with the previous path and the generated future trajectory. Note that the target object location is marked with a circle.", "description": "This figure visualizes the navigation process using the proposed Trajectory Diffusion model.  It shows a series of snapshots at different timesteps (t=0, t=22, t=39, t=76, t=89). Each snapshot includes:\n\n1. **RGB Observation:** The agent's first-person view of the environment.\n2. **Local Map with Denoised Trajectory:** A top-down view of the local semantic map, highlighting the agent's path (blue) and the generated trajectory (red) towards the target object (green circle). The trajectory is generated by the Trajectory Diffusion model.\n3. **Goal:**  The location of the target object.\n\nThe figure demonstrates how the model generates trajectories that effectively guide the agent to the goal, even when the target is partially or fully occluded.", "section": "A.1 Experiments Setup"}, {"figure_path": "1GpY0hsv2w/figures/figures_16_1.jpg", "caption": "Figure 6: More visualizations. At each timestep, we visualize RGB observation, local semantic map along with the previous path and the generated future trajectory. Note that the target object location is marked with a circle.", "description": "This figure shows four examples of navigation processes guided by the proposed trajectory diffusion model. Each row displays a different navigation episode. For each episode, the left side shows the agent's first-person RGB observation at multiple time steps during the navigation. The middle section displays the generated trajectory by the trajectory diffusion model superimposed on the local semantic map at the same time steps. The right side displays the ground truth map along with the actual trajectory of the agent and the location of the target object. The figure demonstrates how the generated trajectory effectively guides the agent towards the target, even when the target remains unseen in the early stage.", "section": "A.1 Experiments Setup"}]