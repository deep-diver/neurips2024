[{"figure_path": "V3QZCM1AQv/figures/figures_2_1.jpg", "caption": "Figure 1: (a) and (b): REBORN iterates between using RL to train the segmentation model and using adversarial training to train the phoneme prediction model. (c): An illustration of the segmentation/boundary merging. 1 means the start of a segment while 0 is not. Given the original segmentation and the predicted phoneme sequence, we merge the segments that result in the same phoneme prediction into the same segment, yielding the merged boundary.", "description": "This figure illustrates the iterative training process of REBORN.  (a) shows the training of the segmentation model using reinforcement learning (RL) to learn better segment boundaries.  The reward function guides the model towards segmentations that result in lower perplexity phoneme predictions. (b) illustrates the training of the phoneme prediction model using adversarial training (GAN).  The phoneme predictor takes the speech features, segmented by the segmentation model, as input and outputs a phoneme transcription.  (c) depicts the boundary merging step. Segments with identical phoneme predictions are merged to create more coherent segmental structures. This iterative process refines both the segmentation and phoneme prediction models, ultimately improving the overall unsupervised ASR performance.", "section": "3 Method: REBORN"}, {"figure_path": "V3QZCM1AQv/figures/figures_8_1.jpg", "caption": "Figure 2: PER across training epochs on the test-clean split of LibriSpeech. BC pretraining speeds up convergence and raises performance.", "description": "This figure shows the phoneme error rate (PER) on the LibriSpeech test-clean set over training epochs.  Two lines are plotted: one for a segmentation model that was pre-trained using behavior cloning (BC) and one trained from scratch. The BC pre-trained model shows faster convergence to a lower PER, indicating that the behavior cloning step significantly improves the performance of the segmentation model.", "section": "5.3 Ablation Study"}, {"figure_path": "V3QZCM1AQv/figures/figures_8_2.jpg", "caption": "Figure 3: PER of each stage during REBORN's two-stage iterative training on the test-clean split of LibriSpeech. St.: stage; w2vu: wav2vec-U.", "description": "This figure shows the phoneme error rate (PER) at different stages of the REBORN model training process on the LibriSpeech test-clean dataset.  The x-axis represents the different stages (initialization with wav2vec-U, then iterative training of segmentation model and phoneme prediction model), and the y-axis shows the PER.  The figure shows a significant decrease in PER after the first iteration of training, and further improvement with each subsequent iteration, indicating the effectiveness of the iterative training approach.", "section": "5.3 Iterative Training"}]