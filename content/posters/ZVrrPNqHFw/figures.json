[{"figure_path": "ZVrrPNqHFw/figures/figures_2_1.jpg", "caption": "Figure 1: Precision of detecting bias-conflicting samples among Loss, Gradient Norm, Influence function on training set (IFtrain), and Self-Influence (SI). The precision is evaluated with the ground truth number of bias-conflicting samples. The average precision of loss value, gradient norm, SI, and IF are presented in bars across three runs.", "description": "This figure compares the precision of four different methods in detecting bias-conflicting samples across four different datasets: CMNIST, CIFAR10C, BFFHQ, and Waterbird.  The methods compared are using the loss value, gradient norm, influence function on the training set, and self-influence. The precision is calculated against a ground truth of bias-conflicting samples.  The bar chart shows the average precision across three runs for each method and dataset.", "section": "3 An analysis of Self-Influence in bias-conflicting sample detection"}, {"figure_path": "ZVrrPNqHFw/figures/figures_3_1.jpg", "caption": "Figure 2: The overview of our method. We compute Bias-Conditioned Self-Influence (BCSI) of the training data and construct a small but concentrated pivotal set with a high ratio of bias-conflicting samples. Then, we remedy biased models through fine-tuning that utilizes the pivotal set and remaining samples.", "description": "This figure illustrates the proposed method's workflow. First, Bias-Conditioned Self-Influence (BCSI) is calculated for the training data to identify bias-conflicting samples. A pivotal set is created using these samples, which is then used in a fine-tuning process along with the remaining samples to remedy the biased model. The method aims to improve the precision of detecting bias-conflicting samples and effectively rectify biased models.", "section": "3 An analysis of Self-Influence in bias-conflicting sample detection"}, {"figure_path": "ZVrrPNqHFw/figures/figures_4_1.jpg", "caption": "Figure 3: A comprehensive analysis of Influence function on the training set (IFtrain) and Self-Influence (SI) in biased datasets. Figure 3(a) shows the classification accuracy of bias-aligned and bias-conflicting samples over training epochs. Figure 3(b) and 3(c) depict the detection precision of IFtrain and SI across training epochs for varying ratios of bias-conflicting samples in CIFAR10C. Figure 3(d) shows histograms of sample distribution in CIFAR10C (1%) and each bar indicates the number of samples within a specific range.", "description": "This figure presents a comprehensive analysis of influence functions on biased datasets.  It shows how classification accuracy changes over training epochs for both bias-aligned and bias-conflicting samples. It also compares the detection precision of two influence function methods (IFtrain and SI) under varying ratios of bias-conflicting samples in the CIFAR10C dataset. Finally, it visualizes the distribution of self-influence scores for both bias-aligned and bias-conflicting samples using histograms.", "section": "3 An analysis of Self-Influence in bias-conflicting sample detection"}, {"figure_path": "ZVrrPNqHFw/figures/figures_4_2.jpg", "caption": "Figure 1: Precision of detecting bias-conflicting samples among Loss, Gradient Norm, Influence function on training set (IFtrain), and Self-Influence (SI). The precision is evaluated with the ground truth number of bias-conflicting samples. The average precision of loss value, gradient norm, SI, and IF are presented in bars across three runs.", "description": "This figure compares the precision of four different methods in detecting bias-conflicting samples: Loss, Gradient Norm, Influence Function on the training set (IFtrain), and Self-Influence (SI).  The precision is calculated against the ground truth number of bias-conflicting samples.  The bar chart displays the average precision across three separate runs for each method, showcasing their relative effectiveness in identifying such samples.  The datasets used are CMNIST (1%), CIFAR10C (1%), BFFHQ, and Waterbird.", "section": "3 An analysis of Self-Influence in bias-conflicting sample detection"}, {"figure_path": "ZVrrPNqHFw/figures/figures_5_1.jpg", "caption": "Figure 5: Example images from BFFHQ ranked within the top 100 by BCSI score. (a) and (b) are bias-conflicting samples with high and relatively lower BCSI scores, respectively. (c) is a bias-aligned sample with a high BCSI score, while (d) is a bias-aligned sample with a low BCSI score.", "description": "This figure shows example images from the Biased FFHQ dataset, which are ranked by their Bias-Conditioned Self-Influence (BCSI) scores.  The top row displays examples of images with high BCSI scores and the bottom row examples with low BCSI scores.  Within each row, the left side shows bias-conflicting samples and the right side bias-aligned samples.  The image examples visually illustrate how BCSI can better distinguish bias-conflicting samples (those contradicting the learned bias) from bias-aligned samples, which helps in identifying and rectifying model bias.", "section": "3.2 Bias-Conditioned Self-Influence (BCSI)"}, {"figure_path": "ZVrrPNqHFw/figures/figures_6_1.jpg", "caption": "Figure 6: Test accuracy under varying bias-conflicting ratios. Figure 6(a) shows the accuracy for last layer retraining across varying bias ratios in pivotal sets. Figure 6(b) depicts performance changes of last layer retraining and fine-tuning under diverse bias ratios. In Figure 6(c), our performance gains are provided. We present the average accuracy with the error bars indicating the standard error across three runs.", "description": "This figure shows the results of experiments conducted to evaluate the performance of the proposed method for rectifying biased models.  Three subfigures present different aspects of the model's performance across various conditions. (a) shows the accuracy of retraining only the last layer of the model using pivotal sets with different ratios of bias-conflicting samples. (b) compares the accuracy of retraining the last layer, fine-tuning the entire model, and using a vanilla model without any bias correction methods. This comparison is done across varying bias-conflicting ratios. (c) illustrates the performance gain achieved by incorporating the proposed method into SelecMix. The x-axis represents the bias conflicting ratio in all subfigures.  Error bars show standard errors across three runs.", "section": "4 Remedy biased models through fine-tuning"}, {"figure_path": "ZVrrPNqHFw/figures/figures_8_1.jpg", "caption": "Figure 1: Precision of detecting bias-conflicting samples among Loss, Gradient Norm, Influence function on training set (IFtrain), and Self-Influence (SI). The precision is evaluated with the ground truth number of bias-conflicting samples. The average precision of loss value, gradient norm, SI, and IF are presented in bars across three runs.", "description": "This figure compares the performance of four different methods (Loss, Gradient Norm, Influence Function on training set, and Self-Influence) for detecting bias-conflicting samples in four different datasets (CMNIST, CIFAR10C, BFFHQ, and Waterbird).  The precision of each method is shown as a bar chart, with error bars indicating the standard deviation across three runs. The results show that Self-Influence performs better than the other methods for detecting bias-conflicting samples in most cases.", "section": "3 An analysis of Self-Influence in bias-conflicting sample detection"}, {"figure_path": "ZVrrPNqHFw/figures/figures_15_1.jpg", "caption": "Figure 1: Precision of detecting bias-conflicting samples among Loss, Gradient Norm, Influence function on training set (IFtrain), and Self-Influence (SI). The precision is evaluated with the ground truth number of bias-conflicting samples. The average precision of loss value, gradient norm, SI, and IF are presented in bars across three runs.", "description": "This figure compares the precision of four different methods in detecting bias-conflicting samples across four different datasets: CMNIST, CIFAR10C, BFFHQ, and Waterbird.  The four methods are: Loss (using the loss value), Gradient Norm (using gradient norm), Influence Function on training set (IF_train), and Self-Influence (SI). The bar chart shows the average precision across three runs for each method and dataset. The results show that Self-Influence (SI) generally performs better than the other methods in identifying bias-conflicting samples, highlighting its potential use in addressing dataset bias.", "section": "3 An analysis of Self-Influence in bias-conflicting sample detection"}, {"figure_path": "ZVrrPNqHFw/figures/figures_16_1.jpg", "caption": "Figure 1: Precision of detecting bias-conflicting samples among Loss, Gradient Norm, Influence function on training set (IFtrain), and Self-Influence (SI). The precision is evaluated with the ground truth number of bias-conflicting samples. The average precision of loss value, gradient norm, SI, and IF are presented in bars across three runs.", "description": "This figure compares the performance of four different methods (Loss, Gradient Norm, Influence Function on training set, and Self-Influence) for detecting bias-conflicting samples in four different datasets (CMNIST, CIFAR10C, BFFHQ, and Waterbird). The precision of each method is calculated using the ground truth number of bias-conflicting samples.  The bars represent the average precision across three runs for each method and dataset.  The results show that Self-Influence generally performs better than the other methods for detecting bias-conflicting samples.", "section": "3 An analysis of Self-Influence in bias-conflicting sample detection"}, {"figure_path": "ZVrrPNqHFw/figures/figures_18_1.jpg", "caption": "Figure 6: Test accuracy under varying bias-conflicting ratios. Figure 6(a) shows the accuracy for last layer retraining across varying bias ratios in pivotal sets. Figure 6(b) depicts performance changes of last layer retraining and fine-tuning under diverse bias ratios. In Figure 6(c), our performance gains are provided. We present the average accuracy with the error bars indicating the standard error across three runs.", "description": "This figure displays the test accuracy under varying bias-conflicting ratios. The leftmost subplot (a) shows the accuracy for last layer retraining across various bias ratios in pivotal sets. The middle subplot (b) compares the performance changes of last layer retraining and fine-tuning. The rightmost subplot (c) presents performance gains. Error bars represent the standard error across three runs. It demonstrates the effectiveness of the proposed method for rectifying biased models under various bias-conflicting ratios, especially highlighting the complementary nature of fine-tuning to existing methods.", "section": "4 Remedy biased models through fine-tuning"}, {"figure_path": "ZVrrPNqHFw/figures/figures_18_2.jpg", "caption": "Figure 10: Performance of the other baselines and Ours on the CIFAR10C dataset with varying bias ratio. The performance of LfF [40] is shown in Figure 10(a). Figure 10(b) displays the performance of DFA [31].", "description": "This figure shows the performance comparison of applying the proposed method to other debiasing methods such as LfF and DFA with varying bias-conflicting ratios.  The x-axis shows the bias-conflicting ratio, while the y-axis represents the accuracy.  The results demonstrate the effectiveness of the proposed method across different bias levels when combined with existing approaches.", "section": "5.2 Results on highly biased scenarios"}, {"figure_path": "ZVrrPNqHFw/figures/figures_21_1.jpg", "caption": "Figure 1: Precision of detecting bias-conflicting samples among Loss, Gradient Norm, Influence function on training set (IFtrain), and Self-Influence (SI). The precision is evaluated with the ground truth number of bias-conflicting samples. The average precision of loss value, gradient norm, SI, and IF are presented in bars across three runs.", "description": "This figure compares the precision of four different methods (Loss, Gradient Norm, Influence Function on training set, and Self-Influence) in detecting bias-conflicting samples across four different datasets (CMNIST, CIFAR10C, BFFHQ, and Waterbird).  The precision is calculated using the ground truth number of bias-conflicting samples. The bar chart displays the average precision across three runs for each method and dataset.  The results show that Self-Influence generally outperforms the other methods.", "section": "3 An analysis of Self-Influence in bias-conflicting sample detection"}, {"figure_path": "ZVrrPNqHFw/figures/figures_23_1.jpg", "caption": "Figure 1: Precision of detecting bias-conflicting samples among Loss, Gradient Norm, Influence function on training set (IFtrain), and Self-Influence (SI). The precision is evaluated with the ground truth number of bias-conflicting samples. The average precision of loss value, gradient norm, SI, and IF are presented in bars across three runs.", "description": "This figure compares the precision of four different methods in detecting bias-conflicting samples across four datasets: CMNIST, CIFAR10C, FFHQ, and Waterbird.  The methods are: using the training loss, the gradient norm, the influence function evaluated on the training set (IF_train), and self-influence (SI). The precision is calculated using the ground truth number of bias-conflicting samples.  The bar graph shows the average precision across three runs for each method on each dataset.  It highlights that Self-Influence (SI) generally performs poorly compared to other methods.", "section": "3 An analysis of Self-Influence in bias-conflicting sample detection"}, {"figure_path": "ZVrrPNqHFw/figures/figures_23_2.jpg", "caption": "Figure 1: Precision of detecting bias-conflicting samples among Loss, Gradient Norm, Influence function on training set (IFtrain), and Self-Influence (SI). The precision is evaluated with the ground truth number of bias-conflicting samples. The average precision of loss value, gradient norm, SI, and IF are presented in bars across three runs.", "description": "This figure compares the precision of four different methods in detecting bias-conflicting samples across four different datasets. The methods are loss-based, gradient norm-based, influence function-based on the training set, and self-influence-based.  The results are presented as bar graphs showing the average precision for each method across three runs, highlighting the relative effectiveness of Self-Influence in identifying bias-conflicting samples compared to other methods.", "section": "3 An analysis of Self-Influence in bias-conflicting sample detection"}]