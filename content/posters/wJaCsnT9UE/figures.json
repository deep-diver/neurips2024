[{"figure_path": "wJaCsnT9UE/figures/figures_1_1.jpg", "caption": "Figure 1: (Sharpness-diversity trade-off and SharpBalance). (a) Caricature illustrating the sharpness-diversity trade-off that emerges in an ensemble's loss landscape induced by the Sharpness-aware Minimization (SAM) optimizer. We propose SharpBalance to address this trade-off. Each black circle represents an individual NN in a three-member ensemble. The distance between circles represents the diversity between NNs and the ruggedness of the basin represents the sharpness of each NN. (b) Theoretically proving the existence of the sharpness-diversity trade-off and improvement from SharpBalance, plotting the analytic representation of sharpness and diversity from Theorem 1 and Theorem 2 by changing the perturbation radius p of SAM. SharpBalance achieves a larger diversity for the same level of sharpness. (c) Empirical results of verifying sharpness-diversity trade-off improvement from SharpBalance. Each marker represents a three-member ResNet18 ensemble trained on CIFAR-10. Diversity is measured by the variance of individual models' predictions, and sharpness is measured by the adaptive worst-case sharpness, both defined in Section 2.", "description": "This figure illustrates the sharpness-diversity trade-off and how SharpBalance addresses it. (a) shows a caricature of the trade-off, where minimizing sharpness reduces diversity. (b) presents theoretical results showing SharpBalance improves the trade-off. (c) shows empirical results on CIFAR-10 confirming the improvement.", "section": "1 Introduction"}, {"figure_path": "wJaCsnT9UE/figures/figures_1_2.jpg", "caption": "Figure 1: (Sharpness-diversity trade-off and SharpBalance). (a) Caricature illustrating the sharpness-diversity trade-off that emerges in an ensemble's loss landscape induced by the Sharpness-aware Minimization (SAM) optimizer. We propose SharpBalance to address this trade-off. Each black circle represents an individual NN in a three-member ensemble. The distance between circles represents the diversity between NNs and the ruggedness of the basin represents the sharpness of each NN. (b) Theoretically proving the existence of the sharpness-diversity trade-off and improvement from SharpBalance, plotting the analytic representation of sharpness and diversity from Theorem 1 and Theorem 2 by changing the perturbation radius p of SAM. SharpBalance achieves a larger diversity for the same level of sharpness. (c) Empirical results of verifying sharpness-diversity trade-off improvement from SharpBalance. Each marker represents a three-member ResNet18 ensemble trained on CIFAR-10. Diversity is measured by the variance of individual models' predictions, and sharpness is measured by the adaptive worst-case sharpness, both defined in Section 2.", "description": "This figure illustrates the sharpness-diversity trade-off and how SharpBalance addresses it.  Subfigure (a) uses a visual metaphor to show how reducing sharpness (making the loss landscape smoother) can reduce diversity in an ensemble. Subfigure (b) presents theoretical results supporting this trade-off, showing that SharpBalance achieves better diversity for the same sharpness. Subfigure (c) validates these findings with empirical results from CIFAR-10.", "section": "1 Introduction"}, {"figure_path": "wJaCsnT9UE/figures/figures_4_1.jpg", "caption": "Figure 2: (Theoretical vs. Simulated sharpness-diversity trade-off). This figure illustrates the relationship between sharpness (upper and lower bounds) and diversity as predicted by Thereom 1 and as observed in simulations. Note that the upper and lower bounds correspond to the sharpness values plotted along the x-axis, with the upper bound positioned to the right and the lower bound to the left. Also, note that the bounds provided are for the expected sharpness, which means that random fluctuations can cause the simulation results to move beyond these bounds.", "description": "This figure empirically validates Theorem 1, which theoretically analyzes the sharpness-diversity trade-off.  It plots the simulated sharpness and diversity against each other. Each point represents a model trained using SAM (Sharpness-Aware Minimization) with a different perturbation radius (p). The plot shows that increasing sharpness reduces diversity, supporting the existence of this trade-off. The theoretical upper and lower bounds for sharpness derived in Theorem 1 are also plotted for comparison, showing a good match with empirical results.", "section": "3 Theoretical Analysis of Sharpness-diversity Trade-off"}, {"figure_path": "wJaCsnT9UE/figures/figures_5_1.jpg", "caption": "Figure 1: (Sharpness-diversity trade-off and SharpBalance). (a) Caricature illustrating the sharpness-diversity trade-off that emerges in an ensemble's loss landscape induced by the Sharpness-aware Minimization (SAM) optimizer. We propose SharpBalance to address this trade-off. Each black circle represents an individual NN in a three-member ensemble. The distance between circles represents the diversity between NNs and the ruggedness of the basin represents the sharpness of each NN. (b) Theoretically proving the existence of the sharpness-diversity trade-off and improvement from SharpBalance, plotting the analytic representation of sharpness and diversity from Theorem 1 and Theorem 2 by changing the perturbation radius p of SAM. SharpBalance achieves a larger diversity for the same level of sharpness. (c) Empirical results of verifying sharpness-diversity trade-off improvement from SharpBalance. Each marker represents a three-member ResNet18 ensemble trained on CIFAR-10. Diversity is measured by the variance of individual models' predictions, and sharpness is measured by the adaptive worst-case sharpness, both defined in Section 2.", "description": "This figure illustrates the sharpness-diversity trade-off and how SharpBalance addresses it.  Panel (a) shows a cartoon illustrating the trade-off:  reducing sharpness improves individual model performance but reduces diversity, hindering ensemble performance. SharpBalance aims to improve this. Panel (b) shows theoretical results supporting the existence of this trade-off, and how SharpBalance improves it. Panel (c) shows empirical results confirming these findings, showing improved ensemble performance with SharpBalance.", "section": "Sharpness-diversity trade-off"}, {"figure_path": "wJaCsnT9UE/figures/figures_6_1.jpg", "caption": "Figure 4: (Empirical observations of sharpness-diversity trade-off). The identified trade-off shows that while reducing sharpness enhances individual model performance, it concurrently lowers diversity and thus diminishes the ensemble improvement rate. First row: the color encoding represents the ensemble improvement rate (EIR) defined in equation (4), from red to blue means ensembling improvement decreases. Second row: the color encoding represents the individual ensemble member's OOD accuracy, from blue to red means individual performance becomes better. Each marker represents a three-member ResNet18 ensemble trained with SAM with a different perturbation radius.", "description": "This figure empirically validates the sharpness-diversity tradeoff.  It shows that while reducing sharpness improves individual model performance, it negatively affects ensemble performance by reducing diversity. This trade-off is demonstrated across three datasets (CIFAR-10, CIFAR-100, and TinyImageNet) using different metrics for measuring both sharpness and diversity.", "section": "4.2 Empirical validation of Sharpness-diversity trade-off"}, {"figure_path": "wJaCsnT9UE/figures/figures_7_1.jpg", "caption": "Figure 4: (Empirical observations of sharpness-diversity trade-off). The identified trade-off shows that while reducing sharpness enhances individual model performance, it concurrently lowers diversity and thus diminishes the ensemble improvement rate. First row: the color encoding represents the ensemble improvement rate (EIR) defined in equation (4), from red to blue means ensembling improvement decreases. Second row: the color encoding represents the individual ensemble member's OOD accuracy, from blue to red means individual performance becomes better. Each marker represents a three-member ResNet18 ensemble trained with SAM with a different perturbation radius.", "description": "This figure empirically validates the sharpness-diversity trade-off phenomenon.  It shows that while decreasing the sharpness of individual models (x-axis) improves their individual performance (bottom row), it also decreases the diversity among the models (y-axis). This diversity reduction negatively impacts the overall ensemble improvement rate (top row), illustrating the trade-off between sharpness and diversity.", "section": "4.2 Empirical validation of Sharpness-diversity trade-off"}, {"figure_path": "wJaCsnT9UE/figures/figures_7_2.jpg", "caption": "Figure 5: (Sharpness-diversity trade-off in models varying overparameterization levels). Different types of markers represent models with varying degrees of overparameterization, determined by changing the model width (a) or sparsity (b). Each marker represents a three-member ensemble trained with SAM with a different perturbation radius. The \u03b2 reflects the rate of decline in the trade-off curve, calculated via applying linear fitting over the ensembles at each level of overparameterization. A higher \u03b2 points to a steeper decline in the trade-off. Ensembles with narrower widths or increased sparsity display more pronounced trade-off effects. The model used in ResNet18 and the dataset is CIFAR-10.", "description": "This figure empirically validates the sharpness-diversity trade-off across different model architectures (varying width and sparsity).  It shows that reducing sharpness improves individual model performance, but simultaneously reduces diversity, leading to less ensemble improvement.  The trade-off is more pronounced in smaller or sparser models, illustrated by steeper curves.", "section": "4.2 Empirical validation of Sharpness-diversity trade-off"}, {"figure_path": "wJaCsnT9UE/figures/figures_7_3.jpg", "caption": "Figure 6: (System diagram of SharpBalance). Each ensemble member fe, optimizes the sharpness reduction objective on subset Dsam and the normal training objective on DNormal. Dsam is formed by selecting data samples from D that significantly affect the loss landscape sharpness of other ensemble members.", "description": "This figure illustrates the SharpBalance algorithm.  It divides the training dataset into two subsets for each ensemble member: a \"sharpness-aware set\" and a \"normal set\".  The sharpness-aware set is constructed by identifying data points that significantly influence the sharpness of other ensemble members. The model is then trained to minimize sharpness on the sharpness-aware set and the standard training objective on the normal set.  This process aims to balance sharpness and diversity in the ensemble.", "section": "4.3 Our SharpBalance method"}, {"figure_path": "wJaCsnT9UE/figures/figures_8_1.jpg", "caption": "Figure 1: (Sharpness-diversity trade-off and SharpBalance). (a) Caricature illustrating the sharpness-diversity trade-off that emerges in an ensemble's loss landscape induced by the Sharpness-aware Minimization (SAM) optimizer. We propose SharpBalance to address this trade-off. Each black circle represents an individual NN in a three-member ensemble. The distance between circles represents the diversity between NNs and the ruggedness of the basin represents the sharpness of each NN. (b) Theoretically proving the existence of the sharpness-diversity trade-off and improvement from SharpBalance, plotting the analytic representation of sharpness and diversity from Theorem 1 and Theorem 2 by changing the perturbation radius p of SAM. SharpBalance achieves a larger diversity for the same level of sharpness. (c) Empirical results of verifying sharpness-diversity trade-off improvement from SharpBalance. Each marker represents a three-member ResNet18 ensemble trained on CIFAR-10. Diversity is measured by the variance of individual models' predictions, and sharpness is measured by the adaptive worst-case sharpness, both defined in Section 2.", "description": "This figure illustrates the sharpness-diversity trade-off and how SharpBalance addresses it.  Panel (a) shows a cartoon illustrating how minimizing sharpness (smoothness of the loss landscape) reduces diversity in an ensemble of neural networks. Panel (b) presents theoretical results supporting the existence of this trade-off and demonstrating that SharpBalance improves upon it. Panel (c) provides empirical validation of these findings on the CIFAR-10 dataset.", "section": "1 Introduction"}, {"figure_path": "wJaCsnT9UE/figures/figures_9_1.jpg", "caption": "Figure 4: (Empirical observations of sharpness-diversity trade-off). The identified trade-off shows that while reducing sharpness enhances individual model performance, it concurrently lowers diversity and thus diminishes the ensemble improvement rate. First row: the color encoding represents the ensemble improvement rate (EIR) defined in equation (4), from red to blue means ensembling improvement decreases. Second row: the color encoding represents the individual ensemble member's OOD accuracy, from blue to red means individual performance becomes better. Each marker represents a three-member ResNet18 ensemble trained with SAM with a different perturbation radius.", "description": "This figure empirically validates the sharpness-diversity trade-off phenomenon.  It shows that while reducing sharpness improves individual model performance (OOD accuracy), it reduces ensemble diversity, which negatively impacts the ensemble improvement rate (EIR). The results are shown across three datasets (CIFAR-10, CIFAR-100, TinyImageNet), each with different sharpness and diversity levels obtained by varying the perturbation radius (p) in SAM.", "section": "4.2 Empirical validation of Sharpness-diversity trade-off"}, {"figure_path": "wJaCsnT9UE/figures/figures_21_1.jpg", "caption": "Figure 2: (Theoretical vs. Simulated sharpness-diversity trade-off). This figure illustrates the relationship between sharpness (upper and lower bounds) and diversity as predicted by Thereom 1 and as observed in simulations. Note that the upper and lower bounds correspond to the sharpness values plotted along the x-axis, with the upper bound positioned to the right and the lower bound to the left. Also, note that the bounds provided are for the expected sharpness, which means that random fluctuations can cause the simulation results to move beyond these bounds.", "description": "This figure empirically validates Theorem 1 by comparing theoretical and simulated sharpness-diversity trade-off curves. Each point represents a model trained using SAM with different perturbation radius values. The plot shows the relationship between sharpness (x-axis) and diversity (y-axis). The theoretical upper and lower bounds of the sharpness are also plotted.  The close alignment between simulated and theoretical results demonstrates the accuracy of Theorem 1.", "section": "3 Theoretical Analysis of Sharpness-diversity Trade-off"}, {"figure_path": "wJaCsnT9UE/figures/figures_21_2.jpg", "caption": "Figure 9: (Theoretical vs. Simulated sharpness-diversity trade-off in SharpBalance) This figure illustrates the relationship between sharpness(upper bound) and diversity as predicted by Theorem 2 and as observed in simulations under different configurations. (a) validates our theoretical results by varying the perturbation radius p from 1.0 to 0.4. (b) validates the derivation by varying number of iterations k from 1 to 15. These results demonstrate the soundness of our derivation across a range of parameters.", "description": "This figure empirically validates the theoretical sharpness-diversity trade-off predictions from Theorem 2 of the paper.  Two subfigures are shown: one varies the perturbation radius (p) of the SAM optimizer, and the other varies the number of training iterations (k). The results show that the observed sharpness and diversity closely match the theoretical upper and lower bounds, supporting the theoretical analysis.", "section": "C.3 Empirical Verification of Theorem 1 and 2"}, {"figure_path": "wJaCsnT9UE/figures/figures_22_1.jpg", "caption": "Figure 1: (Sharpness-diversity trade-off and SharpBalance). (a) Caricature illustrating the sharpness-diversity trade-off that emerges in an ensemble's loss landscape induced by the Sharpness-aware Minimization (SAM) optimizer. We propose SharpBalance to address this trade-off. Each black circle represents an individual NN in a three-member ensemble. The distance between circles represents the diversity between NNs and the ruggedness of the basin represents the sharpness of each NN. (b) Theoretically proving the existence of the sharpness-diversity trade-off and improvement from SharpBalance, plotting the analytic representation of sharpness and diversity from Theorem 1 and Theorem 2 by changing the perturbation radius p of SAM. SharpBalance achieves a larger diversity for the same level of sharpness. (c) Empirical results of verifying sharpness-diversity trade-off improvement from SharpBalance. Each marker represents a three-member ResNet18 ensemble trained on CIFAR-10. Diversity is measured by the variance of individual models' predictions, and sharpness is measured by the adaptive worst-case sharpness, both defined in Section 2.", "description": "This figure illustrates the sharpness-diversity tradeoff and how SharpBalance addresses it. (a) shows a caricature of the tradeoff, where lower sharpness leads to lower diversity, which is undesirable for ensembles. (b) presents theoretical results supporting the existence of this tradeoff and showing that SharpBalance improves it. (c) presents empirical results demonstrating the improved sharpness-diversity tradeoff achieved by SharpBalance.", "section": "Sharpness-diversity trade-off"}, {"figure_path": "wJaCsnT9UE/figures/figures_23_1.jpg", "caption": "Figure 4: (Empirical observations of sharpness-diversity trade-off). The identified trade-off shows that while reducing sharpness enhances individual model performance, it concurrently lowers diversity and thus diminishes the ensemble improvement rate. First row: the color encoding represents the ensemble improvement rate (EIR) defined in equation (4), from red to blue means ensembling improvement decreases. Second row: the color encoding represents the individual ensemble member's OOD accuracy, from blue to red means individual performance becomes better. Each marker represents a three-member ResNet18 ensemble trained with SAM with a different perturbation radius.", "description": "This figure empirically validates the sharpness-diversity trade-off phenomenon.  It shows that reducing sharpness improves individual model performance (OOD accuracy) but simultaneously reduces diversity, leading to a decrease in the ensemble improvement rate. This is demonstrated across three datasets (CIFAR-10, CIFAR-100, TinyImageNet), using different sharpness levels achieved by varying the perturbation radius in the SAM optimizer.", "section": "4.2 Empirical validation of Sharpness-diversity trade-off"}, {"figure_path": "wJaCsnT9UE/figures/figures_24_1.jpg", "caption": "Figure 4: (Empirical observations of sharpness-diversity trade-off). The identified trade-off shows that while reducing sharpness enhances individual model performance, it concurrently lowers diversity and thus diminishes the ensemble improvement rate. First row: the color encoding represents the ensemble improvement rate (EIR) defined in equation (4), from red to blue means ensembling improvement decreases. Second row: the color encoding represents the individual ensemble member's OOD accuracy, from blue to red means individual performance becomes better. Each marker represents a three-member ResNet18 ensemble trained with SAM with a different perturbation radius.", "description": "This figure empirically validates the sharpness-diversity trade-off. It shows that reducing sharpness improves individual model performance but reduces diversity within the ensemble, ultimately leading to a decrease in ensemble improvement. The results are shown across three datasets (CIFAR-10, CIFAR-100, and TinyImageNet), illustrating the generality of the trade-off.", "section": "4.2 Empirical validation of Sharpness-diversity trade-off"}, {"figure_path": "wJaCsnT9UE/figures/figures_26_1.jpg", "caption": "Figure 4: (Empirical observations of sharpness-diversity trade-off). The identified trade-off shows that while reducing sharpness enhances individual model performance, it concurrently lowers diversity and thus diminishes the ensemble improvement rate. First row: the color encoding represents the ensemble improvement rate (EIR) defined in equation (4), from red to blue means ensembling improvement decreases. Second row: the color encoding represents the individual ensemble member's OOD accuracy, from blue to red means individual performance becomes better. Each marker represents a three-member ResNet18 ensemble trained with SAM with a different perturbation radius.", "description": "This figure empirically validates the sharpness-diversity trade-off phenomenon.  It shows that lowering sharpness improves individual model performance (OOD accuracy), but simultaneously reduces the diversity within the ensemble, negatively affecting the ensemble improvement rate (EIR). This trade-off is observed across three different datasets (CIFAR-10, CIFAR-100, TinyImageNet).", "section": "4.2 Empirical validation of Sharpness-diversity trade-off"}, {"figure_path": "wJaCsnT9UE/figures/figures_26_2.jpg", "caption": "Figure 1: (Sharpness-diversity trade-off and SharpBalance). (a) Caricature illustrating the sharpness-diversity trade-off that emerges in an ensemble's loss landscape induced by the Sharpness-aware Minimization (SAM) optimizer. We propose SharpBalance to address this trade-off. Each black circle represents an individual NN in a three-member ensemble. The distance between circles represents the diversity between NNs and the ruggedness of the basin represents the sharpness of each NN. (b) Theoretically proving the existence of the sharpness-diversity trade-off and improvement from SharpBalance, plotting the analytic representation of sharpness and diversity from Theorem 1 and Theorem 2 by changing the perturbation radius p of SAM. SharpBalance achieves a larger diversity for the same level of sharpness. (c) Empirical results of verifying sharpness-diversity trade-off improvement from SharpBalance. Each marker represents a three-member ResNet18 ensemble trained on CIFAR-10. Diversity is measured by the variance of individual models' predictions, and sharpness is measured by the adaptive worst-case sharpness, both defined in Section 2.", "description": "This figure illustrates the sharpness-diversity trade-off and how SharpBalance addresses it.  Panel (a) shows a cartoon illustrating how minimizing sharpness (making the loss landscape smoother) reduces diversity in an ensemble of neural networks. Panel (b) presents theoretical results supporting the existence of this trade-off and demonstrating that SharpBalance improves it.  Panel (c) shows empirical results verifying the trade-off and the effectiveness of SharpBalance on CIFAR-10.", "section": "1 Introduction"}, {"figure_path": "wJaCsnT9UE/figures/figures_27_1.jpg", "caption": "Figure 15: (Uncertainty metrics on CIFAR100-C). \u201cECE\u201d represents expected calibration error, and \u201cNLL\u201d represents negative log-likelihood. Both metrics are lower the better. The model architecture is ResNet-18. The uncertainty metrics demonstrate the superior performance of SharpBalance. x-axis represents the number of individual models in one ensemble.", "description": "This figure shows the expected calibration error (ECE) and negative log-likelihood (NLL) for different numbers of models in the ensemble.  Lower values for both ECE and NLL indicate better uncertainty estimates and improved model performance.  The results show that SharpBalance consistently outperforms both a standard deep ensemble and a deep ensemble trained with SAM (Sharpness-Aware Minimization), across all ensemble sizes. This supports the paper's claim that SharpBalance improves the sharpness-diversity tradeoff and leads to better calibrated uncertainty estimates.", "section": "F.5 Evaluation on uncertainty metrics"}, {"figure_path": "wJaCsnT9UE/figures/figures_27_2.jpg", "caption": "Figure 15: (Uncertainty metrics on CIFAR100-C). \u201cECE\u201d represents expected calibration error, and \u201cNLL\u201d represents negative log-likelihood. Both metrics are lower the better. The model architecture is ResNet-18. The uncertainty metrics demonstrate the superior performance of SharpBalance. x-axis represents the number of individual models in one ensemble.", "description": "This figure shows the expected calibration error (ECE) and negative log-likelihood (NLL) for different ensemble sizes using three different methods: Deep ensemble, Deep ensemble + SAM, and SharpBalance.  Both ECE and NLL are lower is better, indicating better uncertainty estimates.  The results show that SharpBalance consistently outperforms the other two methods across different ensemble sizes, indicating that it provides more reliable uncertainty estimates.", "section": "F.5 Evaluation on uncertainty metrics"}]