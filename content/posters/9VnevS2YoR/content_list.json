[{"type": "text", "text": "Vision Mamba Mender ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Jiacong $\\mathbf{H}\\mathbf{u}^{1,5}$ , Anda $\\mathbf{Cao}^{1}$ , Zunlei Feng2,3,4,\u2217 Shengxuming Zhang2, Yi Wang1, Lingxiang Jia1, Mingli Song1,3,4 ", "page_idx": 0}, {"type": "text", "text": "1College of Computer Science and Technology, Zhejiang University, 2School of Software Technology, Zhejiang University, 3State Key Laboratory of Blockchain and Data Security, Zhejiang University, 4Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security ", "page_idx": 0}, {"type": "text", "text": "{jiaconghu,caoanda,zunleifeng}@zju.edu.cn, {zsxm1998,y_w,lingxiangjia,brooksong}@zju.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Mamba, a state-space model with selective mechanisms and hardware-aware architecture, has demonstrated outstanding performance in long sequence modeling tasks, particularly garnering widespread exploration and application in the field of computer vision. While existing works have mixed opinions of its application in visual tasks, the exploration of its internal workings and the optimization of its performance remain urgent and worthy research questions given its status as a novel model. Existing optimizations of the Mamba model, especially when applied in the visual domain, have primarily relied on predefined methods such as improving scanning mechanisms or integrating other architectures, often requiring strong priors and extensive trial and error. In contrast to these approaches, this paper proposes the Vision Mamba Mender, a systematic approach for understanding the workings of Mamba, identifying flaws within, and subsequently optimizing model performance. Specifically, we present methods for predictive correlation analysis of Mamba\u2019s hidden states from both internal and external perspectives, along with corresponding definitions of correlation scores, aimed at understanding the workings of Mamba in visual recognition tasks and identifying flaws therein. Additionally, tailored repair methods are proposed for identified external and internal state flaws to eliminate them and optimize model performance. Extensive experiments validate the efficacy of the proposed methods on prevalent Mamba architectures, significantly enhancing Mamba\u2019s performance. The code is available at https://github.com/jiaconghu/Vision-Mamba-Mender. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Deep learning has demonstrated outstanding performance in various fields of artificial intelligence, with deep neural networks such as convolutional neural networks (CNNs) [1, 2] and Vision Transformer [3, 4] dominating the field of computer vision. However, the limited receptive field [5, 6] of CNNs and the quadratic computational complexity [7, 8] of Transformers constrain their further development. To overcome these limitations, an increasing number of studies have attempted to propose more advanced models [9\u201312]. Recently, Mamba [13], based on the state space model [11], has become the focus of these research efforts. Mamba can maintain nearly linear computational complexity while achieving a global receptive field, leading to outstanding performance. Consequently, it has been widely adopted in the field of computer vision [14\u201316]. ", "page_idx": 0}, {"type": "text", "text": "To enhance the performance of Mamba in visual tasks, existing works mainly focus on improving the architecture of Mamba [17\u201321]. For instance, Zhu et al.[17] proposed Vision Mamba, which adds branches to the original Mamba to simultaneously process image sequences in both forward and backward directions. Nearly simultaneously, Liu et al.[18] introduced VMamba, which adopts a four-way scanning strategy on top of the original Mamba to achieve a more comprehensive global receptive field. Other improvements include PlainMamba [19], Mamba-ND [20], SiMBA [21], and MambaMixer [22], all of which are variants of the original Mamba framework. ", "page_idx": 1}, {"type": "text", "text": "However, the aforementioned methods that optimize the Mamba model by improving its architecture are predefined and require strong prior knowledge and extensive trial and error. Additionally, Yu et al. [23] recently pointed out in their latest research that the current improvements made to Mambabased visual models are unnecessary for visual tasks, especially for visual recognition tasks. This opposing view underscores the necessity and urgency of further optimizing Mamba models in the field of computer vision. Hence, unlike the aforementioned pre-optimization methods, this paper attempts to analyze the working mechanism of Mamba from a post-perspective, identify the reasons of flaws leading to incorrect prediction results, and automatically rectify them to further enhance the performance of Mamba models. Moreover, this approach is applicable to all Mamba-like models. ", "page_idx": 1}, {"type": "text", "text": "Based on this idea, in this paper, we propose Vision Mamba Mender, a systematic approach to understanding the working mechanism of Mamba from a post-perspective, identifying flaws within it, and rectifying them to ultimately improve model performance. In understanding the operational mechanism of the Mamba model, we categorize the computational process of Mamba into external state interaction and internal state interaction. ", "page_idx": 1}, {"type": "text", "text": "Along these two perspectives of external and internal states, we introduce a state correlation analysis method tailored for Mamba to establish the correlation between hidden states and predicted results. Additionally, we define external state correlation scores and internal state correlation scores to quantitatively analyze differences in state correlations, revealing flaws existing respectively in the external and internal states. Specifically, external state flaws refer to instances where correct model predictions in certain states are predominantly associated with foreground regions, while incorrect predictions are primarily linked to background regions. Internal state flaws, on the other hand, pertain to cases where correct predictions within a class are correlated with the same regions within the state and exhibit low overall complexity, whereas incorrect predictions within the class focus on different internal regions of the state and demonstrate higher overall complexity. ", "page_idx": 1}, {"type": "text", "text": "Furthermore, we propose repair methods tailored for addressing both external state flaws and internal state flaws. Specifically, in the repair of external state flaws, we impose constraints on the external state correlations within certain modules of Mamba to increase their correlation with foreground information during prediction. On the other hand, in the repair of internal state flaws, we impose constraints on the internal state correlations within certain modules of Mamba to enhance their correlation with genuine class-specific internal information during prediction. Through extensive experimentation, we demonstrate that the proposed Vision Mamba Mender is applicable to state-ofthe-art Vision Mamba architectures. ", "page_idx": 1}, {"type": "text", "text": "The contributions of this paper are summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We propose a novel post-hoc optimization method named Vision Mamba Mender. This method is applicable to existing state-of-the-art Vision Mamba architectures, identifying and repairing flaws in the Mamba model\u2019s mechanisms for visual recognition tasks from a post-hoc perspective, ultimately enhancing the model\u2019s performance. \u2022 We introduce a state correlation analysis method and correlation score definitions for Mamba from both external and internal hidden state perspectives. These methods are used to identify flaws. Additionally, we introduce a state correlation constraint method to rectify these flaws. \u2022 Extensive experiments demonstrate that the proposed Vision Mamba Mender can effectively identify and repair flaws in the Mamba model without introducing additional parameters, significantly improving the performance of the Vision Mamba. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Mamba [13] is a novel and efficient sequence modeling model composed of multiple uniformly stacked Mamba blocks. Each Mamba block is constructed based on a selective state space model (SSM). Unlike the previous time-invariant SSM [11], it allows the parameters of the SSM to depend on the input, enhancing the model\u2019s expressive capacity. Furthermore, inspired by H3 [24] and Gated MLP [25], each Mamba block also incorporates modules such as causal convolution and gating mechanisms. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "As illustrated in Figure 1, given the hidden state h(n\u2113)\u22121of the i-th token in the input of the -th Mamba block, the computation of the hidden state $h_{n}^{(\\ell)}$ of the $i$ -th token in the output of the $\\ell_{}$ -th Mamba block is as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\boldsymbol{x}_{n}^{(\\ell)}=\\mathrm{SiLU}(h_{n}^{(\\ell)-1}\\cdot W_{x}^{(\\ell)}),}\\\\ &{\\boldsymbol{^{(\\ell)}},\\boldsymbol{c}_{2}^{(\\ell)},\\ldots,\\boldsymbol{c}_{n}^{(\\ell)}=\\mathrm{cacusal-ConvlD}(\\boldsymbol{x}_{1}^{(\\ell)},\\boldsymbol{x}_{2}^{(\\ell)},\\ldots,\\boldsymbol{x}_{n}^{(\\ell)}}\\\\ &{\\boldsymbol{^{(\\ell)}}=\\mathrm{selective-SSM}(\\boldsymbol{c}_{1}^{(\\ell)},\\boldsymbol{c}_{2}^{(\\ell)},\\ldots,\\boldsymbol{c}_{n}^{(\\ell)}),}\\\\ &{\\boldsymbol{z}_{n}^{(\\ell)}=\\mathrm{SiLU}(h_{n}^{(\\ell)-1}\\cdot W_{z}^{(\\ell)}),}\\\\ &{\\boldsymbol{y}_{n}^{(\\ell)}=(s_{n}^{(\\ell)}\\odot\\boldsymbol{z}_{n}^{(\\ell)})\\cdot W_{y}^{(\\ell)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mathrm{SiLU}(.)$ , causal-Conv1D(.), and selective- $\\cdot S\\mathbf{M}(.)$ denote the activation function, the casual 1D convolution, and the selective state model, respectively. $W_{x}^{(\\ell)},W_{z}^{(\\ell)}$ W z(\u2113 ), and W y(\u2113) are the projection matrices for the linear operations in the Mamba block, while $x,\\,z$ , $c,\\,s$ , and $y$ represent the intermediate states within the Mamba block. Finally, by applying a residual connection, the hidden state $h_{n}^{(\\ell)}$ is obtained as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\nh_{n}^{(\\ell)}=h_{n}^{(\\ell)-1}+y_{n}^{(\\ell)}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "In Eqn. (5), $\\odot$ denotes the Hadamard product. The term $z_{n}^{(\\ell)}$ (\u2113) in Eqn. (4) is computed through a separate pathway, serving as a gating mechanism to regulate the information flow in the main pathway. ", "page_idx": 2}, {"type": "image", "img_path": "9VnevS2YoR/tmp/0e92c6d0f59871caec87550bbbb568baf601d0050be04cf00fcdb735ec67da62.jpg", "img_caption": ["Figure 1: The computational process of a Mamba block. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "However, the original Mamba block is designed for one-dimensional sequences and is not suitable for handling multidimensional visual data, particularly for vision tasks requiring spatial awareness. Existing vision Mamba architectures enhance the basic Mamba block to accommodate these requirements, such as ViM [17], VMamba [18], PMamba [19], Mamba-ND [20], and SiMBA [21]. Unlike the predefined optimizations, our approach analyzes the working mechanism of the Mamba model post-hoc, identifying flaws and making repairs to further enhance the model\u2019s performance. ", "page_idx": 2}, {"type": "text", "text": "3 Where Do Flaws Occur? ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Identifying flaws in Mamba first requires an understanding of how Mamba operates. Some studies have provided empirical evidence to elucidate the mechanisms of Mamba models in the NLP domain, such as their contextual learning ability [26], factual recall capability [27], and interpretability [28]. However, elucidating the operational mechanisms of Mamba models in the visual domain remains a significant challenge. Ali et al. [29] established a connection between the selective SSM within the Mamba block and the self-attention mechanism in Transformers, allowing the selective SSM to represent the interaction process between any two states by constructing a self-attention matrix, which is utilized for image feature attribution. However, focusing solely on the selective SSM within the Mamba block is far from sufficient, as causal convolution, as shown in Eqn. (2), also participates in the interaction between states. Moreover, other computational modules within the Mamba block used for state interaction must also be considered. ", "page_idx": 2}, {"type": "text", "text": "In this section, we first investigate the working mechanisms of Mamba. We summarize the computational processes within Mamba as state interactions1. These interactions are categorized into external state interactions (where a state interacts with other states to form a new state, as shown in Eqn. (2) and (3) and internal state interactions (where a state interacts only with its internal information to form a new state, as shown in Eqn. (1), (4), and (5). We explore the operational mechanisms of Mamba from both the external and internal state interaction perspectives to identify flaws. ", "page_idx": 2}, {"type": "image", "img_path": "9VnevS2YoR/tmp/612dbdaa5e310850043e8bc964d8d908ffdbc46cb534e96b949afa83e584e89e.jpg", "img_caption": ["Figure 2: Visualization of the external state correlation $\\mathbf{e}^{(\\ell,s)}$ of the output $s_{n}^{(\\ell)}$ from the selectiveSSM module in different ViM [17] blocks. The depth of the ViM blocks increases from left to right. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "3.1 External State Correlation Analysis ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To understand the impact of external states on predictions within Mamba\u2019s working mechanisms, we propose the Grad-ESC method, inspired by Grad-CAM [30], which uses gradient and activation information to assess the importance of each neuron in decision-making. Grad-ESC calculates the correlation between external states and the model\u2019s prediction outcomes, termed external state correlation. Unlike the attention mechanism derived by Ali et al. [29], which applies only to the selective SSM module within the Mamba block, Grad-ESC allows for correlation analysis of the outputs from any module within the Mamba block. ", "page_idx": 3}, {"type": "text", "text": "Specifically, given the predictive distribution $p$ output by the Mamba model and the true class $k$ of the input sample, the calculation process for external state correlation $\\mathbf{e}^{(\\ell,s)}\\in\\mathbb{R}^{H\\times W}$ (where $H$ and $W$ represent the height and width of the input image) of the states $\\{s_{n}^{(\\ell)}\\}_{i=1}^{N}$ output by the selective SSM module (where $s_{n}^{(\\ell)}\\in\\mathbb{R}^{D}$ , $N$ and $D$ are the number and dimensionality of the states) is as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{e}^{(\\ell,s)}=\\mathcal{R}(\\overline{{s}}_{1}^{(\\ell)},\\overline{{s}}_{2}^{(\\ell)},\\dots,\\overline{{s}}_{N}^{(\\ell)}),\\,\\overline{{s}}_{n}^{(\\ell)}=\\mathbb{E}_{D}(g^{(\\ell,s)}\\odot s_{n}^{(\\ell)}),\\,g^{(\\ell,s)}=\\frac{1}{N}\\sum_{n=1}^{N}\\frac{\\partial p^{k}}{\\partial s_{n}^{(\\ell)}},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $g^{(\\ell,s)}\\in\\mathbb{R}^{D}$ represents the weights used to weight the state $s_{n}^{(\\ell)}$ along its dimensions based on gradient information, $\\mathbb{E}_{D}(\\cdot)$ denotes the average across all dimensions, $\\hat{s}_{n}^{(\\ell)}\\in\\mathbb{R}$ signifies the degree of correlation between the $n$ -th state and the prediction after integrating gradient information, and $\\mathcal{R}$ denotes the operation of reshaping and scaling to the original image size after retaining only the states corresponding to the image patches. ", "page_idx": 3}, {"type": "text", "text": "As illustrated in Figure 2, taking the state sn as an example, we visualize the external state correlations of $s_{n}^{(\\ell)}$ in different blocks of ViM [17]. It can be observed that the external state correlations of $s_{n}^{(\\ell)}$ vary across different blocks; some blocks exhibit correlations with foreground regions (such as the 1st layer), while others correlate with background regions (such as the 2nd layer). We consider correlations with the foreground to be interpretable, whereas correlations with the background are deemed uninterpretable. To quantify the interpretability of external state correlations, we propose the following definition of an external state correlation score based on commonly used interpretable evaluation methods such as perturbation test [29, 31] and segmentation test [32, 30, 33]: ", "page_idx": 3}, {"type": "text", "text": "Definition 1 (External Correlation Score). Given a pre-trained Mamba model $\\mathcal F(\\cdot)$ , an input image i, foreground annotations m of the input image, and external state correlation $\\mathbf{e}^{(\\ell,s)}$ computed through the proposed method, the external correlation score is defined as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathtt{E C S}(\\mathrm{e}^{(\\ell,s)})=\\underbrace{\\mathrm{softmax}(\\mathcal{F}(\\mathrm{e}^{(\\ell,s)+}\\odot i))}_{\\mathrm{perturbation\\,test}}\\times\\underbrace{\\mathrm{IoU}(\\mathrm{e}^{(\\ell,s)+},m)}_{\\mathrm{segmentation\\,test}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathbf{e}^{(\\ell,s)+}=\\mathbb{1}(\\mathbf{e}^{(\\ell,s)}>\\alpha)$ denotes the retention of important regions (those greater than the threshold $\\alpha$ ) in $\\mathbf{e}^{(\\ell,s)}$ , setting them to 1, and the removal of unimportant regions (those less than the threshold $\\alpha$ ), setting them to 0, for use in negative perturbation tests. Conversely, $\\mathbf{e}^{(\\ell,s)-}=$ $\\mathbb{1}(\\mathbf{e}^{(\\ell,s)}<\\alpha)$ denotes the removal of important regions and the retention of unimportant regions, for use in positive perturbation tests. Additionally, $\\mathtt{E C S}(\\mathbf{e}^{(\\ell,s)})\\in[0,+\\infty)$ , where a higher value indicates a higher correlation score. ", "page_idx": 3}, {"type": "image", "img_path": "9VnevS2YoR/tmp/518b6b8c9299f1aacdee635b3bef1a7ccc2431647a02cb90579091929687e76b.jpg", "img_caption": ["Figure 3: Visualization of the internal state correlations $\\mathbf{i}_{n}^{(\\ell,x)}$ of the output states $s_{n}^{(\\ell)}$ from the linear mapping module $w_{s}^{\\ell}$ in ViM [17] for samples of the same class. The horizontal axis represents the state dimensions, and the vertical axis represents the samples. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "3.2 Internal State Correlation Analysis ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "To comprehend the influence of internal states on prediction outcomes within the operational mechanism of Mamba, we introduce the Grad-ISC method. This method is utilized for computing the degree of correlation between the internal states and model predictions, termed as the state-internal correlation. ", "page_idx": 4}, {"type": "text", "text": "Specifically, given the predicted distribution $p$ outputted by the Mamba model and the true class $k$ of the input sample, let\u2019s take the example of the $n$ -th state $\\boldsymbol{x}_{n}^{\\ell}\\in\\mathbb{R}^{D}$ , which is the output of the linear mapping matrix $w_{x}^{\\ell}$ . The computation process for the corresponding Internal State Prediction Correlation $\\mathbf{i}_{n}^{(\\ell,x)}\\in\\mathbb{R}^{D}$ is as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbf{i}_{n}^{(\\ell,x)}=g_{n}^{(\\ell,x)}\\odot s_{n}^{(\\ell)},g_{n}^{(\\ell,x)}=\\frac{\\partial p^{k}}{\\partial x_{n}^{(\\ell)}},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where gn $g_{n}^{(\\ell,x)}\\,\\in\\,\\mathbb{R}^{D}$ denotes the weights applied to the dimensions of state $x_{n}^{(\\ell)}$ using gradient information. Similarly, the Grad-ISC method can perform internal state correlation analysis on the output of any module within the Mamba block. ", "page_idx": 4}, {"type": "text", "text": "Continuing with the example of state $x_{n}^{(\\ell)}$ , we visualize the internal state correlations $\\mathbf{i}_{n}^{(\\ell,x)}$ for samples belonging to the same class in ViM [17], as shown in Figure 3. It can be observed that for the same class, the regions of internal state correlation are relatively consistent. We posit that the more consistent and simpler the internal state correlation regions are for samples of the same class, the more interpretable they are. Conversely, the more inconsistent and complex the internal state correlation regions are for samples of the same class, the more difficult they are to interpret. To quantify the interpretability of internal state correlations, we propose a novel definition for the Internal Correlation Score: ", "page_idx": 4}, {"type": "text", "text": "Definition 2 (Internal Correlation Score). Given $J$ samples belonging to the same class and the internal state prediction correlatio n i(n\u2113,x)\u2208RD computed using the proposed method for a particular sample, the Internal Correlation Score is defined as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathrm{ICS}(\\mathbf{i}_{n}^{(\\ell,x)})=\\mathbb{E}_{D}(\\frac{1}{j}\\sum_{j=1}^{J}\\mathbf{i}_{n,j}^{(\\ell,x)+})\\times\\mathbb{E}_{D}(\\frac{\\frac{1}{J}\\sum_{j=1}^{J}\\mathbf{i}_{n,j}^{(\\ell,x)+}}{\\mathbf{i}_{n,1}^{(\\ell,x)+}\\oplus\\mathbf{i}_{n,2}^{(\\ell,x)+}\\oplus\\cdots\\oplus\\mathbf{i}_{n,J}^{(\\ell,x)+}})\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "wher  i(n\u2113,,jx) e represents the internal state correlation for the $j$ -th ample, $\\mathbf{i}_{n,j}^{(\\ell,x)+}\\,=\\,\\mathbb{1}(\\mathbf{i}_{n,j}^{(\\ell,x)}\\,>\\,\\beta)$ denotes the binarized internal correlation (set to 1 if greater than $\\beta$ , otherwise set to 0), $\\bigoplus$ denotes the XOR operation, and $\\mathbb{E}_{D}(\\cdot)$ denotes the average over all dimensions. Furthermore, $\\operatorname{ICS}(\\mathbf{i}^{(\\ell,x)})\\in$ $\\lbrack0,+\\infty)$ , where a higher value indicates a higher correlation score. ", "page_idx": 4}, {"type": "text", "text": "3.3 Identifying Flaw through Correlation Analysis ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "To analyze flaws within the Mamba model, we examined the external and internal state correlation scores under different conditions using the ViM model and the ImageNet-10 dataset. This analysis allowed us to observe variations in correlation relationships across different states. ", "page_idx": 4}, {"type": "image", "img_path": "9VnevS2YoR/tmp/9aa48076ea750d28adbb61c8c4ed0167c23c7d4b110e5470a9c159a6a9bd4f09.jpg", "img_caption": ["Figure 4: Comparison of external and internal state correlation scores across different blocks in the Mamba model between simple and difficult samples. (a) and ${\\bf(b)}$ show the external state correlation scores for simple and difficult samples, respectively. (c) and (d) present the internal state correlation scores for simple and difficult samples, respectively. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Flaws in External State Correlation. To uncover flaws in the external correlations of states, we compare the scores of external state correlations in the Mamba model between simple and difficult samples, as illustrated in Fig. 4(a) and (b). For simple samples, it can be observed that across different blocks, the external correlation scores of states $x_{n}^{(\\ell)},\\dot{c}_{n}^{(\\ell)},s_{n}^{(\\ell)}$ , and $z_{n}^{(\\ell)}$ are all better than those of state $y_{n}^{(\\ell)}$ , especially in deeper blocks. Furthermore, by comparing simple samples (a) with difficult samples (b), it can be noted that the external correlation scores of all states in all blocks have decreased. This indicates that for difficult samples, the Mamba model tends to associate certain incomprehensible regions in the external states. ", "page_idx": 5}, {"type": "text", "text": "Flaws in Internal State Correlation. To unveil patterns in internal state correlations and detect flaws within them, we also conducted a comparative analysis of the internal correlation scores within the Mamba model, as depicted in Figure 4(c) and (d). For both simple and difficult samples, the internal correlation score of state $x_{n}^{(\\bar{\\ell})}$ is generally better than that of other states. Furthermore, simultaneous comparison of simple and difficult samples reveals a decrease in the internal correlation scores of all states, including state $x_{n}^{(\\ell)}$ . This suggests that for difficult samples, the Mamba model tends to correlate with some incomprehensible regions within the internal states. ", "page_idx": 5}, {"type": "text", "text": "4 How to Repair Flaws? ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In principle, repairing flaws within the model\u2019s internals can enhance Mamba\u2019s decision-making process and improve its performance. However, there has been limited research specifically addressing such issues in Mamba models, particularly when applied in the domain of visual processing. Therefore, in this section, we investigate post-hoc flaw repair in the Mamba model from two perspectives: external state correlation and internal state correlation. ", "page_idx": 5}, {"type": "text", "text": "4.1 External State Correlation Repair ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To repair flaws related to external state correlations, it is essential to identify the key components within the Mamba block that need fixing. In flaw identification regarding external state correlations, it is observed that the states $x_{n}^{(\\ell)}$ , $c_{n}^{(\\ell)}$ , $\\bar{s_{n}^{(\\ell)}}$ , and $z_{n}^{(\\ell)}$ exhibit flaws when predicting difficult samples. For these states, the external correlation scores for simple samples are higher than those for difficult samples. This implies that the model primarily correlates with foreground regions in correct predictions and with background regions in incorrect predictions. Furthermore, considering that external state interactions occur only within Conv and SSM modules (as indicated by Eqn.(2) and Eqn.(3)), we empirically suggest that the Conv and SSM components are crucial for influencing the model\u2019s anomalous decisions. Theoretically, it is also feasible to apply external flaw repair to other states. ", "page_idx": 5}, {"type": "text", "text": "We focus on repairing the external correlation flaws of the states $c_{n}^{(\\ell)}$ and $s_{n}^{(\\ell)}$ output by the Conv and SSM modules in the deeper blocks. Specifically, we first identify difficult samples from the training set and then constrain the external correlations of the hidden states $c_{n}^{(\\ell)}$ and $\\bar{s}_{n}^{(\\ell)}$ using foreground annotations $m$ : ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname{Loss}_{\\mathbf{e}}=\\mathbb{E}_{H W}(\\mathbf{e}^{(\\ell,c)+}\\odot m)+\\mathbb{E}_{H W}(\\mathbf{e}^{(\\ell,s)+}\\odot m),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\mathbb{E}_{H W}$ denotes the averaging operation over the two-dimensional matrix. It is important to note that during backpropagation, each term in the computational graph of $\\mathrm{Loss}_{\\mathbf{e}}$ is differentiable, which involves second-order gradients as specified in Eqn. (7). The complete loss function, combining with the original task loss, is formulated as follows: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathrm{Loss}=\\mathrm{Loss}_{\\mathbf{ce}}+\\lambda\\mathrm{Loss}_{\\mathbf{e}},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\mathrm{Loss}_{\\mathbf{ce}}$ denotes the cross-entropy loss for the image recognition task, and $\\lambda$ serves to balance the magnitudes of the respective loss components. ", "page_idx": 6}, {"type": "text", "text": "4.2 Internal State Correlation Repair ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Similarly, when identifying flaws related to internal state correlations, it is observed that states in different blocks exhibit flaws when predicting difficult samples. For instance, the internal correlation scores of state $x_{n}^{(\\ell)}$ for simple samples are higher than those for difficult samples. This suggests that in predictions biased toward correctness within a class, the model aligns with internally consistent regions of the state, characterized by lower overall complexity. Conversely, in predictions biased toward incorrectness within a class, the model tends to focus on internally inconsistent regions of the state with higher overall complexity. In our experiments, we consider the linear mapping $w_{s}^{\\ell}$ within deeper blocks as a critical component influencing the model\u2019s predictions. However, theoretically, it is also feasible to apply internal flaw repair to other states. ", "page_idx": 6}, {"type": "text", "text": "We focus on repairing the internal correlation flaws of the states $x_{n}^{(\\ell)}$ output by the linear mapping $w_{s}^{\\ell}$ within deeper blocks. Specifically, we first select $J$ simple samples for each class from the training set and create corresponding internal correlation templates $\\begin{array}{r}{\\hat{\\mathbf{i}}_{n}^{(\\ell,s)+}=\\frac{1}{J}\\sum_{j=1}^{J}\\mathbf{i}_{n,j}^{(\\ell,x)+}}\\end{array}$ i(\u2113,x)+for each class. We then utilize these templates to constrain the internal correlations of $x_{n}^{(\\ell)}$ : ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname{Loss}_{\\mathbf{i}}=\\mathbb{E}_{D}(\\mathbf{i}_{n}^{(\\ell,x)+}\\odot\\widehat{\\mathbf{i}}_{n}^{(\\ell,s)+}).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Similarly, during backpropagation, each term in the computational graph of Lossi is also differentiable, which involves second-order gradients as specified in Eqn. (9). Combined with the loss for the original task, the complete loss is as follows: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathrm{Loss}=\\mathrm{Loss}_{\\bf c e}+\\gamma\\mathrm{Loss}_{\\bf i},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\gamma$ is a balancing factor to adjust the scale between loss functions. ", "page_idx": 6}, {"type": "text", "text": "It is important to note that external and internal state corrections represent two distinct perspectives, allowing these two methods to be used orthogonally. To maximize flaw repair, we recommend sequentially repairing external flaws (Eqn. (11)) followed by internal flaws (Eqn. (13)). ", "page_idx": 6}, {"type": "text", "text": "4.3 Results of Flaw Repair ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We evaluated the proposed flaw repair method on five state-of-the-art Mamba models for visual tasks, including ViM-T [17], VMamba-T [18], SiMBA-S [21], EfficientVMamba-T (EMamba-T) [34], and LocalVim-T [35]. To ensure smooth operation of the Mamba models within limited computational resources, we modified certain model parameters, such as the number of blocks and the dimensionality of hidden states. Additionally, we conducted experiments on three scales of the ImageNet [36] dataset: ImageNet-50, ImageNet-300, and ImageNet-1K. To obtain the image foreground annotations $m$ as defined in Definition 1 from the ImageNet dataset, we utilized annotations from the ImageNet-S dataset [37]. These annotations correspond to those used during training, covering all 50 classes in ImageNet-50, 300 classes in ImageNet-300, and 919 classes in ImageNet-1K, with an average of 10 foreground-labeled samples per class. Further details on experimental settings are provided in Appendix B. ", "page_idx": 6}, {"type": "image", "img_path": "9VnevS2YoR/tmp/218d12f4fcef1af541bbec89a37fcd11d3abe6f8ece981786c9a8937b0332fdd.jpg", "img_caption": ["Figure 5: Comparison of external and internal state correlation scores across different blocks in the Mamba model before and after flaw repair. (a) and ${\\bf(b)}$ show the external and internal state correlation scores before flaw repair, respectively. (c) and (d) present the external and internal state correlation scores after flaw repair, respectively. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Table 1: Comparison of model accuracy after external state flaw repair for different states. Taking $x_{n}^{(\\ell)}\\!:$ \u2019 as an example, it represents the external flaw repair of state $\\bar{x}_{n}^{(\\ell)}$ . The results in the second row of the table correspond to external flaw repair, while the third row presents the outcomes of internal flaw repair. The experiment was conducted within the last block of the ViM model, using the ImageNet-50 dataset. ", "page_idx": 7}, {"type": "table", "img_path": "9VnevS2YoR/tmp/f7d46f1a1a7223c10055ec2c526fb50ed0a05792cadea450af4fdf8795d5075e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Comparing State Correlation Scores Before and After Repair. To validate the effectiveness of the flaw repair methods, we compared the internal and external state correlation scores of difficult samples before and after flaw repair, as shown in Figure 5. It can be observed that the proposed flaw repair methods effectively enhance the correlation scores of the Mamba model, thereby improving the predicted correlation regions within both internal and external states. Specifically, for the ViM model, after external state flaw repair, the external correlation scores of the states $c_{n}^{(\\ell)}$ are significantly higher than before repair. Similarly, after internal state flaw repair, the internal correlation scores of the states xn are also notably higher than before repair. ", "page_idx": 7}, {"type": "text", "text": "Repairing External and Internal Flaws in Different States. As shown in Table 1 (second row), we conducted experiments on external flaw repair for different states within the same block. The results indicate that simultaneously performing external flaw repair on states $c_{n}^{(\\ell)}$ and $s_{n}^{(\\ell)}$ leads to an improvement in model accuracy. This aligns with our findings in the main text regarding flaw detection, where states $x_{n}^{(\\ell)}$ , $c_{n}^{(\\ell)}$ , $s_{n}^{(\\ell)}$ , and $z_{n}^{(\\ell)}$ exhibit flaws when predicting challenging samples. Furthermore, since the Conv and SSM modules in each block facilitate external interactions, applying external flaw repair to states $c_{n}^{(\\ell)}$ and $s_{n}^{(\\ell)}$ is effective. ", "page_idx": 7}, {"type": "text", "text": "Similarly, as illustrated in Table 1 (third row), we performed experiments on internal flaw repair for different states within the same block. The results demonstrate that individually addressing internal flaws in state xn also results in improved model accuracy. This supports our earlier findings regarding flaw detection, where state $x_{n}^{(\\ell)}$ shows flaws when predicting challenging samples, thus validating the effectiveness of internal flaw repair for state $x_{n}^{(\\ell)}$ . ", "page_idx": 7}, {"type": "text", "text": "Repairing SOTA Vision Mamba Models. As shown in the Table 2, we validated the proposed flaw repair methods on various mainstream Vision Mamba models. It can be observed that regardless of whether external or internal state flaw repair is performed, the accuracy of the repaired models exceeds that of the original models. Specifically, for external state flaw repair, on ImageNet-50, the accuracy of VMamba increased by $1.12\\%$ after flaw repair, and the accuracy of SiMBA-S increased by $3.16\\%$ . For internal state flaw repair, on ImageNet-1K, the accuracy of ViM increased by $1.15\\%$ after flaw repair, and the accuracy of LocalViM increased by $2.20\\%$ . It is worth noting that external state flaw repair and internal state flaw repair can be orthogonal. For example, on ImageNet-50, simultaneously performing external state flaw repair and internal state flaw repair on ViM increased the accuracy by $2.04\\%$ and $1.76\\%$ , respectively, compared to performing each repair method individually. This resulted in an overall improvement of $3.24\\%$ compared to the original model. ", "page_idx": 7}, {"type": "table", "img_path": "9VnevS2YoR/tmp/91d08b2f56df27d081e1c8717caa1c69ccf58e1f6e7a3989f508de6d90ecf854.jpg", "table_caption": ["Table 2: Comparison of the accuracy of the SOTA Vision Mamba model after flaw repair. Base\u2019 denotes the original model, $\\mathbf{+Ext}^{\\bullet}$ , $+\\mathrm{Int}'$ , and $+\\mathrm{All}^{\\ast}$ represent models after external flaw repair, internal flaw repair, and simultaneous external and internal flaw repair, respectively.2 "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "5 Related Works ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Model Optimization. Optimizing model performance through various prior designs or theoretical derivations has always been a pursuit in the field of artificial intelligence. Existing methods for optimizing the Mamba model, especially when applied to visual tasks, mainly involve adjusting the network architecture [17\u201322]. For instance, improvements have been made through the bidirectional scanning mechanism [17], cross-scanning mechanism [18], continuous 2D scanning mechanism [19], and incorporating new channel modeling techniques [21]. However, these enhancements are predesigned and require extensive trial and error. For a more detailed understanding of Mamba\u2019s applications in computer vision, we recommend readers refer to recent surveys by Zhang et al. [14] and $\\mathrm{Xu}$ et al. [16]. So far, there has been no research focusing on post-hoc optimization to correct internal flaws within the Mamba model to improve its performance. Optimizing models beyond Mamba, such as Convolutional Neural Networks [1, 38] and Transformers [3, 39], is also primarily achieved through architectural improvements [2, 40\u201342, 4], feature enhancement [43\u201346], or some post-hoc debugging methods [47\u201350]. However, these approaches either cannot be directly applied to a brand-new Mamba model or do not involve post-hoc optimization. In summary, unlike the aforementioned studies, the proposed Vision Mamba Mender is the first framework dedicated to post-hoc analysis and optimization of the Mamba model. Its aim is to rectify flaws within Mamba models in the domain of vision, thereby further enhancing the performance of Mamba models. ", "page_idx": 8}, {"type": "text", "text": "Model Explanation. Enhancing model transparency and trustworthiness through research on model explainability has been a major focus in the field of artificial intelligence. In the context of Mamba model explainability, most studies have primarily concentrated on the model\u2019s context learning capabilities [26], factual recall abilities [27], and comparisons of the explainability between Mamba and previous models [28]. These studies do not address the identification of flaws in the Mamba model\u2019s mechanisms and are focused on natural language processing (NLP), leaving a gap in their application to visual tasks. In the realm of computer vision, Ali et al.[29] established a connection between the selective SSM in the Mamba block and the self-attention mechanism in Transformers. They developed a feature attribution method for Mamba based on AttentionRollout[51] and Transformer-Attribution [31], which can be used for image feature attribution. However, this method is limited to the selective SSM module and does not consider or apply to other modules within the Mamba model. In research on model explainability beyond the Mamba model, a plethora of methods have emerged, including activation-based methods [52\u201356], gradient-based methods [30, 57, 33], LRP-based methods [58, 59, 31], and perturbation-based methods [60\u201362]. However, most of these explainability methods are designed for specific network architectures and may not be directly applicable to Mamba. Inspired by Grad-CAM [30], this paper introduces GradESC and Grad-ISC methods tailored for the Mamba\u2019s external and internal states, respectively. These methods effectively establish the correlation between the model\u2019s states and predictions, providing simple yet powerful analytical tools for identifying flaws in the Mamba model\u2019s mechanisms. ", "page_idx": 9}, {"type": "text", "text": "6 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "As one of the most prominent models today, Mamba has found widespread application in the field of computer vision. While attitudes towards its utilization in visual tasks may vary, it does not impede the exploration of its novel internal operational mechanisms. On the contrary, it urges further research into optimizing the performance of Mamba models applied in visual tasks. Moreover, at this juncture, considering the potential changes in future architectures, devising a set of architecture-agnostic post-optimization methods becomes crucial. ", "page_idx": 9}, {"type": "text", "text": "However, in this work, we only analyzed the overall operational mechanisms of each module within Mamba, without delving into the internal details of each module. For instance, we hypothesize that there might be flaws within the SSM module itself during prediction, and further optimization of its internal details may potentially enhance the model\u2019s performance. Additionally, similar postoptimization paradigms should be further explored in non-visual tasks within Mamba or even applied in non-Mamba architectures. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Mamba incorporates intricate computational modules, making it non-trivial to delve into its operational mechanisms. In this paper, we have proposed a post-analysis and post-optimization approach to understand the workings of Mamba in visual recognition tasks and enhance its performance. Specifically, departing from existing pre-defined optimization methods, we have introduced predictive correlation analysis and correlation scoring definitions from both internal and external perspectives of Mamba\u2019s states. These methodologies aim to identify flaws within Mamba\u2019s operational mechanisms. Simultaneously, we have presented corresponding approaches for repairing internal and external flaws to optimize model performance. Extensive and comprehensive experiments have demonstrated the effectiveness of Vision Mamba Mender on mainstream Mamba architectures. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This research was supported by the Joint Funds of the Zhejiang Provincial Natural Science Foundation of China under Grant No. LHZSD24F020001 and Ningbo Natural Science Foundation (2022J182). ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems, 25, 2012.   \n[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.   \n[3] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020.   \n[4] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF international conference on computer vision, pages 10012\u201310022, 2021.   \n[5] Wenjie Luo, Yujia Li, Raquel Urtasun, and Richard Zemel. Understanding the effective receptive field in deep convolutional neural networks. Advances in neural information processing systems, 29, 2016.   \n[6] Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li, Guodong Zhang, Han Hu, and Yichen Wei. Deformable convolutional networks. In Proceedings of the IEEE international conference on computer vision, pages 764\u2013773, 2017.   \n[7] Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. Generating long sequences with sparse transformers. arXiv preprint arXiv:1904.10509, 2019.   \n[8] Sinong Wang, Belinda Z Li, Madian Khabsa, Han Fang, and Hao Ma. Linformer: Self-attention with linear complexity. arXiv preprint arXiv:2006.04768, 2020.   \n[9] Fisher Yu and Vladlen Koltun. Multi-scale context aggregation by dilated convolutions. arXiv preprint arXiv:1511.07122, 2015.   \n[10] Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and Fran\u00e7ois Fleuret. Transformers are rnns: Fast autoregressive transformers with linear attention. In International conference on machine learning, pages 5156\u20135165. PMLR, 2020.   \n[11] Albert Gu, Karan Goel, and Christopher R\u00e9. Efficiently modeling long sequences with structured state spaces. arXiv preprint arXiv:2111.00396, 2021.   \n[12] Bo Peng, Eric Alcaide, Quentin Anthony, Alon Albalak, Samuel Arcadinho, Huanqi Cao, Xin Cheng, Michael Chung, Matteo Grella, Kranthi Kiran GV, et al. Rwkv: Reinventing rnns for the transformer era. arXiv preprint arXiv:2305.13048, 2023.   \n[13] Albert Gu and Tri Dao. Mamba: Linear-time sequence modeling with selective state spaces. arXiv preprint arXiv:2312.00752, 2023.   \n[14] Hanwei Zhang, Ying Zhu, Dan Wang, Lijun Zhang, Tianxiang Chen, and Zi Ye. A survey on visual mamba. arXiv preprint arXiv:2404.15956, 2024.   \n[15] Xiao Liu, Chenxu Zhang, and Lei Zhang. Vision mamba: A comprehensive survey and taxonomy. arXiv preprint arXiv:2405.04404, 2024.   \n[16] Rui Xu, Shu Yang, Yihui Wang, Bo Du, and Hao Chen. A survey on vision mamba: Models, applications and challenges. arXiv preprint arXiv:2404.18861, 2024.   \n[17] Lianghui Zhu, Bencheng Liao, Qian Zhang, Xinlong Wang, Wenyu Liu, and Xinggang Wang. Vision mamba: Efficient visual representation learning with bidirectional state space model. arXiv preprint arXiv:2401.09417, 2024.   \n[18] Yue Liu, Yunjie Tian, Yuzhong Zhao, Hongtian Yu, Lingxi Xie, Yaowei Wang, Qixiang Ye, and Yunfan Liu. Vmamba: Visual state space model. arXiv preprint arXiv:2401.10166, 2024.   \n[19] Chenhongyi Yang, Zehui Chen, Miguel Espinosa, Linus Ericsson, Zhenyu Wang, Jiaming Liu, and Elliot J Crowley. Plainmamba: Improving non-hierarchical mamba in visual recognition. arXiv preprint arXiv:2403.17695, 2024.   \n[20] Shufan Li, Harkanwar Singh, and Aditya Grover. Mamba-nd: Selective state space modeling for multidimensional data. arXiv preprint arXiv:2402.05892, 2024.   \n[21] Badri N Patro and Vijay S Agneeswaran. Simba: Simplified mamba-based architecture for vision and multivariate time series. arXiv preprint arXiv:2403.15360, 2024.   \n[22] Ali Behrouz, Michele Santacatterina, and Ramin Zabih. Mambamixer: Efficient selective state space models with dual token and channel selection. arXiv preprint arXiv:2403.19888, 2024.   \n[23] Weihao Yu and Xinchao Wang. Mambaout: Do we really need mamba for vision? arXiv preprint arXiv:2405.07992, 2024.   \n[24] Daniel Y Fu, Tri Dao, Khaled K Saab, Armin W Thomas, Atri Rudra, and Christopher R\u00e9. Hungry hungry hippos: Towards language modeling with state space models. arXiv preprint arXiv:2212.14052, 2022.   \n[25] Weizhe Hua, Zihang Dai, Hanxiao Liu, and Quoc Le. Transformer quality in linear time. In International conference on machine learning, pages 9099\u20139117. PMLR, 2022.   \n[26] Riccardo Grazzi, Julien Siems, Simon Schrodi, Thomas Brox, and Frank Hutter. Is mamba capable of in-context learning? arXiv preprint arXiv:2402.03170, 2024.   \n[27] Arnab Sen Sharma, David Atkinson, and David Bau. Locating and editing factual associations in mamba. arXiv preprint arXiv:2404.03646, 2024.   \n[28] Gon\u00e7alo Paulo, Thomas Marshall, and Nora Belrose. Does transformer interpretability transfer to rnns? arXiv preprint arXiv:2404.05971, 2024.   \n[29] Ameen Ali, Itamar Zimerman, and Lior Wolf. The hidden attention of mamba models. arXiv preprint arXiv:2403.01590, 2024.   \n[30] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based localization. In Proceedings of the IEEE international conference on computer vision, pages 618\u2013626, 2017.   \n[31] Hila Chefer, Shir Gur, and Lior Wolf. Transformer interpretability beyond attention visualization. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 782\u2013791, 2021.   \n[32] Gr\u00e9goire Montavon, Alexander Binder, Sebastian Lapuschkin, Wojciech Samek, and Klaus-Robert M\u00fcller. Layer-wise relevance propagation: an overview. Explainable AI: interpreting, explaining and visualizing deep learning, pages 193\u2013209, 2019.   \n[33] Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution for deep networks. In International conference on machine learning, pages 3319\u20133328. PMLR, 2017.   \n[34] Xiaohuan Pei, Tao Huang, and Chang Xu. Efficientvmamba: Atrous selective scan for light weight visual mamba. arXiv preprint arXiv:2403.09977, 2024.   \n[35] Tao Huang, Xiaohuan Pei, Shan You, Fei Wang, Chen Qian, and Chang Xu. Localmamba: Visual state space model with windowed selective scan. arXiv preprint arXiv:2403.09338, 2024.   \n[36] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009.   \n[37] Shanghua Gao, Zhong-Yu Li, Ming-Hsuan Yang, Ming-Ming Cheng, Junwei Han, and Philip Torr. Largescale unsupervised semantic segmentation. 2022.   \n[38] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.   \n[39] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.   \n[40] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2818\u20132826, 2016.   \n[41] Shunyu Liu, Yihe Zhou, Jie Song, Tongya Zheng, Kaixuan Chen, Tongtian Zhu, Zunlei Feng, and Mingli Song. Contrastive identity-aware learning for multi-agent value decomposition. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 11595\u201311603, 2023.   \n[42] Lin Chen, Zhijie Jia, Lechao Cheng, Yang Gao, Jie Lei, Yijun Bei, and Zunlei Feng. Vit-calibrator: Decision stream calibration for vision transformer. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 1147\u20131155, 2024.   \n[43] Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herv\u00e9 J\u00e9gou. Training data-efficient image transformers & distillation through attention. In International conference on machine learning, pages 10347\u201310357. PMLR, 2021.   \n[44] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015.   \n[45] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9729\u20139738, 2020.   \n[46] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. Masked autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 16000\u201316009, 2022.   \n[47] Michael Brooks, Saleema Amershi, Bongshin Lee, Steven M Drucker, Ashish Kapoor, and Patrice Simard. Featureinsight: Visual support for error-driven feature ideation in text classification. In 2015 IEEE Conference on Visual Analytics Science and Technology (VAST), pages 105\u2013112. IEEE, 2015.   \n[48] Gabriel Cadamuro, Ran Gilad-Bachrach, and Xiaojin Zhu. Debugging machine learning models. In ICML Workshop on Reliable Machine Learning in the Wild, volume 103, 2016.   \n[49] Zunlei Feng, Jiacong Hu, Sai Wu, Xiaotian Yu, Jie Song, and Mingli Song. Model doctor: A simple gradient aggregation strategy for diagnosing and treating cnn classifiers. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 616\u2013624, 2022.   \n[50] Josua Krause, Adam Perer, and Kenney Ng. Interacting with predictions: Visual inspection of black-box machine learning models. In Proceedings of the 2016 CHI conference on human factors in computing systems, pages 5686\u20135697, 2016.   \n[51] Samira Abnar and Willem Zuidema. Quantifying attention flow in transformers. arXiv preprint arXiv:2005.00928, 2020.   \n[52] Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Learning deep features for discriminative localization. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2921\u20132929, 2016.   \n[53] Maithra Raghu, Thomas Unterthiner, Simon Kornblith, Chiyuan Zhang, and Alexey Dosovitskiy. Do vision transformers see like convolutional neural networks? Advances in neural information processing systems, 34:12116\u201312128, 2021.   \n[54] Shunyu Liu, Jie Song, Yihe Zhou, Na Yu, Kaixuan Chen, Zunlei Feng, and Mingli Song. Interaction pattern disentangling for multi-agent reinforcement learning. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2024.   \n[55] Shunyu Liu, Wei Luo, Yanzhen Zhou, Kaixuan Chen, Quan Zhang, Huating Xu, Qinglai Guo, and Mingli Song. Transmission interface power flow adjustment: A deep reinforcement learning approach based on multi-task attribution map. IEEE Transactions on Power Systems, 39(2):3324\u20133335, 2024.   \n[56] Amin Ghiasi, Hamid Kazemi, Eitan Borgnia, Steven Reich, Manli Shu, Micah Goldblum, Andrew Gordon Wilson, and Tom Goldstein. What do vision transformers learn? a visual exploration. arXiv preprint arXiv:2212.06727, 2022.   \n[57] Misha Denil, Alban Demiraj, and Nando De Freitas. Extraction of salient sentences from labelled documents. arXiv preprint arXiv:1412.6815, 2014.   \n[58] Sebastian Bach, Alexander Binder, Gr\u00e9goire Montavon, Frederick Klauschen, Klaus-Robert M\u00fcller, and Wojciech Samek. On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation. PloS one, 10(7):e0130140, 2015.   \n[59] Gr\u00e9goire Montavon, Sebastian Lapuschkin, Alexander Binder, Wojciech Samek, and Klaus-Robert M\u00fcller. Explaining nonlinear classification decisions with deep taylor decomposition. Pattern recognition, 65:211\u2013 222, 2017.   \n[60] Ruth C Fong and Andrea Vedaldi. Interpretable explanations of black boxes by meaningful perturbation. In Proceedings of the IEEE international conference on computer vision, pages 3429\u20133437, 2017.   \n[61] Ruth Fong, Mandela Patrick, and Andrea Vedaldi. Understanding deep networks via extremal perturbations and smooth masks. In Proceedings of the IEEE/CVF international conference on computer vision, pages 2950\u20132958, 2019.   \n[62] Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. Advances in neural information processing systems, 30, 2017.   \n[63] Xiao Wang, Shiao Wang, Yuhe Ding, Yuehang Li, Wentao Wu, Yao Rong, Weizhe Kong, Ju Huang, Shihao Li, Haoxiang Yang, et al. State space model for new-generation network alternative to transformers: A survey. arXiv preprint arXiv:2404.09516, 2024.   \n[64] Badri Narayana Patro and Vijay Srinivas Agneeswaran. Mamba-360: Survey of state space models as transformer alternative for long sequence modelling: Methods, applications, and challenges. arXiv preprint arXiv:2404.16112, 2024.   \n[65] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "image", "img_path": "9VnevS2YoR/tmp/e2ed8b50a76057b84fb62c3fa666f1a4dbeae6074b30401fe9d93702066ee710.jpg", "img_caption": ["A Vision Mamba Mender. The magnifying glass held in one hand symbolizes flaw detection, while the wrench held in the other hand symbolizes flaw repair. "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "Appendix for Vision Mamba Mender ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "To facilitate a better understanding of the value and significance of this work, as well as to thoroughly demonstrate the effectiveness and applicability of the proposed method, we have provided the algorithm code in supplementary material. This code will be made publicly available. Additionally, in the appendix, we have supplemented more information about the Mamba architecture, related work on Mamba interpretability, detailed experimental settings, additional results on state flaw identification, additional results on state flaw repair, and detailed ablation experiments, as follows. ", "page_idx": 14}, {"type": "text", "text": "A Origin of the Mamba Model ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "One of the core components of Mamba is the State Space Model (SSM). SSMs were initially inspired by continuous systems, which map a one-dimensional input signal $x(t)\\in\\mathbb{R}$ to a one-dimensional output signal $y(\\dot{t})\\in\\mathbb{R}$ through an $N$ -dimensional latent state $h(\\bar{t})\\in\\mathbb{R}^{N}$ . The general computational process can be defined as follows: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{h^{\\prime}(t)={\\bf A}h(t)+{\\bf B}x(t),}}\\\\ {{y(t)={\\bf C}h(t),}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where ${\\bf A}\\in\\mathbb{R}^{N\\times N}$ , $\\mathbf{B}\\in\\mathbb{R}^{N\\times1}$ , and $\\mathbf{C}\\in\\mathbb{R}^{1\\times N}$ are the state matrix, input matrix, and output matrix, respectively. ", "page_idx": 14}, {"type": "text", "text": "Unlike the continuity in Equation 15, Structured State Space Models (S4) [11] employ transformation methods, such as the zero-order hold (ZOH), to discretize it. ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle h^{\\prime}(t)=\\overline{{\\bf A}}h(t)+\\overline{{\\bf B}}x(t),}}\\\\ {{\\displaystyle y(t)=\\overline{{\\bf C}}h(t),}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\overline{{\\mathbf{A}}}=\\exp\\left(\\Delta\\mathbf{A}\\right)$ and $\\overline{{\\mathbf{B}}}=(\\Delta\\mathbf{A})^{-1}(\\exp{(\\Delta\\mathbf{A})}-\\mathbf{I})\\cdot\\Delta\\mathbf{B}$ are the discretized parameters, and $\\Delta$ denotes the step size. ", "page_idx": 14}, {"type": "text", "text": "Building on this foundation, the Selective State Space Model (S6) creatively introduces selective scanning to overcome the limitations imposed by time-invariant parameters on context representation learning: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbf{B}=S_{B}(\\mathbf{x}),\\mathbf{C}=S_{C}(\\mathbf{x}),\\boldsymbol{\\Delta}=\\tau_{\\Delta}(\\boldsymbol{\\Delta}+S_{\\Delta}(\\mathbf{x})),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $S_{B},S_{C}$ , and $S_{\\Delta}$ are different linear mappings. Additionally, for more detailed information on Mamba\u2019s specifics and applications, we recommend readers consult several recent and well-regarded review articles [63, 64, 14\u201316]. ", "page_idx": 14}, {"type": "text", "text": "B Detailed Experimental Settings ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "To facilitate the reproducibility of our results, we provide detailed experimental settings as follows. Throughout the entire experiment, we utilized 8 NVIDIA A40 GPU cards and a CPU with 24 cores and 500GB of memory. ", "page_idx": 15}, {"type": "text", "text": "Model Parameter Settings. To enable the Mamba model to train efficiently within limited computational resources, we adjusted certain parameters across the Mamba models. For instance, in the case of VMamba-T, we set the patch size to 16x16. For SiMBA-S, the model depth was adjusted to [2, 3, 3, 2], and we introduced a class token for classification in the last block. For EfficientVMamba-T, we similarly set the patch size to 16x16. In the case of LocalViM-T, we reduced the model depth from 20 to 9 and set the state dimensionality to 128. These parameter adjustments were made to validate the proposed methods under constrained resources. While this may somewhat reduce the baseline performance, it does not affect the fairness of comparing the Mamba model\u2019s performance before and after flaw identification and repair. ", "page_idx": 15}, {"type": "text", "text": "Model Training Settings. To ensure a fair comparison with limited resources, our training settings primarily followed the experimental setup of DeiT [43]. Specifically, we employed data augmentation techniques such as random cropping and random horizontal flipping. When training on $224\\!\\!\\!\\times\\!224$ input images, we optimized the model using AdamW [65] with a momentum of 0.9, a total batch size of 128, and a weight decay of 0.1. We utilized a cosine learning rate schedule with an initial learning rate of 5e-4, training the Mamba model for 300 epochs. In particular during the baseline model training, these training strategies resulted in an exceedingly smooth training curve in the later stages, effectively optimizing the fti. During testing, we performed center cropping on the validation set to extract $224\\mathrm{x}224$ images. ", "page_idx": 15}, {"type": "text", "text": "State Flaw Identification. For external state correlation analysis, the threshold $\\alpha$ is set to 0.5 by default. For internal state correlation, the threshold $\\beta$ is set to 0.3 by default. The impact of thresholds on flaw detection can be found in the Appendices C and D. It is worth noting that for multi-branch Mamba, when conducting external flaw identification and repair, we merge all branches corresponding to the same state together. However, for internal flaw identification and repair, we consider each branch of the state separately. ", "page_idx": 15}, {"type": "text", "text": "State Flaw Repair. In our experiments, the balance weight $\\lambda$ for the loss function of external state flaw repair is set to $1e+7$ by default, and the balance weight $\\gamma$ for the loss function of internal state flaw repair is also set to $1e+7$ by default. Furthermore, based on the conclusions about flaw identification in the main text, external state flaw repair is applied by default to the first Mamba block, while internal state flaw repair is applied to the last Mamba block. The impact of repairing flaws in different blocks on model performance can be found in Appendices E and F. ", "page_idx": 15}, {"type": "text", "text": "C Impact of Threshold $\\alpha$ on External State Correlation Scores ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "As shown in Figure 6, we compared the impact of different values of threshold $\\alpha$ on external state correlation scores. By contrasting simple samples with difficult samples, we found that the value of $\\alpha$ does not significantly affect the relative magnitudes of the external correlation scores. Specifically, regardless of whether $\\alpha$ is set to 0.0, 0.2, or 0.8, the external correlation scores for states $x_{n}^{(\\ell)}$ , $c_{n}^{(\\ell)}$ , $s_{n}^{(\\bar{\\ell})}$ , $z_{n}^{(\\ell)}$ , and $y_{n}^{(\\ell)}$ in difficult samples all decrease compared to those in simple samples. Additionally, when $\\alpha$ is set between 0.4 and 0.6, more details can be observed; in different blocks, the external correlation scores of states $x_{n}^{(\\ell)}$ , $c_{n}^{(\\ell)}$ , $s_{n}^{(\\ell)}$ , and $z_{n}^{(\\ell)}$ are better than those of state $y_{n}^{(\\ell)}$ . Therefore, we recommend that the value of $\\alpha$ should not be too extreme when calculating external state correlation scores. It can be set between 0.4 and 0.6; we use a default setting of $\\alpha=0.5$ . ", "page_idx": 15}, {"type": "text", "text": "D Impact of Threshold $\\beta$ on Internal State Correlation Scores ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We also examined the impact of different values of threshold $\\beta$ on internal state correlation scores, as shown in Fig. 7. Similarly, by comparing simple and difficult samples, it can be observed that the value of $\\beta$ does not affect the relative magnitudes of the internal correlation scores. Specifically, regardless of whether $\\beta$ is set to 0.0, 0.2, or 0.8, the internal correlation scores for states $x_{n}^{(\\ell)}$ , $c_{n}^{(\\ell)}$ , $s_{n}^{(\\bar{\\ell})}$ , $z_{n}^{(\\ell)}$ , and $y_{n}^{(\\ell)}$ in difficult samples all decrease compared to those in simple samples. Additionally, cwohrerenl $\\beta$ iiosn  ssect obreets woef esnt a0t.e4 d a0r.e6 ,b emttoerr et hdaent atihlso scea no f bset aotebss , raenntd .k sT, htehree fionrtee,r nwael $x_{n}^{(\\ell)}$ $c_{n}^{(\\ell)},\\,s_{n}^{(\\ell)},\\,z_{n}^{(\\ell)},$ $y_{n}^{(\\ell)}$ recommend that the value of $\\beta$ should not be too extreme when calculating internal state correlation scores. It can be set between 0.4 and 0.6; we use a default setting of $\\beta=0.5$ . ", "page_idx": 15}, {"type": "image", "img_path": "9VnevS2YoR/tmp/2c3b881451eb3c76bcf56233ccd432760d2e6418c7b463f978d833b4a1b755e5.jpg", "img_caption": ["Figure 6: Comparison of external state correlation scores for simple and difficult samples under different threshold values of $\\alpha$ . The left column of images shows the external state correlation scores for simple samples at various $\\alpha$ values. The right column of images shows the external state correlation scores for difficult samples at various $\\alpha$ values. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "E External Flaw Repair in Different Blocks ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "As shown in Figure E(a), we conducted a study on repairing external flaws in different blocks, revealing a clear enhancement in model performance following external flaw repair. Specifically, when external flaws are repaired in the final block, the model\u2019s accuracy improves by $2.04\\%$ compared to the baseline. In contrast, while repairing external flaws in other blocks, such as the tenth block, also yields an accuracy increase, the improvement is only $1.72\\%$ . This discrepancy may be attributed to the presence of external flaws in the states across nearly every block, as illustrated in Figure 2, including states such as $x_{n}^{(\\ell)},c_{n}^{(\\ell)},s_{n}^{(\\ell)},$ , and $z_{n}^{(\\ell)}$ , which exhibit significant external flaws on difficult samples. However, due to structures like residual connections, the influence of external flaws on model predictions varies across different blocks. ", "page_idx": 16}, {"type": "image", "img_path": "9VnevS2YoR/tmp/71ac73fa5e9102a2f2ab992a6b51e8ed4e2f78288ef10bc8d4e56f9feb7ce84b.jpg", "img_caption": ["Figure 7: Comparison of internal state correlation scores for simple and difficult samples under different threshold values of $\\beta$ . The left column of images shows the internal state correlation scores for simple samples at various $\\beta$ values. The right column of images shows the internal state correlation scores for difficult samples at various $\\beta$ values. "], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "9VnevS2YoR/tmp/77e4dcb59ccbc5af86a1183a5047f61974671757f562d246b27789b924b2e412.jpg", "img_caption": ["Figure 8: Comparison of model accuracy after state flaw repair in different blocks. (a) shows the results of external state flaw repair, conducted on states $c_{n}^{(\\ell)}$ and $s_{n}^{(\\ell)}$ in each block of the ViM model, using the ImageNet-50 dataset. (b) shows the results of internal state flaw repair, conducted on state $x_{n}^{(\\ell)}$ in each block of the ViM model, also using the ImageNet-50 dataset. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "F Internal Flaw Repair in Different Blocks ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "As shown in Figure E(b), we conducted a study on repairing internal flaws in different blocks, which also demonstrates a noticeable improvement in model performance. Specifically, when internal flaws are repaired in the final block, the model\u2019s accuracy increases by $1.76\\%$ compared to the baseline. In contrast, repairing internal flaws in other blocks, such as the second-to-last block, results in an accuracy improvement of $2.4\\%$ . Furthermore, repairing internal correlations in other blocks yields varying levels of accuracy enhancement. This variation may similarly stem from the model\u2019s internal structures, such as residual connections, which lead to different degrees of influence from internal flaws on model performance across the various blocks. ", "page_idx": 18}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: Section 1. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 19}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: Section 6. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 19}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 19}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 20}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: Section B. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 20}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The algorithm code is available in the supplementary material and will be publicly accessible. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 21}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: Section B. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 21}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [No] ", "page_idx": 21}, {"type": "text", "text": "Justification: To prevent the occurrence of accidental experimental results, we conducted each experiment at least twice to ensure the accuracy of the findings. The data presented in this paper are the averages of two or more experimental runs. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: Section B. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 22}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: [NA] Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 22}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 23}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: Please refer to the citations in the paper. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 23}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 24}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We have provided the complete code. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 24}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 24}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 24}]