[{"figure_path": "SF2GlFhVsS/tables/tables_8_1.jpg", "caption": "Table 1: Results on POPE. Regular decoding denotes direct sampling, whereas VCD refers to Visual Contrastive Decoding method, whereas VDD refers to Visual Debias Decoding. The best performances within each setting are bolded.", "description": "This table presents the performance of different decoding methods (Regular, VCD, ICD, VDD, and Ours) on the POPE dataset for object hallucination.  The results are broken down by three different settings: random, popular, and adversarial.  For each setting and decoding method, the accuracy, precision, recall, and F1 score are reported.  The best performing method for each metric in each setting is shown in bold. The table helps to demonstrate the effectiveness of the proposed HIO method in reducing hallucinations compared to existing state-of-the-art techniques.", "section": "6.2 Experimental Results"}, {"figure_path": "SF2GlFhVsS/tables/tables_8_2.jpg", "caption": "Table 2: Hallucination performance of different methods.", "description": "This table presents a comparison of hallucination performance between different methods on the CHAIR benchmark.  It shows the length of generated captions, the CHAIRS and CHAIRI scores (lower is better, indicating fewer hallucinations), and the Recall score (higher is better, indicating more details in captions). The results demonstrate the effectiveness of the proposed HIO method in reducing hallucinations while maintaining a good level of detail in generated captions.", "section": "6.2 Experimental Results"}, {"figure_path": "SF2GlFhVsS/tables/tables_9_1.jpg", "caption": "Table 3: Results on the hallucination subset of MME. Regular decoding denotes direct sampling, VCD denotes Visual Contrastive Decoding method, whereas VDD refers to Visual Debias Decoding. The best performances within each setting are bolded.", "description": "This table presents the results of the Hallucination-Induced Optimization (HIO) method compared to other state-of-the-art methods on the Multimodal Large Language Model Evaluation (MME) benchmark's hallucination subset.  It evaluates the performance of different decoding strategies (Regular, Visual Contrastive Decoding - VCD, Visual Debias Decoding - VDD, and HIO) across various metrics: Existence, Count, Position, and Color at object-level and attribute-level.  The best performance for each setting is highlighted in bold, showcasing the effectiveness of HIO in reducing hallucinations.", "section": "6.2 Experimental Results"}, {"figure_path": "SF2GlFhVsS/tables/tables_9_2.jpg", "caption": "Table 4: Ablation study with different components of our model on CHAIR-COCO.", "description": "This table presents the ablation study results evaluating the impact of individual components of the proposed Hallucination-Induced Optimization (HIO) method on the CHAIR-COCO benchmark.  The rows represent different experimental configurations, showing which components (CBTM, AMTH, ACI) were included.  The columns show the resulting CHAIRS, CHAIR1 scores (lower is better), and Recall scores (higher is better). This demonstrates the individual and combined contributions of each component to the overall performance.", "section": "6.3 Ablation Study"}, {"figure_path": "SF2GlFhVsS/tables/tables_9_3.jpg", "caption": "Table 5: Ablation study on the generalization of each component on unseen datasets.", "description": "This table presents the results of an ablation study conducted to evaluate the generalization capability of the proposed HIO method's components (CBTM, AMTH, and ACI) on unseen datasets.  It shows the performance (Accuracy, Precision, Recall, F1 Score) of the model with different combinations of these components on two unseen datasets: unseen-N and unseen-P. The results demonstrate how each component contributes to the overall performance and their effectiveness in generalizing to unseen data.", "section": "6.3 Ablation Study"}, {"figure_path": "SF2GlFhVsS/tables/tables_14_1.jpg", "caption": "Table 3: Results on the hallucination subset of MME. Regular decoding denotes direct sampling, VCD denotes Visual Contrastive Decoding method, whereas VDD refers to Visual Debias Decoding. The best performances within each setting are bolded.", "description": "This table presents the results of the hallucination subset of the MME (Multimodal Large Language Model Evaluation) benchmark.  It compares three different decoding methods: Regular (direct sampling), Visual Contrastive Decoding (VCD), and Visual Debias Decoding (VDD). The table shows the performance of each method across various attributes, including Existence, Count, Position, Color, and Total Scores. The best performance for each metric is highlighted in bold.", "section": "6.2 Experimental Results"}, {"figure_path": "SF2GlFhVsS/tables/tables_15_1.jpg", "caption": "Table 1: Results on POPE. Regular decoding denotes direct sampling, whereas VCD refers to Visual Contrastive Decoding method, whereas VDD refers to Visual Debias Decoding. The best performances within each setting are bolded.", "description": "This table presents the quantitative results of the proposed Hallucination-Induced Optimization (HIO) method and compares it against several state-of-the-art decoding methods on the POPE benchmark.  The POPE benchmark evaluates the ability of Large Vision-Language Models (LVLMs) to avoid hallucinating objects when answering questions about images. The table shows the accuracy, precision, recall, and F1-score for each method across different settings (random, popular, and adversarial).  The bolded values indicate the best-performing method for each metric and setting, demonstrating HIO's superior performance in reducing hallucinations.", "section": "6.2 Experimental Results"}]