[{"figure_path": "Bjh4mcYs20/tables/tables_7_1.jpg", "caption": "Table 1: Summary of success rates and required steps to achieve target rewards in MiniGrid and MetaWorld tasks: \u201caverage value \u00b1 standard deviation", "description": "This table summarizes the performance of different reinforcement learning algorithms on MiniGrid and MetaWorld tasks.  For each task and algorithm, it shows the average success rate (percentage of successful trials) and the average number of steps required to reach the target reward.  The results are presented as average values \u00b1 standard deviations, providing a measure of variability. The table also shows the average percentage improvement of the proposed algorithm (SI2E) compared to the baseline algorithms.", "section": "5 Experiments"}, {"figure_path": "Bjh4mcYs20/tables/tables_8_1.jpg", "caption": "Table 2: Summary of average episode rewards for control tasks in DMControl, encompassing two cartpole tasks characterized by sparse rewards: \u201caverage value \u00b1 standard deviation", "description": "This table presents the average episode rewards achieved by different reinforcement learning algorithms (DrQv2 and its variants with different exploration methods) on six continuous control tasks from the DeepMind Control Suite.  Two cartpole tasks are highlighted as having sparse rewards. The table shows average performance and standard deviation across multiple runs. The improvement of SI2E compared to the baseline DrQv2 is also indicated.  ", "section": "5.3 DMControl Evaluation"}, {"figure_path": "Bjh4mcYs20/tables/tables_13_1.jpg", "caption": "Table 1: Summary of success rates and required steps to achieve target rewards in MiniGrid and MetaWorld tasks: \u201caverage value \u00b1 standard deviation", "description": "This table presents a summary of the performance of different reinforcement learning algorithms across various tasks in the MiniGrid and MetaWorld environments.  It shows the success rates (percentage of times the algorithm successfully completed the task) and the number of steps required to achieve the target reward for each algorithm. The results are presented as average values with standard deviations, providing a measure of the algorithms' performance variability. The table also calculates the average percentage improvement of each algorithm compared to a baseline.", "section": "5 Experiments"}, {"figure_path": "Bjh4mcYs20/tables/tables_14_1.jpg", "caption": "Table 1: Summary of success rates and required steps to achieve target rewards in MiniGrid and MetaWorld tasks: \u201caverage value \u00b1 standard deviation\u201d and \u201caverage improvement\u201d. Bold: the best performance, underline: the second performance.", "description": "This table presents a summary of the experimental results obtained for the MiniGrid and MetaWorld tasks.  For each task, it shows the success rate (percentage of successful trials) and the average number of steps required to achieve the target reward, along with standard deviations.  It highlights the best and second-best performing methods for each task, providing a quantitative comparison of the proposed SI2E method against baseline approaches.  The values are presented as average \u00b1 standard deviation, and the average improvement of SI2E over the baselines is also indicated.", "section": "5 Experiments"}, {"figure_path": "Bjh4mcYs20/tables/tables_15_1.jpg", "caption": "Table 1: Summary of success rates and required steps to achieve target rewards in MiniGrid and MetaWorld tasks: \u201caverage value \u00b1 standard deviation\u201d and \u201caverage improvement\u201d. Bold: the best performance, underline: the second performance.", "description": "This table presents a summary of the experimental results obtained using the SI2E framework on MiniGrid and MetaWorld environments. For each task, it shows the average success rate and number of steps required to achieve the target reward, calculated across multiple trials. The table also includes the average improvement achieved by SI2E compared to other baselines. The best and second-best performances are highlighted in bold and underlined respectively. This provides a comprehensive comparison of the performance of SI2E against other state-of-the-art methods in terms of both final performance and sample efficiency.", "section": "5 Experiments"}, {"figure_path": "Bjh4mcYs20/tables/tables_21_1.jpg", "caption": "Table 1: Summary of success rates and required steps to achieve target rewards in MiniGrid and MetaWorld tasks: \u201caverage value \u00b1 standard deviation", "description": "This table summarizes the performance of different reinforcement learning algorithms on MiniGrid and MetaWorld tasks.  For each task and algorithm, it shows the success rate (percentage of successful trials) and the average number of steps required to reach the target reward.  The values are given as average \u00b1 standard deviation.  The table helps compare the effectiveness of different exploration strategies in reinforcement learning. ", "section": "5 Experiments"}, {"figure_path": "Bjh4mcYs20/tables/tables_21_2.jpg", "caption": "Table 1: Summary of success rates and required steps to achieve target rewards in MiniGrid and MetaWorld tasks: \u201caverage value \u00b1 standard deviation", "description": "This table presents a summary of the experimental results obtained on MiniGrid and MetaWorld tasks using different exploration methods.  For each task and method, it shows the success rate (percentage) and the number of steps required to achieve the target reward.  The results are expressed as average values \u00b1 standard deviations, allowing for comparison across different exploration methods.  The table highlights the performance gains achieved by the SI2E method compared to several baselines. ", "section": "5 Experiments"}, {"figure_path": "Bjh4mcYs20/tables/tables_23_1.jpg", "caption": "Table 1: Summary of success rates and required steps to achieve target rewards in MiniGrid and MetaWorld tasks: \u201caverage value \u00b1 standard deviation", "description": "This table presents a summary of the performance of different reinforcement learning algorithms on MiniGrid and MetaWorld tasks. For each task and algorithm, the table shows the average success rate and the average number of steps required to achieve the target reward.  The results are presented as average value \u00b1 standard deviation. The best performance is highlighted in bold.", "section": "5 Experiments"}, {"figure_path": "Bjh4mcYs20/tables/tables_24_1.jpg", "caption": "Table 1: Summary of success rates and required steps to achieve target rewards in MiniGrid and MetaWorld tasks: \u201caverage value \u00b1 standard deviation", "description": "This table summarizes the performance of different reinforcement learning algorithms across various MiniGrid and MetaWorld tasks.  It shows the success rate (percentage of successful trials) and the number of required steps to reach the target reward for each algorithm. The results are presented as average values plus or minus standard deviations, indicating variability across multiple trials.  The table allows for a comparison of the performance of algorithms incorporating various exploration strategies (such as SI2E, SE, and VCSE) and also illustrates the sample efficiency of each approach.", "section": "5 Experiments"}]