[{"type": "text", "text": "The motion planning neural circuit in goal-directed navigation as Lie group operator search ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Junfeng Zuo1,3 Ying Nian Wu2 zuojunfeng@pku.edu.cn ywu@stat.ucla.edu ", "page_idx": 0}, {"type": "text", "text": "Si Wu1 siwu@pku.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Wen-Hao Zhang3,4\u2217 wenhao.zhang@utsouthwestern.edu ", "page_idx": 0}, {"type": "text", "text": "1Peking-Tsinghua Center for Life Sciences, Academy for Advanced Interdisciplinary Studies, School of Psychology and Cognitive Sciences, IDG/McGovern Institute for Brain Research, Center of Quantitative Biology, Peking University. ", "page_idx": 0}, {"type": "text", "text": "2Department of Statistics, University of California, Los Angeles. 3Lyda Hill Department of Bioinformatics, UT Southwestern Medical Center. 4O\u2019Donnell Brain Institute, UT Southwestern Medical Center. ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The information processing in the brain and embodied agents form a sensory-action loop to interact with the world. An important step in the loop is motion planning which selects motor actions based on the current world state and task need. In goal-directed navigation, the brain chooses and generates motor actions to bring the current state into the goal state. It is unclear about the neural circuit mechanism of motor action selection, nor its underlying theory. The present study formulates the motion planning as a Lie group operator search problem, and uses the 1D rotation group as an example to provide insight into general operator search in neural circuits. We found the abstract group operator search can be implemented by a two-layer feedforward circuit utilizing circuit motifs of connection phase shift, nonlinear activation function, and pooling, similar to Drosophila\u2019s goal-directed navigation neural circuits. And the computational complexity of the feedforward circuit can be even lower than common signal processing algorithms in certain conditions. We also provide geometric interpretations of circuit computation in the group representation space. The feedforward motion planning circuit is further combined with sensory and motor circuit modules into a full circuit of the sensoryaction loop implementing goal-directed navigation. Our work for the first time links the abstract operator search with biological neural circuits. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The information processing in the brain forms a sensory-action loop to interact with the external world (Fig. 1A) [1\u20133]. The sensory-action loop consists of three modules: the sensory neural circuit module forms a neural representation of the world state, the motor circuit module produces motor actions to change the world states, and in between there is an essential sensorimotor transformation module that plans motor actions based on the sensory input and tasks goals [4, 5]. For example, in goal-directed navigation tasks, the sensorimotor transformation module plans a sequence of motor actions to bring the current sensory state towards a goal state. Extensive neuroscience studies have investigated the neural circuit mechanism of motion planning [4\u20139], however, it remains far from clear as well as the underlying computational theory. Motion planning is also an essential computation for embodied agents in engineering research, including, e.g., robotic control, reinforcement learning, and machine learning [10\u201313], etc. Studying the motion planning neural circuits and their computational theory will help us understand the brain and can provide brain-inspired circuit models for embodied agents. ", "page_idx": 0}, {"type": "image", "img_path": "Qz7BfmWizk/tmp/0d7c60989e9a21dbf619c6ea3ecf14c77a152d402011b285c847f979fbf9cacb.jpg", "img_caption": ["Figure 1: (A) The sensory-action loop. Sensorimotor transformation plans motion actions based on the world state and task goals. (B) The equivariant map of the sensory neurons\u2019 responses. (C) A concrete example of 1D rotation group acting on periodic state $s$ that can be regarded as the heading direction of a fly. The sensory neurons form a neuronal population code $u(x|s)$ uniformly covering the space of $s$ (Eq. 1). (D) Finding a desired operator can be realized by group convolution, i.e., finding the peak location of cross-correlation function over the group manifold. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "To provide theoretical insight into motion planning, the present study defines the sensory-action loop using the (Lie) group theory. Denote by $s$ as a continuous world state, and $u(s)\\equiv u(x|\\dot{s})$ the evoked responses of a population of sensory neurons with $x$ as the neuron index. Suppose the motor system generates the same kind of actions from a Lie Group $\\mathbb{G}$ (e.g., translation or rotation) to transform the world state $s$ . The effect of a motor action $g\\,\\in\\,\\mathbb{G}$ to the world state $s$ and updated sensory representation $u(s)$ can be denoted by (Fig. 1A; $\\circ$ denotes the group action in below)[14], ", "page_idx": 1}, {"type": "equation", "text": "$$\nu(s^{\\prime})=u\\big(R_{g}\\circ s\\big)=\\hat{R}_{g}\\circ u(s),\\ \\ g\\in\\mathbb{G}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "$R_{g}$ is the group operator (motor action) changing the world state $s$ (Fig. 1A, green), whose effect on updated sensory responses $u(s^{\\prime})$ can be summarized as a neural operator $\\hat{R}_{g}$ directly acting on the original response $u(s)$ (Fig. 1A, blue) that can be regarded as the motor-to-sensory neural feedback in the brain [15]. To represent all world states $s$ under all group transformations, $u(s)$ must satisfy Eq. (1) for all $g\\in\\mathbb{G}$ , and is called equivariance with the group $\\mathbb{G}$ (group homomorphism) (Fig. 1B). In the Lie group framework (Eq. 1), motion planning in goal-directed navigation can be formulated as finding an operator $\\hat{R}_{g}$ to bring the sensory response of the current state $u(s)$ into a goal state $u(h)$ , ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathrm{Find}\\quad\\hat{R}_{g};\\ \\ \\mathrm{subject}\\,\\mathrm{to}\\quad\\hat{R}_{g}\\circ u(s)=u(h),\\ \\ g\\in\\mathbb{G}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "An intuitive way to find $\\hat{R}_{g}$ is exhaustive search in the group space: apply every operator to $u(s)$ and select the one transforming $u(s)$ closest to the goal response $u(h)$ (Table S1, Supplementary Info. (SI)), corresponding to find the peak location in the group convolution (Fig. 1D, bottom) [16, 17], ", "page_idx": 1}, {"type": "equation", "text": "$$\ng^{\\ast}=\\arg\\operatorname*{max}_{g}\\;L(g);\\;\\;\\mathrm{where}\\;L(g)=[u(h)\\star u(s)](g)=\\big\\langle u(h),\\hat{R}_{g}\\circ u(s)\\big\\rangle,\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "then the optimal group operator is $\\hat{R}_{g^{*}}$ . The $\\star$ denotes the group $g$ convolution, and $\\langle u(h),\\hat{R}_{g}\\circ$ $\\begin{array}{r}{u(s)\\rangle=\\int u(x|h)u(x|R_{g}\\circ s)d x}\\end{array}$ is the inner product. In particular, when $s$ is a 1D variable and $\\hat{R}_{g}$ is a 1D translation operator, the group convolution $L(g)$ (Eq. 3) simplifies into the cross-correlation function that is extensively used in signal processing [18, 19]. ", "page_idx": 1}, {"type": "text", "text": "The present study investigates how brain\u2019s neural circuits search group operators $\\hat{R}_{g}$ (action) in goaldirected navigation (Eq. 2). We use the 1D rotation group as a working example to provide insight into the neural circuit mechanism of general operator search. Although finding 1D rotation operators is mathematically simple and can be realized by available signal processing algorithms, its neural circuit implementation has never been explored. We theoretically derive a two-layer nonlinear feedforward circuit for 1D rotation operator search, which is composed of circuit motifs of connection phase shift, nonlinear activation function, and pooling, and the derived circuit is similar to Drosophila\u2019s goal-directed navigation neural circuits [20\u201323]. We link every neural circuit computation with operations in operator search, and provide geometric interpretations of circuit computation in the group representation space. Moreover, the computational complexity of the derived feedforward circuit for operator search can be even lower than the standard algorithm based on the fast Fourier transform in signal processing in certain conditions. We further assemble the derived feedforward circuit with sensory and motor circuits to form a full neural circuit of the whole sensory-action loop. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Significance. The present study is one of the first studies formulating motion planning as the group operator search problem, and deriving a biologically plausible neural circuit implementation with rigorous mathematical analysis. The group operator search formulation of motion planning can provide a normative approach to generalize existing motion planning algorithms into different transformations. Moreover, in terms of group equivariant machine learning, the theory and the sensorimotor transformation circuit model developed in the present study are complementary to many existing equivariant networks that correspond to the sensory system (e.g., [17, 24\u201327]). ", "page_idx": 2}, {"type": "text", "text": "2 1D rotation neural group operator search ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We use the 1D rotation group $\\mathbb{U}(1)$ as an example to provide insight into the general principle of group operator search in neural circuits. The $\\mathbb{U}(1)$ manifold is a unit circle on the complex plane (Fig. 2A), and can be parameterized by the angle $\\theta$ (corresponding to $g$ in a general Lie group, Eq. 1), ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{U}(1)=\\{\\exp(i\\theta),\\;\\theta\\in[-\\pi,\\pi)\\},\\;\\;\\;i=\\sqrt{-1}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "A group element $R(\\theta)\\in\\mathbb{U}(1)$ rotates a 1D stimulus direction $s\\in[-\\pi,\\pi)$ , or its complex representation $e^{i s}$ , by $\\theta$ , i.e., $s$ into $s+\\theta$ (mod $2\\pi$ ), and is denoted as $R(\\theta)\\circ s\\triangleq e^{i\\theta}e^{i s}=e^{i(s+\\theta)}$ . Based on Eq. (1), a rotation-equivariant sensory response $u(s)$ should satisfy (suppress \u201cmod $2\\pi^{\\star}$ \u201d for brevity), ", "page_idx": 2}, {"type": "equation", "text": "$$\nu[R(\\theta)\\circ s]=u(s+\\theta)=\\hat{R}(\\theta)\\circ u(s).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "$\\hat{R}(\\theta)$ is the neural operator rotating the sensory representation $u(s)$ . Since the rotation operator changes $s$ in an additive way, i.e, $u(x|s)\\mapsto u(\\dot{x}|s\\+\\theta)$ , it can be checked the equivariant sensory response satisfies $u(x|s)=u(x-s)\\equiv u(s)$ [28], where the neuron index $x$ (also called preferred direction) additively interacts with $s$ , implying the neuronal response only depends on the difference $x-s$ (Fig. 1D). The rotation-equivariant neural responses $u(x-s)$ have been widely used in neural coding studies [29\u201331], and are usually called homogeneous neural codes. To make our theory general, we leave the concrete proflie of $u(s)$ open and will see how the group structure constrains it. ", "page_idx": 2}, {"type": "text", "text": "In the case of 1D rotation, the motion planning in goal-directed navigation task is finding a rotation operator $\\hat{R}(\\theta)$ to rotate the sensory response $u(s)$ into the goal direction, $u(h)$ . Due to the simplicity of $\\mathbb{U}(1)$ (Eq. 5), the desired rotation operator is ${\\hat{R}}(\\theta^{*}=h-s)$ , in that ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\hat{R}(h-s)\\circ u(x-s)=u[x-(s+h-s)]=u(x-h),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "whose parameter is the angular difference $\\theta^{*}=h-s$ . Although computing the angular difference is simple, it is non-trivial to search neural operators $\\hat{R}(\\theta)$ in neural circuits. This is because $\\hat{R}(\\theta^{*})$ is an abstract math object rather than the numerical value $\\theta^{*}$ , even if it is indexed by $\\theta^{*}$ . This distinction is reflected by the fact that although the operator\u2019s parameter $\\theta^{*}=h-s$ is arithmetic subtraction, the neural operator $\\hat{R}(\\theta)$ by no means of arithmetic subtraction between neural responses $u(h)$ and $u(s)$ . ", "page_idx": 2}, {"type": "text", "text": "2.1 The structure and representation of 1D neural rotation operators ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Searching abstract neural operators $\\hat{R}(\\theta)$ first requires neural circuits to represent them. Intuitively, the representation means a one-to-one mapping between abstract operators with numerical values (e.g., neuronal activity), and then searching abstract operators can be converted into common numerical optimizations and further mapped to neural dynamics. Hence, we study the structure of the neural operator $\\hat{R}(\\theta)$ to reveal its neural representation. Consider an infinitesimal rotation $\\hat{R}(\\delta\\theta)\\;(\\delta\\theta\\rightarrow0)$ , whose effect on the sensory response $u(x-s)$ is (using first-order Taylor expansion), ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\hat{R}(\\delta\\theta)\\circ u(x-s)=u(x-\\delta\\theta-s)\\approx u(x-s)+\\delta\\theta(-\\partial_{x})u(x-s)=(1+\\delta\\theta\\cdot\\hat{J})u(x-s).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "$\\hat{J}\\equiv-\\partial_{x}=-\\partial/\\partial x$ is the 1D rotation generator characterizing the tangent space of infinitesimal rotations, and can be used as the basis of Lie algebra. By using the infinitesimal rotation, the ", "page_idx": 2}, {"type": "image", "img_path": "Qz7BfmWizk/tmp/58b7a3511284b29bdc643d17288d59561e51e9f3ee80f0c22984e112e1d5d8d2.jpg", "img_caption": [], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Figure 2: (A) The 1D rotation group manifold. (B) The eigenvalue spectrum of the 1D rotation group operators. (C-D) The representation of neural responses (C) and desired rotation operator (D) in the group representation space spanned by operators\u2019 eigenfunctions. (E) Two mathematically equivalent processes of rotating sensory responses into the goal direction. (F) Sequential motion planning. ", "page_idx": 3}, {"type": "text", "text": "differential and exponential form of a rotation operator is (see SI. Sec. 1.1), ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\frac{d}{d\\theta}\\hat{R}(\\theta)=\\hat{J}\\circ\\hat{R}(\\theta)\\;\\;\\;\\Leftrightarrow\\;\\;\\;\\hat{R}(\\theta)=\\exp(\\theta\\hat{J}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The neural rotation operator $\\hat{R}(\\theta)$ is commutative, meaning the composition of two rotations is the same regardless of their order, i.e., $\\hat{R}(\\theta_{1})\\hat{R}(\\theta_{2})=\\hat{R}(\\theta_{2})\\hat{R}(\\theta_{1})$ . Commutative group operators share a common set of\u221a eigenfunctions that can be used to represent group operators. It can be checked $\\{f_{\\omega}(x)=e^{i\\omega x}/\\sqrt{2\\pi},\\omega\\in\\mathbb{Z}\\}$ is the normalized eigenfunction set of $\\hat{J}$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\hat{J}\\circ f_{\\omega}=-\\partial_{x}e^{i\\omega x}/\\sqrt{2\\pi}=(-i\\omega)\\cdot e^{i\\omega x}/\\sqrt{2\\pi}=\\rho_{\\omega}(\\hat{J})\\cdot f_{\\omega},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "with each $f_{\\omega}$ having eigenvalue $\\rho_{\\omega}(\\hat{J})\\;\\triangleq\\;-i\\omega$ . The eigenvalue $\\rho_{\\omega}(\\hat{J})$ can be regarded as the representation of $\\hat{J}$ based on $f_{\\omega}$ . Hereafter, we call the space spanned by the eigenfunctions $\\{f_{\\omega}\\}$ as the representation space. It is worth noting that $\\{f_{\\omega}\\}$ are Fourier bases, which are widely used in frequency analysis in signal processing to extract each frequency component [18, 19]. In contrast, the current study uses Fourier bases to represent the generator $\\hat{J}$ and operator $\\hat{R}(\\theta)$ . ", "page_idx": 3}, {"type": "text", "text": "Since rotation operators can be composed by the generator $\\hat{J}$ via the exponential map (Eq. 8), the neural operator\u2019s representation based on the eigenfunction $f_{\\omega}$ is derived as (details at SI. Sec. 1.2), ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{R}(\\theta)\\circ f_{\\omega}=e^{-i\\omega\\theta}\\cdot f_{\\omega}\\triangleq\\rho_{\\omega}(\\theta)\\cdot f_{\\omega},}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "whose eigenvalue $e^{-i\\omega\\theta}\\ \\triangleq\\ \\rho_{\\omega}(\\theta)$ is regarded as the representation of rotation operator $\\hat{R}(\\theta)$ . Comparing Eqs. (9 and 10), we see the exponential map from the generator to the operator, i.e., $\\hat{R}(\\theta)=\\exp(\\theta\\hat{J})$ , also exists in the representation space, i.e., $\\rho_{\\omega}(\\theta)=\\exp(-i\\omega\\theta)=\\exp[\\theta\\cdot\\rho_{\\omega}(\\hat{J})]$ . The closed-form formula of $\\rho(\\boldsymbol{\\theta})$ is the inner product between the rotated and the original eigenfunctions (multiplying both sides of Eq. (10) by $f_{\\omega}^{\\dagger}$ ( $\\dagger$ : conjugate), and integrating over $x$ ), ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\rho_{\\omega}(\\theta)=\\left\\langle\\hat{R}(\\theta)\\circ f_{\\omega},f_{\\omega}\\right\\rangle=\\int_{-\\pi}^{\\pi}\\left[\\hat{R}(\\theta)\\circ f_{\\omega}\\right]f_{\\omega}^{\\dagger}d x=e^{-i\\omega\\theta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "There is an one-to-one mapping between each operator $\\hat{R}(\\theta)$ and its representation $\\rho_{\\omega}(\\boldsymbol{\\theta})$ . The advantage of using eigenfunctions to represent abstract operators $\\hat{R}(\\theta)$ is searching abstract operators (Eq. 3) can be converted into usual numerical optimization in the representation space. ", "page_idx": 3}, {"type": "text", "text": "2.2 Rotation operator search in the representation space ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Despite the ansatz of the desired operator (Eq. 6), we still need an algorithm explicitly outputting the operator based on neuronal responses. To derive the numerical computation in the representation space, we decompose neural responses $u(s)$ and $u(h)$ by using operators\u2019 eigenfunctions $f_{\\omega}$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{u(s)=\\sum_{\\omega}\\langle u(s),f_{\\omega}\\rangle\\cdot f_{\\omega}=\\sum_{\\omega}U(\\omega|s)f_{\\omega}\\triangleq\\mathcal{F}^{-1}[U(\\omega|s)],}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "corresponding to the inverse Fourier transform. Meanwhile the representation $U(\\omega|s)\\equiv U(s)$ ( $\\omega$ is suppressed unless confusion), called Fourier coefficient, is calculated via Fourier transform, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{U(s)=\\langle u(s),f_{\\omega}\\rangle=\\int_{-\\pi}^{\\pi}u(s)f_{\\omega}^{\\dagger}d x\\triangleq\\mathcal{F}[u(s)],}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "table", "img_path": "Qz7BfmWizk/tmp/c40f08e1137006c9f8598d9b5d18dab0a00a03dce4efa05eaa892cb0bf63e85f.jpg", "table_caption": ["Table 1: Computational complexity. $N$ is the neuron number, i.e., the dimension of $u(s)$ . "], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "Since $u(s)=\\hat{R}(s)\\circ u(0)$ , we have $U(s)=\\rho_{\\omega}(s)U(0)=e^{-i\\omega s}U(0)$ , with $U(0)$ the representation of $u(s=0)$ . Similarly, the representation of the goal neurons\u2019 response $u(h)$ is $\\dot{U}(h)=\\rho_{\\omega}(h)U(0)$ . Referring both $U(s)$ and $\\bar{U}(\\bar{h})$ by $U(0)$ , their representations are $\\rho_{\\omega}(s)$ and $\\rho_{\\omega}(h)$ respectively, and are geometrically visualized as two vectors of unit length with angle $s$ and $h$ respectively (Fig. 2C). ", "page_idx": 4}, {"type": "text", "text": "With sensory and goal neuronal responses\u2019 representations (Eq. 12), the objective function of abstract rotation operators, $L(\\theta)=\\langle\\hat{R}(\\theta)\\circ u(s),u(h)\\rangle$ (Eq. 3), simplifies into a numerical function as the inner product of representations of neuronal responses and operators (see details in SI. Sec. 1.2), ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{L(\\theta)=\\sum_{\\omega}\\big[U(\\omega|s)\\rho_{\\omega}(\\theta)\\big]U(\\omega|h)^{\\dagger}\\leq\\sum_{\\omega}\\|U(\\omega|s)\\rho_{\\omega}(\\theta)\\|\\|U(\\omega|h)\\|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where the Cauchy-Schwartz inequality is used and $\\left\\|a\\right\\|={\\sqrt{a a^{\\dagger}}}$ . The Eq. (14) is maximized only if $U(\\omega|s)\\rho_{\\omega}(\\theta)=\\dot{U}(\\omega|h)$ , implying the representation of the required rotation operator is (Fig. 2D), ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\rho_{\\omega}(\\theta^{*})=U(h)/U(s)=\\rho_{\\omega}(h)/\\rho_{\\omega}(s)=e^{-i\\omega(h-s)}\\ \\ \\Leftrightarrow\\ \\ \\theta^{*}=\\arg\\operatorname*{max}_{\\theta}L(\\theta)=h-s.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In the representation space, the neural operator is a numerical ratio with a closed-form solution, which provides an algorithm to find the operator rather than checking the ansatz (Eq. 6). Moreover, the computational complexity of finding operators in the representation space is much lower than the group convolution (Table 1; SI. Sec. 2): the complexity via the representation space is $\\mathcal{O}(N\\log N)$ with $N$ the neuron number, mainly coming from Fourier transform when using fast Fourier transform (FFT) (Eq. 13) [18]. In contrast, the complexity of the group convolution (Eq. 3) is $\\mathcal{O}(N^{2})$ . Once $\\rho_{\\omega}(\\theta^{\\ast})$ is found (Eq. 15), it can be multiplied with $U(s)$ followed by inverse Fourier transform to rotate the sensory response into the goal direction $u(h)$ , i.e., $\\mathcal{F}^{-1}[U(s)\\bar{\\rho}_{\\omega}(\\theta^{*})]=\\mathcal{F}^{-1}[U(h)]=u(h)$ (Fig. 2E, dashed lines). Nevertheless, this procedure (Fig. 2E, dashed lines) is physically different from actual motor actions, which corresponds to firstly mapping $\\rho_{\\omega}(\\theta^{\\ast})$ back to the physical operator $\\hat{R}(\\theta^{*})$ and acting on $u(s)$ directly (Fig. 2E, solid line). Hence we explore how the neural circuit finds the operator $\\hat{R}(\\theta^{*})$ and use it to physically rotate sensory response $u(s)$ (Fig. 2, solid line). ", "page_idx": 4}, {"type": "text", "text": "3 Towards a neural circuit of motion planning ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "3.1 Sequential motion planning strategy ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In reality, the motor system (muscles) has power constraints and cannot generate actions with too large amplitude, implying it might not rotate the stimulus direction abruptly within an infinitesimal time period. Rather, the brain decomposes a strategic, complex motion action into a continuous sequence of small actions [1, 4], forming a time-continuous process (Fig. 2F), ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{R}(\\theta^{*})\\circ u(s_{0})=\\big[\\cdots\\hat{R}(\\delta\\theta_{t+1})\\hat{R}(\\delta\\theta_{t})\\cdots\\hat{R}(\\delta\\theta_{0})\\big]\\circ u(s_{0})=\\big[\\cdots\\hat{R}(\\delta\\theta_{t+1})\\big]\\circ u(s_{t}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $s_{0}=s$ is the initial stimulus direction, and $\\begin{array}{r}{s_{t}=s_{0}+\\sum_{\\tau=0}^{t}\\delta\\theta_{\\tau}}\\end{array}$ is the direction after applying rotation sequence with angles $\\delta\\theta_{0}$ to $\\delta\\theta_{t}$ . The sequential motion planning imposes a sensory-action loop: after the motor system generates a small rotation $\\hat{R}(\\delta\\theta_{t})$ at time $t$ , the sensory response updates from $\\boldsymbol{u}(\\boldsymbol{s}_{t})$ to $\\boldsymbol{u}(s_{t+1})$ , followed by another rotation $\\hat{R}(\\delta\\theta_{t+1})$ , which repeats over time until the stimulus direction $s$ is rotated to the goal $h$ . Differentiating Eq. (16) over $t$ , utilizing the differential form of operators (Eq. 8), the dynamics of the sensory responses $\\boldsymbol{u}(\\boldsymbol{s}_{t})$ in the sensory-action loop is, ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\frac{d}{d t}u(s_{t})=\\frac{d}{d t}\\hat{R}(\\theta_{t})\\circ u(s_{0})=\\frac{d\\hat{R}(\\theta_{t})}{d\\theta_{t}}\\frac{d\\theta_{t}}{d t}\\circ u(s_{0})=v_{t}\\hat{J}\\hat{R}(\\theta_{t})\\circ u(s_{0})=v_{t}\\hat{J}\\circ u(s_{t}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We see the rotation dynamics is determined by the rotation speed $v_{t}=d\\theta_{t}/d t$ . There are multiple strategies for generating $v_{t}$ sequence and we consider a strategy performing gradient ascent along the objective function (Eq. 3), i.e., the $v_{t}$ at time $t$ is proportional to the gradient of rotation angle $\\theta_{t}$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\nv_{t}=\\lambda\\frac{d L(\\theta_{t})}{d\\theta_{t}}=\\lambda\\frac{d\\langle\\hat{R}(\\theta_{t})\\circ u(s_{0}),u(h)\\rangle}{d\\theta_{t}}=\\lambda\\sum_{\\omega}\\|U(\\omega|s)\\|^{2}\\omega\\sin[\\omega(h-s_{t})],\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "with $\\lambda$ determining the step size. The rotation speed is a sine function of the direction difference $h-s_{t}$ and representing rotation group parameter (comparing Eqs. 18 and 15, Fig. 3D). ", "page_idx": 4}, {"type": "image", "img_path": "Qz7BfmWizk/tmp/e522c02b9fe9ac6ddfd9b5fc1199d16a2e2b183be1f6ca64d17bae171312e389.jpg", "img_caption": ["ATwo-layer feedforward circuit for BDrosophila\u2019s goal-directed  CThe geometry of feedforward D "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Figure 3: (A) The derived feedforward motion planning circuit, composed of circuit motifs of connection phase shift $(r_{\\theta_{\\pm}}$ neurons receive different connection phases from $u(s)$ and $u(h);$ ), nonlinear activation function (left-bottom inset), and pooling $(\\Sigma)$ . The difference between two output neurons $r_{v\\pm}$ conveys the rotation speed $v_{t}$ . (B) Drosophila\u2019s goal-directed navigation circuit (adapted and modified from [21]). Neurons are arranged by their preferred direction $x$ . For illustration, only four PFL3 neurons $(r_{\\theta_{\\pm}}$ neurons in A) are shown. The PFL3 right (green) and left (red) neurons receive heading input $u(\\bar{s})$ with shifted phases and goal input $u(h)$ . Two DN neurons $\\boldsymbol{r}_{v\\pm}$ neurons in A) pool PFL3 left and right neurons respectively and rotate heading direction. (C-D) The geometry of feedforward circuit computation in the representation space. (C): Two populations of $r_{\\theta\\pm}$ neurons rotate the $\\rho_{\\omega}(\\bar{\\theta}_{t})$ by $\\mp\\Delta\\theta$ . The firing rate difference of two output neurons $r_{v\\pm}$ is regarded as the length difference between horizontal green and pink arrows, which is a sine function with $\\bar{\\theta}_{t}=h-s_{t}$ , the distance to the goal direction $h$ (D). ", "page_idx": 5}, {"type": "text", "text": "3.2 A feedforward circuit for motion planning ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The closed-form solution of $v_{t}$ in sequential motion planning (Eq. 18) and the optimal operator (Eq. 15) imply $v_{t}$ can be computed by a feedforward circuit in a single propagation of neural inputs, which would be faster and simpler than a recurrent circuit. We explore how a generic feedforward circuit computes $v_{t}$ (Eq. 18) via receiving sensory response $u(s)$ and goal response $u(h)$ [29], ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{r_{v}(x)=F\\big[\\int w_{s}(x,x^{\\prime})u(x^{\\prime}-s)d x^{\\prime}+\\int w_{h}(x,x^{\\prime})u(x^{\\prime}-h)d x^{\\prime}\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $F(\\cdot)$ is a nonlinear increasing activation function. $w_{s}(x,x^{\\prime})$ and $w_{h}(x,x^{\\prime})$ are feedforward weights from sensory neuron $u(x-s)$ and goal neuron $u(x-h)$ . Two issues are to be resolved for $v_{t}$ computation in feedforward circuits. One is how the feedforward circuit as a nonlinear function of summed neural inputs (Eq. 19) computes $L(\\theta_{t})$ as an inner product of neural inputs $u(s)$ and $u(h)$ (Eq. 18). Another is computing the derivative $d L/d\\theta_{t}$ in the feedforward circuit. ", "page_idx": 5}, {"type": "text", "text": "We propose the feedforward circuit approximates the derivative $d L(\\theta_{t})/d\\theta_{t}$ as a difference form, ", "page_idx": 5}, {"type": "equation", "text": "$$\nv_{t}\\approx\\lambda\\frac{L(\\theta_{t}+\\Delta\\theta)-L(\\theta_{t}-\\Delta\\theta)}{2\\Delta\\theta}=\\frac{\\lambda}{2\\Delta\\theta}\\left[\\langle u(s_{+}),u(h)\\rangle-\\langle u(s_{-}),u(h)\\rangle\\right],\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $s_{\\pm}=(s_{0}+\\theta_{t})\\pm\\Delta\\theta=s_{t}\\pm\\Delta\\theta$ . To implement the inner product (Eq. 18) in the feedforward circuit (Eq. 19), we convert the inner product of two neural inputs into, ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\langle u(s_{\\pm}),u(h)\\rangle=\\left(\\|u(s_{\\pm})+u(h)\\|^{2}-\\|u(s_{\\pm})\\|^{2}-\\|u(h)\\|^{2}\\right)/2.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "$\\begin{array}{r}{\\|u(s_{\\pm})\\|^{2}=\\int u(x-s_{\\pm})^{2}d x}\\end{array}$ where the square function is similar to feedforward circuit\u2019s nonlinear output (Eq. 19). By using the form in Eq. (21), the two inner products\u2019 difference in Eq. (20) is, ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\langle u(s_{+}),u(h)\\rangle-\\langle u(s_{-}),u(h)\\rangle=\\big(\\|u(s_{+})+u(h)\\|^{2}-\\|u(s_{-})+u(h)\\|^{2}\\big)/2,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where we used $\\|u(s_{\\pm})\\|^{2}=\\|u(h)\\|^{2}$ , i.e., the norm of neural responses is irrelevant with represented directions. Eq. (22) suggests computing $L(\\theta_{t}+\\Delta\\theta)-L(\\theta_{t}-\\bar{\\Delta}\\theta)$ for $v_{t}$ (Eq. 28) can be achieved by a two-layer feedforward circuit with each layer containing two neuronal populations (Fig. 3A). ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{First\\,layer:~}r_{\\theta\\pm}(x)=[u(x-s_{\\pm})+u(x-h)]^{2},}\\\\ &{\\mathrm{Second\\,\\,layer:~}r_{v_{\\pm}}=\\int r_{\\theta\\pm}(x)d x=\\|u(s_{\\pm})+u(h)\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "In the 1st layer, each neuronal population $r_{\\theta\\pm}(x)$ computes the square of the sum of sensory and goal inputs, followed by two neurons $r_{v\\pm}$ at the 2nd layer pooling responses $r_{\\theta_{\\pm}}(x)$ at the 1st layer. ", "page_idx": 5}, {"type": "text", "text": "Receiving rotated sensory input $u(s_{\\pm})$ by $\\pm\\Delta\\theta$ can be realized by feedforward weights with shifted connection phase (Fig. 3A, $r_{\\theta\\pm}$ receives connections from $u(s)$ and $u(h)$ with different phases), ", "page_idx": 6}, {"type": "equation", "text": "$$\nw_{\\theta\\pm,s}(x,x^{\\prime})=\\delta(x-x^{\\prime}\\mp\\Delta\\theta),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $w_{\\theta\\pm,s}(x,x^{\\prime})$ is the weight from sensory neuron $u(x^{\\prime}-s)$ to $r_{\\theta_{\\pm}}(x)$ . Eventually, the difference of two neurons at the 2nd layer is proportional to the rotation speed $v_{t}$ (combine Eqs. 20 and 22) ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\left(r_{v_{+}}-r_{v_{-}}\\right)=2\\left[\\langle u(s_{+}),u(h)\\rangle-\\langle u(s_{-}),u(h)\\rangle\\right]\\propto v_{t}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Then each $r_{v\\pm}$ can drive a corresponding effector (e.g., muscle) that generates actual motor actions to rotate the heading direction clockwise or counter-clockwise. ", "page_idx": 6}, {"type": "text", "text": "General nonlinear activation functions. The square function for the first layer neurons $r_{\\theta\\pm}(x)$ (Eq. 23) doesn\u2019t necessarily mean their activation function must be a square function, otherwise our theory and circuit is limited. Instead, the derived feedforward circuit works well with a general nonlinear activation function $F(u)$ monotonically increasing with $u$ (Eq. 19). To see the mechanism of general nonlinear activation functions, we expand it at 0 to the second order, ", "page_idx": 6}, {"type": "equation", "text": "$$\nF(u)\\approx F(0)+F^{\\prime}(0)u+F^{\\prime\\prime}(0)u^{2}/2\\triangleq F_{0}+F_{1}\\cdot u+F_{2}\\cdot u^{2}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Then the neuronal responses $r_{\\theta_{\\pm}}(x_{v})$ can be approximated as, ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{r_{\\theta\\pm}(x)\\approx F_{0}+F_{1}\\cdot[u(x-s_{\\pm})+u(x-h)]+F_{2}\\cdot[u(x-s_{\\pm})^{2}+u(x-h)^{2}],}\\\\ &{\\qquad\\qquad+\\;2F_{2}\\cdot u(x-s_{\\pm})u(x-h),}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Finally, the difference of neurons at the 2nd layer is still proportional to the rotation speed $v_{t}$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{r_{v_{+}}-r_{v_{-}}=\\int r_{\\theta_{+}}(x)d x-\\int r_{\\theta_{-}}(x)d x=2F_{2}\\cdot\\left[\\langle u(s_{+}),u(h)\\rangle-\\langle u(s_{-}),u(h)\\rangle\\right]\\propto v_{t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Again, we used the fact that the summed neuronal activities do not depend on the represented direction, i.e., $\\begin{array}{r}{\\int u(x-s)d x=\\int u(x)d x}\\end{array}$ , and $\\begin{array}{r}{\\int u(x-s)^{2}d x=\\int u(x)^{2}\\dot{d x}}\\end{array}$ . Notably, the 1st layer neuron $r_{\\theta\\pm}$ must have a nonlinear activation function to enable the feedforward circuit to output the rotation speed $v_{t}$ , otherwise (setting $F_{2}=0$ in Eq. 28), the neurons at the 2nd layer, $r_{v\\pm}$ will fully cancel. Overall, the architecture of the derived feedforward circuit utilizes the connection phase shift, nonlinear activation function, and pooling of neuronal activities to compute the rotation speed $v_{t}$ . ", "page_idx": 6}, {"type": "text", "text": "Comparison with Drosophila\u2019s circuit. The derived feedforward circuit is similar to the recently identified Drosophila\u2019s goal-directed navigation circuit (Fig. 3A-B) [20\u201322], which also has a twolayer feedforward architecture receiving the sensory input $u(s)$ (E-PG neurons) and the goal input $u(h)$ (FC neurons) to compute the rotation speed $v_{t}$ . At the 1st layer in Drosophila\u2019s circuit, PFL3 left (right) neuronal population (Fig. 3B, red (green) neurons) combines the shifted sensory input $u(s)$ with angle $\\mp\\Delta\\theta$ respectively with the goal input $u(h)$ , and output via a nonlinear activation function, which are similar to $r_{\\theta\\pm}$ neurons in our feedforward circuit (Fig. 3A). Then the DN left and right neurons at the 2nd layer (equivalent to $r_{v\\pm}$ neurons) pool all activities of PFL3 right and left neurons respectively, and their response difference determines the rotation speed $v_{t}$ [20\u201322]. ", "page_idx": 6}, {"type": "text", "text": "Neural circuit computational complexity. Considering each $r_{\\theta\\pm(x)}$ neuron only receives one feedforward connection from sensory neurons $u(s)$ , i.e., $w_{\\theta\\pm,s}$ is a delta function (Eq. 24), which is the case in Drosophila\u2019s circuit. Then in each time step during sequential rotations, the feedforward circuit computes $\\mathcal{O}(N)$ addition and $\\mathcal{O}(N)$ multiplication (suppose a square activation function). Given a fixed goal direction $h$ , the sequential rotation will take $\\bar{\\mathcal{O}}(\\log\\left|h-s\\right|)$ time steps to rotate from the original direction $s$ into $h$ [19]. Hence the total complexity of feedforward circuit during the whole sequential rotations is ${\\mathcal{O}}(N\\log|h-s|)$ . When the stimulus direction $s$ is close to the goal direction $h$ enough, i.e., $|h-s|<N$ , the computational complexity of the feedforward circuit is even lower than the widely used fast Fourier transform (Eq. 13) with complexity $\\mathcal{O}(N\\log N)$ (Table 1). ", "page_idx": 6}, {"type": "text", "text": "3.3 The geometry of feedforward circuit computation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Although the feedforward circuit doesn\u2019t explicitly use the operator\u2019s representation (Eq. 15, Fig. 2E), the representation space (Eq. 9) provides clear geometrical interpretation of the feedforward circuit computation. Substituting the representation of sensory response $\\boldsymbol{u}(\\boldsymbol{s}_{t})$ at time $t$ and goal response $u(h)$ (Eq. 12) into rotation speed neurons $r_{v\\pm}$ (Eq. 27), ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{r_{v_{\\pm}}=2F_{2}\\cdot\\sum_{\\omega}\\|U(\\omega|0)\\|^{2}\\big[\\rho_{\\omega}(\\bar{\\theta}_{t}\\mp\\Delta\\theta)+\\rho_{\\omega}(\\bar{\\theta}_{t}\\mp\\Delta\\theta)^{\\dagger}\\big]+\\mathrm{const},~~(\\bar{\\theta}_{t}=h-s_{t}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "image", "img_path": "Qz7BfmWizk/tmp/dab00835712aff3d12b3cb232c3189230b73ca0a58515a4715c4861d15a5df67.jpg", "img_caption": ["Figure 4: (A) The full circuit of the sensory-action loop. The diagram is simplified from Drosophila\u2019s goal-directed navigation circuit to illustrate connections, without influencing the circuit function. Only neurons on the right side are labeled and names in the parenthesis denoting Drosophila\u2019s neurons. (B) Top: population response of sensory neurons $u(s)$ in the full circuit. Bottom: The decoded stimulus direction from $u(s)$ moves towards the goal direction. (C) Right and left DN neural activities drive the rotation in (B). (D) Difference between right and left DN linearly matches the moving velocity of sensory representation. (E) Sensory response tracks a moving goal direction. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "const is a constant irrelevant with angles (from the first two terms at Eq. (27), RHS). Geometrically, $r_{v\\pm}$ corresponds to rotate the optimal operator\u2019s representation $\\rho_{\\omega}(\\bar{\\theta}_{t})$ by $\\mp\\Delta\\theta$ , and sum the rotated operator with its complex conjugate (mirrored by the real axis, Fig. 3B), and hence it resides on the real axis. The difference between $r_{v_{+}}$ and $r_{v_{-}}$ , exhibited by the length difference of pink and green arrows in Fig. 3C, is a sine function depending on the optimal operator\u2019s angle ${\\bar{\\theta}}_{t}$ (Fig. 3D). ", "page_idx": 7}, {"type": "text", "text": "4 A full circuit model of the sensory-action loop ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We further assemble the derived feedforward motion planning circuit (Fig. 3A) with concrete sensory and motor circuit modules to construct a full circuit of the sensory-action loop (Fig. 4A) implementing sequential rotations (Eq. 17). For simplicity, the full circuit model only includes the internal motorto-sensory neural feedback (Fig. 1A, blue line) rather than the external loop (Fig. 1A, green lines), with a mildly implicit assumption that the actual sensory feedback from the physical world is the same as the internal motor-to-sensory feedback. To be realistic, all neurons in the full circuit have temporal dynamics, even if our theoretical derivations consider memory-less neurons (Eq. 19). All connection weights have Gaussian profiles spreading over the neuronal space $x$ (SI.Eq. S12), with different peak weights, connection widths and phases. Due to the page limit, we briefly introduce key features of the full circuit here, and its detailed dynamics can be found at SI.Sec. 3. ", "page_idx": 7}, {"type": "text", "text": "Sensory and motor circuit modules. The sensory and motor circuit modules are based on a recent theoretical study that analytically linked Drosophila\u2019s sensory and motor circuit model in its internal compass circuit with the 1D translation/rotation group [28]. The sensory circuit module $u(s)$ is modeled by a ring attractor network that has been experimentally verified in Drosophila\u2019s brain (Fig. 4A, blue ring) [32\u201334]. The ring attractor network uses its rotation-invariant recurrent connections to generate rotation-equivariant sensory representation $u(s)$ [28]. The motor circuit module has two neuronal populations $r_{s\\pm}(x)$ (Fig. 4A, P-EN), whose feedback connections to sensory neurons $u(s)$ are shifted by $\\mp\\Delta x$ towards opposite directions (comparing connections from red and green PB neurons to the ring attractor, Fig. 4A). It was found that these shifted connections give rise to the rotation generator $\\hat{J}$ and the firing rate difference $\\begin{array}{r}{\\sum_{x}[r_{s+}(x)-r_{s-}(x)]}\\end{array}$ determines the rotation speed $v_{t}$ of sensory representation $u(s)$ . Hence we call $r_{s\\pm}$ as rotation generator neurons hereafter. ", "page_idx": 7}, {"type": "text", "text": "Assemble the full sensory-action circuit. The rotation group interpretation of sensory and motor circuits [28] provides a clear interface to connect three circuit modules. Functionally, we use feedforward circuit output neuron $r_{v\\pm}$ to modulate the gain of rotation generator neuron $r_{s\\pm}$ , i.e., multiplying each generator neuron $r_{s_{+}}^{\\ \\ \\hat{}}(x)$ or $r_{s_{-}}(x)$ by feedforward circuit output neuron response (scalar) $r_{v+}$ or $r_{v_{-}}$ respectively. The gain modulation of rotation generator neurons $r_{s\\pm}$ by rotation speed $v_{t}$ was indeed observed in experiments [35]. In addition, the feedforward circuit receives the instantaneous sensory responses $u(x-s)$ (Eq. 19) generated by the ring attractor network. ", "page_idx": 7}, {"type": "text", "text": "Theoretical analysis of the full circuit. We perform theoretical analysis of the full circuit dynamics to verify whether it implements sequential rotations toward the goal direction (Eq. 17). We perform perturbative analysis of the whole circuit dynamics around its attractor states, analytically derive the eigenvector corresponding to the stimulus direction $s$ in the neural dynamics and find the eigenvector of $s$ has the largest eigenvalue suggesting the circuit dynamics is dominated by the movements along the stimulus direction. Then throwing away the circuit dynamics along the subspace perpendicular to the eigenvector of $s$ , we find the sensory responses in the ring attractor embedded into the full circuit are approximately reduced to a form similar to the sequential rotation dynamics (Eq. 17), ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "equation", "text": "$$\n\\frac{d}{d t}u(x-s_{t})\\propto w_{s_{\\pm},s}(r_{v_{+}}-r_{v_{-}})\\cdot\\left[(w_{s,s_{\\pm}}\\Delta x)\\hat{J}\\circ u(x-s_{t})\\right],\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where the difference of motion planning circuit\u2019s output neurons $r_{v_{+}}-r_{v_{-}}$ determines the rotation speed $v_{t}$ (compared to Eq. 17). In Eq. (30), $w_{s,s\\pm}$ and $\\Delta x$ denote respectively the peak weight and the weight shift (absolute value) of the connection from rotation generator neuron $r_{s\\pm}$ to the sensory neuron $u(s)$ in ring attractor (Fig. 4A), and similarly for $w_{s\\pm,s}$ . Further analysis reveals, ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(r_{v_{+}}-r_{v_{-}})\\propto w_{v,\\theta}w_{\\theta,s}^{2}\\cdot\\sum_{\\omega}\\|R(\\omega|0)\\|^{2}\\sin{(\\omega\\Delta\\theta)}\\sin[(\\omega(h-s))],}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $w_{\\theta,s}$ and $w_{v,\\theta}$ are the peak weights from sensory neuron $u(s)$ to neurons $r_{\\theta_{\\pm}}$ , and the one from $r_{\\theta\\pm}$ to the output neuron $r_{v\\pm}$ respectively. $\\Delta\\theta$ is the weight phase shift for the weight from $u(s)$ to $r_{\\theta\\pm}$ (Eq. (24)). $R(\\omega|0)$ is the Fourier transformation of $r(x)$ at $s=0$ . The derivation details can be found in SI. Sec. 4.3. ", "page_idx": 8}, {"type": "text", "text": "We perform numerical simulations of the full sensory-action loop circuit. We fix all circuit parameters and only change the goal direction $h$ that determines goal neurons\u2019 responses $u(h)$ . Fig. 4B shows the represented stimulus direction $s$ in the ring attractor\u2019s population responses $u(s)$ indeed moves towards the goal direction $h$ , which is driven by the activity difference between $r_{v\\pm}$ neurons (Fig. 4C. The full circuit model can also track a moving direction (Fig. 4D), although some delay exists due to the temporal dynamics of neurons (see Discussion). Numerical simulation also confirms the rotation speed of sensory responses is proportional to the response difference between $r_{v\\pm}$ (DN neurons). ", "page_idx": 8}, {"type": "text", "text": "5 Conclusion and Discussion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Motion planning is important in sensorimotor transformation in the brain and embodied agents. The present study formulates motion planning as a group operator search problem and investigates the neural circuit mechanism of operator search goal-directed navigation. Using the 1D rotation group as an example, we analytically derive searching 1D rotation operators can be realized by a two-layer feedforward circuit with three circuit motifs of connection phase shift, nonlinear activation function, and pooling, which is similar to the recently identified goal-directed navigation circuit in Drosophila\u2019s brain [20\u201322]. We further assemble the feedforward sensorimotor transformation circuit with sensory and motor circuit modules into a full circuit of the sensory-action loop which successfully produces sequential rotation dynamics in tracking goal direction (Fig. 4). Our study provides overarching connections between Lie group operator search with a biologically plausible neural circuit model comparable to Drosophila\u2019s circuit. It gains our understanding of neural circuit computations from a structured computation perspective, and also provides a biologically plausible neural network solution for artificial intelligence research. ", "page_idx": 8}, {"type": "text", "text": "5.1 Comparison to other work ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Although the derived feedforward circuit is similar to circuit models in recent neuroscience studies of Drosophilas [20\u201322], there are several notable differences. First, recent circuit models required both neural responses $u(s)$ and $u(h)$ to have a cosine-proflie (pure frequency component at $\\omega=1$ , Eq. 13) [20, 21]. Although the cosine proflie is experimentally supported, our theory releases the requirement of neural response profile, e.g., our sensory-action circuit has Gaussian profile neural responses (Fig. 4A). The generalization may reduce the limitation when deploying the neural circuit model in real applications. Second, goal-directed navigation circuit models in Drosophila\u2019s research [20\u201322] haven\u2019t composed a full circuit of the sensory-action loop as in the present study. In addition, from the group equivariant machine learning perspective, the group operator search theory and the motion planning feedforward circuit in the current study correspond to the sensorimotor transformation stage, which is complementary to many equivariant neural networks corresponding to the sensory system (e.g., [17, 24\u201327]) when building embodied agents. ", "page_idx": 8}, {"type": "text", "text": "5.2 Extensions and limitations of the model ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Extension to complicated scenarios. For the sake of concision and biological solidity, we only demonstrated the 1D rotation case in the main text, but our modeling framework has the potential to extend to more complicated scenarios. The 2D translation group is a sufficient example to explain its generality. An important step in motion planning neural circuit is approximating the derivative of the objective function over the transformation amount (Eq. 18) by the spatial difference in the neural circuit (Eq. 20), i.e., the sensory representation is rotated to the positive and negative direction $(\\theta_{t}+\\Delta\\theta$ and $\\theta_{t}-\\Delta\\theta$ in Eq. 20). This spatial difference strategy can also be used in the 2D case and there are two equivalent circuit solutions. One is considering an allocentric representation with an x-y coordinates, where the sensory representation will be shifted along $\\pm x$ and $\\pm y$ , forming 4 neuron populations analog to PFL3 left and right neurons in our model, which was also considered in spatial representation circuits [36]. Another strategy operates in an egocentric representation with a polar coordinate, and the sensory representation will be shifted along the clockwise and counter-clockwise directions, requiring 2 neuron populations This strategy is supported by a recent experiment ([37]). A simulation result is shown in Fig. S1. ", "page_idx": 9}, {"type": "text", "text": "Non-uniform distribution of neurons. Our model considered neurons are uniformly distributed in the attractor manifolds, a simplification widely used in continuous attractor networks [38\u201341]. Although the assumption holds in Drosophila\u2019s brain, the representation is usually non-uniform in other cases. For non-uniform distributions of neurons in the current circuit model (the $x$ in Eq. S12 is irregular), the same neural circuit dynamics (Eqs. S13-S15 in the SI.) can still approximately facilitate motion planning and rotate heading representations. To realize exact computation in the non-uniform case, the recurrent weights (below Eq.S12 in SI.) need to be fine-tuned numerically, by using a technique similar to [42]. Overall, we think the non-uniform distribution does not alter the neural circuit implementation substantially while it requires new theoretical insights to understand why the system still functions effectively. Besides, the uniform distribution of neurons is only required by the translation symmetry [28], while it can be non-uniform/imperfect in other group structures, e.g., the scaling group would require a log coding [43]. ", "page_idx": 9}, {"type": "text", "text": "False nulling problem. Our feedforward motion planning circuit outputs zero speed when the heading and goal directions are anti-aligned, which is under debate in experiments (e.g., [20] observed maximum speed around the anti-aligned direction while [44] observed the opposite). A reasonable model should not have the \u2018false nulling\u2019 problem (settling at the opposite direction [20]), and one potential circuit solution is introducing PFL2 neurons observed in Drosophila which fire actively at the anti-aligned direction. That is, PFL2 neurons will speed up turning velocity near the opposite direction and provide gain modulation to P-EN to E-PG feedback. Moreover, including PFL2 will only change the $\\lambda$ in our theoretically defined objective function (Eq. 18). ", "page_idx": 9}, {"type": "text", "text": "Future work. From the neurobiology perspective, the direct gain modulation from $r_{v\\pm}$ (DN neurons) to $r_{s\\pm}$ (P-EN neurons) in the full circuit model (Fig. 4A, Eq.S14) needs to be verified by future experiments. It is likely to be the case in Drosophila\u2019s brain because $r_{s\\pm}$ neurons are gain modulated by rotation speed [32\u201334]. From the machine learning point of view, as a proof of concept, we only study the theory and corresponding circuit model for 1D rotation operator search, where the group representation theory (Sec. 2.1 - 2.2) appears unnecessary because an ansatz of the optimal operator can be obtained intuitively (Eq. 6). Nevertheless, the group representation theory and the research protocol in the present study are necessary for searching complicated group operators especially non-commutative groups, e.g., $S O(3)$ and $S E(2)$ , where obtaining the solution of the required operator is non-trivial and no longer intuitive (e.g., [13]). The group representation theory is a normative method that guarantees to find such an operator and derive corresponding circuit models. Extending the motion planning circuit to search more complicated group operators forms our future research. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "W.H.Z. is supported by the UT Southwestern Endowed Scholars program. Y.N.W. is supported by NSF DMS-2015577, NSF DMS-2415226. S.W. is supported by the National Natural Science Foundation of China (No. T2421004), the Science and Technology Innovation 2030-Brain Science and Brain-inspired Intelligence Project (No. 2021ZD0200204). The authors thank Yue Liu and Gengshuo Tian for feedback on an early draft of this manuscript. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Eric R Kandel, James H Schwartz, Thomas M Jessell, Steven Siegelbaum, A James Hudspeth, Sarah Mack, et al. Principles of neural science, volume 4. McGraw-hill New York, 2000.   \n[2] Marc O Ernst and Heinrich H B\u00fclthoff. Merging the senses into a robust percept. Trends in Cognitive Sciences, 8(4):162\u2013169, 2004.   \n[3] Konrad P K\u00f6rding and Daniel M Wolpert. Bayesian decision theory in sensorimotor control. Trends in cognitive sciences, 10(7):319\u2013326, 2006.   \n[4] Richard A Andersen and He Cui. Intention, action planning, and decision making in parietalfrontal circuits. Neuron, 63(5):568\u2013583, 2009. [5] Krishna V Shenoy, Maneesh Sahani, and Mark M Churchland. Cortical control of arm movements: a dynamical systems perspective. Annual review of neuroscience, 36:337\u2013359, 2013. [6] Benjamin Gorko, Igor Siwanowicz, Kari Close, Christina Christoforou, Karen L Hibbard, Mayank Kabra, Allen Lee, Jin-Yong Park, Si Ying Li, Alex B Chen, et al. Motor neurons generate pose-targeted movements via proprioceptive sculpting. Nature, 628(8008):596\u2013603, 2024.   \n[7] Alexandre Pouget and Lawrence H Snyder. Computational approaches to sensorimotor transformations. Nature neuroscience, 3(11):1192\u20131198, 2000.   \n[8] Richard A Andersen and Christopher A Buneo. Intentional maps in posterior parietal cortex. Annual review of neuroscience, 25(1):189\u2013220, 2002. [9] Daniel M Wolpert, J\u00f6rn Diedrichsen, and J Randall Flanagan. Principles of sensorimotor learning. Nature reviews neuroscience, 12(12):739\u2013751, 2011.   \n[10] Caelan Reed Garrett, Rohan Chitnis, Rachel Holladay, Beomjoon Kim, Tom Silver, Leslie Pack Kaelbling, and Tom\u00e1s Lozano-P\u00e9rez. Integrated task and motion planning. Annual review of control, robotics, and autonomous systems, 4:265\u2013293, 2021.   \n[11] Mohamed Elbanhawi and Milan Simic. Sampling-based robot motion planning: A review. Ieee access, 2:56\u201377, 2014.   \n[12] Szil\u00e1rd Aradi. Survey of deep reinforcement learning for motion planning of autonomous vehicles. IEEE Transactions on Intelligent Transportation Systems, 23(2):740\u2013759, 2020.   \n[13] Sangli Teng, Ashkan Jasour, Ram Vasudevan, and Maani Ghaffari. Convex geometric motion planning on lie groups via moment relaxation. arXiv preprint arXiv:2305.13565, 2023.   \n[14] Junfeng Zuo, Xiao Liu, Ying Nian Wu, Si Wu, and Wenhao Zhang. A recurrent neural circuit mechanism of temporal-scaling equivariant representation. Advances in Neural Information Processing Systems, 36, 2023.   \n[15] M Jeannerod and Michael Arbib. Action monitoring and forward control of movements. The handbook of brain theory and neural networks, pages 83\u201385, 2003.   \n[16] Gregory S Chirikjian. Stochastic models, information theory, and Lie groups, volume 2: Analytic methods and modern applications, volume 2. Springer Science & Business Media, 2011.   \n[17] Taco Cohen and Max Welling. Group equivariant convolutional networks. In International conference on machine learning, pages 2990\u20132999. PMLR, 2016.   \n[18] John G Proakis. Digital signal processing: principles, algorithms, and applications, 4/E. Pearson Education India, 2007.   \n[19] Richard C Dorf Robert H Bishop. Modern control systems. 2011.   \n[20] Elena A Westeinde, Emily Kellogg, Paul M Dawson, Jenny Lu, Lydia Hamburg, Benjamin Midler, Shaul Druckmann, and Rachel I Wilson. Transforming a head direction signal into a goal-oriented steering command. Nature, pages 1\u20138, 2024.   \n[21] Peter Mussells Pires, Lingwei Zhang, Victoria Parache, LF Abbott, and Gaby Maimon. Converting an allocentric goal into an egocentric steering signal. Nature, pages 1\u201311, 2024.   \n[22] Rachel I Wilson. Neural networks for navigation: From connections to computations. Annual Review of Neuroscience, 46:403\u2013423, 2023.   \n[23] Andrew MM Matheson, Aaron J Lanz, Ashley M Medina, Al M Licata, Timothy A Currier, Mubarak H Syed, and Katherine I Nagel. A neural circuit for wind-guided olfactory navigation. Nature Communications, 13(1):4613, 2022.   \n[24] Taco Cohen and Max Welling. Learning the irreducible representations of commutative lie groups. In International Conference on Machine Learning, pages 1755\u20131763. PMLR, 2014.   \n[25] Taco S Cohen, Mario Geiger, Jonas K\u00f6hler, and Max Welling. Spherical cnns. arXiv preprint arXiv:1801.10130, 2018.   \n[26] Risi Kondor and Shubhendu Trivedi. On the generalization of equivariance and convolution in neural networks to the action of compact groups. In International Conference on Machine Learning, pages 2747\u20132755. PMLR, 2018.   \n[27] Risi Kondor, Zhen Lin, and Shubhendu Trivedi. Clebsch\u2013gordan nets: a fully fourier space spherical convolutional neural network. Advances in Neural Information Processing Systems, 31, 2018.   \n[28] Wenhao Zhang, Ying Nian Wu, and Si Wu. Translation-equivariant representation in recurrent networks with a continuous manifold of attractors. Advances in Neural Information Processing Systems, 35:15770\u201315783, 2022.   \n[29] Peter Dayan and Laurence F Abbott. Theoretical neuroscience, volume 806. Cambridge, MA: MIT Press, 2001.   \n[30] Alexandre Pouget, Peter Dayan, and Richard S Zemel. Inference and computation with population codes. Annual Review of Neuroscience, 26(1):381\u2013410, 2003.   \n[31] Alexandre Pouget, Jeffrey M Beck, Wei Ji Ma, and Peter E Latham. Probabilistic brains: knowns and unknowns. Nature neuroscience, 16(9):1170, 2013.   \n[32] Sung Soo Kim, Herv\u00e9 Rouault, Shaul Druckmann, and Vivek Jayaraman. Ring attractor dynamics in the drosophila central brain. Science, 356(6340):849\u2013853, 2017.   \n[33] Jonathan Green, Atsuko Adachi, Kunal K Shah, Jonathan D Hirokawa, Pablo S Magani, and Gaby Maimon. A neural circuit architecture for angular integration in drosophila. Nature, 546(7656):101\u2013106, 2017.   \n[34] Anna Kutschireiter, Melanie A Basnak, Rachel I Wilson, and Jan Drugowitsch. A bayesian perspective on the ring attractor for heading-direction tracking in the drosophila central complex. bioRxiv, 2021.   \n[35] Daniel Turner-Evans, Stephanie Wegener, Herve Rouault, Romain Franconville, Tanya Wolff, Johannes D Seelig, Shaul Druckmann, and Vivek Jayaraman. Angular velocity integration in a fly heading circuit. Elife, 6:e23496, 2017.   \n[36] Yoram Burak and Ila R Fiete. Accurate path integration in continuous attractor network models of grid cells. PLoS computational biology, 5(2):e1000291, 2009.   \n[37] Abraham Z. Vollan, Richard J. Gardner, May-Britt Moser, and Edvard I. Moser. Left-rightalternating theta sweeps in the entorhinal-hippocampal spatial map. bioRxiv, 2024.   \n[38] R Ben-Yishai, R Lev Bar-Or, and H Sompolinsky. Theory of orientation tuning in visual cortex. Proceedings of the National Academy of Sciences, 92(9):3844\u20133848, 1995.   \n[39] Si Wu, Kosuke Hamaguchi, and Shun-ichi Amari. Dynamics and computation of continuous attractors. Neural Computation, 20(4):994\u20131025, 2008.   \n[40] Wen-Hao Zhang, Aihua Chen, Malte J Rasch, and Si Wu. Decentralized multisensory information integration in neural systems. The Journal of Neuroscience, 36(2):532\u2013547, 2016.   \n[41] Mikail Khona and Ila R. Fiete. Attractor and integrator networks in the brain. Nature Reviews Neuroscience, 23(12):744\u2013766, December 2022.   \n[42] Marcella Noorman, Brad K Hulse, Vivek Jayaraman, Sandro Romani, and Ann M Hermundstad. Accurate angular integration with only a handful of neurons. bioRxiv, 2022.   \n[43] Carlos Esteves, Christine Allen-Blanchette, Xiaowei Zhou, and Kostas Daniilidis. Polar transformer networks. arXiv preprint arXiv:1709.01889, 2017.   \n[44] Jonathan Green, Vikram Vijayan, Peter Mussells Pires, Atsuko Adachi, and Gaby Maimon. A neural heading estimate is compared with an internal goal to guide oriented navigation. Nature neuroscience, 22(9):1460\u20131468, 2019. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 13}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 13}, {"type": "text", "text": "Justification: We summarize our claims and contribution clearly in the Abstract and Introduction, and also discuss the limitation and extension of the current work in Discussion. ", "page_idx": 13}, {"type": "text", "text": "Guidelines: ", "page_idx": 13}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 13}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 13}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Justification: It can be found in the Discussion section. ", "page_idx": 13}, {"type": "text", "text": "Guidelines: ", "page_idx": 13}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 13}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 13}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 13}, {"type": "text", "text": "Justification: We clearly state the assumptions in deriving the circuit model (Sec. 3-4 in the main text) ", "page_idx": 14}, {"type": "text", "text": "Guidelines: ", "page_idx": 14}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 14}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 14}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 14}, {"type": "text", "text": "Justification: The SI. Sec. 5 has sufficient details about the network simulation. Guidelines: ", "page_idx": 14}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 14}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 14}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 15}, {"type": "text", "text": "Justification: Codes have been included in supplementrary materials. Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 15}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 15}, {"type": "text", "text": "Justification: This is not a study about learning, while the details of model simulation is presented as SI. Sec. 5. ", "page_idx": 15}, {"type": "text", "text": "Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 15}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 15}, {"type": "text", "text": "Answer: [No] ", "page_idx": 15}, {"type": "text", "text": "Justification: This is a theoretical study of Lie group theory and dynamical system theory and doesn\u2019t involve statistics. ", "page_idx": 15}, {"type": "text", "text": "Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: Please refer to SI. Sec. 5. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 16}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: We confirm our study conform the Code of Ethics. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 16}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 16}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 16}, {"type": "text", "text": "Justification: This is a theoretical study for basic science research and will not have direct societal impacts. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 17}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 17}, {"type": "text", "text": "Justification: This is a theoretical study for basic science research and will not incur any risk. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 17}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: We adapt one figure from a recent experimental paper (Fig. 3B) and we state where that figure is from. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: The main result of this paper is its theoretical derivations. And the code of simulating the model is uploaded. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 18}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 18}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 18}]