[{"type": "text", "text": "HYSYNTH: Context-Free LLM Approximation for Guiding Program Synthesis ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Shraddha Barke UC San Diego San Diego, USA sbarke@ucsd.edu ", "page_idx": 0}, {"type": "text", "text": "Emmanuel Anaya Gonzalez UC San Diego San Diego, USA fanayagonzalez@ucsd.edu ", "page_idx": 0}, {"type": "text", "text": "Saketh Ram Kasibatla   \nUC San Diego   \nSan Diego, USA   \nskasibatla@ucsd.edu   \nTaylor Berg-Kirkpatrick UC San Diego San Diego, USA   \ntbergkirkpatrick@ucsd.edu   \nNadia Polikarpova   \nUC San Diego   \nSan Diego, USA   \nnpolikarpova@ucsd.edu ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Many structured prediction and reasoning tasks can be framed as program synthesis problems, where the goal is to generate a program in a domain-specific language (DSL) that transforms input data into the desired output. Unfortunately, purely neural approaches, such as large language models (LLMs), often fail to produce fully correct programs in unfamiliar DSLs, while purely symbolic methods based on combinatorial search scale poorly to complex problems. Motivated by these limitations, we introduce a hybrid approach, where LLM completions for a given task are used to learn a task-specific, context-free surrogate model, which is then used to guide program synthesis. We evaluate this hybrid approach on three domains, and show that it outperforms both unguided search and direct sampling from LLMs, as well as existing program synthesizers. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Large language models (LLMs) demonstrate impressive capabilities in various domains, but they continue to struggle with tasks that require precision\u2014e.g. structured prediction, reasoning, counting, or data transformation\u2014when direct task examples are not prevalent in their training data [8, 12, 23, 31, 38, 40, 45]. As one example, consider the Abstraction and Reasoning Corpus (ARC) [14], which was designed as a benchmark for human-like structured reasoning. ARC tasks are grid-based puzzles, such as one depicted in Fig. 1a. This puzzle consists of three training examples, which are pairs of input and output grids; the goal is to infer the transformation that maps the input to the output, and then apply this transformation to the test grid. The ARC benchmark\u2019s emphasis on generalization and few-shot learning has rendered it challenging to solve with purely machine learning techniques: state-of-the-art generative models like GPT-4 hardly solve more than $10\\%$ of the tasks in the dataset when asked to predict the test output, even with the help of advanced prompting techniques [25]. ", "page_idx": 0}, {"type": "text", "text": "In fact, the leading entries in the ARC Kaggle competition [1] tackle this task using Programming-byExample (PBE): instead of predicting the output directly, they search for a program that captures the transformation occurring in the input-output examples. For example, the transformation in Fig. 1a might be represented as the following program: ", "page_idx": 0}, {"type": "text", "text": "if color_of(self) $=$ GREY \u2227is_neighbor(self, other) \u2227size_of(other) = MIN ", "page_idx": 0}, {"type": "image", "img_path": "5jt0ZSA6Co/tmp/adcab077d8ca2c7971f132c71ac4d1f417756fcc86781250c2fdfe76b6e6666b.jpg", "img_caption": ["Figure 1: Example problems from the three PBE domains we evaluate HYSYNTH on: grid-based puzzles (ARC), tensor manipulation (TENSOR), and string manipulation (STRING). "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "This particular program is written in a domain-specific language (DSL) inspired by the ARGA tool [44]. It consists of a single rule of the form if filter then transform, which is applied to each object in the grid simultaneously; if the fliter holds for the focus object self and another object other, then self undergoes the transform. In this case, the rule says that any grey object that has a neighbor of the grid\u2019s minimum size (here, a single pixel) should be colored with the color of that neighbor. ", "page_idx": 1}, {"type": "text", "text": "Beyond grid puzzles, PBE is a general paradigm for structured reasoning and data transformation tasks: for example, it can help spreadsheet users with systematic string manipulation [20], and help programmers use unfamiliar APIs [17, 18, 36]; Fig. 1 shows example PBE tasks from three domains. ", "page_idx": 1}, {"type": "text", "text": "Challenge: Harnessing the Power of LLMs for PBE How can we automatically learn programs from the input-output examples like those shown in Fig. 1? The traditional program synthesis approach is based on combinatorial search [2, 7, 34, 35, 39], which works well for small programs and restrictive DSLs, but becomes infeasible as the program size and the DSL complexity grow. At the other end of the spectrum, purely neural approaches [15, 42] use a neural model to predict the program from input-output examples; unfortunately, even state-of-art LLMs like GPT-4o [33] struggle to predict an entire program in an unfamiliar DSL: when we asked GPT-4o to generate 10 programs for the running example above, none of them were entirely correct.1 ", "page_idx": 1}, {"type": "text", "text": "In the past, the limitations of both program synthesis and neural techniques have motivated a hybrid approach, where combinatorial search is guided by a learned probabilistic model [9, 24, 26, 32, 36, 37]. Existing hybrid techniques, however, use domain-specific models trained on datasets of similar PBE tasks, which limits their generalization to new domains. With the advent of LLMs, can we now use a single pre-trained model to guide program synthesis across a wide range of domains? ", "page_idx": 1}, {"type": "text", "text": "Interestingly, there is some tension in the hybrid approach between the efficiency of the search algorithm and the power of the model: a search algorithm is efficient when it factorizes the search space (i.e., merges many search states into one), which often makes it incompatible with a powerful model that requires a lot of context to make a prediction. Specifically, one of the most widely used program synthesis techniques is bottom-up search [2, 11, 28, 36, 39], which is a dynamic programming algorithm, whose efficiency relies on reusing the work of constructing and evaluating subprograms in many different contexts. This essentially precludes using models with unlimited left-to-right context\u2014like LLMs\u2013to guide bottom-up search. ", "page_idx": 1}, {"type": "text", "text": "Our Solution: Context-Free LLM Approximation To bridge this gap and harness the power of LLMs to guide bottom-up search, we propose to approximate the LLM\u2019s conditional output distribution for a given task with a context-free surrogate model. Recent work in NLP [46] has found that a Hidden Markov Model (HMM) trained to match an LLM can be used as an efficient surrogate in style-controlled language generation. We extend this idea to program synthesis, replacing the HMM with a probabilistic context-free grammar (PCFG). The beneftis of using a PCFG are twofold: (1) PCFGs are context-free, which makes them compatible with bottom-up search for PBE [11, 36], and (2) while a context-free model may make a poor approximation to an LLM\u2019s full joint, in a PBE setting it is able to reasonably approximate an LLM\u2019s conditional distribution over output programs for a given prompt. The overview of our approach is shown in Fig. 2. ", "page_idx": 1}, {"type": "image", "img_path": "5jt0ZSA6Co/tmp/fb3761d0ae07aabd5c7bc8b5a6b9a9a75d3a8c00d9026c7c6bb5e9f9e811b0f6.jpg", "img_caption": ["Figure 2: An overview of the hybrid program synthesis technique that uses a context-free LLM approximation. Programs generated by an LLM are used to learn a PCFG, which guides a bottom-up synthesizer to generate programs until a solution is found. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Evaluation We implemented this technique in a tool $\\mathrm{HYSYNTH}^{2}$ and evaluated it on 299 PBE tasks from three domains: ARC grid-based puzzles [14], tensor manipulation tasks from TFCODER [36], and string manipulation tasks from the SYGUS benchmark [5], which are inspired by spreadsheet use cases. Example problems from these domains are shown in Fig. 1. Our evaluation shows that HYSYNTH outperforms both unguided search and LLMs alone, solving $58\\%$ of the tasks overall, compared to $40\\%$ for unguided search and $6\\%$ for LLMs without search. Our tool also outperforms baseline program synthesizers for these domains\u2014ARGA, TFCODER, and PROBE [11], respectively; importantly, in the TENSOR domain, the guidance from the LLM not only speeds up the search, but also frees the user from having to explicitly provide any non-standard constants that the solution might use, thereby significantly improving the usability of the tool. ", "page_idx": 2}, {"type": "text", "text": "Contributions In summary, this paper makes the following contributions: ", "page_idx": 2}, {"type": "text", "text": "1. We propose a hybrid program synthesis approach that integrates LLMs with efficient bottomup search via a task-specific context-free approximation.   \n2. We implement this approach in a tool HYSYNTH and instantiate it on three domains: gridbased puzzles (ARC), tensor manipulation (TENSOR), and string manipulation (STRING). While the latter two domains reuse off-the-shelf bottom-up synthesizers, for ARC we implement a custom synthesizer that uses a divide-and-conquer strategy [6] to leverage the structure of the rule-based DSL to further speed up the search.   \n3. We evaluate HYSYNTH on the three domains and show that it outperforms both the LLM alone and existing baseline synthesizers, which are not guided by LLMs. ", "page_idx": 2}, {"type": "text", "text": "2 Background ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "2.1 Programming-By-Example ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Programming by Example (PBE) [21] is the task of synthesizing programs that satisfy a given set of input-output examples. To restrict the program space, the programs are typically drawn from a domain-specific language (DSL), which is specified by a context-free grammar and an evaluation function. This section provides a formal definition of these concepts. ", "page_idx": 2}, {"type": "text", "text": "Context-Free Grammars A context-free grammar (CFG) is a quadruple $\\mathcal{G}=(\\mathcal{N},\\Sigma,S,\\mathcal{R})$ , where $\\mathcal{N}$ is a set of non-terminal symbols, $\\Sigma$ is a set of terminal symbols, $s\\in\\mathcal{N}$ denotes the starting ", "page_idx": 2}, {"type": "equation", "text": "$$\n{\\begin{array}{r l r l}{R u l e\\rightarrow}&{\\mathbf{if}\\;F i l t e r\\;\\mathbf{then}\\;T r a n s f o r m}&{C o l o r\\rightarrow}&{\\mathbf{color}_{-0}\\mathbf{f}\\;(O b j)\\;\\left|\\;\\mathbf{dex}\\right|\\;\\mathbf{Rep}\\;...}\\\\ {F i l t e r\\rightarrow}&{A t o m\\;\\left|\\;\\mathbf{not}\\;A t o m\\;\\middle|\\;A t o m\\;\\middle|\\;A t o m\\;\\middle|\\;...\\;}&{S i z e\\rightarrow}&{\\mathbf{size}_{-0}\\mathbf{f}\\;(O b j)\\;\\middle|\\;\\forall\\mathbf{I}\\;\\mathbf{N}\\;\\middle|\\;...}\\\\ {A t o m\\rightarrow}&{C o l o r{=}\\;C o l o r\\;\\left|\\;S i z e=\\mathbf{s}\\;S i z e\\;\\middle|\\;...\\;}&{D i r\\rightarrow}&{\\mathbf{dir}_{-0}\\mathbf{f}\\;(O b j)\\;\\middle|\\;\\mathbf{y}\\;\\middle|\\;\\mathbf{D}0\\mathbf{W}\\;\\middle|\\;...}\\\\ {a n s f o r m\\rightarrow}&{\\mathbf{update}_{-}\\mathbf{color}\\;(C o l o r)\\;\\middle|\\;\\mathbf{move}\\;(D i r)\\;\\middle|\\;...\\;}&{O b j\\rightarrow}&{\\mathbf{self}\\;\\middle|\\;x\\;\\middle|\\;y\\;\\middle|\\;...}\\end{array}}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "non-terminal, and $\\mathcal{R}$ is the set of production rules. An example CFG is shown in Fig. 3. We denote with ${\\mathcal{R}}(\\mathbf{N})$ the set of all rules $\\mathbf{R}\\in\\mathcal{R}$ whose left-hand side is N. A grammar $\\mathcal{G}$ defines a (leftmost) single-step derivation relation on sequences of symbols: $s\\mathrm{N}\\alpha\\Rightarrow s\\beta\\alpha$ if $\\Nu\\rightarrow\\beta\\in\\mathcal{R}$ , where $s\\in\\Sigma^{*}$ and $\\alpha,\\beta\\in(N\\cup\\Sigma)^{*}$ . The transitive closure of this relation $\\Rightarrow^{*}$ is called (leftmost) derivation. ", "page_idx": 3}, {"type": "text", "text": "Programs A program $P\\,\\in\\,\\Sigma^{*}$ is a terminal sequence derivable from some $\\Nu\\in\\mathcal{N}$ ; we call a program whole if it is derivable from $\\boldsymbol{S}$ . The set of all programs is called the language of the grammar $\\mathcal{G}$ : $\\bar{\\mathcal{L}}(\\mathcal{G})\\,=\\,\\{s\\,\\in\\,\\Sigma^{*}\\;\\vert\\;\\,\\mathrm{N}\\,\\Rightarrow^{*}\\,s\\}$ . The trace of a program $\\mathrm{tr}(P)$ is the sequence of production rules $\\mathbf{R}_{1},\\ldots,\\mathbf{R}_{n}$ used in its derivation $(\\mathbf{N}\\Rightarrow\\alpha_{1}\\Rightarrow...\\Rightarrow\\alpha_{n-1}\\Rightarrow P)$ ). The size of a program $|P|$ is the length of its trace. The semantics of a program $P$ is defined by the evaluation function $\\mathrm{\\bar{[}}P\\mathrm{\\dot{]}\\colon V a l^{*}\\ \\rightarrow\\bar{\\ V a l}}$ , which maps the values of program variables to its output value. ", "page_idx": 3}, {"type": "text", "text": "Problem Statement A PBE problem is defined by a DSL with a grammar $\\mathcal{G}$ and an evaluation function $[\\![\\cdot]\\!]$ , as well as a set of input-output examples $\\dot{\\varepsilon}=\\overrightarrow{\\langle i,o\\rangle}$ where $i\\in\\mathrm{Val}^{*}$ , $o\\in\\mathrm{Val}$ . A solution to the pr o b lem is a program $P\\in{\\mathcal{L}}({\\mathcal{G}})$ such that $\\forall\\langle i,o\\rangle\\in\\mathcal{E}$ , $\\mathbb{[}P\\mathbb{]}(i)=o$ . ", "page_idx": 3}, {"type": "text", "text": "2.2 Assigning Costs to Programs ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Weighted Context-free Grammar A weighted context-free grammar (WCFG) $\\mathcal{G}_{w}$ is a pair of a CFG $\\mathcal{G}$ and a function $w_{\\mathbb{R}}:\\mathcal{R}\\to\\mathbb{R}^{+}$ that maps each production rule $\\mathbf{R}\\in\\mathcal{R}$ to a positive weight. Given a weighted grammar $\\mathcal{G}_{w}$ , we can define the real cost of a program $P$ as the sum of weights of all the productions in its trace: $\\begin{array}{r}{\\mathrm{cost}_{\\mathbb{R}}(P)=\\sum_{\\mathbf{R}_{i}\\in\\mathrm{tr}(P)}w_{\\mathbb{R}}(\\mathbf{R}_{i})}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "For the purposes of search, it is convenient to define a discrete weight function $w:\\mathcal{R}\\to\\mathbb{Z}^{+}$ , which rounds weights up to the nearest integer: $w(\\mathbf{R})=\\lceil w_{\\mathbb{R}}(\\mathbf{R})\\rceil$ . The (discrete) cost of a program $P$ is defined as the sum of discrete production weights: $\\begin{array}{r}{\\mathrm{cost}(P)=\\sum_{\\mathbf{R}_{i}\\in\\mathrm{tr}(P)}w(\\mathbf{R}_{i})}\\end{array}$ . Note that because of error accumulation, the discrete cost of a program can differ from its rounded real cost, but the difference can be made arbitrarily small by scaling all the costs by a constant factor $\\alpha>1$ . ", "page_idx": 3}, {"type": "text", "text": "Probabilistic Context-free Grammar A popular way to assign weights to production rules is via a probabilistic context-free grammar (PCFG). A PCFG $\\mathcal{G}_{p}$ is a pair of a CFG $\\mathcal{G}$ and a function $p:\\mathcal{R}\\to[0,1]$ that maps each production rule $\\mathbf{R}\\in\\mathcal{R}$ to its probability, such that probabilities of all the rules for a given non-terminal $\\Nu\\in\\mathcal{N}$ sum up to one: $\\begin{array}{r}{\\forall\\bar{\\mathbf{N}}.\\sum_{\\mathbf{R}\\in\\mathcal{R}(\\mathbf{N})}p(\\mathbf{R})=\\bar{1}}\\end{array}$ . A PCFG defines a probability distribution on programs: $\\begin{array}{r}{p(P)=\\prod_{\\mathrm{R}_{i}\\in\\mathrm{tr}(P)}p(\\mathbf{R}_{i})}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "Given a PCFG $(\\mathcal{G},p)$ we can derive a WCFG $\\mathcal{G}_{w}$ where $w_{\\mathbb{R}}(\\mathbf{R})=-\\log(p(\\mathbf{R}))$ ; to make sure that all weights are finite and positive, we exclude rules with $p(\\mathbf{R})=0$ and inline rules with $p(\\mathbf{R})=1$ . In this WCFG, the real cost of a program is related to its probability: $\\mathrm{cost}_{\\mathbb{R}}(P)=-\\log(p(P))$ . ", "page_idx": 3}, {"type": "text", "text": "2.3 Bottom-up Search ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Bottom-up search is a popular search technique in program synthesis [2, 11, 28, 36, 39], which enumerates programs from the DSL in the order of increasing costs until it finds a program that satisfies the given examples. The search is implemented as a dynamic programming algorithm (see Alg. 1), which maintains a program bank B mapping discrete costs to programs of that cost. Starting with an empty bank and current cost level $\\mathrm{LVL}=1$ , the search iteratively creates all programs of cost 1, 2, 3, and so on; to create complex programs, the algorithm reuses simpler programs already stored in the bank, and combines them using the production rules of the grammar. ", "page_idx": 3}, {"type": "text", "text": "For example, consider the CFG in Fig. 3, and assume a uniform weight function $w(\\cdot)=1$ . Then in the first iteration (cost level 1), the algorithm will enumerate programs consisting of a single literal or variable\u2014e.g. self, GREY, UP, etc\u2014and store them in ${\\bf B}[1]$ . At cost level 2, it will enumerate unary operators applied to programs stored in B[1]: e.g. color_of(self), move(UP), etc. More generally, at cost level LVL, the algorithm considers all available productions, and for each production, enumerates all combinations of arguments whose costs sum up to $\\mathrm{LVL-1}$ . ", "page_idx": 3}, {"type": "table", "img_path": "5jt0ZSA6Co/tmp/709a739f0614bce5cce11ae44ad75511caffa21ebf11b1cb881e2d1cc4b0a1ac.jpg", "table_caption": [], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "During search, each candidate expression is evaluated to see if it satisfies the examples (lines $^{5-}$ 7). Importantly, the search maintains a cache of all evaluation results E, and discards the newly constructed program if it is observationally equivalent to a program already in the bank (line 8), i.e. if it evaluates to the same output for all inputs in the examples. This step is the key to the efficiency of the bottom-up search algorithm: it allows the synthesizer to factorize the search space by evaluation result, significantly reducing the number of programs explored at each cost level. ", "page_idx": 4}, {"type": "text", "text": "3 The HYSYNTH Approach ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "A key challenge in program synthesis is the astronomical size of the search space the synthesizer has to explore. For example, to find the program Eq. 1, the solution to the ARC task from the introduction, bottom-up search with a uniform weight function has to enumerate around 450K programs (all programs of size $\\le16$ ), which takes 4.5 minutes in our experiments. ", "page_idx": 4}, {"type": "text", "text": "On the other hand, sampling solutions to this task from an LLM yields programs that are close to the desired solution, even if not quite correct. As we show in Appendix A, GPT-4o uses relevant components update_color, color_of, and is_neighbor in nearly all of its solutions (usually missing some part of the fliter or using the wrong color in the transform), and never uses irrelevant components like move or rotate. This suggests that the LLM generally has the right intuition about the components the solution needs to use; our insight is to leverage this intuition to guide bottom-up search by assigning lower weights to the components that the LLM uses frequently. ", "page_idx": 4}, {"type": "text", "text": "3.1 Guiding Bottom-up Search with Context-Free LLM Approximation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The overview of our approach, HYSYNTH, is shown in Fig. 2. Given a PBE problem consisting of a DSL with grammar $\\mathcal{G}$ and a set of input-output examples $\\mathcal{E}$ , HYSYNTH proceeds in three steps. ", "page_idx": 4}, {"type": "text", "text": "Step 1: Sampling Solutions from an LLM HYSYNTH starts by creating an LLM prompt that contains $\\mathcal{G}$ and $\\mathcal{E}$ ; the prompt can be optionally augmented with in-context examples if they are available for the given DSL. A complete prompt for the ARC running example can be found in Appendix B. The LLM is then used to sample a set $\\{S_{i}\\}_{i=1}^{N}$ of completions; the choice of $N$ trades off computational cost and the faithfulness of the approximation to the true LLM conditional. ", "page_idx": 4}, {"type": "text", "text": "Step 2: Learning a PCFG from LLM Solutions Next, HYSYNTH attempts to parse each completion $S_{i}$ into a program $P_{i}$ using the grammar $\\mathcal{G}$ . The resulting set of programs $\\bar{\\{P_{i}\\}}_{i=1}^{N^{\\prime}}$ (where $N^{\\prime}\\leq$ N) is used to learn a PCFG Gp via maximum likelihood estimation: p(R) = R\u2208Rc coouunnt(t(RR))++\u03b1\u03b1\u00d7|R|. Here count(R) is the frequency of rule R in all the derivations of the programs in $\\{P_{i}\\}$ and $\\alpha$ is a smoothing parameter that ensures that every rule has a non-zero probability (typically set to 1). ", "page_idx": 5}, {"type": "text", "text": "Our experiments show that some models struggle to generate grammatical completions, leading to $N^{\\prime}\\ll\\Bar{N}$ . To increase the sampling efficiency in those cases, HYSYNTH implements non-strict mode, where ungrammatical completions $S_{i}$ are not discarded. Instead the tool performs lexical analysis on $S_{i}$ to convert it into a sequence of terminals and approximates the frequency of each production $\\mathbf{R}$ based on the frequency of its operator terminal, a designated terminal of R, which represents a DSL operator; e.g. count(Atom \u2192not $A t o m)=\\mathrm{count}(\\mathsf{n}\\bar{\\mathsf{o}}\\mathsf{t})$ .3 ", "page_idx": 5}, {"type": "text", "text": "Step 3: Guiding Bottom-up Search with PCFG Finally, HYSYNTH uses the PCFG computed in the previous step to derive a weighted grammar $\\mathcal{G}_{w}$ as explained in Sec. 2.2, and uses it to initialize the bottom-up search procedure in Alg. 1. As a result, the search is guided by the insights from the the LLM. For example, the WCFG learned from the GPT-4o completions for the ARC task above gives the relevant transform operator update_color weight 2, while all other Transform rules have weight 4; the relevant filter operators color_of and is_neighbor are similarly down-weighted. As a result, the search procedure only has to enumerate around 220K programs instead of 450K, achieving a ${4\\bf{x}}$ speedup, and solving the motivating example in just one minute with LLM guidance. ", "page_idx": 5}, {"type": "text", "text": "3.2 Domain-Specific Instantiations ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We now describe how the HYSYNTH approach is instantiated in three different domains: ARC grid puzzles, TENSOR manipulations, and STRING manipulations. ", "page_idx": 5}, {"type": "text", "text": "ARC Domain An example task from this domain is shown in Fig. 1a and has been used as a running example throughout this paper. There is no established DSL for ARC, and arguably, DSL design is the biggest challenge when attempting to solve ARC using a PBE approach, since it is hard to capture the wide variety of tasks in this domain. Our DSL is inspired by the rule-based language of ARGA [44], which we modified slightly to make it more compositional. ", "page_idx": 5}, {"type": "text", "text": "A program in our DSL is a sequence of rules of the form if fliter then transform. A rule refers to the current object self, which is modified by the transform if the fliter is satisfied in the current state of the grid. The rule can also refer to other objects in the grid, such as other in Eq. 1. This program is well-defined because its fliter uniquely identifies the object other; if the fliter is too weak to uniquely determine the effect of the transform, the program\u2019s output is considered undefined. The full grammar of our DSL can be found in Appendix H. ", "page_idx": 5}, {"type": "text", "text": "Instead of searching for a complete program using Alg. 1, we further optimize our synthesizer using a divide-and-conquer strategy inspired by [6], searching for filters and transforms separately. Specifically, HYSYNTH-ARC first searches for transforms that are correct on some objects in the grid; once it has found a set of transforms that collectively describe all grid objects, it searches for filters that distinguish between the subsets of objects changed by each transform. ", "page_idx": 5}, {"type": "text", "text": "Consider once again our running example. When the transform synthesizer enumerates the expression update_color(color_of(other)), it detects that this transform works for all grey objects, because for each grey object self there exists a corresponding object other whose color can be copied. Now the goal of filter synthesis is to find a boolean expression that holds exactly for those pairs of objects (self, other) that make the transform work. See Appendix K for more details about this algorithm. ", "page_idx": 5}, {"type": "text", "text": "TENSOR Domain This domain originates from the TFCODER synthesizer [36], which takes as input examples of a tensor transformation (with an optional natural language description) and synthesizes a TensorFlow program that performs the transformation. An example task from this domain is shown in Fig. 1b, whose solution is: tf.gather_nd(in1, tf.stack((in2, in3), $\\mathsf{a}\\!\\times\\!\\dot{\\mathsf{i}}\\mathsf{s}\\!=\\!-1\\!;$ )). The main challenge, however, is that the TensorFlow grammar is very large (see Appendix G), and most importantly, the programs are allowed to use an unbounded set of constants. The original TFCODER synthesizer requires the user to provide any non-standard constants that a task might require, and, according to their paper, this is the main barrier to the usability of their tool. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "For program synthesis in this domain we use the TFCODER synthesizer off the shelf. TFCODER performs weighted bottom-up search, using a combination of hand-tuned weights and weights derived by two custom-trained neural models. HYSYNTH-TENSOR replaces these weights entirely with weights computed by sampling from an LLM. Importantly, our version of the tool does not require the user to provide any constants; instead we extract constants from the LLM completions, whereby significantly reducing the burden on the user. ", "page_idx": 6}, {"type": "text", "text": "STRING Domain Our third domain involves string manipulation tasks from the SYGUS competition [4], which are inspired by spreadsheet use cases. An example task, which requires extracting the top-level domain name from a URL, is shown in Fig. 1c. In this domain we use the PROBE [11] synthesizer off the shelf. PROBE performs weighted bottom-up search, starting with a uniform grammar and updating the weights on the fly; HYSYNTH-STRING instead initializes PROBE\u2019s search with weights derived from an LLM, and disables the weight updates during search. ", "page_idx": 6}, {"type": "text", "text": "4 Experiments and Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "4.1 Experimental Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We evaluate HYSYNTH on 299 PBE tasks from three different domains: ARC (160 tasks), STRING (70 tasks) and TENSOR (69 tasks). ", "page_idx": 6}, {"type": "text", "text": "ARC Benchmark The 160 ARC tasks are taken from the testing set of ARGA [44]. This objectcentric subset of the full ARC corpus is known as OBJECT-ARC, and has been used to evaluate other ARC solvers [27]. ARC specifications consist of 2-7 input-output training grids and 1 testing grid. Correctness is based on whether the generated solution produces the correct output on the testing grid. Our ARC DSL has a total of 20 operations and 50 constants and variables across all types. ", "page_idx": 6}, {"type": "text", "text": "TENSOR Benchmark The 69 TENSOR tasks taken from TFCODER focus on tensor manipulation. 49 of them are sourced from StackOverflow inquiries, and 20 are from real-world scenarios faced by TensorFlow users at Google. The overall benchmark suite consists of 72 tasks. We use three of these tasks as in-context examples and evaluate on the rest. The grammar for this domain consists of 134 Tensorflow operations, primitives like 0, 1, -1, True and other task-specific constants. ", "page_idx": 6}, {"type": "text", "text": "STRING Benchmark The 70 STRING tasks are taken from testing set of PROBE, which is derived from the SYGUS benchmark [4]. The number of examples ranges from 2 to 400. The original SYGUS benchmark have custom grammars for each task, but we use a union of all the grammars to make the search more challenging; the union grammar has 16 operations and 59 constants. ", "page_idx": 6}, {"type": "text", "text": "Configurations Our main HYSYNTH configuration uses GPT4O as the LLM, with 100 samples per task to learn a PCFG in non-strict mode (i.e. syntactically invalid completions are included in the PCFG learning process, as explained in Sec. 3.1). For each domain, we compare the performance of HYSYNTH with a baseline synthesizer for that domain (ARGA4, PROBE, and TFCODER), as well as three ablations: (1) no search, i.e. using the 100 samples from the LLM directly, (2) unguided search, i.e. running the same synthesizer but with a uniform weighted grammar, and (3) binary surrogate, running the synthesizer but with a binary PCFG, i.e. a CFG that includes the components present in the LLM samples with equal probabilities, and excludes all other components completely. We also analyze the performance of HYSYNTH with different number of samples used to learn the PCFG (10, 20, and 50), with other LLMs (GPT3.5 and DEEPSEEK [22]), as well as in strict mode (which discards syntactically invalid LLM completions). The timeout is set to 10 minutes for all experiments and includes the search time and time to sample LLM completions (and compute PCFG). The average time to sample 100 solutions from GPT4O is 4 seconds, 12 seconds and 20 seconds per task for the STRING, ARC and TENSOR domains, respectively. ", "page_idx": 6}, {"type": "text", "text": "4.2 Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "How does HYSYNTH compare to baselines and ablations? We compare the time to solution for the main HYSYNTH configuration, baseline synthesizers, and the three ablations; the results for the three domains are shown in Fig. 4a, Fig. 4b, and Fig. 4c. Overall, HYSYNTH consistently outperforms both the baseline synthesizers and ablations, solving more tasks across all domains. ", "page_idx": 6}, {"type": "image", "img_path": "5jt0ZSA6Co/tmp/3f8c88106fed4bfba05f79be6962916ecc670d16a3733e97ae1838522065b617.jpg", "img_caption": ["(a) HYSYNTH-ARC results with GPT4O "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "5jt0ZSA6Co/tmp/474a92cc7eb7ac42a6240953b797f05f84744237c9a49dab8c99a6f2035c3fb5.jpg", "img_caption": ["(c) HYSYNTH-TENSOR results with GPT4O ", "Figure 4: (a,b,c) Number of benchmarks solved by HYSYNTH as a function of time for the ARC, TENSOR, and STRING domains; timeout is $10\\,\\mathrm{min}$ . (d) Percentage of syntactically valid completions per domain. "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "5jt0ZSA6Co/tmp/2ffaa261b2ef7ba8b5f296dd5159bf160c6013886370faa008075298ccab740b.jpg", "img_caption": ["(b) HYSYNTH-STRING results with GPT4O "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "5jt0ZSA6Co/tmp/813143fa9c7fdfd3b6625651806531c1b180c54f349ea9731b453035390b974d.jpg", "img_caption": ["(d) Percentage of syntactically valid completions "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "In more detail, direct LLM sampling performs very poorly on all domains, solving between 0 and 14 tasks; this confirms our hypothesis that LLMs struggle on PBE tasks in domain-specific languages, which are not prevalent in their training data. Interestingly, despite not being able to solve any TENSOR tasks by itself, GPT4O provides excellent guidance for HYSYNTH on that domain, helping it solve $96\\%$ of the total benchmark! On the other hand, synthesis guided by a binary surrogate model performs worse than HYSYNTH (and even unguided search in case of ARC and TENSOR) since the search excludes essential components from the grammar. ", "page_idx": 7}, {"type": "text", "text": "In STRING and TENSOR domains, the baseline synthesizers predictably do better than unguided search, since both use the same search implementation, but with different weights. On ARC, however, our custom synthesizer outperforms ARGA5 even without LLM guidance; this speaks to the efficiency of the bottom-up search and the divide-and-conquer strategy we use, which are results of years of research in the program synthesis community. ", "page_idx": 7}, {"type": "text", "text": "How many samples are needed to learn a PCFG? To better understand how the number of samples affects the quality of PCFG guidance, we vary the number of GPT4O programs used in PCFG learning $N=10,20,50,100.$ , and once again measure the number of tasks solved over time. The results are shown in Fig. 5a, Fig. 5b, and Fig. 5c. As expected, larger sample sizes generally lead to better performance, but the difference is minimal: in ARC and TENSOR, the difference between the best and worst performing versions of HYSYNTH is only 2 problems each, while in STRING, HYSYNTH solves 9 fewer problems with 10 samples than with 100. Despite these differences, all versions of HYSYNTH still outperform the baseline and unguided search. This suggests that fewer samples are sufficient to effectively train a robust surrogate model, thereby optimizing costs. ", "page_idx": 7}, {"type": "image", "img_path": "5jt0ZSA6Co/tmp/9cf20d8ec692393778c5e5ae1a4ff3b94d1d4a298832fd78c1f4993f7e205148.jpg", "img_caption": ["(a) HYSYNTH-ARC with varied sample sizes "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "5jt0ZSA6Co/tmp/0a710235d72b7bd1272399cfd28c7d99bdb5e0aa97a70419adcd6503250f93e0.jpg", "img_caption": ["(b) HYSYNTH-STRING with varied sample sizes "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "5jt0ZSA6Co/tmp/7fe1092cea5ba9687a579f18f88b2be3661229f064c0d3dc2ab06d4511fba6d2.jpg", "img_caption": [], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "5jt0ZSA6Co/tmp/a186a2451f824762ae5f1be5e90acc35521d43d0e64807c6a40c67e7ca474904.jpg", "img_caption": ["(c) HYSYNTH-TENSOR with varied sample sizes (d) HYSYNTH-ARC with strict and non-strict modes ", "Figure 5: HYSYNTH-ARC, HYSYNTH-TENSOR and HYSYNTH-STRING results guided by a PCFG learned from different number of GPT4O samples $\\mathrm{n}{=}10$ , 20, 50, 100). "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Do our results generalize to other models? To answer this question, we repeat our experiments on STRING and TENSOR domains with ${\\mathrm{GPT}}3.5$ and the open-source model deepseek-coder-33b-instruct (DEEPSEEK) [22]. The results with these models are detailed in Fig. 9 in Appendix C, and they corroborate the pattern observed with GPT4O, where the guided versions outperform the baseline, unguided search, and direct sampling from the LLM. ", "page_idx": 8}, {"type": "text", "text": "How important is non-strict mode? Fig. 4d shows the percentage of syntactically valid completions generated by GPT4O and DEEPSEEK (where applicable). You can see that while on TENSOR almost all completions are valid, this percentage falls to $78.4\\%$ for ARC and $37.5\\%$ for STRING; this is not surprising, given that the former are TensorFlow programs, which the model has seen during training, while the latter two are custom DSLs. In the STRING benchmark, the grammar is very restricted (e.g. only numeric constants allowed are 0-9), and the LLM has trouble adhering to this restricted grammar. But even if we were to relax the definition of syntactic validity, LLM solutions would achieve a syntactic validity of only $47\\%$ . Hence our non-strict mode proves especially helpful for low-resource domains, where otherwise we would have to discard a large proportion of completions. At the same time, we find that given the same number of completions to learn from, the PCFGs learned in non-strict mode are just as effective as those learned in strict mode: as shown in Fig. 5d, HYSYNTH-ARC with the guidance from 100 GPT4O completions solves 58 tasks in either mode (with the difference that strict mode has to sample more completions to get 100 valid ones). ", "page_idx": 8}, {"type": "text", "text": "4.3 Limitations ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "The main limitation of our hybrid approach wrt. purely neural approaches is that it requires implementing a synthesizer for each DSL of interest; although we have shown that the same bottom-up search can be used across different domains, some implementation effort is still required. On the other hand, compared to purely symbolic approaches, our method requires sampling from an LLM, which is costly; additionally, the guidance provided by our approach is only as good as the LLM\u2019s completions: if they contain many irrelevant operators, our guided search can be slower than unguided search. Finally, our experiments are subject to the usual threat that the LLMs might have seen our benchmarks in their training data; we do not consider it a major issue, however, given that our main result is the superior performance of guided search relative to using LLMs without search. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "5 Related Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Guiding Program Synthesis with Probabilistic Models The traditional approach to program synthesis is based on combinatorial search [7], augmented with pruning techniques based on program semantics [2, 6, 39]. To further speed up the search, researchers have proposed guiding the search with a learned probabilistic model. Most approaches to guided search use special-purpose models that have to be trained on a domain-specific corpus of programs [26] or PBE tasks [9, 24, 32, 37]. Although some of these models can be trained on synthetic data, the training process is still expensive and requires manual tuning, which makes it hard to apply these techniques to new domains. ", "page_idx": 9}, {"type": "text", "text": "With the advent of pretrained Large Language Models (LLMs), it seems only natural to use them to guide search-based program synthesis, thus alleviating the need for domain-specific training data. We are only aware of one other attempt to do this: concurrent work by Li et al. [29], which also extracts a PCFG from the LLM\u2019s samples, similarly to HYSYNTH. An important difference is that they use the PCFG to guide top-down $\\mathbf{A}^{*}$ search, while we use it to guide bottom-up search, which is known to be more efficient (they also evaluate their tool on synthesis from logical formulas as opposed to PBE). ", "page_idx": 9}, {"type": "text", "text": "Solving the Abstraction and Reasoning Corpus All state-of-the-art solvers for this benchmark have relied on carefully curated DSLs for ARC [3, 13, 19, 27, 43]. Xu et al. [44] proposed the DSL we extend in our approach, and the OBJECT-ARC subset we evaluate on. Lei et al. [27] embed their DSL as a subset of PDDL and use a Generalized Planning (GP) algorithm as their search component. They have the current best performance on OBJECT-ARC, however they encode more domain-knowledge in the form of preconditions and per-abstraction restrictions on filters and transforms, to make GP viable. Our approach does not require this additional information. [3, 10] use DreamCoder [16], to perform execution-guided search over a DSL for grid manipulations, however they only provide proof-of-concept evaluations. [38, 41] also use an LLM to generate code given the spec of the task. Both of these approaches interact with the model across several rounds, while our technique uses the suggestions from the LLM only as a starting point. Our technique also performs a complete search guided by the LLM distribution, enabled by the structure of our DSL, whereas previous approaches only consider code directly generated by the LLM. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion and Future Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Our approach introduces a robust technique for using both valid and invalid completions from an LLM to learn a surrogate model. By incorporating ungrammatical completions, we can extract useful insights that would otherwise be discarded. Overall, we provide an alternative to the conventional strategy of large-scale sampling from LLMs, proposing a more effective use of the available completions to guide the search process. An interesting future direction would be to guide search with a more expressive context-dependent surrogate model. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] 2020. Arc kaggle competition leaderboard. Accessed: 2024-05-19.   \n[2] Aws Albarghouthi, Sumit Gulwani, and Zachary Kincaid. 2013. Recursive program synthesis. In International Conference on Computer Aided Verification, pages 934\u2013950. Springer.   \n[3] Simon Alford, Anshula Gandhi, Akshay Rangamani, Andrzej Banburski, Tony Wang, Sylee Dandekar, John Chin, Tomaso Poggio, and Peter Chin. 2022. Neural-guided, bidirectional program search for abstraction and reasoning. In Complex Networks & Their Applications X: Volume 1, Proceedings of the Tenth International Conference on Complex Networks and Their Applications COMPLEX NETWORKS 2021 10, pages 657\u2013668. Springer.   \n[4] Rajeev Alur, Rastislav Bod\u00edk, Garvit Juniwal, Milo M. K. Martin, Mukund Raghothaman, Sanjit A. Seshia, Rishabh Singh, Armando Solar-Lezama, Emina Torlak, and Abhishek Udupa. 2013. Syntax-guided synthesis. In Formal Methods in Computer-Aided Design, FMCAD 2013, pages 1\u20138.   \n[5] Rajeev Alur, Dana Fisman, Rishabh Singh, and Armando Solar-Lezama. 2017. Sygus-comp 2017: Results and analysis. arXiv preprint arXiv:1711.11438.   \n[6] Rajeev Alur, Arjun Radhakrishna, and Abhishek Udupa. 2017. Scaling enumerative program synthesis via divide and conquer. In International Conference on Tools and Algorithms for the Construction and Analysis of Systems, pages 319\u2013336. Springer.   \n[7] Rajeev Alur, Rishabh Singh, Dana Fisman, and Armando Solar-Lezama. 2018. Search-based program synthesis. Communications of the ACM, 61(12):84\u201393.   \n[8] Xuefeng Bai, Jialong Wu, Yulong Chen, Zhongqing Wang, and Yue Zhang. 2023. Constituency parsing using llms. arXiv preprint arXiv:2310.19462.   \n[9] Matej Balog, Alexander L Gaunt, Marc Brockschmidt, Sebastian Nowozin, and Daniel Tarlow. 2016. Deepcoder: Learning to write programs. arXiv preprint arXiv:1611.01989.   \n[10] Andrzej Banburski, Anshula Gandhi, Simon Alford, Sylee Dandekar, Sang Chin, and tomaso a poggio. 2020. Dreaming with ARC. In Learning Meets Combinatorial Algorithms at NeurIPS2020.   \n[11] Shraddha Barke, Hila Peleg, and Nadia Polikarpova. 2020. Just-in-time learning for bottom-up enumerative synthesis. Proceedings of the ACM on Programming Languages, 4(OOPSLA):1\u2013 29.   \n[12] Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, and Owain Evans. 2023. The reversal curse: Llms trained on\" a is b\" fail to learn\" b is a\". arXiv preprint arXiv:2309.12288.   \n[13] Natasha Butt, Blazej Manczak, Auke Wiggers, Corrado Rainone, David W Zhang, Micha\u00ebl Defferrard, and Taco Cohen. 2023. Codeit: Abstract reasoning with iterative policy-guided program synthesis.   \n[14] Fran\u00e7ois Chollet. 2019. On the measure of intelligence. arXiv preprint arXiv:1911.01547.   \n[15] Jacob Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh, Abdel-rahman Mohamed, and Pushmeet Kohli. 2017. Robustflil: Neural program learning under noisy i/o. In International conference on machine learning, pages 990\u2013998. PMLR.   \n[16] Kevin Ellis, Catherine Wong, Maxwell Nye, Mathias Sable-Meyer, Luc Cary, Lucas Morales, Luke Hewitt, Armando Solar-Lezama, and Joshua B Tenenbaum. 2020. Dreamcoder: Growing generalizable, interpretable knowledge with wake-sleep bayesian program learning. arXiv preprint arXiv:2006.08381.   \n[17] Yu Feng, Ruben Martins, Osbert Bastani, and Isil Dillig. 2018. Program synthesis using confilctdriven learning. In Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2018, pages 420\u2013435, New York, NY, USA. Association for Computing Machinery.   \n[18] Yu Feng, Ruben Martins, Yuepeng Wang, Isil Dillig, and Thomas W. Reps. 2017. Componentbased synthesis for complex apis. In POPL.   \n[19] Raphael Fischer, Matthias Jakobs, Sascha M\u00fccke, and Katharina Morik. 2020. Solving abstract reasoning tasks with grammatical evolution. In LWDA, pages 6\u201310.   \n[20] Sumit Gulwani. 2011. Automating string processing in spreadsheets using input-output examples. ACM Sigplan Notices, 46(1):317\u2013330.   \n[21] Sumit Gulwani. 2016. Programming by examples (and its applications in data wrangling). In Javier Esparza, Orna Grumberg, and Salomon Sickert, editors, Verification and Synthesis of Correct and Secure Systems. IOS Press.   \n[22] Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao Zhang, Guanting Chen, Xiao Bi, Y Wu, YK Li, et al. 2024. Deepseek-coder: When the large language model meets programming\u2013the rise of code intelligence. arXiv preprint arXiv:2401.14196.   \n[23] Martin Josifoski, Marija Sakota, Maxime Peyrard, and Robert West. 2023. Exploiting asymmetry for synthetic training data generation: Synthie and the case of information extraction. arXiv preprint arXiv:2303.04132.   \n[24] Ashwin Kalyan, Abhishek Mohta, Oleksandr Polozov, Dhruv Batra, Prateek Jain, and Sumit Gulwani. 2018. Neural-guided deductive search for real-time program synthesis from examples. arXiv preprint arXiv:1804.01186.   \n[25] Seungpil Lee, Woochang Sim, Donghyeon Shin, Sanha Hwang, Wongyu Seo, Jiwon Park, Seokki Lee, Sejin Kim, and Sundong Kim. 2024. Reasoning abilities of large language models: In-depth analysis on the abstraction and reasoning corpus.   \n[26] Woosuk Lee, Kihong Heo, Rajeev Alur, and Mayur Naik. 2018. Accelerating search-based program synthesis using learned probabilistic models. ACM SIGPLAN Notices, 53(4):436\u2013449.   \n[27] Chao Lei, Nir Lipovetzky, and Krista A. Ehinger. 2024. Generalized planning for the abstraction and reasoning corpus.   \n[28] Xiang Li, Xiangyu Zhou, Rui Dong, Yihong Zhang, and Xinyu Wang. 2024. Efficient bottom-up synthesis for programs with local variables. Proc. ACM Program. Lang., 8(POPL).   \n[29] Yixuan Li, Julian Parsert, and Elizabeth Polgreen. 2024. Guiding enumerative program synthesis with large language models.   \n[30] John McCarthy. 1960. Recursive functions of symbolic expressions and their computation by machine, part i. Commun. ACM, 3(4):184\u2013195.   \n[31] R Thomas McCoy, Shunyu Yao, Dan Friedman, Matthew Hardy, and Thomas L Grifftihs. 2023. Embers of autoregression: Understanding large language models through the problem they are trained to solve. arXiv preprint arXiv:2309.13638.   \n[32] Augustus Odena, Kensen Shi, David Bieber, Rishabh Singh, Charles Sutton, and Hanjun Dai. 2020. Bustle: bottom-up program synthesis through learning-guided exploration. arXiv preprint arXiv:2007.14381.   \n[33] OpenAI. 2024. Hello gpt-4.0. Accessed: 2024-05-19.   \n[34] Peter-Michael Osera and Steve Zdancewic. 2015. Type-and-example-directed program synthesis. ACM SIGPLAN Notices, 50(6):619\u2013630.   \n[35] Andrew Reynolds, Haniel Barbosa, Andres N\u00f6tzli, Clark Barrett, and Cesare Tinelli. 2019. cvc 4 sy: smart and fast term enumeration for syntax-guided synthesis. In International Conference on Computer Aided Verification, pages 74\u201383. Springer.   \n[36] Kensen Shi, David Bieber, and Rishabh Singh. 2022. Tf-coder: Program synthesis for tensor manipulations. ACM Trans. Program. Lang. Syst., 44(2).   \n[37] Kensen Shi, Hanjun Dai, Kevin Ellis, and Charles Sutton. 2022. Crossbeam: Learning to search in bottom-up program synthesis. arXiv preprint arXiv:2203.10452.   \n[38] John Chong Min Tan and Mehul Motani. 2023. Large language model (llm) as a system of multiple expert agents: An approach to solve the abstraction and reasoning corpus (arc) challenge. arXiv preprint arXiv:2310.05146.   \n[39] Abhishek Udupa, Arun Raghavan, Jyotirmoy V Deshmukh, Sela Mador-Haim, Milo MK Martin, and Rajeev Alur. 2013. Transit: specifying protocols with concolic snippets. ACM SIGPLAN Notices, 48(6):287\u2013296.   \n[40] Shubham Ugare, Tarun Suresh, Hangoo Kang, Sasa Misailovic, and Gagandeep Singh. 2024. Improving llm code generation with grammar augmentation. arXiv preprint arXiv:2403.01632.   \n[41] Ruocheng Wang, Eric Zelikman, Gabriel Poesia, Yewen Pu, Nick Haber, and Noah D Goodman. 2023. Hypothesis search: Inductive reasoning with language models. arXiv preprint arXiv:2309.05660.   \n[42] Yeming Wen, Pengcheng Yin, Kensen Shi, Henryk Michalewski, Swarat Chaudhuri, and Alex Polozov. 2024. Grounding data science code generation with input-output specifications.   \n[43] Johan Sokrates Wind. 2020. Arc kaggle competition, 1st place. Accessed: 2024-05-19.   \n[44] Yudong Xu, Elias B Khalil, and Scott Sanner. 2023. Graphs, constraints, and search for the abstraction and reasoning corpus. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 4115\u20134122.   \n[45] Yudong Xu, Wenhao Li, Pashootan Vaezipoor, Scott Sanner, and Elias B Khalil. 2023. Llms and the abstraction and reasoning corpus: Successes, failures, and the importance of object-based representations. arXiv preprint arXiv:2305.18354.   \n[46] Honghua Zhang, Meihua Dang, Nanyun Peng, and Guy Van den Broeck. 2023. Tractable control for autoregressive language generation. In International Conference on Machine Learning, pages 40932\u201340945. PMLR. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "// Solution 1, occurs 6 times if color_of(self) $=$ GREY \u2227is_neighbor(self, other) then update_color(color_of(other)) ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "// Solution 2, occurs 1 time if is_neighbor(self, other) \u2227color_of(other) $=$ GREY then update_color(color_of(other)) ", "page_idx": 13}, {"type": "text", "text": "// Solution 3, occurs 1 time if color_of(self) $=$ GREY then update_color(color_of(other)) ", "page_idx": 13}, {"type": "text", "text": "// Solution 4, occurs 1 time ", "page_idx": 13}, {"type": "text", "text": "if not (color_of(self) $\\Delta={\\sf G R E Y}$ ) $\\wedge$ is_neighbor(self, other) \u2227color_of(other) $=$ GREY then update_color(FUCHSIA) ", "page_idx": 13}, {"type": "text", "text": "// Solution 5, occurs 1 time ", "page_idx": 13}, {"type": "text", "text": "if size_of(self) $=4$ then update_color(RED) ; if size_of(self) $=4~\\wedge$ color_of(self) $=$ GREY then update_color(FUCHSIA) ; if size_of(self) $=4$ \u2227color_of(self) $=$ BLUE then update_color(ORANGE) ; if size_of(self) $=4$ \u2227color_of(self) $=$ YELLOW then update_color(CYAN) ", "page_idx": 13}, {"type": "text", "text": "Figure 6: Ten samples from GPT4o for the motivating example in Fig. 1a ", "page_idx": 13}, {"type": "text", "text": "A GPT4o Solutions for the Motivating Example ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Recall the motivating example in Fig. 1a where the task is to update the color of the grey objects to the color of their single-pixel neighbor. As a reminder, the smallest correct solution to this task consists of the following rule: ", "page_idx": 13}, {"type": "text", "text": "if color_of(self) = GREY \u2227is_neighbor(self, x) \u2227size_of(x) = MIN then update_color(color_of(x)) ", "page_idx": 13}, {"type": "text", "text": "Fig. 6 shows the programs we obtained by deduplicating 10 samples from GPT4o for this task. The syntax of the solutions is slightly modified for readability; our implementation uses a LISP-style s-expression syntax [30] to simplify parsing. ", "page_idx": 13}, {"type": "text", "text": "As you can see, the most frequent solution is almost correct, except that it does not constrain the neighbor other to be of size 1; this leads to the constraint being ambiguous (since every grey object has multiple neighbors of different colors), in which case the program semantics is considered undefined. That said, you can observe that the model consistently uses relevant components, such as color_of, is_neighbor, and update_color, which enables us to extract a useful PCFG from these solutions. ", "page_idx": 13}, {"type": "text", "text": "When we increased the sample size to 125, GPT4o was able to produce one correct solution (which is slightly larger than the minimal solution above): ", "page_idx": 13}, {"type": "text", "text": "if color_of(self) = GREY $\\wedge$ is_neighbor(self, other) \u2227not (color_of(other) $=$ GREY) then update_color(color_of(other)) ", "page_idx": 13}, {"type": "text", "text": "Figure 7: System prompt for ARC domain. ", "page_idx": 14}, {"type": "text", "text": "B LLM Prompt for the ARC Grammar ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.1 System Prompt ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The system prompt given to the LLM for ARC domain is shown in Fig. 7. ", "page_idx": 14}, {"type": "text", "text": "B.2 User Prompt ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The full user prompt for the ARC domain is shown in Fig. 8. It contains the domain-specific language, four in-context examples and the query for the test task. ", "page_idx": 14}, {"type": "text", "text": "You are an efficient assistant for logical reasoning and code generation.   \nYou will help me solve a visual perception and reasoning task.   \nI will first provide you with the definition of a Domain Specific Language you will use $\\hookrightarrow$ for writing a solution for the task.   \nI will then present you with the description of the task that you will be tested in.   \nYou will then respond to the queries I make regarding the solution of the task. ", "page_idx": 15}, {"type": "text", "text": "This is the definition of the DSL you will use to solve the task. It is given as a context-free grammar in the EBNF format used by the Lark parser $\\hookrightarrow$ generator, with some informative comments about the semantics. You will return a string that is parseable by the \u2018program\u2018 non-terminal of the grammar. ", "page_idx": 15}, {"type": "text", "text": "library: \"(\" program $^*$ \")\" ", "page_idx": 15}, {"type": "text", "text": "// Rules are executed one after another, in the order they appear. // There could be no rules, in which case the program does nothing. program: \"(\" \"do\" rule\\* \")\" ", "page_idx": 15}, {"type": "text", "text": "<<< DSL IMPLEMENTATION IN LARK >>> ", "page_idx": 15}, {"type": "text", "text": "\u2018\u2018\u2018   \nNow we continue with the visual perception and reasoning task.   \nThe input for the task is a small number of pairs of grids of characters.   \nThe value of each of the cells of the grids are the colors defined in the DSL, so we can $\\hookrightarrow$ think of grids as images.   \nEach pair of images correspond to an input-output example for an unknown program P.   \nFor each pair, the program P is evaluated on the image grid and operates on the objects $\\hookrightarrow$ that appear in it.   \nThe output of the program is then the output image.   \nThe objects in the images are easy and natural to identify for humans, so there is no $\\hookrightarrow$ need to define them explicitly.   \nHowever you are able to abstract them correctly, and the DSL is interpreted with the $\\hookrightarrow$ same correct abstraction. ", "page_idx": 15}, {"type": "text", "text": "Now I will show you some demonstration tasks along with the output you would be expected $\\hookrightarrow$ to produce for each of them. ", "page_idx": 15}, {"type": "text", "text": "## DEMONSTRATION TASK 1 ", "page_idx": 15}, {"type": "text", "text": "### INPUT   \nPAIR 1   \nINPUT GRID:   \n$\\begin{array}{c}{\\begin{array}{c c c c c c c c c}{0}&{0}&{0}&{0}&{0}&{0}&{0}&{0}\\\\ {0}&{0}&{0}&{0}&{0}&{\\textsf{R00}}&{0}\\\\ {0}&{\\textsf{R000}}&{0}&{\\textsf{R0}}&{\\textsf{R}}&{}\\\\ {0}&{\\textsf{R}}&{0}&{0}&{\\textsf{R00}}&{0}&{}\\\\ {0}&{0}&{0}&{0}&{0}&{0}&{0}&{}\\\\ {0}&{\\textsf{R R000}}&{0}&{0}&{0}&{0}&{}\\\\ {0}&{\\textsf{R R0\\det R R00}}&{0}&{\\textsf{I m}}&{0}&{}\\\\ {0}&{\\textsf{O000000}}&{0}&{0}&{0}&{}\\end{array}}\\end{array}$ ", "page_idx": 15}, {"type": "text", "text": "OUTPUT GRID: $\\begin{array}{c c l}{0}&{0}&{0}&{0}&{0}&{0}\\\\ {0}&{0}&{0}&{0}&{\\nabla}&{0}\\\\ {0}&{\\nabla}&{0}&{0}&{\\nabla}&{0}\\\\ {0}&{\\nabla}&{0}&{0}&{\\nabla}&{0}\\\\ {0}&{0}&{0}&{0}&{0}&{0}\\\\ {0}&{\\nabla}&{0}&{0}&{0}&{0}\\\\ {0}&{\\nabla}&{\\nabla}&{0}&{0}&{0}\\\\ {0}&{\\nabla}&{\\nabla}&{0}&{\\nabla}&{0}\\\\ {0}&{0}&{0}&{0}&{0}&{0}\\end{array}$ ", "page_idx": 16}, {"type": "text", "text": "<<< ENCODING OF EXAMPLE PAIR 2 AND 3 OF DEMO TASK 1>>> ", "page_idx": 16}, {"type": "text", "text": "### EXPECTED OUTPUT   \n{ \"nl_description\": \"Recolor all objects to color Y\", \"code\": <<< EXPECTED CODE IN DSL >>>   \n} ", "page_idx": 16}, {"type": "text", "text": "<<< MORE DEMONSTRATION TASKS (4 IN TOTAL) >>> ", "page_idx": 16}, {"type": "text", "text": "Now follows task you will be evaluated on. Output the solution as a JSON object, which should contain both a natural language $\\hookrightarrow$ description of the solution and the solution written in the DSL. ", "page_idx": 16}, {"type": "text", "text": "{ \"nl_description\": \"TO_BE_FILLED\", \"code\": \"TO_BE_FILLED\"   \n} ", "page_idx": 16}, {"type": "text", "text": "## TEST TASK ", "page_idx": 16}, {"type": "text", "text": "PAIR 1   \nINPUT GRID:   \n$\\begin{array}{c c l}{0}&{0}&{8\\times0\\ 0\\ \\textrm{r}\\ \\textrm{0}\\ 0\\ 0\\ \\textrm{0}\\ \\textrm{0}\\ \\textrm{0}\\ \\textrm{0}\\ \\textrm{0}}\\\\ {0}&{0}&{0}&{0\\ 0\\ \\textrm{0}\\ 0\\ \\textrm{0}\\ \\textrm{0}\\ \\textrm{0}}\\\\ {0}&{0}&{0\\ 0\\ 0\\ \\textrm{X}\\times\\textrm{X}\\times\\textrm{0}\\ 0}\\\\ {0}&{0}&{0\\ 0\\ \\textrm{X}\\times\\textrm{X}\\times\\textrm{0}\\ \\textrm{0}}\\\\ {0}&{\\times\\textrm{X}\\ 0\\ \\textrm{X}\\times\\textrm{X}\\times\\textrm{0}\\ \\textrm{0}}\\\\ {0}&{\\times\\textrm{X}\\ 0\\ \\textrm{x}\\times\\textrm{X}\\ x\\ \\textrm{0}\\ \\textrm{0}}\\\\ {0}&{\\times\\textrm{X}\\ 0\\ 0\\ 0\\ 0\\ 0\\ 0}\\\\ {0}&{\\times\\textrm{X}\\ 0\\ 0\\ 0\\ 0\\ \\textrm{0}\\times\\textrm{X}\\times}\\\\ {0}&{\\times\\textrm{X}\\ 0\\ 0\\ 0\\ 0\\ \\textrm{0}\\times\\textrm{X}\\times\\textrm{X}}\\\\ {0}&{0}&{0\\ 0\\ 0\\ 0\\textrm{X}\\times\\textrm{X}}\\\\ {0}&{\\times\\ 0\\ 0\\ 0\\ 0\\ 0\\textrm{0}\\times\\textrm{X}\\times\\textrm{X}}\\end{array}$   \nOUTPUT GRID:   \n$\\begin{array}{r}{\\begin{array}{c c c c c c c c c c}{0}&{0}&{{\\texttt R000}}&{{\\texttt F0}}&{0}&{0}&{{\\texttt C}}&\\\\ {0}&{0}&{0}&{0}&{0}&{0}&{0}&{0}\\\\ {0}&{0}&{0}&{0}&{{\\texttt F}}&{{\\texttt F}}&{0}&{0}\\\\ {0}&{0}&{0}&{0}&{{\\texttt F}}&{{\\texttt F}}&{0}&{0}\\\\ {0}&{{\\texttt R}\\times{\\texttt0}}&{{\\texttt F}}&{{\\texttt F}}&{{\\texttt F}}&{0}&{0}\\\\ {0}&{{\\texttt R}\\times{\\texttt0}}&{{\\texttt F}}&{{\\texttt F}}&{{\\texttt F}}&{0}&{0}\\\\ {0}&{{\\texttt R}\\times{\\texttt0}}&{0}&{0}&{0}&{0}&{0}\\\\ {0}&{{\\texttt R}\\times{\\texttt0}}&{0}&{0}&{0}&{{\\texttt C}}&{{\\texttt C}}&\\\\ {0}&{{\\texttt R}\\times{\\texttt0}}&{0}&{0}&{0}&{{\\texttt C}}&{{\\texttt C}}&\\\\ {0}&{0}&{0}&{0}&{0}&{0}&{{\\texttt C}}&{{\\texttt C}}\\end{array}}\\end{array}$ ", "page_idx": 16}, {"type": "text", "text": "<<< REST OF THE I/O EXAMPLES OF TEST TASK >>> (c) HYSYNTH-TENSOR results with DEEPSEEK (d) HYSYNTH-TENSOR results with GPT3.5 Figure 9: HYSYNTH-STRING and HYSYNTH-TENSOR evaluation results with DEEPSEEK and GPT3.5. ", "page_idx": 16}, {"type": "image", "img_path": "5jt0ZSA6Co/tmp/037381c5752fffa67581211fe01c3b196b1405b3a852bc792ba16d558f6bc56c.jpg", "img_caption": ["C Experimental results with LLMs DEEPSEEK and GPT3.5 ", "(a) HYSYNTH-STRING results with DEEPSEEK "], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "5jt0ZSA6Co/tmp/8726fd6543500db49c3f5245be95236114341ee654c076cf73ba928987e50f13.jpg", "img_caption": ["(b) HYSYNTH-STRING results with GPT3.5 "], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "5jt0ZSA6Co/tmp/2de64620141550936c2da9d3c26da345ddf62da2cec6f840bc8c4393a49bc547.jpg", "img_caption": [], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "5jt0ZSA6Co/tmp/b3119fd5949b6150d37b093695c5670e0f06c18568217ac0c4d947a3d251fc0a.jpg", "img_caption": [], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "You are a coding assistant. Be precise and terse.   \nYou will be provided a list of tensorflow operators, a task description, and some input/output examples.   \nYour task is to generate the body of a python function that will transform the input to the output.   \nOnly use the operators provided in the list.   \nYour answer should be as short as possible while still being correct.   \nMake sure to only generate python code. ", "page_idx": 18}, {"type": "text", "text": "Figure 10: System prompt for TENSOR domain. ", "page_idx": 18}, {"type": "text", "text": "[TENSORFLOW OPERATORS] <<< see appendix E >>> [TASK DESCRIPTION] index into the tensor [INPUTS] [[ 5. 2.] [ 1. 3.] [ 0. -1.]] [OUTPUTS] [[[ 5. 5.] [ 1. 1.] [ 0. 0.]] [[ 2. 2.] [ 3. 3.] [-1. -1.]]] [PROGRAM] def transform(in1): ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "Figure 11: User prompt for TENSOR domain ", "page_idx": 18}, {"type": "text", "text": "D LLM Prompt for the TENSOR Grammar ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "The system and user prompt for TENSOR domain are in Fig. 10 and Fig. 11. ", "page_idx": 18}, {"type": "text", "text": "You are a coding assistant. Be precise and terse.   \nYou will be given a SyGuS grammar, a natural language specification, and a set of input$\\hookrightarrow$ output examples.   \nYour task is to complete the provided function definition with an implementation that is $\\hookrightarrow$ correct according to the grammar, specification, and examples.   \nYour answer should be as short as possible while still being correct.   \nMake sure that your answer is a valid s-expression. ", "page_idx": 19}, {"type": "text", "text": "Figure 12: System prompt for STRING domain ", "page_idx": 19}, {"type": "text", "text": "[GRAMMAR]   \n(synth-fun f ((_arg_0 String)) String ((Start String (ntString)) (ntString String ( $\\hookrightarrow-{\\mathsf{a r g}}_{-}{\\mathsf{0}}$ \"\" \" \" \"BRD\" \"DRS\" \"LDS\" \"Branding\" \"Direct Response\" \"Leads\" \"=\" \"/\" \"in $\\hookrightarrow$ \" \"_\" \"9\" \".\" \"microsoft\" \"windows\" \"apple\" \"mac\" \"-\" \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" $\\hookrightarrow$ \"7\" \"8\" \"0\" \",\" \"<\" \">\" \"/n\" \"%\" \"b\" \"apple\" \"bananas\" \"strawberries\" \"oranges\" $\\hookrightarrow$ \"LLC\" \"Inc\" \"Corporation\" \"Enterprises\" \"Company\" \"(\" \")\" \"+\" \"name\" \",\" (str. $^{++}$ $\\hookrightarrow$ ntString ntString) (str.replace ntString ntString ntString) (str.at ntString $\\hookrightarrow$ ntInt) (int.to.str ntInt) (ite ntBool ntString ntString) (str.substr ntString $\\hookrightarrow$ ntInt ntInt))) (ntInt Int (-1 1 2 3 4 5 6 7 8 9 0 1 0 -1 ( $^+$ ntInt ntInt) (- $\\hookrightarrow$ ntInt ntInt) (str.len ntString) (str.to.int ntString) (ite ntBool ntInt ntInt) ( $\\hookrightarrow$ str.indexof ntString ntString ntInt))) (ntBool Bool (true false ( $=$ ntInt ntInt) $\\hookrightarrow$ (str.prefixof ntString ntString) (str.suffixof ntString ntString) (str.contains $\\hookrightarrow$ ntString ntString))))) ", "page_idx": 19}, {"type": "text", "text": "[NATURAL LANGUAGE SPECIFICATION] ; http $\\leftrightharpoons$ //exceljet.net/formula/get-top-level-domain-tld ", "page_idx": 19}, {"type": "text", "text": "[EXAMPLES] www.domain.com $\\rightarrow$ com mail.net $\\rightarrow$ net www.amazon.co.uk $\\rightarrow$ uk [SOLUTION] (define-fun f (_arg_0 String) String ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "Figure 13: User message for STRING ", "page_idx": 19}, {"type": "text", "text": "E LLM Prompt for STRING ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The system and user prompt for STRING domain are in Fig. 12 and Fig. 13. ", "page_idx": 19}, {"type": "text", "text": "F The Full STRING Grammar ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The full grammar for the STRING domain is detailed in Fig. 14. ", "page_idx": 19}, {"type": "text", "text": "Start \u2192 S ", "page_idx": 20}, {"type": "text", "text": "S \u2192 arg0 | arg1| . . . string variables | lit-1 | lit-2 | . . . string literals (replace S S S) replace $\\texttt{S}\\times\\texttt{y}$ replaces first occurrence of $\\times$ in s with y (concat $S\\;S^{\\mathrm{\\scriptsize~\\textrm~{\\,~}~}}$ ) concat $\\times$ y concatenates $\\times$ and y (substr S I I) substr x y z extracts substring of length ${\\sf z}$ , from index y | (ite B S S) ite $\\texttt{x y z}$ returns $\\mathsf{y}$ if $\\times$ is true, otherwise z | (int.to.str I) int.to.str $\\times$ converts int $\\boldsymbol{x}$ to a string | (at S I) at x y returns the character at index $\\mathsf{y}$ in string x   \n$B\\rightarrow$ true | false bool literals | $\\left(=I\\,I\\right)$ $=~\\times$ y returns true if $\\times$ equals y | (contains S S) contains $\\times\\ y$ returns true if $\\boldsymbol{x}$ contains y | (suffixof S S) suffixof $\\times\\ y$ returns true if $\\boldsymbol{x}$ is the suffix of y | (prefixof S S) prefixof $\\times\\ y$ returns true if $\\boldsymbol{x}$ is the prefix of $\\mathsf{y}$   \n$I\\to$ arg0 | arg1| . . . int variables | lit-1 | lit-2 | . . int literals | (str.to.int $S$ ) str.to.int $\\times$ converts string $\\mathbf{X}$ to a int | $\\left(+\\textit{I I}\\right)$ + x y sums $\\boldsymbol{x}$ and y | $(\\,.\\,I\\,I)$ - x y subtracts y from $\\boldsymbol{x}$ | (length S) length $\\times$ returns length of $\\times$ | (ite B I I) ite $\\texttt{x y z}$ returns $\\mathsf{y}$ if $\\times$ is true, otherwise z (indexof S S I) indexof x y z returns index of $\\mathsf{y}$ in $\\boldsymbol{x}$ , starting at index z ", "page_idx": 20}, {"type": "text", "text": "Figure 14: The full SYGUS STRING grammar of the PROBE benchmark suite. Integer and string variables and constants change per benchmark. Some benchmark files contain a reduced grammar. ", "page_idx": 20}, {"type": "text", "text": "G The Full TENSOR Grammar ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "General TensorFlow functions: ", "page_idx": 21}, {"type": "text", "text": "tf.abs(x)   \ntf.add(x, y)   \ntf.add_n(inputs)   \ntf.argmax(input, axis)   \ntf.argmin(input, axis)   \ntf.argsort(values, axis, stable $\\r=$ True)   \ntf.argsort(values, axis, direction $\\mathbf{\\omega}=\\mathbf{\\'}$ DESCENDING\u2019, stable=True)   \ntf.boolean_mask(tensor, mask)   \ntf.broadcast_to(input, shape)   \ntf.cast(x, dtype)   \ntf.clip_by_value(t, clip_value_min, clip_value_max)   \ntf.concat(values, axis)   \ntf.constant(value)   \ntf.constant(value, dtype)   \ntf.divide(x, y)   \ntf.equal(x, y)   \ntf.exp(x)   \ntf.expand_dims(input, axis)   \ntf.eye(num_rows)   \ntf.eye(num_rows, num_columns)   \ntf.eye(num_rows, dtype)   \ntf.fill(dims, value)   \ntf.gather(params, indices)   \ntf.gather(params, indices, axis, batch_dims)   \ntf.gather_nd(params, indices)   \ntf.gather_nd(params, indices, batch_dims)   \ntf.greater(x, y)   \ntf.greater_equal(x, y)   \ntf.math.bincount(arr)   \ntf.math.ceil(x)   \ntf.math.count_nonzero(input)   \ntf.math.count_nonzero(input, axis)   \ntf.math.cumsum(x, axis)   \ntf.math.cumsum(x, axis, exclusive $:=$ True)   \ntf.math.divide_no_nan(x, y)   \ntf.math.floor(x)   \ntf.math.log(x)   \ntf.math.negative(x)   \ntf.math.reciprocal(x)   \ntf.math.reciprocal_no_nan(x)   \ntf.math.segment_max(data, segment_ids)   \ntf.math.segment_mean(data, segment_ids)   \ntf.math.segment_min(data, segment_ids)   \ntf.math.segment_prod(data, segment_ids)   \ntf.math.segment_sum(data, segment_ids)   \ntf.math.squared_difference(x, y)   \ntf.math.top_k(input, k)   \ntf.math.unsorted_segment_max(data, segment_ids, num_segments)   \ntf.math.unsorted_segment_mean(data, segment_ids, num_segments)   \ntf.math.unsorted_segment_min(data, segment_ids, num_segments)   \ntf.math.unsorted_segment_prod(data, segment_ids, num_segments)   \ntf.math.unsorted_segment_sum(data, segment_ids, num_segments)   \ntf.matmul(a, b)   \ntf.maximum(x, y)   \ntf.minimum(x, y)   \ntf.multiply(x, y)   \ntf.not_equal(x, y)   \ntf.one_hot(indices, depth)   \ntf.ones(shape)   \ntf.ones_like(input)   \ntf.pad(tensor, paddings, mode $\\prime$ CONSTANT\u2019)   \ntf.pad(tensor, paddings, mode $\\r=\\prime$ CONSTANT\u2019, constant_values)   \ntf.pad(tensor, paddings, mode $={}^{\\prime}$ \u2019REFLECT\u2019)   \ntf.pad(tensor, paddings, mode $=^{t}$ SYMMETRIC\u2019)   \ntf.range(start)   \ntf.range(start, limit, delta)   \ntf.reduce_any(input_tensor, axis)   \ntf.reduce_max(input_tensor)   \ntf.reduce_max(input_tensor, axis)   \ntf.reduce_mean(input_tensor)   \ntf.reduce_mean(input_tensor, axis)   \ntf.reduce_min(input_tensor)   \ntf.reduce_min(input_tensor, axis)   \ntf.reduce_prod(input_tensor, axis)   \ntf.reduce_sum(input_tensor)   \ntf.reduce_sum(input_tensor, axis)   \ntf.reshape(tensor, shape)   \ntf.reverse(tensor, axis)   \ntf.roll(input, shift, axis)   \ntf.round(x)   \ntf.searchsorted(sorted_sequence, values, side $\\mathbf{\\omega}=\\mathbf{\\'}$ left\u2019)   \ntf.searchsorted(sorted_sequence, values, side $\\mathbf{\\omega}=\\mathbf{\\'}$ right\u2019)   \ntf.sequence_mask(lengths)   \ntf.sequence_mask(lengths, maxlen)   \ntf.shape(input)   \ntf.sign(x)   \ntf.sort(values, axis)   \ntf.sort(values, axis, direction $\\r=\\prime$ DESCENDING\u2019)   \ntf.sqrt(x)   \ntf.square(x)   \ntf.squeeze(input)   \ntf.squeeze(input, axis)   \ntf.stack(values, axis)   \ntf.subtract(x, y)   \ntf.tensordot(a, b, axes)   \ntf.tile(input, multiples)   \ntf.transpose(a)   \ntf.transpose(a, perm)   \ntf.unique_with_counts(x)   \ntf.unstack(value, axis)   \ntf.where(condition)   \ntf.where(condition, x, y)   \ntf.zeros(shape)   \ntf.zeros_like(input) ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "SparseTensor functions: ", "page_idx": 22}, {"type": "text", "text": "tf.SparseTensor(indices, values, dense_shape) tf.sparse.add(a, b) tf.sparse.concat(axis, sp_inputs) tf.sparse.expand_dims(sp_input, axis) ", "page_idx": 22}, {"type": "text", "text": "tf.sparse.from_dense(tensor)   \ntf.sparse.maximum(sp_a, sp_b)   \ntf.sparse.minimum(sp_a, sp_b)   \ntf.sparse.reduce_max(sp_input, axis, output_is_sparse)   \ntf.sparse.reduce_sum(sp_input, axis, output_is_sparse)   \ntf.sparse.reset_shape(sp_input)   \ntf.sparse.reshape(sp_input, shape)   \ntf.sparse.retain(sp_input, to_retain)   \ntf.sparse.slice(sp_input, start, size)   \ntf.sparse.split(sp_input, num_split, axis)   \ntf.sparse.to_dense(sp_input)   \ntf.sparse.to_dense(sp_input, default_value)   \ntf.sparse.to_indicator(sp_input, vocab_size)   \ntf.sparse.transpose(sp_input)   \ntf.sparse.transpose(sp_input, perm) ", "page_idx": 23}, {"type": "text", "text": "Python-syntax operations: ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "IndexingAxis1Operation: arg1[:, arg2] IndexingOperation: arg1[arg2] PairCreationOperation: (arg1, arg2) SingletonTupleCreationOperation: (arg1,) SlicingAxis0BothOperation: arg1[arg2:arg3] SlicingAxis0LeftOperation: arg1[arg2:] SlicingAxis0RightOperation: arg1[:arg2] SlicingAxis1BothOperation: arg1[:, arg2:arg3] SlicingAxis1LeftOperation: arg1[:, arg2:] SlicingAxis1RightOperation: arg1[:, :arg2] TripleCreationOperation: (arg1, arg2, arg3) ", "page_idx": 23}, {"type": "text", "text": "Rule \u2192 if Filter then Transforms   \nTransforms $\\rightarrow$ Transform | Transform ; Transforms Filter $\\rightarrow$ Atom | not Atom | Atom \u2227Filter | Atom \u2228Filter $A t o m\\rightarrow$ $C o l o r\\!=\\!_{c}$ Color | Size =s Size | Degree $=_{d}$ Degree | Width $=_{w}$ Width | Height $\\overline{{-h}}$ Height | Shape =SShape | Row =r Row | Column $\\eqcirc C$ Column | is_neighbor (Obj, Obj )   \nTransform $\\rightarrow$ update_color(Color) | move(Dir) | move_max(Dir) | extend(Dir, Overlap) | rotate(Angle) | fill_rectangle(Color, Overlap) | hollow_rectangle(Color) | mirror(Axis) | add_border(Color) | flip(Axis) | NoOp $O b j\\rightarrow$ self | x | y | . . . $C o l o r\\rightarrow$ color_of(Obj ) | GREY | RED | BLACK | BLUE | YELLOW | ORANGE | BROWN | GREEN | GREY | FUCHSIA . . . $D i r\\to$ dir_of(Obj ) | UP | DOWN | LEFT | RIGHT | UPLEFT | DOWNLEFT | UPRIGHT | DOWNRIGHT . . . $A x i s\\rightarrow$ axis_of(Obj ) | VERTICAL | HORIZONTAL | LEFTDIAGONAL | RIGHTDIAGONAL . . . Overlap $\\rightarrow$ TRUE | FALSE Angle $\\rightarrow$ 90 | 180 | 270 $S i z e\\rightarrow$ size_of(Obj ) | MIN | MAX | . . . Degree $\\rightarrow$ degree_of(Obj ) | MIN | MAX | . . . Width $\\rightarrow$ width_of(Obj ) | MIN | MAX | . . . Height $\\rightarrow$ height_of(Obj ) | MIN | MAX | . . . Column $\\rightarrow$ column_of(Obj ) | MIN | MAX | . . . Row \u2192 row_of(Obj ) | MIN | MAX | . . . Shape $\\rightarrow$ shape_of(Obj ) | ENCLOSED | SQUARE | . . . ", "page_idx": 24}, {"type": "text", "text": "Figure 16: The full grammar for our ARC DSL, object specific parameters like size, degree change per benchmark. ", "page_idx": 24}, {"type": "text", "text": "H The Full ARC DSL ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "The full grammar of our ARC DSL is shown in Fig. 16. ", "page_idx": 24}, {"type": "text", "text": "I Detailed Prompt Settings ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "For ARC, we sample completions with temperature 1 and 4000 max tokens. For TENSOR, we use temperature 1 and 4000 max tokens. For SYGUS, we use temperature 0.5 and 4000 max tokens. We use the same settings for all three LLMs. When prompting GPT4O, we set response_type to JSON. ", "page_idx": 24}, {"type": "text", "text": "J Broader Research Impacts ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Our technique presents a powerful strategy for harnessing both syntactically valid and invalid outputs from an LLM to learn a surrogate model. Incorporating hallucinatory outputs \u2013 often erroneous generated by the model, allows us to extract insights that are discarded in standard practices. Our approach mitigates the need for large-scale sampling of completions from LLMs, promoting a more efficient and effective utilization of these models, saving resources. In addition to improving the cost effectiveness of using LLMs, it also opens up new avenues for enhancing model robustness and adaptability across different domains. ", "page_idx": 24}, {"type": "text", "text": "Algorithm 2 ARC Synthesis Algorithm ", "page_idx": 25}, {"type": "text", "text": "Input: A set of input-output example grids $\\mathcal{E}$ , transform grammar $\\mathcal{G}_{t}$ and filter grammar $\\mathcal{G}_{f}$   \nOutput: A solution map $\\mathcal{M}$ from each transform to the corresponding filter   \n1: procedure HYSYNTH-ARC $(\\mathcal{E},\\mathcal{G}_{p},\\mathcal{G}_{t})$   \n2: LVL, $\\mathbf{B}\\gets0,\\emptyset$ \u25b7Initialize search state   \n3: $S_{\\mathrm{llm}}\\gets\\mathrm{LLM}(\\mathcal{E})$ $\\triangleright$ Sample solutions from the LLM   \n4: $\\mathcal{G}_{p},\\mathcal{G}_{t}\\gets\\operatorname{INIT}(\\mathcal{G}_{p},\\mathcal{S}_{\\operatorname*{llm}}),\\operatorname{INIT}(\\mathcal{G}_{t},\\mathcal{S}_{\\operatorname*{llm}})$ \u25b7Initialize both PCFGs using LLM solutions   \n5: while not timeout do   \n6: $\\mathcal{O}\\gets\\mathrm{TRANSFORM-SEARCH}(\\mathcal{G}_{t},\\mathcal{E})$ \u25b7Synthesize transforms that cover all objects   \n7: M \u2190FILTER-SEARCH(Gf, E, O) \u25b7Synthesize filters for the above transforms   \n8: if \u2200(t, f) \u2208M, f \u0338= \u22a5then \u25b7Found a filter for each transform   \n9: return M \u25b7Return the complete solution ", "page_idx": 25}, {"type": "text", "text": "Algorithm 3 Transform Synthesis Algorithm ", "page_idx": 25}, {"type": "text", "text": "Input: PCFG $\\mathcal{G}_{t}$ and input-output grids $\\mathcal{E}$   \nOutput: A map $\\scriptscriptstyle\\mathcal{O}$ from transforms to correctly changed objects   \n1: procedure TRANSFORMS-SEARCH $(\\mathcal{G}_{t},\\mathcal{E})$   \n2: LVL, $\\mathbf{B},\\mathbf{E}\\gets0,\\emptyset,\\emptyset$ \u25b7Initialize search state   \n3: while $\\chi_{\\mathrm{L}}\\leq\\mathrm{LIM}$ do   \n4: for $T\\in$ NEW-TRANSFORMS $\\left({\\mathcal{G}}_{t},\\mathrm{LVL},\\mathbf{B}\\right)$ do \u25b7For all transforms with cost LVL   \n5: $\\mathrm{EvAL}\\gets\\{[T]|(\\omega_{i})\\;|\\;\\langle i,o\\rangle\\in\\mathcal{E},\\omega_{i}\\in i\\}$ $\\triangleright$ Apply transform on objects in input grids from $\\mathcal{E}$   \n6: if EVAL $\\cap\\bigcup_{\\langle i,o\\rangle\\in\\varepsilon}\\{\\omega_{o}\\mid\\omega_{o}\\in o\\}\\neq\\emptyset$ then $\\triangleright T$ covers a subset of objects   \n7: $\\mathcal{O}[T]\\leftarrow\\mathrm{EvAL}$ \u25b7Store the transform and objects covered by it   \n8: else if EVAL $\\in\\mathrm{E}$ then   \n9: continue \u25b7 $T$ is observationally equivalent to another transform in B   \n10: $\\begin{array}{r}{\\ensuremath{\\mathbf i}\\{\\bigcup_{T\\in\\mathcal{O}}\\mathcal{O}[T]=\\bigcup_{\\left\\langle i,o\\right\\rangle\\in\\mathcal{E}}\\{\\omega_{o}\\;\\big\\vert\\;\\omega_{o}\\in o\\}}\\end{array}$ then $\\triangleright$ All objects are correctly transformed   \n11: return O   \n12: $\\mathrm{B}[\\mathrm{LVL}]\\leftarrow\\mathrm{B}[\\mathrm{LVL}]\\cup\\{T\\}$ \u25b7Add transform to the bank, indexed by cost for later search   \n13: E \u2190E \u222aEVAL $\\triangleright$ Cache evaluation result   \n14: LVL \u2190LVL + 1   \n15: return \u22a5 \u25b7Cost limit reached ", "page_idx": 25}, {"type": "text", "text": "K The ARC Synthesis Algorithm ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Overall Synthesis Algorithm The overall synthesis algorithm takes as input a set of input-output grids $\\mathcal{E}$ , along with grammars $\\mathcal{G}_{t}$ and $\\mathcal{G}_{f}$ . We sample candidate solutions from an LLM by constructing a prompt using $\\mathcal{E}$ . These solutions are used to initialize the weights of production rules in the transform and filter grammars, $\\mathcal{G}_{t}$ and $\\mathcal{G}_{f}$ , respectively. We optimize the search by using a divide and conquer approach: first, a TRANSFORM-SEARCH procedure searches for transforms, mapping each to its correctly transformed objects in $\\scriptscriptstyle\\mathcal{O}$ . Following this, a search for filters is initiated using the FILTERSEARCH procedure. If a filter is found for each transform, the algorithm terminates and returns $\\mathcal{M}$ , which maps each transform to its corresponding filter. The algorithm described above terminates after the first solution is found, but we keep searching for a smaller set of transforms [6]. ", "page_idx": 25}, {"type": "text", "text": "Transform Search Algorithm The transform synthesis algorithm in Algorithm 3 takes as input a PCFG $\\mathcal{G}_{t}$ and $\\mathcal{E}$ . It enumerates transforms in the order of increasing discrete costs according to $\\mathcal{G}_{t}$ . ", "page_idx": 25}, {"type": "text", "text": "The algorithm starts with the following initial state: 1) a cost level (LVL) equal to 0 in order to keep track of the current cost during enumeration, 2) a program bank (B) that indexes the enumerated transforms by their cost for efficient retrieval, and 3) an evaluation cache (E) that stores the result of all evaluated transforms within B. At each iteration, the algorithm explores the space of all new transforms generated by the NEW-TRANSFORMS procedure for the current cost level. ", "page_idx": 25}, {"type": "text", "text": "On line 5 in Algorithm 3, the enumerated transform $T$ is applied to each object in the input grids from $\\mathcal{E}$ . If $T$ correctly transforms a subset of objects, $T$ and the objects covered by it are stored in map $\\scriptscriptstyle\\mathcal{O}$ indexed by the transform (line 7). When the transforms in $\\scriptscriptstyle\\mathcal{O}$ cover all grid objects, $\\scriptscriptstyle\\mathcal{O}$ is returned (line 10-11). For transforms with objects bound by a filter, such as in update_color(color_of(other)), we consider all possible values (of color) that could be assigned and yield concrete transforms corresponding to each of those assignments. ", "page_idx": 25}, {"type": "text", "text": "Filter Search Algorithm The filter search algorithm takes as input a filter PCFG $\\mathcal{G}_{f}$ , $\\mathcal{E}$ , and the map $\\scriptscriptstyle\\mathcal{O}$ returned by the transform search in Algorithm 3. The filter search proceeds in a similar manner as the transforms search wherein it enumerates filters in the order of increasing cost as per the PCFG $\\mathcal{G}_{f}$ . It initiates a new search to find a fliter for each transform in $\\scriptscriptstyle\\mathcal{O}$ . Each enumerated fliter expression is evaluated on all objects in the input grids. If the objects for which the fliter is True are the same as the objects covered by the transform, we have found a filter for this transform. Once a filter is found for each of the transforms in $\\scriptscriptstyle\\mathcal{O}$ , we return the solution map $\\mathcal{M}$ . ", "page_idx": 26}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: The main claims accurately reflect the paper\u2019s contributions and scope. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 27}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: The authors have created a separate \"Limitations\" section (4.3) included in the experiments section of the paper. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 27}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The paper does not include theoretical results. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 28}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: All the results presented in the paper can be reproduced using the LLM generations and synthesizers, both of which are publicly available on GitHub. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 28}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: The authors provide a detailed description of the datasets. Instructions for reproducing the results, along with the actual results in the paper, are included in the supplemental material. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/ guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 29}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: The paper and Github repository provide all the necessary details to reproduce the experimental results. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 29}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: The non-deterministic component of our experiments is the LLM sampling and the results are validated by performing the experiments across different models and domains, and also for different number of LLM samples. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 29}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 30}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: The experimental setup details are provided in the experiments section. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 30}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: The research conducted in the paper conforms with the NeurIPS Code of Ethics. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 30}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: The paper discusses the potential impacts of the work in the conclusion and the \"Broader Impacts\" section in the appendix. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 30}, {"type": "text", "text": "\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 31}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 31}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The authors reference all relevant papers related to existing assets. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: The authors have included experimental results in the supplemental data and publicly released the ARC synthesizer on GitHub, complete with documentation. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 32}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 32}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}]