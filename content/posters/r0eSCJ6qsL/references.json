{"references": [{"fullname_first_author": "Mingxing Tan", "paper_title": "EfficientNetV2: Smaller Models and Faster Training", "publication_date": "2021-07-01", "reason": "This paper is highly relevant due to its introduction of EfficientNetV2, a model that significantly improves training speed and efficiency, directly impacting the AsCAN architecture's design choices for efficient attention mechanisms."}, {"fullname_first_author": "Chitwan Saharia", "paper_title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding", "publication_date": "2022-12-01", "reason": "This work is crucial because it presents state-of-the-art text-to-image generation models that achieve photorealistic results, providing a benchmark against which the AsCAN's text-to-image capabilities are measured and compared."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-Resolution Image Synthesis with Latent Diffusion Models", "publication_date": "2022-06-01", "reason": "This paper is highly influential for its introduction of latent diffusion models, significantly impacting the AsCAN architecture's design and training strategy for large-scale image generation tasks."}, {"fullname_first_author": "Zihang Dai", "paper_title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes", "publication_date": "2021-12-01", "reason": "CoAtNet is a key reference as it introduces a hybrid architecture that combines convolutional and transformer blocks, a core design principle adopted and further developed by AsCAN for efficient computation across various resolutions."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising Diffusion Probabilistic Models", "publication_date": "2020-12-01", "reason": "This foundational paper introduces denoising diffusion probabilistic models (DDPMs), which form the basis for the AsCAN's text-to-image generation approach, providing the theoretical underpinning for this model's training and generation processes."}]}