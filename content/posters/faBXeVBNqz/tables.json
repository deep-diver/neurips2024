[{"figure_path": "faBXeVBNqz/tables/tables_7_1.jpg", "caption": "Table 1: Energy (E) and force (F) mean absolute errors (MAEs) for the rMD17 data set. E-and F-MAE are given in meV and meV/\u00c5, respectively. Results are shown for models trained using Ntrain = {950, 50} configurations randomly drawn from the data set, with further 50 used for early stopping. All values are obtained by averaging over five independent runs, with the standard deviation provided if available. Best performances, considering the standard deviation, are highlighted in bold.", "description": "This table presents the mean absolute errors (MAE) in total energies (E) and atomic forces (F) for models trained on the rMD17 dataset.  The models were trained with either 950 or 50 configurations, and the results are averages of five independent runs.  The best-performing models, taking into account the standard deviation, are shown in bold.  The MAEs are given in meV for energy and meV/\u00c5 for force.", "section": "Experiments and results"}, {"figure_path": "faBXeVBNqz/tables/tables_8_1.jpg", "caption": "Table 2: Energy (E) and force (F) root-mean-square errors (RMSEs) for the 3BPA data set. E- and F-RMSE are given in meV and meV/\u00c5, respectively. Results are shown for models trained using 450 configurations randomly drawn from the training data set collected at 300 K, with further 50 used for early stopping. All ICTP results are obtained by averaging over five independent runs. For MACE and NequIP, the results are reported for three runs. The standard deviation is provided if it is available. Best performances, considering the standard deviation, are highlighted in bold. Inference time and memory consumption are measured for a batch size of 100. Inference time is reported per structure in ms, while memory consumption is provided for the entire batch in GB.", "description": "This table shows the RMSE of energy and force for different models trained on the 3BPA dataset.  It compares the performance of ICTP (with various configurations) against MACE and NequIP, considering different temperatures and dihedral angles.  Inference time and memory consumption are also reported, providing a holistic view of model efficiency.", "section": "Experiments and results"}, {"figure_path": "faBXeVBNqz/tables/tables_9_1.jpg", "caption": "Table 2: Energy (E) and force (F) root-mean-square errors (RMSEs) for the 3BPA data set. E- and F-RMSE are given in meV and meV/\u00c5, respectively. Results are shown for models trained using 450 configurations randomly drawn from the training data set collected at 300 K, with further 50 used for early stopping. All ICTP results are obtained by averaging over five independent runs. For MACE and NequIP, the results are reported for three runs. The standard deviation is provided if it is available. Best performances, considering the standard deviation, are highlighted in bold. Inference time and memory consumption are measured for a batch size of 100. Inference time is reported per structure in ms, while memory consumption is provided for the entire batch in GB.", "description": "This table shows the performance of different models on the 3BPA dataset.  It presents the root-mean-square errors (RMSEs) for energy and force, calculated using different methods at three different temperatures (300 K, 600 K, and 1200 K) and along various dihedral angles.  The table highlights the best performance achieved for each metric and condition and includes inference time and memory consumption.", "section": "Experiments and results"}, {"figure_path": "faBXeVBNqz/tables/tables_31_1.jpg", "caption": "Table A1: Inference times and memory consumption as a function of the tensor rank L and the correlation order v for the 3BPA data set. All values for ICTP and MACE models are obtained by averaging over five independent runs. The standard deviation is provided if it is available. Best performances are highlighted in bold. Inference time and memory consumption are measured for a batch size of 10. Inference time is reported per structure in ms; memory consumption is provided for the entire batch in GB.", "description": "This table presents the inference times and memory consumption for ICTP and MACE models on the 3BPA dataset for different tensor ranks (L) and correlation orders (v).  The results are averages over five independent runs, with standard deviations included where available.  The table shows how the computational cost scales with increasing tensor rank and correlation order, highlighting the performance differences between the ICTP and MACE methods.", "section": "E.3 Additional results"}, {"figure_path": "faBXeVBNqz/tables/tables_31_2.jpg", "caption": "Table A2: Energy (E) and force (F) mean absolute errors (MAEs) for the MD22 data set.<sup>a</sup> E- and F-MAE are given in meV/atom and meV/\u00c5, respectively. Results are shown for models trained using training set sizes defined in the original publication [48]. All values for ICTP models are obtained by averaging over three independent runs. We also use an additional subset of 500 configurations drawn randomly from the original data set for early stopping. The standard deviation is provided if available. Best performances, considering the standard deviation, are highlighted in bold.", "description": "This table presents the mean absolute errors (MAE) for energy (E) and force (F) in the MD22 dataset using various machine learning models, including the ICTP model proposed in this paper.  The models were trained with the same dataset sizes as used in the original MD22 publication.  The results highlight that the ICTP model performs on par with or better than other state-of-the-art models for this particular dataset.", "section": "Experiments and results"}, {"figure_path": "faBXeVBNqz/tables/tables_32_1.jpg", "caption": "Table A3: Energy (E) and force (F) root-mean-square errors (RMSEs) for the 3BPA data set (results for Ntrain = 50). E- and F-RMSE are given in meV and meV/\u00c5, respectively. Results are shown for models trained using 50 molecules randomly drawn from the training data set collected at 300 K, with further 50 used for early stopping. All ICTP and MACE results are obtained by averaging over five independent runs, with the standard deviation provided if available. Best performances, considering the standard deviation, are highlighted in bold.", "description": "This table presents the RMSEs in total energies and atomic forces for the 3BPA dataset when training models with only 50 configurations.  It compares the performance of ICTPfull, ICTPsym, ICTPsym+lt, and MACE models.  The best performing model for each metric is highlighted.", "section": "Experiments and results"}, {"figure_path": "faBXeVBNqz/tables/tables_33_1.jpg", "caption": "Table A3: Energy (E) and force (F) root-mean-square errors (RMSEs) for the 3BPA data set (results for Ntrain = 50). E- and F-RMSE are given in meV and meV/\u00c5, respectively. Results are shown for models trained using 50 molecules randomly drawn from the training data set collected at 300 K, with further 50 used for early stopping. All ICTP and MACE results are obtained by averaging over five independent runs, with the standard deviation provided if available. Best performances, considering the standard deviation, are highlighted in bold.", "description": "This table presents the RMSEs in total energies and atomic forces for the 3BPA dataset when the models are trained with only 50 configurations.  The table compares the performance of ICTP full, ICTP sym, ICTP sym+lt, and MACE models, showing the mean and standard deviation of the RMSEs for different temperatures and dihedral slices.  It highlights the best performing models for each metric.", "section": "E.3 Additional results"}, {"figure_path": "faBXeVBNqz/tables/tables_34_1.jpg", "caption": "Table A3: Energy (E) and force (F) root-mean-square errors (RMSEs) for the 3BPA data set (results for Ntrain = 50). E- and F-RMSE are given in meV and meV/\u00c5, respectively. Results are shown for models trained using 50 molecules randomly drawn from the training data set collected at 300 K, with further 50 used for early stopping. All ICTP and MACE results are obtained by averaging over five independent runs, with the standard deviation provided if available. Best performances, considering the standard deviation, are highlighted in bold.", "description": "This table presents the RMSEs in total energies and atomic forces for the 3BPA dataset when models are trained with only 50 configurations.  The results are compared for ICTP (with full, symmetric, and latent-space product basis) and MACE models at different temperatures (300 K, 600 K, 1200 K) and for dihedral angle slices.  The best-performing model for each scenario is highlighted.", "section": "E.3 Additional results"}, {"figure_path": "faBXeVBNqz/tables/tables_36_1.jpg", "caption": "Table A6: Energy (E) and force (F) root-mean-square errors (RMSEs) for the Ta-V-Cr-W data set. E- and F-RMSEs are given in meV/atom and eV/\u00c5, respectively. Results are obtained by averaging over ten splits of the original data set, except for the deformed structures. For the latter, the results are obtained using the whole data set (training + test). For the ICTP, MACE, and GM-NN models, we randomly selected a validation data set of 500 structures from the corresponding training data sets. Best performances, considering the standard deviation, are highlighted in bold. Inference time and memory consumption are measured for a batch size of 50. Inference timea is reported per atom in \u00b5s; memory consumption is provided for the entire batch in GB.", "description": "Table A6 presents the RMSEs in energy and force for the Ta-V-Cr-W dataset.  It compares the performance of ICTP models with varying tensor ranks (L=0,1,2) against MACE models with the same tensor ranks, and also against MTP, GM-NN, and EAM. Results are shown separately for various subsystems (binary, ternary, quaternary alloys, and deformed structures) and overall.  The table includes inference time and memory consumption per atom and per batch, respectively.", "section": "Experiments and results"}]