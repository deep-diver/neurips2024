{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2020-00-00", "reason": "This paper introduces NeRF, a foundational work in neural implicit representations for novel view synthesis, which the current paper builds upon for inverse rendering."}, {"fullname_first_author": "Mark Boss", "paper_title": "Nerd: Neural reflectance decomposition from image collections", "publication_date": "2021-00-00", "reason": "This paper presents NeRD, a significant advancement in neural inverse rendering, directly addressing the challenge of decomposing scene properties from images, which the current paper improves upon."}, {"fullname_first_author": "Xiuming Zhang", "paper_title": "Nerfactor: Neural factorization of shape and reflectance under an unknown illumination", "publication_date": "2021-00-00", "reason": "This paper introduces NeRFactor, a key method in implicit neural inverse rendering that explicitly models visibility, which is crucial for handling shadows and reflections, a core focus of the current work."}, {"fullname_first_author": "Yuanqing Zhang", "paper_title": "Modeling indirect illumination for inverse rendering", "publication_date": "2022-00-00", "reason": "This paper, InvRender, is a direct predecessor, introducing the modeling of indirect illumination in implicit inverse rendering, which the current paper significantly extends to handle high-illumination scenarios."}, {"fullname_first_author": "Brent Burley", "paper_title": "Physically-based shading at disney", "publication_date": "2012-00-00", "reason": "This paper details Disney's physically-based rendering model, which is widely used as a basis for many modern rendering techniques, and the current paper leverages this foundation to accurately estimate BRDF parameters."}]}