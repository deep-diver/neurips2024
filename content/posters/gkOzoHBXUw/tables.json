[{"figure_path": "gkOzoHBXUw/tables/tables_5_1.jpg", "caption": "Table 1: The LoRA configurations that compose heterogeneous resource distributions, detailed in Figure 3.", "description": "This table lists four different LoRA configurations used to create heterogeneous resource distributions in the experiments.  Each configuration specifies the rank (r) of the LoRA matrices used for fine-tuning different layers of the model. Type 1 uses a low rank (r=8) on all layers, Type 2 uses a medium rank (r=30) on all layers, Type 3 uses a medium rank on attention layers and a high rank (r=200) on feed-forward network (FFN) layers, and Type 4 uses a high rank (r=200) on all layers. The percentage of parameters tuned by each configuration relative to the total number of parameters is also provided. This variation in ranks and parameter counts simulates the diversity of resources available in real-world federated learning settings.", "section": "4.1 Setup for Cross-Device FL Environments"}, {"figure_path": "gkOzoHBXUw/tables/tables_6_1.jpg", "caption": "Table 2: The weighted average Rouge-L scores of unseen clients provide insights into the global model's generalization ability. Results from baseline methods with homogeneous ranks (Line 3, denoted as Homo Rank) are compared with those incorporating FlexLoRA and HETLORA across various resource distributions (Line 4~7). The significant test are presented in Appendix F.", "description": "This table compares the performance of different federated learning methods on unseen clients, assessing their ability to generalize to new data distributions.  It shows the average Rouge-L scores for several baselines (FedAvg, FedIT, SLORA) with homogeneous LoRA ranks, and the same baselines enhanced with FlexLoRA and HETLORA, across different resource distribution scenarios (Uniform, Heavy-Tail-Light, Normal, Heavy-Tail-Strong).  The results highlight the improved generalization performance of FlexLoRA across various scenarios.", "section": "4.3 Unseen Client Generalization"}, {"figure_path": "gkOzoHBXUw/tables/tables_7_1.jpg", "caption": "Table 3: Average percentage improvement of FlexLoRA over baseline methods (FedAvg, FedIT, SLORA) across different resource distributions, calculated over 12 NLP task categories. More detailed comparison is presented in Figure 4.", "description": "This table presents the average percentage improvement achieved by integrating FlexLoRA across different resource distributions for three baseline methods: FedAvg, FedIT, and SLORA.  The improvements are calculated across 12 NLP task categories.  A more detailed comparison is shown in Figure 4.", "section": "4.3 Unseen Client Generalization"}, {"figure_path": "gkOzoHBXUw/tables/tables_8_1.jpg", "caption": "Table 4: Convergence round and FL cost per round for different LoRA ranks.", "description": "This table shows the number of communication rounds (\"R\") needed to reach a loss of 2 (approximately 75% progress to convergence) and the per-round FL cost (\"CostR\") relative to the homogeneous rank baseline (1.001x \u2248 100%). The total cost (\"Costall\") is also shown, representing the product of \"R\" and \"CostR\".  The results illustrate FlexLoRA's efficiency gains under different resource distributions (Homo Rank, Heavy-Tail (L), Uniform).", "section": "4.6 Scalability Study"}, {"figure_path": "gkOzoHBXUw/tables/tables_15_1.jpg", "caption": "Table 5: Trainable parameters and memory cost for different LoRA configurations, and the corresponding efficiency improvement compared with full finetuning.", "description": "This table compares four different LoRA configurations (Type 1-4) with full finetuning in terms of the percentage of trainable parameters, memory cost, and the speedup achieved.  Type 1 uses a rank of 8 across all layers, Type 2 uses a rank of 30, Type 3 uses a rank of 30 for attention layers and 200 for feed-forward network (FFN) layers, and Type 4 uses a rank of 200 across all layers. The table shows that using LoRA significantly reduces the number of trainable parameters and memory consumption compared to full finetuning, with the speedup increasing as the rank increases.", "section": "Efficiency Improvement from LoRA under Different Ranks"}, {"figure_path": "gkOzoHBXUw/tables/tables_15_2.jpg", "caption": "Table 6: Speedup of LoRA tuning for each communication round.", "description": "This table shows the average time per client to complete one communication round for different LoRA ranks (8 and 200) and for full finetuning.  It demonstrates the speedup achieved by using LoRA compared to full finetuning.  A lower time and higher speedup indicate a more efficient training process.", "section": "4.2 Setup for FL Baselines"}, {"figure_path": "gkOzoHBXUw/tables/tables_15_3.jpg", "caption": "Table 7: Illustration of the original data structure for tasks in natural instruction dataset [39].", "description": "This table provides example inputs, outputs, and explanations for a \"Cause Effect Classification\" task from the Natural Instructions dataset. It shows how the task is defined, including positive and negative examples to illustrate the expected input-output relationships.  The table also includes a sample instance and the valid output format.", "section": "4.3 Unseen Client Generalization"}, {"figure_path": "gkOzoHBXUw/tables/tables_16_1.jpg", "caption": "Table 7: Illustration of the original data structure for tasks in natural instruction dataset [39].", "description": "This table shows an example of how the data is structured in the natural instruction dataset used in the paper. It illustrates the format of the input, output, and category for a specific task, namely \"Cause Effect Classification.\" The example shows how two sentences are provided as input, and the task is to determine whether the second sentence is the cause or effect of the first.  The output shows the correct label (\"cause\") for this specific example, along with the task category.", "section": "4.4 Cross-Task Generalization"}, {"figure_path": "gkOzoHBXUw/tables/tables_16_2.jpg", "caption": "Table 9: Impact of choosing different layers to apply LoRA module. The results are zero-shot Rouge-L score of the global model. For the experiment that uses FlexLoRA for aggregation, the client resource distribution is uniform.", "description": "This table shows the impact of adding LoRA to different layers (attention layers only vs. all layers) on the zero-shot Rouge-L score of the global model in a federated learning setting.  The results are compared for the standard FedIT method and the same method augmented with FlexLoRA (a proposed aggregation method).  A uniform client resource distribution was used for the FlexLoRA experiment.", "section": "4.1 Setup for Cross-Device FL Environments"}, {"figure_path": "gkOzoHBXUw/tables/tables_17_1.jpg", "caption": "Table 10: Percentage of improvement of FedAvg, FedIT, and SLORA incorporating with FlexLoRA compared with their respective configurations without FlexLoRA, as shown in Table 2.", "description": "This table shows the percentage improvement achieved by integrating FlexLoRA into three different federated learning baselines (FedAvg, FedIT, SLORA) across four different resource distributions (Uniform, Heavy-Tail-Light, Normal, Heavy-Tail-Strong).  The average improvement across all baselines and distributions is also provided.  It offers a concise summary of the performance gains obtained by incorporating FlexLoRA to highlight its effectiveness in enhancing the generalization ability of federated global models.", "section": "4.3 Unseen Client Generalization"}, {"figure_path": "gkOzoHBXUw/tables/tables_17_2.jpg", "caption": "Table 11: Significant test results (in p-values) between FlexLoRA and its FL baselines to be integrated.", "description": "This table presents the p-values from statistical significance tests comparing the performance of FlexLoRA against three federated learning baselines (FedAvg, FedIT, and SLORA) across four different resource distributions.  Low p-values (typically below 0.05) indicate statistically significant differences, suggesting that FlexLoRA's performance improvements are not due to random chance. The results show FlexLoRA's consistent outperformance across various scenarios.", "section": "4.3 Unseen Client Generalization"}, {"figure_path": "gkOzoHBXUw/tables/tables_18_1.jpg", "caption": "Table 12: Results of homogeneous LoRA configurations versus FlexLoRA under FedAvg methods. The experiments are conducted on both DataJucier (1.3B) and LLaMA-3(8B) models on Dolly-15K.", "description": "This table presents the results of comparing the performance of standard FedAvg with FlexLoRA integrated FedAvg under different resource distributions (uniform and heavy-tail-light) and using two different base models (DataJucier 1.3B and LLaMA-3 8B).  It shows the average Rouge-L scores achieved by each method, highlighting the impact of FlexLoRA on model generalization across diverse resource conditions.", "section": "4.6 Scalability Study"}, {"figure_path": "gkOzoHBXUw/tables/tables_19_1.jpg", "caption": "Table 13: 8 examples of single-client performance under FedIT with homo rank 8 and homo rank 200 distribution in a single round.", "description": "This table presents eight examples illustrating the performance of individual clients under the Federated IT (FedIT) framework using homogeneous LoRA ranks of 8 and 200.  Each row shows a different client's performance on a specific NLP task, showcasing the impact of the LoRA rank on individual client performance in a single round of the FedIT process. The results highlight the potential for improvement when higher ranks are utilized.", "section": "J Single Client's Performance under Different Rank"}, {"figure_path": "gkOzoHBXUw/tables/tables_19_2.jpg", "caption": "Table 2: The weighted average Rouge-L scores of unseen clients provide insights into the global model's generalization ability. Results from baseline methods with homogeneous ranks (Line 3, denoted as Homo Rank) are compared with those incorporating FlexLoRA and HETLORA across various resource distributions (Line 4~7). The significant test are presented in Appendix F.", "description": "This table presents the weighted average Rouge-L scores achieved on unseen clients using different federated learning (FL) methods.  It compares the performance of  methods with homogeneous LoRA ranks (a baseline) to methods incorporating the proposed FlexLoRA and HETLORA approaches. The comparison is made across various resource distributions (uniform, heavy-tail light, normal, heavy-tail strong).  The results highlight the global model's generalization ability as measured by its performance on unseen clients.", "section": "4.3 Unseen Client Generalization"}]