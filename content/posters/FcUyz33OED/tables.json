[{"figure_path": "FcUyz33OED/tables/tables_6_1.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents a comparison of different point cloud classification methods on the ModelNet-C dataset, which is a benchmark dataset for evaluating robustness against real-world corruptions.  The metric used is mean corruption error (mCE), a lower value indicates better performance.  The table includes results for several existing state-of-the-art methods (DGCNN, PointNet, etc.) and the proposed APCT method, highlighting APCT's superior performance across different corruption types.  The corruption types include variations in scale, jitter, drop (global/local), add (global/local), and rotation.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_7_1.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents a comparison of the mean corruption error (mCE) rates achieved by various point cloud classification methods on the ModelNet-C dataset.  The ModelNet-C dataset is a corrupted version of the standard ModelNet40 dataset and includes seven types of corruptions (Scale, Jitter, Drop-Global, Drop-Local, Add-Global, Add-Local, Rotate) each with five levels of severity. The table highlights the performance of the proposed APCT method in comparison to state-of-the-art methods, showcasing its robustness against real-world corruptions.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_7_2.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents the results of several point cloud classification methods on the ModelNet-C dataset, which is a benchmark dataset for evaluating the robustness of 3D models to common real-world corruptions.  The table shows the mean corruption error (mCE) for each method across seven different types of corruptions (Scale, Jitter, Drop-G, Drop-L, Add-G, Add-L, and Rotate) at five severity levels. The best performance for each corruption type is highlighted in bold. The methods are categorized into those designed specifically against corruption and those that are not.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_12_1.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents a comparison of various point cloud classification methods on the ModelNet-C dataset, focusing on their robustness against different types of corruption (Jitter, Scale, Drop-Global, Drop-Local, Add-Global, Add-Local, Rotate). The metric used for comparison is the mean corruption error (mCE), which measures the average classification error across all types and levels of corruption. The table includes both methods that were specifically designed to address corruptions (indicated by \u2020) and standard methods. The best performance for each corruption type is highlighted in bold.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_12_2.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents a comparison of the mean corruption error (mCE) rates achieved by various point cloud classification methods on the ModelNet-C dataset.  The ModelNet-C dataset is a corrupted version of the standard ModelNet40 dataset, designed to test the robustness of 3D perception models against various real-world corruptions (jitter, scale, rotation, dropping, and adding of points). The table shows the performance of each method across different corruption types and severities, with the best-performing method highlighted in bold.  The '\u2020' symbol indicates methods specifically designed to be robust against corruption.  The results provide a quantitative evaluation of the resilience of the different approaches to various types of data noise and artifacts.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_13_1.jpg", "caption": "Table 8: Results on point cloud attack defense, OA(%, \u2191).", "description": "This table presents the results of point cloud attack defense experiments.  It compares the classification accuracy (OA) of a baseline model (no defense) against a model incorporating the proposed APCT method.  Several types of attacks are tested, including Perturb, Add-CD, Add-HD, KNN, Drop-100, and Drop-200.  The \u0394 row shows the improvement in OA achieved by the APCT method for each attack type.  The results demonstrate the effectiveness of APCT against various point cloud attack methods.", "section": "A.4 Results on Point Cloud Attack Defense"}, {"figure_path": "FcUyz33OED/tables/tables_13_2.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents the classification results on the ModelNet-C dataset, which evaluates the robustness of 3D point cloud recognition models against various corruptions.  The metric used is mean corruption error (mCE), with lower values indicating better performance. The table compares the proposed APCT method with several state-of-the-art methods across different corruption types (Scale, Jitter, Drop-Global, Drop-Local, Add-Global, Add-Local, Rotate).  The best performance for each corruption type is highlighted in bold.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_14_1.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents a comparison of different point cloud classification methods on the ModelNet-C dataset, which is a corrupted version of the ModelNet40 dataset. The table shows the mean corruption error (mCE) for each method across seven different types of corruptions (Scale, Jitter, Drop-Global, Drop-Local, Add-Global, Add-Local, Rotate) at five different severity levels. The best performing method for each corruption type is highlighted in bold.  The methods are categorized into those specifically designed to handle corruptions (indicated with a \u2020) and general-purpose methods.  The table allows readers to assess the robustness of various methods against different types of noise and corruptions commonly found in real-world point cloud data.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_14_2.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents a comparison of the mean corruption error (mCE) rates achieved by different methods on the ModelNet-C dataset.  ModelNet-C is a benchmark dataset for evaluating the robustness of 3D point cloud recognition models against various types of corruptions (jitter, scale, drop, add, and rotation).  The lower the mCE, the better the performance of the method in handling corruptions. The table highlights the state-of-the-art performance achieved by the proposed APCT method.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_14_3.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents the classification results on the ModelNet-C dataset, which is a benchmark dataset for evaluating the robustness of 3D point cloud recognition models against various corruptions. The metric used is mean corruption error (mCE), and the lower the mCE, the better the performance. The table compares the proposed APCT method with several state-of-the-art methods, showing its superior performance in handling various types of corruptions, including scale, jitter, drop, add, and rotate.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_15_1.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents a comparison of the mean corruption error (mCE) rates achieved by different methods on the ModelNet-C dataset.  ModelNet-C is a corrupted version of the ModelNet40 dataset, used to evaluate the robustness of 3D point cloud recognition models to various types of noise and corruptions. The table includes the performance of several state-of-the-art methods, including those specifically designed to handle corrupted data.  The lowest mCE value indicates the best performance, showing which model is most robust to corruption.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_15_2.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents a comparison of the mean corruption error (mCE) rates achieved by various point cloud classification methods on the ModelNet-C dataset.  The dataset includes seven types of corruptions at varying severity levels.  The table shows that the proposed APCT method achieves the lowest mCE rate, indicating superior robustness to corruption compared to existing methods. The table also highlights the state-of-the-art (SoTA) results for each corruption type.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_17_1.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents the classification results on the ModelNet-C dataset, a benchmark for evaluating the robustness of 3D point cloud models against various corruptions.  The metric used is mean corruption error (mCE), which represents the average classification error across different corruption types and levels. The table compares the performance of APCT against several state-of-the-art methods.  The lowest mCE values indicate better robustness to corruption.  The \"\u2020\" symbol marks methods specifically designed for robustness against corruption.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_17_2.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents a comparison of different methods for point cloud classification on the ModelNet-C dataset, which is a challenging benchmark with several types of corruptions. The main evaluation metric is mean corruption error (mCE), which measures the average error rate across different corruption levels. The table shows that the proposed APCT method achieves state-of-the-art results, outperforming other methods by a significant margin.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_18_1.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents a comparison of the mean corruption error (mCE) for various point cloud classification methods on the ModelNet-C dataset.  The dataset contains point clouds with different types of corruptions (scale, jitter, drop-global, drop-local, add-global, add-local, and rotate), each at five levels of severity.  The table shows the mCE for each method under each type of corruption. The best-performing method for each corruption type is highlighted in bold. Methods specifically designed to handle corrupted data are marked with a \u2020 symbol. This allows for a quantitative comparison of the robustness of different methods against real-world corruptions.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_18_2.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents a comparison of different point cloud classification methods on the ModelNet-C dataset, which is a benchmark dataset for evaluating the robustness of models against various types of corruptions. The table shows the mean corruption error (mCE) for each method across seven different corruption types: Scale, Jitter, Drop-Global, Drop-Local, Add-Global, Add-Local, and Rotate. The best performance for each corruption type is shown in bold. Methods marked with \u2020 are specifically designed to be robust against corruptions. The table provides a quantitative evaluation of different methods' performance in handling real-world corruptions.", "section": "4.1 Results on ModelNet-C"}, {"figure_path": "FcUyz33OED/tables/tables_18_3.jpg", "caption": "Table 1: Classification results on the ModelNet-C dataset, mCE(%, \u2193) is reported, the best performance is bold. \u2020 denotes method designed specifically against corruption.", "description": "This table presents a comparison of classification results on the ModelNet-C dataset (a benchmark for evaluating the robustness of point cloud models against various types of corruption) among different methods.  The mCE (mean Corruption Error) metric, a percentage representing the average classification error across different types of corruption and severity levels, is used to evaluate the performance of each method. The best performance for each corruption type is highlighted in bold.  The \u2020 symbol indicates that a method was specifically designed to handle corrupted data.  This allows one to directly compare the resilience of standard methods with those tailored for robustness.", "section": "4.1 Results on ModelNet-C"}]