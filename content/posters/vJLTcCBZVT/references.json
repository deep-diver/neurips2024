{"references": [{"fullname_first_author": "Julius Adebayo", "paper_title": "Quantifying and mitigating the impact of label errors on model disparity metrics", "publication_date": "2023-10-26", "reason": "This paper is highly relevant to the main topic because it directly addresses the issue of label errors and model disparity, which are crucial factors in achieving subgroup robustness."}, {"fullname_first_author": "Martin Arjovsky", "paper_title": "Invariant risk minimization", "publication_date": "2019-07-16", "reason": "This paper introduces the concept of Invariant Risk Minimization (IRM), which is a key technique for addressing spurious correlations, and this is central to the current paper's goals."}, {"fullname_first_author": "Abeba Birhane", "paper_title": "Large image datasets: A pyrrhic win for computer vision?", "publication_date": "2021-01-01", "reason": "This paper is highly relevant as it discusses large-scale datasets and the biases they contain, which is the direct starting point of this research."}, {"fullname_first_author": "Kate Crawford", "paper_title": "Excavating AI: the politics of images in machine learning training sets", "publication_date": "2021-12-01", "reason": "This paper discusses the societal and political biases encoded in training data which directly motivates the current paper's goal of creating debiasing techniques."}, {"fullname_first_author": "Vitaly Feldman", "paper_title": "What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation", "publication_date": "2020-01-01", "reason": "This paper introduces the concept of influence functions for understanding the effect of individual data points on model predictions, and it is a major underlying methodology of the current paper."}]}