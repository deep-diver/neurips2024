[{"figure_path": "l04i6dPMxK/figures/figures_6_1.jpg", "caption": "Figure 1: Illustrative example of abstention where we cover the foreground and background classes with metric balls. We consider two clusters (blue and orange) as the foreground and one background class (white), using the shortest path do metric. Using abstention, we can cover two clusters with one ball for each and abstain the background with no balls required (Fig. 1(a)). In contrast, if we treat the background class as another class, it would require significantly more balls to cover the background class, as seen by the 10 gray balls in Fig. 1(b). If the number of balls to cover significantly increases like in this case, the bound involving the number of balls also gets significantly worse.", "description": "This figure illustrates the advantage of using abstention in contextual bandits.  It shows two scenarios: one where abstention allows efficient coverage of foreground classes with fewer balls, and another where treating the background as a class requires significantly more balls. This highlights how abstention improves reward bounds.", "section": "5 Adversarial contextual bandits with abstention"}, {"figure_path": "l04i6dPMxK/figures/figures_7_1.jpg", "caption": "Figure 2: Results regarding the number of mistakes over time, the four main settings are presented from left to right: the Stochastic Block Model, Gaussian graph, Cora graph and LastFM Asia graph. In this context, D1, D2, and D-INF represent the p-norm bases, LVC represents the community detection basis, and INT represents the interval basis. The baselines, EXP3 for each context, Contextual Bandit with similarity, and GABA-II, are denoted as EXP3, CBSim, and GABA, respectively, and are represented with dashed lines. All the figures display the data with 95% confidence intervals over 20 runs, calculated using the standard error multiplied by the z-score 1.96.", "description": "This figure displays the results of an experiment comparing the performance of several algorithms for contextual bandits with abstention on four different graph datasets.  Each subplot shows the cumulative number of mistakes made by each algorithm over time. The algorithms are CBA with different basis functions (D1, D2, D-INF, LVC, INT), and three baselines (EXP3, CBSim, GABA). The different graph datasets represent varying levels of complexity and structure. Error bars are shown for 95% confidence intervals.", "section": "5.2 Efficient learning with balls"}, {"figure_path": "l04i6dPMxK/figures/figures_19_1.jpg", "caption": "Figure 3: Stochastic Block Model results, dotted lines represent different baselines, while solid lines are used to represent various results.", "description": "This figure presents the results of experiments conducted using the Stochastic Block Model. It compares the performance of the CBA algorithm (solid lines) against several baseline algorithms (dotted lines) in terms of the number of mistakes made over time. Different line styles represent different algorithms (CBA with various bases and baselines). The plot shows that CBA consistently outperforms baseline algorithms, showcasing its effectiveness in the Stochastic Block Model setting.", "section": "5.2 Efficient learning with balls"}, {"figure_path": "l04i6dPMxK/figures/figures_20_1.jpg", "caption": "Figure 2: Results regarding the number of mistakes over time, the four main settings are presented from left to right: the Stochastic Block Model, Gaussian graph, Cora graph and LastFM Asia graph. In this context, D1, D2, and D-INF represent the p-norm bases, LVC represents the community detection basis, and INT represents the interval basis. The baselines, EXP3 for each context, Contextual Bandit with similarity, and GABA-II, are denoted as EXP3, CBSim, and GABA, respectively, and are represented with dashed lines. All the figures display the data with 95% confidence intervals over 20 runs, calculated using the standard error multiplied by the z-score 1.96.", "description": "The figure shows the performance of the CBA algorithm on four different graph datasets: Stochastic Block Model, Gaussian graph, Cora graph, and LastFM Asia graph.  Four different baselines (EXP3, CBSim, GABA, and various p-norm, community detection, and interval bases) are compared against the CBA algorithm. The y-axis represents the number of mistakes, and the x-axis represents time. The results are shown with 95% confidence intervals across 20 runs. The figure demonstrates that the CBA algorithm outperforms baselines on all datasets when the appropriate basis is selected.", "section": "5.2 Efficient learning with balls"}, {"figure_path": "l04i6dPMxK/figures/figures_21_1.jpg", "caption": "Figure 5: Cora results, dotted lines represent different baselines, while solid lines are used to represent various results", "description": "This figure shows the results of applying different algorithms to the Cora dataset for node classification.  The x-axis represents time, and the y-axis represents the number of mistakes.  Several different baselines are compared (dotted lines), and several variations of the CBA algorithm with different basis functions (solid lines) are shown. The different plots represent different selections of labels that were treated as 'noise' in the dataset.", "section": "Experiments"}, {"figure_path": "l04i6dPMxK/figures/figures_22_1.jpg", "caption": "Figure 6: LastFM Asia results, dotted lines represent different baselines, while solid lines are used to represent various results", "description": "The figure shows the results of applying different algorithms (LVC, GABA, CBSim, EXP3) to the LastFM Asia dataset for different noise configurations. Each subplot represents a different set of labels chosen as noise, and the solid lines represent the performance of the CBA algorithm with different bases.  The dotted lines show the performance of other baselines.", "section": "6 Experiments"}]