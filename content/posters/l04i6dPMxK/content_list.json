[{"type": "text", "text": "Bandits with Abstention under Expert Advice ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Stephen Pasteris1\u2217 Alberto Rumi2,3 Maximilian Thiessen4 Shota Saito5 Atsushi Miyauchi3 Fabio Vitale3 Mark Herbster5 ", "page_idx": 0}, {"type": "text", "text": "1The Alan Turing Institute 2University of Milan 3CENTAI Institute 4TU Wien 5University College London \u2217spasteris@turing.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study the classic problem of prediction with expert advice under bandit feedback. Our model assumes that one action, corresponding to the learner\u2019s abstention from play, has no reward or loss on every trial. We propose the confidence-rated bandits with abstentions (CBA) algorithm, which exploits this assumption to obtain reward bounds that can significantly improve those of the classical EXP4 algorithm. Our problem can be construed as the aggregation of confidence-rated predictors, with the learner having the option to abstain from play. We are the first to achieve bounds on the expected cumulative reward for general confidence-rated predictors. In the special case of specialists we achieve a novel reward bound, significantly improving the previous bounds of SPECIALISTEXP (treating abstention as another action). We discuss how CBA can be applied to the problem of adversarial contextual bandits with the option of abstaining from selecting any action. We are able to leverage a wide range of inductive biases, outperforming previous approaches both theoretically and in preliminary experimental analysis. Additionally, we achieve a reduction in runtime from quadratic to almost linear in the number of contexts for the specific case of metric space contexts. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study the classic problem of prediction with expert advice under bandit feedback. The problem is structured as a sequence of trials. During each trial, each expert recommends a probability distribution over the set of possible actions. The learner then selects an action and observes and incurs the (potentially negative) reward associated with that action on that particular trial. In practical applications, errors often lead to severe consequences, and consistently making predictions is neither safe nor economically practical. For this reason, the abstention option has gained a lot of interest in the literature, both in the batch and online setting [Chow, 1957, 1970, Hendrickx et al., 2021, Cortes et al., 2018]. Similarly to previous works, this paper is based on the assumption that one of the actions always has zero reward: such an action is equivalent to an abstention of the learner from play. Besides the rewards being bounded, we make no additional assumptions regarding how the rewards or expert predictions are generated. In this paper, we present an efficient algorithm CBA (Confidence-rated Bandits with Abstentions) which exploits the abstention action to get reward bounds that can be dramatically higher than those of EXP4 [Auer et al., 2002]. In the worst case, our reward bound essentially matches that of EXP4 so that CBA can be seen as a strict improvement, since the time-complexities of the two algorithms are, up to a factor logarithmic in the time horizon, identical in the general case. ", "page_idx": 0}, {"type": "text", "text": "Our problem can also be seen as that of aggregating confidence-rated predictors [Blum and Mansour, 2007, Gaillard et al., 2014, Luo and Schapire, 2015] when the learner has the option of abstaining from taking actions. When the problem is phrased in this way, at the start of each trial, each predictor recommends a probability distribution over the actions (which now may not include an action with zero reward) but with a confidence rating. A low confidence rating can mean that either the predictor thinks that all actions are bad (so that the learner should abstain) or simply does not know which action is the best. Previous works on confidence-rated experts measure the performance of their algorithm in terms of the sum of scaled per-trial rewards. In contrast to previous algorithms, our approach allows for the derivation of bounds on the expected cumulative reward of CBA. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "This formulation enables us to extend our work to the problem of adversarial contextual bandits with the abstention option, which has not been studied before. Previous work has considered the abstention option in the standard (context-free) adversarial bandit setting or in stochastic settings [Cortes et al., 2018, 2020, Neu and Zhivotovskiy, 2020], but not in the contextual and adversarial case. Moreover, their results and methods cannot be applied to confidence-rated predictors. To get more intuition on this setup, we can think of any deterministic policy that maps contexts into actions. Any such policy can be viewed as a classifier, with foreground classes associated with each action and a background class associated with abstaining. Our learning bias is represented by a set of information we refer to as the basis, which we formally define later. It encodes contextual structural assumptions that hold exclusively for the foreground classes and are provided to the algorithm a priori. A particular type of basis is generated by a set of potential clusters that can overlap. Alternatively, a basis can also be created using balls generated by any kind of distance function, which groups contexts believed to be close together. For this latter family of basis, we can also achieve a significant speedup in the per-trial time complexity of CBA. This result is very different (and incomparable) to other results about adversarial bandits in metric spaces [Pasteris et al., 2023b,a]. ", "page_idx": 1}, {"type": "text", "text": "1.1 Additional related work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "The non-stochastic multi-armed bandit problem, initially introduced by Auer et al. [2002], has been a subject of significant research interest. Auer et al. [2002] also considered the multi-armed bandit problem with expert advice, introducing the EXP4 algorithm. EXP4 evolved the field of multiarmed bandits to encompass more complex scenarios, particularly the contextual bandit [Lattimore and Szepesv\u00b4ari, 2020]. Contextual bandits are an extension of the classical multi-armed bandit framework, where an agent makes a sequence of decisions while taking into account contextual information. Our work is also related to the multi-class classification with bandit feedback, called weak reinforcement [Auer and Long, 1999]. An action in our bandit setting corresponds to a class in the multi-class classification framework. ", "page_idx": 1}, {"type": "text", "text": "As discussed in the introduction, a key aspect of this work is the option to abstain from making any decision. In the batch setting [Chow, 1957, 1970], this option is usually referred to as \u201crejection\u201d. These works study whether to use or reject a specific model prediction based on specific requests (see Hendrickx et al. [2021] for a survey). In online learning, \u201crejection\u201d can be the possibility of abstention by the learner. These works usually rely on a cost associated with the abstention action. Neu and Zhivotovskiy [2020] studied the magnitude of the cost associated with abstention in an expert setting with bounded losses. They state that if the cost is lower than half of the amplitude of the interval of the loss, it is possible to derive bounds that are independent of the time. In Cortes et al. [2018], a non-contextual and partial information setting with the option of abstention is studied. The sequel model [Cortes et al., 2020] regards this model as a special case of their stochastic feedback graph model. Schreuder and Chzhen [2021] studied the fairness setting when using the option of abstaining as it may lead to discriminatory predictions. ", "page_idx": 1}, {"type": "text", "text": "One specific scenario where prior algorithms can establish cumulative reward bounds is as follows: on any given trial, the predictors are specialists [Freund et al., 1997], having either full confidence (a.k.a. awake) or no confidence (a.k.a. asleep). The SPECIALISTEXP algorithm by Herbster et al. [2021], a bandit version of the standard specialist algorithm, achieves regret bounds with respect to any subset of specialists where exactly one specialist is awake on each trial. We differ from this work as abstention is an algorithmic choice. Instead of sleeping in the rounds where the specialist is not active, the specialist will vote for abstention, which is a proper action of our algorithm. In Section 5.2, we present an illustrative problem involving learning balls in a space equipped with a metric. This example demonstrates our capability to significantly improve on SPECIALISTEXP. For this problem, we also present subroutines that significantly speed up CBA. ", "page_idx": 1}, {"type": "text", "text": "2 Problem formulation and notation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We consider the classic problem of prediction with expert advice under bandit feedback. In this problem we have $K+1$ actions, $E$ experts, and $T$ trials. On each trial $t$ : ", "page_idx": 2}, {"type": "text", "text": "1. Each expert suggests, to the learner, a probability distribution over the $K+1$ actions.   \n2. The learner selects an action $a_{t}$ .   \n3. The reward incurred by action $a_{t}$ on trial $t$ (which is in $[-1,1])$ is revealed to the learner. ", "page_idx": 2}, {"type": "text", "text": "We note that the experts\u2019 suggestions and the rewards (associated with each action) are chosen a-priori and hence do not depend on the learner\u2019s actions. The aim of the learner is to maximize the cumulative reward obtained by its selected actions. As discussed in Section 1, we consider the case in which there is an action (the abstention action) that incurs zero reward on every trial. ", "page_idx": 2}, {"type": "text", "text": "We denote our action set by $\\smash{\\{K\\}\\cup\\{\\square\\}}$ where $\\sqsubset$ is the abstention action. For each trial $t\\in[T]$ we define the vector $\\pmb{r}_{t}\\in[-1,1]^{K}$ such that for all $a\\in[K]\\,,r_{t,a}$ is the reward obtained by action $a$ on trial $t$ . Moreover, we define $r_{t,\\boxed{\\cdot}}:=0$ which is the reward of the abstention action $\\sqsubset$ . ", "page_idx": 2}, {"type": "text", "text": "It will be useful for us to represent probability distributions over the actions by vectors in the set: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{\\mathcal{A}}:=\\left\\{\\pmb{\\mathscr{s}}\\in\\left[0,1\\right]^{K}\\vert\\;\\vert\\vert\\pmb{\\mathscr{s}}\\vert\\vert_{1}\\leq1\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Any vector $s\\in A$ represents the probability distribution over actions which assigns, for all $a\\in[K]$ , a probability of $s_{a}$ to action $a$ , and assigns a probability of $1-\\|\\pmb{\\mathscr{s}}\\|_{1}$ to the abstention action $\\boxed{\\begin{array}{r l}\\end{array}}$ , where $\\lVert\\pmb{s}\\rVert_{1}$ denotes 1-norm of $\\pmb{s}$ . We write $a\\sim s$ to represent that action $a$ is drawn from the probability distribution $\\pmb{s}$ . We will refer to the elements of the set $\\boldsymbol{\\mathcal{A}}$ as stochastic actions. ", "page_idx": 2}, {"type": "text", "text": "A policy is any element of ${\\mathcal{A}}^{T}$ (noting that any such policy is a matrix in $[0,1]^{T\\times K})$ . Any policy $e\\in A^{\\check{T}}$ defines a stochastic sequence of actions: on every trial $t\\in[T]$ an action $\\underline{{a}}\\in[K]\\;\\bar{\\cup}\\;\\{\\sqcap\\}\\rbrace$ being drawn as $a\\sim e_{t}$ . Note that if the learner plays according to a policy $e\\in A^{T}$ , then on each trial $t$ it obtains an expected reward of $\\boldsymbol{r}_{t}\\cdot\\boldsymbol{e}_{t}$ , where the operator $\\cdot$ denotes the dot product. Note that each expert is equivalent to a policy. Thus, for all $i\\in[E]$ we denote the $i$ -th expert by $e^{i}\\in\\mathcal{A}^{T}$ . Hence, at the start of each trial $t\\in[T]$ , the learner views the sequence $\\left\\langle e_{t}^{i}\\mid i\\in[E]\\right\\rangle$ . ", "page_idx": 2}, {"type": "text", "text": "We can also view the experts as confidence-rated predictors over the set $[K]$ : for each $i\\in[E]$ and $t\\in[T]$ , the vector $e_{t}^{i}$ can be viewed as suggesting the probability distribution $\\bar{e}_{t}^{i}/\\lVert e_{t}^{i}\\rVert_{1}$ over $[K]$ , but with confidence $\\lVert e_{t}^{i}\\rVert_{1}$ . We denote this confidence by $\\bar{c}_{t,i}:=\\|\\bar{e}_{t}^{i}\\|_{1}$ and write $\\pmb{c}_{t}:=(c_{t,1},\\dots,c_{t,E})$ . ", "page_idx": 2}, {"type": "text", "text": "In this work, we will refer to the unnormalized relative entropy defined by: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\Delta(\\pmb{u},\\pmb{v}):=\\sum_{i\\in[E]}u_{i}\\ln\\left(\\frac{u_{i}}{v_{i}}\\right)-\\|\\pmb{u}\\|_{1}+\\|\\pmb{v}\\|_{1}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "for any $\\pmb{u},\\pmb{v}\\in\\mathbb{R}_{+}^{E}$ . We will also use the Iverson bracket notation $\\mathbb{\\left[P\\mathrm{RED}\\right]}$ as the indicator function, meaning that it is equal to 1 if PRED is true, and 0 otherwise. All  t he proo fs are in the Appendix. ", "page_idx": 2}, {"type": "text", "text": "3 Main result ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Our main result is represented by a bound on the cumulative reward of our algorithm CBA. We note that any weight vector $u\\in\\mathbb{R}_{+}^{E}$ induces a matrix $\\pi(\\pmb{u})\\in\\mathbb{R}_{+}^{T\\times K}$ defined by ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\pi(u):=\\sum_{i\\in[E]}u_{i}e^{i},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "which is the linear combination of the experts with coefficients given by $\\textbf{\\em u}$ . However, only some of such linear combinations generate valid policies. Thus, we define ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{V}:=\\{\\pmb{u}\\in\\mathbb{R}_{+}^{E}\\,|\\,\\pi(\\pmb{u})\\in\\mathcal{A}^{T}\\}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "as the set of all weight vectors that generate valid policies. Particularly, note that $\\pmb{u}\\in\\mathcal{V}$ if and only if, on every trial $t$ , the weighted sum of the confidences $\\mathbf{\\nabla}u\\cdot\\mathbf{c}_{t}$ is no greater than one. Given some $\\pmb{u}\\in\\mathcal{V}$ , we define ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\rho(\\pmb{u}):=\\sum_{t\\in[T]}\\pmb{r}_{t}\\cdot\\pmb{\\pi}_{t}(\\pmb{u})\\,,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "which would be the expected cumulative reward of the learner if it was to follow the policy $\\pi(u)$ .   \nWe point out that the learner does not know $\\mathcal{V}$ or the function $\\pi$ a-priori. ", "page_idx": 3}, {"type": "text", "text": "The following theorem (proved in Appendix A) allows us to bound the regret of CBA with respect to any valid linear combination $\\textbf{\\em u}$ of experts. ", "page_idx": 3}, {"type": "text", "text": "Theorem 3.1. CBA takes parameters $\\eta\\,\\in\\,(0,1)$ and $\\pmb{w}_{1}\\,\\in\\,\\mathbb{R}_{+}^{E}$ . For any $\\pmb{u}\\in\\mathcal{V}$ the expected cumulative reward of CBA is bounded below by: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\sum_{t\\in[T]}\\mathbb{E}[r_{t,a_{t}}]\\geq\\mathbb{E}[\\rho(\\pmb{u})]-\\frac{\\Delta(\\pmb{u},\\pmb{w}_{1})}{\\eta}-\\eta(12K+2)T\\,,\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where the expectations are with respect to the randomization of CBA\u2019s strategy. The per-trial time complexity of CBA is in $\\mathcal{O}(K E)$ . ", "page_idx": 3}, {"type": "text", "text": "We now compare our bound to those of previous algorithms. Firstly, EXP4 can only achieve bounds relative to a $\\pmb{u}\\in\\mathcal{V}$ with $\\|u\\|_{1}=1$ , in which case it essentially matches our bound but with $12K+2$ replaced by $8K+8$ . Hence, for any $\\pmb{u}\\in\\mathcal{V}$ the EXP4 bound essentially replaces the term $\\rho(u)$ in our bound by $\\rho(\\boldsymbol{\\mathbf{\\mathit{u}}})/\\|\\boldsymbol{\\mathbf{\\mathit{u}}}\\|_{1}$ . Note that $\\lVert\\boldsymbol{u}\\rVert_{1}$ could be as high as the number of experts which implies we can dramatically outperform $\\mathrm{ExP4^{1}}$ . ", "page_idx": 3}, {"type": "text", "text": "Secondly, when viewing our experts as confidence-rated predictors, we note that previous algorithms for this setting only give bounds on a weighted sum of the per-trial rewards where the weight on each trial is $\\mathbf{\\nabla}u\\cdot\\mathbf{c}_{t}$ for some $\\pmb{u}\\in\\mathcal{V}$ . This is only a cumulative reward bound when ${\\pmb u}\\cdot{\\pmb c}_{t}=1$ for all $t\\in[T]$ , and finding such a $\\textbf{\\em u}$ is typically impossible. When there does exist $\\textbf{\\em u}$ that satisfies this constraint, the reward relative to $\\textbf{\\em u}$ is essentially the same as for us [Blum and Mansour, 2007]. However, there will often be another value of $\\textbf{\\em u}$ that will give us a much better bound, as we show in Section 5.2. ", "page_idx": 3}, {"type": "text", "text": "4 The CBA algorithm ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The CBA algorithm is given in Algorithm 1. In this section, we describe its derivation via a modification of the classic mirror descent algorithm. ", "page_idx": 3}, {"type": "text", "text": "Our modification of mirror descent is based on the following mathematical objects. For all $t\\in[T]$ we first define: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{V}_{t}:=\\left\\{v\\in\\mathbb{R}_{+}^{E}\\,|\\,\\Vert\\pi_{t}(v)\\Vert_{1}\\leq1\\right\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "which is the set of all weight vectors that give rise to linear combinations producing valid stochastic actions at trial $t$ . Given some $t\\in[T]$ , we define our objective function $\\rho_{t}\\ \\dot{:}\\ \\mathcal{V}_{t}\\rightarrow[-1,1]$ as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\rho_{t}(\\boldsymbol{v}):=\\boldsymbol{r}_{t}\\cdot\\boldsymbol{\\pi}(\\boldsymbol{v})\\;\\mathrm{for}\\;\\mathrm{all}\\;\\boldsymbol{v}\\in\\mathcal{V}_{t}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Like mirror descent, CBA maintains, on each trial $t\\in[T]$ , a weight vector $\\pmb{w}_{t}\\in\\mathbb{R}_{+}^{E}$ . However, unlike mirror descent on the simplex, we do not keep $\\pmb{w}_{t}$ normalized, but we will instead project it into $\\mathcal{V}_{t}$ at the start of trial $t$ , producing a vector $\\tilde{\\pmb{w}}_{t}$ . Also, unlike mirror descent, CBA does not use the actual gradient (which it does not know) of $\\rho_{t}$ at $\\tilde{\\pmb{w}}_{t}$ , but (inspired by the EXP3 algorithm) uses an unbiased estimator instead. Specifically, on each trial $t\\in[T]$ , CBA does the following: ", "page_idx": 3}, {"type": "text", "text": "1. Set $\\pmb{\\tilde{w}}_{t}\\gets\\mathrm{argmin}_{\\pmb{v}\\in\\mathcal{V}_{t}}\\,\\Delta(\\pmb{v},\\pmb{w}_{t}).$ .   \n2. Randomly construct a vector $\\pmb{g}_{t}\\in\\mathbb{R}^{E}$ such that $\\mathbb{E}[\\pmb{g}_{t}]=\\nabla\\rho_{t}(\\tilde{\\pmb{w}}_{t})$ .   \n3. Set $\\begin{array}{r}{{\\pmb w}_{t+1}\\leftarrow\\mathrm{argmin}_{{\\pmb v}\\in\\mathbb{R}_{+}^{E}}(\\eta{\\pmb g}_{t}\\cdot({\\pmb\\tilde{w}}_{t}-{\\pmb v})+\\Delta({\\pmb v},{\\pmb\\tilde{w}}_{t})).}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "This naturally raises two questions: how is $a_{t}$ selected and how is $\\scriptstyle g_{t}$ constructed? On each trial $t\\in[T]$ we define ", "page_idx": 3}, {"type": "equation", "text": "$$\ns_{t}:=\\sum_{i\\in[E]}\\tilde{w}_{t,i}e_{t}^{i}\\,,\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "which is the stochastic action generated by the linear combination $\\tilde{\\pmb{w}}_{t}$ , and select $a_{t}\\sim s_{t}$ . Note that: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbb{E}[r_{t,a_{t}}]=\\rho_{t}(\\tilde{\\pmb{w}}_{t})\\,,\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "$\\mathbf{Algorithm\\,1\\,CBA}(\\pmb{w}_{1},\\eta)$ ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "For $t=1,2,\\dots,T\\,{\\bf d o}$ : 1. For all $i\\in[E]$ receive $e_{t}^{i}$ 2. For all $i\\in[E]$ set $c_{t,i}\\gets\\lVert e_{t}^{i}\\rVert_{1}$ 3. If $\\|c_{t}\\|_{1}\\leq1$ then: (a) S $\\mathrm{et}\\,\\tilde{\\pmb{w}}_{t}\\gets\\pmb{w}_{t}$ 4. Else: (a) By interval bisection find $\\lambda>0$ such that: $\\sum_{i\\in[E]}c_{t,i}w_{t,i}\\exp(-\\lambda c_{t,i})=1$ (b) For all $i\\in[E]$ set $\\tilde{w}_{t,i}\\gets w_{t,i}\\exp(-\\lambda c_{t,i})$ 5. Set: $s_{t}\\gets\\sum_{i\\in[E]}\\tilde{w}_{t,i}e_{t}^{i}$ 6. Draw $a_{t}\\sim s_{t}$ 7. Receive rt,a 8. For all $a\\in[K]$ set: $\\displaystyle\\hat{r}_{t,a}\\gets1-[[a=a_{t}](1-r_{t,a_{t}})/s_{t,a_{t}}$ 9. For all $i\\in[E]$ set $w_{(t+1),i}\\gets\\tilde{w}_{t,i}\\exp(\\eta e_{t}^{i}\\cdot\\hat{\\boldsymbol{r}}_{t})$ ", "page_idx": 4}, {"type": "text", "text": "which confirms that $\\rho_{t}$ is our objective function at trial $t$ . Once $\\boldsymbol r_{t,a_{t}}$ is revealed to us we can proceed to construct the gradient estimator $\\scriptstyle\\mathbf{\\textit{g}}_{t}$ . It is important that we construct this estimator in a specific way. Inspired by EXP4 we first define a reward estimator $\\hat{\\pmb{r}}_{t}$ such that for all $a\\in[K]$ we have: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{r}_{t,a}:=1-[\\![a=a_{t}]\\!](1-r_{t,a_{t}})/s_{t,a_{t}}\\,.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "This reward estimate is unbiased as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\hat{r}_{t,a}]=1-\\operatorname*{Pr}[a=a_{t}](1-r_{t,a})/s_{t,a}=r_{t,a}\\,.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We then define, for all $i\\in[E]$ , the component: ", "page_idx": 4}, {"type": "equation", "text": "$$\ng_{t,i}:=\\pmb{e}_{t}^{i}\\cdot\\hat{\\pmb{r}}_{t}\\,.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Note that for all $i\\in[E]$ we have: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}[g_{t,i}]=e_{t}^{i}\\cdot\\mathbb{E}[\\hat{\\boldsymbol{r}}_{t}]=e_{t}^{i}\\cdot\\boldsymbol{r}_{t}=\\partial_{i}\\rho_{t}(\\tilde{\\boldsymbol{w}}_{t})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "so that $\\mathbb{E}[\\pmb{g}_{t}]=\\nabla\\rho_{t}(\\tilde{\\pmb{w}}_{t})$ as required. ", "page_idx": 4}, {"type": "text", "text": "Now that we defined the process by which CBA operates we must show how to compute $\\tilde{\\pmb{w}}_{t}$ and $\\pmb{w}_{t+1}$ . First we show how to compute $\\tilde{\\pmb{w}}_{t}$ from $\\pmb{w}_{t}$ . If $\\|c_{t}\\|_{1}\\leq1$ it holds that $w_{t}\\;\\in\\;\\mathcal{V}_{t}$ so we immediately have $\\tilde{\\pmb{w}}_{t}=\\pmb{w}_{t}$ . Otherwise we must find $\\tilde{w}_{t}\\in\\mathbb{R}_{+}^{E}$ that minimizes $\\Delta(\\tilde{\\pmb{w}}_{t},\\pmb{w}_{t})$ subject to the constraint: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\sum_{i\\in[E]}\\tilde{w}_{t,i}c_{t,i}=1\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "which is equivalent to the constraint that $\\lVert\\pmb{\\pi}(\\tilde{\\pmb{w}}_{t})\\rVert_{1}=1$ . Hence, by Lagrange\u2019s theorem there exists $\\lambda$ such that: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\nabla_{\\tilde{\\pmb{w}}_{t}}\\bigg(\\Delta(\\tilde{\\pmb{w}}_{t},\\pmb{w}_{t})+\\lambda\\sum_{i\\in[E]}\\tilde{w}_{t,i}c_{t,i}\\bigg)=0\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "which is solved by setting, for all $i\\in[E]$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\tilde{w}_{t,i}:=w_{t,i}\\exp(-\\lambda c_{t,i})\\,.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The constraint is then satisfied if $\\lambda$ is such that: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\sum_{i\\in[E]}c_{t,i}w_{t,i}\\exp(-\\lambda c_{t,i})=1\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Since this function is monotonic decreasing, $\\lambda$ can be found by interval bisection. For this computation step, we treat our numerical precision as a constant in our time complexity. In Appendix A.1, we show that, even if the numerical precision is unbounded, we incur a time complexity equal to that of EXP4, up to a factor logarithmic in $T$ , adding only 1 to the regret. ", "page_idx": 5}, {"type": "text", "text": "Turning to the computation of $\\pmb{w}_{t+1}$ , since it is unconstrained it is found by the equation: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\nabla_{{\\pmb w}_{t+1}}({\\pmb g}_{t}\\cdot{\\pmb w}_{t+1}+\\eta^{-1}\\Delta({\\pmb w}_{t+1},\\tilde{\\pmb w}_{t}))=0\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "which is solved by setting, for all $i\\in[E]$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\nw_{(t+1),i}:=\\tilde{w}_{t,i}\\exp(\\eta g_{t,i})\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "5 Adversarial contextual bandits with abstention ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "One main application of CBA is in the problem of adversarial contextual bandits with a finite context set. In this problem, we have a finite set of contexts $\\mathcal{X}$ . A-priori nature selects a sequence: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\langle(x_{t},\\pmb{r}_{t})\\in\\mathcal{X}\\times[-1,1]^{K}\\,|\\,t\\in[T]\\rangle\\,,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "but does not reveal it to the learner. For all $t\\in[T]$ we define $r_{t,\\boxed{\\cdot}}:=0$ . On each trial $t\\in[T]$ the following happens: ", "page_idx": 5}, {"type": "text", "text": "1. The context $x_{t}$ is revealed to the learner.   \n2. The learner selects an action $a_{t}\\in[K]\\cup\\{\\sqsubseteq\\}$ .   \n3. The learner sees and incurs reward $r_{t,a_{t}}\\in[-1,1]$ . ", "page_idx": 5}, {"type": "text", "text": "We will assume that we are given, a-priori, a set $B\\subseteq2^{X}$ that we call the basis. We call each element of $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ a basis element (which is a set of contexts). We will later introduce various potential bases, determined by the nature of the context\u2019s structure: points within a metric space, nodes within a graph, and beyond. Importantly, our method is capable of accommodating any type of basis and, thus, any potential inductive bias that might be present in the data. ", "page_idx": 5}, {"type": "text", "text": "Given our basis we run our algorithm CBA with each expert corresponding to a pair $(B,k)\\in B\\times[K]$ . The expert corresponding to each pair $(B,k)$ will deterministically choose action $k$ when the current context $x_{t}$ is in $B$ , and abstain otherwise. ", "page_idx": 5}, {"type": "text", "text": "Corollary 5.1. Given any basis $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ of cardinality $N$ and any $M\\,\\in\\,\\mathbb{N}$ we can implement CBA such that for any sequence of disjoint basis elements $\\langle B_{j}\\,|\\,j\\,\\in\\,[M]\\rangle$ with corresponding actions $\\langle b_{j}\\in[K]\\mid j\\in[M]\\rangle$ we have: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\sum_{t\\in[T]}\\mathbb{E}[r_{t,a_{t}}]\\geq\\sum_{t\\in[T]}\\sum_{j\\in[M]}\\mathbb{I}x_{t}\\in B_{j}\\mathbb{I}r_{t,b_{j}}-\\sqrt{2M\\ln(N)(6K+1)T}\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The per-trial time complexity of this implementation of CBA is in $\\mathcal{O}(K N)$ . ", "page_idx": 5}, {"type": "text", "text": "Proof. The choice of experts for CBA that leads to Corollary 5.1 is defined by the set of pairs so that $E=N K$ and for each $B\\in\\mathcal{B}$ and action $a\\in[K]$ there exists an unique $i\\in[E]$ such that for all $t\\in[T]$ and $b\\in[K]$ we have: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{e_{t,b}^{i}:=\\mathbb{[}x_{t}\\in B]\\mathbb{\\backslash}\\mathbb{b}=a\\mathbb{]}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "By choosing $w_{1,i}:=M/N K$ for all $i\\in[E]$ , and choosing ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\eta:=(M\\ln(N)/(6K+1)T)^{-1/2}\\,,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Theorem 3.1 implies the reward bound in Corollary 5.1. The per-trial time complexity of a direct implementation of CBA for this set of experts would be $\\mathcal{O}(K N)$ . \u53e3 ", "page_idx": 5}, {"type": "image", "img_path": "l04i6dPMxK/tmp/02cdfd58088d3dc9285b7167e6f207629f8275db6cb01c02025a893dbf13ac30.jpg", "img_caption": [], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Figure 1: Illustrative example of abstention where we cover the foreground and background classes with metric balls. We consider two clusters (blue and orange) as the foreground and one background class (white), using the shortest path $d_{\\infty}$ metric. Using abstention, we can cover two clusters with one ball for each and abstain the background with no balls required (Fig. 1(a)). In contrast, if we treat the background class as another class, it would require significantly more balls to cover the background class, as seen by the 10 gray balls in Fig. 1(b). If the number of balls to cover significantly increases like in this case, the bound involving the number of balls also gets significantly worse. ", "page_idx": 6}, {"type": "text", "text": "We briefly comment on the term: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\sum_{j\\in[M]}\\mathbb{I}^{x_{t}}\\in B_{j}\\mathbb{I}^{r_{t,b_{j}}}\\,,\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "that appears in the theorem statement. If $x_{t}$ does not belong to any of the sets in $\\langle B_{j}\\,|\\,j\\in[M]\\rangle$ then this term is equal to zero (which is the reward of abstaining). Otherwise, since the sets are disjoint, $x_{t}$ belongs to exactly one of them and the term is equal to the reward induced by the action that corresponds to that set. In other words, the total cumulative reward is bounded relative to that of the policy that abstains whenever $x_{t}$ is outside the union of the sets and otherwise selects the action corresponding to the set that $x_{t}$ lies in. ", "page_idx": 6}, {"type": "text", "text": "Note the vast improvement of our reward bound over that of SPECIALISTEXP with abstention as one of the actions. Let\u2019s assume our context set is a metric space and our basis is the set of all balls. In order to get a reward bound for SPECIALISTEXP, the sets in which the specialists are awake must partition the set $\\mathcal{X}$ . This means that we must add to our $M$ balls a disjoint covering (by balls) of the complement of the union of the original $M$ balls. Note that the added balls correspond to the sets in which the specialists predicting the abstention action are awake. Typically this would require a huge number of balls so that the total number of specialists is huge (much larger than $M$ ); this huge number of specialists essentially replaces the term $M$ in our reward bound (we illustrate an example in Figure 1). ", "page_idx": 6}, {"type": "text", "text": "Furthermore, in Appendix D, we show that the same implementation of CBA is capable of learning a weighted set of overlapping basis elements, as long as the sum of the weights of the basis elements covering any context is bounded above by one, which SPECIALISTEXP cannot do in general. ", "page_idx": 6}, {"type": "text", "text": "As we will see below, the practical bases we propose have a moderate size of $|B|={\\mathcal{O}}(|{\\mathcal{X}}|^{2})$ leading to a per-step runtime of $\\bar{\\mathcal{O}}(K|\\mathcal{X}|^{2})$ for CBA in this contextual bandit problem. In Section 5.2, we show how to significantly improve the runtime for a broad family of bases. ", "page_idx": 6}, {"type": "text", "text": "5.1 A lower bound ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we show that CBA is, up to an $\\mathcal{O}(\\ln(|B|))$ factor, essentially best possible on this contextual bandit problem: ", "page_idx": 6}, {"type": "text", "text": "Proposition 5.2. Take any learning algorithm. Given any basis $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ and any $M\\,\\in\\,\\mathbb{N},$ , for any sequence of disjoint basis elements $\\langle B_{j}\\,|\\,j\\in[M]\\rangle$ there exists a sequence of corresponding actions $\\langle b_{j}\\in[K]\\mid j\\in[M]\\rangle$ such that an adversary can force: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\sum_{t\\in[T]}\\sum_{j\\in[M]}\\lVert x_{t}\\in\\mathcal{B}_{j}\\rVert r_{t,b_{j}}-\\sum_{t\\in[T]}\\mathbb{E}[r_{t,a_{t}}]\\in\\Omega\\left(\\sqrt{M K T}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "image", "img_path": "l04i6dPMxK/tmp/56b9feb0680714ccbfc7444179e60548d8dd9c3d465a9b9218013f5956fa12c2.jpg", "img_caption": [], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figure 2: Results regarding the number of mistakes over time, the four main settings are presented from left to right: the Stochastic Block Model, Gaussian graph, Cora graph and LastFM Asia graph. In this context, D1, D2, and D-INF represent the $p$ -norm bases, LVC represents the community detection basis, and INT represents the interval basis. The baselines, EXP3 for each context, Contextual Bandit with similarity, and GABA-II, are denoted as EXP3, CBSim, and GABA, respectively, and are represented with dashed lines. All the figures display the data with $95\\%$ confidence intervals over 20 runs, calculated using the standard error multiplied by the $z$ -score 1.96. ", "page_idx": 7}, {"type": "text", "text": "5.2 Efficient learning with balls ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In practice we can often quantify the similarity between any pair of contexts. That is, the contexts form a metric space, equipped with a distance function $d:\\mathcal{X}\\times\\mathcal{X}\\to\\mathbb{R}_{+}$ known to the learner a-priori. For example, contexts could have feature vectors in $\\mathbb{R}^{m}$ (and the metric is the standard Euclidean distance or cosine similarity) or be nodes in a graph with the metric given by the shortestpath distance. A natural basis for this situation is the set of metric balls. Specifically, a ball is any set $B\\subseteq\\mathcal{X}$ in which there exists some $x\\in\\mathscr{X}$ and $\\delta\\in\\mathbb{R}_{+}$ with: ", "page_idx": 7}, {"type": "equation", "text": "$$\nB=\\left\\{z\\in\\mathcal{X}\\,|\\,d(x,z)\\leq\\delta\\right\\}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "For this broad family of bases2 we can achieve the following speed-up, relying on a a sophisticated data structure based on binary trees. ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.3. Let $N:=|\\mathcal{X}|$ . Given any $M\\in\\mathbb{N}$ we can implement CBA such that for any sequence of disjoint balls $\\langle B_{j}\\,|\\,j\\in[M]\\rangle$ with corresponding actions $\\langle b_{j}\\in[K]\\mid j\\in[M]\\rangle$ we have: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\sum_{t\\in[T]}\\mathbb{E}[r_{t,a_{t}}]\\geq\\sum_{t\\in[T]}\\sum_{j\\in[M]}\\mathbb{I}x_{t}\\in B_{j}\\mathbb{I}r_{t,b_{j}}-\\sqrt{4M\\ln(N)(6K+1)T}\\,.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The per-trial time complexity of this implementation of CBA is in $\\mathcal{O}(K N\\ln(N))$ . ", "page_idx": 7}, {"type": "text", "text": "As there are at most $\\mathcal{O}(N^{2})$ metric balls, this improves the runtime of the direct CBA implementation from $\\mathcal{O}(K N^{2})$ to $\\mathcal{O}(K N\\ln(N))$ , that is almost linear per step. All the details are in Appendix B. ", "page_idx": 7}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "This section conducts preliminary experiments, the code is available at $\\mathrm{GitHub}^{3}$ . We evaluate our method to compare existing algorithms using graph data, since it is common to consider graph structures under the confidence-rated expert setting [Cesa-Bianchi et al., 2013, Herbster et al., 2021]. As mentioned above, the bases used in our algorithm can be constructed arbitrarily, allowing to encompass different inductive biases based on applications. Thus, we consider some representative bases used on learning tasks on graphs before, each leading to different inductive priors on the contexts. We provide a short description of the bases here and refer to Appendix E for more details. ", "page_idx": 7}, {"type": "text", "text": "Effective $p$ -resistance basis $d_{p}$ : Balls given by the metric ", "page_idx": 8}, {"type": "equation", "text": "$$\nd_{p}(i,j):=\\left(\\operatorname*{min}_{u\\in\\mathbb{R}^{N}}\\sum_{s,t\\in V}|u_{s}-u_{t}|^{p}\\right)^{-1/p}.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "We use $d_{1},d_{2}$ , and $d_{\\infty}$ [Herbster and Lever, 2009]. ", "page_idx": 8}, {"type": "text", "text": "Louvain method basis (LVC): Communities returned by the Louvain method [Blondel et al., 2008], processed by the greedy peeling algorithm [Lanciano et al., 2024]. ", "page_idx": 8}, {"type": "text", "text": "Geodesic intervals basis (INT): All sets of the form $I(x,y):=\\{z\\in\\mathcal{X}\\mid z$ is on a shortest x-y path} for all $x,y\\in\\mathcal{X}$ [Pelayo, 2013, Thiessen and Ga\u00a8rtner, 2021]. ", "page_idx": 8}, {"type": "text", "text": "Let $N$ be the cardinality of $|{\\mathcal{X}}|$ . For all three basis types, we immediately get an $O(K N^{2})$ runtime per step of CBA as there are $\\mathcal{O}(N^{2})$ basis elements. Moreover, for $d_{p}$ balls and the LVC basis we can use the more efficient $\\mathcal{O}(K N\\ln{N})$ implementation through Theorem 5.3. We empirically evaluate our approach in the context of online multi-class node classification on a given graph with bandit feedback. At each time step, the algorithm is presented with a node chosen uniformly at random and must either predict an action from the set of possible actions $[K]$ or abstain. The node can accept (resulting in a positive reward) or reject (resulting in a negative reward) the suggestion based on its preferred class with a certain probability. In a real-world application, this models a scenario where each user has a category preference (such as music genre or interest). When the item we decide to present matches their interest, there is a high probability of receiving a reward. ", "page_idx": 8}, {"type": "text", "text": "We compare our approach CBA using each of these bases on real-world and artificial graphs against the following baselines: an implementation of CONTEXTUALBANDIT from Slivkins [2011], the GABA-II algorithm proposed by Herbster et al. [2021], and an EXP3 instance for each data point. We use the following graphs for evaluation. ", "page_idx": 8}, {"type": "text", "text": "Stochastic block model. We use an established synthetic graph, stochastic block model [Holland et al., 1983]. This graph is generated by spawning an arbitrary number of disjoint cliques representing the foreground classes. Then an arbitrary number of background points are generated and connected to every possible point with a low probability. Figure 2(a) are displayed the results for the case of $F=160$ nodes for each foreground class and $B=480$ nod\u221aes for the background class. Connecting each node of the background class with a probability of $1/\\sqrt{F B}$ . ", "page_idx": 8}, {"type": "text", "text": "Gaussian graph. The points on this graph are generated in a two-dimensional space using five different Gaussian distributions with zero mean. Four of them are positioned at the corners of the unit square, representing the foreground classes and having a relatively low standard deviation. Meanwhile, the fifth distribution, representing the background class, is centered within the square and is characterized by a larger standard deviation. The points are linked in a $k$ -nearest neighbors graph. In Figure 2(b) are displayed the results for 160 nodes for each foreground class and a standard deviation of 0.2, 480 nodes for the background class with a standard deviation of 1.75, along with a 7-nearest neighbors graph. ", "page_idx": 8}, {"type": "text", "text": "Real-world dataset. We tested our approach on the Cora dataset [Sen et al., 2008] and the LastFM Asia dataset [Leskovec and Krevl, 2014]. While both of these graphs contain both features and a graph, we exclusively utilized the largest connected component of each graph, resulting in 2485 nodes and 5069 edges for the Cora graph and 7624 nodes and 27806 edges for the LastFM Asia graph. Subsequently, we randomly chose a subset of three out of the original seven and eighteen classes, respectively, to serve as the background class. Additionally, we selected $15\\%$ of the nodes from the foreground classes randomly to represent noise points, and we averaged the results over multiple runs, varying the labels chosen for noise. Both in Figures 2(c) and 2(d) we averaged over 5 different label sets as noise. For the LastFM Asia graph, we exclusively tested the LVC bases, as it is the most efficient one to compute given the large size of the graph. ", "page_idx": 8}, {"type": "text", "text": "Results. The results from both synthetically generated tests (Figures 2(a) and 2(b)) demonstrate the superiority of our method when compared to the baselines. In particular, $d_{\\infty}$ -balls delivered exceptional results for both graphs, implying that $d_{\\infty}$ -balls effectively cover the foreground classes as expected. For the Cora dataset (Figure 2(c)), we observed that our method outperforms GABAII only when employing the community detection basis. This similarity in performance is likely attributed to the dataset\u2019s inherent lack of noise. Worth noting that the method we employed to inject noise into the dataset may not have been the optimal choice for this specific context. However, it is essential to highlight that our primary focus revolves around the abstention criteria, which plays a central role in ensuring the robustness of our model in the presence of noise. For the LastFM Asia dataset, our objective was to assess the practical feasibility of the model on a larger graph. We tested the LVC bases as they were the most promising and most efficient to compute. We outperform the baselines in our evaluation as shown in Figure 2(d) and further discussed in Appendix F. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "In summary, our first results confirm what we expected: our approach excels when we choose basis functions that closely match the context\u2019s structure. However, it also encounters difficulties when the chosen basis functions are not a good fti for the context. In Appendix F, the results for a wide range of different parameters used to generate the previously described graphs are displayed. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgement ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "SP acknowledges the following funding. Research funded by the Defence Science and Technology Laboratory (Dstl) which is an executive agency of the UK Ministry of Defence providing world class expertise and delivering cutting-edge science and technology for the benefit of the nation and allies. The research supports the Autonomous Resilient Cyber Defence (ARCD) project within the Dstl Cyber Defence Enhancement programme. AR acknowledges the support from the NeurIPS 2024 Financial Assistance. MT acknowledges support from a DOC fellowship of the Austrian academy of sciences ( O\u00a8AW). SS acknowledges the support by Huawei for his Ph.D study at UCL. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Morteza Alamgir and Ulrike von Luxburg. Phase transition in the family of $p$ -resistances. In Proc. NIPS, pages 379\u2013387, 2011.   \nPeter Auer and Philip M Long. Structural results about on-line learning models with and without queries. Mach. Learn., 36:147\u2013181, 1999.   \nPeter Auer, Nicolo\\` Cesa-Bianchi, Yoav Freund, and Robert E Schapire. The nonstochastic multiarmed bandit problem. SIAM J. Comput., 32(1):48\u201377, 2002.   \nAmir Beck. First-Order Methods in Optimization. SIAM, 2017.   \nVincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. Fast unfolding of communities in large networks. J. Stat. Mech. Theory Exp., 2008(10):P10008, 2008.   \nAvrim Blum and Yishay Mansour. From external to internal regret. J. Mach. Learn. Res., 8(6), 2007.   \nMarco Bressan, Nicolo\\` Cesa-Bianchi, Silvio Lattanzi, and Andrea Paudice. Exact recovery of clusters in finite metric spaces using oracle queries. In Proc. COLT, 2021.   \nNicolo Cesa-Bianchi, Claudio Gentile, and Giovanni Zappella. A gang of bandits. In Proc. NIPS, volume 26, 2013.   \nC Chow. On optimum recognition error and reject tradeoff. IEEE Trans. Inf. Theory, 16(1):41\u201346, 1970.   \nChi-Keung Chow. An optimum character recognition system using decision functions. IRE Trans. Electron. Comput., EC-6(4):247\u2013254, 1957.   \nCorinna Cortes, Giulia DeSalvo, Claudio Gentile, Mehryar Mohri, and Scott Yang. Online learning with abstention. In Proc. ICML, pages 1059\u20131067, 2018.   \nCorinna Cortes, Giulia DeSalvo, Claudio Gentile, Mehryar Mohri, and Ningshan Zhang. Online learning with dependent stochastic feedback graphs. In Proc. ICML, pages 2154\u20132163, 2020.   \nPeter G Doyle and J Laurie Snell. Random Walks and Electric Networks, volume 22 of The Carus Mathematical Monographs. American Mathematical Society, 1984.   \nRobert W Floyd. Algorithm 97: shortest path. Commun. ACM, 5(6):345, 1962.   \nSanto Fortunato. Community detection in graphs. Phys. Rep., 486(3):75\u2013174, 2010.   \nYoav Freund, Robert E Schapire, Yoram Singer, and Manfred K Warmuth. Using and combining predictors that specialize. In Proc. STOC, pages 334\u2013343, 1997.   \nPierre Gaillard, Gilles Stoltz, and Tim Van Erven. A second-order bound with excess losses. In Proc. COLT, pages 176\u2013196, 2014.   \nRalph E Gomory and Tien Chung Hu. Multi-terminal network flows. J. Soc. Ind. Appl. Math., 9(4): 551\u2013570, 1961.   \nKilian Hendrickx, Lorenzo Perini, Dries Van der Plas, Wannes Meert, and Jesse Davis. Machine learning with a reject option: A survey. arXiv preprint arXiv:2107.11277, 2021.   \nMark Herbster and Guy Lever. Predicting the labelling of a graph via minimum $p$ -seminorm interpolation. In Proc. COLT, 2009.   \nMark Herbster, Stephen Pasteris, Fabio Vitale, and Massimiliano Pontil. A gang of adversarial bandits. In Proc. NeurIPS, pages 2265\u20132279, 2021.   \nPaul W Holland, Kathryn Blackmond Laskey, and Samuel Leinhardt. Stochastic blockmodels: First steps. Soc. Netw., 5(2):109\u2013137, 1983.   \nTommaso Lanciano, Atsushi Miyauchi, Adriano Fazzone, and Francesco Bonchi. A survey on the densest subgraph problem and its variants. ACM Comput. Surv., 56(8):1\u201340, 2024.   \nTor Lattimore and Csaba Szepesva\u00b4ri. Bandit Algorithms. Cambridge University Press, 2020.   \nJure Leskovec and Andrej Krevl. SNAP Datasets: Stanford large network dataset collection. http: //snap.stanford.edu/data, June 2014.   \nHaipeng Luo and Robert E Schapire. Achieving all with no parameters: Adanormalhedge. In Proc. COLT, pages 1286\u20131304, 2015.   \nGergely Neu and Nikita Zhivotovskiy. Fast rates for online prediction with abstention. In Proc. COLT, pages 3030\u20133048, 2020.   \nMark E.J. Newman and Michelle Girvan. Finding and evaluating community structure in networks. Phys. Rev. E, 69(2):026113, 2004.   \nStephen Pasteris, Madeleine Dwyer, Chris Hicks, and Vasilios Mavroudis. A hierarchical nearest neighbour approach to contextual bandits. arXiv preprint arXiv:2312.09332, 2023a.   \nStephen Pasteris, Chris Hicks, and Vasilios Mavroudis. Nearest neighbour with bandit feedback. In Proc. NeurIPS, 2023b.   \nIgnacio M. Pelayo. Geodesic Convexity in Graphs. Springer, 2013.   \nShota Saito and Mark Herbster. Multi-class graph clustering via approximated effective $p$ -resistance. In Proc. ICML, pages 29697\u201329733, 2023.   \nNicolas Schreuder and Evgenii Chzhen. Classification with abstention but without disparities. In Proc. UAI, pages 1227\u20131236, 2021.   \nYevgeny Seldin and G\u00b4abor Lugosi. A lower bound for multi-armed bandits with expert advice. In Proc. EWRL, volume 2, page 7, 2016.   \nPrithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. Collective classification in network data. AI Mag., 29(3):93\u201393, 2008.   \nAleksandrs Slivkins. Contextual bandits with similarity information. In Proc. COLT, pages 679\u2013702, 2011.   \nMaximilian Thiessen and Thomas Ga\u00a8rtner. Active learning of convex halfspaces on graphs. In Proc. NeurIPS, 2021.   \nVincent A Traag. Faster unfolding of communities: Speeding up the louvain algorithm. Phys. Rev. E, 92(3):032801, 2015.   \nMarcel LJ van De Vel. Theory of Convex Structures. Elsevier, 1993. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "A CBA analysis ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "Here we prove Theorem 3.1 from the modification of mirror descent (and the specific construction of $\\pmb{g}_{t}$ ) given in Section 4. Whenever we take expectations in this analysis they are over the draw of $a_{t}$ from $\\pmb{s}_{t}$ for some $t\\in[T]$ . As for mirror descent, our analysis hinges on the following classic lemma: ", "page_idx": 11}, {"type": "text", "text": "Lemma A.1. Given any convex set ${\\mathcal{C}}\\subseteq\\mathbb{R}_{+}^{E}$ , any convex function $\\xi:\\mathbb{R}_{+}^{E}\\rightarrow\\mathbb{R}$ , any $\\pmb q\\in\\mathcal{C}$ and any $z\\in\\mathbb{R}_{+}^{E}$ with: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\boldsymbol{q}=\\operatorname*{argmin}_{\\boldsymbol{v}\\in\\mathcal{C}}\\!\\left(\\xi(\\boldsymbol{v})+\\Delta(\\boldsymbol{v},z)\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "then for all $\\pmb{u}\\in\\mathcal{C}$ we have: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\xi({\\pmb u})+\\Delta({\\pmb u},z)\\geq\\xi({\\pmb q})+\\Delta({\\pmb u},{\\pmb q})\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "oPurro ocfa.s eT $\\Delta$ iosr einmd e9e.1d 2a  inB rBegecmka [n2 d0i1v7e]r gsehnocew:s t thhaat t otfh teh teh ceoornevemx  hfoulndcst iiof $\\Delta$ $f:\\mathbb{R}_{+}^{E}\\overset{\\bullet}{\\rightarrow}\\mathbb{R}$ fdoirv earllg $\\pmb{v}\\in\\mathbb{R}_{+}^{E}$ ", "page_idx": 11}, {"type": "equation", "text": "$$\nf(\\pmb{v}):=\\sum_{i\\in[E]}v_{i}\\ln(v_{i}),\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "which concludes the proof. ", "page_idx": 11}, {"type": "text", "text": "Proof of Theorem 3.1. Choose any $\\pmb{u}\\in\\mathcal{V}$ and $t\\in[T]$ . We immediately have $\\mathcal{V}\\subseteq\\mathcal{V}_{t}$ by definition, and therefore $\\pmb{u}\\in\\mathcal{V}_{t}$ . Hence, by setting $\\xi$ such that $\\dot{\\boldsymbol{\\xi}}(\\boldsymbol{v}):=0$ for all $\\pmb{v}\\in\\mathbb{R}_{+}^{E}$ , setting $\\mathcal{C}\\in\\mathcal{V}_{t}$ and setting $\\boldsymbol{z}=\\boldsymbol{w}_{t}$ in Lemma A.1 we have ${\\boldsymbol{q}}=\\tilde{{\\boldsymbol{w}}}_{t}$ so that: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\Delta({\\pmb u},{\\pmb w}_{t})\\geq\\Delta({\\pmb u},\\tilde{{\\pmb w}}_{t})\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Alternatively, by setting $\\xi$ such that $\\xi(\\pmb{v}):=\\eta\\pmb{g}_{t}\\cdot(\\tilde{\\pmb{w}}_{t}-\\pmb{v})$ for all $\\pmb{v}\\in\\mathbb{R}_{+}^{E}$ E. , setting ${\\mathcal{C}}=\\mathbb{R}_{+}^{E}$ and setting $\\pmb{z}=\\tilde{\\pmb{w}}_{t}$ in Lemma A.1 we have $\\pmb{q}=\\pmb{w}_{t+1}$ so that: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\eta g_{t}\\cdot(\\tilde{\\boldsymbol{w}}_{t}-\\boldsymbol{u})+\\Delta(\\boldsymbol{u},\\tilde{\\boldsymbol{w}}_{t})\\geq\\eta g_{t}\\cdot(\\tilde{\\boldsymbol{w}}_{t}-\\boldsymbol{w}_{t+1})+\\Delta(\\boldsymbol{u},\\boldsymbol{w}_{t+1})\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Since $\\mathbb{E}[\\pmb{g}_{t}]=\\nabla\\rho_{t}(\\tilde{\\pmb{w}}_{t})$ and $\\rho_{t}$ is linear we have: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\pmb{g}_{t}\\cdot(\\pmb{\\tilde{w}}_{t}-\\pmb{u})]=\\rho_{t}(\\pmb{\\tilde{w}}_{t})-\\rho_{t}(\\pmb{u})\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "In what follows we use the fact that for all $x\\leq1$ we have: ", "page_idx": 11}, {"type": "equation", "text": "$$\nx(1-\\exp(x))\\geq-2x^{2}\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "For all $i\\in[E]$ , we have, by definition, that $g_{t,i}=e_{t}^{i}\\cdot\\hat{\\pmb{r}}_{t}$ so by Equation (2) we have: ", "page_idx": 11}, {"type": "equation", "text": "$$\ng_{t}\\cdot\\big(\\tilde{\\pmb{w}}_{t}-\\pmb{w}_{t+1}\\big)=\\sum_{i\\in[E]}\\tilde{w}_{t,i}\\pmb{e}_{t}^{i}\\cdot\\hat{\\pmb{r}}_{t}\\big(1-\\exp(\\eta\\pmb{e}_{t}^{i}\\cdot\\hat{\\pmb{r}}_{t})\\big)\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Since, for all $a\\in[K]$ , we have $\\hat{r}_{t,a}\\leq1$ and hence, as $\\eta<1$ and, for all $i\\in[E]$ we have $\\|e_{t}^{i}\\|_{1}\\leq1$ , we can invoke Equation (6), which gives us: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\eta\\pmb{g}_{t}\\cdot(\\tilde{\\pmb{w}}_{t}-\\pmb{w}_{t+1})\\geq-2\\sum_{i\\in[E]}\\tilde{w}_{t,i}(\\eta\\pmb{e}_{t}^{i}\\cdot\\hat{\\pmb{r}}_{t})^{2}\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "By definition of $\\hat{\\pmb{r}}_{t}$ we have, for all $i\\in[E]$ , that: ", "page_idx": 11}, {"type": "equation", "text": "$$\ne_{t}^{i}\\cdot\\hat{r}_{t}=\\Vert e_{t}^{i}\\Vert_{1}+e_{t,a_{t}}^{i}(1-r_{t,a_{t}})/s_{t,a_{t}}\\leq c_{t,i}+2e_{t,a_{t}}^{i}/s_{t,a_{t}}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "so that since, for all $a\\in[K]$ , we have $\\operatorname*{Pr}[a_{t}=a]=s_{t,a}$ we also have: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\mathbb{E}[(e_{t}^{i}\\cdot\\hat{r}_{t})^{2}]\\leq c_{t,i}^{2}+\\sum_{a\\in[K]}\\left(2e_{t,a}^{i}c_{t,i}+4(e_{t,a}^{i})^{2}/s_{t,a}\\right).\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Since, for all $i\\in[E]$ and $a\\in[K]$ , we have $e_{t,a}^{i}\\leq1$ and $c_{t,i}\\leq1$ and hence also $c_{t,i}^{2}\\leq c_{t,i}$ we then have: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\mathbb{E}[(e_{t}^{i}\\cdot\\hat{\\boldsymbol{r}}_{t})^{2}]\\le(2K+1)c_{t,i}+4\\sum_{a\\in[K]}e_{t,a}^{i}/s_{t,a}\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Note that since $\\tilde{\\pmb{w}}_{t}\\in\\mathcal{V}_{t}$ we have: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sum_{i\\in[E]}\\tilde{w}_{t,i}c_{t,i}\\leq1\\,.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Also, by definition of $\\scriptstyle s_{t}$ we have: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sum_{i\\in[E]}\\tilde{w}_{t,i}\\sum_{a\\in[K]}e_{t,a}^{i}/s_{t,a}=\\sum_{a\\in[K]}\\frac{1}{s_{t,a}}\\sum_{i\\in[E]}\\tilde{w}_{t,i}e_{t,a}^{i}=\\sum_{a\\in[K]}\\frac{1}{s_{t,a}}s_{t,a}=K\\,.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Multiplying Inequality (9) by $\\tilde{w}_{t,i}$ , summing over all $i\\in[E]$ , and then substituting in Inequality (10) and Equation (11) gives us: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sum_{i\\in[E]}\\tilde{w}_{t,i}\\mathbb{E}[(e_{t}^{i}\\cdot\\hat{r}_{t})^{2}]\\leq(2K+1)+4K=6K+1\\,.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Taking expectations on Inequality (7) and substituting in Inequality (12) (after taking expectations) gives us: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\eta\\pmb{g}_{t}\\cdot\\left(\\tilde{\\pmb{w}}_{t}-\\pmb{w}_{t+1}\\right)]\\ge-\\eta^{2}(12K+2)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Taking expectations (over the draw $a_{t}\\sim s_{t})$ ) on Inequality (4), substituting in Inequalities (3), (5) and (13), and then rearranging gives us: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\Delta(\\pmb{u},\\pmb{w}_{t})-\\mathbb{E}[\\Delta(\\pmb{u},\\pmb{w}_{t+1})]\\ge\\eta(\\rho_{t}(\\pmb{u})-\\rho_{t}(\\tilde{\\pmb{w}}_{t}))-\\eta^{2}(12K+2)\\,.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Summing this inequality over all $t\\in[T]$ , taking expectations (over the entire sequence of action draws) and noting that $\\Delta(u,w_{T+1})>0$ gives us: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\Delta(\\pmb{u},\\pmb{w}_{1})\\geq\\eta\\sum_{t\\in[T]}\\mathbb{E}[\\rho_{t}(\\pmb{u})-\\rho_{t}(\\pmb{\\tilde{w}}_{t})]-\\eta^{2}(12K+2)T\\,.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Substituting in Equation (1) and rearranging then gives us, by definition of $\\rho$ and $\\rho_{t}$ , the required goal: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sum_{t\\in[T]}\\mathbb{E}[r_{t,a_{t}}]\\geq\\mathbb{E}[\\rho(\\pmb{u})]-\\Delta(\\pmb{u},\\pmb{w}_{1})/\\eta-\\eta(12K+2)T\\,.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "A.1 Unbounded precision case ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "We will now show how to handle the case in which our numerical precision is unbounded, incurring a time complexity equal, up to a factor logarithmic in $T$ , to that of Exp4 and adding only 1 to the regret. This additive factor, however, can be made arbitrarily small. ", "page_idx": 12}, {"type": "text", "text": "Let us restrict ourselves to compare against $\\textbf{\\em u}$ with $\\|u\\|_{\\infty}\\leq Z$ for some arbitrary $Z$ . Note that this always has to be the case when each expert has a confidence of at least $1/Z$ on some trial. Our time complexity will be logarithmic in $Z$ . At the beginning of trial $t$ we will now project (via the unnormalised relative entropy) $\\pmb{w}_{t}$ into the set $\\{\\pmb{v}\\in\\mathbf{\\bar{R}}^{E}\\mid\\|\\pmb{\\bar{v}}\\|_{\\infty}\\leq Z\\}$ which simply requires clipping its components. Since the set $\\{\\pmb{v}\\in\\mathbb{R}^{E}\\mid\\|\\pmb{v}\\|_{\\infty}\\leq Z\\}$ is convex and contains our comparator $\\textbf{\\em u}$ this will not affect our regret bound. ", "page_idx": 12}, {"type": "text", "text": "For any $q\\in\\mathbb{R}$ let $\\backslash\\!\\left.\\lambda_{t}(q)\\right.$ be the set of all $\\pmb{v}$ with $\\pmb{v}\\cdot\\pmb{c}_{t}\\leq q$ . We note that given, for all $t\\in[T]$ , a value $q_{t}\\in[1-1/T,1]$ we have that there exists $\\hat{\\pmb u}\\in\\bigcap_{t}\\mathcal{V}_{t}(q_{t})$ such that the cumulative reward of $\\pi(\\hat{\\boldsymbol{u}})$ is no less than that of $\\pi(u)$ minus 1. This means that, on any trial $t$ we can, instead of projecting into the set $\\mathcal{V}_{t}$ , project into the set $\\mathcal{V}_{t}(q_{t})$ for some $q_{t}\\in[1-\\dot{1}/T,1]$ and add no more than one to the regret (by considering $\\hat{\\pmb u}$ as the comparator instead of $\\textbf{\\em u}$ ). ", "page_idx": 12}, {"type": "text", "text": "So the problem (for the projection step at time $t$ if necessary) is now to project into the set of all $\\{v\\,|\\,v\\cdot\\bar{c}\\leq q_{t}\\}$ for some arbitrary $q_{t}\\,\\stackrel{-}{\\in}\\,[1-1/T,1]$ . Following our use of Lagrange multipliers, this means that we need to find $\\lambda>0$ with $\\begin{array}{r}{\\sum_{i}\\dot{c}_{t,i}w_{t,i}\\exp(-\\lambda c_{t,i})\\in[1-1/T,\\bar{1}]}\\end{array}$ . So consider the function $f$ defined by $\\begin{array}{r}{f(\\lambda^{\\prime}):=\\sum_{i}c_{t,i}w_{t,i}\\,\\overline{{\\exp}}(-\\lambda^{\\prime}c_{t,i})}\\end{array}$ . ", "page_idx": 12}, {"type": "text", "text": "Consider $\\lambda^{\\prime}\\ :=\\ Z E\\ln(Z E)$ and take any $\\textit{i}\\in\\ [E]$ . Since $w_{t,i}~\\leq~Z$ we have that when $c_{t,i}~<~1/Z E$ then $c_{t,i}w_{t,i}\\exp(-\\lambda^{\\prime}c_{t,i})\\ \\leq\\ c_{t,i}w_{t,i}\\stackrel{.}{<}\\ 1/E$ and that when $c_{t,i}~\\geq~1/Z E$ then $c_{t,i}w_{t,i}\\exp(-\\lambda^{\\prime}c_{t,i})\\leq Z\\exp(-\\lambda^{\\prime}/Z E)=1/E$ . This implies that $f(\\lambda^{\\prime})\\leq1$ and hence (since $f$ is monotonic decreasing) an acceptable $\\lambda$ lies in $[0,Z E\\ln(\\bar{Z}E)]$ . ", "page_idx": 12}, {"type": "table", "img_path": "l04i6dPMxK/tmp/b6bf8f3bc153a76d059b7282c57bfdf20abcb2cd3a4d3ae8b3245b2edbb52573.jpg", "table_caption": [], "table_footnote": [], "page_idx": 13}, {"type": "text", "text": "For general $\\lambda^{\\prime}$ we note that $\\begin{array}{r}{\\nabla f(\\lambda^{\\prime})\\,=\\,-\\sum_{i}c_{t,i}^{2}w_{t,i}\\exp(-\\lambda^{\\prime}c_{t,i})\\,\\geq\\,-f(\\lambda^{\\prime})}\\end{array}$ . This means that $|\\nabla f(\\lambda)|\\leq1$ . Since the length of the interval $[1-1/T,1]$ is $1/T$ this means that the length of the interval containing acceptable values of $\\lambda$ is at least $1/T$ . ", "page_idx": 13}, {"type": "text", "text": "So we have shown that either $\\lambda=Z E\\ln(Z E)$ is acceptable or the range of acceptable values of $\\lambda$ is of length $1/T$ and lies in $[0,Z E\\ln(Z E)]$ (which has length $Z E\\ln(Z E))$ . The ratio of these lengths is $Z E T\\ln(Z E)$ so interval bisection will find an acceptable value of $\\lambda$ in $O(\\ln(Z E T\\ln(Z E)))=$ $O(\\ln(E Z T))$ steps. ", "page_idx": 13}, {"type": "text", "text": "So we have a time complexity $O(E K+E\\ln(E Z T))$ and we have only added 1 to the regret (although this additive factor can be made arbitrarily small). ", "page_idx": 13}, {"type": "text", "text": "B Efficient implementation proof ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We here prove the time complexity of Theorem 5.3. The per-trial time complexity of a direct implementation of CBA for this set of experts would be $\\mathcal{O}(K\\bar{N}^{2})$ . We now show how to implement CBA in a per-trial time of only $\\mathcal{O}(K N\\ln(N))$ . To do this first note that we can assume, without loss of generality, that for all $q,x,z\\in\\mathcal{X}$ with $x\\neq z$ we have $d(q,x)\\neq d(q,z)$ since ties can be broken arbitrarily and balls can be duplicated. ", "page_idx": 13}, {"type": "text", "text": "Given $x,z\\in\\mathcal{X}$ , $a\\in[K]$ and $t\\in[T]$ we let $y_{t,a}(x,z):=w_{t,i}$ and $\\tilde{y}_{t,a}(x,z):=\\tilde{w}_{t,i}$ where $i$ is the index of the expert corresponding to the ball-action pair with ball: $\\{q\\in\\mathcal{X}\\,|\\,d(x,q)\\leq d(x,z)\\}$ , and action $a$ . Given $x,z\\in\\mathcal{X}$ let $\\mathcal{E}(x,z):=\\{q\\in\\mathcal{X}\\,|\\,d(x,q)\\geq d(x,z)\\}$ . It is straightforward to derive the following equations for the quantities in CBA at trial $t\\in[T]$ . First we have: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\|c_{t}\\|_{1}=\\sum_{a\\in[K]}\\sum_{x\\in\\mathcal{X}}\\sum_{z\\in\\mathcal{E}(x,x_{t})}y_{t,a}(x,z)\\,.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "For all $x,z\\in\\mathcal{X}$ and $a\\in[K]$ we have the following: ", "page_idx": 13}, {"type": "text", "text": "For all $a\\in[K]$ we have: ", "page_idx": 13}, {"type": "equation", "text": "$$\ns_{t,a}=\\sum_{x\\in\\mathcal{X}}\\sum_{z\\in\\mathcal{E}(x,x_{t})}\\tilde{y}_{t,a}(x,z)\\,.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Finally, for all $x,z\\in\\mathcal{X}$ and $a\\in[K]$ we have the following: ", "page_idx": 13}, {"type": "equation", "text": "$$\ny_{(t+1),a}(x,z)=\\left\\{\\!\\!\\begin{array}{l l}{\\tilde{y}_{t,a}(x,z)}&{\\mathrm{if~}z\\notin\\mathcal{E}(x,x_{t})\\,,}\\\\ {\\tilde{y}_{t,a}(x,z)\\exp(\\eta e_{t}^{i}\\cdot\\hat{r}_{t})}&{\\mathrm{if~}z\\in\\mathcal{E}(x,x_{t})\\,.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Hence, to implement CBA we need, for each $x\\in\\mathscr{X}$ and $a\\in[K]$ , a data structure that implicitly maintains a function $h:\\mathcal{X}\\to\\mathbb{R}^{+}$ and has the following two subroutines, that take parameters $q\\in\\mathcal{X}$ and $p\\in\\mathbb{R}_{+}$ . ", "page_idx": 13}, {"type": "text", "text": "1. QUERY $(q)$ : Compute $\\textstyle\\sum_{z\\in{\\mathcal{E}}(x,q)}h(z)$ .   \n2. UPDATE $(q,p)$ : Set $h(z)\\leftarrow p h(z)$ for all $z\\in\\mathcal{E}(x,q)$ . ", "page_idx": 13}, {"type": "text", "text": "Now fix $x\\in\\mathscr{X}$ and $a\\in[K]$ . Let $h$ be as above. On each trial $t\\in[T]$ and for all $z\\in\\mathcal{X}\\,,h(z)$ will start equal to $y_{t,a}(x,z)$ and change to $\\tilde{y}_{t,a}(x,z)$ and then $y_{(t+1),a}(x,z)$ by applying the UPDATE subroutine. ", "page_idx": 13}, {"type": "text", "text": "1. For all $i\\in[n]\\cup\\{0\\}$ let $\\gamma_{i}$ be the ancestor of $q$ at depth $i$ in $\\mathcal{D}$   \n2. Descend $\\mathcal{D}$ from $\\gamma_{0}$ to $\\gamma_{n-1}$ . When at $\\gamma_{i}$ set: (a) $\\phi(\\triangle(\\gamma_{i}))\\leftarrow\\phi(\\gamma_{i})\\phi(\\triangleleft(\\gamma_{i}))$ (b) $\\phi(\\triangleright(\\gamma_{i}))\\leftarrow\\phi(\\gamma_{i})\\phi(\\triangleright(\\gamma_{i}))$ (c) $\\phi(\\gamma_{i})\\leftarrow1$   \n3. For all $i\\in[n-1]\\cup\\{0\\}$ , if $\\gamma_{i+1}=\\mathcal{1}(\\gamma_{i})$ then set $\\phi(\\triangleright(\\gamma_{i}))\\leftarrow p\\phi(\\triangleright(\\gamma_{i}))$   \n4. Set $\\phi(\\gamma_{n})\\leftarrow p\\phi(\\gamma_{n})$   \n5. Climb $\\mathcal{D}$ from $\\gamma_{n-1}$ to $\\gamma_{0}$ . When at $\\gamma_{i}$ set: $\\psi(\\gamma_{i})\\gets\\psi(\\mathsf{1}(\\gamma_{i}))\\phi(\\mathsf{1}(\\gamma_{i}))+\\psi(\\mathsf{5}(\\gamma_{i}))\\phi(\\mathsf{5}(\\gamma_{i}))$ ", "page_idx": 14}, {"type": "text", "text": "We now show how to implement these subroutines implicitly in a time of $\\mathcal{O}(\\ln(N))$ as required. Without loss of generality, assume that $N=2^{n}$ for some $n\\in\\mathbb N$ . Our data structure is based on a balanced binary tree $\\mathcal{D}$ whose leaves are the elements of $\\mathcal{X}$ in order of increasing distance from $x$ . This implies that for any $z\\in\\mathcal{X}$ we have that $\\mathcal{E}(x,z)$ is the set of leaves that do not lie on the left of $z$ . Given a node $v\\in\\mathcal{D}$ we let $\\Uparrow(v)$ be the set of ancestors of $v$ and let $\\Downarrow(v)$ be the set of all $z\\in\\mathcal{X}$ which are descendants of $v$ . For any internal node $v$ let $\\triangleleft(v\\right)$ and $\\mathsf{\\Delta}\\mathsf{\\Sigma}^{\\mathsf{D}}(v)$ be the left and right children of $v$ respectively. ", "page_idx": 14}, {"type": "text", "text": "We maintain functions $\\phi,\\psi:{\\mathcal{D}}\\rightarrow\\mathbb{R}_{+}$ such that for all $v\\in\\mathcal{D}$ we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\psi(v)\\prod_{v^{\\prime}\\in\\uparrow\\uparrow(v)}\\phi(v^{\\prime})=\\sum_{z\\in\\Downarrow(v)}h(z)\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The pseudo-code for the subroutines QUERY and UPDATE are given in Algorithms 2 and 3 respectively. We now prove their correctness. We first consider the QUERY subroutine with parameter $q\\in\\mathcal{X}$ . From Equation (14) we see that, by (reverse) induction on $i\\in[n]\\cup\\{0\\}$ , we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\sigma_{i}\\prod_{v^{\\prime}\\in\\uparrow\\uparrow(\\gamma_{i})\\setminus\\{\\gamma_{i}\\}}\\phi(v^{\\prime})=\\sum_{z\\in\\Downarrow(\\gamma_{i})\\cap\\mathcal{E}(x,q)}h(z)\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Since $\\gamma_{0}$ is the root of $\\mathcal{D}$ , we have $\\textstyle\\sigma_{0}=\\sum_{z\\in\\mathcal{E}(x,q)}h(z)$ as required. Now consider the UPDATE subroutine with parameters $q\\in\\mathcal{X}$ and $p\\in\\mathbb{R}_{+}$ . Let $h$ be the implicitly maintained function before the subroutine is called. For Equation (14) to hold after the subroutine is called we need: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\psi(v)\\prod_{v^{\\prime}\\in\\uparrow\\uparrow(v)}\\phi(v^{\\prime})=\\sum_{z\\in\\downarrow(v)}h^{\\prime}(z)\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where for all $z\\in\\mathcal{X}$ we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\nh^{\\prime}(z):=\\|z\\notin\\mathcal{E}(x,q)\\|h(z)+\\|z\\in\\mathcal{E}(x,q)\\|p h(z)\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We shall now show that Equation (15) does indeed hold after the subroutine is called, which will complete the proof. To show this we consider each step of the subroutine in turn. After Step 2 we have (via induction) that: ", "page_idx": 14}, {"type": "text", "text": "\u2022 For all $v\\in\\Uparrow(q)$ we have $\\phi(v)=1$ . ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\psi(v)\\prod_{v^{\\prime}\\in\\uparrow\\uparrow(v)}\\phi(v^{\\prime})=\\sum_{z\\in\\Downarrow(v)}h(z)\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "So, since $\\mathcal{E}(x,q)$ is the set of all $z\\in\\mathcal{X}$ that do not lie to the left of $q$ in $\\mathcal{D}$ we have that, after Step 4 of the algorithm, the following holds: ", "page_idx": 14}, {"type": "text", "text": "\u2022 For all $v\\in\\Uparrow(q)$ we have $\\phi(v)=1$ , \u2022 For all $v\\in{\\mathcal{D}}\\setminus\\Uparrow(q)$ we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\psi(v)\\prod_{v^{\\prime}\\in\\upuparrow(v)}\\phi(v^{\\prime})=\\sum_{z\\in\\updownarrow(v)}h^{\\prime}(z)\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Hence, by induction, we have that, after Step 5 of the algorithm, it is the case that for all $v\\in\\Uparrow(q)$ we have: $\\begin{array}{r}{\\psi(\\bar{v})=\\sum_{z\\in\\Downarrow(v)}h^{\\prime}(z)}\\end{array}$ . So since $\\phi(\\bar{v})=1$ for all $v\\in\\textstyle\\uparrow(q)$ and Step 5 does not alter $\\phi(v)$ or $\\psi(v)$ for any $v\\in{\\mathcal{D}}\\setminus\\Uparrow(q)$ we have Equation (15). \u25a0 ", "page_idx": 14}, {"type": "text", "text": "C Lower bound proof ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Proposition C.1. Take any learning algorithm. Given any basis $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ and any $M\\in\\mathbb{N}$ then for any sequence of disjoint basis elements $\\langle B_{j}\\,|\\,j\\in[M]\\rangle$ there exists a sequence of corresponding actions $\\bar{\\langle b_{j}^{\\bar{\\mathbf{\\alpha}}}\\in[K]\\,\\dot{|\\,j}\\in[M]\\rangle}$ such that an adversary can force: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{t\\in[T]}\\sum_{j\\in[M]}\\mathbb{I}x_{t}\\in\\mathcal{B}_{j}\\mathbb{J}|r_{t,b_{j}}-\\sum_{t\\in[T]}\\mathbb{E}[r_{t,a_{t}}]\\in\\Omega(\\sqrt{M K T})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. In this scenario, at each time step, either a single expert (i.e., the basis element containing the current context $x_{t}$ ) is active, making predictions based on its label, or no expert is active, prompting the learner to abstain and thus incur zero reward or cost. ", "page_idx": 15}, {"type": "text", "text": "Therefore we define $\\begin{array}{r}{T^{\\prime}=\\{t\\in[T]\\,|\\,\\sum_{j\\in[M]}[\\![x_{t}\\in B_{j}]\\!]=1\\}}\\end{array}$ as the set of timesteps in which the learner is going to play. Since the concept of abstention is that our algorithm is not going to pay anything for the timesteps in which we abstain, we can see that: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{t\\in[T]}\\sum_{j\\in[M]}\\mathbb{I}\\!x_{t}\\in\\mathcal{B}_{j}\\mathbb{J}\\!\\!\\Vert r_{t,b_{j}}-\\sum_{t\\in[T]}\\mathbb{E}[r_{t,a_{t}}]=\\sum_{t\\in T^{\\prime}}r_{t,b_{j}}-\\sum_{t\\in T^{\\prime}}\\mathbb{E}[r_{t,a_{t}}]\\,,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "For any ball $j~\\in~[M]$ , we define $T_{j}\\;=\\;\\{t\\;\\in\\;[T^{\\prime}]\\;|\\;[x_{t}\\;\\in\\;{\\cal B}_{j}]\\}$ . Following the ideas of Seldin and Lugosi [2016], for any of the sets $T_{j}$ we can cre  ate a mult i-armed bandit instance as the one described in the lower bound by Auer et al. [2002]. Note that in the lower bound construction, the abstention arm would be a forehand known suboptimal arm, which results in a lower bound of the order $c\\sqrt{(K-1)T}$ , for the constant $\\begin{array}{r}{c=\\frac{\\sqrt{2}-1}{\\sqrt{32\\ln(4/3)}}>0}\\end{array}$ . Since the presented context $x_{t}$ is chosen adversarially at each time step, we can ensure that each basis element is activated for $|T^{\\prime}|/M$ time steps, obtaining: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{j\\in[M]}\\left(\\displaystyle\\sum_{s\\in T_{j}^{\\prime}}r_{s,b_{j}}-\\displaystyle\\sum_{s\\in T_{j}^{\\prime}}\\mathbb{E}[r_{s,a_{s}}]\\right)\\ge\\displaystyle\\sum_{j\\in[M]}c\\sqrt{(K-1)|T_{j}^{\\prime}|}}&{}\\\\ {=\\displaystyle\\sum_{j\\in[M]}c\\sqrt{(K-1)|T^{\\prime}|/M}}&{}\\\\ &{=c\\sqrt{M(K-1)|T^{\\prime}|}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "As \u221awe can choose $\\left|T^{\\prime}\\right|$ to be any fraction of $\\mathrm{T}$ , we end up with the desired lower bound of the order $\\Omega({\\sqrt{M K T}})$ , which matches, up to logarithmic factors, the cumulative reward bound presented in Theorem 5.3. \u53e3 ", "page_idx": 15}, {"type": "text", "text": "D Overlapping balls extension ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we present the theorem that allows us to present the results of overlapping balls as expressed in Section 5.2. Note that Theorem 5.3 is the special case of Theorem D.1 when the balls are disjoint and $u_{j}=1$ for all $j\\in[M]$ . ", "page_idx": 15}, {"type": "text", "text": "Theorem D.1. Let $M\\in\\mathbb{N}$ and $\\{(B_{j},b_{j},u_{j})\\,|\\,j\\,\\in\\,[M]\\}$ be any sequence such that $B_{j}$ is a ball, $b_{j}\\in[K]$ is an action, and $u_{j}\\in[0,1]$ is such that for all $x\\in\\mathscr{X}$ we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{j\\in[M]}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\mathbb{[x\\in B_{j}]\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\leq1\\,\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "For all $t\\in[T]$ define: ", "page_idx": 15}, {"type": "equation", "text": "$$\nr_{t}^{*}:=\\sum_{j\\in[M]}\\ensuremath{[\\![x_{t}\\in B_{j}]\\!]}u_{j}r_{t,b_{j}}\\;,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "which represents the reward of the policy induced by $\\{(B_{j},b_{j},u_{j})\\,|\\,j\\in[M]\\}$ on trial $t$ . The regret of CBA, with the set of experts given in Section 5.2 and with correctly tuned parameters, is then bounded by: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{t\\in[T]}r_{t}^{*}-\\sum_{t\\in[T]}\\mathbb{E}[r_{t,a_{t}}]\\in\\mathcal{O}\\left(\\sqrt{\\ln(K N)K T\\sum_{j\\in[M]}u_{j}}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Its per-trial time complexity is: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathcal{O}(K N\\ln(N))\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. Direct from Theorem 3.1 using the experts (with efficient implementation) given in Section 5.2 ", "page_idx": 16}, {"type": "text", "text": "E The details of the graph bases ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "This section expands the definition and explanations for the bases we used in the Experiment. Remember that we refer to any set of experts that correspond to set-action pairs of the form $(B,k)\\in$ $2^{\\mathcal{X}}\\times[K]$ as a basis elements, and a set of basis elements as basis. ", "page_idx": 16}, {"type": "text", "text": "E.1 $p$ -seminorm balls on graphs ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "As we see in Sec. 5.2, the CBA seems to work only for vector data. However, in the following sections, we explore how our CBA algorithm can be applied to graph data by creating a ball structure over the graph. ", "page_idx": 16}, {"type": "text", "text": "We first introduce the notations of a graph. A graph is a pair of nodes $V:=[N]$ and edges $E$ . An edge connects two nodes, and we assume that our graph is undirected and weighted. For each edge $\\{i,j\\}\\in E$ , we denote its weight by $c_{i j}$ . For convenience, for each pair of nodes $i,j$ with $\\{i,j\\}\\not\\in E$ , we define $c_{i j}=0$ . ", "page_idx": 16}, {"type": "text", "text": "To form a ball over a graph, a family of metrics we are particularly interested in is given by $p$ -norms on a given graph $G$ . Let ", "page_idx": 16}, {"type": "equation", "text": "$$\nd_{p}(i,j):=\\left(\\operatorname*{min}_{u\\in\\mathbb{R}^{N}}\\sum_{s,t\\in V}c_{s t}|u_{s}-u_{t}|^{p}\\right)^{-1/p}\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which is a well-defined metric for $p\\in[1,\\infty)$ if the graph is connected and may be defined for $p=\\infty$ by taking the appropriate limits. When $p=2$ this is the square root of the effective resistance circuit between nodes $i$ and $j$ which comes from interpreting the graph as an electric circuit where the edges are unit resistors and the denominator of Equation (16) is the power required to maintain a unit voltage difference between $u$ and $v$ [Doyle and Snell, 1984]. More generally, $d_{p}(i,j)^{p}$ is known as $p$ -(effective) resistance [Herbster and Lever, 2009, Alamgir and von Luxburg, 2011, Saito and Herbster, 2023]. When $p\\in\\{1,2,\\infty\\}$ there are natural interpretation of the $p$ -resistance. In the case of $p=1$ , we have that the effective is equal to one over the number of edge-disjoint paths between $i$ and $j$ which is equivalently one over the minimal cut that separates $i$ from $j$ . When $p=2$ it is the effective resistance as discussed above. And finally when $p=\\infty$ we have that $d_{\\infty}$ is the geodesic distance (shortest path) between $i$ and $j$ . Note that, interestingly, there are at most $2N$ distinct balls for $d_{1}$ ; as opposed to the general bound $O(N^{2})$ on the number of metric balls. This follows since $d_{1}$ is an ultrametric. A nice feature of metric balls is that they are ordinal, i.e., we can take an increasing function of the distance and the distinct are unchanged. The time complexity for each ball is as follows. For $d_{1}$ ball, we compute every pair of distance in $\\mathcal{O}(N^{3})$ using the Gomory- $\\mathbf{\\nabla}\\cdot\\mathbf{H}\\mathbf{u}$ tree [Gomory and $\\operatorname{Hu}$ , 1961]. For $d_{2}$ ball, it is actually enough to compute the pseudoinverse of graph Laplacian once, which costs $\\mathcal{O}(N^{3})$ [Doyle and Snell, 1984]. For $d_{\\infty}$ ball, we can compute every pair of distance in $\\mathcal{O}(N^{3})$ by Floyd\u2013Warshall algorithm [Floyd, 1962]. ", "page_idx": 16}, {"type": "text", "text": "E.2 Community detection bases ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section, we consider only bases formed via a set of subsets (a.k.a clusters) $C\\subseteq2^{[N]}$ . Each of these subsets induces $K$ basis elements: one for each action $a\\in[K]$ . Specifically, the basis element $\\beta:[N]\\rightarrow[K_{\\rightleftarrows}]$ corresponding to the pair $(C,a)$ is such that $\\beta(x)$ is equal to $a$ whenever $x\\in C$ and equal to $\\sqsubset$ otherwise. Hence, in this section, we equate a basis with a set of subsets of $[N]$ . ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "We can compute a basis for a given graph $G\\,=\\,(V,E)$ using community detection algorithms. Community detection is one of the most well-studied operations for graphs, where the goal is to find a partition $\\{C_{1},\\ldots,C_{q}\\}$ of $V$ (i.e., $\\textstyle\\bigcup_{i=1}^{q}C_{i}=V$ and $C_{i}\\cap C_{j}=\\emptyset$ for $i\\neq j$ ) so that each $C_{i}$ is densely connected internally but spar sely connected to the rest of the graph [Fortunato, 2010]. There are many community detection algorithms, all of which can be used here, but the most popular algorithm is the Louvain method [Blondel et al., 2008]. We briefly describe how this algorithm works. The algorithm starts with an initial partition $\\{\\{v\\}\\mid v\\in V\\}$ and aggregates the clusters iteratively: For each $v\\in V$ , compute the gain when moving $v$ from its current cluster to its neighbors\u2019 clusters and indeed move it to a cluster with the maximum gain (if the gain is positive). Note that the gain is evaluated using modularity, i.e., the most popular quality function for community detection [Newman and Girvan, 2004]. The algorithm repeats this process until no movement is possible. Then the algorithm aggregates each cluster to a single super node (with appropriate addition of self-loops and change of edge weights) and repeats the above process on the coarse graph as long as the coarse graph is updated. Finally, the algorithm outputs the partition of $V$ in which each cluster corresponds to each super node in the latest coarse graph. Note that it is widely recognized that the Louvain method works in $\\mathcal{O}(N\\log N)$ in practice [Traag, 2015]. ", "page_idx": 17}, {"type": "text", "text": "To obtain a finer-grained basis, we apply the so-called greedy peeling algorithm for each $C_{i}$ in the output of the Louvain method. For $C_{i}\\subseteq V$ and $v\\in C_{i}$ , we denote by $d_{C_{i}}(v)$ the degree of $v$ in the induced subgraph $G[C_{i}]$ . For $G[C_{i}]$ , the greedy peeling iteratively removes a node with the smallest degree in the currently remaining graph and obtains a sequence of node subsets from $C_{i}$ to a singleton. Specifically, it works as follows: Set $j\\leftarrow|C_{i}|$ and Ci(j)\u2190Ci. For each j = |Ci|, . . . , 2, compute $v_{\\operatorname*{min}}\\in\\arg\\operatorname*{min}\\{d_{C_{i}^{(j)}}(v)\\mid v\\in C_{i}^{(j)}\\}$ and $C_{i}^{(j-1)}\\gets C_{i}^{(j)}\\setminus\\{v_{\\mathrm{min}}\\}$ . Using a sophisticated data structure, this algorithm runs in linear time [Lanciano et al., 2024]. ", "page_idx": 17}, {"type": "text", "text": "In summary, our community detection basis is the collection of node subsets $\\{C_{i}^{(j)}\\mid i=1,\\ldots,q,\\,j=$ $1,\\cdot\\cdot\\cdot,|C_{i}|\\}$ together with $\\{\\{v\\}\\mid v\\in V\\}$ for completeness. ", "page_idx": 17}, {"type": "text", "text": "E.3 Graph convexity bases ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "An alternative to metric balls and communities are, for example, (geodesically) convex sets in a graph. They correspond to the inductive bias that if two nodes prefer the same action, then also the nodes on a shortest path between the two tend to prefer the same action. Geodesically convex sets are well-studied [van De Vel, 1993, Pelayo, 2013] and have been recently used in various learning settings on graphs [Bressan et al., 2021, Thiessen and Ga\u00a8rtner, 2021]. Similarly to convex sets in the Euclidean space, a set $C$ of nodes is convex if the nodes of any shortest path with endpoints in $C$ are in $C$ , as well. More formally, the (geodesic) interval $I(u,v)=\\{x\\in V:x$ is on a shortest path between $u$ and $v\\}$ of two nodes $u$ and $v$ contains all the nodes on a shortest path between them. For a set of node $A$ we define $I(A)=\\cup_{a,b\\in A}I(a,b)$ as a shorthand notation for the union of all pairwise intervals in $A$ . A set $A$ is (geodesically) convex iff $I(A)=A$ and the convex hull $\\operatorname{conv}(A)$ of a set $A$ is the (unique) smallest convex set containing $A$ . Note that for $u,v\\in V$ , $I(u,v)$ and $\\mathrm{conv}(\\{u,v\\})$ are typically different sets. Indeed, $I(u,v)$ is in general non-convex, as nodes on a shortest path between two nodes in $I(u,v)$ (except for $u,v)$ are not necessarily contained in $I(u,v)$ . As the total number of convex sets can be exponential in $N$ , e.g., all subsets of a complete subgraph are convex, we consider the basis consisting of all intervals: $I(u,v)$ for $u,v\\in[N]$ . This involves $\\hat{\\mathcal{O}}(N^{2})$ basis elements, each of size $\\mathcal{O}(N)$ . With a simple modification of the Floyd Warshall [Floyd, 1962] algorithm, computing the interval basis takes $\\bar{\\mathcal O}\\bar{(N^{3})}$ time complexity. ", "page_idx": 17}, {"type": "text", "text": "F Additional experimental results ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We thoroughly explored various configurations for the three graphs described in our experimental setup in Section 6. We run our experiments with an Intel Xeon Gold 6312U processor and 256 GB of RAM ECC 3200 MHz. Figure 3 displays different settings for the number of nodes in each clique and noise levels. ", "page_idx": 17}, {"type": "text", "text": "As we compare the computational complexity of each basis in Section E and the main results, the most intense computational load in the experiments will arise from the calculation of the basis, which can be seen as an initialization step in our algorithm. The proposed methods have varying computational complexities, and an arbitrarily complex function can be employed to compute the basis. Remark that, in the usual complexity comparison among online learning algorithms using experts, we compare the complexity given the experts. Practically, we use pre-computed bases or even human experts. Also note that due to the expensive complexity of the $p$ -balls and the convex sets seen in Section E, we only conduct the LVC for LastFM Asia. ", "page_idx": 18}, {"type": "text", "text": "In Figure 4, we present multiple settings for generating the Gaussian graph. Here the title of each plot is \u201cForeground $x,y$ ; Background $x^{\\prime},y^{\\prime}$ ; $k$ -NN,\u201d which is explained as follows: $x$ represents the number of nodes in each foreground class, $x^{\\prime}$ represents the number of nodes in the background class, $y$ represents the standard deviation of the Gaussians generating the foreground class, $y^{\\prime}$ represents the standard deviation of the Gaussian generating the background class, and $k$ represents the number of nearest neighbors used to generate the graph. ", "page_idx": 18}, {"type": "text", "text": "In Figure 5, we present the various labels chosen as noise for the Cora graph. In Figure 2(c), we presented the averages of all these different configurations. Here, we can see that the main behavior of the various bases is roughly maintained independently of the different labels chosen to be masked as background class. ", "page_idx": 18}, {"type": "text", "text": "In Figure 6, we present the various labels chosen as noise for the LastFM Asia graph. This graph comprises nodes representing LastFM users in Asian countries and edges representing mutual follower connections. Vertex features are extracted based on the artists liked by the users. During this initial analysis, we arbitrarily chose three out of eighteen possible labels to serve as the background class. In Figure 2(d), we presented the averages of all these different configurations. Varying the chosen background classes also produces different results, this is indeed due to the inherent lack of noise in the dataset. It is nice to see that regardless of the noise labels chosen, the behavior of our algorithm is always good, showing, as expected, that based on the amount of noise, we can just improve. ", "page_idx": 18}, {"type": "image", "img_path": "l04i6dPMxK/tmp/a55602b65fb94399985eb0ac5882c4f0cac0791dc92d94dfa8ba29c46d1fae06.jpg", "img_caption": [], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "Figure 3: Stochastic Block Model results, dotted lines represent different baselines, while solid lines are used to represent various results. ", "page_idx": 19}, {"type": "image", "img_path": "l04i6dPMxK/tmp/650b126a2f0b99782956902ebbcb8b9f993cb7f8d478a8c5c2efb8605dd65a19.jpg", "img_caption": ["Figure 4: Gaussian graph results, dotted lines represent different baselines, while solid lines are used to represent various results. "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "l04i6dPMxK/tmp/3579bec1fc1233cbb60021ab65a93f0b4f55078d77e4a66c48eaa8e8dd209004.jpg", "img_caption": ["Figure 5: Cora results, dotted lines represent different baselines, while solid lines are used to represent various results "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "l04i6dPMxK/tmp/3ca62b36f38da00a6635d9b72b135ec891253d28d258ad4a412cb5ec92c4b2a0.jpg", "img_caption": ["Figure 6: LastFM Asia results, dotted lines represent different baselines, while solid lines are used to represent various results "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Impact Statement ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Given the theoretical nature of our work, we cannot foresee the shape of positive or negative societal impacts which this work may have in future. ", "page_idx": 23}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: All the claims are supported in the main body. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 23}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The limitations and future work are discussed in the introduction and in the experimental results analysis. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \u201dLimitations\u201d section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 23}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We explicitly write the assumptions of all the theoretical claims. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 24}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We provided the experimental codes. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 24}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We cited the datasets which we use in the experiments. Also, these datasets are publicly available and widely used in the community. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 25}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We provided the details in the main body as well as in the Appendix. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 25}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: We provided error bars and did statistical tests in the main body. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \u201dYes\u201d if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We explicitly write the computing resources we used in the experiments in the Appendix. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 26}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We have read and followed NeurIPS Code of Ethics. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 26}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We provided the dedicated section for this. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 26}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 27}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 27}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: We used the datasets that are widely used in the community. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 28}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 28}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 28}]