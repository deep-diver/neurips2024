[{"figure_path": "zJNSbgl4UA/tables/tables_5_1.jpg", "caption": "Table 1: Comparison with scaling baseline methods AutoFormer [4], US-Net [37] and Separate Training under different width ratios r. The best results are bold-faced.", "description": "This table compares the performance of Scala against three different baseline methods (AutoFormer, US-Net, and Separate Training) for different width ratios (r = 0.25, 0.50, 0.75, 1.00) on the ImageNet-1K dataset.  The metrics shown include accuracy (Acc1) and GFLOPs.  The table highlights Scala's superior performance compared to the baselines, particularly at smaller width ratios, demonstrating its efficiency and effectiveness in achieving high accuracy with fewer parameters.  Separate Training serves as a strong baseline, representing a fully optimized model trained separately for each size.  Autoformer and US-Net are other state-of-the-art width-adjustable models.", "section": "5.1 Experiment Settings"}, {"figure_path": "zJNSbgl4UA/tables/tables_7_1.jpg", "caption": "Table 2: Slimmable ability examination over different architectures on ImageNet-1K under various width ratios. The interpolated results are shown in blue color.", "description": "This table presents the results of evaluating the slimmable ability of different network architectures on the ImageNet-1K dataset.  The architectures tested were ViT (using DeiT-S), CNN-ViT (using Uniformer-S), and CNN (using MobileNetV2).  For each architecture, the top-1 accuracy is reported for various width ratios, demonstrating how well each model performs when scaled down.  The blue colored numbers indicate interpolated results, highlighting the ability of the models to perform well at previously unseen width settings during inference.", "section": "5.3 Comparisons over Extended Training"}, {"figure_path": "zJNSbgl4UA/tables/tables_8_1.jpg", "caption": "Table 3: Comparison with SN-Net [25] over DeiT-B [29] on ImageNet-1K. \u25c7, \u2663 denotes utilizing DeiT-B [29], RegNetY-16GF [27] as the teacher model to facilitate training.", "description": "This table compares the performance of Scala with the state-of-the-art method SN-Net [25] on the ImageNet-1K dataset using DeiT-B [29] as the backbone.  It shows the Top-1 accuracy achieved by both methods across various width ratios (0.25 to 1.00). Two variations of Scala are presented, one using DeiT-B [29] as a teacher model (\u25c7) and another using RegNetY-16GF [27] as a teacher model (\u2663) to facilitate training. The results demonstrate that Scala outperforms SN-Net in most of the width ratios and achieves a comparable performance in other ratios. The table highlights the effectiveness of Scala in achieving comparable or better results than the state-of-the-art method with fewer parameters.", "section": "5.3 Comparisons over Extended Training"}, {"figure_path": "zJNSbgl4UA/tables/tables_8_2.jpg", "caption": "Table 4: Comparison with Separate Training (ST) over DeiT-B [29] on ImageNet-1K under different width ratios r. \u00a7 denotes the expected training epochs of each model.", "description": "This table compares the performance of Scala and Separate Training (ST) on DeiT-B for ImageNet-1K classification.  It shows accuracy (Acc1.) and the number of training epochs (\u00a7) required for different width ratios (r), representing different model sizes.  The comparison highlights Scala's efficiency in achieving comparable or better accuracy with significantly fewer training epochs than ST, especially at smaller model sizes.", "section": "5. Experiments"}, {"figure_path": "zJNSbgl4UA/tables/tables_9_1.jpg", "caption": "Table 5: Evaluation of slimmable representation on dense prediction task Semantic Segmentation over ADE20K [44] dataset. We equipped the pre-trained Uniformer-S [20] from Fig. 7 with Semantic FPN [16] and compare the sub-networks extracted from Scala with Separate Training (ST).", "description": "This table presents the comparison of the performance of slimmable representation on semantic segmentation task using ADE20K dataset. The backbone used is Uniformer-S, which is equipped with Semantic FPN.  The results show mIoU scores for different width ratios (0.25, 0.50, 0.75, 1.00) when using both Separate Training (ST) and Scala. It demonstrates the performance of Scala compared to Separate Training across different scales.", "section": "5.5 Dense Prediction"}, {"figure_path": "zJNSbgl4UA/tables/tables_9_2.jpg", "caption": "Table 6: Ablation study of Scala over DeiT-S [29] on ImageNet-1K under various width ratios. IA, PKT, SS, NC denote Isolated Activation, Progressive Knowledge Transfer, Stable Sampling, Noise Calibration, respectively. The best results are bold-faced.", "description": "This table presents the ablation study of the proposed method, Scala, on the ImageNet-1K dataset using the DeiT-S model.  It shows the impact of removing each component of Scala (Isolated Activation, Progressive Knowledge Transfer, Stable Sampling, and Noise Calibration) on the top-1 accuracy at various width ratios (0.25, 0.375, 0.50, 0.625, 0.75, 0.875, 1.00). The results highlight the contribution of each component to the overall performance of Scala.", "section": "5.6 Ablation Study"}, {"figure_path": "zJNSbgl4UA/tables/tables_13_1.jpg", "caption": "Table 7: Comparisons of training from scratch and fine-tuning on ImageNet-1K.", "description": "This table compares the performance of training a DeiT-S model from scratch versus fine-tuning a pre-trained model using the Scala method.  The results are shown for different width ratios (0.25, 0.50, 0.75, 1.00), representing different model sizes. The \"Scratch\" row represents training a model from random initialization while the \"Fine-tune\" row shows the results of fine-tuning a pre-trained model.  The table demonstrates that training from scratch significantly outperforms fine-tuning, especially for smaller models.", "section": "A.3 Larger Slicing Bound"}, {"figure_path": "zJNSbgl4UA/tables/tables_14_1.jpg", "caption": "Table 8: Comparison with Separate Training (ST) over DeiT-B [29] on ImageNet-1K with different training epochs under different r.  \u00a7 denotes the expected training epochs of each model.", "description": "This table compares the performance of Scala and Separate Training (ST) on the DeiT-B model for ImageNet-1K classification.  It shows the accuracy (Acc1.) achieved by each method at different width ratios (r = 0.25, 0.50, 0.75, 1.00) and training epochs.  \u00a7 represents the expected training epochs for each model, showing Scala's efficiency in requiring fewer epochs to achieve comparable or better results than ST.", "section": "5. Experiments"}, {"figure_path": "zJNSbgl4UA/tables/tables_14_2.jpg", "caption": "Table 6: Ablation study of Scala over DeiT-S [29] on ImageNet-1K under various width ratios. IA, PKT, SS, NC denote Isolated Activation, Progressive Knowledge Transfer, Stable Sampling, Noise Calibration, respectively. The best results are bold-faced.", "description": "This table presents the ablation study results of the Scala model on the ImageNet-1K dataset using DeiT-S.  The study examines the impact of four key components of the Scala framework: Isolated Activation (IA), Progressive Knowledge Transfer (PKT), Stable Sampling (SS), and Noise Calibration (NC). Each row represents a variant of the Scala model with one component removed.  The Top-1 accuracy is reported for various width ratios (0.25 to 1.00), showing the contribution of each component to the overall performance.  Boldfaced values indicate the best performance for each width ratio.", "section": "5.6 Ablation Study"}, {"figure_path": "zJNSbgl4UA/tables/tables_15_1.jpg", "caption": "Table 1: Comparison with scaling baseline methods AutoFormer [4], US-Net [37] and Separate Training under different width ratios r. The best results are bold-faced.", "description": "This table compares the performance of Scala against three baseline methods: AutoFormer, US-Net, and Separate Training.  The comparison is made across four different width ratios (r = 0.25, 0.50, 0.75, 1.00) representing different model sizes. For each method and width ratio, the table shows the top-1 accuracy (Acc1), the number of parameters (Param), the number of training epochs (\u03be), and the number of GFLOPS.  The best result for each width ratio is shown in bold.", "section": "5.1 Experiment Settings"}, {"figure_path": "zJNSbgl4UA/tables/tables_15_2.jpg", "caption": "Table 11: Comparisons of training time with baseline methods on 8 A100 GPUs.", "description": "This table compares the training time (in hours) required for three different methods to train 13 models: Separate Training, US-Net, and Scala.  Separate Training trains each model separately, resulting in the longest training time. US-Net and Scala are more efficient, with Scala showing a slightly longer training time than US-Net.", "section": "5.2 Proof-of-Concept"}]