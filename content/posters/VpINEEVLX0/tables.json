[{"figure_path": "VpINEEVLX0/tables/tables_7_1.jpg", "caption": "Table 1: Node classification performance with GCN as the backbone on three datasets (averaged over 10 trials). Standard deviation is denoted after \u00b1.", "description": "This table presents the results of node classification experiments using Graph Convolutional Networks (GCNs) as the backbone model on three different datasets. The table compares the performance of various continual learning methods, including the proposed TACO framework.  The metrics used are Average Performance (AP) and Average Forgetting (AF) for macro F1 and balanced accuracy scores (BACC). The results are averaged over ten trials, and the standard deviations are provided.", "section": "4.1 Comparison methods"}, {"figure_path": "VpINEEVLX0/tables/tables_7_2.jpg", "caption": "Table 2: Coarsen runtime (seconds) and trade-off results of different coarsening methods on three datasets with GCN (average over 10 trials). Boldface indicates the best result of each column.", "description": "This table presents a comparison of different graph coarsening methods' performance in terms of computation time and their effect on model performance.  The trade-off is calculated as the time required to improve or reduce specific metrics (F1-AP, F1-AF, BACC-AP, BACC-AF) by 1%, compared to a fine-tuning baseline. The results are obtained using the GCN model and averaged over 10 trials on three datasets (Kindle, DBLP, ACM).", "section": "4.4.1 Graph coarsening methods"}, {"figure_path": "VpINEEVLX0/tables/tables_9_1.jpg", "caption": "Table 3: Comparision between experience replay-based CGL methods.", "description": "This table compares several experience replay-based continual graph learning methods, highlighting their differences in terms of replay buffer contents, graph topology preservation, handling of inter-task edges, and consideration of the dynamic receptive field.  A checkmark indicates that the method includes the feature; an 'X' indicates it does not.  The table helps illustrate the unique aspects of TACO compared to existing methods.", "section": "5 Related Work"}, {"figure_path": "VpINEEVLX0/tables/tables_15_1.jpg", "caption": "Table 1: Node classification performance with GCN as the backbone on three datasets (averaged over 10 trials). Standard deviation is denoted after \u00b1.", "description": "This table presents the results of node classification experiments using a Graph Convolutional Network (GCN) as the backbone model on three different datasets.  The table compares the performance of the proposed TACO method against several state-of-the-art continual learning methods. The metrics used for evaluation are Average Performance (AP) and Average Forgetting (AF), calculated using macro F1 scores and balanced accuracy scores (BACC).  The results are averaged over 10 independent trials, with standard deviations reported.", "section": "4.1 Comparison methods"}, {"figure_path": "VpINEEVLX0/tables/tables_23_1.jpg", "caption": "Table 4: Statistics of datasets. \"Interval\" indicates the length of the time interval for each task. \"#Item\" indicates the total number of items/papers in each dataset.", "description": "This table presents the statistics of three datasets used in the paper: Kindle, DBLP, and ACM.  For each dataset, it shows the time period covered, the length of the time interval used to define each task, the total number of tasks, the number of classes, and the total number of items (e-books for Kindle, papers for DBLP and ACM).", "section": "E Supplemental experiment setups"}, {"figure_path": "VpINEEVLX0/tables/tables_24_1.jpg", "caption": "Table 1: Node classification performance with GCN as the backbone on three datasets (averaged over 10 trials). Standard deviation is denoted after \u00b1.", "description": "This table presents the results of node classification experiments using the Graph Convolutional Network (GCN) as the backbone model across three datasets: Kindle, DBLP, and ACM.  The table compares the performance of TACO (the proposed method) with several state-of-the-art continual learning methods.  For each method, the average F1-score and average forgetting (AF) are reported, along with standard deviations across ten trials. The results demonstrate the effectiveness of TACO in reducing catastrophic forgetting in graph neural networks.", "section": "4.1 Comparison methods"}, {"figure_path": "VpINEEVLX0/tables/tables_25_1.jpg", "caption": "Table 1: Node classification performance with GCN as the backbone on three datasets (averaged over 10 trials). Standard deviation is denoted after \u00b1.", "description": "This table presents the results of node classification experiments using the Graph Convolutional Network (GCN) model as the backbone.  The experiments were conducted on three different datasets (Kindle, DBLP, ACM), and the performance of various continual learning methods (including the proposed TACO method) is evaluated in terms of Average Performance (AP) and Average Forgetting (AF) using macro F1 and Balanced Accuracy scores.  Each result represents the average over 10 trials, and the standard deviations are included.", "section": "4.1 Comparison methods"}, {"figure_path": "VpINEEVLX0/tables/tables_26_1.jpg", "caption": "Table 2: Coarsen runtime (seconds) and trade-off results of different coarsening methods on three datasets with GCN (average over 10 trials). Boldface indicates the best result of each column.", "description": "This table presents the computation time and trade-off analysis for various graph coarsening methods used in the TACO framework. The methods are compared across three datasets using the GCN model and the results are averaged over ten trials.  The trade-off values represent the coarsening time needed to increase or decrease the performance metrics (F1-AP, F1-AF, BACC-AP, BACC-AF) by 1% compared with the fine-tuning baseline. The best-performing methods for each metric are highlighted in bold.", "section": "4.4.1 Graph coarsening methods"}, {"figure_path": "VpINEEVLX0/tables/tables_27_1.jpg", "caption": "Table 8: The averaged short-term forgetting in terms of F1 score (%) with GCN as the backbone on three datasets (averaged over 10 trials).", "description": "This table presents the results of short-term forgetting (AF-st) experiment. AF-st measures the decline in model performance on the most recent task when a new task is learned. The table shows the AF-st values (in percentage) for different continual graph learning (CGL) methods on three datasets: Kindle, DBLP, and ACM.  The values represent the average F1 score drop on the test set of the most recent task after training on all previous and current tasks. A lower value indicates better performance in retaining knowledge of recent tasks.", "section": "4.3 Main results"}, {"figure_path": "VpINEEVLX0/tables/tables_27_2.jpg", "caption": "Table 1: Node classification performance with GCN as the backbone on three datasets (averaged over 10 trials). Standard deviation is denoted after \u00b1.", "description": "This table presents the results of node classification experiments using a Graph Convolutional Network (GCN) as the backbone model on three different datasets.  The performance is measured by Average Performance (AP) and Average Forgetting (AF) using macro F1 and Balanced Accuracy (BACC) as metrics.  The table compares the performance of TACO against several state-of-the-art continual learning methods, demonstrating TACO's superiority.  Each method's performance (AP and AF) is shown for both macro F1 and BACC scores, along with standard deviations across ten trials.", "section": "4.1 Comparison methods"}, {"figure_path": "VpINEEVLX0/tables/tables_28_1.jpg", "caption": "Table 10: The averaged memory usage (MB) for each task of experience-replay-based methods.", "description": "This table presents the average memory usage in MB for each task across different experience-replay based continual graph learning methods.  It shows how much memory each method requires to store information about past tasks (replay buffer) during the continual learning process. The methods compared include ERGNN (with different memory update strategies), DyGrain, IncreGNN, SSM, SSRM, and TACO. The table allows a comparison of memory efficiency across various approaches.", "section": "G.3 Efficiency Analysis"}, {"figure_path": "VpINEEVLX0/tables/tables_29_1.jpg", "caption": "Table 1: Node classification performance with GCN as the backbone on three datasets (averaged over 10 trials). Standard deviation is denoted after \u00b1.", "description": "This table presents the results of node classification experiments using the Graph Convolutional Network (GCN) model as the backbone on three different datasets: Kindle, DBLP, and ACM.  The table compares the performance of various continual learning methods (including the proposed TACO method and several state-of-the-art baselines) in terms of average performance (AP) and average forgetting (AF), using macro F1 and balanced accuracy (BACC) as evaluation metrics. The results are averaged over 10 trials, with standard deviations reported.", "section": "4.1 Comparison methods"}, {"figure_path": "VpINEEVLX0/tables/tables_30_1.jpg", "caption": "Table 1: Node classification performance with GCN as the backbone on three datasets (averaged over 10 trials). Standard deviation is denoted after \u00b1.", "description": "This table presents the results of node classification experiments using Graph Convolutional Networks (GCNs) as the backbone model on three different datasets.  The table compares the performance of various continual learning methods, including the proposed TACO method, against several state-of-the-art baselines.  Metrics reported include average performance (AP) and average forgetting (AF) using macro F1 and balanced accuracy scores.  The results are averaged over ten trials, with standard deviations included.", "section": "4.1 Comparison methods"}]