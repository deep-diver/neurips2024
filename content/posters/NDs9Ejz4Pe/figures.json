[{"figure_path": "NDs9Ejz4Pe/figures/figures_1_1.jpg", "caption": "Figure 1: (a) An exemplar of the studied class-agnostic OD and downstream OOD-OD tasks. (B) Zero-shot class-agnostic OD performance of Grounding DINO [33] on MS-COCO [32], with the hand-crafted UNIVERSAL query from ChatGPT and CLASS-WIDE query from WordNet [14].", "description": "This figure shows two subfigures. Subfigure (a) illustrates the class-agnostic object detection (OD) task and its downstream out-of-distribution (OOD) object detection task.  It displays examples of images with detected objects. Subfigure (b) presents a bar chart comparing the zero-shot class-agnostic object detection performance of Grounding DINO on MS-COCO using two different types of hand-crafted queries: UNIVERSAL queries (generated by ChatGPT) and CLASS-WIDE queries (from WordNet). The chart shows the average recall (AR) for various query types, highlighting the impact of query design on detection performance.", "section": "1 Introduction"}, {"figure_path": "NDs9Ejz4Pe/figures/figures_3_1.jpg", "caption": "Figure 2: A case study investigating the impact of semantic overlap between text queries on the detection confidence of the pre-trained Grounding DINO [33]. Semantic overlaps are quantified by the angular distance, denoted as \u03b8, between tokenized embeddings of word pairs using BERT [9].", "description": "This figure shows a case study demonstrating how semantic overlap between text queries affects object detection confidence using the Grounding DINO model.  Three different query combinations are tested: \"plates\", \"dishes\", and \"plates. dishes\".  The results show that when semantically similar words (\"plates\" and \"dishes\") are combined, the detection confidence decreases compared to using each word individually.  However, combining words with less semantic overlap (\"plates\" and \"cup\") maintains high detection confidence. The angular distance between word embeddings, calculated using BERT, is used to quantify the semantic overlap.", "section": "2 Pilot Study"}, {"figure_path": "NDs9Ejz4Pe/figures/figures_4_1.jpg", "caption": "Figure 3: An illustration of the \u2460 proposed prompt expansion strategy that selectively grows a set of child prompts for the highlighted parent prompt across L iterations; \u2461 diversifying initialized embeddings of the child prompt on a hypersphere and \u2462 quantifying maximum angular coverage @max for early termination of the prompt growth.", "description": "This figure illustrates the DiPEx (Dispersing Prompt Expansion) approach.  The left panel shows the hierarchical structure of the prompt expansion process, where a parent prompt is iteratively expanded into multiple child prompts over L layers. The middle panel details how child prompt embeddings are initialized by diversifying the parent prompt embedding on a hypersphere through random rotations. The right panel demonstrates how the maximum angular coverage (@max) is calculated to determine when to stop expanding prompts, balancing the richness of semantic information and computational cost. This figure visually summarizes the key steps of DiPEx, showing how it efficiently expands prompts while avoiding excessive growth and semantic overlap.", "section": "3 Proposed Approach"}, {"figure_path": "NDs9Ejz4Pe/figures/figures_8_1.jpg", "caption": "Figure 4: Impact of the prompt length on the MS-COCO dataset. The average recall (AR) and precision (AP) are reported to compare the derived DiPEx against CoOp [24] and CoCoOp [23].", "description": "This figure shows the impact of the number of prompts on the average recall (AR) and average precision (AP) for class-agnostic object detection on the MS-COCO dataset.  It compares the performance of DiPEx against two other methods, CoOp and CoCoOp, demonstrating that increasing the number of prompts generally improves performance for DiPEx but not necessarily for other methods. The x-axis represents the number of prompts and the y-axis shows the average recall and precision scores.", "section": "4.3 Ablation Study and Model Analysis"}, {"figure_path": "NDs9Ejz4Pe/figures/figures_8_2.jpg", "caption": "Figure 5: The heatmap visualization presents the angular coverage across all learned prompts through the 2nd, the 3rd, and the 4th round of training. The maximum angular coverage (MAC) monotonically increases from 67.7\u00b0 in the 2nd round to 75.95\u00b0 in the final round. The gradual reduction in rate of change in angular coverage towards the final round suggests that the model nearing convergence.", "description": "This figure displays heatmaps showing the angular coverage of learned prompts after 2, 3, and 4 training rounds.  The heatmaps visualize the pairwise angular distances between the prompts.  The maximum angular coverage (MAC) increases monotonically over the rounds, indicating that the prompts are successfully expanding to cover a broader semantic space. The diminishing rate of increase in MAC in later rounds suggests the model is approaching convergence, implying the prompt expansion process is nearing completion.", "section": "3.2 Dispersing Prompt Expansion (DiPEx)"}, {"figure_path": "NDs9Ejz4Pe/figures/figures_9_1.jpg", "caption": "Figure 6: The distribution of logit activation of the learned prompts in the 2nd round (left) and the 3rd round (right). The prompt of the highest activation frequency is identified for further expansion.", "description": "This figure shows the distribution of logit activation frequencies for the learned prompts after the second and third rounds of prompt expansion in the DiPEx method.  The left panel displays the distribution after the second round, while the right panel shows the distribution after the third round.  The prompt with the highest activation frequency (the one with the most uncertainty) is then selected for further expansion in subsequent rounds.  This visualization helps to illustrate how the method iteratively refines the prompts and addresses semantic ambiguity by focusing on the most uncertain prompts.", "section": "4.3 Ablation Study and Model Analysis"}, {"figure_path": "NDs9Ejz4Pe/figures/figures_9_2.jpg", "caption": "Figure 7: Visualization of the class-agnostic detection performance by baselines and the proposed DiPEx on MS-COCO [32]. More visualizations are provided in Appendix (Figures 9 and 10).", "description": "This figure shows a qualitative comparison of class-agnostic object detection results on several images from the MS-COCO dataset.  It compares the performance of several methods: MOST, CutLER, Zero-shot G-DINO, and the proposed DiPEx. Each column represents the detection results from a different method, while the last column shows the ground truth bounding boxes. The figure aims to visually demonstrate DiPEx's superior ability to detect a wider range of objects, especially smaller objects, compared to other baselines.", "section": "5 Conclusion and Limitations"}, {"figure_path": "NDs9Ejz4Pe/figures/figures_17_1.jpg", "caption": "Figure 8: Study of Loss Coefficient \u03b3", "description": "This bar chart displays the impact of the loss coefficient \u03b3 on the average recall (AR) and average precision (AP) in the DiPEx model.  It shows that a moderate value of \u03b3 yields optimal results; larger values lead to over-regularization, while smaller values may not sufficiently separate child prompts.", "section": "A.3 More Ablation Studies"}, {"figure_path": "NDs9Ejz4Pe/figures/figures_18_1.jpg", "caption": "Figure 9: Additional visualizations of class-agnostic box predictions. Columns 1\u20134 correspond to the following methods: MOST [43], CutLER [50], zero-shot Grounding DINO [\u201cgeneric\u201d] [9], and our proposed DiPEx, respectively. The final column presents human-annotated ground truth bounding boxes from the MS-COCO dataset [32].", "description": "This figure provides a qualitative comparison of class-agnostic object detection performance between several methods, including MOST, CutLER, zero-shot Grounding DINO, and the proposed DiPEx method.  Each column displays the detection results from a different method for the same set of images, while the last column shows the ground truth bounding boxes. This visualization allows for a direct comparison of the detection accuracy and the ability to locate objects in different scenes.", "section": "A. Additional Visualizations of Class-Agnostic Box Predictions"}, {"figure_path": "NDs9Ejz4Pe/figures/figures_19_1.jpg", "caption": "Figure 7: Visualization of the class-agnostic detection performance by baselines and the proposed DiPEx on MS-COCO [32]. More visualizations are provided in Appendix (Figures 9 and 10).", "description": "This figure provides a visual comparison of class-agnostic object detection results on several images from the MS-COCO dataset.  The results from four different methods (MOST, CutLER, zero-shot Grounding DINO, and DiPEx) are shown alongside the ground truth bounding boxes.  The figure demonstrates DiPEx's superior ability to detect a wider range of objects, particularly smaller objects, compared to the baseline methods.", "section": "Qualitative Study"}]