[{"figure_path": "lizRmKCnBp/figures/figures_1_1.jpg", "caption": "Figure 1: Our NeCGeS can compress geometry data with hundreds or even thousands of shapes into 1~2 MB while preserving details. Left: Original Geometry Data. Right: Decompressed Geometry Data. Q Zoom in for details.", "description": "This figure shows the effectiveness of the NeCGS method in compressing a large number of 3D models. The left side displays the original, uncompressed dataset of diverse 3D models, while the right side shows the same models after compression using NeCGS.  The compression ratio is high (around 900x), yet the decompressed models retain a significant level of detail.  The caption encourages viewers to zoom in for a closer look at the details.", "section": "1 Introduction"}, {"figure_path": "lizRmKCnBp/figures/figures_3_1.jpg", "caption": "Figure 2: The pipeline of NeCGS. It first represents original meshes regularly into TSDF-Def volumes, and an auto-decoder network is utilized to regress these volume. Then the embedded features and decoder parameters are compressed into bitstreams through entropy coding. When decompressing the models, the decompressed embedded features are fed into the decoder with the decompressed parameters from the bitstreams, reconstructing the TSDF-Def volumes, and the models can be extracted from them.", "description": "This figure illustrates the workflow of the NeCGS neural compression framework.  It begins by converting irregular 3D mesh models into a regular 4D representation called TSDF-Def volumes. These volumes are then processed by an auto-decoder network to generate embedded features and network parameters that capture the essence of the models. These features and parameters are compressed into a bitstream. During decompression, the bitstream is used to reconstruct the TSDF-Def volumes, from which the original 3D models are then extracted. This shows the stages of regular geometry representation and compact neural representation.", "section": "3 Proposed Method"}, {"figure_path": "lizRmKCnBp/figures/figures_3_2.jpg", "caption": "Figure 3: 2D visual illustration of DMC. The blue points refer to the deformable grid points, the green points refer to the vertices of the extracted surfaces, and the orange lines refer to the faces of the extracted surfaces. Left: The original grid points. Right: The surface extraction.", "description": "This figure illustrates the Differentiable Deformable Marching Cubes (DMC) algorithm. The left panel shows a regular grid of points. The right panel shows how the DMC algorithm deforms this grid to extract a surface from a 3D model represented as a Truncated Signed Distance Function (TSDF). The deformed grid points are shown in blue, the surface vertices in green, and the surface faces in orange.", "section": "3.1 Regular Geometry Representation"}, {"figure_path": "lizRmKCnBp/figures/figures_6_1.jpg", "caption": "Figure 4: Quantitative comparisons of different methods on four 3D geometry sets.", "description": "This figure presents a comparison of different geometry compression methods across four datasets (AMA, DT4D, Thingi10K, and Mixed). It shows Rate-Distortion (RD) curves, illustrating the trade-off between compression ratio and distortion (measured by Chamfer Distance (CD) and F-Score). The results demonstrate that the proposed NeCGS method achieves superior compression efficiency with minimal distortion compared to existing methods, particularly at high compression ratios.", "section": "4.2 Results"}, {"figure_path": "lizRmKCnBp/figures/figures_6_2.jpg", "caption": "Figure 6: (a) RD curve of different neural representation structures. (b) RD curves of different regression losses.", "description": "This figure demonstrates the impact of different neural representation structures and regression losses on the rate-distortion performance of the proposed neural compression method.  Subfigure (a) compares the performance of an auto-encoder and an auto-decoder based approach, showing the superiority of the auto-decoder. Subfigure (b) illustrates how using a joint loss function (combining MAE and SSIM) significantly improves the compression performance over using MAE alone.", "section": "4.3 Ablation Study"}, {"figure_path": "lizRmKCnBp/figures/figures_7_1.jpg", "caption": "Figure 5: Visual comparisons of different compression methods. All numbers in corners represent the compression ratio. Zoom in for details.", "description": "This figure displays the visual comparison of different compression methods applied to four sets of 3D models (AMA, DT4D, Thingi10K, Mixed). Each row presents the same model set, starting with the original model. Subsequent models are compressed using different methods (GPCC, VPCC, PCGCv2, Draco, QuantDeepSDF), each with varying compression ratios indicated in the corners. The visual difference allows a qualitative assessment of the methods' ability to preserve details in models under different compression levels. The \"Zoom in for details\" note suggests a detailed examination of the images is encouraged for a better understanding.", "section": "4.2 Results"}, {"figure_path": "lizRmKCnBp/figures/figures_7_2.jpg", "caption": "Figure 1: Our NeCGS can compress geometry data with hundreds or even thousands of shapes into 1~2 MB while preserving details. Left: Original Geometry Data. Right: Decompressed Geometry Data. Q Zoom in for details.", "description": "This figure shows the effectiveness of the proposed NeCGS method. The left side displays the original geometry data, which consists of hundreds to thousands of diverse 3D shapes. The right side shows the decompressed geometry data after applying NeCGS.  Despite achieving a compression ratio of nearly 900 (reducing the size from ~684 MB to 0.76 MB), the decompressed models retain their detailed structures, demonstrating the high-quality compression capability of the method.", "section": "1 Introduction"}, {"figure_path": "lizRmKCnBp/figures/figures_8_1.jpg", "caption": "Figure 8: (a) RD curves of different neural representation structures. (b) RD curves of different regression losses.", "description": "This figure presents two sub-figures showing Rate-Distortion (RD) curves which evaluate the performance of different neural representation structures and regression losses.  Subfigure (a) compares the performance of an auto-encoder and an auto-decoder, demonstrating the effectiveness of using an auto-decoder architecture.  Subfigure (b) shows that including the Structural Similarity Index (SSIM) in the loss function improves compression performance.", "section": "4.3 Ablation Study"}, {"figure_path": "lizRmKCnBp/figures/figures_8_2.jpg", "caption": "Figure 9: Visual comparison of regression loss w/ and w/o SSIM item.", "description": "This figure shows a visual comparison of the results obtained with and without the SSIM (Structural Similarity Index) loss in the regression process. It visually demonstrates the importance of incorporating SSIM loss for improving the quality of the reconstructed 3D models. The models reconstructed without the SSIM loss show some floating parts around the reconstructed models. In contrast, when using the SSIM loss, the reconstructed models look much cleaner and more accurate.", "section": "3.2 Compact Neural Representation"}, {"figure_path": "lizRmKCnBp/figures/figures_8_3.jpg", "caption": "Figure 1: Our NeCGS can compress geometry data with hundreds or even thousands of shapes into 1~2 MB while preserving details. Left: Original Geometry Data. Right: Decompressed Geometry Data. Q Zoom in for details.", "description": "This figure shows the effectiveness of the NeCGS method in compressing a large dataset of 3D models.  The left side displays the original, uncompressed models, demonstrating their diversity in shape and size. The right side shows the same models after compression with NeCGS, illustrating that high compression ratios can be achieved (hundreds or even thousands of models compressed into 1-2MB) while retaining important details of the 3D structures.", "section": "Introduction"}, {"figure_path": "lizRmKCnBp/figures/figures_14_1.jpg", "caption": "Figure 2: The pipeline of NeCGS. It first represents original meshes regularly into TSDF-Def volumes, and an auto-decoder network is utilized to regress these volume. Then the embedded features and decoder parameters are compressed into bitstreams through entropy coding. When decompressing the models, the decompressed embedded features are fed into the decoder with the decompressed parameters from the bitstreams, reconstructing the TSDF-Def volumes, and the models can be extracted from them.", "description": "This figure illustrates the workflow of the Neural Compression for 3D Geometry Sets (NeCGS) method. It starts by converting irregular 3D mesh models into a regular 4D representation called TSDF-Def volumes.  An auto-decoder network then learns to represent these volumes compactly using embedded features and network parameters. These features and parameters are compressed into a bitstream for efficient storage and transmission.  During decompression, the embedded features and parameters are retrieved from the bitstream, fed into the decoder to reconstruct the TSDF-Def volumes, and finally, the original 3D mesh models are extracted from the reconstructed volumes.", "section": "3 Proposed Method"}, {"figure_path": "lizRmKCnBp/figures/figures_14_2.jpg", "caption": "Figure 2: The pipeline of NeCGS. It first represents original meshes regularly into TSDF-Def volumes, and an auto-decoder network is utilized to regress these volume. Then the embedded features and decoder parameters are compressed into bitstreams through entropy coding. When decompressing the models, the decompressed embedded features are fed into the decoder with the decompressed parameters from the bitstreams, reconstructing the TSDF-Def volumes, and the models can be extracted from them.", "description": "This figure illustrates the overall pipeline of the NeCGS method.  It starts with a set of original 3D mesh models. These are first converted into a regular 4D representation called TSDF-Def volumes. An auto-decoder neural network then learns to represent these volumes compactly using embedded features and network parameters.  These features and parameters are compressed using entropy coding to reduce file size.  During decompression, the decoder reconstructs the TSDF-Def volumes from the compressed information, allowing for the final extraction of the original 3D models.", "section": "3 Proposed Method"}, {"figure_path": "lizRmKCnBp/figures/figures_15_1.jpg", "caption": "Figure 5: Visual comparisons of different compression methods. All numbers in corners represent the compression ratio. Q Zoom in for details.", "description": "This figure presents a visual comparison of the results obtained using various compression methods on three different 3D geometry datasets (AMA, DT4D, and Thingi10K). Each row shows the results for one dataset, with the leftmost column depicting the original models and the subsequent columns showing the decompressed models at increasing compression ratios (indicated by the numbers in the corners). The figure aims to demonstrate the relative performance of different compression methods, showcasing how well each method preserves the details of the 3D models under different compression levels.", "section": "4.2 Results"}]