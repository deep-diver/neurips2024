[{"figure_path": "x69O84Df2G/tables/tables_7_1.jpg", "caption": "Table 1: Cartpole swing-up. Statistics for the random variable X\u2081 = \u2211t=11ri(stat)>0 (with ri \u2208 R or ri \u2208 Rrnd). Values are multiplied by 100 and rounded to the first digit. In bold statistically significant results (in parentheses we indicate the 95% confidence interval over 30 seeds).", "description": "This table presents the results for the Cartpole swing-up experiment. It shows the statistics for the random variable X\u1d62, which is the sum of rewards received when the pole is upright (i.e., satisfying specific conditions). The table compares different algorithms (DBMR-BPI, RND, APT, Disagreement) for different difficulty levels (k = 3, 5) and training steps (T = 150000, 200000).  The results are shown as average, standard deviation, minimum, and maximum values of X\u1d62, along with 95% confidence intervals.", "section": "3.4 Numerical Results on Tabular MDPS"}, {"figure_path": "x69O84Df2G/tables/tables_7_2.jpg", "caption": "Table 4: Cartpole swing-up. Statistics for the random variable X\u2081 = \u2211t=1 ri(st, at)>0 (with ri \u2208 Rbase). Values are multiplied by 100 and rounded to the first digit. In bold statistically significant results (in parentheses we indicate the 95% confidence interval).", "description": "The table presents the results for two difficulty levels (k=3,5) and various training steps (T=150000, 200000).  The random variable X\u1d62 represents the sum of positive rewards accumulated by the agent up to time T. For each reward in the set Rbase (base rewards), the table shows the mean, standard deviation, median, maximum, and minimum values of X\u1d62, averaged across 30 independent seeds.  Statistically significant results are highlighted in bold.", "section": "3.4 Numerical Results on Tabular MDPS"}, {"figure_path": "x69O84Df2G/tables/tables_8_1.jpg", "caption": "Table 2: DeepSea. Statistics for the random variable X\u2081 = \u2211t=1 ri(st, at) (with ri \u2208 R or ri \u2208 Rrnd). Values are multiplied by 100 (except the third metric for the base rewards) and rounded to the first digit. In bold statistically significant results (in parentheses we indicate the 95% confidence interval over 30 seeds).", "description": "This table presents the performance of different algorithms (DBMR-BPI, RND, APT, Disagreement) on the DeepSea environment for different sizes of the grid (N=20 and N=30).  For each algorithm, the table shows the average reward collected (E[AvgR({Xi})], E[AvgRnd({Xi})]), standard deviation (E[stdr({Xi})], E[stdRnd({Xi})]), median (E[medR({Xi})], E[medRnd({Xi})]), maximum (E[maxR({Xi})], E[maxRnd({Xi})]), minimum (E[minR({Xi})], E[minRnd({Xi})]) and number of cells in the last row of the grid that have not been visited by the algorithm at the end of the experiment (E[\u2211\u2081\u2081 x\u1d62=0]).  The results are for both the base rewards (R) and random unseen rewards (Rrnd) and are averaged over 30 seeds.  Statistically significant results are bolded and the 95% confidence interval is reported in parentheses.", "section": "Numerical Results"}, {"figure_path": "x69O84Df2G/tables/tables_34_1.jpg", "caption": "Table 1: Cartpole swing-up. Statistics for the random variable X\u2081 = \u2211t=11ri(stat)>0 (with ri \u2208 R or ri \u2208 Rrnd). Values are multiplied by 100 and rounded to the first digit. In bold statistically significant results (in parentheses we indicate the 95% confidence interval over 30 seeds).", "description": "This table presents the numerical results for the Cartpole swing-up problem.  The results are averaged over 30 seeds, and the 95% confidence intervals are shown in parentheses. The table shows the average (E[Avg]), standard deviation (E[std]), median (E[med]), minimum (E[min]), and maximum (E[max]) values for the random variable X\u1d62, which represents the sum of rewards received when the pole is upright, across multiple rewards.  The results are shown for both the base rewards (R) and randomly generated rewards (Rrnd). Statistically significant results are highlighted in bold.", "section": "3.4 Numerical Results on Tabular MDPs"}, {"figure_path": "x69O84Df2G/tables/tables_55_1.jpg", "caption": "Table 4: Cartpole swing-up. Statistics for the random variable X\u2081 = \u2211t=11ri(stat)>0 (with ri \u2208 Rbase). Values are multiplied by 100 and rounded to the first digit. In bold statistically significant results (in parentheses we indicate the 95% confidence interval).", "description": "This table presents the results for the Cartpole swing-up task, comparing the performance of different algorithms (DBMR-BPI, RND, APT, and Disagreement) across two difficulty levels (k=3 and k=5).  The values represent statistics for the random variable Xi, which is the sum of rewards received when the pole is upright (or above a certain threshold).  The table shows the average (AvgR), median (medR), standard deviation (stdR), maximum (maxR), and minimum (minR) values of Xi, along with 95% confidence intervals.  The results highlight the relative performance of DBMR-BPI in accumulating positive rewards compared to the other methods.", "section": "3.4 Numerical Results on Tabular MDPS"}, {"figure_path": "x69O84Df2G/tables/tables_57_1.jpg", "caption": "Table 5: Cartpole swing-up. Statistics for the random variable X\u2081 = \u2211t=1 ri(st, at)>0, with ri \u2208 Rrnd. Values are multiplied by 100 and rounded to the first digit. In bold statistically significant results (in parentheses we indicate the 95% confidence interval).", "description": "This table presents the results of the Cartpole swing-up experiment for different difficulty levels (k=3 and k=5) and training steps (T=150000 and T=200000).  The results are averaged over 30 seeds.  The key metric is X\u1d62, representing the sum of positive rewards (r\u1d62(s\u209c, a\u209c)) received up to time T, where r\u1d62 is drawn from the set of random rewards Rrnd (not used during training).  The table shows statistical measures (mean, median, standard deviation, maximum, and minimum) for X\u1d62, highlighting statistically significant differences using bold font and confidence intervals in parentheses.", "section": "Numerical Results"}, {"figure_path": "x69O84Df2G/tables/tables_58_1.jpg", "caption": "Table 6: Parameters and values of the algorithms. For all algorithms we used a batch size of 128.", "description": "This table lists the hyperparameters used for each of the algorithms evaluated in the paper.  The hyperparameters are divided into categories by algorithm (DBMR-BPI, APT, Disagreement, RND) and then lists the specific value assigned to each parameter within each algorithm.  Note that all algorithms used a batch size of 128.", "section": "Deep-RL Algorithms Details"}, {"figure_path": "x69O84Df2G/tables/tables_60_1.jpg", "caption": "Table 7: DeepSea environment. Statistics for the random variable X\u2081 = \u2211t=1 ri(st, at) (with ri \u2208 Rbase). Values are multipled by 100 and rounded to the first digit. In parentheses we indicate the 95% confidence interval.", "description": "This table presents the statistical results for the DeepSea environment, focusing on the random variable X\u1d62, which represents the sum of rewards obtained for the i-th reward in a specific instance.  The results are averaged across 30 seeds, with values multiplied by 100 and rounded to the first digit.  95% confidence intervals are included in parentheses.  The table includes statistics such as the median, geometric mean, standard deviation, maximum, minimum, and the sum of instances where X\u1d62 equals zero. These metrics provide insights into the performance of various algorithms across different rewards in the DeepSea environment.", "section": "4.1 Numerical Results"}, {"figure_path": "x69O84Df2G/tables/tables_61_1.jpg", "caption": "Table 5: Cartpole swing-up. Statistics for the random variable X\u2081 = \u2211t=11ri(stat)>0, with ri \u2208 Rrnd. Values are multiplied by 100 and rounded to the first digit. In bold statistically significant results (in parentheses we indicate the 95% confidence interval).", "description": "This table presents the results for the Cartpole swing-up problem, focusing on the random rewards.  The random variable X\u1d62 represents the sum of positive rewards collected by the agent during each episode.  The table shows the average, standard deviation, median, maximum, and minimum values of X\u1d62 for different algorithms (DBMR-BPI, RND, APT, Disagreement) and difficulty levels (k=3 and k=5).  Statistically significant results are highlighted.", "section": "Numerical Results on Tabular MDPS"}, {"figure_path": "x69O84Df2G/tables/tables_63_1.jpg", "caption": "Table 6: Parameters and values of the algorithms. For all algorithms we used a batch size of 128.", "description": "This table lists the hyperparameters used for each algorithm in the Deep Reinforcement Learning experiments.  It shows the values used for DBMR-BPI, APT, Disagreement, and RND, including parameters such as ensemble size, network architecture, learning rates, exploration parameters, and buffer size.  The consistent batch size of 128 is also noted.", "section": "E Deep-RL Algorithms Details"}, {"figure_path": "x69O84Df2G/tables/tables_67_1.jpg", "caption": "Table 6: Parameters and values of the algorithms. For all algorithms we used a batch size of 128.", "description": "This table lists the hyperparameters used for each of the algorithms in the experiments: DBMR-BPI, APT, Disagreement, and RND.  It shows the values used for parameters such as ensemble size, network architecture, learning rates, and other algorithm-specific settings. The batch size was consistently set to 128 across all algorithms.", "section": "Deep-RL Algorithms Details"}, {"figure_path": "x69O84Df2G/tables/tables_68_1.jpg", "caption": "Table 1: Cartpole swing-up. Statistics for the random variable X\u2081 = \u2211t=11ri(st,at)>0 (with ri \u2208 R or ri \u2208 Rrnd). Values are multiplied by 100 and rounded to the first digit. In bold statistically significant results (in parentheses we indicate the 95% confidence interval over 30 seeds).", "description": "This table presents the numerical results for the Cartpole swing-up problem, comparing the performance of DBMR-BPI against several baselines.  The results show the average, standard deviation, minimum, and maximum of the random variable X\u2081, which is the sum of rewards received when the pole is upright from time step 1 to T.  The table is divided into sections for different difficulty levels (k) and training steps (T), with both base and randomly generated rewards.", "section": "3.4 Numerical Results on Tabular MDPs"}, {"figure_path": "x69O84Df2G/tables/tables_69_1.jpg", "caption": "Table 6: Parameters and values of the algorithms. For all algorithms we used a batch size of 128.", "description": "This table lists the hyperparameters used for each of the algorithms evaluated in the paper.  It includes the values for DBMR-BPI (Deep Bootstrapped Multi-Reward BPI), RND (Random Network Distillation), APT (Auxiliary Prediction Target), and Disagreement.  The hyperparameters control various aspects of each algorithm's learning process, such as network architecture, learning rates, and exploration strategies. The consistent batch size of 128 is also noted.", "section": "Deep-RL Algorithms Details"}, {"figure_path": "x69O84Df2G/tables/tables_69_2.jpg", "caption": "Table 6: Parameters and values of the algorithms. For all algorithms we used a batch size of 128.", "description": "This table lists the hyperparameters used for the different algorithms in the Deep Reinforcement Learning experiments.  It includes details for DBMR-BPI, RND, APT, and Disagreement algorithms.  The table shows the values for parameters such as network architecture (Nensemble, Ndbmrbpi, Ndqn, Ntrunk, Ndisag, Nrnd, NF, NB), learning rates (\u03b1, \u03b1r, \u03b1\u03bc, lapt, Arnd), exploration parameters (Puniform, Pmask), and the size of the replay buffer (C). A batch size of 128 was used consistently across all algorithms.", "section": "Deep-RL Algorithms Details"}, {"figure_path": "x69O84Df2G/tables/tables_70_1.jpg", "caption": "Table 6: Parameters and values of the algorithms. For all algorithms we used a batch size of 128.", "description": "This table presents the hyperparameters used for all the algorithms in the experiments.  It shows the values used for DBMR-BPI, RND, APT, and Disagreement,  including specifics like ensemble size, network layer sizes, learning rates, and other algorithm-specific parameters.  A batch size of 128 was consistently used across all algorithms.", "section": "Exploration in Deep Reinforcement Learning with a Set of Rewards"}, {"figure_path": "x69O84Df2G/tables/tables_70_2.jpg", "caption": "Table 6: Parameters and values of the algorithms. For all algorithms we used a batch size of 128.", "description": "This table lists the hyperparameters used for all algorithms in the experiments.  The table includes values for DBMR-BPI, RND, APT, and Disagreement, showing the specific values set for various parameters such as ensemble size, network architecture, learning rates, exploration parameters, and more.", "section": "4.1 Numerical Results"}, {"figure_path": "x69O84Df2G/tables/tables_70_3.jpg", "caption": "Table 6: Parameters and values of the algorithms. For all algorithms we used a batch size of 128.", "description": "This table lists the hyperparameters and their values used for the different algorithms evaluated in the paper.  It includes details for DBMR-BPI, RND, APT, and Disagreement, specifying values for parameters such as network architecture, learning rates, exploration factors, and other algorithm-specific settings.  The consistent batch size of 128 is also noted.", "section": "Deep-RL Algorithms Details"}]