[{"figure_path": "vMMzjCr5Zj/figures/figures_2_1.jpg", "caption": "Figure 1: Overview of LPTM. The input time-series y(1\u2026\u2026T) is first segmented based on a scoring function optimized using SSL loss. The segments are fed as individual tokens to the transformer encoder to get output embeddings of time-series that are used for downstream tasks.", "description": "This figure illustrates the architecture of the Large Pre-trained Time-series Models (LPTM).  The input time series is first segmented using an adaptive segmentation module guided by a scoring function that aims to minimize the self-supervised learning (SSL) loss. These segments, acting as tokens, are then fed into a transformer encoder. The encoder's output embeddings are used for various downstream time series analysis tasks.", "section": "3 Methodology"}, {"figure_path": "vMMzjCr5Zj/figures/figures_8_1.jpg", "caption": "Figure 2: Performance of LPTM and best baseline with varying fractions of training data. In most cases LPTM significantly outperforms baselines with lower amount of data.", "description": "This figure compares the performance of LPTM and the best-performing baseline model for several time-series forecasting tasks, when trained on varying percentages of the available training data.  The x-axis represents the percentage of training data used, ranging from 20% to 100%.  The y-axis displays the Root Mean Squared Error (RMSE), a common metric for evaluating the accuracy of time-series forecasts. Lower RMSE values indicate better forecasting accuracy. The figure showcases that LPTM consistently achieves lower RMSE values than the baselines across various datasets, demonstrating its superior performance even when trained on significantly less data.", "section": "Results"}, {"figure_path": "vMMzjCr5Zj/figures/figures_9_1.jpg", "caption": "Figure 3: Segmentation learned by LPTM", "description": "This figure visualizes the segmentation strategy learned by the LPTM model for three different time series datasets: Flu-US, ETT1, and BasicMotions.  The red dots represent the segment boundaries identified by the adaptive segmentation module of LPTM.  The plots show that the model learns to segment the time series based on the underlying dynamics.  In regions with high variance or important temporal patterns, such as the peak of an epidemic (Flu-US), the segments are shorter and more frequent, capturing the intricate details of the time series. In contrast, simpler trends, such as the smoother patterns in ETT1, have longer segments. This adaptive segmentation enables LPTM to effectively capture both local and global temporal patterns within the time series, improving its overall performance.", "section": "3 Methodology"}, {"figure_path": "vMMzjCr5Zj/figures/figures_15_1.jpg", "caption": "Figure 3: Segmentation learned by LPTM", "description": "This figure visualizes the segmentations learned by the LPTM model for different time series datasets.  It shows how the adaptive segmentation module identifies variable-length segments, with shorter segments in regions of high variance or significant events (like the peak of an epidemic) and longer segments in smoother areas. This highlights the model's ability to adapt to the varying characteristics of different time series.", "section": "3 Methodology"}, {"figure_path": "vMMzjCr5Zj/figures/figures_16_1.jpg", "caption": "Figure 3: Segmentation learned by LPTM", "description": "This figure visualizes the segmentation strategy learned by the LPTM model for three different time series datasets: Flu-US, ETT1, and BasicMotions.  The x-axis represents time, and the y-axis represents the value of the time series.  Each colored segment represents a segment identified by the adaptive segmentation module.  The lengths of the segments vary depending on the complexity of the time series patterns within each domain. In domains with smoother trends, the segments are longer.  In domains with more complex, rapidly changing trends, the segments are shorter. This demonstrates the adaptive nature of the segmentation module in handling the diversity and variability found in real-world time series data.", "section": "3 Methodology"}]