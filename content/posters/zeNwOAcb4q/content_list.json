[{"type": "text", "text": "Estimating Transition Matrix with Diffusion Models for Instance-Dependent Label Noise ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 Learning with noisy labels is a common problem in weakly supervised learning,   \n2 where the transition matrix approach is a prevalent method for dealing with label   \n3 noise. It estimates the transition probabilities from a clean label distribution to a   \n4 noisy label distribution and has garnered continuous attention. However, existing   \n5 transition matrix methods predominantly focus on class-dependent noise, making   \n6 it challenging to incorporate feature information for learning instance-dependent   \n7 label noise. This paper proposes the idea of using diffusion models for estimating   \n8 transition matrix in the context of instance-dependent label noise. Specifically, we   \n9 first estimate grouped transition matrices through clustering. Then, we introduce   \n0 a process of adding noise and denoising with the transition matrix, incorporating   \n11 features extracted by unsupervised pre-trained models. The proposed method   \n2 enables the estimation of instance-dependent transition matrix and extends the   \n3 application of transition matrix method to a broader range of noisy label data.   \n14 Experimental results demonstrate the significant effectiveness of our approach on   \n15 both synthetic and real-world datasets with instance-dependent noise. The code   \n16 will be open sourced upon acceptance of the paper. ", "page_idx": 0}, {"type": "text", "text": "17 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "18 For classification problems with given labels, deep neural networks have demonstrated significant   \n19 improvements compared to traditional methods in recent years [25]. The efficacy of deep neural   \n20 networks heavily relies on the accuracy of the labels. Directly incorporating polluted erroneous labels   \n21 into network learning can result in the network fitting the noise, potentially severely impacting the   \n22 predictive performance of the network [8]. However, in reality, obtaining accurate annotated data can   \n23 be prohibitively expensive, and a substantial amount of data comes from the Internet or is annotated   \n24 by non-expert annotators, inevitably containing noisy labels. Therefore, researching and promoting   \n25 methods to mitigate the damage to models and make them more robust in the face of label noise data   \n26 is a highly worthwhile problem to investigate, known as the problem of learning with noisy labels   \n27 [23, 10, 34, 1].   \n28 Different approaches have been proposed to address the problem of label noise. One category   \n29 [31, 22] involves the design of specialized loss functions or network structures to enhance the model\u2019s   \n30 robustness against noisy labels. Another major category focuses on sample selection [2, 10, 14],   \n31 where samples are partitioned into a set of clean samples and a set of contaminated noisy samples   \n32 based on the magnitude of the loss or the similarity of extracted features. The labels of the noisy   \n33 samples are then modified or their weights are reduced, followed by learning using semi-supervised   \n34 methods. Sample selection methods are currently mainstream and have achieved promising results.   \n35 However, the selection process relies heavily on intuition and lacks theoretical support. Additionally,   \n36 the sample selection procedure is often complex and computationally intensive. In contrast, another   \n37 significant category of methods is the transition matrix method [34, 17, 12, 42], which estimates the   \n38 transition probabilities from the clean label distribution to the noisy label distribution. This class   \n39 of methods reveals the generation process of noisy labels and exhibits statistical consistency, often   \n40 accompanied by theoretical analyses as methodological support. As a result, they have garnered   \n41 continuous attention and occupy an important position in various algorithms for learning with noisy   \n42 labels.   \n43 In transition matrix methods, accurate estimation of the transition matrix is crucial. If an accurate   \n44 estimation of the transition matrix can be obtained, along with the observed data for estimating the   \n45 posterior distribution of the noisy labels, it is possible to infer the distribution of clean labels for   \n46 neural network learning. Previous transition matrix methods [34, 17, 39] have mainly focused on   \n47 class-dependent label noise, where a single transition matrix is estimated for all samples, which is   \n48 typically straightforward. However, for instance-dependent label noise and complex real-world data,   \n49 the label transition probabilities for each sample are not entirely identical. The transition matrix often   \n50 depends on the specific features of individual samples, requiring the estimation of a separate transition   \n51 matrix for each sample. However, in most cases, a single observed label corresponds to each sample   \n52 in the dataset, making it an identifiability problem to estimate a separate transition matrix for each   \n53 sample [20]. Although some methods [33, 41, 15] have utilized separate small networks to generate   \n54 the transition matrix or divided the data into groups to transform it into a grouped class-dependent   \n55 scenario, there still exist significant estimation errors and a lack of incorporating features effectively   \n56 into the estimation of the transition matrix.   \n57 To better incorporate the feature information of images into the estimation of the transition matrix,   \n58 this work employs conditional diffusion models. The diffusion model originates from generative   \n59 models and has been widely applied in various computer vision tasks in recent years [36, 7], showing   \n60 remarkable results. The proposed method revolves around the core idea of replacing image samples in   \n61 the original diffusion process with a transition matrix. The matrix undergoes a process of adding noise   \n62 and denoising, where the denoising step incorporates the sample features extracted by a pre-trained   \n63 model as conditions. This generates a feature-dependent transition matrix. The constructed diffusion   \n64 module is illustrated in Figure 1. Additionally, considering the assumption that instance-dependent   \n65 label noise is usually correlated with features [6], clustering methods are utilized at the feature level   \n66 to group samples. Preliminary estimations of the transition matrices are obtained for each group,   \n67 which are then incorporated into the diffusion module for learning. The overall framework of the   \n68 method is depicted in Figure 2.   \n69 The subsequent sections are organized as follows. Section 2 presents an in-depth review of the   \n70 relevant works. In Section 3, we introduce our proposed model framework. Section 4 outlines   \n71 the experimental analysis conducted on diverse synthetic and real-world noisy datasets, along with   \n72 comparisons against other existing methods. Finally, we provide concluding in Section 5. The   \n73 primary contributions of this paper can be summarized as follows:   \n74 \u2022 We propose a method that utilizes diffusion models to add noise and denoise on the transition   \n75 matrix, incorporating image features extracted through pre-trained encoder.   \n76 \u2022 By combining the transition matrix-based diffusion model with feature-based clustering, we   \n77 establish a framework capable of addressing instance-dependent label noise problems.   \n78 \u2022 Our method demonstrates significant improvements over other transition matrix methods on   \n79 both synthetic and real-world noisy datasets, and it achieves comparable performance to   \n80 state-of-the-art methods. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "image", "img_path": "zeNwOAcb4q/tmp/499e6b9bbc13cb26417090dbafb85f6c5967aeccecd32dbe4fdb5af7e7621a5f.jpg", "img_caption": ["Figure 1: Diffusion Model for Transition Matrix. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "image", "img_path": "zeNwOAcb4q/tmp/0fae2951c83f3ff22d1f356fc07f1efa2d7bf17e6685921913f3bd46f0fa7ae6.jpg", "img_caption": ["Figure 2: The overall framework of DTM. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "81 2 Related Works ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "82 2.1 Transition Matrix Methods ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "83 Most previous methods for estimating transition matrix in the presence of label noise have primarily   \n84 focused on class-dependent noise scenarios, simplifying the estimation process. Methods such as   \n85 [24, 34] assume the existence of anchor points to identify the transition matrix. [17] and [39]   \n86 introduce different regularization techniques to relax the anchor point assumption. Additionally,   \n87 [26, 38] apply techniques such as meta-learning to estimate the transition matrix, but these approaches   \n88 may require more clean data and computational resources. While these methods are effective for   \n89 handling class-dependent label noise, they are not suitable for instance-dependent noise or real-world   \n90 noisy data.   \n91 However, estimating an individual transition matrix for each sample without additional assumptions   \n92 or multiple noisy labels is infeasible [20]. To approximate the estimation of the instance-dependent   \n93 transition matrix, [9] utilize an adaptation layer that estimates the transition matrix based on the   \n94 output of each sample. [37] employs a separate network to estimate the transition matrix based on   \n95 Bayesian labels. Some methods, such as [33, 30, 41], employ clustering to learn part-dependent   \n96 or group-dependent matrices, which can be viewed as a compromise between instance-dependent   \n97 and class-dependent methods. Other approaches, including [6, 12], utilize the similarity in the   \n98 feature space to aid in learning the transition matrix. Although these instance-dependent transition   \n99 matrix methods achieve identifiability through specialized treatments, they have not effectively   \n100 utilized feature information in the learning process, resulting in errors in estimating feature-dependent   \n101 transition matrices. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "102 2.2 Diffusion Models ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "103 Diffusion models, as generative models, have played a significant role in computer vision [36, 7].   \n104 Prominent examples include DDPM [11], DDIM [27], score matching methods [28], and methods   \n105 based on stochastic differential equations [29]. Diffusion models and their variants have been applied   \n106 to various computer vision tasks such as image generation, image-to-image translation, text-to-image   \n107 generation, among others. However, their application to the problem of label noise is relatively novel.   \n108 To the best of our knowledge, only one existing work [3] has utilized diffusion models for addressing   \n109 this problem. However, this work treats labels as the output of the diffusion model, which limits   \n110 their expressive power due to the low dimension of the labels. Moreover, it overly relies on directly   \n111 incorporating image features as conditions in the label generation process, which depends heavily on   \n112 pre-trained models and may not be as reasonable as incorporating them into the transition matrix that   \n113 reveals the process of noise generation. Experimental results also support this perspective. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "114 3 Method ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "115 In this section, we present the definitions of symbols and introduce our method of using Diffusion   \n116 models to construct the Transition Matrix (DTM). ", "page_idx": 3}, {"type": "text", "text": "117 3.1 Preliminaries ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "118 Let $\\mathcal{X}\\subset\\mathbb{R}^{d}$ be the input image space, $\\mathcal{Y}=\\{1,2,\\cdot\\cdot\\cdot,C\\}$ be the label space, where $C$ is the number   \n119 of classes. Random variables $(X,Y),(X,{\\tilde{Y}})\\in\\,\\mathcal{X}\\times\\mathcal{Y}$ denote the underlying data distributions   \n120 with true and noisy labels respectively. In general, we can not observe the latent true data samples   \n121 $\\mathbb{D}=\\{(\\pmb{x}_{i},y_{i})\\}_{i=1}^{N}$ , but can only obtain the corrupted data $\\tilde{\\mathbb{D}}=\\{(\\pmb{x}_{i},\\tilde{y_{i}})\\}_{i=1}^{N}$ , where $\\tilde{y}\\in\\mathcal{V}$ is the   \n122 noisy label corrupted from the true label $y$ , while denote corresponding one-hot label as $\\textit{\\textbf{y}}$ and $\\tilde{\\pmb{y}}$ .   \n123 Transition matrix methods use a matrix $\\pmb{T}(\\pmb{x})\\in[0,1]^{C\\times C}$ to represent the probability from clean   \n124 label to noisy label, where the $i j$ -th entry of the transition matrix is the probability that the instance   \n125 $\\textbf{\\em x}$ with the clean label $i$ corrupted to a noisy label $j$ . The matrix satisfies the requirement that the   \n126 sum of each row $\\textstyle\\sum_{j=1}^{C}T_{i j}({\\pmb x})$ is 1, and usually has the requirement for $\\pmb{T}_{i i}(\\pmb{x})>\\pmb{T}_{i j}(\\pmb{x}),\\forall j\\neq i$   \n127 Let $P({\\pmb Y}|{\\pmb X}={\\pmb x})=[P({\\pmb Y}=1|{\\pmb X}={\\pmb x}),\\cdot\\cdot\\cdot{\\bf\\nabla},P({\\pmb Y}=C|{\\pmb X}={\\pmb x})]^{\\top}\\mathrm{~be~t~}$ he clean class-posterior   \n128 probability and $P(\\tilde{Y}|X=x)\\,=\\,[P(\\tilde{Y}\\,=\\,1|X\\,=\\,x),\\cdots\\,,P(\\tilde{Y}\\,=\\,C|X\\,=\\,x)]^{\\intercal}$ be the noisy   \n129 class-posterior probability, the formula can be write as: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\nP(\\tilde{Y}|X=x)={\\mathbf{T}}({\\mathbf{x}})^{\\top}P(Y|X=x).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "130 By estimating the transition matrix and the noisy class-posterior probability, the clean class-posterior   \n131 probability can be inferred by ", "page_idx": 3}, {"type": "equation", "text": "$$\nP({\\cal Y}|{\\cal X}={\\pmb x})={\\pmb T}({\\pmb x})^{-\\top}P(\\tilde{\\cal Y}|{\\cal X}={\\pmb x}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "132 where the symbol $-\\top$ denotes the transpose of the inverse matrix. ", "page_idx": 3}, {"type": "text", "text": "133 The majority of existing methods [24, 10, 17] focus on studying the class-dependent and instance  \n134 independent transition matrix, i.e., $\\pmb{T}(\\pmb{x})\\equiv\\pmb{T}$ for $\\forall\\pmb{x}$ . However, these methods are not applicable to   \n135 instance-dependent noise scenarios where the transition matrix ${\\pmb T}({\\pmb x})$ varies with respect to the input   \n136 $X$ . The main focus of our work is to utilize the feature information from input images to construct a   \n137 instance-dependent transition matrix ${\\pmb T}({\\pmb x})$ . ", "page_idx": 3}, {"type": "text", "text": "138 3.2 Diffusion Model for Transition Matrix ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "139 We adopt the classic DDPM model [11] from diffusion models as a reference to perform noise   \n140 addition and denoising on the transition matrix. The diagram is illustrated in Figure 1.   \n141 For the forward diffusion process beginning with transition matrix ${\\cal T}_{0}\\,\\sim\\,q(T)$ , the process of   \n142 gradually adding noise is obtained according to the following Markov process: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\nq\\left(T_{m}\\mid T_{m-1}\\right)=\\mathcal{N}\\left(T_{m};\\sqrt{1-\\beta_{m}}T_{m-1},\\beta_{m}\\mathbf{I}\\right),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "143 for $m=1,2,\\cdot\\cdot\\cdot,M$ , where we use $M$ to replace $T$ , which is usually used in other diffusion models,   \n144 in above equation for distinguishing from the symbol of transition matrix $_T$ .   \n145 We aim to make the distribution of $q(\\pmb{T}_{M})$ approach a standard normal distribution $\\mathcal{N}\\left(0,\\mathbf{I}\\right)$ and   \n146 through ${\\mathbf{}}T_{M}$ to conduct the reverse denoising process by fitting a neural network $\\pmb{\\mu}_{\\theta}$ to fit the   \n147 disttibution: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\np_{\\theta}\\left(T_{m-1}\\mid T_{m}\\right)=\\mathcal{N}\\left(T_{m-1};\\mu_{\\theta}\\left(T_{m},\\boldsymbol{\\mathbf{x}},f_{p},m\\right),\\tilde{\\beta}_{m}\\mathbf{I}\\right),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "148 where define = 11\u2212\u2212\u03b1\u00af\u03b1\u00afmm\u22121 \u03b2m, \u03b1m = 1 \u2212\u03b2m, \u03b1\u00afm =  im=1 \u03b1i. The fp in equation (4) denotes the   \n149 pre-trained encoder for feature extraction. ", "page_idx": 3}, {"type": "text", "text": "150 The diffusion model can be learned by optimizing the evidence lower bound: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathrm{ELBO}}=\\mathbb{E}_{q}\\left[\\mathcal{L}_{M}+\\sum_{m>1}^{M}\\mathcal{L}_{m-1}+\\mathcal{L}_{0}\\right],\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "151 where ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}_{0}=-\\log p_{\\theta}\\left(\\boldsymbol{T}_{0}\\mid\\boldsymbol{T}_{1}\\right),}\\\\ &{\\mathcal{L}_{m-1}=D_{\\mathrm{KL}}\\left(q\\left(\\boldsymbol{T}_{m-1}\\mid\\boldsymbol{T}_{m},\\boldsymbol{T}_{0}\\right)\\Vert p_{\\theta}\\left(\\boldsymbol{T}_{m-1}\\mid\\boldsymbol{T}_{m}\\right)\\right),}\\\\ &{\\mathcal{L}_{M}=D_{\\mathrm{KL}}\\left(q\\left(\\boldsymbol{T}_{M}\\mid\\boldsymbol{T}_{0}\\right)\\Vert p_{\\theta}\\left(\\boldsymbol{T}_{M}\\right)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "152 Similar to the derivation and simplification process of DDPM, when a pre-trained encoder $f_{p}$ is   \n153 provided along with the training data incorporating the initial transition matrix $_T$ , the learning   \n154 algorithm for the diffusion model is presented in Algorithm 1.   \n155 Next, for each image $\\textbf{\\em x}$ , we can sample the corresponding transition matrix ${\\pmb T}({\\pmb x})$ as shown in   \n156 Algorithm 2. ", "page_idx": 4}, {"type": "table", "img_path": "zeNwOAcb4q/tmp/182db219edde71aff2a437a4be3742e0cc9c1d9a25f7c36baab896ed5b4efb96.jpg", "table_caption": [], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "table", "img_path": "zeNwOAcb4q/tmp/5e65f23c54b12dd4829577a3494fe62dc2477c202443127efc80dae4f7f80438.jpg", "table_caption": [], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "157 3.3 Feature-Dependent Framework ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "158 From Algorithm 1, it can be observed that there are two components of the diffusion process that   \n159 need to be provided in advance: the pre-trained encoder $f_{p}$ and the initial input ${\\pmb T}({\\pmb x})$ .   \n160 The pre-trained encoder $f_{p}$ can be obtained through self-supervised learning or directly using the   \n161 large model like CLIP. In our experiments, we employ the commonly used SimCLR [4] method in   \n162 contrastive learning as the feature extraction model.   \n163 On the other hand, the part involving the transition matrix ${\\pmb T}({\\pmb x})$ used for learning the diffusion   \n164 model is also related to the pre-trained encoder $f_{p}$ . Based on the assumption that the noise transition   \n165 probability depends on image features, we adopt a group-dependent transition matrix as the initial   \n166 input. We perform clustering algorithms at the feature extraction level $f_{p}({\\pmb x})$ , using the $\\mathbf{K}_{\\mathrm{}}$ -means   \n167 method in our experiments, to group the image data. Then, based on the method VolMinNet [17], we   \n168 train class-dependent transition matrices for each group and obtain the initial transition matrix ${\\pmb T}({\\pmb x})$   \n169 for each image $\\textbf{\\em x}$ , which is then used as input in Algorithm 1. It is worth to note that the initial ${\\pmb T}({\\pmb x})$   \n170 used as input for the diffusion process does not require different for each $\\textbf{\\em x}$ . However, the denoising   \n171 process of the diffusion model will further incorporate the feature information into the learning of the   \n172 transition matrix.   \n173 After obtaining the instance-dependent estimated transition matrix ${\\pmb T}({\\pmb x})$ , the neural network can be   \n174 learned to fit the clean label distribution by the loss function: ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathcal{L}=\\frac{1}{N}\\sum_{i=1}^{N}\\ell\\left(\\pmb{T}(\\pmb{x}_{i})^{\\top}f_{\\phi}(\\pmb{x}_{i}),\\tilde{\\pmb{y}}_{i}\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "175 where $f_{\\phi}(\\cdot)\\,:\\,\\mathcal{X}\\,\\rightarrow\\,\\Delta^{C-1}$ $\\langle\\Delta^{C-1}\\,\\subset\\,[0,1]^{C}$ is the $C_{}$ -dimensional simplex) is a differentiable   \n176 function represented by a neural network with parameters $\\phi$ and $\\ell$ is a loss function usually using   \n177 cross-entropy (CE) loss.   \n178 The schematic diagram of the proposed framework is shown in Figure 2, and the pseudocode is   \n179 presented in Algorithm 3. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Algorithm 3 A framework of DTM ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Input: Training set $\\{(\\pmb{x}_{i},\\pmb{y}_{i})\\}_{i=1}^{N}$ , pre-trained encoder $f_{p}$ , diffusion model $\\epsilon_{\\theta}$ , classification neural network $f_{\\phi}$ . ", "page_idx": 5}, {"type": "text", "text": "1: Utilize input data to train $f_{p}$ or directly utilizing $f_{p}$ to extract features.   \n2: Perform 3: $\\{\\pmb{x}_{i},\\pmb{T}_{i}\\}_{i=1}^{N}$ $\\mathbf{K}$ -means on feature space and estimate the transition matrix for each group to get data .fusion model with Algorithm 1. $\\epsilon_{\\theta}$   \n4: Sample instance-dependent train matrix ${\\pmb T}({\\pmb x})$ for any input image $\\pmb{x}_{i}$ with Algorithm 2.   \n5: Update the parameters of the classification network by incorporating the transition matrix $\\pmb{T}(\\pmb{x}_{i})$ into equation (7). ", "page_idx": 5}, {"type": "text", "text": "Output: Network parameters $\\phi$ . ", "page_idx": 5}, {"type": "text", "text": "180 3.4 Matrix Transformation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "181 Considering that the transition matrix typically require the sum of each row $\\textstyle\\sum_{j=1}^{C}\\pmb{T}_{i j}(\\pmb{x})$ is 1, and   \n182 for $\\pmb{T}_{i i}(\\pmb{x})>\\pmb{T}_{i j}(\\pmb{x}),\\forall j\\neq i.$ , we employ a transformation during the update learning process in our   \n183 practical experiments.   \n184 We utilize a $C\\times C$ weight matrix $W~=~(w_{i j})$ to assist in the process. Denote matrix $\\pmb{A}$ as   \n185 $A_{i i}=1+\\sigma\\left(w_{i i}\\right)$ for all $i\\in\\{1,2,\\dots,C\\}$ and $\\mathbf{\\ddot{A}}_{i j}=\\sigma\\left(w_{i j}\\right)$ for all $i\\neq j$ where $\\sigma$ is the sigmoid   \n186 function. Then we do the normalization T ij = CAi jAkj to get the transition matrix $\\textbf{\\emph{T}}$ .   \n187 Through this transformation, we ensure that the learned transition matrix has row sums equal to 1 and   \n188 that the diagonal elements are the largest in each row. In practical experiments, we apply the diffusion   \n189 modeling discussed in subsection 3.2 to the matrix $W$ , and then transform it into the transition matrix   \n190 $\\textbf{\\emph{T}}$ for application. To simplify the notation, we uniformly use the term of transition matrix $W$ to   \n191 represent it, unless it leads to singularity. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "192 4 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "193 In this section, we present experimental findings to showcase the effectiveness of our proposed   \n194 method compared to other methods. We evaluate our approach on both synthetic instance-dependent   \n195 noisy datasets and real-world noisy datasets. ", "page_idx": 5}, {"type": "text", "text": "196 4.1 Datasets ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "197 We conduct experiments on following image classification datasets: CIFAR-10 and CIFAR-100 [13],   \n198 CIFAR-10N and CIFAR-100N [32], Clothing1M [35], Webvision and ILSVRC12 [16]. Among   \n199 them, CIFAR-10 and CIFAR-100 both have $32\\times32\\times3$ color images including 50,000 training   \n200 images and 10,000 test images. CIFAR-10 has 10 classes while CIFAR-100 has 100 classes. We   \n201 generate instance-dependent noisy data on CIFAR-10 and CIFAR-100 with noise rates ranging from   \n202 $10\\%$ to $50\\%$ , following the same generation method as in [33]. CIFAR-10N has three annotated   \n203 labels, namely Random1, Random 2 and Random 3. The \"Aggregate\" is the aggregation of three noisy   \n204 labels by majority voting, and the \"Worst\" is the dataset with the worst case. For CIFAR-100N, each   \n205 image contains a coarse label and a fine label given by a human annotator. Clothing1M is a real-world   \n206 dataset consisting of 1 million training images, consisting of 14 categories. WebVision contains 2.4   \n207 million images crawled from the websites using the 1,000 concepts in ImageNet ILSVRC12, but only   \n208 the first 50 classes of the Google image subset are used in our experiments. For the validation set   \n209 selection in our BTR method, we randomly sampled 10 samples from each observed class for each   \n210 dataset to form the validation set, while the remaining samples were used for the training set. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "211 4.2 Experimental Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "212 For the pre-trained model, we employ the commonly used SimCLR model [4] from contrastive   \n213 learning, which directly performs self-supervised learning on input images without utilizing additional   \n214 datasets. For the diffusion model, we follow the setup similar to DDPM [11] to set $\\beta_{1}=1\\overline{{0}}^{-4},\\beta_{M}=$   \n215 0.02 and utilize a similar U-Net network architecture but we reduce the $M$ from 1000 to 10 to   \n216 accelerate the learning process. As for the classification network, it may vary depending on the   \n217 specific dataset. More specifically, for CIFAR-10/10N, we use ResNet-18 as the backbone network   \n218 with batch size 128 and learning rate 0.05. For CIFAR-100/100N, we use ResNet-34 network   \n219 with batch size 128, learning rate 0.02. For clothing1M, we use a ResNet-50 pre-trained with 10   \n220 epochs, batch size 64, learning rate 0.002 for network and divided by 10 after the 5th epoch. We use   \n221 InceptionResNetV2 network on Webvision, with 100 epochs, batch size 32, learning rate 0.02 for   \n222 network and divided by 10 after the 30th and 60th epoch. For clustering, we utilize the K-means   \n223 method, where the number of clusters is set to 10 times the number of classes in the datasets. For   \n224 the initialization of transition matrix, the update method and setting are consistent with [17]. While   \n225 the updates for other parameters are performed using the stochastic gradient descent optimization   \n226 method. ", "page_idx": 6}, {"type": "table", "img_path": "zeNwOAcb4q/tmp/8e72ddfbc5a82bafc97355f53d8d69b5245b78ad28da543476a44f12b59c5dfa.jpg", "table_caption": ["Table 1: Test accuracy with instance-dependent noise on CIFAR-10/100. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "227 4.3 Comparison Methods ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "228 In our experiments, we included the following common transition matrix and baseline methods as   \n229 comparison: (1) VolMinNet [17], (2) PeerLoss [21] (3) BLTM [37], (4) PartT [33], (5) MEIDTM   \n230 [6], as well as state-of-the-art methods for learning with noisy labels: (6) Co-teaching [10], (7) ELR+   \n231 [18], (8) DivideMix [14], (9) SOP and $\\mathrm{SOP+}$ [19], (10) PGDF [5], (11) CC [40], (12) LRA [3]   \n232 with SimCLR as encoder similarly. ", "page_idx": 6}, {"type": "table", "img_path": "zeNwOAcb4q/tmp/5bf13f0b4a2127d65cb99bec3f1240a8d897efe1cf13c0aa9c4826684531984c.jpg", "table_caption": ["Table 2: Test accuracy on CIFAR-10N and CIFAR-100N. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "233 4.4 Experimental Results on Synthetic Datasets ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "234 We primarily validated our proposed method DTM against previous instance-based transition matrix   \n235 methods on synthetic CIFAR-10/100 noise datasets. These methods mainly focus on estimating the   \n236 transition matrix and some methods applicable to instance-dependent label noise. We performed 5   \n237 independent runs for each experimental configuration, and the average values and standard deviations   \n238 of each experiment are presented in Table 1.   \n239 The results demonstrate that our proposed DTR method outperforms other methods of the same   \n240 category across various noise rates. It is evident that traditional transition matrix methods for class  \n241 dependent noise as VolMinNet exhibit subpar performance when handling instance-dependent noise.   \n242 While even advanced transition matrix methods for instance-dependent label noise such as BLTM,   \n243 ParT and MEIDTM, still show significant gaps compared to our method.   \n244 Furthermore, as the noise rates increase, the test accuracy of existing transition matrix methods   \n245 significantly decline. This is particularly pronounced in the case of CIFAR-100 with $50\\%$ instance  \n246 dependent noise (IDN) data, where all transition matrix methods achieve test accuracy below $60\\%$ .   \n247 In contrast, our proposed DTR method achieves a remarkable test accuracy of $74.85\\%$ , showcasing   \n248 its exceptional performance. That demonstrates relatively robust performance of DTM with only a   \n249 slight decrease as the noise rate increases.   \n250 This experiment clearly demonstrates that there is a significant performance gap between previous   \n251 transition matrix methods and other advanced techniques, such as CC and LRA, when dealing with   \n252 instance-dependent noise problems. However, the experimental results indicate that our proposed   \n253 method DTM, which incorporates the diffusion model into the estimation of the transition matrix,   \n254 outperforms these advanced techniques, except for the case of $40\\%$ noise in CIFAR-100, where   \n255 our method slightly underperforms CC. It is evident that by leveraging the diffusion modeling to   \n256 estimate the transition matrix, we effectively incorporate the image\u2019s feature information, leading to a   \n257 substantial improvement in the effectiveness of the transition matrix. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "258 4.5 Experimental Results on Real-World Datasets ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "259 In addition to synthetic datasets, we also applied our method to real-world datasets and compared it   \n260 with other state-of-the-art techniques for handling label noise problems. The results are presented in   \n261 Table 2 and Table 3.   \n262 The results demonstrate that regardless of the type of noise labels, whether it is aggregated, random,   \n263 or the worst-case scenario in CIFAR-10N, as well as in CIFAR-100N with more label categories,   \n264 our method consistently achieves the best results in handling real-world noise. When dealing with   \n265 large datasets like Clothing1M and complex image datasets like Webvision, DTM also performs   \n266 comparably to other state-of-the-art methods.   \n267 Through extensive experiments on five real-world datasets and the rusults on synthetic datasets above,   \n268 our method outperforms the LRA method, which also utilizes the diffusion model for label noise   \n269 problems. The LRA method models label diffusion with fewer dimensional information and lacks the   \n270 rationale of our method, which considers noise generation from a transfer probability distribution   \n271 perspective. The experiments demonstrate that our method achieves better learning performance by   \n272 effectively integrating the transition matrix with the diffusion model. ", "page_idx": 7}, {"type": "table", "img_path": "zeNwOAcb4q/tmp/456ba9d3adf34fe664ff6bc9f107469963bc31488f1febbd24a5f2641a2892d1.jpg", "table_caption": ["Table 3: Test accuracy on Clothing1M, Webvision and ILSVRC12. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "273 4.6 Ablation Study ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "274 Besides the aforementioned experiments, we conducted ablation studies on proposed DTM method   \n275 to assess the importance of each component. Table 4 presents the comparative results under $20\\%$   \n276 and $40\\%$ instance-dependent noise rates, where \"w/o\" denotes \"without\". We conducted ablation   \n277 experiments on three components of our method, they are diffusion module, pre-trained encoder   \n278 module, and clustering module respectively. \"w/o diffusion\" indicates directly using the features   \n279 extracted by the pre-trained model for the classification task with the transition matrix. \"w/o pre-train\"   \n280 means not extracting features through self-supervised learning and directly utilizing the classification   \n281 network with the diffusion model. \"w/o clustering\" indicates that the initial transition matrix used for   \n282 the diffusion model is the same for all samples.   \n283 From the results in Table 4, it can be observed that regardless of which component of diffusion   \n284 module, pre-trained encoder module and clustering module is missing, the performance is consistently   \n285 weaker compared to the original DTM. This indicates that each module plays a crucial role in our   \n286 method. Our approach effectively combines the transition matrix, diffusion model, and pre-trained   \n287 feature extraction, leading to significant improvements. ", "page_idx": 8}, {"type": "table", "img_path": "zeNwOAcb4q/tmp/fcc0b3001cdc1e1bed0f8018191a90b8c31264ed15f8ada61c8cdd68e8418383.jpg", "table_caption": ["Table 4: Ablation study of DTR. The data in the table represents the test accuracy. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "288 5 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "289 In this paper, we propose a method that models the transition matrix using diffusion models, incorpo  \n290 rating the feature information extracted by a pre-trained encoder into the estimation of the transition   \n291 matrix. This approach enables the model to handle instance-dependent label noise with a wider range   \n292 of applicability. Experimental results on both synthetic and real-world noisy datasets demonstrate the   \n293 effectiveness of our proposed method. ", "page_idx": 8}, {"type": "text", "text": "294 References ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "295 [1] G\u00f6rkem Algan and Ilkay Ulusoy. Image classification with deep learning in the presence of   \n296 noisy labels: A survey. Knowledge-Based Systems, 215:106771, 2021.   \n297 [2] Devansh Arpit, Stanis\u0142aw Jastrz\u02dbebski, Nicolas Ballas, David Krueger, Emmanuel Bengio,   \n298 Maxinder S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al.   \n299 A closer look at memorization in deep networks. In International Conference on Machine   \n300 Learning, pages 233\u2013242. PMLR, 2017.   \n301 [3] Jian Chen, Ruiyi Zhang, Tong Yu, Rohan Sharma, Zhiqiang Xu, Tong Sun, and Changyou Chen.   \n302 Label-retrieval-augmented diffusion models for learning from noisy labels. arXiv preprint   \n303 arXiv:2305.19518, 2023.   \n304 [4] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework   \n305 for contrastive learning of visual representations. In International Conference on Machine   \n306 Learning, pages 1597\u20131607. PMLR, 2020.   \n307 [5] Wenkai Chen, Chuang Zhu, and Mengting Li. Sample prior guided robust model learning to   \n308 suppress noisy labels. In Joint European Conference on Machine Learning and Knowledge   \n309 Discovery in Databases, pages 3\u201319. Springer, 2023.   \n310 [6] De Cheng, Tongliang Liu, Yixiong Ning, Nannan Wang, Bo Han, Gang Niu, Xinbo Gao,   \n311 and Masashi Sugiyama. Instance-dependent label-noise learning with manifold-regularized   \n312 transition matrix estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision   \n313 and Pattern Recognition, pages 16630\u201316639, 2022.   \n314 [7] Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, and Mubarak Shah. Diffusion   \n315 models in vision: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence,   \n316 2023.   \n317 [8] Amit Daniely and Elad Granot. Generalization bounds for neural networks via approximate   \n318 description length. Advances in Neural Information Processing Systems, 32, 2019.   \n319 [9] Jacob Goldberger and Ehud Ben-Reuven. Training deep neural-networks using a noise adapta  \n320 tion layer. In International Conference on Learning Representations, 2016.   \n321 [10] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi   \n322 Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels.   \n323 Advances in Neural Information Processing Systems, 31, 2018.   \n324 [11] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances   \n325 in Neural Information Processing Systems, 33:6840\u20136851, 2020.   \n326 [12] Zhimeng Jiang, Kaixiong Zhou, Zirui Liu, Li Li, Rui Chen, Soo-Hyun Choi, and Xia Hu. An   \n327 information fusion approach to learning with instance-dependent label noise. In International   \n328 Conference on Learning Representations, 2021.   \n329 [13] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.   \n330 2009.   \n331 [14] Junnan Li, Richard Socher, and Steven CH Hoi. Dividemix: Learning with noisy labels as   \n332 semi-supervised learning. arXiv preprint arXiv:2002.07394, 2020.   \n333 [15] Shikun Li, Xiaobo Xia, Hansong Zhang, Yibing Zhan, Shiming Ge, and Tongliang Liu. Esti  \n334 mating noise transition matrix with label correlations for noisy multi-label learning. Advances   \n335 in Neural Information Processing Systems, 35:24184\u201324198, 2022.   \n336 [16] Wen Li, Limin Wang, Wei Li, Eirikur Agustsson, and Luc Van Gool. Webvision database:   \n337 Visual learning and understanding from web data. arXiv preprint arXiv:1708.02862, 2017.   \n338 [17] Xuefeng Li, Tongliang Liu, Bo Han, Gang Niu, and Masashi Sugiyama. Provably end-to-end   \n339 label-noise learning without anchor points. In International Conference on Machine Learning,   \n340 pages 6403\u20136413. PMLR, 2021.   \n341 [18] Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda. Early  \n342 learning regularization prevents memorization of noisy labels. Advances in Neural Information   \n343 Processing Systems, 33:20331\u201320342, 2020.   \n344 [19] Sheng Liu, Zhihui Zhu, Qing Qu, and Chong You. Robust training under label noise by over  \n345 parameterization. In International Conference on Machine Learning, pages 14153\u201314172.   \n346 PMLR, 2022.   \n347 [20] Yang Liu, Hao Cheng, and Kun Zhang. Identifiability of label noise transition matrix. In   \n348 International Conference on Machine Learning, pages 21475\u201321496. PMLR, 2023.   \n349 [21] Yang Liu and Hongyi Guo. Peer loss functions: Learning from noisy labels without knowing   \n350 noise rates. In International Conference on Machine Learning, pages 6226\u20136236. PMLR, 2020.   \n351 [22] Xingjun Ma, Hanxun Huang, Yisen Wang, Simone Romano, Sarah Erfani, and James Bailey.   \n352 Normalized loss functions for deep learning with noisy labels. In International Conference on   \n353 Machine Learning, pages 6543\u20136553. PMLR, 2020.   \n354 [23] Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learning   \n355 with noisy labels. Advances in Neural Information Processing Systems, 26, 2013.   \n356 [24] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu.   \n357 Making deep neural networks robust to label noise: A loss correction approach. In Proceedings   \n358 of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1944\u20131952, 2017.   \n359 [25] Samira Pouyanfar, Saad Sadiq, Yilin Yan, Haiman Tian, Yudong Tao, Maria Presa Reyes, Mei  \n360 Ling Shyu, Shu-Ching Chen, and Sundaraja S Iyengar. A survey on deep learning: Algorithms,   \n361 techniques, and applications. ACM Computing Surveys (CSUR), 51(5):1\u201336, 2018.   \n362 [26] Jun Shu, Qian Zhao, Zongben Xu, and Deyu Meng. Meta transition adaptation for robust deep   \n363 learning with noisy labels. arXiv preprint arXiv:2006.05697, 2020.   \n364 [27] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv   \n365 preprint arXiv:2010.02502, 2020.   \n366 [28] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data   \n367 distribution. Advances in Neural Information Processing Systems, 32, 2019.   \n368 [29] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and   \n369 Ben Poole. Score-based generative modeling through stochastic differential equations. arXiv   \n370 preprint arXiv:2011.13456, 2020.   \n371 [30] Jialu Wang, Yang Liu, and Caleb Levy. Fair classification with group-dependent label noise. In   \n372 Proceedings of the 2021 ACM conference on fairness, accountability, and transparency, pages   \n373 526\u2013536, 2021.   \n374 [31] Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James Bailey. Symmetric cross   \n375 entropy for robust learning with noisy labels. In Proceedings of the IEEE/CVF International   \n376 Conference on Computer Vision, pages 322\u2013330, 2019.   \n377 [32] Jiaheng Wei, Zhaowei Zhu, Hao Cheng, Tongliang Liu, Gang Niu, and Yang Liu. Learning   \n378 with noisy labels revisited: A study using real-world human annotations. arXiv preprint   \n379 arXiv:2110.12088, 2021.   \n380 [33] Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu,   \n381 Dacheng Tao, and Masashi Sugiyama. Part-dependent label noise: Towards instance-dependent   \n382 label noise. Advances in Neural Information Processing Systems, 33:7597\u20137610, 2020.   \n383 [34] Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and Masashi   \n384 Sugiyama. Are anchor points really indispensable in label-noise learning? Advances in Neural   \n385 Information Processing Systems, 32, 2019.   \n386 [35] Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. Learning from massive   \n387 noisy labeled data for image classification. In Proceedings of the IEEE Conference on Computer   \n388 Vision and Pattern Recognition, pages 2691\u20132699, 2015.   \n389 [36] Ling Yang, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao, Wentao Zhang,   \n390 Bin Cui, and Ming-Hsuan Yang. Diffusion models: A comprehensive survey of methods and   \n391 applications. ACM Computing Surveys, 56(4):1\u201339, 2023.   \n392 [37] Shuo Yang, Erkun Yang, Bo Han, Yang Liu, Min Xu, Gang Niu, and Tongliang Liu. Estimating   \n393 instance-dependent bayes-label transition matrix using a deep neural network. In International   \n394 Conference on Machine Learning, pages 25302\u201325312. PMLR, 2022.   \n395 [38] LIN Yong, Renjie Pi, Weizhong Zhang, Xiaobo Xia, Jiahui Gao, Xiao Zhou, Tongliang Liu,   \n396 and Bo Han. A holistic view of label noise transition matrix in deep learning and beyond. In   \n397 The Eleventh International Conference on Learning Representations, 2022.   \n398 [39] Yivan Zhang, Gang Niu, and Masashi Sugiyama. Learning noise transition matrix from only   \n399 noisy labels via total variation regularization. In International Conference on Machine Learning,   \n400 pages 12501\u201312512. PMLR, 2021.   \n401 [40] Ganlong Zhao, Guanbin Li, Yipeng Qin, Feng Liu, and Yizhou Yu. Centrality and consistency:   \n402 two-stage clean samples identification for learning with instance-dependent noisy labels. In   \n403 European Conference on Computer Vision, pages 21\u201337. Springer, 2022.   \n404 [41] Zhaowei Zhu, Yiwen Song, and Yang Liu. Clusterability as an alternative to anchor points   \n405 when learning with noisy labels. In International Conference on Machine Learning, pages   \n406 12912\u201312923. PMLR, 2021.   \n407 [42] Zhaowei Zhu, Jialu Wang, and Yang Liu. Beyond images: Label noise transition matrix   \n408 estimation for tasks with lower-quality features. In International Conference on Machine   \n409 Learning, pages 27633\u201327653. PMLR, 2022. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "410 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "11   \n412 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n413 paper\u2019s contributions and scope?   \n414 Answer: [Yes]   \n415 Justification: The main content and contributions of the work are reflected in the abstract   \n416 and introduction.   \n417 Guidelines:   \n418 \u2022 The answer NA means that the abstract and introduction do not include the claims   \n419 made in the paper.   \n420 \u2022 The abstract and/or introduction should clearly state the claims made, including the   \n421 contributions made in the paper and important assumptions and limitations. A No or   \n422 NA answer to this question will not be perceived well by the reviewers.   \n423 \u2022 The claims made should match theoretical and experimental results, and reflect how   \n424 much the results can be expected to generalize to other settings.   \n425 \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals   \n426 are not attained by the paper.   \n427 2. Limitations   \n428 Question: Does the paper discuss the limitations of the work performed by the authors?   \n429 Answer: [Yes]   \n430 Justification: In the experimental section, we analyze the applicability and limitations of our   \n431 method.   \n432 Guidelines:   \n433 \u2022 The answer NA means that the paper has no limitation while the answer No means that   \n434 the paper has limitations, but those are not discussed in the paper.   \n435 \u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n436 \u2022 The paper should point out any strong assumptions and how robust the results are to   \n437 violations of these assumptions (e.g., independence assumptions, noiseless settings,   \n438 model well-specification, asymptotic approximations only holding locally). The authors   \n439 should reflect on how these assumptions might be violated in practice and what the   \n440 implications would be.   \n441 \u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was   \n442 only tested on a few datasets or with a few runs. In general, empirical results often   \n443 depend on implicit assumptions, which should be articulated.   \n444 \u2022 The authors should reflect on the factors that influence the performance of the approach.   \n445 For example, a facial recognition algorithm may perform poorly when image resolution   \n446 is low or images are taken in low lighting. Or a speech-to-text system might not be   \n447 used reliably to provide closed captions for online lectures because it fails to handle   \n448 technical jargon.   \n449 \u2022 The authors should discuss the computational efficiency of the proposed algorithms   \n450 and how they scale with dataset size.   \n451 \u2022 If applicable, the authors should discuss possible limitations of their approach to   \n452 address problems of privacy and fairness.   \n453 \u2022 While the authors might fear that complete honesty about limitations might be used by   \n454 reviewers as grounds for rejection, a worse outcome might be that reviewers discover   \n455 limitations that aren\u2019t acknowledged in the paper. The authors should use their best   \n456 judgment and recognize that individual actions in favor of transparency play an impor  \n457 tant role in developing norms that preserve the integrity of the community. Reviewers   \n458 will be specifically instructed to not penalize honesty concerning limitations.   \n459 3. Theory Assumptions and Proofs   \n460 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n461 a complete (and correct) proof?   \n463 Justification: The focus of the work is on application and does not include a theoretical   \n464 proof component.   \n465 Guidelines:   \n466 \u2022 The answer NA means that the paper does not include theoretical results.   \n467 \u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross  \n468 referenced.   \n469 \u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n470 \u2022 The proofs can either appear in the main paper or the supplemental material, but if   \n471 they appear in the supplemental material, the authors are encouraged to provide a short   \n472 proof sketch to provide intuition.   \n473 \u2022 Inversely, any informal proof provided in the core of the paper should be complemented   \n474 by formal proofs provided in appendix or supplemental material.   \n475 \u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "476 4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "477 Question: Does the paper fully disclose all the information needed to reproduce the main ex  \n478 perimental results of the paper to the extent that it affects the main claims and/or conclusions   \n479 of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 13}, {"type": "text", "text": "Justification: The paper provides a detailed description of the model construction and the specifics of the experimental data. ", "page_idx": 13}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n5 \u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of   \n7 whether the code and data are provided or not. \u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n0 \u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may   \n3 be necessary to either make it possible for others to replicate the model with the same   \n4 dataset, or provide access to the model. In general. releasing code and data is often   \n5 one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. \u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in   \n13 some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 13}, {"type": "text", "text": "515 5. Open access to data and code ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "16 Question: Does the paper provide open access to the data and code, with sufficient instruc  \n17 tions to faithfully reproduce the main experimental results, as described in supplemental   \n18 material?   \n19 Answer: [No]   \n20 Justification: Upon acceptance of our paper, we will provide open-source code. The data we   \n21 used is from commonly available open-source datasets.   \n22 Guidelines:   \n23 \u2022 The answer NA means that paper does not include experiments requiring code.   \n24 \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/   \n25 public/guides/CodeSubmissionPolicy) for more details.   \n26 \u2022 While we encourage the release of code and data, we understand that this might not be   \n27 possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not   \n28 including code, unless this is central to the contribution (e.g., for a new open-source   \n29 benchmark).   \n30 \u2022 The instructions should contain the exact command and environment needed to run to   \n31 reproduce the results. See the NeurIPS code and data submission guidelines (https:   \n32 //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n33 \u2022 The authors should provide instructions on data access and preparation, including how   \n34 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n35 \u2022 The authors should provide scripts to reproduce all experimental results for the new   \n36 proposed method and baselines. If only a subset of experiments are reproducible, they   \n37 should state which ones are omitted from the script and why.   \n38 \u2022 At submission time, to preserve anonymity, the authors should release anonymized   \n39 versions (if applicable).   \n40 \u2022 Providing as much information as possible in supplemental material (appended to the   \n41 paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 14}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 14}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 14}, {"type": "text", "text": "Justification: The experimental section of the paper provides details of the model and data. Guidelines: ", "page_idx": 14}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 14}, {"type": "text", "text": "554 7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "555 Question: Does the paper report error bars suitably and correctly defined or other appropriate   \n556 information about the statistical significance of the experiments? ", "page_idx": 14}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 14}, {"type": "text", "text": "Justification: We conducted multiple repeated experiments to validate our approach and performed ablation experiments. ", "page_idx": 14}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). ", "page_idx": 14}, {"type": "text", "text": "568 \u2022 The method for calculating the error bars should be explained (closed form formula,   \n569 call to a library function, bootstrap, etc.)   \n570 \u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n571 \u2022 It should be clear whether the error bar is the standard deviation or the standard error   \n572 of the mean.   \n573 \u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should   \n574 preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis   \n575 of Normality of errors is not verified.   \n576 \u2022 For asymmetric distributions, the authors should be careful not to show in tables or   \n577 figures symmetric error bars that would yield results that are out of range (e.g. negative   \n578 error rates).   \n579 \u2022 If error bars are reported in tables or plots, The authors should explain in the text how   \n580 they were calculated and reference the corresponding figures or tables in the text.   \n581 8. Experiments Compute Resources   \n582 Question: For each experiment, does the paper provide sufficient information on the com  \n583 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n584 the experiments?   \n585 Answer: [Yes]   \n586 Justification: We list the relevant details in the experimental section.   \n587 Guidelines:   \n588 \u2022 The answer NA means that the paper does not include experiments.   \n589 \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster,   \n590 or cloud provider, including relevant memory and storage.   \n591 \u2022 The paper should provide the amount of compute required for each of the individual   \n592 experimental runs as well as estimate the total compute.   \n593 \u2022 The paper should disclose whether the full research project required more compute   \n594 than the experiments reported in the paper (e.g., preliminary or failed experiments that   \n595 didn\u2019t make it into the paper).   \n596 9. Code Of Ethics   \n597 Question: Does the research conducted in the paper conform, in every respect, with the   \n598 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \n599 Answer: [Yes]   \n600 Justification: We submitted the paper following the NeurIPS Code of Ethics.   \n601 Guidelines:   \n602 \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n603 \u2022 If the authors answer No, they should explain the special circumstances that require a   \n604 deviation from the Code of Ethics.   \n605 \u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consid  \n606 eration due to laws or regulations in their jurisdiction).   \n607 10. Broader Impacts   \n608 Question: Does the paper discuss both potential positive societal impacts and negative   \n609 societal impacts of the work performed?   \n610 Answer: [Yes]   \n611 Justification: We discuss the positive implications of our work and ensure it does not have   \n612 any negative societal impact.   \n613 Guidelines:   \n614 \u2022 The answer NA means that there is no societal impact of the work performed.   \n615 \u2022 If the authors answer NA or No, they should explain why their work has no societal   \n616 impact or why the paper does not address societal impact.   \n617 \u2022 Examples of negative societal impacts include potential malicious or unintended uses   \n618 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n619 (e.g., deployment of technologies that could make decisions that unfairly impact specific   \n620 groups), privacy considerations, and security considerations.   \n621 \u2022 The conference expects that many papers will be foundational research and not tied   \n622 to particular applications, let alone deployments. However, if there is a direct path to   \n623 any negative applications, the authors should point it out. For example, it is legitimate   \n624 to point out that an improvement in the quality of generative models could be used to   \n625 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n626 that a generic algorithm for optimizing neural networks could enable people to train   \n627 models that generate Deepfakes faster.   \n628 \u2022 The authors should consider possible harms that could arise when the technology is   \n629 being used as intended and functioning correctly, harms that could arise when the   \n630 technology is being used as intended but gives incorrect results, and harms following   \n631 from (intentional or unintentional) misuse of the technology.   \n632 \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation   \n633 strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n634 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n635 feedback over time, improving the efficiency and accessibility of ML).   \n636 11. Safeguards   \n637 Question: Does the paper describe safeguards that have been put in place for responsible   \n638 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n639 image generators, or scraped datasets)?   \n640 Answer: [NA]   \n641 Justification: There are no concerns in this regard regarding this work.   \n642 Guidelines:   \n643 \u2022 The answer NA means that the paper poses no such risks.   \n644 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n645 necessary safeguards to allow for controlled use of the model, for example by requiring   \n646 that users adhere to usage guidelines or restrictions to access the model or implementing   \n647 safety filters.   \n648 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n649 should describe how they avoided releasing unsafe images.   \n650 \u2022 We recognize that providing effective safeguards is challenging, and many papers do   \n651 not require this, but we encourage authors to take this into account and make a best   \n652 faith effort.   \n653 12. Licenses for existing assets   \n654 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n655 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n656 properly respected?   \n657 Answer: [Yes]   \n658 Justification: The data and code used in our work are all publicly available and open-source.   \n659 Guidelines:   \n660 \u2022 The answer NA means that the paper does not use existing assets.   \n661 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n662 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n663 URL.   \n664 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n665 \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of   \n666 service of that source should be provided.   \n667 \u2022 If assets are released, the license, copyright information, and terms of use in the   \n668 package should be provided. For popular datasets, paperswithcode.com/datasets   \n669 has curated licenses for some datasets. Their licensing guide can help determine the   \n670 license of a dataset.   \n671 \u2022 For existing datasets that are re-packaged, both the original license and the license of   \n672 the derived asset (if it has changed) should be provided.   \n673 \u2022 If this information is not available online, the authors are encouraged to reach out to   \n674 the asset\u2019s creators.   \n675 13. New Assets   \n676 Question: Are new assets introduced in the paper well documented and is the documentation   \n677 provided alongside the assets?   \n678 Answer: [NA]   \n679 Justification: The paper currently does not include any new assets.   \n680 Guidelines:   \n681 \u2022 The answer NA means that the paper does not release new assets.   \n682 \u2022 Researchers should communicate the details of the dataset/code/model as part of their   \n683 submissions via structured templates. This includes details about training, license,   \n684 limitations, etc.   \n685 \u2022 The paper should discuss whether and how consent was obtained from people whose   \n686 asset is used.   \n687 \u2022 At submission time, remember to anonymize your assets (if applicable). You can either   \n688 create an anonymized URL or include an anonymized zip file.   \n689 14. Crowdsourcing and Research with Human Subjects   \n690 Question: For crowdsourcing experiments and research with human subjects, does the paper   \n691 include the full text of instructions given to participants and screenshots, if applicable, as   \n692 well as details about compensation (if any)?   \n693 Answer: [NA]   \n694 Justification: The paper does not involve crowdsourcing nor research with human subjects.   \n695 Guidelines:   \n696 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n697 human subjects.   \n698 \u2022 Including this information in the supplemental material is fine, but if the main contribu  \n699 tion of the paper involves human subjects, then as much detail as possible should be   \n700 included in the main paper.   \n701 \u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation,   \n702 or other labor should be paid at least the minimum wage in the country of the data   \n703 collector.   \n704 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human   \n705 Subjects   \n706 Question: Does the paper describe potential risks incurred by study participants, whether   \n707 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n708 approvals (or an equivalent approval/review based on the requirements of your country or   \n709 institution) were obtained?   \n710 Answer: [NA]   \n711 Justification: The paper does not involve crowdsourcing nor research with human subjects.   \n712 Guidelines:   \n713 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n714 human subjects.   \n715 \u2022 Depending on the country in which research is conducted, IRB approval (or equivalent)   \n716 may be required for any human subjects research. If you obtained IRB approval, you   \n717 should clearly state this in the paper.   \n718 \u2022 We recognize that the procedures for this may vary significantly between institutions   \n719 and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the   \n720 guidelines for their institution.   \n721 \u2022 For initial submissions, do not include any information that would break anonymity (if   \n722 applicable), such as the institution conducting the review. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}]