[{"type": "text", "text": "Learning to Price Homogeneous Data ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Keran Chen Joon Suk Huh Kirthevasan Kandasamy UW-Madison UW-Madison UW-Madison kchen429@wisc.edu jhuh23@wisc.edu kandasamy@cs.wisc.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study a data pricing problem, where a seller has access to $N$ homogeneous data points (e.g. drawn i.i.d. from some distribution). There are $m$ types of buyers in the market, where buyers of the same type $i$ have the same valuation curve $v_{i}\\,:\\,[N]\\,\\rightarrow\\,[0,1]$ , where $v_{i}(n)$ is the value for having $n$ data points. A priori, the seller is unaware of the distribution of buyers, but can repeat the market for $T$ rounds so as to learn the revenue-optimal pricing curve $p\\bar{\\mathbf{\\Omega}}\\colon[N]\\to[0,1]$ . To solve this online learning problem, we first develop novel discretization schemes to approximate any pricing curve. When compared to prior work, the size of our discretization schemes scales gracefully with the approximation parameter, which translates to better regret in online learning. Under assumptions like smoothness and diminishing returns which are satisfied by data, the discretization size can be reduced further. We then turn to the online learning problem, both in the stochastic and adversarial settings. On each round, the seller chooses an anonymous pricing curve $p_{t}$ . A new buyer appears and may choose to purchase some amount of data. She then reveals her type only $i f$ she makes a purchase. Our online algorithms build on classical algorithms such as UCB and FTPL, but require novel ideas to account for the asymmetric nature of this feedback and to deal with the vastness of the space of pricing curves. Our algorithms achieve $\\widetilde{\\mathcal{O}}(m\\sqrt{T})$ regret in the stochastic setting and $\\widetilde{\\mathcal{O}}(m^{3/2}\\sqrt{T})$ regret in the adversarial setting. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Due to the rise in popularity of machine learning, there is an increased demand for data. However, not all users of data have the wherewithal to collect data on their own, and have to rely on data marketplaces to acquire the data they need. For example, a materials data platform (e.g. [18]), may have collected vast amounts of data from various proprietary sources. Materials scientists in smaller organizations and academia, who do not have large experimental apparatuses, may wish to purchase this data to aid in their research. Similarly, small businesses may wish to purchase customer data for advertising and product recommendations [4, 5], while small technology companies may wish to purchase data about cloud operations to optimize their computing infrastructure [2, 3]. ", "page_idx": 0}, {"type": "text", "text": "Model. Motivated by the emergence of such data marketplaces, we study the following online data pricing problem. A seller has access to $N$ homogeneous data points, (e.g. drawn i.i.d. from some distribution). He wishes to sell the data to a sequence of distinct buyers over $T$ rounds, and intends to achieve large revenue. There are $m$ types of buyers in the data marketplace, with all buyers in type $i$ having the same valuation curve $v_{i}\\bar{:}[N]\\rightarrow[\\dot{0},1]$ for the data, where $v_{i}(n)$ represents the buyer's value for having $n$ points. As data is homogeneous, we can treat an agent's value as a function of the amount of data $n$ (we will illustrate this in the sequel). Valuation curves are monotone non-decreasing, as more data is better. At each round $t$ , the seller chooses a price curve $p_{t}:[N]\\to[0,1]$ ,where $p_{t}(n)$ is the price for purchasing $n$ data points. Then, a buyer with type $i_{t}$ arrives and purchases an amount of data that maximizes her utility (value minus price), provided that she can achieve non-negative utility. A buyer will reveal her type to the seller only $i f$ she makes a purchase, and only after she makes the purchase. The seller has knowledge of valuation curves of the $m$ types, but does not know the distribution $q$ over types (stochastic setting), or the buyer sequence (adversarial setting). Moreover, he cannot practice non-anonymous (discriminatory) pricing, as he needs to choose the pricingcurve $p_{t}$ without knowledge of the buyer's type on that round. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "While there is extensive research on revenue-optimal pricing and learning to price, data marketplaces merit special attention, both due to their recent emergence and the unique characteristics of data. Typically the number of data $N$ (number of goods) is very large, but data usually satisfies additional properties such as smoothness (an agent's value does not increase significantly with a small amount of additional data) and diminishing returns (additional data is more valuable when a buyer has less data). To illustrate further, note that two steps are essential to develop an effective online learning solution for data pricing. $(I)$ First, we need to solve the planning problem, i.e. find a revenue-optimal pricing curve when the type distribution $q$ is known. (2) Second, when $q$ is unknown, we need to combine the algorithm in step (1) with estimates for $q$ to maximize long-term revenue. ", "page_idx": 1}, {"type": "text", "text": "Methods in the existing literature fall short in both steps. $(I)$ When the type distribution $q$ is known, the data pricing problem resembles an ordered item pricing problem, which is known to be NP-hard [13, 25]. Hence, prior work has aimed at approximating the optimal pricing curves via discretization schemes. Unfortunately, existing discretization schemes have poor, often exponential, dependence on the approximation parameter $\\epsilon$ . However, achieving sublinear regret in online learning requires choosing $\\epsilon$ that vanishes with longer time horizons, i.e. $\\epsilon\\to0$ as $T\\to\\infty$ . Therefore, directly using existing discretization schemes in an online setting leads to poor statistical and computational properties of the associated online algorithm. This requires us to leverage the above properties of data to design discretization schemes with better dependence on e. (2) While there is prior work on learning optimal prices [22, 27, 33], these techniques either fall short of addressing the complexities in our setting, or fail to account for the properties of data, and hence do not scale gracefully when the amount of data $N$ is very large. Moreover, in our online learning setup, the seller faces a trade-off between setting high prices to maximize instantaneous revenue versus setting low prices so as to guarantee a purchase, which results in the buyer revealing their type, which in turn can be helpful in future rounds. Prior work has studied this asymmetric feedback model only in single-item markets which is significantly simpler, and only in the stochastic setting [23, 47]. ", "page_idx": 1}, {"type": "text", "text": "1.1  Summary of our contributions ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Our contributions in this work are threefold: $(I)$ First, in $\\S3$ , we develop discretization schemes for revenue-optimal data pricing under a variety of assumptions, which we will use later in our online learning schemes. (2) In $\\S4$ , we study learning a revenue-optimal price in a stochastic setting, where the customer types on each round are drawn from a fixed but unknown distribution $q$ (3) Finally, in $\\S5$ , we study online learning when the buyer types are chosen by an oblivious adversary. ", "page_idx": 1}, {"type": "text", "text": "1. Discretization (approximation) schemes for revenue-optimal data pricing. Assuming only monotonicity, we show that there is a discretization of size $\\widetilde{\\mathcal{O}}((N/\\epsilon)^{m})$ which is an $O(\\epsilon)$ additive approximation to any pricing curve. When compared to prior work [14, 25], our discretization scheme has smaller dependence on $\\bar{\\epsilon}^{-1}$ when the number of types $m$ is small (see Table 1). This will be useful, both statistically and computationally, when we study the online setting, as we need to choose $\\epsilon\\rightarrow0$ as $T\\rightarrow\\infty$ to achieve sublinear regret. This is still quite large in real-world data marketplaces, where $N$ may be very large. Hence, we also study two other assumptions. First, when valuations are smooth, satisfying an $L$ -Lipschitz-like condition, we construct a discretization of size $\\widetilde{\\cal O}\\left((L/\\epsilon^{2})^{m}\\right)$ , which has no dependence on $N$ . Next, under a diminishing returns condition, we construct a discretization of size $\\mathcal{O}^{*}(J^{m}\\epsilon^{-3m}\\log^{m}(N))$ , which only has polylogarithmic dependence on $N$ ", "page_idx": 1}, {"type": "text", "text": "Key insights. We first show that when there are only $m$ types, for any price function $p:[N]\\to[0,1]$ there exists an \u201c $^{\\cdot}m$ -step\"\u201d price function $p^{\\prime}$ whose revenue is at least as much as that of $p$ on any type distribution $q$ .An $m$ -step function is non-decreasing and changes values at most $m$ times, allowing us to focus on this restricted class and thereby reduce the search space when $m\\ll N$ .We then consider discretizations of the data space $[N]$ and valuations $[0,1]$ which allow us to obtain an $O(\\epsilon).$ -approximation to any pricing curve, and then apply this insight to construct our discretizations. Finally, we show that with monotonicity and diminishing returns, similarly accurate approximations are attainable with substantially coarser discretizations. ", "page_idx": 1}, {"type": "text", "text": "2. Learning to price in the stochastic setting. Next, we turn to the online learning problem described in the beginning in a stochastic setting. On each round, our algorithm computes an ", "page_idx": 1}, {"type": "table", "img_path": "KoyTqNs6SZ/tmp/e0d204bb8eb0db462efecd4a1304c857c411034a7fa75e1eb6d0fe53930530d8.jpg", "table_caption": [], "table_footnote": [], "page_idx": 2}, {"type": "text", "text": "Table 1: Comparison of discretization (approximation) schemes of prior work and our methods under various assumptions. All methods achieve a $O(\\epsilon)$ additive approximation to any pricing curve. Here, M means Monotonicity, $\\mathbf{F}$ means that there are a Finite $(m)$ number of types, $\\mathbf{S}$ means that the valuation curves satisfy a $L$ -Lipschitz-like Smoothness condition (Assumption 1), and $\\mathbf{D}$ means that they satisfy a Diminishing returns condition (Assumption 2). The $\\widetilde O$ notation suppresses log dependencies when there is already a polynomial dependence on a parameter. Prior work has exponential dependence in either $N$ or $\\epsilon^{-\\bar{1}}$ . We wish to do better since $(i)$ typically, the number of data $N$ is very large and $(i i)$ we need $\\epsilon\\rightarrow0$ as $T\\to\\infty$ to achieve sublinear regret. ", "page_idx": 2}, {"type": "text", "text": "upper confidence bound (UCB) [8, 38] on the revenue for each price curve in the discretization previously developed; we then choose the price curve with the highest UCB. As summarized in Table 2, this algorithm achieves a $\\widetilde{\\mathcal{O}}(m\\sqrt{T})$ bound on the regret for any discretization scheme, including those from prior work. In the stochastic setting, the key advantage of our discretization schemes is computational. ", "page_idx": 2}, {"type": "text", "text": "Key insights. Both the design and the anlaysis of an algorithm is challenging in this setting due to tworeasons: $(i)$ the large size of the discretization and $(i)$ the asymmetric nature of feedback. First, naively maintaining UCBs for each price leads to large confidence intervals, and hence large regret as the size of the discretization is large; instead, we construct confidence intervals on estimates of the type distribution, and translate them to UCBs for the revenue. Second, the asymmetric nature of the feedback places us between bandit and full-information settings. Treating this like a bandit setting would lead to poor, exponential dependence on $m$ in the regret. However, we are unable to treat this as full information since the type distribution is revealed only if there is a purchase. Handling this asymmetry requires a delicate construction of the UCB. ", "page_idx": 2}, {"type": "text", "text": "3. Learning to price in the adversarial setting. We study learning in an adversarial setting where the types on each round may be chosen adversarially. Table 2 shows the regret and time complexity of our method when paired with various discretization schemes. In the adversarial setting, our discretization schemes offer both computational and statistical advantages compared to prior work. ", "page_idx": 2}, {"type": "text", "text": "Key insights. Our algorithm builds on the Follow-the-Perturbed-Leader (FTPL) [31], originally designed for full-information settings and not directly applicable here. To handle asymmetric feedback, we use the information we have about the valuation curves to keep track of which customers would not have made a purchase given a price curve. If a purchase is made and we observe feedback, we use the usual FTPL update, but if not, we reward each pricing curve with the sum of revenue of all types that would not purchase in that current round. ", "page_idx": 2}, {"type": "text", "text": "1.2  Related work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Dynamic pricing. The online posted-price mechanism, also known as dynamic pricing, is a central research area in algorithmic market design [19, 33]. In the most classical setting [33], the seller sets a price for an item in each round, and a buyer purchases the item only if their valuation exceeds the posted price. While several extensions of this setting have been explored for both parametric [12, 20, 28, 29, 32, 46] and non-parametric [11, 17, 39, 40, 44] demands, most focus on single-parameter demands, i.e., selling a single item to buyers. Our data pricing problem is multi-parameter, as demands are parameterized by multiple outcomes, i.e. the number of data points. ", "page_idx": 2}, {"type": "text", "text": "Bayesian unit-demand pricing problem. Formally, our data pricing problem is a variant of the Bayesian Unit-demand Pricing Problem (BUPP) [13]. BUPP addresses the problem of (offline) revenue maximization over a known distribution of unit-demand buyers, meaning they want to buy at ", "page_idx": 2}, {"type": "table", "img_path": "KoyTqNs6SZ/tmp/a2d67ec955f947129a6e2acb128365d892a13053220d85222afebcd645641f4a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 3}, {"type": "text", "text": "Table 2: Comparison of regret and time complexity of our online learning methods when paired with our discretization schemes and schemes from prior work. See Table 1 for a description of the assumptions. All methods, including [14, 25] achieve $\\mathcal{O}(m\\sqrt{T})$ regret in the stochastic setting. ", "page_idx": 3}, {"type": "text", "text": "most one item from the inventory. In BUPP, a seller has $N$ distinct items to sell to a unit-demand buyer whose valuations are $\\boldsymbol{v}=(v_{1},\\dots,v_{N})$ , where $v_{i}$ is the value of the $i$ th item. Given prices $p_{i}$ $i\\in[N]$ , the unit-demand buyer purchases a single item $i\\,\\in\\,[N]$ that maximizes their utility: $v_{i}-p_{i}$ . Assuming the valuation profile $v$ follows a known distribution $D$ , the goal of BUPP is to find the best prices $\\{p_{i}\\}_{i\\in[N]}$ that maximize the seller's expected revenue. ", "page_idx": 3}, {"type": "text", "text": "Our data pricing problem is a variant of BUPP in two ways: $(I)$ We study the sequential setting where type distributions are unknown, while valuation profiles for each type are known, and (2) We assume monotonic values $v_{1}\\leq\\dots\\leq v_{N}$ , which is natural in data pricing. Unfortunately, BUPP is a computationally intractable problem, as is ours. BUPP is known to be NP-hard even when $D$ is a product distribution [16]. Moreover, even assuming that values are monotonic (i.e., $v_{1}\\leq\\cdots\\leq v_{N})$ the problem remains (strongly) NP-hard [14]. Therefore, we aim to provide a reasonably efficient no-regret algorithm for our problem, especially when the number of types $m$ is a fixed constant. ", "page_idx": 3}, {"type": "text", "text": "The previous works most relevant to our paper are Hartline and Koltun [25] and Chawla et al. [14], which study offline revenue maximization for unit-demand buyers. Buyers in our problem are also unitdemand, as each amount of data points can be seen as an individual item. Revenue maximization for unit-demand buyers is known to be computationally intractable [24], even with ordered (monotonic) buyer values [14], leading these works to focus on approximation algorithms. Hartline and Koltun [25] proposed an approximation algorithm with near-linear runtime in the number of buyers, given a fixed number of items. Chawla et al. [14] introduced a polynomial-time approximation scheme (PTAS) for unit-demand buyers with monotonic values. In this work, we extend the framework to the online setting with partial feedback, which has more practical implications. ", "page_idx": 3}, {"type": "text", "text": "In addition, Balcan and Beyhaghi [10] provide new guarantees for learning revenue-maximizing menus of lotteries and two-part tariffs, demonstrating that their discretization technique yields efficient solutions for specific pricing models. Similar discretization methods could be investigated in future work to potentially improve our approach in more complex data pricing scenarios. ", "page_idx": 3}, {"type": "text", "text": "Market design for data-sharing. In recent years, there has been a plethora of work devoted to algorithmic market design for data sharing [6, 7, 30, 43]. These works provide ingenious solutions to challenges unique to the data market, such as free replicability and the difficulty of valuation due to the combinatorial nature of data. Except for Agarwal et al. [6], the above-cited solutions are inherently offline or single-shot. While we focus on a simplified yet relevant setting where data comes from a single source, resulting in monotonic valuations, in this work, we tackle the problem in a sequential, dynamic setting, which has practical importance. In contrast to our approach, Agarwal et al. [6] considered the price to be a constant (i.e., a scalar rather than a price vector) to address the inherent computational intractability of multi-dimensional pricing. Instead, we maintain the price as a vector (i.e., a price function) but focus on cases where the valuation function satisfies natural properties such as monotonicity, smoothness, and diminishing returns. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "2  Problem setting, assumptions, and challenges ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "A seller has $N$ homogeneous data points. There are $m$ types of buyers who wish to purchase this data. A buyer of type $i\\in[m]$ has a valuation curve $v_{i}:[N]\\to[0,1]$ , where $v_{i}(n)$ is her value for $n$ data points. We will assume $v_{i}(n)$ is non-decreasing as more data is valuable, and further that $v_{i}(0)=0$ ", "page_idx": 4}, {"type": "text", "text": "Example 1. To motivate this model, consider a seller with $N$ ordered data points $\\{x_{1},\\ldots,x_{N}\\}$ drawn i.i.d. from a distribution $D$ . If a buyer purchases $n$ points, she receives the first $n$ points, $X_{n}=\\{x_{1},\\ldots,x_{n}\\}$ . Her ex-post value $\\widetilde{v}_{i}(X_{n})$ may represent the accuracy of her ML model trained with $X_{n}$ . However, as the buyer has not seen the data before the purchase, she does not know which specific points she will receive, and hence her (ex-ante) value $v_{i}\\bar{(n)}=\\mathbb{E}_{X_{n}}[\\widetilde{v}_{i}(X_{n})]$ is the expected model accuracy when $n$ i.i.d points are drawn from $D$ . The different types could be buyers who use the data for different tasks or models. For instance, with ImageNet's [21], $N\\approx1.4$ million data points, different types of buyers could perform different learning tasks such as object detection, identification, and segmentation, and/or train different models such as AlexNet [36], ResNet [26], and GoogLeNet [42]. Both empirically and theoretically, for many learning tasks, $v_{i}(n)$ is non-decreasing, and satisfies additional characteristics such as smoothness and/or diminishing returns. ", "page_idx": 4}, {"type": "text", "text": "Pricing curves, buyer utility, and buyer purchase model. Let $p:[N]\\to[0,1]$ be a pricing curve chosen by the seller. Let $\\mathcal{P}\\triangleq\\{p:[N]\\to[0,1]:\\ p(0)=0\\}$ denote the set of all pricing curves. If a buyer purchases $n$ points, her utility is $u_{i}(n)=v_{i}(n)-p(n)$ . If a buyer can achieve non-negative utility, i.e. $v_{i}(n)\\geq p(n)$ for some $n\\in[N]$ , she will purchase an amount of data to maximize her utility. To fully specify the buyer's purchase model, we will assume that when there are multiple $n$ which maximizes her utility, she wili choose the largest such $n$ . Formally, for a given pricing curve $p$ a buyer of type $i$ will purchase $n_{i,p}$ points where, ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{n_{i,p}\\triangleq\\left\\{\\begin{array}{l l}{0\\quad}&{\\mathrm{if~}v_{i}(n)<p(n)\\mathrm{~for~all~}n\\in[N],}\\\\ {\\operatorname*{max}\\big\\{\\operatorname{argmax}_{n\\in[N]}\\big(v_{i}(n)-p(n)\\big)\\big\\}\\quad}&{\\mathrm{otherwise.}}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Optimal revenue. It follows that the revenue from a buyer of type is $p(n_{i,p})$ . Let $q=(q_{1},\\ldots,q_{m})$ be the distribution of the buyers. Under this distribution $q$ , the expected revenue $\\operatorname{rev}(p)$ for a price curve $p$ , the optimal price $p^{\\dot{\\mathrm{OPT}}}$ , and the optimal revenue OPT as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathrm{rev}(p)\\triangleq\\sum_{i=1}^{m}q_{i}\\cdot p(n_{i,p}),\\qquad\\quad p^{\\mathrm{opr}}\\triangleq\\underset{p\\in\\mathcal{P}}{\\mathrm{argmax}}\\,\\mathrm{rev}(p),\\qquad\\quad\\mathrm{OPT}\\triangleq\\mathrm{rev}(p^{\\mathrm{opr}}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We have omitted the dependence on $q$ in rev, $p^{\\mathrm{opT}}$ , and OPT. There is no closed-form solution to finding the optimal pricing curve, even when $q$ is known. Therefore, in $\\S3$ , we explore discretization methods to approximate $\\bar{p}^{\\mathrm{OPT}}$ , which will then be used in $\\S4$ and $\\S5$ to develop online learning algorithms. Unfortunately, the size of this discretization can be very large in $N$ and $m$ without further assumptions. Therefore, we also consider two additional commonly satisfied conditions by data. ", "page_idx": 4}, {"type": "text", "text": "Our first such assumption states that buyer valuation curves satisfy a Lipschitz-like smoothness condition with Lipschitz constant $L/N$ .Weuse $L/N$ instead of $L$ since the number of data has a range $[0,N]$ , while the valuations only have a range $[0,1]$ . This condition states that a buyer's valuation does not change significantly if she only purchases a few additional points. ", "page_idx": 4}, {"type": "text", "text": "Assumption 1 (Smoothness, S). For all $n,n^{\\prime}\\in[N]$ we have $\\begin{array}{r}{v_{i}(n+n^{\\prime})-v_{i}(n)\\leq\\frac{L}{N}n^{\\prime}.}\\end{array}$ ", "page_idx": 4}, {"type": "text", "text": "Our second condition is based on the fact that data typically exhibits diminishing returns [34, 35].   \nThis means that an additional data point is more valuable when there is less data, i.e. $v_{i}(n\\,{+}\\,1)\\,{-}\\,v_{i}(n)$   \nisdecreasingwith $n$ . We will in fact make a stronger assumption, and justify it below. ", "page_idx": 4}, {"type": "text", "text": "Assumption 2 (Diminishing returns, $\\mathbf{D}$ .There exists some $J>0$ such that, for all types $i\\in[m]$ and for all $n\\in[N]$ we have $\\begin{array}{r}{v_{i}(n+1)-v_{i}(n)\\leq\\frac{J}{n}}\\end{array}$ ", "page_idx": 4}, {"type": "text", "text": "Assumption 2 quantifies the rate of decrease of diminishing returns. Following Example 1, the valuation (accuracy) curves for many learning problems take the form $v_{i}(n)\\,\\,\\bar{=}\\,\\,\\alpha\\,-\\,\\bar{\\beta}n^{-\\gamma}$ ;for instance, for binary classification in a VC class $\\mathcal{H}$ \uff0c $\\alpha$ may be the best accuracy in $\\mathcal{H}$ \uff0c $\\beta\\in\\mathcal{O}(\\sqrt{d_{\\mathcal{H}}})$ where $d_{\\mathcal{H}}$ is the VC dimension, and $\\gamma=1/2$ [41]; similarly, for nonparametric regression of a twice differentiable function, $\\alpha$ and $\\beta$ are constants while $\\gamma=2/5$ [45]. In such cases, Assumption 2 is satisfied with $J=\\beta\\gamma$ . Note that neither assumption subsumes the other: a non-concave Lipschitz function will not satisfy Assumption 2, while a suitable $L$ for a function which satisfies Assumption 2 may need to be very large for Assumption 1 to hold for small $n$ ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "2.1  Learning to price in online settings ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this work, we will also study how a seller may learn to maximize revenue. In our learning problem, the seller is aware of the valuation curves $\\{v_{i}\\}_{i}$ of each type, but does not know the distribution of types (stochastic setting) or there may be no such distribution (adversarial setting). ", "page_idx": 5}, {"type": "text", "text": "Setup.  The seller repeats the data market for $T$ rounds. At the beginning of each round, he chooses some price curve $p_{t}\\in\\mathcal{P}$ . After the seller has chosen $p_{t}$ , a new buyer of type $i_{t}\\in[m]$ appears and purchases $n_{t}=n_{i_{t},p_{t}}$ amount of data (see (1)). The buyer is aware of her own valuation curve. If she makes a purchase, that is if $n_{t}>0$ , she pays $p_{t}(n_{t})$ to the seller and reveals her type $i_{t}$ . Otherwise, the buyer will make no payment and not reveal her type. ", "page_idx": 5}, {"type": "text", "text": "We have assumed that a priori,the seller is aware of the buyer valuation curves $\\{v_{i}\\}_{i\\in[m]}$ and that buyers are aware of their own valuation curves. In Example 1, a seller can profile how different machine learning models perform with different amounts of data and publish them ahead of time. The buyers can also gauge their value from these curves, even though they do not have access to the data. Next, we have also assumed that buyers will reveal their type after the purchase. In modern machine learning as a service platforms [1, 4, 18], buyers directly run their jobs in the seller's computing platform, so the seller can observe the buyers job type directly. Even if this is not the case, sellers can elicit this information via questionnaires and reviews from customers who have made a purchase [23]. ", "page_idx": 5}, {"type": "text", "text": "Challenges. Despite these assumptions, the learning problem remains challenging_ for two main reasons. First, the space of price curves is vast: discretizing the valuations in $[0,1]$ into $K$ bins, stillleaves $\\mathcal{O}(K^{N})$ possible price curves, which is both statistically and computationaily intractable, especially for large $N$ . Second, in addition to the exploration-exploitation trade-off usually encountered in sequential decision-making, the seller faces a tension between high instantaneous revenue and information acquisition: setting high prices can yield high immediate revenue if a purchase occurs, but it also increases the risk of no purchase, resulting in no revenue and crucially no feedback about the buyer type which could help him in future rounds. This trade-off was recently studied for single-item markets in a stochastic setting [23, 47], but is more complex in our multi-item problem. Moreover, to our knowledge, no existing work addresses this asymmetric feedback model in an adversarial setting, even for single-item markets. Next, we describe the buyer arrival model and define the regret for the learning problem in both stochastic and adversarial settings. ", "page_idx": 5}, {"type": "text", "text": "Stochastic setting. Here, there is some fixed but unknown distribution of types $q$ . On each round, a buyer of type $i_{t}\\sim q$ is drawn independently. The optimal expected revenue OPT under type distribution $q$ is as defined in (2). The regret $R_{T}$ is as defined below. We wish to design algorithms which have small expected regret $\\mathbb{E}[R_{T}]$ , where the expectation accounts for both the sampling of types $i_{t}\\sim q$ and any randomness in the algorithm. We have, ", "page_idx": 5}, {"type": "equation", "text": "$$\nR_{T}\\;\\stackrel{\\Delta}{=}\\;T\\cdot\\mathrm{OPT}\\,-\\,\\sum_{t=1}^{T}p_{t}(n_{t})\\;=\\;T\\cdot\\mathrm{OPT}\\,-\\,\\sum_{t=1}^{T}p_{t}(n_{i_{t},p_{t}}).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Adversarial setting. Here, the types on each round $\\{i_{t}\\}_{t=1}^{T}$ are chosen arbitrarily, possibly by an oblivious adversary, ahead of time. The type on round $t$ is revealed to the seller only at the end of the round, and only if there is a purchase. In the adversarial setting, we define our regret $R_{T}$ with respect to the single best price in $\\mathcal{P}$ in hindsight. We wish to design algorithms with small expected regret $\\mathbb{E}[R_{T}]$ , where the expectation is with respect to any randomness in the algorithm. We have, ", "page_idx": 5}, {"type": "equation", "text": "$$\nR_{T}\\;\\stackrel{\\Delta}{=}\\;\\operatorname*{max}_{p\\in\\mathcal{P}}\\sum_{t=1}^{T}p(n_{i_{t},p})\\;-\\;\\sum_{t=1}^{T}p_{t}\\big(n_{i_{t},p_{t}}\\big).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Algorithm 1 Price discretization scheme under monotonicity ", "page_idx": 6}, {"type": "text", "text": "Given: Approximation parameter $\\epsilon>0$ Let $W$ be discretization of the valuation space $[0,1]$ defined as follows, ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{{Z_{i}\\triangleq\\left\\{\\epsilon(1+\\epsilon)^{i};\\quad\\forall\\,i\\in\\left\\{0,1,\\ldots,\\left\\lceil\\log_{1+\\epsilon}\\frac{1}{\\epsilon}\\right\\rceil\\right\\}\\right\\},}}\\\\ {{W_{i}\\triangleq\\left\\{Z_{i-1}+Z_{i-1}\\cdot\\frac{\\epsilon k}{m};\\ \\forall k\\in\\{1,2,\\ldots,\\lceil(2+\\epsilon)m\\rceil\\}\\right\\},\\quad W\\stackrel{\\Delta}{=}\\bigcup_{i=1}^{\\left\\lceil\\log_{1+\\epsilon}\\frac{1}{\\epsilon}\\right\\rceil}W_{i}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Set $\\overline{{\\mathcal{P}}}$ to be the class of all \u201c $m$ -step\" functions mapping $[N]$ to $W$ ", "page_idx": 6}, {"type": "text", "text": "3  Efficient discretization of price curves with small errors ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We first study the revenue maximization problem in the offline setting, where the seller knows both the valuation curves $v_{i},i\\in[m]$ , and the type distribution $q$ . Our goal is to design a discretization so as to achieve revenue within a gap of $O(\\epsilon)$ from OPT. Before discussing our discretization algorithms, we first show that the optimal pricing curve is \u201csimple\u201d when there are at most $m$ types. ", "page_idx": 6}, {"type": "text", "text": "Lemma 3.1. Assume there are m types with non-decreasing value curves $\\{v_{i}\\}_{i\\in[m]}$ . For any nondecreasing price curve $p$ there exists an\u201c $m$ -step\"price curve $\\bar{p}$ that yields expected revenue at least thatof $p$ with respect to any distribution over the $m$ types. Here, $m$ -step refers to non-decreasing functions $f:[N]\\to[0,1]$ where $f(n+1)-f(n)>0$ in at most m points (i.e., at most m jumps). ", "page_idx": 6}, {"type": "text", "text": "Lemma 3.1, proven in Appendix A.1, will be an important tool in all three discretization algorithms of this section. It will allow us to reduce the space of pricing curves as we only need to focus on $m$ -step price curves. Next, we present our first discretization procedure in Algorithm 1, which only assumes the monotonicity of the valuation curves. ", "page_idx": 6}, {"type": "text", "text": "Discretization scheme under monotonic valuations.  Our discretization proecdure, outlined in Algorithm 1, adapts the method in Hartline and Koltun [25] using Lemma 3.1. For this, we will first construct a discretization $W$ of the valuation space as follows. Let $Z_{i}~=~\\epsilon(1+\\epsilon)^{i}$ $i=0,1,\\dots,\\left\\lceil\\log_{1+\\epsilon}\\frac{1}{\\epsilon}\\right\\rceil$ be the powers of $(1+\\epsilon)$ on price space $[\\epsilon,1]$ . For each $i$ we let $W_{i}$ be a uniform discretization of the interval $[Z_{i-1},Z_{i+1})$ uniformly with gap $Z_{i-1}\\cdot\\frac{\\epsilon}{m}$ . Finally, let $W$ be the union of all such $W_{i}$ . According to Lemma 3.1, every price function in $\\mathcal{P}$ has the same revenue as an $m$ -step function. We set $\\overline{{\\mathcal{P}}}$ to be all choices of non-decreasing $m$ -step functions that take value in $W$ . We have the following theorem about Algorithm 1 which we prove in Appendix A.2. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.1. Consider the discretization $\\overline{{\\mathcal{P}}}$ as constructed in Algorithm 1. For any type distribution, there exists $p~\\in~\\overline{{\\mathcal{P}}}$ suchthat $\\mathrm{rev}(p)\\;\\geq\\;\\mathrm{OPT}\\,-\\,\\mathcal{O}(\\epsilon)$ .Moreover, we have $|\\overline{{\\mathcal{P}}}|\\ \\leq$ $\\begin{array}{r}{\\left(\\frac{e(N-1)}{m}\\right)^{m}\\left(e\\lceil(2+\\epsilon)\\rceil\\left\\lceil\\log_{1+\\epsilon}\\frac{1}{\\epsilon}\\right\\rceil\\right)^{m}\\in\\widetilde{\\mathcal{O}}\\left(\\left(\\frac{N}{\\epsilon}\\right)^{m}\\right)}\\end{array}$ ", "page_idx": 6}, {"type": "text", "text": "Discretization scheme for smooth monotonic valuations. Due to space constraints, we present our algorithm, under Assumption 1 in Appendix A.4. We have the following theorem about Algorithm 5. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.2. Consider the discretization $\\overline{{\\mathcal{P}}}$ asconstructedinAlgorithm5.UnderAssumption $^{\\,l}$ \uff0c for any type distribution, there exists $p\\in\\overline{{\\mathcal{P}}}$ such that $\\mathrm{rev}(p)\\geq\\mathrm{\\bar{O}P T}-{\\mathcal{O}}(\\epsilon)$ .Moreover, $|{\\overline{{\\mathcal{P}}}}|\\in$ $\\begin{array}{r}{\\mathcal{O}\\left(\\log_{1+\\epsilon}^{m}\\left(1/\\epsilon\\right)\\cdot\\left(L/\\epsilon\\right)^{m}\\right)\\in\\widetilde{\\mathcal{O}}\\left(\\left(\\frac{L}{\\epsilon^{2}}\\right)^{m}\\right)}\\end{array}$ ", "page_idx": 6}, {"type": "text", "text": "Discretization scheme for monotone valuations under diminishing returns. Finally, we study dis  \ncretization schemes under the diminishing returns condition. Our procedure, outlined in Algorithm 2   \nproceeds as follows. We use the same discretization $W$ of the valuation space from Algorithm 1.   \nNext, we will discretize the dataspace $[N]$ . To exploit the structure in the diminishing returns   \ncondition we wil ned to do so more densely when $n$ is seall For this,let $\\begin{array}{r}{Y_{i}=\\frac{2J m}{\\epsilon^{2}}\\bar{(}1+\\epsilon^{2})^{i}}\\end{array}$   \n$i=0,\\ldots,\\lceil\\log_{1+\\epsilon^{2}}\\frac{N\\epsilon^{2}}{2J m}\\rceil$ be the powers of $(1+\\epsilon^{2})$ on data space $\\left[\\frac{2J m}{\\epsilon^{2}},N\\right]$ For each $i$ the set $Q_{i}$ $[Y_{i},Y_{i+1})$ $\\begin{array}{r}{Y_{i}\\cdot\\frac{\\epsilon^{2}}{2J m}}\\end{array}$ $n$ .m\u4e38 $\\frac{2J m}{\\epsilon^{2}}$ $n$ $N_{\\mathbf{D}}$ ", "page_idx": 6}, {"type": "text", "text": "Algorithm 2 Price discretization scheme monotonic valuations under diminishing returns ", "page_idx": 7}, {"type": "text", "text": "Given: Diminishing returns constant $J$ , approximation parameter $\\epsilon$ $W\\overset{\\Delta}{=}\\bigcup_{i=2}^{\\left\\lceil\\log_{1+\\epsilon}\\frac{\\bar{1}}{\\epsilon}\\right\\rceil}W_{i}$ $W_{i}\\mathbf{s}$ Let $N_{\\mathbf{D}}$ be discretization of the interval $[0,N]$ defined as follows, ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{Y_{i}\\triangleq\\left\\lfloor\\frac{{2J m}}{{\\epsilon^{2}}}(1+\\epsilon^{2})^{i}\\right\\rfloor,\\;i=0,1,\\ldots,\\left\\lceil{\\log_{1+\\epsilon^{2}}\\left(\\frac{{N\\epsilon^{2}}}{{2J m}}\\right)}\\right\\rceil,}}\\\\ {{\\quad Q_{i}\\triangleq\\left\\{\\left\\lfloor{Y_{i}+Y_{i}\\cdot\\frac{{\\epsilon^{2}}k}{{2J m}}}\\right\\rfloor,\\;\\;k=0,1,\\ldots,\\lfloor{2J m}\\rfloor\\right\\},\\quad Q\\triangleq\\qquad\\bigcup_{i=1}^{\\left\\lceil{\\log_{1+\\epsilon^{2}}\\left(\\frac{{N\\epsilon^{2}}}{{2J m}}\\right)}\\right\\rceil}Q_{i},}}\\\\ {{\\quad N_{\\mathbf{D}}\\triangleq\\left\\{1,2,\\ldots,\\left\\lfloor{\\frac{{2J m}}{{\\epsilon^{2}}}}\\right\\rfloor\\right\\}\\cup Q.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The discretization price set $\\overline{{\\mathcal{P}}}$ is the class of all \u2018 $m$ -step\" price curves on function space $N_{\\mathbf{D}}\\rightarrow W$ ", "page_idx": 7}, {"type": "text", "text": "$\\left\\{1,2,\\dots,\\left\\lfloor{\\frac{2J m}{\\epsilon^{2}}}\\right\\rfloor\\right\\}$ $Q_{i}$ $N_{\\mathbf{D}}$ $\\scriptstyle{\\frac{2J m}{\\epsilon^{2}}}+2J m\\left[\\log_{1+\\epsilon^{2}}{\\frac{N\\epsilon^{2}}{2J m}}\\right]$ ", "page_idx": 7}, {"type": "text", "text": "Theorem 3.3. Consider the discretization $\\overline{{\\mathcal{P}}}$ as constructed in Algorithm 2. Under Assumption 2, for any type distribution, there exists $p\\in\\overline{{\\mathcal{P}}}$ suchthatre $\\mathfrak{x}(p)\\geq\\mathrm{OPT}-\\mathcal{O}(\\epsilon)$ Moreover, ", "page_idx": 7}, {"type": "equation", "text": "$$\n|\\overline{{\\mathcal{P}}}|\\in\\mathcal{O}\\left(\\left(\\frac{J}{\\epsilon^{2}}\\right)^{m}\\log^{m}\\left(\\frac{N\\epsilon^{2}}{J m}\\right)\\cdot\\left(\\log_{1+\\epsilon}^{m}1/\\epsilon\\right)\\right)\\in\\widetilde{\\mathcal{O}}\\left(\\left(\\frac{J}{\\epsilon^{3}}\\right)^{m}\\right).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Proof outine.By Lemma3.1, we may assume the optimal pric curve $p^{\\star}=\\{(n_{i}^{\\star},p_{i}^{\\star})\\}_{i=1}^{m}$ is an $m$ -step function, where $p_{i}^{\\star}$ denote the value of $p$ on step $i$ .We generate an $m$ -step price curve $\\boldsymbol{p}=\\{\\dot{(n_{i},p_{i})}\\}_{i=1}^{m}$ on space $N_{\\mathbf{D}}\\rightarrow W$ such that $n_{i}$ isobtainedbyroundingdown $n_{i}^{\\star}$ to the closest value in $N_{\\mathbf{D}}$ , and $p_{i}\\geq{p_{i}^{\\star}}/{(1+\\epsilon)}$ . We then show that if a buyer purchases at step $i$ under price $p^{\\star}$ she will not purchase at step $j<i$ under new price $p$ . Therefore, the revenue from this buyer is at least $p_{i}\\geq p_{i}^{\\star}/(1+\\epsilon)=p_{i}^{\\star}\\stackrel{\\_}{-}\\mathcal{O}(\\epsilon)$ , which ensures that r $\\mathrm{ev}(p)\\geq\\mathrm{OPT}-{\\mathcal{O}}(\\epsilon)$ \uff1a ", "page_idx": 7}, {"type": "text", "text": "4   Online learning in the stochastic setting ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We now study the online learning problem outlined in $\\S2.1$ in the stochastic setting. Our Algorithm, outlined in Algorithm 3 is based on the classical upper confidence bound (UCB) algorithm for stochastic bandits [8, 38]. It takes a discretization $\\overline{{\\mathcal{P}}}$ of the pricing curves as input, and on each round chooses a $p_{t}\\in\\overline{{\\mathcal{P}}}$ which has the largest UCB on the revenue. ", "page_idx": 7}, {"type": "text", "text": "The key challenge lies in constructing an UCB. As $\\overline{{\\mathcal{P}}}$ is large, naively constructing UCB over prices in $\\overline{{\\mathcal{P}}}$ will lead to a $\\sqrt{|\\overline{{\\mathcal{P}}}|T\\log T}$ upper bound, leading to poor, exponential dependence on $m$ . This is the bound if we only observe the reward for the prices that are actually pulled, but do not observe the types after purchase. Therefore, naively applying UCB is like bandit feedback. On the other extreme, had we been in an alternative setting where we observe the type regardless of purchase, this is like a full information feedback because once observe the type, we know the revenue for all prices. Then UCB gives us $\\sqrt{\\log(|\\overline{{\\mathcal{P}}}|)T\\log T}$ upper bound. We are in an intermediate regime between bandit feedback and fuil information: The challenge in constructing the UCB arises because we only observe types upon purchase. As the key unknown is the type distribution, we maintain UCBs for it and translate them to UCBs for the revenue. In particular, our UCB depends on how many times a buyer could have purchased at a given round, which is a random quantity depending on the algorithm itself. ", "page_idx": 7}, {"type": "text", "text": "Construction of UCB. We will now show how to construct the upper confidence bound $\\widehat{\\mathrm{rev}_{t}}$ at the end of round $t$ , which will be used in computing $p_{t+1}$ . For $\\tau\\leq t$ , let $S_{\\tau}$ , defined below in (5), be the set of types who would have purchased in round $\\tau$ at price $p_{\\tau}$ had they appeared in that round. Then, for any type $i\\in[m]$ , we define $T_{i,t}$ to be the number of times that type $i$ appears in set $S_{\\tau}$ for ", "page_idx": 7}, {"type": "text", "text": "Given: time horizon $T$ , discretization $\\overline{{\\mathcal{P}}}$ of price curves.   \nSet $p_{1}$ to be the zero function. # Give data away for free on round 1.   \nA buyer of type $i_{1}\\sim q$ arrives and purchases $N$ data points at price 0.   \nfor $t=2$ to $T$ do Compute the UCB $\\widehat{\\mathrm{rev}}_{t-1}(p)$ on the revenue of $p$ for each $p\\in\\overline{{\\mathcal{P}}}$ # See (5), (6), and (7). Set $p_{t}=\\operatorname*{argmax}_{p\\in\\overline{{\\mathcal{P}}}}\\widehat{\\operatorname{rev}}_{t-1}(p)$ A buyer of type $i_{t}\\sim q$ arrives, purchases $n_{i_{t},p_{t}}$ points, and pays $p_{t}(n_{i_{t},p_{t}})$   \nend for ", "page_idx": 8}, {"type": "text", "text": "$\\tau\\in\\{1,\\ldots,t\\}$ . That is, $T_{i,t}$ measures the number of times a buyer of type $i$ would have purchased during the first $t$ rounds. We have, ", "page_idx": 8}, {"type": "equation", "text": "$$\nS_{\\tau}\\triangleq\\big\\{i\\in[m]:\\exists n\\in[N],v_{i}(n)-p_{\\tau}(n)\\geq0\\big\\},\\qquad T_{i,t}\\triangleq\\sum_{\\tau=1}^{t}\\mathbb{I}(i\\in S_{\\tau}).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Note that as we use the 0 price function on round 1, i.e. $p_{1}(\\cdot)\\;=\\;0$ , we have $T_{i,t}~>~0$ for all $t>1$ . Next, we estimate $q_{i}$ via the fraction of times that type $i$ has appeared in the past $t$ rounds, provided that $i\\in S_{\\tau}$ for $\\bar{\\tau}\\in\\{1,\\ldots,t\\}$ .We have defined this quantity, $\\overline{{q}}_{i,t}$ below in (6). Via a standard application of Hoeffding's inequality, we can show that $|q_{i}-\\overline{{q}}_{i,t}|\\leq\\sqrt{(\\log T)/T_{i,t}}$ with high probability. Using this, we can construct an upper confidence bound $\\widehat{q}_{i,t}$ as follows, ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\overline{{q}}_{i,t}\\triangleq\\frac{1}{T_{i,t}}\\sum_{\\tau=1}^{t}\\mathbb{I}(i\\in S_{\\tau},i_{\\tau}=i),\\quad\\qquad\\widehat{q}_{i,t}\\triangleq\\overline{{q}}_{i,t}+\\sqrt{\\frac{\\log T}{T_{i,t}}}.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "We now translate the UCBs on $q$ to the UCBs on the revenue. Recall from (1) that a buyer of type $i$ will purchase $n_{i,p}$ points at price $p$ and the revenue from this buyer will be $p(n_{i,p})$ . Note that as the seller has access to the valuation curves, he can compute $n_{i,p}$ for any $i$ and price curve $p$ . Since $\\mathrm{rev}(p)=\\mathbb{E}_{i\\sim q}[p(n_{i,p})]$ , we have the following natural UCB for $\\operatorname{rev}(p)$ on round $t$ ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\widehat{\\mathrm{rev}}_{t}(p)\\ \\triangleq\\ \\sum_{i=1}^{m}\\widehat{q}_{i,t}\\cdot p(n_{i,p}).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "This completes the description of our construction. The following theorem bounds the regret for Algorithm 3 when paired with any of the discretization schemes in $\\S3$ .While the computational complexity of our method depends on $|\\mathcal P|$ , there is no dependence on the regret because of the above construction of the UCB. The proof is given in Appendix C. ", "page_idx": 8}, {"type": "text", "text": "Theorem 4.1. Suppose in Algorithm 3 we use a discretization $\\overline{{\\mathcal{P}}}$ whichisa $\\mathcal{O}(1/\\sqrt{T})$ additive approximation to any price curve. Then, the regret of Algorithm 3 satisfies $\\mathbb{E}[R_{T}]\\in\\tilde{\\mathcal{O}}(m\\sqrt{T})$ ", "page_idx": 8}, {"type": "text", "text": "Proof challenges. When bounding the regret, we first observe that the subsets $S\\subset[m]$ induces a partitioning of the price curves, where $p$ belongs to the partition of $S$ , if all types in $S$ would make a purchase at price $p$ , and all types in $S^{c}$ would not make a purchase at price $p$ .With this insight, we can view the action of a seller as not just choosing a price curve, but also choosing a set $\\bar{S_{t}}\\subset[n]$ That is, $S_{t}$ can be viewed as a super-arm in a combinatorial semi-bandit problem [37]. ", "page_idx": 8}, {"type": "text", "text": "5   Online learning in the adversarial setting ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We now study the adversarial setting. Similar to the stochastic setting, our algorithm will use a discretization of the price curves from $\\S3$ . We will control regret by bounding both the discretization error and the algorithm's regret relative to the best pricing curve in the discretization. ", "page_idx": 8}, {"type": "text", "text": "Before proceeding, let us first contextualize our feedback model against prior work. If the buyers do not reveal their types, this becomes an adversarial bandit problem with $|\\mathcal P|$ arms (pricing curves) [33]. Using an algorithm such as EXP-3 [9] results in large $\\widetilde{\\mathcal{O}}(T^{1/2}|\\overline{{\\mathcal{P}}}|^{1/2})$ regret, which is not ideal due to $|\\overline{{\\mathcal{P}}}|$ 's exponential dependence in $m$ . Conversely, if buyers reveal their types regardless of purchase, ", "page_idx": 8}, {"type": "text", "text": "Given: time horizon $T$ , discretization $\\overline{{\\mathcal{P}}}$ , perturbation parameter $\\theta$   \nFor each $p\\in\\overline{{\\mathcal{P}}}$ , sample $\\theta_{p}$ from an exponential distribution with pdf $\\theta e^{-\\theta x}$   \nfor $t=1$ to $T$ do Set price curve for the current round $p_{t}=\\underset{p\\in\\overline{{\\mathcal{P}}}}{\\operatorname{argmax}}\\sum_{\\tau=1}^{t-1}r_{\\tau}(p)\\ +\\ \\theta_{p}.$ A buyer of type $i_{t}$ arrives, purchases $n_{i_{t},p_{t}}$ points, and pays $p_{t}(n_{i_{t},p_{t}})$ if $n_{i_{t},p_{t}}>0$ then  Set $r_{t}(p)=p(n_{i_{t},p})$ for all $p\\in\\overline{{\\mathcal{P}}}$ # If there was a purchase else Set $\\begin{array}{r}{r_{t}(p)=\\sum_{i\\in S_{t}^{c}}p(n_{i,p})}\\end{array}$ for alli $p\\in\\overline{{\\mathcal{P}}}$ # See (5) for $S_{t}$ end if   \nend for ", "page_idx": 9}, {"type": "text", "text": "this is equivalent to full information feedback, where algorithms such as Hedge or Follow-theperturbed-leader (FTPL) [31] yield ${\\mathcal{O}}(T^{1/2}\\log^{1/2}|{\\overline{{\\mathcal{P}}}}|)$ regret, translating to $\\widetilde{\\mathcal{O}}((m T)^{1/2})$ with our discretization schemes in $\\S3$ . In our intermediate regime, where feedback is only revealed upon purchase, we aim for a middle ground. We show our algorithm, outlined in Algorithm 4, achieves $\\widetilde{\\mathcal{O}}(m^{3/2}T^{1/2})$ regret, which is worse than full information,but still depends polynomiallyon $m$ ", "page_idx": 9}, {"type": "text", "text": "Our algorithm takes a discretization $\\overline{{\\mathcal{P}}}$ and a perturbation parameter $\\theta$ as input. First, it samples a random perturbation $\\theta_{p}$ from an exponential distribution with pdf $\\theta e^{-\\theta x}$ for each pricing curve $p$ in $\\overline{{\\mathcal{P}}}$ . It maintains rewards $\\{r_{t}(p)\\}_{t,p}$ for each round $t$ and price curve $p$ . On each round, it chooses the price curve that maximizes the perturbed cumulative reward $\\textstyle\\sum_{\\tau=1}^{t}r_{\\tau}(p)+\\theta_{p}$ \uff0c ", "page_idx": 9}, {"type": "text", "text": "This scheme is similar to FTPL, but the key difference is in how we design the rewards $\\{r_{t}(p)\\}_{t,p}$ To describe this, let $S_{t}$ , defined exactly as in (5), be the set of agents who would have purchased in round $t$ at price $p_{t}$ . At the end of the round, if there was a purchase, for all prices $p\\in\\overline{{\\mathcal{P}}}$ , we set the reward to be $r_{t}(p)=p(n_{i_{t},p})$ , i.e. the payment we would have received from the buyer at that round, had the price been $p$ (see (1)). If there was no purchase, we know that $i_{t}\\notin S_{t}$ , in which case we set $\\begin{array}{r}{r_{t}(p\\bar{\\bf\\alpha})=\\sum_{i\\in S_{t}^{c}}\\bar{p}(n_{i,p})}\\end{array}$ . In this case, $r_{t}(p)$ is an upper bound on $p(n_{i_{t},p})$ , and this upper bound is tight around prices similar to the chosen price $p_{t}$ ; in fact, $r_{t}(p_{t})\\,=\\,0$ if there was no purchase. Intuitively, $r_{t}(p)$ deals with the uncertainty of not knowing the type on round $t$ by providing a large reward (as we are taking the sum) to prices that could have resulted in a purchase, which encourages exploration of such prices in future rounds. This intuition will help us bound the regret. ", "page_idx": 9}, {"type": "text", "text": "Theorem 5.1 provides a bound on the regret for Algorithm 4. Its proof is given in Appendix B.   \nCombining this with the size of $\\overline{{\\mathcal{P}}}$ under the various assumptions in $\\S3$ weobtain $\\widetilde{\\mathcal{O}}(m^{3/2}\\sqrt{T})$ regret. ", "page_idx": 9}, {"type": "text", "text": "Theorem 5.1. Suppose in Algorithm $^{4}$ we use a discretization $\\overline{{\\mathcal{P}}}$ which is a ${\\mathcal{O}}(1/{\\sqrt{T}})$ additive approximation to any price curve. Let $R_{T}$ be as defined in (4). Then, for Algorithm 4, we have $\\mathbb{E}[R_{T}]~\\in$ $\\mathcal{O}\\left(m^{2}\\theta T+\\theta^{-1}\\left(1+\\log\\left|\\overline{{\\mathcal{P}}}\\right|\\right)\\right)$ .Setting $\\begin{array}{r}{\\theta=\\sqrt{\\frac{1+\\log\\left|\\overline{{\\mathcal{P}}}\\right|}{m^{2}T}}}\\end{array}$ we have $\\mathbb{E}[R_{T}]\\;\\in\\;\\mathcal{O}\\big(m\\sqrt{T\\log\\vert\\overline{{\\mathcal{P}}}\\vert}\\big)$ ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion and Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We designed revenue-optimal learning algorithms for pricing data. First, we leveraged properties like smoothness and diminishing returns to create novel discretization schemes for approximating any pricing curve. These schemes were then used in our learning algorithms to improve their statistical and computational properties. Our algorithms build on classical methods like UCB and FTPL but required significant adaptations to handle the vast space of pricing curves and the asymmetric feedback. An interesting future direction would be to relax the assumption that the seller knows the valuationcurves U'. ", "page_idx": 9}, {"type": "text", "text": "Computational complexity.  Our algorithm is designed to achieve polynomial computational complexity with respect to the number of data points when the number of types is fixed, making it suitable for practical data pricing scenarios where the type count is typically small or bounded. While the overall computational cost grows exponentially with the number of types due to the problem's strong NP-hardness (see [14]), this design choice ensures computational feasibility in settings with large datasets and a limited number of types. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] AWS Forecast. https: //aws .amazon.com/forecast/, . Accessed: 2024-05-12.   \n[2] AWS Data Hub. https : //aws.amazon.com/blogs/big-data/tag/datahub/, . Accessed: 2024-05-11.   \n[3] Azure Data Share. https: //azure.microsoft.com/en-us/products/data-share. Accessed: 2024-05-10.   \n[4] Delta Sharing. https: //docs.databricks.com/en/data-sharing/index.html. Accessed: 2024-05-11.   \n[5] Ads Data Hub. https: //developers .google.com/ads-data-hub/guides/intro. Accessed: 2022-05-10.   \n[6]  A. Agarwal, M. Dahleh, and T. Sarkar. A marketplace for data: An algorithmic solution. In Proceedings of the 2019 ACM Conference on Economics and Computation, pages 701-726, 2019.   \n[7]  A. Agarwal, M. Dahleh, T. Horel, and M. Rui. Towards data auctions with externalities. arXiv preprint arXiv:2003.08345, 2020.   \n[8]  P. Auer. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine Learning Research, 3(Nov):397-422, 2002.   \n[9]  P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. The nonstochastic multiarmed bandit problem. SIAM journal on computing, 32(1):48-77, 2002.   \n[10] M. F. Balcan and H. Beyhaghi. New guarantees for learning revenue maximizing menus of lotteries and two-part tariffs. Transactions on Machine Learning Research, 2024.   \n[11]  O. Besbes and A. Zeevi. Dynamic pricing without knowing the demand function: Risk bounds and near-optimal algorithms. Operations Research, 57(6): 1407-1420, 2009.   \n[12] O. Besbes and A. Zeevi. On the (surprising) suffciency of linear models for dynamic pricing with demand learning. Management Science, 61(4):723-739, 2015.   \n[13] S. Chawla, J. D. Hartline, and R. Kleinberg. Algorithmic pricing via virtual valuations. In Proceedings of the 8th ACM Conference on Electronic Commerce, pages 243-251, 2007.   \n[14] S. Chawla, R. Rezvan, Y. Teng, and C. Tzamos. Pricing ordered items. In Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing, pages 722-735, 2022.   \n[15]  W. Chen, W. Hu, F. Li, J. Li, Y. Liu, and P Lu. Combinatorial multi-armed bandit with general reward functions. Advances in Neural Information Processing Systems, 29, 2016.   \n[16] X. Chen, I. Diakonikolas, D. Paparas, X. Sun, and M. Yannakakis. The complexity of optimal multidimensional pricing. In Proceedings of the twenty-fth anual ACM-SIAM symposium on Discrete algorithms, pages 1319-1328. SIAM, 2014.   \n[17] W. C. Cheung, D. Simchi-Levi, and H. Wang. Dynamic pricing and demand learning with limited price experimentation. Operations Research, 65(6):1722-1731, 2017.   \n[18] Citrine Informatics. Citrine Informatics - Accelerating Materials Innovation. URL: https : / /citrine.io/, 2024. Accessed: March 9, 2024.   \n[19]  A. V. Den Boer. Dynamic pricing and learning: Historical origins, current research, and new directions. Surveys in Operations Research and Management Science, 20(1):1-18, 2015.   \n[20]  A. V. den Boer and B. Zwart. Simultaneously learning and optimizing using controlled variance pricing. Management Science, 60(3):770-783, 2014.   \n[21] J. Deng, W. Dong, R.Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical imagedatabase.I 2009 IEEE conference on computervision and pattrn recognition, pages 248-255. Ieee, 2009.   \n[22] M. Dudik, N. Haghtalab, H. Luo, R. E. Schapire, V. Syrgkanis, and J. W. Vaughan. Oracleefficient online learning and auction design. Journal of the ACM (JACM), 67(5):1-57, 2020.   \n[23] W. Guo, N. Haghtalab, K. Kandasamy, and E. Vitercik. Leveraging reviews: Learning to price with buyer and seller uncertainty. In Proceedings of the 24th ACM Conference on Economics and Computation, pages 816-816, 2023.   \n[24] V. Guruswami, J. D. Hartline, A. R. Karlin, D. Kempe, C. Kenyon, and F. McSherry. On profit-maximizing envy-free pricing. In SODA, volume 5, pages 1164-1173, 2005.   \n[25]  J. D. Hartline and V. Koltun. Near-optimal pricing in near-linear time. In Proceedings of the 9th International Conference on Algorithms and Data Structures, WADS'05, page 422-431, Berlin, Heidelberg, 2005. Springer-Verlag. ISBN 3540281010. doi: 10.1007/11534273_37. URL https : //doi . org/10.1007/11534273_37.   \n[26] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770- 778, 2016.   \n[27] M. Jagadeesan, A. Wei, Y. Wang, M. Jordan, and J. Steinhardt. Learning equilibria in matching markets from bandit feedback. Advances in Neural Information Processing Systems, 34:3323- 3335,2021.   \n[28]  A. Javanmard. Perishability of data: dynamic pricing under varying-coefficient models. The Journal of Machine Learning Research, 18(1):1714-1744, 2017.   \n[29]  A. Javanmard and H. Nazerzadeh. Dynamic pricing in high-dimensions. The Journal of Machine Learning Research, 20(1):315-363, 2019.   \n[30] R. Jia, D. Dao, B. Wang, F. A. Hubis, N. Hynes, N. M. Gurel, B. Li, C. Zhang, D. Song, and C. J. Spanos. Towards efficient data valuation based on the Shapley value. In The 22nd International Conference on Artificial Intelligence and Statistics, pages 1167-1176. PMLR, 2019.   \n[31]  A. Kalai and S. Vempala. Efficient algorithms for online decision problems. Journal of Computer and System Sciences, 71(3):291-307, 2005.   \n[32]  N. B. Keskin and A. Zeevi. Dynamic pricing with an unknown demand model: Asymptotically optimal semi-myopic policies. Operations Research, 62(5):1142-1167, 2014.   \n[33]  R. Kleinberg and T. Leighton. The value of knowing a demand curve: Bounds on regret for online posted-price auctions. In 44th Annual IEEE Symposium on Foundations of Computer Science, 2003. Proceedings., pages 594-605. IEEE, 2003.   \n[34]  A. Krause and C. Guestrin. Submodularity and its applications in optimized information gathering. ACM Transactions on Intelligent Systems and Technology (TIST), 2(4):1-20, 2011.   \n[35]  A. Krause, H. B. McMahan, C. Guestrin, and A. Gupta. Robust submodular observation selection. Journal of Machine Learning Research, 9(12), 2008.   \n[36]  A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems, 25, 2012.   \n[37] B. Kveton, Z. Wen, A. Ashkan, and C. Szepesvari. Tight regret bounds for stochastic combinatorial semi-bandits. In Artificial Intelligence and Statistics, pages 535-543. PMLR, 2015.   \n[38] T. L. Lai and H. Robbins. Asymptotically efficient adaptive allocation rules. Advances in applied mathematics, 6(1):4-22, 1985.   \n[39]  K. Misra, E. M. Schwartz, and J. Abernethy. Dynamic online pricing with incomplete information using multiarmed bandit experiments. Marketing Science, 38(2):226-252, 2019.   \n[40] G. Perakis and D. Singhvi. Dynamic pricing with unknown nonparametric demand and limited price changes. Operations Research, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "[41] S. Shalev-Shwartz and S. Ben-David. Understanding machine learning: From theory to algorithms. Cambridge university press, 2014. ", "page_idx": 12}, {"type": "text", "text": "[42] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1-9, 2015.   \n[43]  T. Wang, J. Rausch, C. Zhang, R. Jia, and D. Song. A principled approach to data valuation for federated learning. Federated Learning: Privacy and Incentive, pages 153-167, 2020.   \n[44] Y. Wang, B. Chen, and D. Simchi-Levi. Multimodal dynamic pricing. Management Science, 67 (10):6136-6152, 2021.   \n[45]  L. Wasserman. All of nonparametric statistics. Springer Science & Business Media, 2006.   \n[46] J. Xu and Y.-X. Wang.  Logarithmic regret in feature-based dynamic pricing. Advances in Neural Information Processing Systems, 34:13898-13910, 2021.   \n[47]  H. Zhao and W. Chen. Stochastic one-sided full-information bandit.  In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 150-166. ", "page_idx": 12}, {"type": "text", "text": "Springer, 2019. ", "page_idx": 12}, {"type": "text", "text": "A Omitted Details from Section 3 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A.1 Proof of Lemma 3.1 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Lemma 3.1. Assume there are m types with non-decreasing value curves $\\{v_{i}\\}_{i\\in[m]}$ . For any nondecreasing price curve $p_{\\mathrm{:}}$ there exists an\u2018 $^{\\ast}m$ -step\"pricecurve $\\bar{p}$ that yields expected revenue at least thatof $p$ with respect to any distribution over the m types. Here, $m$ -step refers to non-decreasing functions $f:[N]\\to[0,1]$ where $f(n+1)-f(n)>0$ in at most $m$ points (i.e., at most m jumps). ", "page_idx": 12}, {"type": "text", "text": "Proof of Lemma 3.1. Fix a price curve $p$ . Let $n_{i,p}$ be the amount of data type $i$ purchase at price curve $p$ , that is ", "page_idx": 12}, {"type": "equation", "text": "$$\nn_{i,p}\\triangleq\\operatorname*{max}\\left\\{\\operatorname{argmax}_{n\\in[N]}(v_{i}(n)-p(n))\\right\\}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "For $\\{n_{i,p}\\}_{i\\in[m]}$ let $\\pi:[m]\\to[m]$ be a permutation such that $n_{\\pi(1),p}\\le n_{\\pi(2),p}\\le\\cdots\\le n_{\\pi(m),p}.$ Let n(i) $n_{(i)}\\triangleq n_{\\pi(i),p}$ . Then, define a function $\\bar{p}:[N]\\to[0,1]$ as follows, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\bar{p}(n)\\triangleq\\left\\{\\begin{array}{l l}{p\\left(n_{(1)}\\right),}&{n\\leq n_{(1)},}\\\\ {p\\left(n_{(2)}\\right),}&{n_{(1)}<n\\leq n_{(2)},}\\\\ &{\\vdots}\\\\ {p\\left(n_{(m-1)}\\right),}&{n_{(m-2)}<n\\leq n_{(m-1)},}\\\\ {p\\left(n_{(m)}\\right),}&{n_{(m-1)}<n\\leq N,}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "so that $\\bar{p}$ has at most $m$ steps. Then, $\\bar{p}$ has following properties ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bar{p}(n)=p(n),\\mathrm{~when~}n\\in\\left\\{n_{(1)},n_{(2)},\\ldots,n_{(m)}\\right\\},}\\\\ &{\\bar{p}(n)\\leq p(n),\\mathrm{~when~}n\\in\\left[N\\right]\\backslash\\left\\{n_{(1)},n_{(2)},\\ldots,n_{(m)}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "We next prove that for any $i\\in[m]$ , after changing the price function from $p$ to $\\bar{p}$ , the type $i$ buyer either purchases at $(n_{i,p},p(n_{i,p}))$ or at $(N,p(\\bar{n_{(m)}}\\bar{)})$ ", "page_idx": 12}, {"type": "text", "text": "For any type $i$ and any amount of data $n\\leq n_{(m)}$ , there exists $k$ such that $n_{(k-1)}<n\\leq n_{(k)}$ (let $n_{(0)}=0$ ), we then have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{v_{i}(n)-\\bar{p}(n)\\leq v_{i}\\left(n_{(k)}\\right)-\\bar{p}\\left(n_{(k)}\\right)}&{}&{\\quad\\mathrm{(as~}v_{i}\\mathrm{~is~non-decreasing~and~}\\bar{p}\\mathrm{~is~a~step~function.})}\\\\ {=v_{i}\\left(n_{(k)}\\right)-p\\left(n_{(k)}\\right)}&{}&{\\quad\\mathrm{(as~}\\bar{p}\\left(n_{(k)}\\right)=p\\left(n_{(k)}\\right))}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{l c r}{{\\leq v_{i}(n_{i,p})-p(n_{i,p})}}\\\\ {{=v_{i}(n_{i,p})-\\bar{p}(n_{i,p}).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "(as $n_{i,p}$ maximizes the buyer's utility.) ", "page_idx": 13}, {"type": "text", "text": "As shown in the above, type $i$ still prefers purchasing $n_{i,p}$ data over all $n\\leq n_{(m)}$ under price $\\bar{p}$ ", "page_idx": 13}, {"type": "text", "text": "For $n\\in\\{n_{(m)}+1,\\ldots,N\\}$ , by the monotonicity of value curves, we have ", "page_idx": 13}, {"type": "equation", "text": "$$\nN=\\operatorname*{max}\\left\\{\\operatorname*{arg\\,max}_{n\\in\\left\\{n_{(m)}+1,\\ldots,N\\right\\}}\\left(v_{i}(n)-\\bar{p}(n)\\right)\\right\\}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Therefore, for any $i\\in[m]$ type $i$ either purchases at $(n_{i,p},p(n_{i,p}))$ , or purchases at $(N,\\bar{p}(N))=$ $(N,p(n_{(m)}))$ under price $\\bar{p}$ . No matter in which case, type $i$ contributes no less revenue under $\\bar{p}$ than $p$ It then follows that, for any type distribution $q$ ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathrm{rev}(\\bar{p})\\geq\\mathrm{rev}(p).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "A.2Proof of Theorem 3.1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this subsection, we prove Theorem 3.1 by decomposing it into three technical lemmas (Lemma A.1, A.2 and A.3). In Lemma A.1 and A.2, we prove the approximation guarantee of our discretization scheme and, in Lemma A.3 we provide an upper bound on the size of the discretization. ", "page_idx": 13}, {"type": "text", "text": "Lemma A.1. For any type distribution, there exists a pricing function $\\widetilde{p}:[N]\\to[\\epsilon,1]$ suchthat ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathrm{rev}(\\widetilde{p})\\geq\\mathrm{OPT}-\\epsilon.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Proof of Lemma A.1. Consider the optimal pricing function $p^{\\star}:[N]\\rightarrow[0,1]$ i.e., $\\mathrm{OPT}=\\operatorname{rev}(p^{\\star})$ Consider price curve $\\widetilde{p}:[N]\\to[\\epsilon,1]$ where $\\tilde{p}(n)=\\operatorname*{max}\\left(\\epsilon,p^{\\star}(\\bar{n})\\right)$ ", "page_idx": 13}, {"type": "text", "text": "Let $J\\triangleq\\{n\\in[N]:\\widetilde{p}(n)=p^{\\star}(n)\\}$ be the set of data quantities whose price under $\\widetilde{p}$ are the same as those under $p$ . Any buyer type who would have purchased $n\\in J$ amount of data under $p^{\\star}$ will purchase the same amount of data under $\\widetilde{p}$ . On the other hand, for buyer types who would have purchased $n\\not\\in J$ amount of data under $p^{\\star}$ , since $\\widetilde p(n)=\\epsilon>p^{\\star}(n)$ for $n\\not\\in J$ , the expected revenue contribution from such buyers under $p^{\\star}$ is at most $\\epsilon$ hence no matter they purchase or not under $\\widetilde{p}$ we have $\\mathrm{rev}(\\widetilde{p})\\ge\\mathrm{OPT}-\\epsilon$ \u53e3 ", "page_idx": 13}, {"type": "text", "text": "Lemma A.2. For any $\\widetilde{p}\\in[\\epsilon,1]^{N}$ there exists $p^{\\prime}\\in\\overline{{\\mathcal{P}}}$ such that $\\mathrm{rev}(p^{\\prime})\\geq\\mathrm{rev}(\\widetilde{p})/(1+\\epsilon),$ for any type distribution $q$ ", "page_idx": 13}, {"type": "text", "text": "Proof of Lemma A.2. For $m$ buyer types, by Lemma 3.1, there exists a non-decreasing step function $\\bar{p}\\in[\\epsilon,1]^{N}$ with at most $m$ steps, whose expected revenue is at least $\\mathrm{rev}(\\widetilde{p})$ . Assume $\\bar{p}$ has $k$ steps, $k\\leq m$ . To simplify the notation, for $1\\le j\\le k$ , let $\\bar{p}_{j}$ denote the price $\\bar{p}$ on $j$ th step. That is, ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\bar{p}(n)=\\left\\{\\begin{array}{l l}{\\bar{p}_{1},}&{n\\in(0,i_{1}]\\cap\\mathbb{Z},}\\\\ {\\bar{p}_{2},}&{n\\in(i_{1},i_{2}]\\cap\\mathbb{Z},}\\\\ &{\\vdots}\\\\ {\\bar{p}_{k},}&{n\\in(i_{k-1},N]\\cap\\mathbb{Z}.}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Where $i_{1},\\ldots,i_{k-1}\\in[N]$ are discontinuities in $\\bar{p}$ ", "page_idx": 13}, {"type": "text", "text": "Recall the definitions of $Z$ and $W$ as stated in Algorithm 1, ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{Z_{i}\\triangleq\\left\\lbrace\\epsilon(1+\\epsilon)^{i}:\\forall\\,i\\in\\left\\lbrace0,1,\\ldots,\\left\\lceil\\log_{1+\\epsilon}\\frac{1}{\\epsilon}\\right\\rceil\\right\\rbrace\\right\\rbrace,\\,Z=\\bigcup_{i}Z_{i}.}\\\\ &{W_{i}\\triangleq\\left\\lbrace Z_{i-1}+Z_{i-1}\\cdot\\frac{\\epsilon k}{m}:\\forall\\,k\\in\\left\\lbrace1,2,...,\\lceil(2+\\epsilon)m\\rceil\\right\\rbrace\\right\\rbrace,\\quad W\\overset{\\Delta}{=}\\bigcup_{i=1}^{\\left\\lceil\\log_{1+\\epsilon}\\frac{1}{\\epsilon}\\right\\rceil}W_{i}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Let $i_{k}=N$ and for each $j\\in[k]$ , let $Z_{i_{j}}$ be the price obtained by rounding $\\bar{p}_{j}$ down to the nearest value in $Z$ . By constructions of $Z$ and $W$ above, $W_{i_{j}}$ is a partition of interval $(Z_{i_{j}-1},Z_{i_{j}+1})$ . Let $w_{j}$ be the price obtained by rounding $\\bar{p}_{j}$ down to the nearest value in $W_{i_{j}}$ . Set $\\begin{array}{r}{\\boldsymbol{d}_{j}\\triangleq\\frac{\\epsilon}{m}\\cdot\\boldsymbol{Z}_{i_{j}-1}}\\end{array}$ and consider $k$ step function $p$ defined by whose price at $j$ th step (denoted $p_{j}$ is $w_{j}-(j-1)d_{j}\\in W_{i_{j}}$ \uff0c that is ", "page_idx": 14}, {"type": "equation", "text": "$$\np(n)=\\left\\{\\begin{array}{l l}{p_{1}=w_{1},}&{\\mathrm{for}\\;n\\in(0,i_{1}]\\cap\\mathbb{Z},}\\\\ {p_{2}=w_{2}-d_{2},}&{\\mathrm{for}\\;n\\in(i_{1},i_{2}]\\cap\\mathbb{Z},}\\\\ {\\qquad\\qquad\\vdots}\\\\ {p_{k}=w_{k}-(k-1)d_{k},}&{\\mathrm{for}\\;n\\in(i_{k-1},N]\\cap\\mathbb{Z}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "By the tie-breaking rule and the monotonicity of valuation curves, buyers only purchase among $0,i_{1},i_{1},\\ldots,i_{k}$ number of data under $p$ and $\\bar{p}$ ", "page_idx": 14}, {"type": "text", "text": "Subclaim. Then, $p$ and $\\bar{p}$ satisfies the following ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathrm{rev}(p)\\geq\\mathrm{rev}(\\bar{p})/(1+\\epsilon),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "with respect to any type distribution. ", "page_idx": 14}, {"type": "text", "text": "Proof of the Subclaim. We prove the above subclaim with two steps. ", "page_idx": 14}, {"type": "text", "text": "Step 1: No buyer who prefers to purchase $i_{j}$ data under $\\bar{p}$ would prefer $i_{j^{\\prime}}$ data for some $j^{\\prime}<j$ under $p$ (i.e., one with a less price). This is because, when going from price $\\bar{p}$ to $p$ , the increase in the buyer's utility for $i_{j}$ data is $\\bar{p}_{j}-p_{j}$ which is higher than the increase $\\bar{p}_{j^{\\prime}}-p_{j^{\\prime}}$ for $i_{j^{\\prime}}$ data. Formally, this can be seen as follows: For any $j^{\\prime}<j$ we have, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\bar{p}_{j}-p_{j}\\geq w_{j}-p_{j}=(j-1)d_{j},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "as $\\bar{p}_{j}\\geq w_{j}$ and $p_{j}=w_{j}-(j-1)d_{j}$ .Moreover, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\bar{p}_{j^{\\prime}}<w_{j^{\\prime}}+d_{j^{\\prime}}\\implies\\bar{p}_{j^{\\prime}}-p_{j^{\\prime}}<w_{j^{\\prime}}+d_{j^{\\prime}}-p_{j^{\\prime}}=j^{\\prime}d_{j^{\\prime}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The inequality $\\bar{p}_{j^{\\prime}}<w_{j^{\\prime}}+d_{j^{\\prime}}$ holds because $w_{j^{\\prime}}$ is the result of rounding down $\\bar{p}_{j}$ to the nearest value in $W_{i_{j}}$ ", "page_idx": 14}, {"type": "text", "text": "By constructions of sets $Z$ and $W$ wehave $d_{j}\\geq d_{j^{\\prime}}$ which implies $(j-1)d_{j}\\geq j^{\\prime}d_{j^{\\prime}}$ . Then, by combining the above inequalities, we obtain ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\bar{p}_{j}-p_{j}\\geq(j-1)d_{j}\\geq j^{\\prime}d_{j^{\\prime}}\\geq\\bar{p}_{j^{\\prime}}-p_{j^{\\prime}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Consider a buyer with value curve $v$ who prefers to purchase at $i_{j}$ under price $\\bar{p}$ , then it must be ", "page_idx": 14}, {"type": "equation", "text": "$$\nv(i_{j})-\\bar{p}_{j}>v(i_{j^{\\prime}})-\\bar{p}_{j^{\\prime}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Then, by combining (10) and (11), we have ", "page_idx": 14}, {"type": "equation", "text": "$$\nv(i_{j})-p_{j}>v(i_{j^{\\prime}})-p_{j^{\\prime}},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "therefore the buyer would not purchase at $i_{j^{\\prime}}<i_{j}$ under $p$ ", "page_idx": 14}, {"type": "text", "text": "Step 2: Next, we claim that $p_{j}\\geq\\bar{p}_{j}/(1+\\epsilon)$ for all step $j\\in[k]$ . Since $Z_{i_{j}}$ is obtained by rounding $\\bar{p}_{j}$ down to the nearest value in $Z$ , we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\bar{p}_{j}\\geq Z_{i_{j}}=Z_{i_{j}-1}+\\epsilon Z_{i_{j}-1}=Z_{i_{j}-1}+m d_{j}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "By (9) and the above, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\np_{j}\\geq\\bar{p}_{j}-j d_{j}\\geq Z_{i_{j}-1}+(m-j)d_{j}\\geq Z_{i_{j}-1},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where the first inequality is by (9), the second is by (12), and the third is because $m\\le j$ ", "page_idx": 14}, {"type": "text", "text": "Then, it follows that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\bar{p}_{j^{\\prime}}-p_{j}\\leq j\\cdot d_{j}=\\epsilon\\cdot\\frac{j}{m}\\cdot Z_{i_{j}-1}\\leq\\epsilon\\cdot Z_{i_{j}-1}\\leq\\epsilon\\cdot p_{j}\\implies p_{j}\\geq\\bar{p}_{j}/(1+\\epsilon).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "So far we have proved $p_{j}\\geq\\bar{p}_{j}/(1+\\epsilon)$ and no type wants to change their preference to a smaller amount of data under $p$ .If one type purchase at $\\bar{p}_{i}$ under $\\bar{p}$ and $p_{k}$ under $p$ for $k~\\geq~i$ then $p_{k}\\geq p_{i}\\geq\\bar{p}_{i}/(1+\\epsilon)$ . Therefore, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathrm{rev}(p)\\geq\\mathrm{rev}(\\bar{p})/(1+\\epsilon)\\geq\\mathrm{rev}(\\bar{p})/(1+\\epsilon).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since the construction of price $p$ is not relevant to type distribution, the above holds for any type distribution $q$ , which proves the subclaim. ", "page_idx": 15}, {"type": "text", "text": "Note that $p$ constructed in the above subclaim is not necessarily non-decreasing as a larger amount of data surfers more price deduction when going from $\\bar{p}$ to $p$ . In this case, we can directly construct a non-decreasing price curve $p^{\\prime}\\in\\overline{{\\mathcal{P}}}$ from $p$ such that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathrm{rev}(p^{\\prime})\\geq\\mathrm{rev}(\\bar{p})/(1+\\epsilon).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Let $S\\overset{\\Delta}{=}\\{i\\in[k]:\\exists j<i$ ,.t. $p_{j}>p_{i}\\}$ If $S$ is empty, this implies that $p$ is non-decreasing, hence setting $p^{\\prime}=p$ If $S$ is not empty, we define $p^{\\prime}$ as follows: Let $p^{\\prime}$ be a $k$ -step function with the same jump points $i_{1},\\ldots,i_{k}$ as $p$ Let $p_{i}^{\\prime}$ be the value of $p^{\\prime}$ on ith step. Then, for $i\\not\\in S$ let $p_{i}^{\\prime}=p_{i}$ ; and for $i\\in S$ let $p_{i}^{\\prime}=\\operatorname*{max}_{j\\notin S,j<i}p_{j}$ . By construction, $p^{\\prime}$ is non-decreasing. Moreover, $p^{\\prime}=p$ on set $S^{c}$ and $p^{\\prime}>p$ on set $S$ ", "page_idx": 15}, {"type": "text", "text": "Next, we claim that $\\bar{p}_{j}\\mathrm{~-~}p_{j}^{\\prime}$ is non-decreasing for all $j~\\in~[k]$ . Both $(\\bar{p}_{j}\\,-\\,p_{j})_{j\\in[k]}$ and $\\bar{p}$ are non-decreasing with respect to $j$ by the previous results. Hence, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\bar{p}_{j}-p_{j}^{\\prime}<\\bar{p}_{j}-p_{j}^{\\prime}\\leq\\bar{p}_{j+1}-p_{j+1}=\\bar{p}_{j+1}-p_{j+1}^{\\prime},\\quad\\mathrm{if~}j\\in S,j+1\\notin S,}\\\\ {\\bar{p}_{j}-p_{j}^{\\prime}=\\bar{p}_{j}-p_{j}^{\\prime}\\leq\\bar{p}_{j+1}-p_{j+1}=\\bar{p}_{j+1}-p_{j+1}^{\\prime},\\quad\\mathrm{if~}j\\notin S,j+1\\notin S,}\\\\ {\\bar{p}_{j}-p_{j}^{\\prime}=\\bar{p}_{j}-p_{j+1}^{\\prime}\\leq\\bar{p}_{j+1}-p_{j+1}^{\\prime},\\quad\\mathrm{if~}j\\notin S,j+1\\in S,}\\\\ {\\bar{p}_{j}-p_{j}^{\\prime}=\\bar{p}_{j}-p_{j+1}^{\\prime}\\leq\\bar{p}_{j+1}-p_{j+1}^{\\prime},\\quad\\mathrm{if~}j\\in S,j+1\\in S.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Therefore, any type that prefers to purchase at $j$ th step under $\\bar{p}$ would not prefer purchasing at any step $j^{\\prime}<j$ under $p^{\\prime}$ , and since $p_{j}^{\\prime}\\bar{\\geq}p_{j}\\geq\\bar{p}_{j}/(\\bar{1}+\\epsilon)$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathrm{rev}(p^{\\prime})\\geq\\mathrm{rev}(\\bar{p})/(1+\\epsilon)\\geq\\mathrm{rev}(\\widetilde{p})/(1+\\epsilon).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Lemma A.3. When $n>m$ $\\begin{array}{r}{|\\overline{{\\mathcal{P}}}|\\leq\\left(\\frac{e N}{m}\\right)^{m}\\left(e\\lceil(2+\\epsilon)\\rceil\\left\\lceil\\log_{1+\\epsilon}\\frac{1}{\\epsilon}\\right\\rceil\\right)^{m}\\!.}\\end{array}$ ", "page_idx": 15}, {"type": "text", "text": "Proof of Lemma A.3. For any integer $i\\leq m$ , the number of non-decreasing $i$ -step price function is $\\binom{N-1}{i}\\left(\\begin{array}{c}{|W|}\\\\ {i}\\end{array}\\right)$ , hence we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\overline{{p}}\\right|=\\frac{m}{i-1}\\binom{N-1}{i}\\binom{|W|}{i}}\\\\ &{\\quad\\leq\\left(\\frac{m}{i-1}\\binom{N-1}{i}\\right)\\left(\\frac{m}{i-1}\\binom{|W|}{i}\\right)}\\\\ &{\\quad\\leq\\left(\\displaystyle\\sum_{i=0}^{m}\\binom{N-1}{i}\\right)\\left(\\frac{m}{i-1}\\binom{|W|}{i}\\right)}\\\\ &{\\quad\\leq\\left(\\frac{e(N-1)}{m}\\right)^{m}\\left(\\frac{e|W|}{m}\\right)^{m}}\\\\ &{\\quad\\leq\\left(\\frac{e(N-1)}{m}\\right)^{m}\\left(\\frac{e|W|}{m}\\right)^{m}}\\\\ &{\\quad\\leq\\left(\\frac{e(N-1)}{m}\\right)^{m}\\left(e[(2+\\epsilon)]\\left[\\log_{1+\\epsilon}\\frac{1}{\\epsilon}\\right]\\right)^{m}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "In the last inequality, we use the fact that $\\begin{array}{r}{|W|\\leq\\lceil(2+\\epsilon)m\\rceil\\left\\lceil\\log_{1+\\epsilon}\\frac{1}{\\epsilon}\\right\\rceil}\\end{array}$ ", "page_idx": 15}, {"type": "text", "text": "Finally, Theorem 3.1 follows directly from the above lemmas. ", "page_idx": 15}, {"type": "text", "text": "Theorem 3.1. Consider the_discretization $\\overline{{\\mathcal{P}}}$ as constructed in Algorithm 1. For any type distribution,there exists $p~\\in~{\\overline{{\\mathcal{P}}}}$ suchthat $\\mathrm{rev}(p)\\;\\geq\\;\\mathrm{OPT}\\,-\\,\\mathcal{O}(\\epsilon)$ :Moreover, wehave $\\left\\lceil{\\overline{{\\mathcal{P}}}}\\right\\rceil\\ \\leq$ $\\begin{array}{r}{\\left(\\frac{e(N-1)}{m}\\right)^{m}\\left(e\\lceil(2+\\epsilon)\\rceil\\left\\lceil\\log_{1+\\epsilon}\\frac{1}{\\epsilon}\\right\\rceil\\right)^{m}\\in\\widetilde{\\mathcal{O}}\\left(\\left(\\frac{N}{\\epsilon}\\right)^{m}\\right)}\\end{array}$ ", "page_idx": 16}, {"type": "text", "text": "Proof of Theorem 3.1. Combining Lemma A.1 and Lemma A.2 together, we conclude that there existspricecurve $p^{\\prime}\\in\\overline{{\\mathcal{P}}}$ such that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathrm{rev}(p^{\\prime})\\geq\\frac{\\mathrm{rev}(\\tilde{p})}{1+\\epsilon}\\geq\\frac{\\mathrm{OPT}-\\epsilon}{1+\\epsilon}\\geq\\mathrm{OPT}-\\frac{2\\epsilon}{1+\\epsilon}=\\mathrm{OPT}-\\mathcal O(\\epsilon).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The size of $\\overline{{\\mathcal{P}}}$ follows from Lemma A.3. ", "page_idx": 16}, {"type": "text", "text": "A.3 Price discretization scheme for smooth monotonic valuations ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We study discretization schemes to approximate monotone valuations under the smoothness condition in Assumption 1. Our procedure is outlined in Algorithm 5. The discretization $W$ of the valuation space follows Algorithm 1. Aditionally we uniformly splithe dataspace into multiples of $\\lfloor\\frac{\\epsilon N}{m L}\\rfloor$ \uff0c denoting them as the set $N_{\\mathbf{S}}$ . We then set the discretization $\\overline{{\\mathcal{P}}}$ to be the class of all \u201c $m$ -step\" price curves on the function space $N_{\\mathbf{S}}\\rightarrow W$ . The following theorem, proven in Appendix A.4, outlines the main properties of this discretization scheme: the size of the discretization has no dependence on thenumberofdata $N$ ", "page_idx": 16}, {"type": "text", "text": "Algorithm 5 Price discretization scheme for smooth monotonic valuations ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Given: Smoothness constant $L$ , approximation parameter $\\epsilon>0$ Let $W$ be discretization of the valuation space $[0,1]$ given in Algorithm 1. Let $N_{\\mathbf{S}}$ be the following discretization of the interval $[0,N]$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\delta\\triangleq\\left\\lfloor{\\frac{\\epsilon N}{m L}}\\right\\rfloor,\\qquad\\quad N_{\\mathbf{S}}\\triangleq\\left\\{\\delta k:\\,k\\in\\left\\lceil{\\frac{N}{\\delta}}\\right\\rceil\\right\\}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Set $\\overline{{\\mathcal{P}}}$ to be the class of all \u201c $m$ -step\" functions mapping $N_{\\mathbf{S}}\\rightarrow W$ ", "page_idx": 16}, {"type": "text", "text": "A.4Proof of Theorem 3.2 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Theorem 3.2. Consider the discretization $\\overline{{\\mathcal{P}}}$ as constructed in Algorithm 5. Under Assumption 1, for any type distribution, there exists $p\\in\\overline{{\\mathcal{P}}}$ suchthat $\\mathrm{rev}(p)\\geq\\mathrm{\\bar{O}P T}-{\\mathcal{O}}(\\epsilon)$ .Moreover, $|{\\overline{{\\mathcal{P}}}}|\\in$ $\\begin{array}{r}{\\mathcal{O}\\left(\\log_{1+\\epsilon}^{m}\\left(1/\\epsilon\\right)\\cdot\\left(L/\\epsilon\\right)^{m}\\right)\\in\\widetilde{\\mathcal{O}}\\left(\\left(\\frac{L}{\\epsilon^{2}}\\right)^{m}\\right)}\\end{array}$ ", "page_idx": 16}, {"type": "text", "text": "Proof of Theorem 3.2. By Lemma 3.1, there is a revenue optimal price curve $p^{\\star}:[N]\\rightarrow[0,1]$ which is a $k$ -step function, for some $k\\in[m]$ Where $p^{\\star}$ can be compactly represented as the following set of tuples: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\left\\{\\big(n_{1}^{\\star},p_{1}^{\\star}\\big),\\big(n_{2}^{\\star},p_{2}^{\\star}\\big),\\ldots,\\big(n_{k}^{\\star},p_{k}^{\\star}\\big)\\right\\},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $n_{1}^{\\star},\\ldots,n_{k}^{\\star}$ denote the locations of jumps and $p_{i}^{\\star}$ denote the value of $p^{\\star}$ on step $i\\in[k]$ (i.e. $p^{\\star}(n)=p_{i}^{\\star}$ for $\\ddot{n}\\in(n_{i-1}^{\\star},n_{i}^{\\star}])$ ", "page_idx": 16}, {"type": "text", "text": "Let $\\textstyle{\\bar{\\epsilon}}:={\\frac{\\epsilon}{m}}$ . Next, we generate a price $p^{\\prime}$ using Algorithm 6, which ensures that the price curve $p$ generated in the following step (13) is non-decreasing. We demonstrate that in each round of Algorithm 6, we incur a revenue loss of at most . If $p_{i}^{\\prime}>p_{i-1}^{\\prime}+\\bar{\\epsilon}$ everything remains the same and thus does not affect the expected revenue. If not, we combine the price of step $i$ with step $i-1$ , let $p_{j}^{\\prime}\\overset{\\Delta}{=}p_{j}^{\\prime}-\\left(p_{i}^{\\prime}-p_{i-1}^{\\prime}\\right)$ for $j=i,\\dots,k$ . During this process, buyers either make purchases at the same step, or switch to purchase at a higher step. Note that $p_{i}^{\\prime}-p_{i-1}^{\\prime}<\\bar{\\epsilon}$ , so the revenue loss of each type is at most . This implies that the revenue loss in each round is at most . As there are $k$ rounds, we lose expected revenue of at most $m\\bar{\\epsilon}$ . We conclude that rev $\\left(p^{\\prime}\\right)$ is within a gap of $\\epsilon$ from OPT,i.e., $\\mathrm{rev}(p^{\\prime})\\bar{\\geq}\\,\\mathrm{OPT}-\\epsilon$ ", "page_idx": 16}, {"type": "text", "text": "Input: Optimal price curve $p^{\\star}$   \nLet $p^{\\prime}=p^{\\star}$   \nfor $i=2,\\dots,k$ do if $p_{i}^{\\prime}<p_{i-1}^{\\prime}+\\bar{\\epsilon}$ then for $j=i,\\dots,k$ do $\\bar{p}_{j}^{\\prime}=p_{j}^{\\prime}-\\left(p_{i}^{\\prime}-p_{i-1}^{\\prime}\\right)\\!.$ end for end if   \nend for   \nOutput: Price curve $p^{\\prime}$ ", "page_idx": 17}, {"type": "text", "text": "After combining some steps in Algorithm 6, Assume that $p^{\\prime}$ is a $\\bar{k}$ -step function $(\\bar{k}\\leq k)$ represented by ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\left\\{(n_{1}^{\\prime},p_{1}^{\\prime}),(n_{2}^{\\prime},p_{2}^{\\prime}),\\ldots,(n_{\\bar{k}}^{\\prime},p_{\\bar{k}}^{\\prime})\\right\\}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then, we define a new price curve $p\\in\\overline{{\\mathcal{P}}}$ as follows: let $\\begin{array}{r}{\\delta:=\\,\\left\\lfloor\\frac{\\bar{\\epsilon}N}{L}\\right\\rfloor}\\end{array}$ , then $p$ is a $\\bar{k}$ -step function represented by ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\left\\{(n_{1},p_{1}),(n_{2},p_{2}),\\ldots,(n_{\\bar{k}},p_{\\bar{k}})\\right\\},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where ", "page_idx": 17}, {"type": "equation", "text": "$$\nn_{i}\\stackrel{\\Delta}{=}\\left\\lfloor\\frac{n_{i}^{\\prime}}{\\delta}\\right\\rfloor\\delta,\\quad p_{i}\\stackrel{\\Delta}{=}p_{i}^{\\prime}-i\\bar{\\epsilon}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "First, we show that no buyer who purchases at step $i$ under $p^{\\prime}$ would purchase at step $j<i$ under $p$ Let the buyer's valuation be $v$ . First, we prove that the buyer's utility is non-negative at $n_{i}$ ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{v(n_{i})-p_{i}\\geq v(n_{i}^{\\prime})-\\delta\\cdot\\displaystyle\\frac{L}{N}-p_{i}}\\\\ &{\\qquad\\qquad=v(n_{i}^{\\prime})-\\delta\\cdot\\displaystyle\\frac{L}{N}-p_{i}^{\\prime}+i\\bar{\\epsilon}}\\\\ &{\\qquad\\qquad\\geq v(n_{i}^{\\prime})-\\bar{\\epsilon}-p_{i}^{\\prime}+i\\bar{\\epsilon}}\\\\ &{\\qquad=v(n_{i}^{\\prime})-p_{i}^{\\prime}+(i-1)\\bar{\\epsilon}}\\\\ &{\\qquad\\geq v(n_{i}^{\\prime})-p_{i}^{\\prime}}\\\\ &{\\qquad\\geq0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\mathrm{as}\\ \\delta\\cdot\\frac{L}{N}\\leq\\frac{L}{N}\\cdot\\frac{\\bar{\\epsilon}N}{L}=\\bar{\\epsilon}.)}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then, we prove that the buyer's utility at $n_{i}$ is larger than that of $n_{j}$ for $j<i$ , therefore, the buyer would not prefer buying at step $j<i$ under price $p$ ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{v(n_{i})-p_{i}-(v(n_{j})-p_{j})\\geq v(n_{i}^{\\prime})-\\delta\\cdot\\frac{L}{N}-v(n_{j}^{\\prime})-(p_{i}-p_{j})~}}&{(\\mathrm{by~}L/N\\mathrm{-}\\mathrm{Smoothness~of~}v.)}}\\\\ &{}&{=v(n_{i}^{\\prime})-\\delta\\cdot\\frac{L}{N}-v(n_{j}^{\\prime})-(p_{i}^{\\prime}-p_{j}^{\\prime}-(i-j)\\bar{\\epsilon})}\\\\ &{}&{\\geq v(n_{i}^{\\prime})-\\bar{\\epsilon}-v(n_{j}^{\\prime})-(p_{i}^{\\prime}-p_{j}^{\\prime}-(i-j)\\bar{\\epsilon})~(\\mathrm{as}\\ \\delta\\cdot\\frac{L}{N}\\leq\\frac{L}{N}\\cdot\\frac{\\bar{\\epsilon}N}{L}=\\bar{\\epsilon})}\\\\ &{}&{=(v(n_{i}^{\\prime})-p_{i}^{\\prime})-(v(n_{j}^{\\prime})-p_{j}^{\\prime})+(i-j-1)\\bar{\\epsilon}}\\\\ &{}&{\\geq(v(n_{i}^{\\prime})-p_{i}^{\\prime})-(v(n_{j}^{\\prime})-p_{j}^{\\prime})}\\\\ &{}&{\\geq0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Finally, fix the type distribution $(q_{1},\\ldots,q_{m})$ , then we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{rev}(p^{\\prime})-\\mathrm{rev}(p)\\leq\\sum_{h=1}^{m}q_{h}\\left(\\sum_{i=1}^{k}(p_{i}^{\\prime}-p_{i})\\cdot\\mathbb{I}(\\mathrm{Type}~j~\\mathrm{purchase}~\\mathfrak{a t}~p_{i}^{\\prime}~\\mathrm{under}~\\mathrm{price}~p^{\\prime})\\right)\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Hence, $\\operatorname{rev}(p)$ is within a gap of $2\\epsilon$ from OPT. ", "page_idx": 18}, {"type": "text", "text": "Wethen applyTheorem 3.1 to price $p$ . Therefore, it is enough to consider price functions from the set $N_{\\mathbf{S}}\\triangleq\\{k\\delta:k=1,\\ensuremath{\\dots},\\lceil\\frac{N}{\\delta}\\rceil\\}\\subseteq[N]$ $W$ to aproximate therevenue within $O(\\epsilon)$ gap,. Moreover, this discretizatonis f the ize $\\begin{array}{r}{\\left\\lceil\\frac{N}{\\delta}\\right\\rceil^{|W|}\\in\\mathcal{O}\\left(\\left(\\log_{1+\\epsilon}\\left(\\frac{1}{\\epsilon}\\right)\\right)^{m}\\left(\\frac{L}{\\epsilon}\\right)^{m}\\right)}\\end{array}$ $\\begin{array}{r}{\\left\\lceil\\frac{N}{\\delta}\\right\\rceil\\in\\mathcal{O}\\left(\\frac{L m}{\\epsilon}\\right)}\\end{array}$ \u53e3 ", "page_idx": 18}, {"type": "text", "text": "A.5Proof of Theorem 3.3 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Theorem 3.3. Consider the discretization $\\overline{{\\mathcal{P}}}$ as constructed in Algorithm 2. Under Assumption 2, for any type distribution, there exists $p\\in\\overline{{\\mathcal{P}}}$ such thatre $\\mathrm{v}(p)\\geq\\mathrm{OPT}-{\\mathcal{O}}(\\epsilon)$ Moreover, ", "page_idx": 18}, {"type": "equation", "text": "$$\n|\\overline{{\\mathcal{P}}}|\\in\\mathcal{O}\\left(\\left(\\frac{J}{\\epsilon^{2}}\\right)^{m}\\log^{m}\\left(\\frac{N\\epsilon^{2}}{J m}\\right)\\cdot\\left(\\log_{1+\\epsilon}^{m}1/\\epsilon\\right)\\right)\\in\\widetilde{\\mathcal{O}}\\left(\\left(\\frac{J}{\\epsilon^{3}}\\right)^{m}\\right).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Prof f Theorem 3 For ach $\\begin{array}{r}{i=0,1,\\ldots,\\left\\lceil\\log_{1+\\epsilon^{2}}\\left(\\frac{N\\epsilon^{2}}{2J m}\\right)\\right\\rceil}\\end{array}$ $\\begin{array}{r}{Y_{i}\\overset{\\Delta}{=}\\left\\lfloor\\frac{2J m}{\\epsilon^{2}}(1+\\epsilon^{2})^{i}\\right\\rfloor}\\end{array}$ and $Q_{i}$ be the set $\\begin{array}{r}{\\left\\{\\left.\\left[Y_{i}+\\frac{Y_{i}\\epsilon^{2}}{2J m}k\\right]:k=1,\\ldots,\\lfloor2J m\\right\\rfloor\\right\\}}\\end{array}$ ,i.e, $Q_{i}$ splits the interal $[Y_{i},Y_{i+1}]$ equally into $2m J$ parts. ", "page_idx": 18}, {"type": "text", "text": "The union of $Q_{i}\\mathbf{s}$ and the set $\\left\\{1,2,\\ldots,\\left\\lfloor{\\frac{2J m}{\\epsilon^{2}}}\\right\\rfloor\\right\\}$ form a set of grids on $[0,N]$ , denoted by $N_{\\mathbf{D}}$ .There are at most $\\begin{array}{r}{\\frac{2J m}{\\epsilon^{2}}+2J m\\log_{1+\\epsilon^{2}}\\left(\\frac{N\\epsilon^{2}}{2J m}\\right)}\\end{array}$ grids in total. ", "page_idx": 18}, {"type": "text", "text": "By Lemma 3.1, there is a revenue optimal price curve $p^{\\star}:[N]\\rightarrow[0,1]$ which is a $k$ -step function, for some $k\\in[m]$ Where $p^{\\star}$ can be compactly represented as the following set of tuples: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\{(n_{1}^{\\star},p_{1}^{\\star}),(n_{2}^{\\star},p_{2}^{\\star}),\\ldots,(n_{k}^{\\star},p_{k}^{\\star})\\right\\},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $n_{1}^{\\star},\\ldots,n_{k}^{\\star}$ denote the locations of jumps and $p_{i}^{\\star}$ denote the value of $p^{\\star}$ on step $i\\in[k]$ (i.e. $p^{\\star}(n)=p_{i}^{\\star}$ for $\\ddot{n}\\in(n_{i-1}^{\\star},n_{i}^{\\star}])$ \uff1a ", "page_idx": 18}, {"type": "text", "text": "Then, define a new $k$ -step price curve $p$ via ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\{(n_{1},p_{1}),(n_{2},p_{2}),\\ldots,(n_{k},p_{k})\\right\\},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $n_{i}$ is given by ", "page_idx": 18}, {"type": "text", "text": "Then we define $p_{i}$ below. If $p_{i}^{\\star}<\\epsilon(1+\\epsilon)$ , let $p_{i}=\\epsilon(1+\\epsilon)$ ; otherwise, let $Z_{n_{i}^{\\star}}$ be the price obtained by rounding $p_{i}^{\\star}$ down to the nearest value in $Z$ . By constructions of $Z$ and $W$ above, $W_{n_{i}^{\\star}}$ is a partition of interval $(Z_{n_{i}^{\\star}-1},Z_{n_{i}^{\\star}+1})$ . Let $w_{i}$ be the price obtained by rounding $p_{i}^{\\star}$ down to the nearest value in $W_{n_{i}^{\\star}}$ . Set $\\begin{array}{r}{d_{i}\\triangleq\\frac{\\epsilon}{m}\\cdot Z_{n_{i}^{\\star}-1}}\\end{array}$ . Then define $p_{i}\\overset{\\Delta}{=}w_{i}-i\\cdot d_{i}\\in W_{n_{i}^{\\star}}$ ", "page_idx": 18}, {"type": "text", "text": "First, we prove for $i$ satisfying $p_{i}^{\\star}>\\epsilon(1+\\epsilon)$ , if a buyer purchases at $n_{i}$ under price $p^{\\star}$ , she will not purchase at $n_{j}$ \uff0c $j<i$ under new price $p$ . We prove this property separately when $\\begin{array}{r}{n_{i}\\le\\frac{2J m}{\\epsilon^{2}}}\\end{array}$ 2Jm and $\\begin{array}{r}{n_{i}>\\frac{2J m}{\\epsilon^{2}}}\\end{array}$ ", "page_idx": 18}, {"type": "text", "text": "(i) When $\\begin{array}{r}{n_{i}>\\frac{2J m}{\\epsilon^{2}}}\\end{array}$ ", "page_idx": 18}, {"type": "text", "text": "The buyer's utility at $n_{i}$ under price $p$ is, ", "page_idx": 18}, {"type": "equation", "text": "$$\nv(n_{i})-p_{i}=v(n_{j}^{\\star})-p_{i}^{\\star}+(p_{i}^{\\star}-p_{i}-(v(n_{i}^{\\star})-v(n_{i})))\\,.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Let $\\delta_{i}\\triangleq v(n_{i}^{\\star})-v(n_{i})$ Then $\\delta_{i}$ is upper bounded by, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\delta_{i}=\\sum_{h=n_{i}}^{n_{i}^{\\star}-1}v(h+1)-v(h)\\leq\\sum_{h=n_{i}}^{n_{i}^{\\star}-1}\\frac{J}{h}\\leq\\frac{J}{n_{i}}(n_{i}^{\\star}-n_{i})\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\leq{\\frac{J}{n_{i}}}\\cdot\\left(n_{i}\\cdot{\\frac{\\epsilon^{2}}{2m J}}+1\\right)={\\frac{\\epsilon^{2}}{2m}}+{\\frac{J}{n_{i}}}\\leq{\\frac{\\epsilon^{2}}{2m}}+{\\frac{\\epsilon^{2}}{2m}}={\\frac{\\epsilon^{2}}{m}},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the third inequality is due to Lemma A.4. ", "page_idx": 19}, {"type": "text", "text": "By the construction of $p$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\np_{i}^{\\star}-p_{i}=Z_{n_{i}-1}\\cdot\\frac{\\epsilon i}{m}\\geq\\frac{\\epsilon^{2}i}{m}\\geq\\frac{\\epsilon^{2}}{m}\\geq\\delta_{i}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, by (14), $v(n_{i})-p_{i}\\geq v(n_{i}^{\\star})-p_{i}^{\\star}\\geq0$ buyer's utility at $n_{i}$ under price $p$ is non-negative. ", "page_idx": 19}, {"type": "text", "text": "Next, we claim that $v(n_{i})\\,-\\,p_{i}\\,-\\,(v(n_{j})-p_{j})\\,\\geq\\,0$ To prove this, for any $j~<~i$ let $\\delta_{j}\\;\\triangleq$ $v(n_{j}^{\\star})-v(n_{j})$ , then we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{v(n_{i})-p_{i}-(v(n_{j})-p_{j})}}\\\\ {{=v(n_{i}^{\\star})-p_{i}^{\\star}-(v(n_{j}^{\\star})-p_{j}^{\\star})+(p_{i}^{\\star}-p_{i}-\\delta_{i})-(p_{j}^{\\star}-p_{j}-\\delta_{j})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Where $v(n_{i}^{\\star})-p_{i}^{\\star}-(v(n_{j}^{\\star})-p_{j}^{\\star})\\geq0$ because the buyer prefers $n_{i}^{\\star}$ over $n_{j}^{\\star}$ under price $p^{\\star}$ . Recall that we have $\\delta_{j}\\geq0$ , then we bound $\\delta_{i}-\\delta_{j}$ as follows, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\delta_{i}-\\delta_{j}\\leq\\delta_{i}\\leq\\frac{\\epsilon^{2}}{m}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "By the construction of $p_{i}$ , we have, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{p_{i}^{\\star}-p_{i}-(p_{j}^{\\star}-p_{j})=Z_{n_{i}-1}\\cdot\\frac{\\epsilon i}{m}-Z_{n_{j}-1}\\cdot\\frac{\\epsilon j}{m}}\\\\ &{\\phantom{m m m m m m}\\geq Z_{n_{j}-1}\\cdot\\left(\\frac{\\epsilon i}{m}-\\frac{\\epsilon j}{m}\\right)}\\\\ &{\\phantom{m m m m m m}\\geq Z_{n_{j}-1}\\cdot\\left(\\frac{\\epsilon}{m}\\right)}\\\\ &{\\phantom{m m m m m m}\\geq\\frac{\\epsilon^{2}}{m}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, combining (17) and (18) together, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\nv(n_{i})-p_{i}-(v(n_{j})-p_{j})\\geq v(n_{i}^{\\star})-p_{i}^{\\star}-(v(n_{j}^{\\star})-p_{j}^{\\star})\\geq0.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We conclude that under price $p$ , the buyer prefers $n_{i}$ over $n_{j}$ , for any $j<i$ ", "page_idx": 19}, {"type": "text", "text": "(ii) When $\\begin{array}{r}{n_{i}\\le\\frac{2J m}{\\epsilon^{2}}}\\end{array}$ ", "page_idx": 19}, {"type": "text", "text": "In this case, $n_{i}=n_{i}^{\\star}$ , and for any $j<i$ we still have $n_{j}=n_{j}^{\\star}$ . First, we prove the buyer's utility at $n_{i}^{\\prime}$ under $p$ is non-negative: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{v(n_{i})-p_{i}=v(n_{i}^{\\star})-p_{i}}\\\\ &{\\phantom{\\sum}=v(n_{i}^{\\star})-p_{i}^{\\star}+(p_{i}^{\\star}-p_{i})}\\\\ &{\\phantom{\\sum}\\geq v(n_{i}^{\\star})-p_{i}^{\\star}}\\\\ &{\\phantom{\\sum}\\geq0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Then, we show that the buyer prefers $n_{i}$ over $n_{j}$ under $p$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{v(n_{i})-p_{i}-(v(n_{j})-p_{j})=v(n_{i}^{\\star})-p_{i}^{\\star}-(v(n_{j}^{\\star})-p_{j}^{\\star})+(p_{i}^{\\star}-p_{i}-\\delta_{i})-(p_{j}^{\\star}-p_{j}-\\delta_{j})}\\\\ &{\\phantom{x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x}}\\\\ &{\\phantom{x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x}=v(n_{i}^{\\star})-p_{i}^{\\star}-(v(n_{j}^{\\star})-p_{j}^{\\star})+(p_{i}^{\\star}-p_{i})-(p_{j}^{\\star}-p_{j})}\\\\ &{\\phantom{x x x x x x x}\\geq v(n_{i}^{\\star})-p_{i}^{\\star}-(v(n_{j}^{\\star})-p_{j}^{\\star})}\\\\ &{\\phantom{x x x x x x x}\\geq v(n_{i}^{\\star})-p_{i}^{\\star}-(v(n_{j}^{\\star})-p_{j}^{\\star})}\\\\ &{\\phantom{x x x x x x}\\geq0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the first inequality is due to (18), and the second is because the buyer prefers $n_{i}^{\\star}$ over $n_{j}^{\\star}$ under $p^{\\star}$ ", "page_idx": 19}, {"type": "text", "text": "So far we have completed the proof that for $i$ satisfying $p_{i}^{\\star}>\\epsilon(1+\\epsilon)$ , if a buyer purchases at $n_{i}$ under price $p^{\\star}$ , she will not purchase at $n_{j}$ \uff0c $j<i$ under new price $p$ ", "page_idx": 19}, {"type": "text", "text": "Then, similar to Step 2 in the proof of Lemma A.2, we have $\\begin{array}{r}{p\\geq\\frac{p^{\\star}}{1+\\epsilon}}\\end{array}$ pointwise. We then conclude the proof by observing ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathrm{rev}(p)\\geq\\frac{\\mathrm{rev}(p^{\\star})-\\mathcal{O}(\\epsilon)}{1+\\epsilon}=\\mathrm{OPT}-\\mathcal{O}(\\epsilon).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Lemma A.4.When $\\begin{array}{r}{n_{i}>\\frac{2J m}{\\epsilon^{2}}}\\end{array}$ wehave $\\begin{array}{r}{n_{j}^{\\star}-n_{i}\\le n_{i}\\cdot\\frac{\\epsilon^{2}}{2J m}+1.}\\end{array}$ ", "page_idx": 20}, {"type": "text", "text": "Proof of Lemma A.4. By the construction of discretization set, $n_{i}$ must have the following form, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\left|Y_{i^{\\prime}}+Y_{i^{\\prime}}\\cdot\\frac{\\epsilon^{2}k^{\\prime}}{2J m}\\right|,\\;\\mathrm{where}\\;Y_{i^{\\prime}}=\\left\\lfloor\\frac{2J m}{\\epsilon^{2}}(1+\\epsilon^{2})^{i^{\\prime}}\\right\\rfloor\\;\\mathrm{for~some}\\;i^{\\prime},k^{\\prime}\\in\\mathbb{Z}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Since $n_{j}^{\\prime}$ is obtained by rounding down $n_{j}$ to the nearest grid in $N_{\\mathbf{p},\\,}n_{j}$ satisfies the following inequality, ", "page_idx": 20}, {"type": "equation", "text": "$$\nn_{j}\\le n_{j}^{\\star}\\le Y_{i^{\\prime}}+Y_{i^{\\prime}}\\cdot\\frac{\\epsilon^{2}(k^{\\prime}+1)}{2J m}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Therefore, we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{n_{i}^{\\star}-n_{i}\\le Y_{i^{\\prime}}+Y_{i^{\\prime}}\\cdot\\frac{\\epsilon^{2}\\left(k^{\\prime}+1\\right)}{2J m}-n_{i}}\\\\ &{\\qquad\\qquad=Y_{i^{\\prime}}+Y_{i^{\\prime}}\\cdot\\frac{\\epsilon^{2}\\left(k^{\\prime}+1\\right)}{2J m}-\\left[Y_{i^{\\prime}}+Y_{i^{\\prime}}\\cdot\\frac{\\epsilon^{2}k^{\\prime}}{2J m}\\right]}\\\\ &{\\qquad\\le Y_{i^{\\prime}}+Y_{i^{\\prime}}\\cdot\\frac{\\epsilon^{2}\\left(k^{\\prime}+1\\right)}{2J m}-\\left(Y_{i^{\\prime}}+Y_{i^{\\prime}}\\cdot\\frac{\\epsilon^{2}k^{\\prime}}{2J m}\\right)+1}\\\\ &{\\qquad=Y_{i^{\\prime}}\\cdot\\frac{\\epsilon^{2}}{2J m}+1}\\\\ &{\\qquad\\le n_{i}\\cdot\\frac{\\epsilon^{2}}{2J m}+1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Where in the last inequality, since $Y_{i^{\\prime}}$ is an integer, and we have ", "page_idx": 20}, {"type": "equation", "text": "$$\nn_{i}^{\\prime}=\\left\\lfloor Y_{i^{\\prime}}+Y_{i^{\\prime}}\\cdot{\\frac{\\epsilon^{2}k^{\\prime}}{2J m}}\\right\\rfloor\\geq Y_{i^{\\prime}},{\\mathrm{~for~}}k^{\\prime}\\geq0.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "B Proof of Theorem 5.1 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Theorem5.1.Suppose inAlgorithm $^{4}$ we use a discretization $\\overline{{\\mathcal{P}}}$ which is a ${\\mathcal{O}}(1/{\\sqrt{T}})$ additive approximationto anypricecurve.Let $R_{T}$ be as defined in (4). Then, for Algorithm 4, we have $\\mathbb{E}[R_{T}]~\\in$ $\\mathcal{O}\\left(m^{2}\\theta T+\\theta^{-1}\\left(1+\\log\\left|\\overline{{\\mathcal{P}}}\\right|\\right)\\right)$ . Setting $\\begin{array}{r}{\\theta=\\sqrt{\\frac{1+\\log\\left|\\overline{{\\mathcal{P}}}\\right|}{m^{2}T}}}\\end{array}$ we have $\\mathbb{E}[R_{T}]\\;\\in\\;\\mathcal{O}\\big(m\\sqrt{T\\log\\vert\\overline{{\\mathcal{P}}}\\vert}\\big)$ ", "page_idx": 20}, {"type": "text", "text": "Proof of Theorem 5.1. Recall that the regret $R_{T}$ for the adversarial setting is ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R_{T}\\,\\stackrel{\\Delta}{=}\\,\\underset{p\\in\\mathcal{P}}{\\operatorname*{max}}\\displaystyle\\sum_{t=1}^{T}r(i_{t},p)\\,-\\,\\sum_{t=1}^{T}r(i_{t},p_{t})}\\\\ &{=\\underbrace{\\underset{p\\in\\mathcal{P}}{\\operatorname*{max}}\\displaystyle\\sum_{t=1}^{T}r(i_{t},p)\\,-\\,\\underset{p\\in\\mathcal{P}}{\\operatorname*{max}}\\displaystyle\\sum_{t=1}^{T}r(i_{t},p)}_{\\mathrm{Los~of~revenue~ducretization}}\\,+\\,\\underbrace{\\underset{p\\in\\mathcal{P}}{\\operatorname*{max}}\\displaystyle\\sum_{t=1}^{T}r(i_{t},p)\\,-\\,\\sum_{t=1}^{T}r(i_{t},p_{t})}_{\\triangleq\\,\\overline{{R}}_{T}\\mathrm{~(discretization~regret)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Wedecompose $R_{T}$ into two regrets. The first term is the sacrifice of revenue on discretization. The second term is the algorithm regret when competing against the optimal price within the discretization set $\\overline{{\\mathcal{P}}}$ ", "page_idx": 20}, {"type": "text", "text": "According to Theorem 3.1, our discretization scheme approaches optimal revenue within a gap of $\\frac{2\\epsilon}{1{+}\\epsilon}$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{p\\in\\mathcal{P}}\\sum_{t=1}^{T}r(i_{t},p)\\:-\\:\\operatorname*{max}_{p\\in\\mathcal{P}}\\sum_{t=1}^{T}r(i_{t},p)\\leq\\frac{2\\epsilon T}{1+\\epsilon}<2\\epsilon T.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Therefore, the first term can be bounded by $2\\epsilon T$ ", "page_idx": 21}, {"type": "text", "text": "According to Theorem B.1, the second term discretization regret is upper bounded by ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\overline{{R}}_{T}]\\leq3m\\sqrt{T\\log\\left|\\overline{{\\mathcal{P}}}\\right|}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Combining (20) and (21) together, we have, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[R_{T}]\\leq2\\epsilon T+3m\\sqrt{T\\log\\left|\\overline{{\\mathcal{P}}}\\right|}=\\mathcal{O}\\left(m\\sqrt{T\\log\\left|\\overline{{\\mathcal{P}}}\\right|}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\mathrm{as}\\;\\epsilon=\\frac{1}{\\sqrt{T}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Plug in the size of discretization set in Section 3, we have, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}[R_{T}]={\\widetilde{\\mathcal{O}}}\\left(m^{3/2}{\\sqrt{T}}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "TheoreB. Thdisretanege $\\overline{{R}}_{T}$ defned in (19 has upper boud $\\mathcal{O}\\left(m\\sqrt{T\\log\\left|\\overline{{\\mathcal{P}}}\\right|}\\right)$ ", "page_idx": 21}, {"type": "text", "text": "Proof of Theorem B.1. We first claim that $r_{t}(p_{t})=r(i_{t},p_{t})$ all $t$ . If the buyer make a purchase at round $t$ $r_{t}(p_{t})=r(i_{t},p_{t})$ holds by definition. But if the buyer does not purchase at a price $p_{t}$ on round $t$ $r(i_{t},p_{t})=0$ . Since $S_{t}^{c}$ contains all the types that would not make a purchase at $p_{t}$ ,wehave $r(i,p_{t})=\\mathrm{0}$ $\\forall i\\in S_{t}^{c}$ , and ", "page_idx": 21}, {"type": "equation", "text": "$$\nr(i_{t},p_{t})=\\sum_{i\\in S_{t}^{c}}r(i,p_{t})=r_{t}(p_{t})=0.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Therefore, $r_{t}(p_{t})=r(i_{t},p_{t})$ holds for every round $t\\in[T]$ . Denote $p^{\\star}$ as, ", "page_idx": 21}, {"type": "equation", "text": "$$\np^{\\star}=\\underset{p\\in\\overline{{\\mathcal{P}}}}{\\mathrm{argmax}}\\,\\sum_{t=1}^{T}r(i_{t},p).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Then, we decompose the regret as follows, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\xi[R_{T}]=\\sum_{t=1}^{T}r(i_{t},p^{\\star})-\\mathbb{E}\\left[\\sum_{t=1}^{T}r(i_{t},p_{t})\\right]}}\\ ~}\\\\ {{\\displaystyle{~~~~=\\sum_{t=1}^{T}r(i_{t},p^{\\star})-\\mathbb{E}\\left[\\sum_{t=1}^{T}r_{t}(p_{t})\\right]}}\\ ~}\\\\ {{\\displaystyle{~~~~=\\mathbb{E}\\left[\\sum_{t=1}^{T}(r(i_{t},p^{\\star})-r_{t}(p^{\\star}))\\right]+\\mathbb{E}\\left[\\sum_{t=1}^{T}r_{t}(p^{\\star})-\\sum_{t=1}^{T}r_{t}(p_{t+1})\\right]+\\mathbb{E}\\left[\\sum_{t=1}^{T}r_{t}(p_{t+1})-r_{t}(p_{t})\\right]}}\\ ~}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We bound three terms in (22) separately. ", "page_idx": 21}, {"type": "text", "text": "The first term. For any price $p$ and any round $t$ we have $r_{t}(p)\\geq r(i_{t},p)$ by definition. Hence, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\left(r(i_{t},p^{\\star})-r_{t}(p^{\\star})\\right)\\leq0.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The second term. Since $\\boldsymbol{p}^{\\star}=\\underset{\\boldsymbol{p}\\in\\overline{{\\mathcal{P}}}}{\\mathrm{argmax}}\\,\\sum_{t=1}^{T}\\boldsymbol{r}(i_{t},\\boldsymbol{p})$ . We apply Lemma B.1 to $p^{\\star}$ \uff0c ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}r_{t}(p^{\\star})-\\sum_{t=1}^{T}r_{t}(p_{t+1})\\leq\\theta_{p_{1}}-\\theta_{p^{\\star}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Note that both $\\theta_{p_{1}}$ and $\\theta_{p^{\\star}}$ are drawn i.i.d. from exponential distribution, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\theta_{p_{1}}]\\leq\\mathbb{E}\\left[\\operatorname*{max}_{p\\in\\overline{{\\mathcal{P}}}}\\theta_{p}\\right]\\leq\\frac{1+\\log\\left|\\overline{{\\mathcal{P}}}\\right|}{\\theta},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\theta_{p^{\\star}}]\\leq\\mathbb{E}\\left[\\operatorname*{max}_{p\\in\\overline{{\\mathcal{P}}}}\\theta_{p}\\right]\\leq\\frac{1+\\log\\left|\\overline{{\\mathcal{P}}}\\right|}{\\theta}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T}r_{t}(p^{\\star})-\\sum_{t=1}^{T}r_{t}(p_{t+1})\\right]\\leq\\mathbb{E}\\bigl[\\theta_{p_{1}}-\\theta_{p^{\\star}}\\bigr]\\leq\\frac{1+\\log\\left|\\overline{{\\mathcal{P}}}\\right|}{\\theta}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The third term. Note that for any price $p\\in\\overline{{\\mathcal{P}}}$ and any round $t$ $r_{t}(p)\\leq m$ . Therefore we have, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[r_{t}(p_{t+1})-r_{t}(p_{t})\\right]=\\mathbb{P}\\left(p_{t+1}\\neq p_{t}\\right)\\mathbb{E}\\left[r_{t}(p_{t+1})-r_{t}(p_{t})\\mid p_{t+1}\\neq p_{t}\\right]\\leq m\\cdot\\mathbb{P}\\left(p_{t+1}\\neq p_{t}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The price curve on round $t$ is $p_{t}$ , then by the price updation rule. ", "page_idx": 22}, {"type": "equation", "text": "$$\np_{t}=\\underset{p\\in\\overline{{\\mathcal{P}}}}{\\mathrm{argmax}}\\sum_{\\tau=1}^{t-1}r_{\\tau}(p)+\\theta_{p},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "which is equivalent to, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\theta_{p t}\\geq\\theta_{p}+\\sum_{\\tau=1}^{t-1}r_{\\tau}(p)-\\sum_{\\tau=1}^{t-1}r_{\\tau}(p_{t}),\\,\\forall p\\in\\overline{{\\mathcal{P}}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "For all $p^{\\prime}\\in\\overline{{\\mathcal{P}}}$ , let $c_{t-1,p^{\\prime}}$ denote ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{p\\in\\overline{{\\mathcal{P}}}}\\left(\\theta_{p}+\\sum_{\\tau=1}^{t-1}r_{\\tau}(p)-\\sum_{\\tau=1}^{t-1}r_{\\tau}(p^{\\prime})\\right)\\triangleq c_{t-1,p^{\\prime}},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "then $p_{t}=p^{\\prime}$ is equivalent to ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\theta_{p^{\\prime}}\\geq c_{t-1,p^{\\prime}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Subclaim. If $\\theta_{p_{t}}$ also satisfies the following condition (27) ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\theta_{p_{t}}\\geq\\theta_{p}+\\sum_{\\tau=1}^{t-1}r_{\\tau}(p)-\\sum_{\\tau=1}^{t-1}r_{\\tau}(p_{t})+m,\\,\\forall p\\in\\overline{{\\mathcal{P}}},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "then pt+1 = Pt\u00b7 ", "page_idx": 22}, {"type": "text", "text": "Proof of the Subclaim. If (27) holds for all $p\\in\\overline{{\\mathcal{P}}}$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{c l}{\\displaystyle\\theta_{p_{t}}\\geq\\theta_{p}+\\sum_{\\tau=1}^{t-1}r_{\\tau}(p)-\\displaystyle\\sum_{\\tau=1}^{t-1}r_{\\tau}(p_{t})+m}\\\\ {\\geq\\theta_{p}+\\displaystyle\\sum_{\\tau=1}^{t}r_{\\tau}(p)-\\displaystyle\\sum_{\\tau=1}^{t}r_{\\tau}(p_{t}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Hence, ", "page_idx": 22}, {"type": "equation", "text": "$$\np_{t}=\\underset{p\\in\\overline{{\\mathcal{P}}}}{\\mathrm{argmax}}\\sum_{\\tau=1}^{t}r_{\\tau}(p)+\\theta_{p}=p_{t+1}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "\u53e3", "page_idx": 22}, {"type": "text", "text": "Therefore, (27) is a sufficient condition for $p_{t+1}=p_{t}$ . We then bound the probability of $p_{t+1}=p_{t}$ by computing the probability of (27) happening. ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{P}\\left(p_{t}=p_{t+1}\\right)=\\displaystyle\\sum_{p\\in\\overline{{\\mathcal{P}}}}\\mathbb{P}\\left(p_{t}=p\\right)\\mathbb{P}\\left(p_{t+1}=p\\mid p_{t}=p\\right)}&{}\\\\ {=\\displaystyle\\sum_{p\\in\\overline{{\\mathcal{P}}}}\\mathbb{P}\\left(p_{t}=p\\right)\\mathbb{P}\\left(p_{t+1}=p\\mid\\theta_{p}\\geq c_{t-1,p}\\right)}&{}\\\\ {\\ge\\displaystyle\\sum_{p\\in\\overline{{\\mathcal{P}}}}\\mathbb{P}\\left(p_{t}=p\\right)\\mathbb{P}\\left(\\theta_{p}\\geq c_{t-1,p}+m\\mid\\theta_{p}\\geq c_{t-1,p}\\right)}&{}\\\\ {\\ge\\displaystyle\\sum_{p\\in\\overline{{\\mathcal{P}}}}\\mathbb{P}\\left(p_{t}=p\\right)e^{-m\\theta}}&{}\\\\ {=e^{-m\\theta}}&{}\\\\ {\\ge1-m\\theta}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Therefore, $\\mathbb{P}\\left(p_{t}\\neq p_{t+1}\\right)\\leq m\\theta$ . Hence, the third term can be bounded as ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}\\big[r_{t}(p_{t+1})-r_{t}(p_{t})\\big]\\leq m^{2}\\theta\\implies\\sum_{t=1}^{T}\\mathbb{E}\\big[r_{t}(p_{t+1})-r_{t}(p_{t})\\big]\\leq m^{2}\\theta T.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Set $\\theta=\\sqrt{\\frac{\\log\\left|\\overline{{\\mathcal{P}}}\\right|}{m^{2}T}}$ Combining theupbos for tr tems 23), (24ad28gehr, weha ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}[R_{T}]\\leq\\frac{1+\\log\\left|\\overline{{\\mathcal{P}}}\\right|}{\\theta}+m^{2}\\theta T\\in\\mathcal{O}\\left(m\\sqrt{T\\log\\left|\\overline{{\\mathcal{P}}}\\right|}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Plugging in the size of the discretization set (Theorem 3.1), we have, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}[R_{T}]\\in{\\widetilde{\\mathcal{O}}}\\left(m^{3/2}{\\sqrt{T}}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Lemma B.1. For any $p\\in\\overline{{\\mathcal{P}}}$ ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}r_{t}(p_{t+1})+\\theta_{p_{1}}\\geq\\sum_{t=1}^{T}r_{t}(p)+\\theta_{p}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof of Lemma B.1. We prove this by induction. For $T\\,=\\,0$ , the inequality $\\theta_{p1}\\;\\geq\\;\\theta_{p}$ holds by definition $p_{1}=\\mathrm{argmax}\\:\\theta_{p}$ . Assume that the inequality holds for some $T$ . Then for any $p\\in\\overline{{\\mathcal{P}}}$ \uff0c $p{\\in}\\overline{{\\mathcal{P}}}$ ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{t=1}^{T+1}r_{t}(p_{t+1})+\\theta_{p_{1}}=\\displaystyle\\sum_{t=1}^{T}r_{t}(p_{t+1})+\\theta_{p_{1}}+r_{T+1}(p_{T+2})}\\\\ {\\displaystyle\\geq\\sum_{t=1}^{T}r_{t}(p_{T+2})+\\theta_{p_{T+2}}+r_{T+1}(p_{T+2})}\\\\ {\\displaystyle=\\sum_{t=1}^{T+1}r_{t}(p_{T+2})+\\theta_{p_{T+2}}}\\\\ {\\displaystyle\\geq\\sum_{t=1}^{T+1}r_{t}(p)+\\theta_{p}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Where the first inequality is by the induction hypothesis, and the second inequality is by ", "page_idx": 23}, {"type": "equation", "text": "$$\np_{T+2}=\\underset{p\\in\\overline{{\\mathcal{P}}}}{\\arg\\operatorname*{max}}\\sum_{t=1}^{T+1}r_{t}(p)+\\theta_{p}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "By the induction, the inequality (29) holds for any $T\\geq0$ ", "page_idx": 23}, {"type": "text", "text": "C Proof of Theorem 4.1 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In this section, we prove, Theorem 4.1, our regret upper bound of Algorithm 3. We prove the theorem by first decomposing the regret into two parts: Regret with respect to the best price in a discretized set (called \u201cdiscretization regret') and the residual error due to discretization. The residual error is controlled by the approximation guarantees developed in Section 3. Then, the key lemma in this appendix is Lemma C.1 which controls the discretization. We prove Lemma C.1 using a technique adapted from Chen et al. [15]. ", "page_idx": 24}, {"type": "text", "text": "Theorem 4.1. Suppose in Algorithm 3 we use a discretization $\\overline{{\\mathcal{P}}}$ whichisa $\\mathcal{O}(1/\\sqrt{T})$ additive approximation to any price curve. Then, the regret of Algorithm 3 satisfies $\\mathbb{E}[R_{T}]\\in\\tilde{\\mathcal{O}}(m\\sqrt{T})$ ", "page_idx": 24}, {"type": "text", "text": "Proof of Theorem 4.1. For the sake of simplicity, we define $r(i,p)$ as the revenue under type $i$ and price $p$ i.e, $r(i,p)\\,\\stackrel{\\Delta}{=}\\,p(n_{i,p})$ Therefore, on every round, we have $r(i_{t},p_{t})=p_{t}(n_{i_{t},p_{t}})$ ", "page_idx": 24}, {"type": "text", "text": "Recall that the regret $R_{T}$ is ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{{R_{T}\\ \\triangleq\\ T\\cdot\\mathrm{OPT}\\ -\\displaystyle\\sum_{t=1}^{T}p_{t}(n_{i_{t,p_{t}}})}}\\\\ {{~~}}\\\\ {{~~=\\ T\\cdot\\mathrm{OPT}-\\displaystyle\\sum_{t=1}^{T}r(i_{t},p_{t})}}\\\\ {{~~}}\\\\ {{~~=\\underbrace{T\\cdot\\mathrm{OPT}\\ -\\ T\\cdot\\operatorname*{max}_{p\\in\\overline{{\\mathcal{P}}}}\\mathrm{ev}(p)}_{t\\in\\overline{{\\mathcal{P}}}}\\ +\\ T\\cdot\\operatorname*{max}_{p\\in\\overline{{\\mathcal{P}}}}\\mathrm{ev}(p)\\ -\\displaystyle\\sum_{t=1}^{T}r(i_{t},p_{t}).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Wedecompose $R_{T}$ into two parts. The first term is the sacrifice of revenue on discretization. The second term is the algorithm regret when competing against the optimal price within the discretization set $\\overline{{\\mathcal{P}}}$ ", "page_idx": 24}, {"type": "text", "text": "According to Theorem 3.1, our discretization scheme approaches OPT within a gap of $\\frac{2\\epsilon}{1{+}\\epsilon}$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n{\\mathrm{OPT}}\\,-\\,\\operatorname*{max}_{p\\in{\\overline{{\\mathcal{P}}}}}\\operatorname{rev}(p)\\leq{\\frac{2\\epsilon}{1+\\epsilon}}\\leq2\\epsilon.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Therefore, the first term can be bounded as, ", "page_idx": 24}, {"type": "equation", "text": "$$\nT\\cdot\\mathrm{OPT}\\,-\\,T\\cdot\\operatorname*{max}_{p\\in{\\overline{{\\mathcal{P}}}}}\\operatorname{rev}(p)\\leq2\\epsilon T.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "By Lemma C.1, the second term, discretization regret, is upper bounded by ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\overline{{R}}_{T}]\\leq93m\\sqrt{T\\log T}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Combining (31) and (32) together, we have, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}[R_{T}]\\leq2\\epsilon T+93m\\sqrt{T\\log T}=\\widetilde{\\mathcal{O}}(m\\sqrt{T})\n$$", "text_format": "latex", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\mathrm{\\boldmath~as~}\\epsilon=\\frac{1}{\\sqrt{T}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Lemma C.1. The discretization regret $\\overline{{R}}_{T}$ defined in (30) is at most $\\widetilde{\\mathcal{O}}(m\\sqrt{T})$ ", "page_idx": 24}, {"type": "text", "text": "Proof of Lemma C.1. The discretization regret $\\overline{{R}}_{T}$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\overline{{R}}_{T}]\\,=\\mathbb{E}\\left[\\displaystyle T\\cdot\\operatorname*{max}_{p\\in\\overline{{\\mathcal{P}}}}\\mathrm{rev}(p)\\,-\\,\\sum_{t=1}^{T}r(i_{t},p_{t})\\right]}\\\\ &{\\qquad\\quad=\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}\\big(r(p^{\\star},i_{t})\\,-\\,r(p_{t},i_{t})\\big)\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle=\\sum_{t=1}^{T}\\mathbb{E}\\left[r({p^{\\star}},i_{t})-r(p_{t},i_{t})\\right]}}\\\\ {~~}\\\\ {{\\displaystyle=\\sum_{t=1}^{T}\\mathbb{E}\\left[\\mathrm{rev}({p^{\\star}})-\\mathrm{rev}(p_{t})\\right]}}\\\\ {~~}\\\\ {{\\displaystyle=\\sum_{t=1}^{T}\\mathbb{E}\\left[\\left(\\mathrm{rev}({p^{\\star}})-\\mathrm{\\rev}(p_{t})\\right)\\cdot\\mathbb{I}(A_{t})\\right]+\\sum_{t=1}^{T}\\mathbb{E}\\left[\\left(\\mathrm{rev}({p^{\\star}})\\,-\\,\\mathrm{rev}(p_{t})\\right)\\cdot\\mathbb{I}(A_{t}^{c})\\right]}}\\\\ {~~}\\\\ {{\\displaystyle\\triangleq\\sum_{t=1}^{T}\\mathbb{E}\\left[\\delta_{p_{t}}\\cdot\\mathbb{I}(A_{t})\\right]+\\sum_{t=1}^{T}\\mathbb{E}\\left[\\delta_{p_{t}}\\cdot\\mathbb{I}(A_{t}^{c})\\right].}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "We can futher decompose $\\mathbb{E}[{\\overline{{R}}_{T}}]$ into $\\begin{array}{r}{\\sum_{t=1}^{T}\\mathbb E\\left[\\delta_{p_{t}}\\cdot\\mathbb I(A_{t})\\right]}\\end{array}$ and $\\begin{array}{r}{\\sum_{t=1}^{T}\\mathbb{E}\\left[\\delta_{p_{t}}\\cdot\\mathbb{I}(A_{t}^{c})\\right]}\\end{array}$ . Where for any round $t$ we define the good event $A_{t}$ as follows, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\forall i\\in[m]\\,,\\quad q_{i}\\leq\\widehat{q_{i,t}}\\leq q_{i}+2\\sqrt{\\frac{\\log T}{T_{i,t}}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "$\\begin{array}{r}{\\overline{{q}}_{i,t}\\overset{\\Delta}{=}\\frac{\\sum_{\\tau=1}^{t}\\mathbb{I}(i\\in S_{\\tau},i_{\\tau}=i)}{T_{i,t}}=\\frac{\\sum_{s=1}^{t}\\mathbb{I}(i\\in S_{\\tau})\\cdot\\mathbb{I}(i_{\\tau}=i)}{\\sum_{\\tau=1}^{t}\\mathbb{I}(i\\in S_{\\tau})}}\\end{array}$ Is)(=) Note tha I(i = i is arandom variable that follows Bernoulli distribution $\\mathbf{Ber}(q_{i})$ , and one can only observe $\\mathbb{I}(i_{\\tau}=i)$ when $i\\in S_{\\tau}$ , let $\\overline{{x}}_{i,j}$ denote the mean value of first $j$ i.i.d. observations of $\\mathbb{I}(i_{s}=i)$ . Then, we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(\\left|\\overline{{q}}_{i,t}-q_{i}\\right|>\\sqrt{\\frac{\\log T}{T_{i,t}}}\\right)=\\underset{j=0}{\\overset{t}{\\sum}}\\mathbb{P}\\left(\\left|\\overline{{q}}_{i,t}-q_{i}\\right|>\\sqrt{\\frac{\\log T}{T_{i,t}}},\\ T_{i,t}=j\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\underset{j=0}{\\overset{t}{\\sum}}\\mathbb{P}\\left(\\left|\\overline{{x}}_{i,j}-q_{i}\\right|>\\sqrt{\\frac{\\log T}{j}}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\underset{j=0}{\\overset{t}{\\sum}}2\\exp(-2\\log T)}\\\\ &{\\qquad\\qquad\\qquad\\leq\\frac{2}{T}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Where  in  the frst  inequality,  the  event $\\begin{array}{r}{\\left\\{\\left|\\overline{{q}}_{i,t}-q_{i}\\right|>\\sqrt{\\frac{\\log T}{T_{i,t}}},\\;\\;T_{i,t}=j\\right\\}}\\end{array}$ indicates $\\left\\{|\\overline{{x}}_{i,j}-q_{i}|>\\sqrt{\\frac{\\log T}{j}}\\right\\}$ , and the second inequality follows from Hoeffding's inequality. We then bound the second term in (33) ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}\\left[\\delta_{p_{t}}\\mathbb{I}(A_{t}^{c})\\right]\\leq\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}\\left[\\mathbb{I}(A_{t}^{c})\\right]}\\\\ &{\\qquad\\qquad\\qquad\\leq\\displaystyle\\sum_{t=1}^{T}\\sum_{i=1}^{m}\\mathbb{P}\\left(\\left|\\overline{{q}}_{i,t}-q_{i}\\right|>\\sqrt{\\frac{\\log T}{T_{i,t}}}\\right)}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\sum_{t=1}^{T}\\sum_{i=1}^{m}\\frac{2}{T}}\\\\ &{\\qquad\\qquad\\leq2m.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Define event Ht  {0< opt < 2 iest \u221a By Lemma C.3, we know that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{I}(A_{t-1},\\,\\delta_{p_{t}}>0)\\implies\\mathbb{I}\\left(0<\\delta_{p_{t}}<\\sum_{i\\in S_{t}}2\\sqrt{\\frac{\\log T}{T_{i,t-1}}}\\right)=\\mathbb{I}(H_{T}).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "It remains to prove the upper bound for $\\begin{array}{r}{\\sum_{t=1}^{T}\\mathbb{E}\\left[\\delta_{p_{t}}\\mathbb{I}(A_{T})\\right]}\\end{array}$ ", "page_idx": 26}, {"type": "text", "text": "For $t\\in\\{1,\\ldots,T\\}$ and $k\\in\\mathbb{Z}_{+}$ , let ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{m_{k,t}\\triangleq\\left\\{\\alpha_{k}\\left(\\frac{m}{\\delta_{p_{t}}}\\right)^{2}\\log T,\\quad\\delta_{p_{t}}>0,\\right.}\\\\ {\\quad\\left.+\\infty,\\qquad\\qquad\\qquad\\quad\\delta_{p_{t}}=0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "and ", "page_idx": 26}, {"type": "equation", "text": "$$\nA_{k,t}\\triangleq\\{i\\in S_{t}:T_{i,t-1}\\leq m_{k,t}\\}\\,.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Then, we define an event ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathcal{G}_{k,t}\\overset{\\Delta}{=}\\{|A_{k,t}|\\geq\\beta_{k}m\\}\\,,\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "which means \u201cIn the $t$ -th round, at least $\\beta_{k}m$ types in $S_{t}$ has been observed at most $m_{k,t}$ times\". Then, by Lemma C.5, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\mathbb{I}(\\mathcal{H}_{t})\\cdot\\delta_{p_{t}}\\le\\sum_{k=1}^{\\infty}\\sum_{t=1}^{T}\\mathbb{I}\\left(\\mathcal{G}_{k,t},\\delta_{p_{t}}>0\\right)\\cdot\\delta_{p_{t}}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "For $i\\in[m],k\\in\\mathbb{Z}_{+},t\\in[T]$ , define an event ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{G}_{i,k,t}\\overset{\\Delta}{=}\\mathcal{G}_{k,t}\\cap\\{i\\in S_{t},\\,T_{i,t-1}\\leq m_{k,t}\\}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Then by the definitions of $\\mathcal{G}_{k,t}$ and $\\mathcal{G}_{i,k,t}$ we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{I}\\left(\\mathcal{G}_{k,t},\\,\\delta_{p_{t}}>0\\right)\\leq\\frac{1}{\\beta_{k}m}\\sum_{i\\in E_{\\mathrm{B}}}\\mathbb{I}\\left(\\mathcal{G}_{i,k,t},\\,\\delta_{p_{t}}>0\\right).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Therefore, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\mathbb{I}(\\mathcal{H}_{t})\\cdot\\delta_{p_{t}}\\leq\\sum_{i\\in E_{\\mathrm{B}}}\\sum_{k=1}^{\\infty}\\sum_{t=1}^{T}\\mathbb{I}\\left(\\mathcal{G}_{i,k,t},\\,\\delta_{p_{t}}>0\\right)\\cdot\\frac{\\delta_{p_{t}}}{\\beta_{k}m}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "For any price function $p$ define $\\delta_{p}\\ {\\overset{\\Delta}{=}}\\ \\operatorname{rev}(p^{\\star})-\\operatorname{rev}(p)$ .If $\\delta_{p}>0$ , we call it a \u201cbad\" price. Let $E_{B}\\triangleq\\{i\\in[m]:\\mathrm{type}\\,\\,i$ would make a purchase at least one bad pricel. ", "page_idx": 26}, {"type": "text", "text": "For each type $i\\:\\in\\:E_{\\mathrm{B}}$ , suppose $i$ is contained in $N_{i}$ bad prices $p_{i,1}^{\\mathrm{B}},p_{i,2}^{\\mathrm{B}},\\dotsc,p_{i,N_{i}}^{\\mathrm{B}}$ . Let $\\delta_{i,l}\\ \\triangleq$ $\\delta_{p_{i,l}^{\\mathrm{B}}}\\left(l\\in\\left[N_{i}\\right]\\right)$ . Without loss of generality, we assume $\\delta_{i,1}\\ge\\delta_{i,2}\\ge\\dots\\ge\\delta_{i,N_{i}}$ Let $\\delta_{i,\\mathrm{min}}\\triangleq\\delta_{i,N_{i}}$ For conveniene weals dene $\\delta_{i,0}=+\\infty$ ie, $\\begin{array}{r}{\\alpha_{k}\\left(\\frac{2m}{\\delta_{i,0}}\\right)^{2}=0}\\end{array}$ Then, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\mathbb{I}(\\mathcal{H}_{t})\\,\\delta_{p_{t}}}\\\\ &{\\le\\displaystyle\\sum_{i\\in E_{\\mathrm{B}}}\\sum_{k=1}^{\\infty}\\sum_{t=1}^{T}\\mathbb{I}(\\mathcal{G}_{i,k,t},\\,\\delta_{p_{t}}>0)\\,\\frac{\\delta_{p_{t}}}{\\beta_{k}m}}\\\\ &{=\\displaystyle\\sum_{i\\in E_{\\mathrm{B}}}\\sum_{k=1}^{\\infty}\\sum_{t=1}^{T}\\sum_{l=1}^{N_{i}}\\mathbb{I}\\left(\\mathcal{G}_{i,k,t},\\,p_{t}=p_{i,l}^{\\mathrm{B}}\\right)\\,\\frac{\\delta_{p_{t}}}{\\beta_{k}m}}\\\\ &{=\\displaystyle\\sum_{i\\in E_{\\mathrm{B}}}\\sum_{k=1}^{\\infty}\\sum_{t=1}^{T}\\sum_{l=1}^{N_{i}}\\mathbb{I}\\left(\\mathcal{G}_{i,k,t},\\,p_{t}=p_{i,l}^{\\mathrm{B}}\\right)\\,\\frac{\\delta_{i,l}}{\\beta_{k}m}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{{\\mathbb{E}}\\underset{=}{\\sum}\\underset{k\\neq i}{\\sum}\\underset{w\\in[-1,1]}{\\sum}\\mathbb{E}\\left(\\eta_{k-1}\\leq\\eta_{k-1},\\sqrt{\\eta_{k-1}}\\right)\\underset{=}{\\sum}\\underset{\\alpha}{\\sum}\\Biggl[\\int_{{\\mathbb{R}}^{n}}\\mathrm{Er}\\left(\\mathbf{\\tilde{S}}_{j}^{[\\alpha]}\\!-\\!\\mathbf{\\tilde{S}}_{j}^{[\\alpha]}\\!+\\!\\mathbf{\\tilde{S}}_{j}^{[\\alpha]}\\!+\\!\\mathbf{\\tilde{S}}_{j}^{[\\alpha]}\\!\\right)\\Biggr]\\frac{d}{d t}}\\\\ &{\\quad-\\underset{=}{\\sum}\\underset{k\\neq i}{\\sum}\\underset{w\\in[-1,1]}{\\sum}\\underset{=}{\\sum}\\mathbb{E}\\left(\\eta_{k-1}\\!+\\!\\frac{\\alpha}{2}\\left(\\frac{\\eta_{k-1}}{\\Delta_{k}^{2}}\\right)^{2}\\mathrm{brf}\\left(\\mathbf{\\tilde{S}}_{j}^{[\\alpha]}\\!-\\!\\mathbf{\\tilde{S}}_{j}^{[\\alpha]}\\!+\\!\\mathbf{\\tilde{S}}_{j}^{[\\alpha]}\\!\\right)\\right)\\frac{d}{d t}}\\\\ &{\\quad-\\underset{=}{\\sum}\\underset{k\\neq i}{\\sum}\\underset{w\\in[-1,1]}{\\sum}\\underset{=}{\\sum}\\frac{1}{\\sum}{\\sum}\\underset{w\\in[-1,1]}{\\sum}\\left(\\alpha\\!\\left(\\frac{\\beta}{\\Delta_{k-1}^{2}}\\right)^{2}\\mathrm{brf}\\left(\\mathbf{\\tilde{S}}_{j}^{[\\alpha]}\\!-\\!\\mathbf{\\tilde{S}}_{j-1,1}\\leq\\!\\alpha\\left(\\frac{\\beta}{\\Delta_{k}^{2}}\\right)^{2}\\mathrm{brf}\\left(\\mathbf{\\tilde{S}}_{j}^{[\\alpha]}\\!-\\!\\mathbf{\\tilde{S}}_{j}^{[\\alpha]}\\!\\right)\\right)\\frac{d}{d t}\\right.}\\\\ &{\\left.\\quad\\leq\\underset{=}{\\sum}\\frac{1}{\\sum}\\underset{w\\in[-1,1]}{\\sum}\\underset{=}{\\sum}{\\sum}\\underset{w\\in[-1,1]}{\\sum}\\mathbb{E}\\left(\\eta_{k}\\left(\\frac{\\beta}{\\Delta_{k-1}^{2}}\\right)^{2}\\mathrm{brf}\\left(\\mathbf{\\tilde{S}}_{j}^{[\\alpha]}\\!-\\!\\\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the last inequality is due to Lemma C.4. Finally, for each $i\\in E_{\\mathrm{B}}$ wehave ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{j=1}^{N_{i}}\\left(\\frac{1}{\\delta_{i,j}^{2}}-\\frac{1}{\\delta_{i,j-1}^{2}}\\right)\\delta_{i,j}=\\displaystyle\\frac{1}{\\delta_{i,N_{i}}}+\\sum_{j=1}^{N_{i}-1}\\frac{1}{\\delta_{i,j}^{2}}\\left(\\delta_{i,j}-\\delta_{i,j+1}\\right)}\\\\ &{\\le\\displaystyle\\frac{1}{\\delta_{i,N_{i}}}+\\int_{\\delta_{i,N_{i}}}^{\\delta_{i,1}}\\frac{1}{x^{2}}\\mathrm{d}x}\\\\ &{=\\displaystyle\\frac{2}{\\delta_{i,N_{i}}}-\\frac{1}{\\delta_{i,1}}}\\\\ &{\\le\\displaystyle\\frac{2}{\\delta_{i,\\operatorname*{min}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "It follows that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\mathbb{I}({\\mathcal{H}}_{t})\\cdot\\delta_{p_{t}}\\leq1068m\\log T\\cdot\\sum_{i\\in E_{\\mathrm{B}}}{\\frac{2}{\\delta_{i,\\operatorname*{min}}}}=m\\sum_{i\\in E_{\\mathrm{B}}}{\\frac{2136}{\\delta_{i,\\operatorname*{min}}}}\\log T\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "So far, the distribution-dependent regret bound is proven. To prove the distribution-independent bound, wedecompose $\\textstyle\\sum_{t=1}^{T}\\mathbb{I}({\\mathcal{H}}_{t})\\cdot\\delta_{p_{t}}$ into twoparts: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\mathbb{I}(\\mathcal{H}_{t})\\cdot\\delta_{p_{t}}=\\sum_{t=1}^{T}\\mathbb{I}\\left(\\mathcal{H}_{t},\\,\\delta_{p_{t}}\\leq\\epsilon\\right)\\cdot\\delta_{p_{t}}+\\displaystyle\\sum_{t=1}^{T}\\mathbb{I}\\left(\\mathcal{H}_{t},\\,\\delta_{p_{t}}>\\epsilon\\right)\\cdot\\delta_{p_{t}}}\\\\ &{\\leq\\epsilon T+\\displaystyle\\sum_{t=1}^{T}\\mathbb{I}\\left(\\mathcal{H}_{t},\\delta_{p_{t}}>\\epsilon\\right)\\cdot\\delta_{p_{t}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $\\epsilon>0$ is a constant to be determined. The second term can be bounded in the same way as in the proof of the distribution-dependent regret bound, except that we only consider the case ", "page_idx": 27}, {"type": "text", "text": "$\\delta_{p_{t}}>\\epsilon$ (For each type $i\\in E_{\\mathrm{B}}$ , suppose $i$ is contained in $N_{i}$ bad prices $p_{i,1}^{\\mathrm{B}},p_{i,2}^{\\mathrm{B}},\\dotsc,p_{i,N_{i}}^{\\mathrm{B}}$ . Let $\\delta_{i,l}\\triangleq\\delta_{p_{i,l}^{\\mathrm{B}}}\\left(l\\in\\left[N_{i}\\right]\\right)$ satisfies $\\delta_{i,1}\\geq\\delta_{i,2}\\geq...\\geq\\delta_{i,N_{i}}\\geq\\epsilon.$ Also let $\\delta_{i,\\mathrm{min}}\\triangleq\\delta_{i,N_{i}}$ ) Thus, we can replace (34) by ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\mathbb{I}\\left(\\mathcal{H}_{t},\\delta_{p_{t}}>\\epsilon\\right)\\cdot\\delta_{p_{t}}\\le m\\cdot\\sum_{i\\in E_{\\mathrm{B}},\\delta_{i,\\operatorname*{min}}>\\epsilon}\\frac{2136}{\\delta_{i,\\operatorname*{min}}}\\log T\\le\\frac{2136m^{2}}{\\epsilon}\\log T.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "It follows that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\mathbb{I}(\\mathcal{H}_{t})\\cdot\\delta_{S_{t}}\\,\\le\\epsilon\\,T+\\,\\frac{2136m^{2}}{\\epsilon}\\log T.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Finally, letting $\\begin{array}{r}{\\epsilon=\\sqrt{\\frac{2136m^{2}\\log T}{T}}}\\end{array}$ 2136m2 logT, we get ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\mathbb{I}(\\mathcal{H}_{t})\\cdot\\delta_{S_{t}}\\leq2\\sqrt{2136m^{2}T\\log T}\\leq93\\sqrt{m^{2}T\\log T}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Lemma C.2. Under good event $A_{t}$ for any price function $p,$ let $S_{p}$ denote the set of types who would purchase at price $p_{i}$ then we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\forall t\\in[T],\\quad\\mathrm{rev}(p)\\leq\\widehat{\\mathrm{rev}}_{t}(p)\\leq\\mathrm{rev}(p)+\\sum_{i\\in S_{p}}2\\sqrt{\\frac{\\log T}{T_{i,t}}}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof of Lemma C.2. When $A_{t}$ happens, ", "page_idx": 28}, {"type": "equation", "text": "$$\nq_{i}\\leq\\widehat{q}_{i,t}\\leq q_{i}+2\\sqrt{\\frac{\\log T}{T_{i,t}}},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "for all $i\\in[m]$ ", "page_idx": 28}, {"type": "text", "text": "Therefore, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\widehat{\\mathrm{rev}}_{t}(p)=\\sum_{i=1}^{m}\\widehat{q}_{i,t}\\cdot r(i,p)\\geq\\sum_{i=1}^{m}q_{i}\\cdot r(i,p)=\\mathrm{rev}(p)\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "and ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\widehat{\\mathsf{r e v}}_{t}(p)=\\sum_{i=1}^{m}\\widehat{q_{i,t}}\\cdot r(i,p)\\leq\\sum_{i=1}^{m}\\left(q_{i}+2\\sqrt{\\frac{\\log T}{T_{i,t}}}\\right)\\cdot r(i,p)\\leq\\mathrm{rev}(p)+\\sum_{i\\in S_{p}}2\\sqrt{\\frac{\\log T}{T_{i,t}}}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "The last inequality is by $r(i,p)\\leq1$ ", "page_idx": 28}, {"type": "text", "text": "Lemma C.3. For each $t\\in[T]$ under good event $A_{t-1}$ , the following inequality holds, ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\delta_{p_{t}}\\triangleq\\operatorname{rev}(p^{\\star})-\\operatorname{rev}(p_{t})\\leq2\\sum_{i\\in S_{t}}\\sqrt{\\frac{\\log T}{T_{i,t-1}}}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof of Lemma C.3. When $A_{t-1}$ happens, by Lemma C.2, ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{rev}(\\boldsymbol{p}^{\\star})\\leq\\widehat{\\mathrm{rev}}_{t-1}(\\boldsymbol{p}^{\\star}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathrm{rev}(p_{t})\\geq\\widehat{\\mathrm{rev}}_{t-1}(p_{t})-2\\sum_{i\\in S_{t}}\\sqrt{\\frac{\\log T}{T_{i,t-1}}}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "It then follows that, ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\delta_{p_{t}}=\\mathrm{rev}(p^{\\star})-\\mathrm{rev}(p_{t})\\leq\\widehat{\\mathrm{rev}}_{t-1}(p^{\\star})-\\left(\\widehat{\\mathrm{rev}}_{t-1}(p_{t})-2\\sum_{i\\in S_{t}}\\sqrt{\\frac{\\log T}{T_{i,t-1}}}\\right)\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Since $p_{t}=\\operatorname*{argmax}_{p\\in\\overline{{\\mathcal{P}}}}\\widehat{\\operatorname{rev}}_{t-1}(p)$ , we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\widehat{\\mathrm{rev}}_{t-1}(p_{t})\\geq\\widehat{\\mathrm{rev}}_{t-1}(p^{\\star}).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Lemma C.4 (Theorem 4 of Kveton et al. [37]). We can choose $\\{\\alpha_{k}\\}_{k\\ge0}$ and $\\{\\beta_{k}\\}_{k\\ge0}$ which satisfy the following properties: $\\{\\alpha_{k}\\}_{k\\ge0}$ and $\\{\\beta_{k}\\}_{k\\ge0}$ are positive and ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\alpha_{1}>\\alpha_{2}>....~~a n d~1=\\beta_{0}>\\beta_{1}>\\beta_{2}>...\\,,\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "such that $\\begin{array}{r}{\\operatorname*{lim}_{k\\to\\infty}\\alpha_{k}=\\operatorname*{lim}_{k\\to\\infty}\\beta_{k}=0.}\\end{array}$ Moreover, ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\sqrt{6}\\sum_{k=1}^{\\infty}\\frac{\\beta_{k-1}-\\beta_{k}}{\\sqrt{\\alpha_{k}}}\\leq1,\\;a n d\\,\\sum_{k=1}^{\\infty}\\frac{\\alpha_{k}}{\\beta_{k}}<267.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Lemma C.5. On round $t$ if event $\\mathcal{H}_{t}$ happens, then at least one event ${\\mathcal G}_{k,t},\\,k\\in\\mathbb{Z}_{+}$ happens, where ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{G}_{k,t}\\overset{\\Delta}{=}\\left\\{\\left|A_{k,t}\\right|\\geq\\beta_{k}m\\right\\},\\quad w h e r e\\,A_{k,t}\\overset{\\Delta}{=}\\left\\{i\\in S_{t}:T_{i,t-1}\\leq m_{k,t}\\right\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "and $\\begin{array}{r}{m_{k,t}=\\alpha_{k}\\left(\\frac{m}{\\delta_{p_{t}}}\\right)^{2}\\log T}\\end{array}$ when $\\delta_{p_{t}}>0$ and $+\\infty$ otherwise. ", "page_idx": 29}, {"type": "text", "text": "Proof of Lemma C.5.Assume that $\\mathcal{H}_{t}$ happens and that none of $\\mathcal{G}_{1,t},\\mathcal{G}_{2,t},\\ldots.$ happens. Then $|A_{k,t}|~<~\\beta_{k}m$ for all $k\\,\\in\\,\\mathbb{Z}_{+}$ .Let $A_{0,t}\\,=\\,S_{t}$ and $\\bar{A}_{k,t}\\,=\\,S_{t}\\backslash A_{k,t}$ for $k\\,\\in\\,\\mathbb{Z}_{+}\\cup\\{0\\}$ . Thus $\\bar{A}_{k-1,t}\\subseteq\\bar{A}_{k,t}$ for all $k\\in\\mathbb{Z}_{+}$ . Note that $\\begin{array}{r}{\\operatorname*{lim}_{k\\rightarrow\\infty}m_{k,t}=0}\\end{array}$ Thus there exists $N\\in\\mathbb{Z}_{+}$ such that $\\bar{A}_{k,t}=S_{t}$ for all $k\\geq N$ , and then we have $\\begin{array}{r}{S_{t}=\\bigcup_{k=1}^{\\infty}\\left(\\bar{A}_{k,t}\\backslash\\bar{A}_{k-1,t}\\right)}\\end{array}$ . Finally, note that for all $i\\in\\bar{A}_{k,t}$ , we have $T_{i,t-1}>m_{k,t}$ . Therefore ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{k\\in\\mathcal{S}_{t}}\\frac{1}{\\sqrt{T_{i,t-1}}}=\\displaystyle\\sum_{k=1}^{\\infty}\\sum_{i\\in\\mathcal{A}_{k,t}\\backslash\\tilde{A}_{k-1,t}}\\frac{1}{\\sqrt{T_{i,t-1}}}\\le\\displaystyle\\sum_{k=1}^{\\infty}\\sum_{i\\in\\tilde{A}_{k,t}\\backslash\\tilde{A}_{k-1,t}}\\frac{1}{\\sqrt{m_{k,t}}}}&{}\\\\ {\\displaystyle=\\sum_{k=1}^{\\infty}\\frac{\\left|\\tilde{A}_{k,t}\\backslash\\tilde{A}_{k-1,t}\\right|}{\\sqrt{m_{k,t}}}=\\sum_{k=1}^{\\infty}\\frac{\\left|A_{k-1,t}\\backslash\\tilde{A}_{k,t}\\right|}{\\sqrt{m_{k,t}}}=\\sum_{k=1}^{\\infty}\\frac{\\left|A_{k-1,t}\\right|-\\left|A_{k,t}\\right|}{\\sqrt{m_{k,t}}}}\\\\ {\\displaystyle=\\frac{\\left|\\mathcal{S}_{t}\\right|}{\\sqrt{m_{1,t}}}+\\sum_{k=1}^{\\infty}\\left|A_{k,t}\\right|\\left(\\frac{1}{\\sqrt{m_{k+1,t}}}-\\frac{1}{\\sqrt{m_{k,t}}}\\right)}&{}\\\\ {\\displaystyle<\\frac{m}{\\sqrt{m_{1,t}}}+\\sum_{k=1}^{\\infty}\\beta_{k}m\\left(\\frac{1}{\\sqrt{m_{k+1,t}}}-\\frac{1}{\\sqrt{m_{k,t}}}\\right)}&{}\\\\ {\\displaystyle=\\sum_{k=1}^{\\infty}\\frac{\\left(\\beta_{k-1}-\\beta_{k}\\right)m}{\\sqrt{m_{k,t}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Under event $\\mathcal{H}_{t}$ , we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\delta_{p_{t}}\\leq\\displaystyle\\sum_{i\\in S_{t}}2\\sqrt{\\frac{\\log T}{T_{i,t-1}}}=2\\sqrt{\\log T}\\cdot\\displaystyle\\sum_{i\\in S_{t}}\\frac{1}{\\sqrt{T_{i,t-1}}}}\\\\ &{\\qquad<2\\sqrt{\\log T}\\cdot\\displaystyle\\sum_{k=1}^{\\infty}\\frac{\\left(\\beta_{k-1}-\\beta_{k}\\right)m}{\\sqrt{m_{k,t}}}=2\\displaystyle\\sum_{k=1}^{\\infty}\\frac{\\beta_{k-1}-\\beta_{k}}{\\sqrt{\\alpha_{k}}}\\cdot\\delta_{p_{t}}\\leq\\delta_{p_{t}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the last inequality is due to Lemma C.4. We reach a contradiction here, hence the lemma follows. \u25a0 ", "page_idx": 29}, {"type": "text", "text": "D Miscellaneous ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "D.1  Notations ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "The following table contains the notations used in this paper. ", "page_idx": 30}, {"type": "table", "img_path": "KoyTqNs6SZ/tmp/f99b07bdd2ac0f808bef43e191f37c9347e574110604630b54aa819c0ab71d1f.jpg", "table_caption": ["Table 3: Table of notations. "], "table_footnote": [], "page_idx": 30}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We fully included paper's contributions and scope in the appendix. See $\\S1.1$ for the summary of our contributions. ", "page_idx": 31}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer:[Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: See $\\S6$ for future works on relaxing one of key assumptions of the paper. ", "page_idx": 31}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We provided the full set of assumptions. Moreover, we provided the full proofs of each Lemma and Theorem in this paper both in main text and Appendices. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 31}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 31}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: This paper does not include experiments requiring code ", "page_idx": 31}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 31}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] Justification: This paper does not include experiments. ", "page_idx": 32}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce theexperiments? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 32}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: Our research conforms, in every respect, with the NeurIPs Code of Ethics. ", "page_idx": 32}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?   \nAnswer: [NA]   \nJustification: Our research is theoretical and have no societal impact in a foreseeable future. ", "page_idx": 32}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: Our paper poses no such risks. ", "page_idx": 32}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: This paper does not use existing assets. ", "page_idx": 32}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "page_idx": 32}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?   \nAnswer: [NA]   \nJustification: This paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 32}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 33}]