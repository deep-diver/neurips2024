[{"figure_path": "h3Kv6sdTWO/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of DiffusionBlend++ compared to previous 3D image reconstruction works. Previous work used a hand-crafted TV term to \"regularize\" adjacent slices, whereas the proposed approach uses learned diffusion score blending between groups of slices. Here i is the slice index, and t is the reconstruction iteration.", "description": "This figure compares the proposed DiffusionBlend++ method with previous 3D image reconstruction methods.  Previous methods used a hand-crafted total variation (TV) term to regularize adjacent slices, resulting in a loss of z-axis consistency.  DiffusionBlend++, on the other hand, uses a learned diffusion score blending method between groups of slices, improving z-axis consistency and reducing artifacts.", "section": "1 Introduction"}, {"figure_path": "h3Kv6sdTWO/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of slice blending process during reconstruction for DiffusionBlend++. At each iteration, we partition the slices of the volume in a different way; slices of the same color are inputted into the network independently. Positional encoding (PE) is also inputted to the network as information about the separation between the slices.", "description": "This figure illustrates the slice blending process within the DiffusionBlend++ algorithm during 3D image reconstruction.  At each iteration (time step t, t-1, t-2), the volume's slices are divided into groups (same color). Each group is processed independently by a denoising U-Net, incorporating positional encoding (PE) to account for slice separation. This positional encoding provides information on the spatial arrangement of the slices in the 3D volume. The sinogram (measurement data, y) is inputted to the process and provides contextual information. The process iteratively refines the reconstruction from noisy initial conditions, gradually reducing noise in multiple steps until a final 3D volume is produced.", "section": "Methods"}, {"figure_path": "h3Kv6sdTWO/figures/figures_6_1.jpg", "caption": "Figure 3: Results of CT reconstruction with 4 views on AAPM dataset, axial view.", "description": "This figure shows a visual comparison of the results of CT reconstruction using 4 views on the AAPM dataset, focusing on the axial view.  It compares the performance of several methods: Filtered Back Projection (FBP), FBP-UNet, DDS, DDS 2D, the proposed method (Ours), and the ground truth. The red boxes highlight regions of interest where the different methods' performance can be visually assessed. The figure demonstrates the superior quality of the proposed method compared to the others in reconstructing fine details and overall image fidelity.", "section": "4 Experiments"}, {"figure_path": "h3Kv6sdTWO/figures/figures_7_1.jpg", "caption": "Figure 3: Results of CT reconstruction with 4 views on AAPM dataset, axial view.", "description": "This figure shows the results of computed tomography (CT) reconstruction using 4 views of the AAPM dataset. It compares the performance of different reconstruction methods, including FBP, FBP-UNet, DDS, DDS 2D, and DiffusionBlend++. The axial view of the reconstructed images is shown. The ground truth image is also included for comparison.", "section": "4 Experiments"}, {"figure_path": "h3Kv6sdTWO/figures/figures_9_1.jpg", "caption": "Figure 3: Results of CT reconstruction with 4 views on AAPM dataset, axial view.", "description": "This figure compares the results of CT reconstruction using different methods (FBP, FBP-UNet, DDS, DDS 2D, and the proposed DiffusionBlend++) with 4 views on the AAPM dataset. The axial view of the reconstructed CT images is shown for each method.  It demonstrates the superior performance of the proposed method compared to the baselines, particularly in terms of image quality and artifact reduction.", "section": "Experiments"}, {"figure_path": "h3Kv6sdTWO/figures/figures_16_1.jpg", "caption": "Figure 3: Results of CT reconstruction with 4 views on AAPM dataset, axial view.", "description": "This figure shows the results of computed tomography (CT) reconstruction using 4 views on the AAPM dataset.  The axial view is displayed. The figure compares the reconstruction quality of several methods including FBP, FBP-UNet, DDS, DDS 2D, and the proposed DiffusionBlend++ method. The ground truth image is also shown for comparison.", "section": "4 Experiments"}, {"figure_path": "h3Kv6sdTWO/figures/figures_16_2.jpg", "caption": "Figure 3: Results of CT reconstruction with 4 views on AAPM dataset, axial view.", "description": "This figure compares the axial view of CT reconstruction results using different methods on the AAPM dataset with only 4 views.  It shows that DiffusionBlend++ produces a significantly more accurate reconstruction compared to other methods, including Filtered Back Projection (FBP), FBP-UNet, DDS, and DDS 2D. The ground truth image is also shown for comparison. The improved quality highlights the effectiveness of the DiffusionBlend++ approach in reconstructing high-dimensional 3D images from limited data.", "section": "4 Experiments"}, {"figure_path": "h3Kv6sdTWO/figures/figures_17_1.jpg", "caption": "Figure 8: Comparison of DiffusionBlend++ with classical methods", "description": "This figure compares the results of CT reconstruction using DiffusionBlend++ against three classical methods: SBTV, SIRT, and DDS.  Each method's reconstruction is shown alongside the ground truth image.  The purpose is to visually demonstrate the superior performance of DiffusionBlend++ in terms of image quality and detail preservation compared to these traditional techniques.", "section": "Experiments"}, {"figure_path": "h3Kv6sdTWO/figures/figures_17_2.jpg", "caption": "Figure 3: Results of CT reconstruction with 4 views on AAPM dataset, axial view.", "description": "This figure compares the results of CT reconstruction using different methods (FBP, FBP-UNet, DDS, DDS 2D, and DiffusionBlend++) with 4 views on the AAPM dataset. The axial view of the reconstructed volume is shown for each method.  The ground truth is also included for comparison.  It visually demonstrates the superior performance of DiffusionBlend++ in terms of image quality and detail preservation compared to the other methods.", "section": "4 Experiments"}, {"figure_path": "h3Kv6sdTWO/figures/figures_17_3.jpg", "caption": "Figure 3: Results of CT reconstruction with 4 views on AAPM dataset, axial view.", "description": "This figure shows a comparison of different CT reconstruction methods on the AAPM dataset using only 4 views.  The top row displays axial slices of the reconstructed images. The methods compared include FBP (filtered back projection), FBP-UNet (a deep learning approach), DiffusionMBIR, DDS, DiffusionBlend and DiffusionBlend++. The ground truth is also included for reference.  The image shows that DiffusionBlend++ produces results closest to the ground truth, demonstrating the effectiveness of the proposed method in reconstructing high-quality images even with limited data.", "section": "4 Experiments"}, {"figure_path": "h3Kv6sdTWO/figures/figures_18_1.jpg", "caption": "Figure 3: Results of CT reconstruction with 4 views on AAPM dataset, axial view.", "description": "This figure displays the axial view of CT reconstruction results using different methods on the AAPM dataset with only 4 views. The methods compared include FBP, FBP-UNet, DDS, DDS 2D, and the proposed DiffusionBlend++. The ground truth is also included for reference.  The figure shows the effectiveness of DiffusionBlend++ in reconstructing high-quality images even with a limited number of views, demonstrating improved image quality compared to the other methods.", "section": "4 Experiments"}, {"figure_path": "h3Kv6sdTWO/figures/figures_19_1.jpg", "caption": "Figure 3: Results of CT reconstruction with 4 views on AAPM dataset, axial view.", "description": "This figure compares the results of CT reconstruction using different methods on the AAPM dataset with 4 views. The axial view of the CT scans is shown.  The methods compared include FBP, FBP-UNet, DDS (2D), DDS, and the proposed DiffusionBlend++ method.  The ground truth image is also shown for reference. The figure visually demonstrates the improved performance of DiffusionBlend++ compared to the other methods.", "section": "4 Experiments"}]