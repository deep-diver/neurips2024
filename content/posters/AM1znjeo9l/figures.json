[{"figure_path": "AM1znjeo9l/figures/figures_2_1.jpg", "caption": "Figure 1: Dynamics of GD and SGD and GD with injected Gaussian noise for the simple problem l(u,w) = (uwx \u2013 y)\u00b2. Due to the rescaling symmetry between u and w, GD follows a conservation law: u\u00b2(t) \u2013 w\u00b2(t) = u\u00b2(0) \u2013 w\u00b2(0), SGD converges to the balanced solution u\u00b2 = w\u00b2, while GD with injected noise diverges due to simple diffusion in the degenerate directions.", "description": "This figure shows a comparison of the dynamics of three different optimization algorithms (Gradient Descent (GD), Stochastic Gradient Descent (SGD), and GD with added Gaussian noise) on a simple loss function with rescaling symmetry.  GD follows a conservation law, meaning the difference between the squared norms of parameters u and w remains constant. SGD, on the other hand, converges to a balanced solution where the squared norms are equal.  The addition of Gaussian noise to GD leads to divergence because the noise causes the algorithm to explore all directions equally, rather than converging to the balanced solution.", "section": "3.1 Rescaling Symmetry and Law of Balance"}, {"figure_path": "AM1znjeo9l/figures/figures_3_1.jpg", "caption": "Figure 2: A two-layer ReLU network trained on a full-rank dataset. Left: because of the rescaling symmetry, the norms of the two layers are balanced approximately (but not exactly). Right: the first and second terms in Eq. (2). We see that both terms evolve towards a point where they exactly balance. In agreement with our theory, SGD training leads to an approximate norm balance and exact gradient noise balance.", "description": "The figure shows the results of training a two-layer ReLU network on a full-rank dataset. The left panel shows that the norms of the two layers are approximately balanced, while the right panel shows that the gradient noise in the two layers becomes exactly balanced during training. This supports the theory that SGD training leads to both approximate norm and exact gradient noise balance.", "section": "3.2 1d Rescaling Symmetry"}, {"figure_path": "AM1znjeo9l/figures/figures_5_1.jpg", "caption": "Figure 3: Stationary distributions of SGD for simple linear regression (D = 0), and a two-layer network (D = 1) across different T = \u03b7/S: T = 0.05 (left) and T = 0.5 (Mid). We see that for D = 1, the stationary distribution is strongly affected by the choice of the learning rate. In contrast, for D = 0, the stationary distribution is also centered at the global minimizer of the loss function, and the choice of the learning rate only affects the thickness of the tail. Right: the stationary distribution of a one-layer tanh-model, f(x) = tanh(vx) (D = 0) and a two-layer tanh-model f(x) = wtanh(ux) (D = 1). For D = 1, we define v := wu. The vertical line shows the ground truth.", "description": "This figure compares the stationary distributions of SGD for simple linear regression (D=0) and a two-layer network (D=1) with different learning rates (T).  It shows that the two-layer network's stationary distribution is highly sensitive to the learning rate, unlike the single-layer model which is only affected in the tail thickness. The right panel demonstrates the effect for tanh activation functions.", "section": "4 Stationary Distribution of SGD"}, {"figure_path": "AM1znjeo9l/figures/figures_7_1.jpg", "caption": "Figure 4: Regimes of learning for SGD as a function of T and the noise in the dataset \u03c3. According to (1) whether the sparse transition has happened, (2) whether a nontrivial maximum probability estimator exists, and (3) whether the sparse solution is a maximum probability estimator, the learning of SGD can be characterized into 5 regimes. Regime I is where SGD converges to a sparse solution with zero variance. In regime II, the stationary distribution has a finite spread, but the probability of being close to the sparse solution is very high. In regime III, the probability density of the sparse solution is zero, and therefore the model will learn without much problem. In regime b, a local nontrivial probability maximum exists. The only maximum probability estimator in regime a is the sparse solution.", "description": "This figure shows the different learning regimes of SGD based on the learning rate (T) and the noise level (\u03c3) in the dataset.  Five regimes are identified based on three criteria: whether a sparse solution transition happens, whether a non-trivial maximum probability exists, and whether this sparse solution is the maximum probability. The regimes are characterized by the behavior of the stationary distribution of the model's parameters.", "section": "4.3 Power-Law Tail of Deeper Models"}, {"figure_path": "AM1znjeo9l/figures/figures_8_1.jpg", "caption": "Figure 5: SGD on deep networks leads to a well-controlled distribution and training loss. Left: Power law of the tail of the parameter distribution of deep linear nets. The dashed lines show the upper (-7/2) and lower (-5) bound of the exponent of the tail. The predicted power-law scaling agrees with the experiment, and the exponent decreases as the theory predicts. Mid: training loss of a tanh network. D = 0 is the case where only the input weight is trained, and D = 1 is the case where both input and output layers are trained. For D = 0, the model norm increases as the model loses stability. For D = 1, a \"fluctuation inversion\" effect appears. The fluctuation of the model vanishes before it loses stability. Right: performance of fully connected tanh nets on MNIST. Scaling the learning rate as 1/D keeps the model performance relatively unchanged.", "description": "This figure shows three subplots that demonstrate the properties of SGD on deep networks. The left subplot shows the power-law tail of the parameter distribution, demonstrating that the exponent decreases as the depth increases, aligning with theoretical predictions. The middle subplot illustrates the training loss of a tanh network, highlighting a \"fluctuation inversion\" phenomenon where the model's fluctuation decreases before instability. The right subplot displays the performance of fully connected tanh networks on the MNIST dataset, indicating that scaling the learning rate as 1/D maintains consistent performance across varying depths.", "section": "4.3 Power-Law Tail of Deeper Models"}]