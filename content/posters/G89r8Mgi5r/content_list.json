[{"type": "text", "text": "Confusion-Resistant Federated Learning via Diffusion-Based Data Harmonization on Non-IID Data ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Xiaohong Chen1,2,3 Canran Xiao1\u2217 Yongmei Liu1,4 ", "page_idx": 0}, {"type": "text", "text": "1 School of Business, Central South University, Changsha, Hunan 410083, China 2 Xiangjiang Laboratory, Changsha, Hunan 410205, China ", "page_idx": 0}, {"type": "text", "text": "3 School of Advanced Interdisciplinary Studies, School of Management Science and Engineering, Hunan University of Technology and Business, Changsha, Hunan 410205, China 4 Urban Smart Governance Laboratory, Changsha, Hunan 410083, China c88877803@163.com, xiaocanran@csu.edu.cn, liuyongmeicn@163.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Federated learning has become a pivotal distributed learning paradigm, involving collaborative model updates across multiple nodes with private data. However, handling non-i.i.d. (not identically and independently distributed) data and ensuring model consistency across heterogeneous environments present significant challenges. These challenges often lead to model performance degradation and increased difficulty in achieving effective communication among participant models. In this work, we propose Confusion-Resistant Federated Learning via Consistent Diffusion (CRFed), a novel framework designed to address these issues. Our approach introduces a new diffusion-based data harmonization mechanism that includes data augmentation, noise injection, and iterative denoising to ensure consistent model updates across non-i.i.d. data distributions. This mechanism aims to reduce data distribution disparities among participating nodes, enhancing the coordination and consistency of model updates. Moreover, we design a confusionresistant strategy leveraging an indicator function and adaptive learning rate adjustment to mitigate the adverse effects of data heterogeneity and model inconsistency. Specifically, we calculate importance sampling weights based on the optimal sampling probability, which guides the selection of clients and the sampling of their data, ensuring that model updates are robust and aligned across different nodes. Extensive experiments on benchmark datasets, including MNIST, FashionMNIST, CIFAR-10, CIFAR-100, and NIPD, demonstrate the effectiveness of CRFed in improving accuracy, convergence speed, and overall robustness in federated learning scenarios with severe data heterogeneity. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Federated Learning (FL) [McMahan et al., 2017b] has emerged as a powerful paradigm for distributed machine learning, enabling multiple clients to collaboratively train a shared model without exchanging raw data. This approach addresses critical concerns around data privacy and security, which are increasingly significant in various sectors such as healthcare [Antunes et al., 2022], finance [Chatterjee et al., 2023], and IoT [Li et al., 2020a, Pan et al., 2023, Yao et al., 2024]. However, one of the fundamental challenges in FL is dealing with non-independent and identically distributed (non-IID) data, which can significantly impair the performance and convergence of the global model [Zhu et al., 2021]. ", "page_idx": 0}, {"type": "image", "img_path": "G89r8Mgi5r/tmp/23e89ce4509c8b5a956b7c0a535ab23ab047755c08d3d54eba1afe72d3d26745.jpg", "img_caption": ["Figure 1: Problem illustration of federated learning on Non-i.i.d data. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "As illustrated in Figure 1, FL on non-IID data often suffers from issues like divergent model updates and inconsistent global models. Client models trained on heterogeneous data distributions tend to diverge [Ye et al., 2023], making it difficult for the server to aggregate them into a coherent global model. This divergence is due to inconsistencies in data sources [Xiao and Liu, 2024] and distributions across clients [Duan et al., 2021]. This problem leads to reduced accuracy and slower convergence rates, highlighting the need for effective solutions to handle data heterogeneity. Existing research has made significant strides in improving the robustness and efficiency of FL in non-IID settings. Notable methods include FedProx [Li et al., 2020b], which adds a proximal term to handle heterogeneity. Techniques such as MOON [Li et al., 2021b]and FedGen [Nguyen et al., 2021] introduce sophisticated strategies like contrastive learning and data generation to mitigate the effects of data heterogeneity. Despite these advancements, issues related to data distribution disparities and model inconsistency persist, limiting the scalability and effectiveness of FL in real-world scenarios. ", "page_idx": 1}, {"type": "text", "text": "Given the critical gaps in existing FL approaches, particularly their limited robustness to severe non-IID data distributions, there is a pressing need for more resilient and adaptive solutions. This research is motivated by the necessity to enhance FL\u2019s capability to handle heterogeneous data efficiently. The primary objective of this study is to develop a novel FL framework, Confusion-Resistant Federated Learning via Consistent Diffusion (CRFed), which integrates advanced mechanisms to address data distribution disparities and enhance model consistency across clients. ", "page_idx": 1}, {"type": "text", "text": "Our contributions can be summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "1. We propose a novel indicator function that dynamically adjusts sample weighting based on loss values and uncertainties, facilitating a self-paced learning approach that prioritizes more difficult samples over time.   \n2. Our framework employs a diffusion-based mechanism to harmonize data distributions, involving iterative noise injection and denoising processes that align local data with the desired distribution.   \n3. We implement a strategic client selection method based on the indicator function, ensuring the inclusion of the most reliable clients, which enhances the robustness and consistency of model updates.   \n4. Our extensive experimental evaluations demonstrate that CRFed achieves state-of-the-art performance on benchmark datasets. CRFed outperforms existing methods significantly in terms of accuracy and convergence speed under various non-IID settings. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 Non-IID Challenge in Federated Learning ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "The issue of non-IID data in FL was initially highlighted by FedAVG [McMahan et al., 2017a], and it has since been demonstrated that this challenge can significantly hinder the convergence and overall performance of the global model [Zhao et al., 2018, Li et al., 2019]. Numerous studies, categorized as client-centric methods, have been proposed to tackle this problem by adjusting the local training objectives using insights from the global model and the local models of other clients [Wang et al., 2021]. For instance, FedProx [Li et al., 2020b] introduced a proximal term to constrain local updates by leveraging the global model. SCAFFOLD [Karimireddy et al., 2020] utilized control variates to correct for local training drift, while FedDyn [Acar et al., 2021] introduced a dynamic regularizer for parallelizing gradients among clients. MOON [Li et al., 2021b] applied contrastive learning to minimize the discrepancy between model representations, thereby correcting local training. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Despite their contributions, these methods fall short of fully resolving the core of the non-IID issue and may experience performance limitations in scenarios with highly skewed data distributions [Li et al., 2022]. Beyond client-side adjustments, the server also plays a role in mitigating the adverse effects of non-IID data by calibrating the biased global model post-aggregation. For example, CCVR [Luo et al., 2021] uses virtual representations from an approximated Gaussian mixture model to correct the classifier. FedFTG [Zhang et al., 2022] employs data-free knowledge distillation to refine the global model with the knowledge derived from local models. Additionally, strategies such as client clustering [Ghosh et al., 2020, Long et al., 2023] and client selection [Zhang et al., 2021, Wang et al., 2020], can be implemented by the server to alleviate the non-IID problem. IFCA [Ghosh et al., 2020] iteratively estimates client cluster identities based on local empirical loss and updates model parameters for each cluster via gradient descent. ", "page_idx": 2}, {"type": "text", "text": "2.2 Importance Sampling in Federated Learning ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In federated learning (FL), data sampling strategies are vital for enhancing distributed training efficiency. [Tuor et al., 2020] proposed selecting local training data based on user-end data correlation analysis. This led to dynamic sampling strategies like [Li et al., 2021a], where training sample importance is determined by model gradient magnitudes. Similarly, [Rizk et al., 2022] used gradient norms to derive sampling weights, minimizing theoretical convergence bounds. However, these methods require immediate gradient computations, increasing local overhead, and assume convex loss functions, which may not apply to deep learning models [Rizk et al., 2021]. Therefore, developing importance sampling methods suitable for deep learning-based FL remains an open challenge. ", "page_idx": 2}, {"type": "text", "text": "FL convergence can be theoretically analyzed due to the model aggregation mechanism [98, 101- 102, 150], with experimental validation for deep learning tasks [Wan et al., 2021]. Most studies rely on theoretical derivations, limiting practical application. This study aims to use a diffusion model to automate the modeling of optimal sampling strategies in FL. ", "page_idx": 2}, {"type": "text", "text": "3 Method ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 Overview ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The CRFed framework, shown in Figure 2, addresses challenges posed by non-i.i.d. data in FL. Our approach integrates a diffusion mechanism and a confusion-resistant strategy to ensure consistent and robust model updates across heterogeneous data distributions. The core idea of CRFed is that the performance of client $i$ \u2019s data on the global model reflects its contribution to the training process. By using an optimal indicator function, we determine the optimal data sampling probability for each client, enhancing training efficiency and model performance. ", "page_idx": 2}, {"type": "text", "text": "The framework comprises several key components: the current global model downloaded by clients at time $t$ ; the Model Encoder and Meta-model, which process the global model and client-specific data for the diffusion process; an indicator function, computed using client i\u2019s data on the global model; the Diffusion-based Data Harmonization Mechanism, which uses data augmentation, noise injection, and probabilistic modeling to mitigate data distribution disparities; and the Distribution Decoder, which aligns the denoised data distribution with the desired distribution. ", "page_idx": 2}, {"type": "text", "text": "3.2 Indicator Function and Meta-model ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The Indicator Function $I_{\\lambda}(l_{i},\\sigma_{i})$ is designed to measure the reliability of the $i$ -th sample\u2019s loss value $l_{i}$ and its associated uncertainty $\\sigma_{i}$ . The design is inspired by self-paced learning [Fan et al., 2017, Castells et al., 2020], which adjusts the weights of samples based on their loss values, allowing for a gradual learning process from easy to difficult samples. In the context of federated learning, this means that each client should adopt a self-paced learning paradigm, sampling its data in a way that allows the global model to learn from simple to complex tasks. The Indicator Function captures this performance and is defined as follows: ", "page_idx": 2}, {"type": "image", "img_path": "G89r8Mgi5r/tmp/d49002cb4575d99b518a09d0f16cbe3cf24808db8d31d622bd4f7bc885181d6d.jpg", "img_caption": ["Figure 2: CRFed Framework. The process begins with the current global model, which is downloaded by clients. The model encoder processes the global model, and the meta-model is obtained. This meta-model is then projected into a higher-dimensional space and concatenated with the indicator function, forming the combined representation $z_{i}$ . The diffusion-based data harmonization mechanism adds noise to this representation and iteratively denoises it to achieve the desired distribution. The distribution decoder then aligns the denoised data distribution. Client $i$ \u2019s data is sampled based on importance sampling weights $w_{i}$ , calculated as the ratio of the optimal sampling probability $P_{i}^{*}$ to the original data distribution $P_{0}$ . This ensures that the sampled data aligns with the desired distribution, following a curriculum learning approach that progresses from easy to difficult samples, thus enhancing overall model performance. "], "img_footnote": [], "page_idx": 3}, {"type": "equation", "text": "$$\nI_{\\lambda}(l_{i},\\sigma_{i})=(l_{i}-\\tau)\\sigma_{i}+\\lambda(\\log\\sigma_{i})^{2}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\lambda$ is a pre-set regularization coefficient. $\\tau$ is a confidence threshold that determines the difficulty of the sample based on its loss value. It can either be a fixed constant or a dynamically adjusted weighted average during the training process. ", "page_idx": 3}, {"type": "text", "text": "The Indicator Function can be further explained using the following steps: for each client $i$ , the loss value $l_{i}$ of each sample is calculated on the current global model, and the uncertainty $\\sigma_{i}$ of each sample is estimated based on its difficulty. The Indicator Function $I_{\\lambda}(l_{i},\\sigma_{i})$ is then used to assign weights to the samples, with easier samples having lower weights and more difficult samples having higher weights. This adaptive weighting mechanism ensures that the model focuses more on difficult samples over time, leading to improved learning efficiency and robustness. ", "page_idx": 3}, {"type": "text", "text": "Theorem 3.1. In the CRFed framework, using the indicator function $I_{\\lambda}(l_{i},\\sigma_{i})$ ensures stable and convergent updates for heterogeneous federated learning. For an appropriately chosen learning rate $\\eta,$ , the model update rule for client $i$ at iteration $t_{\\mathrm{:}}$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\theta_{t+1}=\\theta_{t}-\\eta\\left(\\sigma_{i}^{*}+(l_{i}-\\tau)k+2\\lambda\\frac{\\log\\sigma_{i}^{*}}{\\sigma_{i}^{*}}k\\right)\\nabla_{\\theta}l_{i},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "guarantees a decreasing step size, promoting convergence. Moreover, CRFed achieves a tighter bound on update steps than FedAvg, indicating faster convergence under the same conditions. ", "page_idx": 3}, {"type": "text", "text": "The proof of Theorem 3.1 can be found in Appendix A.2. ", "page_idx": 3}, {"type": "text", "text": "Given the global model $\\theta$ , the optimal uncertainty $\\boldsymbol{\\sigma}_{i}^{*}$ can be derived through the following theorem: Theorem 3.2. The optimal uncertainty $\\boldsymbol{\\sigma}_{i}^{*}$ for a given loss value $l_{i}$ is obtained by minimizing the Indicator Function $I_{\\lambda}(l_{i},\\sigma_{i})$ . The solution is given by: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\sigma_{i}^{*}(l_{i})=\\exp\\left(-W\\left(\\frac{1}{2\\lambda}\\operatorname*{max}\\left(-\\frac{2}{e},l_{i}-\\tau\\right)\\right)\\right)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $W(\\cdot)$ is the Lambert W function. ", "page_idx": 3}, {"type": "text", "text": "Proof. To find the optimal uncertainty $\\boldsymbol{\\sigma}_{i}^{*}$ , we first perform a variable transformation on the Indicator Function. Let $\\begin{array}{r}{c_{i}=\\frac{\\bar{l}_{i}-\\tau}{\\lambda}}\\end{array}$ and $x_{i}=\\log\\sigma_{i}$ . Then, the problem can be rewritten as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\sigma_{i}^{*}(l_{i})=\\arg\\operatorname*{min}_{x_{i}}\\left(c_{i}e^{x_{i}}+x_{i}^{2}\\right)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Taking the derivative with respect to $x_{i}$ and setting it to zero, we get: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\frac{\\partial}{\\partial x_{i}}\\left(c_{i}e^{x_{i}}+x_{i}^{2}\\right)=0\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Simplifying this, we obtain: ", "page_idx": 4}, {"type": "equation", "text": "$$\nc_{i}e^{x_{i}}+2x_{i}=0\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Let $y=x_{i}e^{x_{i}}$ , then the above equation can be expressed as: ", "page_idx": 4}, {"type": "equation", "text": "$$\nx_{i}=-W\\left({\\frac{c_{i}}{2}}\\right)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $W(\\cdot)$ is the Lambert $\\mathrm{W}$ function. Transforming back, we get: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\sigma_{i}=\\exp\\left(-W\\left(\\frac{c_{i}}{2}\\right)\\right)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Given $c_{i}\\geq-\\frac{2}{e}$ , we can conclude that: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\sigma_{i}^{*}(l_{i})=\\exp\\left(-W\\left(\\frac{1}{2\\lambda}\\operatorname*{max}\\left(-\\frac{2}{e},l_{i}-\\tau\\right)\\right)\\right)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "This optimal uncertainty $\\boldsymbol{\\sigma}_{i}^{*}$ dynamically adjusts sample weighting based on loss values, aligning with the self-paced learning paradigm. When the loss value $l_{i}$ is large, $\\boldsymbol{\\sigma}_{i}^{*}$ decreases, assigning a higher weight to the sample, indicating it is more difficult and needs more attention. Conversely, when $l_{i}$ is small, $\\boldsymbol{\\sigma}_{i}^{*}$ increases, assigning a lower weight, indicating it is easier and needs less focus. When we choose $\\boldsymbol{\\sigma}_{i}^{*}$ , the resulting indicator function is optimal, and the data distribution corresponding to this indicator function is the most optimal for training the current global model. ", "page_idx": 4}, {"type": "text", "text": "Since the indicator function can be regarded as a measure of the client\u2019s data from the perspective of the global model, we need to consider the global model information when modeling the mapping between data distribution and the indicator function using the diffusion model. In this paper, we train a model encoder $E$ using an autoregressive method to compress the global model $\\theta_{t}$ into a meta-model $\\phi_{t}$ $\\langle\\phi_{t}=E(\\theta_{t}))$ . The meta-model $\\phi_{t}$ is then projected into a higher-dimensional space $P$ and concatenated with the indicator function $I_{\\lambda}(l_{i},\\sigma_{i})$ to form $z_{i}\\,=\\,\\mathrm{concat}(P(\\phi_{t}),I_{\\lambda}(l_{i},\\bar{\\sigma}_{i}))$ . This combined representation $z_{i}$ is used as the input for the diffusion model (DiffusionModel $(z_{i}),$ ). Refer to A.3 for more details of model encoder. ", "page_idx": 4}, {"type": "text", "text": "3.3 Diffusion-based Data Harmonization ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The diffusion-based data harmonization mechanism is a critical component of the CRFed framework, responsible for mitigating data distribution disparities and ensuring consistent model updates across heterogeneous environments. The harmonization process is shown in Figure 3, which involves adding noise to the data distribution and then iteratively denoising it to achieve the desired distribution. The workflow of this mechanism can be divided into two main processes: the forward diffusion process and the reverse denoising process. ", "page_idx": 4}, {"type": "text", "text": "Forward Diffusion Process Suppose that a training sample $\\mathbf{x}_{\\mathrm{0}}$ is of a certain distribution, denoted as $q(\\mathbf{x}_{0})$ . In the forward diffusion process, Gaussian noise with variance $\\beta_{t}~\\in~(0,1)$ is added gradually to the sample $\\mathbf{x}_{\\mathrm{0}}$ for $T$ steps, resulting in a latent sample $\\mathbf{x}_{T}\\sim\\mathcal{N}(0,\\mathbf{I})$ . The process is defined as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\nq(\\mathbf{z}_{1:T}|z_{i})=\\prod_{t=1}^{T}q(\\mathbf{z}_{t}|\\mathbf{z}_{t-1}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "equation", "text": "$$\nq(\\mathbf{z}_{t}|\\mathbf{z}_{t-1})=\\mathcal{N}(\\mathbf{z}_{t};\\sqrt{1-\\beta_{t}}\\mathbf{z}_{t-1},\\beta_{t}\\mathbf{I}).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Using notations $\\alpha_{t}=1-\\beta_{t}$ and $\\begin{array}{r}{\\bar{\\alpha}_{t}=\\prod_{s=1}^{t}\\alpha_{s}}\\end{array}$ , the sample $\\mathbf{z}_{t}$ can be defined directly as: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{z}_{t}=\\sqrt{\\bar{\\alpha}_{t}}z_{i}+\\sqrt{1-\\bar{\\alpha}_{t}}\\pmb{\\epsilon},\\ \\ \\ \\ \\ \\epsilon\\sim\\mathcal{N}(0,\\mathbf{I}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Reverse Denoising Process The reverse denoising process aims to sample reversely from ${\\bf z}_{T}$ through transition probabilities $q(\\mathbf{z}_{t-1}|\\mathbf{z}_{t})$ for timesteps $T-1$ through 1, yielding a sample drawn from $q(z_{i})$ . The transition $q(\\mathbf{z}_{t-1}|\\mathbf{z}_{t})$ is a Gaussian distribution, tractable when conditioned on $z_{i}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\nq(\\mathbf{z}_{t-1}|\\mathbf{z}_{t},z_{i})=\\mathcal{N}(\\mathbf{z}_{t-1};\\tilde{\\mu}_{t}(\\mathbf{z}_{t},z_{i}),\\tilde{\\beta}_{t}\\mathbf{I}),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the mean $\\tilde{\\pmb{\\mu}}_{t}$ and variance ${\\tilde{\\beta}}_{t}$ are calculated as: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\tilde{\\mu}_{t}(\\mathbf{z}_{t},z_{i})=\\frac{1}{\\sqrt{\\alpha_{t}}}\\left(\\mathbf{z}_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\epsilon_{t}\\right),}\\\\ &{}&{\\tilde{\\beta}_{t}=\\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar{\\alpha}_{t}}\\beta_{t}.\\quad\\quad\\quad\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The reverse transition probability $p_{\\theta}\\big(\\mathbf{z}_{t-1}\\big|\\mathbf{z}_{t}\\big)$ relies on the entire data distribution and is approximated through a neural network: ", "page_idx": 5}, {"type": "equation", "text": "$$\np_{\\theta}(\\mathbf{z}_{t-1}|\\mathbf{z}_{t})=\\mathcal{N}(\\mathbf{z}_{t-1};\\mu_{\\theta}(\\mathbf{z}_{t},t),\\Sigma_{\\theta}(\\mathbf{z}_{t},t)),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The detailed derivations and computations for these processes can refer to A.1. In the context of federated learning, the reverse denoising process starts from the optimal indicator function $I^{*}$ obtained in the forward diffusion process. By progressively denoising, we obtain the optimal sampling probability for client $i$ , ensuring that the final data distribution aligns with the desired distribution. This minimizes the impact of data heterogeneity and ensures robust model updates across all clients. ", "page_idx": 5}, {"type": "text", "text": "3.4 Confusion-Resistant Strategy ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The confusion-resistant strategy is designed to address the challenges posed by data heterogeneity and model inconsistency in federated learning. It consists of three key components: client selection based on the indicator function, data sampling using the diffusion-based harmonization mechanism, and adaptive learning rate adjustment. ", "page_idx": 5}, {"type": "text", "text": "Client Selection Strategy To mitigate the adverse effects of data heterogeneity, we select clients based on their indicator function $I_{\\lambda}(l_{i},\\sigma_{i})$ , which quantifies the reliability of their data. Clients with the lowest indicator values, reflecting higher data reliability, are chosen for training. This approach follows the curriculum learning paradigm, where lower values indicate better data: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{Selected\\,Clients}=\\{i|I_{\\lambda}(l_{i},\\sigma_{i})\\leq\\gamma\\},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\gamma$ is a dynamically adjusted threshold ensuring the selection of the most suitable clients. ", "page_idx": 5}, {"type": "text", "text": "Data Sampling Strategy For each selected client, the optimal sampling probability $P_{i}^{*}$ is determined through the reverse denoising process, starting from the optimal indicator function $I^{*}$ . This ensures that the sampled data aligns with the desired distribution, enhancing the robustness of model updates. The importance sampling weight $w_{i}$ is calculated as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\nw_{i}=\\frac{P_{i}^{*}}{P_{0}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where P0 is the original data distribution. Using wi, we sample the local training data (Disampled Sample $(D_{i},w_{i});$ ). This sampling ensures the effective sampling probability aligns with $P_{i}^{*}$ . ", "page_idx": 6}, {"type": "text", "text": "The distribution decoder, which is implemented as an autoencoder, is then used to decode the denoised data distribution. The autoencoder is trained to map the denoised samples back to the desired distribution, further ensuring that the data used for training is aligned with the ideal distribution. Refer to the A.3 for more details of distribution decoder. ", "page_idx": 6}, {"type": "text", "text": "Adaptive Learning Rate Adjustment The learning rate $\\eta_{i}$ for each client is adjusted based on the indicator function value, enhancing the influence of more reliable data: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\eta_{i}=\\eta_{0}\\cdot\\frac{I_{\\lambda}(l_{i},\\sigma_{i})}{\\operatorname*{max}_{j}I_{\\lambda}(l_{j},\\sigma_{j})},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\eta_{0}$ is the base learning rate. ", "page_idx": 6}, {"type": "text", "text": "The complete computational process(pseudocode) of CRFed is provided in the A.4. ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "4.1 Experiment Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Datasets Our experiments are conducted on four widely used benchmark datasets: MNIST [LeCun et al., 1998], FashionMNIST [Xiao et al., 2017], CIFAR10 [Krizhevsky et al., 2009], and CIFAR100 [Krizhevsky et al., 2009]. To simulate Non-IID data scenarios, we utilize the Dirichlet distribution [Yurochkin et al., 2019] to generate non-IID partitions with varied concentration parameters, $\\beta$ . Smaller values of $\\beta$ lead to more imbalanced data distributions among clients, thereby increasing levels of data heterogeneity. In our experiments, we set $\\beta$ to 0.5 to reflect this imbalance. In all experiments, we simulate a federated learning environment with 10 edge nodes, i.e., $K\\ =\\ 10$ . For the MNIST and FashionMNIST datasets, each node has 600 data samples. For the CIFAR-10 dataset, each node has 500 data samples. For CIFAR-100, the partitioning strategy remains the same, ensuring that each client\u2019s local data distribution varies significantly, simulating real-world federated learning scenarios. MNIST and FashionMNIST datasets consist of grayscale images of size $28\\times28$ pixels, with 10 classes. CIFAR-10 and CIFAR-100 contain color images of size $32\\times32$ pixels. ", "page_idx": 6}, {"type": "text", "text": "Additionally, we use the NIPD dataset [Yin et al., 2023], a benchmark specifically designed for federated learning in person detection tasks with Non-IID data. This dataset provides a realworld non-IID scenario to test the generalization of CRFed. ", "page_idx": 6}, {"type": "image", "img_path": "G89r8Mgi5r/tmp/eef9f70bcb718c0c64ecf37c717199caa39b566a4c3e9c021bacaa2e1608aa48.jpg", "img_caption": [], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Figure 3: The diffusion-based data harmonization mechanism in CRFed framework. The process involves a forward diffusion process where Gaussian noise is added to the initial data distribution, transforming it into a latent representation. This is followed by a reverse denoising process that iteratively removes the noise, aligning the data distribution with the desired target distribution. ", "page_idx": 6}, {"type": "text", "text": "Competing Methods Apart from FedAvg [McMahan et al., 2017a], we compare the proposed algorithm with several benchmarking FL algorithms specialized for solving the non-IID problem, including FedProx [Li et al., 2020b], MOON [Li et al., 2021b], and FedGen [Nguyen et al., 2021]. We also compare our method against HFMDS-FL [Li et al., 2024], FRAug [Chen et al., 2023], GFML [Yang et al., 2023], FedCD [Long et al., 2023], FedNP [Wu et al., 2023], and FedDPMS [Chen and Vikalo, 2023], which are recent state-of-the-art approaches addressing non-IID data issues in federated learning. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Hyperparameter For local training, the settings are as follows: MNIST with $E\\,=\\,5$ , $B\\,=\\,10$ , $\\eta\\stackrel{.}{=}5\\stackrel{.}{\\times}10^{-3}$ ; FashionMNIST with $E\\,=\\,5$ , $B\\,=\\,100$ , $\\eta\\,=\\,2\\,\\times\\,10^{-4}$ ; CIFAR-10 and CIFAR100 with $E\\,=\\,5$ , $B\\,=\\,100$ , $\\eta\\,=\\,1\\,\\times\\,10^{-4}$ . Momentum optimization with a coefficient of 0.5 is applied. In the CRFed framework, key hyperparameters include maximum global rounds $(T_{G})$ set to 100, local training cycles $(E_{l})$ per global round set to 1, regularization coefficient $(\\lambda)$ set to 0.1, dynamically adjusted confidence threshold $(\\tau)$ , and client selection threshold $(\\gamma)$ initially set to 0.5. These parameters are fine-tuned based on preliminary experiments to ensure training efficiency and model performance. The experiments were conducted using an NVIDIA GeForce RTX 4060 GPU, which has 8GB of VRAM. Detailed configurations of model structure are provided in A.5. ", "page_idx": 7}, {"type": "text", "text": "Evaluation metrics The primary evaluation metrics for our experiments focus on accuracy and the number of training rounds needed to reach convergence, addressing the challenges posed by non-IID data in federated learning. Accuracy is measured at the same training round across different models to ensure fair comparison. Convergence is assessed by the number of rounds required to achieve a target accuracy, which reflects the model\u2019s stability and efficiency. For the NIPD dataset, we use mean Average Precision (mAP) as the evaluation metric. Following [Wang et al., 2020], all reported results are averaged over five runs with different random seeds to account for variability. ", "page_idx": 7}, {"type": "text", "text": "4.2 Performance Comparison ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Table 1: Test accuracy of CRFed and the competing methods on five datasets. We run five trials with different random seeds and report the mean accuracy. ", "page_idx": 7}, {"type": "table", "img_path": "G89r8Mgi5r/tmp/0e45bbafb15d54fe44bced21e99a75c6fb3fe8bd0610ea4cf63cff602b77cb19.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Accuracy comparison Table 1 presents the test accuracy of CRFed compared to several federated learning algorithms under a highly heterogeneous setting $\\mathit{\\Delta}(\\beta\\,=\\,0.5)$ . Our proposed method shows notable improvements over FedAvg [McMahan et al., 2017a], with relative gains of $0.9\\%$ on MNIST, $3.7\\%$ on FashionMNIST, $5.1\\%$ on CIFAR-10, $7.5\\%$ on CIFAR-100, and a significant $7.4\\%$ improvement in mAP on the NIPD dataset. This highlights CRFed\u2019s robustness in handling non-IID data distributions. CRFed consistently outperforms all other methods across the datasets, underscoring its effectiveness in federated learning scenarios with severe data heterogeneity. ", "page_idx": 7}, {"type": "text", "text": "Effect of Data Heterogeneity We ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "analyze the impact of data heterogeneity on the performance of the top 5 models by varying the Dirichlet concentration parameter $\\beta$ . Table 2 shows the performance of these models on CIFAR-100 and NIPD datasets for $\\beta$ values ranging from 0.1 to 0.5. As expected, the performance generally decreases with smaller $\\beta$ values due to increased data heterogeneity Table 2 indicates that as $\\beta$ decrea ", "page_idx": 7}, {"type": "table", "img_path": "G89r8Mgi5r/tmp/f3e02c83c1240abc02fc4c850a7a141f25034f79829090a198564af1bfacab99.jpg", "table_caption": ["Table 2: Performance of top 5 models on CIFAR-100 and NIPD datasets under different $\\beta$ values. "], "table_footnote": ["representing higher data heterogeneity, the performance of all models declines. CRFed consistently "], "page_idx": 7}, {"type": "image", "img_path": "G89r8Mgi5r/tmp/0661428f1b41d2cfd93ad7393ec3fc719736c41224ae5e7e6d4d58aa1855216c.jpg", "img_caption": ["Figure 5: Test accuracy across federated training rounds for top 5 models on FMNIST, CIFAR-10, and CIFAR-100 datasets. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "outperforms other methods across different $\\beta$ settings, demonstrating its robustness in handling data heterogeneity. Notably, the relative performance gap between CRFed and other methods widens as $\\beta$ decreases, highlighting its efficacy in more challenging federated learning scenarios. ", "page_idx": 8}, {"type": "text", "text": "Effect of Increasing Edge Nodes Figure 4 presents the performance of the top 5 models on CIFAR-100 and NIPD datasets as the number of edge nodes $K$ increases from 10 to 100. Across all models, performance generally improves with higher $K$ values, reflecting better data utilization. Notably, CRFed shows the most significant gains, with accuracy increasing from 0.389 to 0.425 on CIFAR-100 and mAP from 0.882 to 0.920 on NIPD. This demonstrates CRFed\u2019s superior scalability and effectiveness in handling more edge nodes, making it robust in federated learning environments with increasing data sources. ", "page_idx": 8}, {"type": "image", "img_path": "G89r8Mgi5r/tmp/13124047d77785ec1a2c71108fa63661967af4640803463535376a73891b3699.jpg", "img_caption": ["Figure 4: Effect of Increasing Edge Nodes "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Convergence Rate The convergence performance of the top five models on FMNIST, CIFAR-10, and CIFAR-100 datasets is depicted in Figure 5. As observed, CRFed demonstrates significantly faster and more stable convergence compared to the competing methods across all three datasets. This superior performance is attributed to the diffusion-based data harmonization mechanism, which effectively aligns data distributions, and the confusionresistant strategy that selects reliable clients and adaptively adjusts learning rates, ensuring efficient and robust training even in highly heterogeneous environments. ", "page_idx": 8}, {"type": "text", "text": "4.3 Ablation Study ", "text_level": 1, "page_idx": 8}, {"type": "image", "img_path": "G89r8Mgi5r/tmp/9e5798ca73d34dc031ef37edd1c9d819558ed655876ae85dab145d2f3b9971e6.jpg", "img_caption": ["Figure 6: Ablation study results on CIFAR-10, CIFAR-100, and NIPD datasets. The bar charts show the accuracy on CIFAR-10 and CIFAR-100 datasets, while the line plot represents the mAP on the NIPD dataset. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "To evaluate the contribution of each component in the CRFed framework, we conduct an ablation study by removing or altering specific components and observing the impact on model performance. Removing the Indicator Function and using uniform sampling led to significant performance drops, with CIFAR-10 accuracy falling from 0.683 to 0.661, CIFAR-100 from 0.389 to 0.365, and NIPD mAP from 0.882 to 0.861. Excluding the Diffusion-based Data Harmonization (DDH) mechanism resulted in reduced accuracy on CIFAR-10 (0.670), CIFAR-100 (0.373), and NIPD mAP (0.870), highlighting its role in aligning data distributions. Replacing strategic client selection with random selection markedly decreased performance, emphasizing the importance of reliable client selection. Fixing the learning rate instead of adapting it slowed convergence and destabilized training. These findings validate the theoretical and practical significance of our proposed components in improving federated learning performance. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "4.4 Comparison with Importance Sampling Methods ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Previous importance sampling methods typically require prior analysis of the data relevance at each client-side [Hsu et al., 2020, Tian et al., 2022] or necessitate deriving optimal sampling weights based on assumptions such as the convexity of the loss function [Rizk et al., 2022, Zhu et al., 2024]. While these methods offer strong theoretical guarantees, they are somewhat limited in their adaptability to real-world federated learning (FL) scenarios. For instance, both FedIR [Hsu et al., 2020] and Harmony [Tian et al., 2022] assume that the server has knowledge of the local distributions of all clients. Although this assumption does not violate the privacy-preserving principles of FL, it can be challenging to obtain in real-world applications. ", "page_idx": 9}, {"type": "text", "text": "In contrast, our CRFed does not depend on these assumptions. Instead, it iteratively adjusts the data distributions during the FL process itself, enabling the model to dynamically harmonize the diverse, non-IID data across clients without requiring explicit distributional assumptions or centralized access to all client data distributions. Guided by the indicator function, our CRFed can derive the optimal sampling strategy for each local node. ", "page_idx": 9}, {"type": "text", "text": "Moreover, as shown in Table 3, empirical experiments demonstrate that the diffusion model achieves superior performance, outperforming other benchmark methods. ", "page_idx": 9}, {"type": "text", "text": "It is worth noting that this comparison is not entirely fair, as each importance sampling method operates under different assumptions. For example, ISFL requires a validation set to update the empirical gradient Lipschitz constants for each local model, while FedIR requires all clients to upload the conditional distribution of images given class labels to match the target distribution. Nevertheless, our CRFed outperforms the others even under less restrictive conditionsunlike ISFedAvg and ISFL, it does not require assumptions about the loss function or gradient variance, and unlike FedIR and Har", "page_idx": 9}, {"type": "text", "text": "mony, it does not require centralized access to all client data distributions before calculating the importance sampling weights. ", "page_idx": 9}, {"type": "table", "img_path": "G89r8Mgi5r/tmp/a7e6ecd27a631b41d2701327de5f1029961d1d5fe47de12a10be729174b5cdf1.jpg", "table_caption": ["Table 3: The performance of different importance sampling methods on CIFAR-100 under various $\\beta$ values. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In conclusion, this study tackles the pressing challenge of handling non-i.i.d. data in federated learning environments. We propose the Confusion-Resistant Federated Learning via Consistent Diffusion (CRFed) framework. This framework introduces a novel Indicator Function that dynamically adjusts sample weighting, facilitating a self-paced learning paradigm that prioritizes more difficult samples over time. Additionally, our diffusion-based data harmonization mechanism ensures consistent and aligned data distributions through iterative noise injection and denoising processes, mitigating the adverse effects of data heterogeneity. Our strategic client selection method, guided by the Indicator Function, ensures that the most reliable clients are chosen for training, thus improving the robustness and consistency of global model updates. ", "page_idx": 9}, {"type": "text", "text": "Despite the promising results, our approach has certain limitations. The reliance on complex diffusion mechanisms and adaptive strategies may introduce computational overhead, which could be a concern for resource-constrained environments. Future work should focus on optimizing the computational efficiency of the CRFed framework and exploring its applicability to a broader range of real-world federated learning scenarios [Zhang et al., 2023]. ", "page_idx": 9}, {"type": "text", "text": "6 Acknowledgement ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This research was funded by the Basic Science Center Project for National Natural Science Foundation of China (Grant No: 72088101), the Xiangjiang Laboratory Major Project(Grant No: ", "page_idx": 9}, {"type": "text", "text": "23XJ01007), and the Fundamental Research Funds for the Central Universities of Central South University(Grant No: 1053320214050). ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "D. A. E. Acar, Y. Zhao, R. M. Navarro, M. Mattina, P. N. Whatmough, and V. Saligrama. Federated learning based on dynamic regularization. arXiv preprint arXiv:2111.04263, 2021.   \nR. S. Antunes, C. Andr\u00e9 da Costa, A. K\u00fcderle, I. A. Yari, and B. Eskofier. Federated learning for healthcare: Systematic review and architecture proposal. ACM Transactions on Intelligent Systems and Technology (TIST), 13(4):1\u201323, 2022.   \nT. Castells, P. Weinzaepfel, and J. Revaud. Superloss: A generic loss for robust curriculum learning. Advances in Neural Information Processing Systems, 33:4308\u20134319, 2020.   \nP. Chatterjee, D. Das, and D. B. Rawat. Federated learning empowered recommendation model for financial consumer services. IEEE Transactions on Consumer Electronics, 2023.   \nH. Chen and H. Vikalo. Federated learning in non-iid settings aided by differentially private synthetic data. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5026\u20135035, 2023.   \nH. Chen, A. Frikha, D. Krompass, J. Gu, and V. Tresp. Fraug: Tackling federated learning with non-iid features via representation augmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 4849\u20134859, 2023.   \nM. Duan, D. Liu, X. Ji, Y. Wu, L. Liang, X. Chen, Y. Tan, and A. Ren. Flexible clustered federated learning for client-level data distribution shift. IEEE Transactions on Parallel and Distributed Systems, 33(11):2661\u20132674, 2021.   \nY. Fan, R. He, J. Liang, and B. Hu. Self-paced learning: An implicit regularization perspective. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 31, 2017.   \nA. Ghosh, J. Chung, D. Yin, and K. Ramchandran. An efficient framework for clustered federated learning. Advances in Neural Information Processing Systems, 33:19586\u201319597, 2020.   \nT.-M. H. Hsu, H. Qi, and M. Brown. Federated visual classification with real-world data distribution. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part X 16, pages 76\u201392. Springer, 2020.   \nS. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, and A. T. Suresh. Scaffold: Stochastic controlled averaging for federated learning. In International conference on machine learning, pages 5132\u20135143. PMLR, 2020.   \nA. Krizhevsky, G. Hinton, et al. Learning multiple layers of features from tiny images. 2009.   \nY. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.   \nA. Li, L. Zhang, J. Tan, Y. Qin, J. Wang, and X.-Y. Li. Sample-level data selection for federated learning. In IEEE INFOCOM 2021-IEEE Conference on Computer Communications, pages 1\u201310. IEEE, 2021a.   \nL. Li, Y. Fan, M. Tse, and K.-Y. Lin. A review of applications in federated learning. Computers & Industrial Engineering, 149:106854, 2020a.   \nQ. Li, B. He, and D. Song. Model-contrastive federated learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10713\u201310722, 2021b.   \nQ. Li, Y. Diao, Q. Chen, and B. He. Federated learning on non-iid data silos: An experimental study. In 2022 IEEE 38th international conference on data engineering (ICDE), pages 965\u2013978. IEEE, 2022.   \nT. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith. Federated optimization in heterogeneous networks. Proceedings of Machine learning and systems, 2:429\u2013450, 2020b.   \nX. Li, K. Huang, W. Yang, S. Wang, and Z. Zhang. On the convergence of fedavg on non-iid data. arXiv preprint arXiv:1907.02189, 2019.   \nZ. Li, Y. Sun, J. Shao, Y. Mao, J. H. Wang, and J. Zhang. Feature matching data synthesis for non-iid federated learning. IEEE Transactions on Mobile Computing, 2024.   \nY. Long, Z. Xue, L. Chu, T. Zhang, J. Wu, Y. Zang, and J. Du. Fedcd: A classifier debiased federated learning framework for non-iid data. In Proceedings of the 31st ACM International Conference on Multimedia, pages 8994\u20139002, 2023.   \nM. Luo, F. Chen, D. Hu, Y. Zhang, J. Liang, and J. Feng. No fear of heterogeneity: Classifier calibration for federated learning with non-iid data. Advances in Neural Information Processing Systems, 34:5972\u20135984, 2021.   \nB. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273\u20131282. PMLR, 2017a.   \nB. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273\u20131282. PMLR, 2017b.   \nD. C. Nguyen, M. Ding, P. N. Pathirana, A. Seneviratne, and A. Y. Zomaya. Federated learning for covid-19 detection with generative adversarial networks in edge cloud computing. IEEE Internet of Things Journal, 9(12):10257\u201310271, 2021.   \nX. Pan, J. Yao, H. Kou, T. Wu, and C. Xiao. Harmonicnerf: Geometry-informed synthetic view augmentation for 3d scene reconstruction in driving scenarios. In ACM Multimedia 2024, 2023.   \nJ. Redmon and A. Farhadi. Yolov3: An incremental improvement. arXiv preprint arXiv:1804.02767, 2018.   \nE. Rizk, S. Vlaski, and A. H. Sayed. Optimal importance sampling for federated learning. In ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 3095\u20133099. IEEE, 2021.   \nE. Rizk, S. Vlaski, and A. H. Sayed. Federated learning under importance sampling. IEEE Transactions on Signal Processing, 70:5381\u20135396, 2022.   \nC. Tian, L. Li, Z. Shi, J. Wang, and C. Xu. Harmony: Heterogeneity-aware hierarchical management for federated learning system. In 2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO), pages 631\u2013645. IEEE, 2022.   \nT. Tuor, S. Wang, B. J. Ko, C. Liu, and K. K. Leung. Data selection for federated learning with relevant and irrelevant data at clients. arXiv preprint arXiv:2001.08300, page 64, 2020.   \nS. Wan, J. Lu, P. Fan, Y. Shao, C. Peng, and K. B. Letaief. Convergence analysis and system design for federated learning over wireless networks. IEEE Journal on Selected Areas in Communications, 39(12):3622\u20133639, 2021.   \nH. Wang, Z. Kaplan, D. Niu, and B. Li. Optimizing federated learning on non-iid data with reinforcement learning. In IEEE INFOCOM 2020-IEEE conference on computer communications, pages 1698\u20131707. IEEE, 2020.   \nJ. Wang, Q. Liu, H. Liang, G. Joshi, and H. V. Poor. A novel framework for the analysis and design of heterogeneous federated learning. IEEE Transactions on Signal Processing, 69:5234\u20135249, 2021.   \nX. Wu, H. Huang, Y. Ding, H. Wang, Y. Wang, and Q. Xu. Fednp: Towards non-iid federated learning via federated neural propagation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 10399\u201310407, 2023.   \nC. Xiao and Y. Liu. A multifrequency data fusion deep learning model for carbon price prediction. Journal of Forecasting, 2024.   \nH. Xiao, K. Rasul, and R. Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.   \nL. Yang, J. Huang, W. Lin, and J. Cao. Personalized federated learning on non-iid data via groupbased meta-learning. ACM Transactions on Knowledge Discovery from Data, 17(4):1\u201320, 2023.   \nJ. Yao, Y. Lai, H. Kou, T. Wu, and R. Liu. Qe-bev: Query evolution for bird\u2019s eye view object detection in varied contexts. In ACM Multimedia 2024, 2024.   \nM. Ye, X. Fang, B. Du, P. C. Yuen, and D. Tao. Heterogeneous federated learning: State-of-the-art and research challenges. ACM Computing Surveys, 56(3):1\u201344, 2023.   \nK. Yin, Z. Ding, Z. Dong, D. Chen, J. Fu, X. Ji, G. Yin, and Z. Wang. Nipd: A federated learning person detection benchmark based on real-world non-iid data. arXiv preprint arXiv:2306.15932, 2023.   \nM. Yurochkin, M. Agarwal, S. Ghosh, K. Greenewald, N. Hoang, and Y. Khazaeni. Bayesian nonparametric federated learning of neural networks. In International conference on machine learning, pages 7252\u20137261. PMLR, 2019.   \nL. Zhang, L. Shen, L. Ding, D. Tao, and L.-Y. Duan. Fine-tuning global model via data-free knowledge distillation for non-iid federated learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10174\u201310183, 2022.   \nW. Zhang, X. Wang, P. Zhou, W. Wu, and X. Zhang. Client selection for federated learning with non-iid data in mobile edge computing. IEEE Access, 9:24462\u201324474, 2021.   \nZ. Zhang, X. Hu, J. Zhang, Y. Zhang, H. Wang, L. Qu, and Z. Xu. Fedlegal: The first real-world federated learning benchmark for legal nlp. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3492\u20133507, 2023.   \nY. Zhao, M. Li, L. Lai, N. Suda, D. Civin, and V. Chandra. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582, 2018.   \nH. Zhu, J. Xu, S. Liu, and Y. Jin. Federated learning on non-iid data: A survey. Neurocomputing, 465:371\u2013390, 2021.   \nZ. Zhu, Y. Shi, P. Fan, C. Peng, and K. B. Letaief. Isf:l Federated learning for non-iid data with local importance sampling. IEEE Internet of Things Journal, 2024. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Supplementary Explanation of the Diffusion-based Data Harmonization Mechanism ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Forward Diffusion Process In the forward diffusion process, Gaussian noise with variance $\\beta_{t}\\in$ $(0,1)$ is added gradually to the sample $\\mathbf{x}_{\\mathrm{0}}$ for $T$ steps. The process is defined as: ", "page_idx": 13}, {"type": "equation", "text": "$$\nq(\\mathbf{z}_{1:T}|z_{i})=\\prod_{t=1}^{T}q(\\mathbf{z}_{t}|\\mathbf{z}_{t-1}),\n$$", "text_format": "latex", "page_idx": 13}, {"type": "equation", "text": "$$\nq(\\mathbf{z}_{t}|\\mathbf{z}_{t-1})=\\mathcal{N}(\\mathbf{z}_{t};\\sqrt{1-\\beta_{t}}\\mathbf{z}_{t-1},\\beta_{t}\\mathbf{I}).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Using notations $\\alpha_{t}=1-\\beta_{t}$ and $\\begin{array}{r}{\\bar{\\alpha}_{t}=\\prod_{s=1}^{t}\\alpha_{s}}\\end{array}$ , the sample $\\mathbf{z}_{t}$ can be defined directly as: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{z}_{t}=\\sqrt{\\bar{\\alpha}_{t}}z_{i}+\\sqrt{1-\\bar{\\alpha}_{t}}\\epsilon,\\~~~~\\epsilon\\sim\\mathcal{N}(0,\\mathbf{I}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Reverse Denoising Process The reverse denoising process aims to sample reversely from ${\\bf z}_{T}$ through transition probabilities $q(\\mathbf{z}_{t-1}|\\mathbf{z}_{t})$ for timesteps $T-1$ through 1 to obtain a sample drawn from $q(z_{i})$ . The transition $q(\\mathbf{z}_{t-1}|\\mathbf{z}_{t})$ is a Gaussian distribution, tractable when conditioned on $z_{i}$ : ", "page_idx": 13}, {"type": "equation", "text": "$$\nq(\\mathbf{z}_{t-1}|\\mathbf{z}_{t},z_{i})=\\mathcal{N}(\\mathbf{z}_{t-1};\\tilde{\\mu}_{t}(\\mathbf{z}_{t},z_{i}),\\tilde{\\beta}_{t}\\mathbf{I}),\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the mean $\\tilde{\\pmb{\\mu}}_{t}$ and variance ${\\tilde{\\beta}}_{t}$ are calculated as: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\tilde{\\mu}_{t}(\\mathbf{z}_{t},z_{i})=\\displaystyle\\frac{1}{\\sqrt{\\alpha_{t}}}\\left(\\mathbf{z}_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\mathbf{\\epsilon}_{t}\\right),}\\\\ {\\tilde{\\beta}_{t}=\\displaystyle\\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar{\\alpha}_{t}}\\beta_{t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "The reverse transition probability $p_{\\theta}\\big(\\mathbf{z}_{t-1}\\big|\\mathbf{z}_{t}\\big)$ relies on the entire data distribution and is approximated through a neural network: ", "page_idx": 13}, {"type": "equation", "text": "$$\np_{\\theta}(\\mathbf{z}_{t-1}|\\mathbf{z}_{t})=N(\\mathbf{z}_{t-1};\\mu_{\\theta}(\\mathbf{z}_{t},t),\\Sigma_{\\theta}(\\mathbf{z}_{t},t)),\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\boldsymbol{\\Sigma}_{\\theta}(\\mathbf{z}_{t},t)\\,=\\,\\tilde{\\beta}_{t}\\mathbf{I}$ and the mean $\\pmb{\\mu}_{\\theta}(\\mathbf{z}_{t},t)$ depends on a noise sample $\\epsilon_{\\theta}(\\mathbf{z}_{t},t)$ learned by a neural network. The learning process is guided by the objective function: ", "page_idx": 13}, {"type": "equation", "text": "$$\nL=\\mathbb{E}_{t,z_{i},\\epsilon}\\left[||\\epsilon-\\epsilon_{\\theta}(\\mathbf{z}_{t},t)||^{2}\\right],\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "while the output sample is obtained as: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbf{z}_{t-1}=\\frac{1}{\\sqrt{\\alpha_{t}}}\\left(\\mathbf{z}_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\epsilon_{\\theta}(\\mathbf{z}_{t},t)\\right)+\\sigma_{t}\\mathbf{z},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\mathbf{z}\\sim\\mathcal{N}(0,\\mathbf{I})$ if $t>1$ and $\\mathbf{z}=0$ otherwise. ", "page_idx": 13}, {"type": "text", "text": "A.2 Proof of Theorem 3.1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Proof. To prove the convergence, we need to show how the indicator function promotes stable updates of the global model. Consider a simplified federated learning framework where the global model parameters $\\theta$ are updated at iteration $t$ as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\theta_{t+1}=\\theta_{t}-\\eta\\sum_{i=1}^{n}\\nabla_{\\theta}I_{\\lambda}(l_{i},\\sigma_{i}),\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\eta$ is the learning rate and $n$ is the number of clients. For simplicity, we consider a single client and expand $\\nabla_{\\theta}I_{\\lambda}(l_{i},\\bar{\\sigma}_{i})$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\nabla_{\\boldsymbol{\\theta}}I_{\\lambda}(l_{i},\\sigma_{i})=\\nabla_{\\boldsymbol{\\theta}}\\left((l_{i}-\\tau)\\sigma_{i}+\\lambda(\\log\\sigma_{i})^{2}\\right).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "By the chain rule, we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\nabla_{\\theta}I_{\\lambda}(l_{i},\\sigma_{i})=\\sigma_{i}\\nabla_{\\theta}l_{i}+(l_{i}-\\tau)\\nabla_{\\theta}\\sigma_{i}+2\\lambda\\frac{\\log{\\sigma_{i}}}{\\sigma_{i}}\\nabla_{\\theta}\\sigma_{i}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Based on the definition of the optimal $\\boldsymbol{\\sigma}_{i}^{*}$ , $\\nabla_{\\boldsymbol{\\theta}}\\sigma_{i}^{*}$ can be approximated as proportional to $\\nabla_{\\theta}l_{i}$ , i.e., ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\nabla_{\\theta}\\sigma_{i}^{*}\\approx k\\nabla_{\\theta}l_{i},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $k$ is a constant. Thus, $\\nabla_{\\theta}I_{\\lambda}(l_{i},\\sigma_{i}^{*})$ simplifies to: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\nabla_{\\theta}I_{\\lambda}(l_{i},\\sigma_{i}^{*})=\\left(\\sigma_{i}^{*}+(l_{i}-\\tau)k+2\\lambda\\frac{\\log\\sigma_{i}^{*}}{\\sigma_{i}^{*}}k\\right)\\nabla_{\\theta}l_{i}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Since $\\boldsymbol{\\sigma}_{i}^{*}$ is obtained by minimizing the indicator function, we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\sigma_{i}^{*}\\approx\\exp\\left(W\\left(\\frac{-(l_{i}-\\tau)}{2\\lambda}\\right)\\right).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Finally, the model update rule can be expressed as: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\theta_{t+1}=\\theta_{t}-\\eta\\left(\\sigma_{i}^{*}+(l_{i}-\\tau)k+2\\lambda\\frac{\\log\\sigma_{i}^{*}}{\\sigma_{i}^{*}}k\\right)\\nabla_{\\theta}l_{i}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "To prove convergence, we note that the step size of parameter updates is finite: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left\\vert\\theta_{t+1}-\\theta_{t}\\right\\vert=\\eta\\left\\vert\\left(\\sigma_{i}^{*}+(l_{i}-\\tau)k+2\\lambda\\frac{\\log\\sigma_{i}^{*}}{\\sigma_{i}^{*}}k\\right)\\nabla_{\\theta}l_{i}\\right\\vert\\leq\\eta C\\left\\vert\\nabla_{\\theta}l_{i}\\right\\vert,\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $C$ is a constant. Thus, as long as the learning rate $\\eta$ is appropriately chosen, the update step size will gradually decrease, ensuring the convergence of the model. ", "page_idx": 14}, {"type": "text", "text": "Convergence speed Next, we compare the convergence speed of our method with the FedAvg algorithm. ", "page_idx": 14}, {"type": "text", "text": "For FedAvg, the update rule is: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\theta_{t+1}=\\theta_{t}-\\eta\\frac{1}{n}\\sum_{i=1}^{n}\\nabla_{\\theta}l_{i},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where the update step size is: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left|\\theta_{t+1}-\\theta_{t}\\right|_{\\mathrm{FedAvg}}=\\eta\\left|\\frac{1}{n}\\sum_{i=1}^{n}\\nabla_{\\theta}l_{i}\\right|.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "For our method with the indicator function, the update step size is: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left|\\theta_{t+1}-\\theta_{t}\\right|_{I_{\\lambda}}=\\eta\\left|\\left(\\sigma_{i}^{*}+(l_{i}-\\tau)k+2\\lambda\\frac{\\log\\sigma_{i}^{*}}{\\sigma_{i}^{*}}k\\right)\\nabla_{\\theta}l_{i}\\right|.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "To demonstrate that our method converges faster or has a tighter bound, we analyze the total update step sizes over all clients. ", "page_idx": 14}, {"type": "text", "text": "For FedAvg: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{n}\\left|\\theta_{t+1}-\\theta_{t}\\right|_{\\mathrm{FedAvg}}=\\eta\\sum_{i=1}^{n}\\left|\\nabla_{\\theta}l_{i}\\right|.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "For our method: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{n}\\left|\\theta_{t+1}-\\theta_{t}\\right|_{I_{\\lambda}}=\\eta\\sum_{i=1}^{n}\\left|\\left(\\sigma_{i}^{*}+(l_{i}-\\tau)k+2\\lambda\\frac{\\log\\sigma_{i}^{*}}{\\sigma_{i}^{*}}k\\right)\\nabla_{\\theta}l_{i}\\right|.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "When $\\begin{array}{r}{\\sigma_{i}^{*}=\\exp\\left(W\\left(\\frac{-(l_{i}-\\tau)}{2\\lambda}\\right)\\right),\\lambda\\geq\\frac{-(l_{i}-\\tau)}{2e}}\\end{array}$ , and $\\begin{array}{r}{\\tau=l_{\\mathrm{max}}-2\\lambda\\ln\\left(\\frac{1}{k}\\right)}\\end{array}$ , we can ensure $|C_{i}|\\leq1$ thus: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\left|C_{i}\\nabla_{\\theta}l_{i}\\right|\\leq\\left|\\nabla_{\\theta}l_{i}\\right|.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Thus, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{n}|C_{i}\\nabla_{\\theta}l_{i}|\\leq\\sum_{i=1}^{n}|\\nabla_{\\theta}l_{i}|\\,.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Therefore, the update step size for our method is less than or equal to that of FedAvg. ", "page_idx": 15}, {"type": "text", "text": "A.3 Design and Training Details of the Model Encoder and Distribution Decoder ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In the CRFed framework, both the model encoder and distribution decoder play crucial roles in ensuring effective data harmonization and robust model updates. These components are implemented using autoencoder architectures, designed to compress and reconstruct data representations efficiently. ", "page_idx": 15}, {"type": "text", "text": "A.3.1 Model Encoder ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The model encoder $E$ is responsible for compressing the global model parameters $\\theta_{t}$ into a lowerdimensional meta-model representation $\\phi_{t}$ . The encoder architecture comprises several fully connected layers activated by ReLU functions, followed by a linear transformation layer to produce the final compressed representation. ", "page_idx": 15}, {"type": "text", "text": "Mathematically, given the input global model parameters $\\theta_{t}\\in\\mathbb{R}^{d}$ , the encoder outputs a compressed representation $\\overline{{\\phi_{t}}}=E(\\theta_{t})\\in\\overline{{\\mathbb{R}^{d}}}$ , where $d^{\\prime}<d$ . The transformation is defined as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\iota_{1}=\\mathrm{ReLU}(W_{1}\\theta_{t}+b_{1})h_{2}=\\mathrm{ReLU}(W_{2}h_{1}+b_{2});h_{k}=\\mathrm{ReLU}(W_{k}h_{k-1}+b_{k})\\phi_{t}=W_{o u t}h_{k}+b_{o u t}h_{o u t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The training of the model encoder involves minimizing the mean squared error (MSE) between the original model parameters and their reconstructions. The loss function is given by: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{L}_{E}=\\frac{1}{N}\\sum_{i=1}^{N}\\|\\theta_{t_{i}}-\\hat{\\theta}_{t_{i}}\\|^{2}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\hat{\\theta}_{t_{i}}\\,=\\,E^{-1}(E(\\theta_{t_{i}}))$ and $N$ is the number of samples. The optimization is performed using the Adam optimizer with a learning rate $\\eta$ . The detailed architecture includes an input layer of size $d$ , hidden layers of sizes [128, 64, 32], and an output layer of size $d^{\\prime}=16$ . ", "page_idx": 15}, {"type": "text", "text": "A.3.2 Distribution Decoder ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The distribution decoder $D$ aims to transform the denoised latent representations $\\mathbf{z}_{t}$ back into the desired data distribution. Like the encoder, the decoder uses a series of fully connected layers with ReLU activations, culminating in a linear layer to reconstruct the data. ", "page_idx": 15}, {"type": "text", "text": "Given the input latent representation $\\mathbf{z}_{t}\\,\\in\\,\\mathbb{R}^{d^{\\prime}}$ , the decoder outputs the reconstructed data $\\hat{\\mathbf{x}}_{t}\\,=$ $D(\\mathbf{z}_{t})\\in\\mathbb{R}^{d}$ . The transformations are defined as: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\iota_{1}=\\mathrm{ReLU}(W_{1}^{\\prime}\\mathbf{z}_{t}+b_{1}^{\\prime})h_{2}=\\mathrm{ReLU}(W_{2}^{\\prime}h_{1}+b_{2}^{\\prime});h_{k}=\\mathrm{ReLU}(W_{k}^{\\prime}h_{k-1}+b_{k}^{\\prime})\\hat{\\mathbf{x}}_{t}=W_{o u t}^{\\prime}h_{k}+b_{o u t}^{\\prime}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The training process for the distribution decoder also minimizes the MSE, defined as: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathcal{L}_{D}=\\frac{1}{N}\\sum_{i=1}^{N}\\|\\mathbf{x}_{t_{i}}-\\hat{\\mathbf{x}}_{t_{i}}\\|^{2}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\hat{\\mathbf{x}}_{t_{i}}=D(\\mathbf{z}_{t_{i}})$ and $N$ is the number of samples. The optimization employs the Adam optimizer with a learning rate $\\eta$ . The architecture details include an input layer of size $d^{\\prime}=16$ , hidden layers of sizes [32, 64, 128], and an output layer of size $d$ . ", "page_idx": 16}, {"type": "text", "text": "A.3.3 Architectural Details ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The model encoder and distribution decoder share a similar architectural approach, emphasizing efficient compression and reconstruction through deep learning techniques. The key parameters for both autoencoders are summarized as follows: ", "page_idx": 16}, {"type": "text", "text": "\u2022 Model Encoder: ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "\u2013 Input layer size: $d$ \u2013 Hidden layer sizes: [128, 64, 32] \u2013 Output layer size: $d^{\\prime}=16$ \u2013 Activation function: ReLU \u2013 Learning rate: $\\eta=0.001$ \u2013 Batch size: 32 \u2022 Distribution Decoder: \u2013 Input layer size: $d^{\\prime}=16$ \u2013 Hidden layer sizes: [32, 64, 128] \u2013 Output layer size: $d$ \u2013 Activation function: ReLU \u2013 Learning rate: $\\eta=0.001$ \u2013 Batch size: 32 ", "page_idx": 16}, {"type": "text", "text": "These architectural and training details ensure that the CRFed framework can effectively handle noni.i.d. data distributions, facilitating robust and consistent model updates across federated learning environments. ", "page_idx": 16}, {"type": "text", "text": "A.4 Pseudocode for CRFed ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The complete computational process of CRFed is illustrated in Algorithm 1. ", "page_idx": 16}, {"type": "text", "text": "A.5 Detailed Model Structure ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The detailed configuration of the models used in our experiments is provided below. Each table outlines the layers and parameters for the respective datasets. ", "page_idx": 16}, {"type": "table", "img_path": "G89r8Mgi5r/tmp/24b83c487a1a4dc511d6b09bb5b4d4a90e27d1a694e99ce139ff8ff61ee62e7c.jpg", "table_caption": ["Table 4: Model structure for MNIST and FashionMNIST datasets "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "Algorithm 1 Confusion-Resistant Federated Learning via Consistent Diffusion (CRFed) ", "page_idx": 17}, {"type": "text", "text": "Require: Maximum global rounds $T_{G}$ , local training cycles $E_{l}$ , client weights $\\{\\pi_{k}\\}$ , local datasets   \n$\\big\\{\\mathcal D_{k}\\big\\}$ , learning rate $\\eta_{0}$ , indicator function threshold $\\gamma$   \n1: Initialize global model parameters $\\theta_{0}$   \n2: Initialize local model parameters $\\{\\theta_{0}^{k}\\}$ and importance sampling weights $\\{w_{i}^{k}\\gets1\\}$   \n3: Set $t\\gets1$   \n4: while $t\\leq T_{G}\\times E_{l}$ do   \n5: for each client $k$ do   \n6: Sample local data $\\mathcal{D}_{i}^{\\mathrm{sampled}}$ based on importance weights $w_{i}^{k}$   \n7: Train local model \u03b8tk on Disampled   \n8: end for   \n9: if $t$ mod $E_{l}==0$ then   \n10: Each client uploads local model $\\{\\theta_{t}^{k}\\}$ to the server   \n11: Server aggregates the global model: $\\begin{array}{r}{\\dot{\\theta}_{t}\\leftarrow\\sum_{k=1}^{K}\\pi_{k}\\theta_{t}^{k}}\\end{array}$   \n12: for each client do   \n13: Compute optimal indicator function $I^{*}$   \n14: Calculate optimal sampling probability $P_{i}^{*}=\\mathrm{ReverseDenoise}(I^{*})$   \n15: Calculate importance sampling weights wi = PP i\u2217   \n16: Sample new local data $\\mathcal{D}_{i}^{\\mathrm{sampled}}$ based on updated importance weights $w_{i}$   \n17: Train local model \u03b8tk on Disampled   \n18: Update local model ${\\theta}_{t}^{k}\\gets\\bar{\\theta}_{t}$   \n19: Adjust learning rate: \u03b7i = \u03b70 \u00b7max\u03bbj I\u03bbi(lji,\u03c3j)   \n20: end for   \n21: end if   \n22: $t\\gets t+1$   \n23: end while   \n24: Output: Global model $\\bar{\\theta}_{t}$ , local models $\\{\\theta_{t}^{k}\\}$ ", "page_idx": 17}, {"type": "table", "img_path": "G89r8Mgi5r/tmp/6eb300aa169e3e0d6fde90c0276ce2837fad20e4795b09f359b85f9413845a67.jpg", "table_caption": ["Table 5: Model structure for CIFAR-10 and CIFAR-100 datasets "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "All weights are initialized with a normal distribution (mean 0, standard deviation 0.1) and biases with a constant value of 0.1. These settings ensure that the models are well-prepared for training and capable of achieving high performance on the respective datasets. ", "page_idx": 17}, {"type": "text", "text": "In the NIPD dataset, we adopted the classic YOLOv3 [Redmon and Farhadi, 2018] model. ", "page_idx": 17}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: The main claims in the abstract and introduction are supported by detailed descriptions, empirical evaluations, and theoretical analysis provided in the body of the paper (Sections 1, 3, and 4). ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 18}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: The paper discusses the limitation in Section 5, addressing potential biases from large language models. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 18}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The paper includes a detailed proof for the convergence theorem in Section 3, providing all necessary assumptions and a complete proof. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 19}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The paper specifies the datasets used, the training and testing details, the hyperparameters, and the evaluation metrics in Section 4, ensuring that the experiments can be reproduced. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 19}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: The data and code is provided. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so No is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 20}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: The paper provides comprehensive details on the training and testing setups, including data splits, hyperparameters, and optimizer settings in Section 4. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 20}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: Since some baselines involve randomness using $\\boldsymbol{\\mathrm{k}}$ -means, the paper did $95\\%$ significance test using 10 repeated results. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 20}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 21}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The paper provides details on the computational resources used, including the type of GPUs and the total amount of compute required for the experiments, as mentioned in Section 4. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 21}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The research adheres to the NeurIPS Code of Ethics, ensuring transparency, reproducibility, and consideration of ethical implications throughout the study. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 21}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The paper discusses the potential positive impacts of improving clustering techniques for various applications and mentions possible negative impacts such as biases introduced by large language models and the risk of misuse in surveillance, along with mitigation strategies in Section 5. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 22}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: The paper does not involve the release of data or models that have a high risk for misuse. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 22}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: The paper properly credits the creators of the datasets and models used, and mentions the licenses and terms of use, as detailed in Section 4. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets. \u2022 The authors should cite the original paper that produced the code package or dataset. \u2022 The authors should state which version of the asset is used and, if possible, include a URL. ", "page_idx": 22}, {"type": "text", "text": "\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 23}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The new datasets and code introduced in the paper are well documented. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 23}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing or research with human subjects. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 23}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing or research with human subjects. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 23}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 24}]