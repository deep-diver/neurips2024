[{"type": "text", "text": "Thinking Forward: Memory-Efficient Federated Finetuning of Language Models ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Kunjal Panchal ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Sunav Choudhary ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Nisarg Parikh University of Massachusetts Amherst, MA 01003-9264 nkparikh@umass.edu ", "page_idx": 0}, {"type": "text", "text": "University of Massachusetts Amherst, MA 01003-9264 kpanchal@umass.edu ", "page_idx": 0}, {"type": "text", "text": "Adobe Research Bangalore, India 560103 schoudha@adobe.com ", "page_idx": 0}, {"type": "text", "text": "Lijun Zhang ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yuriy Brun University of Massachusetts Amherst, MA 01003-9264 brun@cs.umass.edu ", "page_idx": 0}, {"type": "text", "text": "University of Massachusetts Amherst, MA 01003-9264 lijunzhang@cs.umass.edu ", "page_idx": 0}, {"type": "text", "text": "University of Massachusetts Amherst, MA 01003-9264 huiguan@cs.umass.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Finetuning large language models (LLMs) in federated learning (FL) settings has become increasingly important as it allows resource-constrained devices to finetune a model using private data. However, finetuning LLMs using backpropagation requires excessive memory (especially from intermediate activations) for resource-constrained devices. While Forward-mode Auto-Differentiation (AD) can significantly reduce memory footprint from activations, we observe that directly applying it to LLM finetuning results in slow convergence and poor accuracy. In this paper, we introduce SPRY, an FL algorithm that splits trainable weights of an LLM among participating clients, such that each client computes gradients using Forward-mode AD that are closer estimations of the true gradients. SPRY achieves a low memory footprint, high accuracy, and fast convergence. We formally prove that the global gradients in SPRY are unbiased estimators of true global gradients for homogeneous data distributions across clients, while heterogeneity increases bias of the estimates. We also derive SPRY\u2019s convergence rate, showing that the gradients decrease inversely proportional to the number of FL rounds, indicating the convergence up to the limits of heterogeneity. Empirically, SPRY reduces the memory footprint during training by $1.4\u20137.1\\times$ in contrast to backpropagation, while reaching comparable accuracy, across a wide range of language tasks, models, and FL settings. SPRY reduces the convergence time by $1.2\u201320.3\\times$ and achieves $5.2\u201313.5\\%$ higher accuracy against state-of-the-art zero-order methods. When finetuning Llama2-7B with LoRA, compared to the peak memory consumption of 33.9GB of backpropagation, SPRY only consumes 6.2GB of peak memory. For OPT13B, the reduction is from 76.5GB to 10.8GB. SPRY makes feasible previously impossible FL deployments on commodity mobile and edge devices. Our source code is available for replication at https://github.com/Astuary/Spry. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In cross-device federated learning (FL), thousands of edge devices (called clients) collaborate through an orchestrator (called server) to jointly train a machine learning (ML) model [1, 2]. In each round of FL, the server sends an ML model to participating clients, who then update the model weights for several epochs on their individual data and send the new weights back to the server. The server aggregates the weights to update the model and initiates the next round of FL training. Due to the inherent privacy-preserving nature of FL, it has been adopted in many privacy-sensitive domains, such as healthcare [3], IoT [4, 5], and e-commerce [6]. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In parallel, large language models (LLMs) have demonstrated impressive performance on natural language processing tasks [7, 8], creating a surge of interest in finetuning LLMs in FL settings [9, 10]. However, the problem is challenging in practice because of the memory requirements in finetuning LLMs. LLMs can have billions of weights, and finetuning them with backpropagation requires dozens of GBs of memory. These requirements easily overwhelm edge devices, particularly mobile phones with limited memory. The memory footprint of finetuning LLMs mainly comes from model weights and their gradients, optimizer states, and intermediate activations. ", "page_idx": 1}, {"type": "text", "text": "There are three categories of existing algorithms that reduce the memory footprint of finetuning LLMs: parameter-efficient finetuning (PEFT) [11\u201316], quantization [17], and zero-order gradient estimation methods [18\u201320]. Although PEFT and quantization can reduce the memory consumption from parameters and optimizer states, the memory consumed by intermediate activations remains a significant bottleneck because these methods still use backpropagation to finetune LLMs. Backpropagation requires storing all intermediate activations during the forward pass to estimate gradients in the backward pass. For example, finetuning a 4-bit quantized Llama2-7B model [21] with LoRA techniques [12] requires ${\\sim}33.9\\mathrm{GB}$ of RAM, with $83.8\\%$ used for intermediate activations. Zero-order methods leverage finite difference [22] to estimate gradients and thus reduce the memory consumption from intermediate activations [19, 20, 23]. However, these methods suffer from slow convergence and poor model quality because the accumulation of truncation and round-off errors [24], a fundamental issue of finite difference, leads to noisy estimation of weight gradients. ", "page_idx": 1}, {"type": "text", "text": "Forward-mode Auto-Differentiation $(A D)$ [24, 23] has the potential to address the memory consumption problems of backpropagation without introducing the round-off errors of finite difference. It estimates gradients by computing a Jacobian-vector product $(\\mathtt{j v p})$ based on random perturbations of weights during the forward pass, alleviating the need to store all intermediate activations, similar to zero-order methods. $\\mathtt{j v p}$ represents how much changing the weights in the direction of a random perturbation affects the outputs. However, simply replacing backpropagation with Forward-mode AD in FL settings does not produce convergence speed and accuracy performance comparable to established federated optimizers based on backpropagation, such as FEDAVG [1], FEDYOGI [25], FEDSGD [1]. Forward gradients are computationally inefficient and inaccurate in estimating true gradients when the number of trainable weights is large. We empirically observed that, for LLMs finetuned with the LoRA technique, Forward-mode AD suffers from $8.3{-}57.2\\%$ accuracy loss and is $1.4\u20133.9\u2013$ slower to converge for models whose number of trainable weights exceed approximately $1.15\\mathrm{M}$ (see Appendix G). ", "page_idx": 1}, {"type": "text", "text": "In this paper, we propose SPRY1, an FL algorithm for finetuning LLMs using Forward-mode AD while achieving low memory footprint, high accuracy, and fast convergence. SPRY tackles the shortcomings of Forward-mode AD by splitting the trainable weights among participating clients per FL round. SPRY improves computation efficiency as each client only needs to perturb a small fraction of trainable weights to derive their gradients, reducing the number of computations in each forward pass. SPRY achieves higher accuracy and faster convergence because the smaller number of trainable weights for each participating client allows computing gradients that are closer estimations of the true gradients. In contrast to zero-order methods where one training iteration requires 20\u2013100 forward passes, each with a different perturbation [20, 19] to estimate weight gradients well, SPRY allows computing weight gradients from only one forward pass per iteration for each client. Unlike split learning [26], SPRY does not need to transfer intermediate activations among clients. The union of the partial weights trained from each participating client in an FL round updates all the trainable weights of the language model. Since only a subset of weights is finetuned per client, SPRY also saves client-to-server communication bandwidth. ", "page_idx": 1}, {"type": "text", "text": "We formally prove that the global gradients aggregated on the server side in SPRY are unbiased estimators of the true global gradients in case of homogeneous data distributions across clients, while the heterogeneity increases the bias of the estimations. We also derive the convergence rate of SPRY, showing that the norm of global gradients decreases linearly with the inverse of the number of FL rounds. We further discuss how configurations in SPRY affect the convergence behavior of the algorithm and empirically validate the theoretical analysis. ", "page_idx": 1}, {"type": "text", "text": "We empirically evaluate SPRY\u2019s memory efficiency, accuracy, computation efficiency, and communication efficiency through experiments on a wide range of language tasks, models, and FL settings. SPRY achieves within $0.6\u20136.2\\%$ of the accuracy of the best-performing FL backpropagation, with $1.4\u20137.1\\times$ less memory consumption for each client and comparable time to convergence. SPRY also outperforms zero-order-based baselines with $5.2\u201313.5\\%$ higher accuracy, an average of $1.5\u201328.6\\times$ faster per-round computation time, and $1.2\u201320.3\\times$ faster convergence. We also compare SPRY\u2019s communication efficiency to that of FEDAVG (per-epoch communication) and FEDSGD (per-iteration communication). For communication frequency of per-epoch, SPRY reduces the number of model weights sent from a client to the server by $M$ times, where $M$ is the number of participating clients per round. For per-iteration communication frequency, each client of SPRY only needs to send back a scalar to the server, fixing the client-to-server total communication cost to $M$ scalar values. ", "page_idx": 2}, {"type": "text", "text": "We make the following contributions: ", "page_idx": 2}, {"type": "text", "text": "1. SPRY, the first work that demonstrate the potential of Forward-mode AD for finetuning language models (with 18M to 13B parameters) in FL settings with low memory footprint, high accuracy, and fast convergence.   \n2. A federated optimization strategy that only requires a single forward pass per batch on each client to finetune a language model.   \n3. A theoretical analysis of how SPRY\u2019s global gradients estimate true gradients based on the heterogeneity of FL clients, and a proof that SPRY\u2019s convergence is linearly dependent on the number of FL rounds when a client\u2019s learning rate is inversely proportional to the size of perturbations and client data heterogeneity.   \n4. An empirical evaluation shows that SPRY consumes $1.4\u20137.1\\times$ less memory than its backpropagation-based counterparts, and converges $1.2\u201320.3\\times$ faster with $5.2\u201313.5\\%$ higher accuracy compared to its zero-order counterparts. ", "page_idx": 2}, {"type": "text", "text": "2 Forward-mode Automatic Differentiation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "This section presents the background on Forward-mode Auto-Differentiation (AD) necessary to follow the work. Related works on zero-order optimization methods, Forward-mode AD, and FL for LLMs are discussed in detail in Appendix A. ", "page_idx": 2}, {"type": "text", "text": "Forward-mode AD computes gradients by measuring how changes in model weights, in the direction of a random perturbation, affect the loss. Since these gradients are derived from a forward pass, they are referred to as forward gradients [23]. In contrast, backpropagation (also Reverse-mode AD) calculates a direction to adjust weights in, to decrease the loss. Formally, for each training iteration, given the trainable weights $\\pmb{w}$ , Forward-mode AD generates a random perturbation $\\pmb{v}$ whose size is the same as $\\pmb{w}$ . In one forward pass, given training data $\\mathcal{D}$ , Forward-mode AD computes the value of the objective function $f(\\pmb{w};\\mathcal{D})$ and the Jacobian-vector product $(\\mathtt{j v p})$ as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{J}_{f}v=\\nabla f_{v}(w;\\mathcal{D})=\\left[\\frac{\\partial f(w;\\mathcal{D})}{\\partial w_{1}}\\quad.\\,.\\,.\\quad\\frac{\\partial f(w;\\mathcal{D})}{\\partial w_{d}}\\right]\\left[v_{1}\\quad.\\,.\\,.\\quad v_{d}\\right]^{T}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "This $\\mathtt{j v p}$ is a scalar for neural networks since the output of the objective function $f$ is a scalar. Multiplying $\\mathtt{j v p}$ with the perturbation $\\pmb{v}$ gives us the unbiased estimate of true gradients [23], ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla F(\\pmb{w})=\\mathbb{E}_{\\pmb{v}}\\left[\\mathbf{J}_{f}\\pmb{v}\\cdot\\pmb{v}\\right]=\\mathbb{E}_{\\pmb{v},\\mathcal{D}}\\left[\\left(\\left[\\frac{\\partial f(\\pmb{w};\\mathcal{D})}{\\partial w_{1}}\\quad...\\quad\\frac{\\partial f(\\pmb{w};\\mathcal{D})}{\\partial w_{d}}\\right]\\pmb{v}^{T}\\right)\\pmb{v}\\right]}\\\\ &{\\qquad\\qquad=\\mathbb{E}_{\\mathcal{D}}\\left[\\frac{\\partial f(\\pmb{w};\\mathcal{D})}{\\partial w_{1}}\\quad...\\quad\\frac{\\partial f(\\pmb{w};\\mathcal{D})}{\\partial\\pmb{w}_{d}}\\right]=\\mathbb{E}_{\\mathcal{D}}\\left[\\nabla f(\\pmb{w};\\mathcal{D})\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The partial derivative $\\partial f(\\pmb{w};\\mathcal{D})/\\partial\\pmb{w}$ is computed by chain rule on intermediate activations in the forward pass [24]. Unlike backpropagation where all the intermediate activations need to be stored during the forward pass, Forward-mode AD only stores the previous layer\u2019s activations in the forward pass for the chain rule derivatives. Hence, the memory overhead of deriving gradients would be the size of the largest activation in the forward pass. ", "page_idx": 2}, {"type": "text", "text": "3 SPRY: Memory-Efficient Federated Finetuning of Language Models ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "While Forward-mode AD can decrease memory usage during model finetuning, merely substituting backpropagation with Forward-mode AD in FL scenarios often results in poor accuracy and computational inefficiency. To address this challenge, SPRY recognizes that Forward-mode AD operates more efficiently and yields better gradient estimations when the trainable weight count is minimized. Therefore, SPRY optimizes performance by distributing trainable weights among participating clients, assigning each client a responsibility to compute gradients for only a subset of trainable weights. SPRY is compatible with PEFT methods such as IA3 [15], ADAPTER-based methods [27], BITFIT [28], and LORA [12], which mitigate the memory consumption from gradients and optimizer states. In this work, we focus on LORA due to its demonstrated superiority, as highlighted in Appendix G. ", "page_idx": 2}, {"type": "image", "img_path": "dGQtja9X2C/tmp/192e495f7be83a07304ef1d8539fc84e11fdaacb98eea42bef6e122a741e110a.jpg", "img_caption": ["Figure 1: Overview of SPRY, a federated learning framework to finetune language models with low memory footprint. The term \u201cPEFT\u201d stands for parameter-efficient fine-tuning. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Figure 1 gives an overview of SPRY. It includes 5 main steps: (1) At the beginning of each FL round, the server assigns a few trainable layers to each of the participating clients of that round. (2) Each client is sent (i) the trainable weights of the layers assigned to it, (ii) frozen weights of the remaining layers if not previously received, and (iii) a scalar seed value. (3) On the client side, weight perturbations for the allocated layers are generated based on the received seed. These perturbations are utilized to update the assigned weights through computation of the forward gradients. (4) Clients only transmit the updated weights back to the server. (5) The server aggregates all the trained layer weights and updates the language model for the subsequent round. ", "page_idx": 3}, {"type": "text", "text": "Next, we discuss the two key steps of SPRY in detail: Step (1), where the server assigns trainable weights to the participating clients and Step (3), where each client finetunes the assigned trainable weights using Forward-mode AD. ", "page_idx": 3}, {"type": "text", "text": "3.1 Assigning Trainable Layers to Clients at the Server-side ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To enable closer gradient estimations through forward gradients, the server reduces the number of trainable weights per client by selecting a layer and assigning it to a client in a cyclic manner. With LORA, the server selects a LoRA layer, which consists of a pair of weights ( $w_{A}$ and $w_{B}$ matrices) for each client. When # trainable layers $>\\#$ participating clients, each client will be assigned more than one layer. Otherwise, each layer will be assigned to more than one client. The server aggregates the trained weights from each client and updates the model using adaptive optimizers such as FEDYOGI. Adaptive optimizers are shown to be less prone to noisy updates compared to FEDAVG in the literature [25, 29]. The server keeps a mapping of layer names to client IDs, hence it can gather updated layer weights from all clients and update the model. ", "page_idx": 3}, {"type": "text", "text": "FL often faces the data heterogeneity issue, where the data distribution of one client differs from another, leading to poor model accuracy. While the primary aim of SPRY does not directly tackle this issue, it seamlessly integrates with existing finetuning-based personalization techniques [30] to mitigate it. SPRY distributes trainable classifier layers to all participating clients, enabling each client to finetune these layers to personalize the jointly trained model. ", "page_idx": 3}, {"type": "text", "text": "3.2 Finetuning Weights with Forward Gradients on the Client-side ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Clients update the assigned trainable weights with gradients estimated through Forward-mode AD. Specifically, each participating client will get a copy of the trainable weights assigned to it and a scalar seed value from the server. Using the seed value, the client generates a random perturbation for each trainable weight, following a normal distribution with a mean of 0 and a standard deviation of 1. Forward gradients are obtained during forward pass, as shown in Eq. 3. The subsequent steps depend on the communication frequency. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Per-Epoch Communication. Per-epoch communication means that each client transmits the updated trainable weights to the server after every one or more epochs. Locally, the trainable weights are updated using optimizers such as SGD and ADAM. Only the updated trainable weights are sent back to the server, which reduces communication costs. Each client transmits the weights of max $\\left\\{{\\frac{\\#{\\mathrm{Trainable~Layers}}}{\\#{\\mathrm{participating~clients}}}},1\\right\\}$ layers. This means that if there are more trainable layers than participating clients, each client sends back weights for multiple layers. ", "page_idx": 4}, {"type": "text", "text": "Per-Iteration Communication. Unlike FEDSGD, where gradients are sent back to the server and aggregated after each iteration, SPRY offers additional communication cost savings. In this communication mode, SPRY only requires sending the jvp scalar value back to the server after each iteration of fine-tuning. Since the server has the seed value, it can generate the same random perturbation used by each client. Using the received $\\mathtt{j v p}$ values and the generated random perturbations, the server can then compute the gradients and update the model weights. ", "page_idx": 4}, {"type": "text", "text": "A detailed breakdown of communication and computation costs is given in Appendix F. ", "page_idx": 4}, {"type": "text", "text": "4 Theoretical Analysis ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "This section theoretically analyzes convergence behaviors of SPRY. SPRY has a unique aggregation rule for the trainable weights as each client trains a subset of weights. It is also the first work to utilize forward gradients to train LLMs in FL settings where clients could have heterogeneous data distributions. Therefore, we theoretically analyze the effects of (a) data heterogeneity on gradient estimations of SPRY, and (b) configurations in SPRY, including the number of FL rounds, dimension of perturbations, the number of perturbations per iteration, data heterogeneity, and the number of participating clients, on the convergence of SPRY. The proofs are detailed in Appendix I. ", "page_idx": 4}, {"type": "text", "text": "Theorem 4.1 (Estimation of the Global Gradient). In SPRY, global forward gradients $\\nabla\\hat{f}$ of the trainable weights $w\\in\\mathbb{R}^{d}$ , with the corresponding weight perturbations $\\boldsymbol{v}\\in\\bar{\\mathbb{R}}^{d}$ , computed by $M$ participating clients is estimated in terms of true global gradients $\\nabla f$ as, ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\nabla\\hat{f}(w,v;\\mathcal{D})]\\!=\\!\\nabla f(w)\\!+\\!\\frac{1}{\\widetilde{M}}\\!\\left[\\sum_{m\\in\\widetilde{M}_{2}}\\!\\!\\sum_{c=1}^{C}\\alpha_{m,c}\\mathbb{E}_{(x,y_{c})\\in\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{[1,\\frac{d}{M}]},v_{[1,\\frac{d}{M}]};(x,y_{c}))\\right]\\right]^{T}}\\\\ {\\mathbb{E}[\\nabla\\hat{f}(w,v;\\mathcal{D})]\\!=\\!\\nabla f(w)\\!+\\!\\frac{1}{\\widetilde{M}}\\!\\left[\\sum_{m\\in\\widetilde{M}_{2}}\\!\\!\\sum_{c=1}^{C}\\!\\!\\alpha_{m,c}\\mathbb{E}_{(x,y_{c})\\in\\mathcal{D}}\\!\\left[\\nabla\\hat{f}_{m}(w_{[\\frac{d}{M}+1,\\frac{2d}{M}]},v_{[\\frac{d}{M}+1,\\frac{2d}{M}]}^{\\prime};(x,y_{c}))\\right]\\!\\right]^{T}}\\\\ {\\vdots}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where the expectation is under the randomness of sampled data and random perturbation $v.~C$ is total number of classes and $\\begin{array}{r}{\\alpha_{m,c}=\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\dot{\\alpha}_{c}}{|\\mathcal{D}_{m}|}\\right)}\\end{array}$ . For a class c, $n_{c}$ is its sample count, $\\alpha_{c}$ is its Dirichlet concentration parameter. For a client $m$ , $n_{m,c}$ is the sample count of the $c^{t h}$ class and $\\mathcal{D}_{m}$ is the size of the data of client $m$ . The global data is $\\begin{array}{r}{\\mathcal{D}=\\sum_{m\\in\\mathcal{M}}\\mathcal{D}_{m}}\\end{array}$ . $\\widetilde{\\mathcal{M}}$ is the set of clients training an arbitrary subset of weights, $\\widetilde{M}=|\\widetilde{\\mathcal{M}}_{i}|,\\forall i\\in[M/d]$ . ", "page_idx": 4}, {"type": "text", "text": "Discussion. We focus on analyzing how data heterogeneity affects the estimation error between the global forward gradient and the global true gradient. Specifically, the estimation error of SPRY depends on the coefficient \u03b1m,c =  |nDc| \u2212n|mD,cm\u03b1|c . In data homogeneous settings, where all clients share the same data distribution, the Dirichlet concentration parameter $\\alpha_{c}$ , is 1 for any class $c$ . As the ratio of $n_{c}/|\\mathcal{D}|$ (total samples in a class to total samples globally) matches the ratio of $n_{m,c}/|\\mathcal{D}_{m}|$ (total samples in a class to total samples for a client $m$ ), the bias term becomes 0 since $\\alpha_{m,c}=0,\\forall m,c$ . Hence, the global forward gradients are unbiased estimators of the true global gradients. In data heterogeneous settings, when data across clients becomes more heterogeneous, $\\alpha_{c}\\rightarrow0$ and thus $\\alpha_{m,c}\\to n_{c}/|\\mathcal{D}|$ , increasing the estimation error. Hence the global forward gradients are biased estimators that depend on the distances of the data distributions across participating clients. ", "page_idx": 4}, {"type": "text", "text": "Theorem 4.2 (Convergence Analysis). Under the assumptions on $L$ -smoothness (Asmp I.1), bounded global variance $\\sigma_{g}^{2}$ between global true gradients and aggregated expected gradients of each client (Asmp I.2), and bound on gradient magnitude $G$ (Asmp I.3); and the following conditions on the local learning rate \u03b7\u2113, ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\eta_{\\ell}=\\operatorname*{min}\\left\\{\\mathcal{O}\\left(\\frac{\\tau^{2}}{\\sqrt{\\beta_{2}}\\eta G L}\\right)^{\\frac{1}{2}},\\mathcal{O}\\left(\\frac{1}{\\sqrt{\\beta_{2}}G}\\right),\\mathcal{O}\\left(\\frac{\\tau^{3}}{\\sqrt{\\beta_{2}(1-\\beta_{2})}G^{2}}\\right)^{\\frac{1}{2}},}\\\\ &{}&{\\mathcal{O}\\left(\\frac{\\widetilde{M}K}{\\beta_{2}G(3d+K-1)\\sum_{m\\in[M]}\\sum_{c\\in[C]}\\alpha_{m,c}^{2}}\\right)\\right\\};}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The global true gradients of SPRY satisfies the following bound, ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{min}_{0\\le r\\le R}\\mathbb{E}_{r}||\\nabla f(w^{(r)})||^{2}\\le\\frac{f(w^{(0)})-\\mathbb{E}_{R}[f(w^{(R)})]}{\\eta R}}\\\\ &{\\qquad+\\left(2+\\frac{\\eta\\eta_{\\ell}L}{2\\tau^{2}}+\\frac{\\sqrt{1-\\beta_{2}}G\\eta_{\\ell}}{\\tau^{3}}\\right)\\left(\\frac{\\sigma_{g}^{2}(1-s)(3d+K-1)}{\\widetilde{M}K}\\right)\\sum_{m\\in\\mathcal{M}}\\sum_{c\\in[C]}\\alpha_{m,c}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $R$ is the total number of $F L$ rounds, $w\\,\\in\\,\\mathbb{R}^{d}$ are trainable weights, $\\boldsymbol{v}\\in\\mathbb{R}^{d}$ are random perturbation, $K$ is count of random perturbations per iteration, $\\eta$ is global learning rate, $\\tau$ is adaptability constant, and $s$ is client sampling rate. Rest of the symbols are defined in Theorem 4.1. ", "page_idx": 5}, {"type": "text", "text": "Discussion. We focus on analyzing how different configurations in SPRY affect its convergence. (a) The number of $F L$ rounds $(R)$ : The upper bounds of the norm of the global forward gradient in Eq. 6 decrease in proportion to the inverse of $R$ , indicating the convergence of the algorithm up to the limits of data heterogeneity. (b) Dimension of perturbations $(d)$ : $\\begin{array}{r}{\\eta_{\\ell}\\propto\\frac{1}{d}}\\end{array}$ shows that as the number of weights to be perturbed increases, the learning rate must decrease. A lower learning rate can make convergence slower, or worse, as our empirical experiments in Appendix $\\mathrm{G}$ will show, not converge at all. (c) The number of perturbations per iteration $(K)$ : We observe $K$ both in nominator and denominator, which indicates that increasing $K$ brings little advantage in convergence speed. Results in Appendix G confirm the above statement. (d) Data heterogeneity: $\\begin{array}{r}{\\eta_{\\ell}\\,\\propto\\,\\frac{1}{\\alpha_{m,c}^{2}}}\\end{array}$ shows that more homogeneous data distributions across clients allow higher learning rate, and hence faster error reduction. This observation is corroborated by the comparison of convergence speeds between homogeneous and heterogeneous clients in Appendix H. (e) The number of clients training same subset of weights: $\\eta_{\\ell}\\propto\\widetilde{M}$ shows that more clients training the same subset of weights is beneficial for faster convergence, similar observation is shown in Appendix G. ", "page_idx": 5}, {"type": "text", "text": "The theorem also sheds light on the accuracy performance gap between Forward-mode AD and backpropagation in $\\mathrm{FL}$ settings. The upper bounds on the global forward gradient norm includes a second term that increases with $\\alpha_{m,c}^{2}$ and variance $\\sigma_{g}^{2}$ , but does not decrease with $R$ . This results in a gap between estimation errors of backpropagation-based methods like FEDAVG and SPRY. ", "page_idx": 5}, {"type": "text", "text": "5 Empirical Evaluation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We empirically evaluate SPRY on 8 language tasks, 5 medium, and 3 large language models, under various FL settings. Our evaluation measures SPRY\u2019s prediction performance, peak memory consumption, and time-to-convergence. We also ablate SPRY\u2019s components to study the impact of communication frequency, the number of trainable parameters, the number of perturbations per iteration, the number of participating clients, and the importance of splitting layers on performance. ", "page_idx": 5}, {"type": "text", "text": "Datasets, Tasks, and Models. Our evaluation uses 8 datasets: AG News [31] (4-class classification), SST2 [32] (2-class classification), Yelp [31] (2-class classification), Yahoo [31] (10-class classification), SNLI [33] (3-class classification), MNLI [34] (3-class classification), SQuADv2 [35] (Closed-book question answering), and MultiRC [36] (2-class classification). We chose these datasets because they allow us to generate heterogeneous splits in FL settings using Dirichlet distribution [37]. The default dataset split is across 1,000 clients, except the smallest datasets SST2 and MultiRC, where there are 100 clients. SQuADv2 has 500 total clients. Each dataset has two versions: (i) Dirichlet $\\alpha=1.0$ (Homogeneous split), and (ii) Dirichlet $\\alpha=0.1$ (Heterogeneous split). ", "page_idx": 5}, {"type": "text", "text": "Our evaluation uses the following language models: OPT13B [38], Llama2-7B [21], OPT6.7B [38], RoBERTa Large (355M) [39], BERT Large (336M) [40], BERT Base (110M) [40], DistilBERT Base (67M) [41], and Albert Large V2 (17.9M) [42]. For the billion-sized models, we use 4-bit quantization. For all the models, we use LORA as the PEFT method. Appendix B describes the datasets and hyperparameters in more detail. ", "page_idx": 5}, {"type": "table", "img_path": "dGQtja9X2C/tmp/d3b6a7b7fa9aae23dc7b75495418c83564adfd394484ef60e1bd31b507b370d9.jpg", "table_caption": ["on RoBERTa Large and LLMs. SQuADv2 uses F1 score. $\\uparrow$ shows that higher values are better. The datasets are split with Dir $\\alpha=0.1$ . $\\diamondsuit=$ Llama2-7B. $\\star=\\mathrm{OPT}6.7\\mathrm{B}$ . $\\boxed{\\bigstar}=\\mathrm{OPT}13\\mathbf{B}$ . SPRY outperforms the best-performing zero-order-based methods by $5.15{-}13.50\\%$ and approaches the performance of backpropagation-based methods, with a difference of $0.60{-}6.16\\%$ . "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "Comparison Counterparts and Metrics. We compare SPRY to (a) Backpropagation-based federated optimizers FEDAVG [1], FEDYOGI [25], FEDSGD (Variant of FEDAVG with per-iteration communication) [1], (b) Zero-order federated methods FEDMEZO (federated version of MEZO [18]), BAFFLE [20], FWDLLM [19], all based on finite difference. MEZO uses prompt-based finetuning to improve the performance of finite differences. FWDLLM generates a random perturbation that has a high cosine similarity to the global gradients of the previous rounds. BAFFLE generates $\\sim\\!100{-}500$ perturbations per iteration. More details of these methods are in Appendix A. The original implementations of FWDLLM and BAFFLE had excessive memory usage in their implementations. We improve their codebase to be memory-efficient by perturbing only the trainable weights, similar to SPRY. We refer to our implementation as FWDLLM $^+$ and BAFFLE+. ", "page_idx": 6}, {"type": "text", "text": "Evaluation of SPRY and its counterparts for classification tasks is on generalized accuracy $A c c_{g}$ and personalized accuracy $A c c_{p}$ , which are metrics measured on server-side aggregated model and client-side locally updated model, respectively. Similarly, for question-answering tasks, we measure Exact Matches and F1 Score. We also measure time to convergence and peak memory consumption during training. Our convergence criterion is the absence of change in the variance of a performance metric, assessed at intervals of 50 rounds. ", "page_idx": 6}, {"type": "text", "text": "SPRY is implemented in Flower [43] library. Quantization is done using AutoGPTQ [44]. For the zero-order methods, we used their respective client-side implementations with the server simulation structure of Flower. We utilized two Nvidia 1080ti to conduct all experiments of sub-billion sized models and billion-sized models for SPRY and its zero-order methods. We used two RTX8000s and two A100s for Llama2-7B and OPT models on backpropagation-based methods respectively. Each experiment was run thrice with 0, 1, and 2 as seeds. ", "page_idx": 6}, {"type": "text", "text": "5.1 Accuracy Performance Comparison ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Table 1 reports the accuracy performance of SPRY and its backpropagation- and zero-order-based counterparts on heterogeneous datasets for million-sized RoBERTa Large, and billion-sized Llama2- 7B, OPT6.7B, and OPT13B. Similar results on personalized performance is shown in Appendix H, Figure 5. Results on MultiRC for FEDMEZO are absent since the prompt-based finetuning variant of Llama2-7B was unavailable. Results on more model architectures and dataset combinations are available in Appendix G. Details on the learning curves, homogeneous dataset splits, and variance across 3 runs are in Appendix H. ", "page_idx": 6}, {"type": "text", "text": "Overall, SPRY achieves $5.15{-}13.50\\%$ higher generalized accuracy and $4.87{-}12.79\\%$ higher personalized accuracy over the best-performing zero-order-based methods across all datasets. FWDLL $M+$ , the best-performing zero-order counterpart, attempts to reduce the effect of numeric instability of finite differences by (a) Sampling $K$ perturbations (default $K=10$ ) per batch for each client and picking 1 perturbation per batch that has the highest cosine similarity with the previous round\u2019s aggregated gradients and (b) Only picking trained weights from clients whose computed gradients have variance lower than a set threshold. However, we posit that this strategy leads to some clients getting excluded due to a low variance threshold or outlying clients getting included due to a high variance threshold. Besides, picking new perturbations based on the previous round\u2019s aggregated gradients in the initial rounds can damage the learning trajectory. While BAFFLE+ samples more perturbation for each batch to make zero-order finite differences more tractable, the scale of language models demands perturbations on the scale of 500-1000 per batch, which becomes computationally infeasible. FEDMEZO manages to outperform BAFFLE $^{+}$ due to its prompt-based finetuning trick but still falls short due to only using 1 perturbation per batch for finite differences on each client. In contrast, Forward-mode AD used in SPRY avoids the numerical instability from finite differences and improves accuracy by reducing trainable weights assigned to each client. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Compared to backpropagation-based methods, FEDAVG and FEDYOGI, SPRY manages to come as close as $0.60{-}6.16\\%$ of generalized accuracy and $2.50{-}14.12\\%$ of personalized accuracy. The performance gap between backpropagation and Forward-mode AD arises because in backpropagation, weight updates are more accurate as all gradients are computed directly using the error signal of the objective function. In contrast, Forward-mode AD relies on random perturbations, which is relatively less accurate for gradient estimation. Nonetheless, the advantages of SPRY become evident when we see the peak memory consumption of Forward-more AD compared to backpropagation, which we will discuss next. ", "page_idx": 7}, {"type": "text", "text": "5.2 Peak Memory Consumption Comparison ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Figure 2 shows peak memory consumption of backpropagation (used in FEDAVG, FEDYOGI), zero-order finite differences (used in FWDLLM+, BAFFLE $^+$ , FEDMEZO), and firstorder forward mode AD (used in SPRY). The methods are profiled for a single client. ", "page_idx": 7}, {"type": "text", "text": "Compared to backpropagation, Forward-mode AD reduces peak memory usage of RoBERTa Large by $27.90\\%$ , Llama2-7B by $81.73\\%$ , OPT6.7B by $86.26\\%$ and OPT13B by $85.93\\%$ . The sizes of trainable parameter (colored $\\bigcirc_{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!$ ) and gradient $^+$ optimizer state (colored $\\bigcirc,$ ) are consistent across the 3 modes of computing gradients for all 4 models. Hence the savings come from the reduced memory footprint related to activations (colored $\\bigcirc$ in Forward-mode AD. Compared to backpropagation-based methods, the memory cost related to activations is decreased by $12.12\u201349.25\\times$ in SPRY. Unlike storing all the intermediate activations in backpropagation, Forward-mode AD only has to store the previous layer\u2019s activation in a forward pass. The activation footprint of Forward-mode AD is equal to the size of the largest activation. ", "page_idx": 7}, {"type": "image", "img_path": "dGQtja9X2C/tmp/7abbc9a77d8df6dd2cd7490d9148de56fdc25266d76007870189e58f301e1c67.jpg", "img_caption": ["Figure 2: Peak memory consumption of SPRY\u2019s Forward-mode AD versus backpropgation- and zero-order-based methods. RoBERTa Large, Llama2-7B, and $\\mathrm{OPT}6.7\\mathrm{B}$ are profiled with a batch size of 8, and OPT13B with a batch size of 4. SPRY reduces total memory usage by $27.90{-}86.26\\%$ compared to backpropagationbased methods. The $1.54\u20131.96\\times$ additional memory SPRY uses, compared to zero-order-based methods, is offset by the accuracy gains $(\\S\\ S.1)$ . "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Against zero-order methods, Forward-mode AD activations cost $1.96\\times$ , $1.95\\times$ , $1.83\\times$ , and $1.54\\times$ more for RoBERTa Large, Llama2-7B, OPT6.7B, and OPT13B respectively. The increasing cost comes from parallel evaluations of (a) the objective function on the original weights and (b) $\\mathtt{j v p}$ computation on the perturbations in a single forward pass. However, as discussed in $\\S\\ 5.1$ , the increased memory cost is offset by a boost of up to $13.50\\%$ in accuracy performance. And as $\\S\\ 5.3$ will discuss, Forward-mode AD reaches convergence faster than zero-order methods since it takes fewer steps to compute a closer gradient estimation. ", "page_idx": 7}, {"type": "text", "text": "5.3 Time to Convergence Comparison ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Figure 3 shows wallclock time-to-convergence for SPRY and its counterparts. We observe that SPRY is $1.15\\!-\\!1.59\\!\\times$ , $6.16{-}20.28\\times$ , and $1.34{-}2.98\\times$ faster than the zero-order methods FWDLLM $^+$ , $\\scriptstyle\\mathrm{BAFFLE+}$ , and FEDMEZO respectively. For a client in each round, SPRY achieves a faster per-round computation time of $1.46\\times$ , $28.57\\times$ , and $1.80\\times$ on average, against FWDLLM $^+$ , BAFFLE $^{+}$ , and FEDMEZO. Forward-mode AD achieves faster convergence and faster per-round computation by providing a more accurate gradient estimation through a single perturbation per batch, leading to fewer steps needed to reach convergence. Since each client in SPRY only trains partial weights, it gains a speedup of $1.14\\times$ over backpropagation-based FEDAVG, FEDYOGI, and FEDSGD for RoBERTa Large. However, compared to the backpropagation-based methods, SPRY slows down for billion-sized LMs. We attribute this loss of speedup to the way jvp is computed in Forward-mode AD. jvp is computed column-wise, while its counterpart vjp in backpropagation are computed row-wise. The column-wise computation incurs time overhead. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "5.4 Ablation Studies ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We summarize the ablation experiments on various components of SPRY. Further discussions are in Appendix G. ", "page_idx": 8}, {"type": "text", "text": "SPRY can generalize to other language model architectures. Similar to the observations from Table 1, we see a trend of SPRY outperforming the best performing zeroorder method FWDLLM $^+$ by $3.15\\!-\\!10.25\\%$ for generalized accuracy, demonstrating that SPRY can generalize to other language model architectures. ", "page_idx": 8}, {"type": "text", "text": "SPRY is compatible with other PEFT methods. We integrate SPRY with different PEFT methods like IA3, BITFIT, and CLASSIFIER-ONLY FINETUNING. Results shows that LORA with SPRY performs the best, with accuracy improvements of $10.60\u201316.53\\%$ . ", "page_idx": 8}, {"type": "text", "text": "Effects of the number of trainable weights. We change the number of trainable weights by controlling the rank $r$ and scale $\\alpha$ hyperparameters in LORA. Results show that SPRY achieves the highest accuracy with $(r{=}1,\\,\\alpha{=}1)$ setting, which has the smallest trainable weight count. The result is consistent with our theoretical analysis in $\\S4$ . ", "page_idx": 8}, {"type": "text", "text": "Effects of communication frequency. Per-iteration communication in SPRY has been shown to boost accuracy by $4.47\\%$ compared to per-epoch communication. This improvement brings the accuracy within $0.92\\%$ and $0.96\\%$ of FEDAVG and FEDSGD, respectively. ", "page_idx": 8}, {"type": "image", "img_path": "dGQtja9X2C/tmp/8e06f79b257b3b2fee0a2d4410c6eebe0d2ea97ec1e005dcad3831fc2e0253fc.jpg", "img_caption": ["Figure 3: Time to convergence for SPRY and its counterparts. SPRY achieves faster convergence than zero-order methods due to more accurate gradient estimations in a single perturbation. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Effects of perturbation count per batch. We observe that increasing the number of perturbations per batch $(K)$ for Forward-mode AD has little to no impact on the end prediction performance of SPRY, with $K=100$ improving the generalized test accuracy by $1.1\\%$ over $K=1$ . The beneftis of increasing $K$ are however seen in the convergence speed. Setting $K=10$ achieves a steady state (of accuracy ${\\sim}86\\%$ ) around the $200^{\\mathrm{th}}$ round, while the setting with $K=1$ takes 500 rounds. ", "page_idx": 8}, {"type": "text", "text": "Effects of participating client count. Increasing the client count increases the prediction performance of SPRY. For the SST2 dataset, with the total client count fixed to 100, the three settings $C=10$ , $C=50$ , and $C=100$ produce accuracies of $85.14\\%$ , $86.56\\%$ , and $88.08\\%$ , respectively. We also see an improvement in the convergence speed as the participating client count increases. To achieve an accuracy of ${\\sim}85\\%$ ; $C=10$ , $C=50$ , $C=100$ require 500, 450, and 150 rounds, respectively. ", "page_idx": 8}, {"type": "text", "text": "Importance of splitting weights. To understand the effects of splitting, we conduct the following two experiments: (a) With FEDAVGSPLIT, we apply the strategy of splitting trainable layers across clients (see $\\S\\,3.1\\rangle$ to backpropagation-based FEDAVG, and (b) With FEDFGD, we omit the splitting strategy of SPRY for FL with Forward-mode AD. We observe that FEDAVGSPLIT fails to achieve similar accuracy to FEDAVG with a drop of $2.60\u201310.00\\%$ . FEDFGD fails to converge as the size of trainable weights increases, e.g., with RoBERTa Large with LORA, that has 1.15M trainable weights. This proves the necessity of splitting trainable weights for Forward-mode AD in SPRY. ", "page_idx": 8}, {"type": "text", "text": "5.5 Communication and Computation Costs ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Tables 2 and 3 in Appendix F shows the communication and computation overhead of SPRY against all its baselines. We summarize the main observations here: ", "page_idx": 8}, {"type": "text", "text": "SPRY has lower communication cost due to the splitting strategy and scalar jvp. Suppose $w_{g}$ is the total trainable parameter count of a model to be trained in federated setting. The backpropagation-based baselines; FEDAVG (per-epoch communication), FEDSGD (per-iteration communication), and FEDYOGI (per-epoch communication) transmit the entire set of trainable parameters to each participating client, and receives the same from each participating client. That results in \u201cclient to server\u201d communication cost of $w_{g}$ and \u201cserver to client\u201d communication cost of $w_{g}\\times M$ . The per-epoch versions of the zero-order baselines (FEDMEZO, BAFFLE, FWDLLM) follow a similar logic due to all the parameters needing to be transmitted to each client, with \u201cclient to server\u201d communication costing $w_{g}$ , and \u201cserver to client\u201d communication taking the cost of $w_{g}\\times M$ . However, the per-iteration versions of the zero-order baselines fare better, with \u201cclient to server\u201d communication only requiring each client sending a scalar finite difference (cost of 1), and \u201cserver to client\u201d communication accruing $(w_{g}+1)\\times M$ cost, due to the server also needing to send a scalar seed to each client now. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Meanwhile, SPRY only needs to send max $\\textstyle\\left({\\frac{L}{M}},1\\right)$ layers (where $L$ is the total layer count of a model, and $M$ is the participating count of clients for a round), each layer of size $w_{\\ell}$ . Hence, for per-epoch \u201cclient to server\u201d communication accrues $w_{\\ell}$ max $\\textstyle\\left({\\frac{L}{M}},1\\right)$ , which is smaller than $w_{g}$ . Similarly, perepoch \u201cserver to client\u201d communication costs $\\begin{array}{r}{w_{\\ell}M\\operatorname*{max}\\left(\\frac{L}{M},1\\right)}\\end{array}$ , which is also smaller than the cost of $w_{g}M$ related to the baselines. For per-iteration communication, clients only need to send a scalar $\\mathtt{j v p}$ (cost of 1) to the server; this matches the communication cost of per-iteration zero-order methods. Server needs to send a total of $w_{\\ell}M\\operatorname*{max}(L,M)$ (derivation given in Table 2), which is a smaller cost than the costs of backpropagation and zero-order methods. ", "page_idx": 9}, {"type": "text", "text": "SPRY accrues lower computation cost due to lower trainable parameter count. SPRY\u2019s clientside computation cost is traded off by a faster convergence to higher accuracy through better gradient approximations compared to finite difference-based methods. And SPRY is the least computationally expensive on the server side due to needing to aggregate fewer parameters from the clients. ", "page_idx": 9}, {"type": "text", "text": "Let\u2019s assume that matrix multiplication costs $c$ for each layer, resulting in a forward pass cost of $c$ . The cost of backpropagation is $2c$ because the computation of the current layer\u2019s weight gradient is $c$ , and the cost of computing the previous layer\u2019s activation gradient is another $c$ . jvp computation in SPRY takes additional cost of $c$ for each layer. Moreover, since $\\mathtt{j v p}$ calculation happens through column-by-column vector multiplications, the related overhead is quantified by $v$ . ", "page_idx": 9}, {"type": "text", "text": "Hence backpropagation-based methods FEDAVG, FEDSGD, and FEDYOGI computationally costs $3L c$ at client, and costs $w_{g}(M-1)$ at server (due to additions). Note that $L$ amounts to all layers in the model here. FEDMEZO costs ${L}(2c+3w_{\\ell})$ at client through two forward passes, and generating perturbations three times. FWDLLM and BAFFLE costs $K\\bar{L(}2c+w_{\\ell})$ due to $K$ perturbations for all $L$ layers, with two forward passes and generation perturbations once. Against that, SPRY costs $\\begin{array}{r}{2\\operatorname*{max}(\\frac{\\mathbf{\\bar{\\alpha}}_{L}}{M},1)(c+v)+w_{\\ell}L}\\end{array}$ for a smaller count of $L$ , traded-off by the $\\mathtt{j v p}$ computation cost of $v$ . ", "page_idx": 9}, {"type": "text", "text": "On the server side, SPRY is the least computationally demanding. SPRY needs to aggregate a subset of layer weights from only the clients that were assigned to those layers. Computation cost on the server-side changes based on the communication frequency per-iteration communication incurs an additional overhead of $\\begin{array}{r}{w_{\\ell}L(\\frac{M}{L}+1)}\\end{array}$ and $w_{\\ell}L(M+1)$ (generation of perturbations at the server-side, and multiplying those perturbations with aggregate of the $\\mathtt{j v p}$ values received from the clients) for SPRY and its zero-order counterparts respectively. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "SPRY enables finetuning medium and large language models in cross-device FL. It introduces a training strategy where trainable weights are split across federated clients, so each client only applies Forward-mode AD to a fraction of the weights. This approach significantly reduces the memory footprint compared to backpropagation and achieves better gradient estimation, resulting in higher accuracy and faster convergence than zero-order methods. Experiments on various language tasks and models demonstrate SPRY\u2019s effectiveness in reducing memory usage while maintaining accuracy comparable to backpropagation. We formally prove that the estimation bias of the global forward gradients in SPRY depends on data heterogeneity across clients. We also analyzed how the convergence rate of SPRY relates to the configurations of SPRY and FL settings including properties of weight perturbations, data heterogeneity, and the number of clients and FL rounds. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This material is based upon work supported by the National Science Foundation under grant no.   \nCCF-2210243, DMS-2220211, CNS-2224054, CNS-2312396, and CNS-2338512, and by Adobe. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-Efficient Learning of Deep Networks from Decentralized Data. In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, Proceedings of Machine Learning Research. PMLR, 2017. ", "page_idx": 10}, {"type": "text", "text": "[2] Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aur\u00e9lien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista A. Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, Rafael G. L. D\u2019Oliveira, Hubert Eichner, Salim El Rouayheb, David Evans, Josh Gardner, Zachary Garrett, Adri\u00e0 Gasc\u00f3n, Badih Ghazi, Phillip B. Gibbons, Marco Gruteser, Za\u00efd Harchaoui, Chaoyang He, Lie He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi, Gauri Joshi, Mikhail Khodak, Jakub Konecn\u00fd, Aleksandra Korolova, Farinaz Koushanfar, Sanmi Koyejo, Tancr\u00e8de Lepoint, Yang Liu, Prateek Mittal, Mehryar Mohri, Richard Nock, Ayfer \u00d6zg\u00fcr, Rasmus Pagh, Hang Qi, Daniel Ramage, Ramesh Raskar, Mariana Raykova, Dawn Song, Weikang Song, Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian Tram\u00e8r, Praneeth Vepakomma, Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang, Felix X. Yu, Han Yu, and Sen Zhao. Advances and open problems in federated learning. Foundations and Trends in Machine Learning, 2021. ", "page_idx": 10}, {"type": "text", "text": "[3] Tyler J Loftus, Matthew M Ruppert, Benjamin Shickel, Tezcan Ozrazgat-Baslanti, Jeremy A Balch, Philip A Efron, Jr. Gilbert R Upchurch, Parisa Rashidi, Christopher Tignanelli, Jiang Bian, and Azra Bihorac. Federated learning for preserving data privacy in collaborative healthcare research. Digital Health, 2022. ", "page_idx": 10}, {"type": "text", "text": "[4] Li Li, Xi Yu, Xuliang Cai, Xin He, and Yanhong Liu. Contract theory based incentive mechanism for federated learning in health crowdsensing. IEEE Internet of Things Journal, 2022. ", "page_idx": 10}, {"type": "text", "text": "[5] Suresh Dara, Ambedkar Kanapala, A. Ramesh Babu, Swetha Dhamercherala, Ankit Vidyarthi, and Ruchi Agarwal. Scalable federated-learning and internet-of-things enabled architecture for chest computer tomography image classification. Computers and Electrical Engineering, 2022. ", "page_idx": 10}, {"type": "text", "text": "[6] Fabio Pinelli, Gabriele Tolomei, and Giovanni Trappolini. Flirt: Federated learning for information retrieval. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2023. ", "page_idx": 10}, {"type": "text", "text": "[7] OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Sim\u00f3n Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, \u0141ukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina Kim, Yongjik Kim, Jan Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, \u0141ukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David M\u00e9ly, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O\u2019Keefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbute Peres, Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish ", "page_idx": 10}, {"type": "text", "text": "Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine B. Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe Cer\u00f3n Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJ Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph. Gpt-4 technical report. arXiv 2303.08774, 2024. ", "page_idx": 11}, {"type": "text", "text": "[8] Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey, Yanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan Botha, James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng, Colin Cherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, Cl\u00e9ment Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark D\u00edaz, Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, Guy Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey Hui, Jeremy Hurwitz, Michael Isard, Abe Ittycheriah, Matthew Jagielski, Wenhao Jia, Kathleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric Ni, Andrew Nystrom, Alicia Parrish, Marie Pellat, Martin Polacek, Alex Polozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel, Renee Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng, Ce Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu. Palm 2 technical report. arXiv 2305.10403, 2023. ", "page_idx": 11}, {"type": "text", "text": "[9] Bill Yuchen Lin, Chaoyang He, Zihang Ze, Hulin Wang, Yufen Hua, Christophe Dupuy, Rahul Gupta, Mahdi Soltanolkotabi, Xiang Ren, and Salman Avestimehr. FedNLP: Benchmarking federated learning methods for natural language processing tasks. In Findings of the Association for Computational Linguistics: NAACL 2022. Association for Computational Linguistics, 2022. ", "page_idx": 11}, {"type": "text", "text": "[10] Yuanyishu Tian, Yao Wan, Lingjuan Lyu, Dezhong Yao, Hai Jin, and Lichao Sun. Fedbert: When federated learning meets pre-training. ACM Transactions on Intelligent Systems and Technology (TIST), 2022.   \n[11] Alexander Borzunov, Max Ryabinin, Artem Chumachenko, Dmitry Baranchuk, Tim Dettmers, Younes Belkada, Pavel Samygin, and Colin A Raffel. Distributed inference and fine-tuning of large language models over the internet. Advances in Neural Information Processing Systems, 2024.   \n[12] Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations, 2022.   \n[13] Dongqi Cai, Yaozong Wu, Shangguang Wang, and Mengwei Xu. Fedadapter: Efficient federated learning for mobile nlp. In Proceedings of the ACM Turing Award Celebration Conference - China 2023. Association for Computing Machinery, 2023.   \n[14] Zeju Qiu, Weiyang Liu, Haiwen Feng, Yuxuan Xue, Yao Feng, Zhen Liu, Dan Zhang, Adrian Weller, and Bernhard Sch\u00f6lkopf. Controlling text-to-image diffusion by orthogonal finetuning. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[15] Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, and Colin A Raffel. Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning. In Advances in Neural Information Processing Systems, 2022.   \n[16] Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). Association for Computational Linguistics, 2021.   \n[17] Benoit Jacob, Skirmantas Kligys, Bo Chen, Menglong Zhu, Matthew Tang, Andrew Howard, Hartwig Adam, and Dmitry Kalenichenko. Quantization and training of neural networks for efficient integerarithmetic-only inference. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.   \n[18] Sadhika Malladi, Tianyu Gao, Eshaan Nichani, Alex Damian, Jason D. Lee, Danqi Chen, and Sanjeev Arora. Fine-tuning language models with just forward passes. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[19] Mengwei Xu, Dongqi Cai, Yaozong Wu, Xiang Li, and Shangguang Wang. Fwdllm: Efficient fedllm using forward gradient. arXiv 2308.13894, 2024.   \n[20] Haozhe Feng, Tianyu Pang, Chao Du, Wei Chen, Shuicheng Yan, and Min Lin. Does federated learning really need backpropagation? arXiv 2301.12195, 2023.   \n[21] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned chat models. arXiv 2307.09288, 2023.   \n[22] C. H. Richardson. An introduction to the calculus of finite differences. by c.h. richardson pp. vi, 142. 28s. 1954. (van nostrand, new york; macmillan, london). The Mathematical Gazette, 39(330), 1955. doi: 10.2307/3608616.   \n[23] At\u0131l\u0131m G\u00fcne\u00b8s Baydin, Barak A. Pearlmutter, Don Syme, Frank Wood, and Philip Torr. Gradients without backpropagation. arXiv 2202.08587, 2022.   \n[24] At\u0131l\u0131m G\u00fcnes Baydin, Barak A. Pearlmutter, Alexey Andreyevich Radul, and Jeffrey Mark Siskind. Automatic differentiation in machine learning: a survey. The Journal of Machine Learning Research, 2017.   \n[25] Sashank J. Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konec\u02c7n\u00fd, Sanjiv Kumar, and Hugh Brendan McMahan. Adaptive federated optimization. In International Conference on Learning Representations, 2021.   \n[26] Chandra Thapa, Pathum Chamikara Mahawaga Arachchige, Seyit Camtepe, and Lichao Sun. Splitfed: When federated learning meets split learning. In Proceedings of the AAAI Conference on Artificial Intelligence, 2022.   \n[27] Renrui Zhang, Jiaming Han, Chris Liu, Aojun Zhou, Pan Lu, Hongsheng Li, Peng Gao, and Yu Qiao. LLaMA-adapter: Efficient fine-tuning of large language models with zero-initialized attention. In The Twelfth International Conference on Learning Representations, 2024.   \n[28] Elad Ben Zaken, Yoav Goldberg, and Shauli Ravfogel. BitFit: Simple parameter-efficient fine-tuning for transformer-based masked language-models. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Association for Computational Linguistics, 2022.   \n[29] Kunjal Panchal, Sunav Choudhary, Subrata Mitra, Koyel Mukherjee, Somdeb Sarkhel, Saayan Mitra, and Hui Guan. Flash: concept drift adaptation in federated learning. In International Conference on Machine Learning, pages 26931\u201326962. PMLR, 2023.   \n[30] Shanshan Wu, Tian Li, Zachary Charles, Yu Xiao, Ziyu Liu, Zheng Xu, and Virginia Smith. Motley: Benchmarking heterogeneity and personalization in federated learning. arXiv 2206.09262, 2022.   \n[31] Xiang Zhang, Junbo Jake Zhao, and Yann LeCun. Character-level convolutional networks for text classification. In Neural Information Processing Systems, 2015. Available at https: //huggingface.co/datasets/ag_news, https://huggingface.co/datasets/yelp_polarity, https://huggingface.co/datasets/yahoo_answers_topics, Accessed on 15 May, 2024.   \n[32] Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew $\\mathrm{Ng}$ , and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2013. Available at https://huggingface.co/datasets/stanfordnlp/sst2, Accessed on 15 May, 2024.   \n[33] Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2015. Available at https://huggingface.co/datasets/stanfordnlp/snli, Accessed on 15 May, 2024.   \n[34] Adina Williams, Nikita Nangia, and Samuel Bowman. A broad-coverage challenge corpus for sentence understanding through inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). Association for Computational Linguistics, 2018. Available at https://huggingface.co/datasets/ SetFit/mnli, Accessed on 15 May, 2024.   \n[35] Pranav Rajpurkar, Robin Jia, and Percy Liang. Know what you don\u2019t know: Unanswerable questions for SQuAD. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Association for Computational Linguistics, 2018. Available at https:// huggingface.co/datasets/rajpurkar/squad_v2, Accessed on 15 May, 2024.   \n[36] Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, and Dan Roth. Looking beyond the surface: A challenge set for reading comprehension over multiple sentences. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). Association for Computational Linguistics, 2018. Available at https://huggingface.co/datasets/mtc/multirc, Accessed on 15 May, 2024.   \n[37] Kunjal Panchal, Sunav Choudhary, Nisarg Parikh, Lijun Zhang, and Hui Guan. Flow: Per-instance personalized federated learning. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[38] Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang, and Luke Zettlemoyer. Opt: Open pre-trained transformer language models. arXiv 2205.01068, 2022.   \n[39] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized BERT pretraining approach. arxiv 1907.11692, 2019.   \n[40] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirectional transformers for language understanding. arXiv 1810.04805, 2018.   \n[41] Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter. arXiv 1910.01108, 2019.   \n[42] Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. ALBERT: A lite BERT for self-supervised learning of language representations. arXiv 1909.11942, 2019.   \n[43] Daniel J Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Titouan Parcollet, and Nicholas D Lane. Flower: A friendly federated learning research framework. arXiv preprint 2007.14390, 2020.   \n[44] AutoGPTQ, 2024. URL https://github.com/AutoGPTQ/AutoGPTQ.   \n[45] Richard L. Burden and J. Douglas. Faires. Numerical analysis / Richard L. Burden, J. Douglas Faires. Thomson Brooks/Cole, 8th ed. edition, 2005. ISBN 0534392008.   \n[46] K\u00e1roly Jord\u00e1n. Calculus of finite differences. American Mathematical Soc., 1965.   \n[47] Wenzhi Fang, Ziyi Yu, Yuning Jiang, Yuanming Shi, Colin N. Jones, and Yong Zhou. Communicationefficient stochastic zeroth-order optimization for federated learning. IEEE Transactions on Signal Processing, 2022.   \n[48] Rui Ye, Wenhao Wang, Jingyi Chai, Dihan Li, Zexi Li, Yinda Xu, Yaxin Du, Yanfeng Wang, and Siheng Chen. Openfedllm: Training large language models on decentralized private data via federated learning. arXiv 2402.06954, 2024.   \n[49] Tao Fan, Yan Kang, Guoqiang Ma, Weijing Chen, Wenbin Wei, Lixin Fan, and Qiang Yang. Fate-llm: A industrial grade federated learning framework for large language models. arXiv 2310.10049, 2023.   \n[50] Fan Lai, Yinwei Dai, Sanjay S. Singapuram, Jiachen Liu, Xiangfeng Zhu, Harsha V. Madhyastha, and Mosharaf Chowdhury. Fedscale: Benchmarking model and system performance of federated learning at scale. arXiv 2105.11367, 2022.   \n[51] Jae Ro, Theresa Breiner, Lara McConnaughey, Mingqing Chen, Ananda Suresh, Shankar Kumar, and Rajiv Mathews. Scaling language model size in cross-device federated learning. In Proceedings of the First Workshop on Federated Learning for Natural Language Processing (FL4NLP 2022). Association for Computational Linguistics, 2022.   \n[52] Shubham Malaviya, Manish Shukla, and Sachin Lodha. Reducing communication overhead in federated learning for pre-trained language models using parameter-efficient finetuning. In Conference on Lifelong Learning Agents. PMLR, 2023.   \n[53] Zhuo Zhang, Yuanhang Yang, Yong Dai, Qifan Wang, Yue Yu, Lizhen Qu, and Zenglin Xu. FedPETuning: When federated learning meets the parameter-efficient tuning methods of pre-trained language models. In Findings of the Association for Computational Linguistics: ACL 2023. Association for Computational Linguistics, 2023.   \n[54] Seonghwan Park, Dahun Shin, Jinseok Chung, and Namhoon Lee. Fedfwd: Federated learning without backpropagation. arXiv 2309.01150, 2023.   \n[55] Geoffrey Hinton. The forward-forward algorithm: Some preliminary investigations. arXiv 2212.13345, 2022.   \n[56] Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et al. Parameter-efficient fine-tuning of large-scale pre-trained language models. Nature Machine Intelligence, 2023.   \n[57] Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, and Sai Qian Zhang. Parameter-efficient fine-tuning for large models: A comprehensive survey. arXiv 2403.14608, 2024.   \n[58] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. QLoRA: Efficient finetuning of quantized LLMs. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "A Related Work ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "SPRY uses first-order forward gradients for federated finetuning of language models. Hence, we review the literature on estimating gradients with low memory consumption and show how SPRY represents a significant advancement in finetuning language models in FL. ", "page_idx": 15}, {"type": "text", "text": "Zero-order Gradients. Gradients derived from finite difference [45, 22, 46] methods are called zero-order gradients since they don\u2019t involve Taylor expansion of the objective function $f$ . MEZO [18] has shown that finite difference with one perturbation per batch does not reach convergence on its own without additional tricks like prompt-based finetuning, which are highly specific to the tasks. For a more accurate gradient approximation, an average of zero-order gradients derived from multiple $_{\\sim10}$ to 100) random perturbations on the same input batch is required [24], leading to slow convergence. BAFFLE [20] and FEDZO [47] utilize zero-order gradients in federated settings. To train vision models (of parameter count $\\leq13\\mathrm{M},$ , BAFFLE requires (a) ${\\sim}100{-}500$ perturbations per batch for each client respectively, and (b) per-iteration communication among clients like FEDSGD [1]. FEDZO also requires ${\\sim}20$ perturbations per batch for a vision model of size $\\leq25\\mathrm{{M}}$ . Besides, numerical errors associated with finite difference make MEZO, BAFFLE, and FEDZO suffer from sub-optimal predictions compared to backpropagation-based counterparts. SPRY, using Forward-mode AD, computes gradients more accurately in a single forward pass compared to averaged gradients obtained through finite difference methods. This higher accuracy is achieved without needing modifications to model architectures or task structures, while also maintaining a memory footprint similar to that of finite difference methods. ", "page_idx": 15}, {"type": "text", "text": "First-order Forward Gradients. Gradients derived from Forward-mode Auto-Differentiation (AD) are considered first-order since it involves computing partial derivatives of the intermediate activations with respect to the input. We guide interested readers to the survey on different modes of automatic differentiation [24]. FGD [23] shows preliminary results on the speedup and comparable accuracy achieved by Forward-mode AD against backpropagation. The challenge that makes Forward-mode AD less popular than backpropagation is that gradients derived from forward mode require more jvp column-by-column evaluations per input batch as the number of trainable weights increases. Moreover, evaluation of FGD is limited to a multi-layer perceptron of size $d\\approx\\!1.8\\mathrm{M}$ . Direct use of FGD to finetune language models leads to slow or no convergence. SPRY splits the trainable layers of a large language model across multiple clients in FL, letting each client finetune only a small subset of weights through forward gradients. ", "page_idx": 15}, {"type": "text", "text": "Training or Finetuning Language Models in Federated Learning. In recent years, several frameworks have been proposed to train or finetune LLMs in FL [48\u201350]. The backpropagation-based methods [10, 51], even with parameter efficient finetuning (PEFT) and quantization [13, 52, 53], have large memory footprints due to the overhead related to activations, gradients, and gradient history storage for adaptive optimizers [18]. ", "page_idx": 15}, {"type": "text", "text": "FEDFWD [54] applies FWDFWD [55] (which measures \u201cgoodness\u201d of forward pass activations to judge which perturbations are useful) in FL, but FWDFWD struggles as model size scales up. FWDLLM uses zero-order gradients to finetune language models. It samples ${\\sim}10$ perturbations per batch. For each batch, it picks 1 perturbation that has the highest cosine similarity with the previous round\u2019s gradients. Sampling new perturbations based on aggregated gradients from previous rounds during the initial stages can disrupt the learning trajectory. SPRY requires 1 perturbation (without resampling) per batch to reach a higher prediction performance faster than FWDLLM. ", "page_idx": 15}, {"type": "text", "text": "B Datasets and Hyperparameters ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Here we provide details of the datasets and their corresponding training hyperparameters used in this work. ", "page_idx": 16}, {"type": "text", "text": "Simulating Heterogeneity through Dirichlet Distribution. For each of the tasks, the class distribution each client gets depends on the Dirichlet distribution, where a parameter $\\alpha$ regulates the concentration of samples of a particular class for a specific client. Dir $\\alpha=1.0$ means all clients have homogeneous datasets where each class is equally likely to be on each client. With Dir $\\alpha\\rightarrow0$ , the datasets of each client get more heterogeneous, where the sample distribution of each class is more likely to be concentrated on only a subset of clients. ", "page_idx": 16}, {"type": "text", "text": "Default Hyperparameters. Unless otherwise mentioned in dataset-specific paragraphs, the default hyperparameters for each method and for all datasets are stated here. For the backpropagation-based methods FEDAVG, FEDYOGI, and FEDSGD; we will fix the number of epochs to 1 since the goal of this work is to inch closer to backpropagation-like prediction performance while reducing the memory footprint. All the experiments have been run for $1500\\,\\mathrm{{FL}}$ rounds, except the experiments on OPT models, which are run for $600\\;\\mathrm{FL}$ rounds. Our observation from hyperparameter-tuning shows that the learning rate that gives the best performance is the same for all studied methods. BAFFLE and its memory-efficient improvement BAFFL $\\cdot{\\mathrm{E}}+$ made by us, can perform better as the number of perturbations per batch increases, but due to the scale of experiments with 10-100 per round and up to 1500 rounds in the FL setting, we limit the total perturbations per batch of BAFFLE $^{+}$ to 20 perturbations per batch and fixed finite difference step size $\\sigma=1\\mathrm{e}{-4}$ . FWDLLM $^+$ samples 10 perturbations for each batch, finite difference step size of $\\sigma\\,=\\,1\\mathrm{e}{-2}$ . FEDMEZO samples 1 perturbation for each batch, with finite difference step size of $\\sigma=1\\mathrm{e}{-3}$ . FEDMEZO also requires 3-5 epochs for each client. SPRY has 1 perturbation per batch for each client. For SPRY and its zero-order counterparts (BAFFLE $^+$ , FWDLLM+, and FEDMEZO), perturbations are sampled for a normal distribution with 0 mean and 1 variance. Default LORA $r$ and $\\alpha$ are 1 and 1, respectively. All methods use ADAMW as client-side optimizer. Besides FEDAVG, all methods use FEDYOGI as server-side optimizer. ", "page_idx": 16}, {"type": "text", "text": "AG News. AG News dataset [31] has been derived from a corpus of 496,835 categorized news articles. A subset of the corpus is used that has 120,000 total training samples and 7,600 total testing samples spread equally across 4 classes. The news articles are classified into 4 classes: World, Sports, Business, and Sci/Tech. We split this data across 1000 clients. Each client gets an equal number of samples for train and test datasets. This dataset is under Creative Commons CCZero(CC0) public domain dedication. ", "page_idx": 16}, {"type": "text", "text": "Learning rate for backpropagation-based (FEDAVG, FEDYOGI, and FEDSGD), zero-order-based (FWDLLM, BAFFLE, and FEDMEZO), and first-order-based SPRY is $\\{1{\\mathrm{e}}{-}3,5{\\mathrm{e}}{-}4,1{\\mathrm{e}}{-}4,1{\\mathrm{e}}{-}5\\}$ . The batch size is set to 8. The max sequence length is 128. All methods use ADAMW as a client-side optimizer, while SPRY performs better with SGD. Variance threshold of FWDLLM $^+$ is $1\\mathrm{e}+1$ . ", "page_idx": 16}, {"type": "text", "text": "SST2. Stanford Sentiment Treebank Binary[32] (or SST2) dataset is for a binary sentiment classification task. The dataset has 11,855 sentences derived from a set of movie reviews. The corpus was parsed using the Stanford Parser into 215,154 discrete phrases annotated by 3 human judges. This dataset contains 67,349 training samples, 872 validation samples, and 1821 testing samples. This sentiment classification dataset has the following sentiments as classes: Positive, and Negative. These samples are equally split between 100 clients, depending on the Dirichlet distribution. This dataset is under Creative Commons CCZero public domain dedication. ", "page_idx": 16}, {"type": "text", "text": "Learning rate for backpropagation-based (FEDAVG, FEDYOGI, and FEDSGD), zero-order-based (FWDLLM, BAFFLE, and FEDMEZO), and first-order-based SPRY is $\\{1{\\mathrm{e}}{-}3,5{\\mathrm{e}}{-}4,1{\\mathrm{e}}{-}4,1{\\mathrm{e}}{-}5\\}$ . The batch size is set to 8. The max sequence length is 64. Variance threshold of FWDLLM $^+$ is $5\\mathrm{e}{+0}$ . ", "page_idx": 16}, {"type": "text", "text": "Yelp. The Yelp reviews dataset[31] is a binary classification dataset gathered during the 2015 Yelp Dataset Challenge. The full dataset has 1,569,264 total samples, and it defines 2 classification tasks. We use the polarity classification task, which is a binary classification problem. It considers 1-2 stars negative polarity and 3-4 stars positive polarity. This dataset has 280,000 training samples and 19,000 test samples in each polarity. We split this data into 1000 clients. This dataset is under the Apache License, Version 2.0. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "Learning rate for backpropagation-based (FEDAVG, FEDYOGI, and FEDSGD), zero-order-based (FWDLLM, BAFFLE, and FEDMEZO), and first-order-based SPRY is {1e-3, 5e-4, 1e-4, 5e-5, 1e-5}. The batch size is set to 8. The max sequence length is 128. Variance threshold of FWDLLM $^+$ is $5\\mathrm{e}{+1}$ . ", "page_idx": 17}, {"type": "text", "text": "Yahoo. Yahoo! Answers Comprehensive Questions and Answers dataset [31] was gathered via the Yahoo! webscope program. The corpus itself contains 4,483,032 question/answer pairs, which were then formulated as a 10-class classification task. Each class in this dataset has 140,000 training and 5,000 testing samples.are The question/answer pairs are split into the following classes: 1. Society & Culture, 2. Science & Mathematics, 3. Health, 4. Education & Reference, 5. Computers & Internet, 6. Sports, 7. Business & Finance, 8. Entertainment & Music, 9. Family & Relationships, 10. Politics & Government. We split this dataset between 1000 clients, where each client gets an equal amount of data samples, where the data distribution is set by changing the Dirichlet distribution $\\alpha$ to range from most homogeneous $\\left(\\alpha=1\\right)$ ) to least homogeneous $\\stackrel{\\cdot}{\\alpha}=0$ ). This dataset is under the Apache License, Version 2.0. ", "page_idx": 17}, {"type": "text", "text": "Learning rate for backpropagation-based (FEDAVG, FEDYOGI, and FEDSGD), zero-order-based (FWDLLM, BAFFLE, and FEDMEZO), and first-order-based SPRY is $\\{1{\\mathrm{e}}{-}3,5{\\mathrm{e}}{-}4,1{\\mathrm{e}}{-}4,1{\\mathrm{e}}{-}5\\}$ . The batch size is set to 8. The max sequence length is 128. Variance threshold of FWDLLM $^+$ is $5\\mathrm{e}{+1}$ . ", "page_idx": 17}, {"type": "text", "text": "SNLI. The Stanford Natural Language Inference corpus [33] has 570,152 total sentence pairs. It is a natural language inference dataset, where the task is identifying if one sentence infers another. It has 550,152 training samples, 10,000 testing samples, and 10,000 evaluation samples. This dataset is split among 1,000 clients. The dataset has 3 classes: 1) The first sentence entails the second sentence, 2) The first sentence is neutral to the second sentence and 3) The first sentence contradicts the second sentence. This dataset is under CC BY-SA 4.0. ", "page_idx": 17}, {"type": "text", "text": "Learning rate for backpropagation-based (FEDAVG, FEDYOGI, and FEDSGD), zero-order-based (FWDLLM, BAFFLE, and FEDMEZO), and first-order-based SPRY is {1e-3, 5e-4, 1e-4, 5e-5, 1e-5}. The batch size is set to 8. The max sequence length is 80. Variance threshold of FWDLLM $^+$ is $1\\mathrm{e}{+2}$ ", "page_idx": 17}, {"type": "text", "text": "MNLI. The Multi-Genre Natural Language Inference (MNLI) [34] corpus contains 432,702 sentence pairs which were crowd-sourced and then annotated with textual entailment information. This dataset is also a Natural Language Inference dataset as with SNLI. This dataset has 392,702 training, 20,000 evaluation, and 20,000 testing samples. These samples are split among 1,000 clients. This dataset draws from multiple sources, most of which are under the Open American National Corpus (OANC) license. The rest are under either the CC BY 3.0 Unported licenses or the CC BY-SA 3.0 licenses. ", "page_idx": 17}, {"type": "text", "text": "Learning rate for backpropagation-based (FEDAVG, FEDYOGI, and FEDSGD), zero-order-based (FWDLLM, BAFFLE, and FEDMEZO), and first-order-based SPRY is {1e-3, 5e-4, 1e-4, 5e-5, 1e-5}. The batch size is set to 8. The max sequence length is 80. Variance threshold of FWDLLM $^+$ is $1\\mathrm{e}{+2}$ ", "page_idx": 17}, {"type": "text", "text": "SQuADv2. The Stanford Question Answering Dataset (SQuADv2) [35] consists of crowd-sourced questions about a set of Wikipedia articles. It is a reading comprehension dataset, where the answer to a question is a section (or a span) from the passage. It is also possible for the question to be unanswerable. The dataset contains 100,000 answerable and 50,000 unanswerable questions. This dataset was split into 500 clients. The heterogeneity is generated based on the topic labels (or \u201ctitles\u201d) associated with each question in the dataset. There are 35 titles available. This dataset is under the CC BY-SA 4.0 license. ", "page_idx": 17}, {"type": "text", "text": "Learning rate for backpropagation-based (FEDAVG, FEDYOGI, and FEDSGD), zero-order-based (FWDLLM, BAFFLE, and FEDMEZO), and first-order-based SPRY is $\\left\\{1{\\mathrm{e}}{-}3,\\;5{\\mathrm{e}}{-}4,\\;1{\\mathrm{e}}{-}4,\\;1{\\mathrm{e}}{-}5\\right\\}$ . The batch size is set to 8 for Forward-mode AD and zero-order differentiation-based methods. Backpropagation-based methods use a batch size of 4. The max sequence length is 400. Variance threshold of FWDLLM $^+$ is $5\\mathrm{e}{+1}$ . ", "page_idx": 17}, {"type": "text", "text": "MultiRC. Multi-sentence Reading Comprehension (MultiRC) corpus is a dataset that contains short paragraphs with questions, whose answers can be found in the paragraph itself. We consider a task where we classify if the input question given as input is correct or false. It has 6k multi-sentence questions about ${800+}$ paragraphs. Due to the scale of the dataset, we split it into 100 clients. This dataset is under the MIT license. ", "page_idx": 18}, {"type": "text", "text": "Learning rate for backpropagation-based (FEDAVG, FEDYOGI, and FEDSGD), zero-order-based (FWDLLM, BAFFLE, and FEDMEZO), and first-order-based SPRY is $\\{1{\\mathrm{e}}{-}3,5{\\mathrm{e}}{-}4,1{\\mathrm{e}}{-}4,1{\\mathrm{e}}{-}5\\}$ . The batch size is set to 8. The max sequence length is 256. Variance threshold of FWDLLM $^+$ is $1\\mathrm{e}{+2}$ . ", "page_idx": 18}, {"type": "text", "text": "C Limitations and Future Work ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "SPRY achieves a remarkable drop in memory consumption due to Forward-mode AD not having to store activations during the forward pass. However, the current implementation of Forward-mode AD by PyTorch is still suboptimal in terms of computation time. The high computation time is attributed to the column-by-column computation of the intermediate results of $\\mathtt{j v p}$ . Improving the computation of $\\mathtt{j v p}$ such that it takes significantly less time (almost half) than backpropagation remains an open and interesting problem. Moreover, there\u2019s room for improvement in reducing the memory consumption to that of zero-order methods. In zero-order methods, the weights are perturbed and a forward pass is computed on the perturbed weights. However, with the current implementation of Forward-mode AD, perturbations create a separate copy from the original weights, which accrues additional overhead. To further utilize the computation capacity of clients in FL, device-heterogeneity-aware strategies on splitting and mapping layers to clients can be explored for SPRY, e.g., layer selection could happen on the client-side according to their data distributions. ", "page_idx": 18}, {"type": "text", "text": "D Broader Impact ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Through SPRY, we aspire to bring impact in terms of data privacy and accessible finetuning of large language models (LLMs) on edge devices. ", "page_idx": 18}, {"type": "text", "text": "For small and medium organizations and individual users, the cost to finetune these language models can be prohibitively expensive as the size of the trainable weights increases. With SPRY, we enable finetuning LLMs on resource-constrained edge devices with low memory consumption, making it feasible for a wider range of users. Moreover, the federated setting also provides benefits of data privacy. This can be ideal for use cases where LLMs can bring improved performance for a plethora of personalized downstream tasks, but the finetuning data containing sensitive and confidential information is never shared with a third party. With SPRY, such data remains on the user\u2019s device, ensuring privacy while still allowing for effective finetuning of the LLM. ", "page_idx": 18}, {"type": "text", "text": "However, making LLM finetuning accessible to a broader range of organizations and individuals comes with its own challenges like a spread of biases or misinformation. Without preprocessing and filtering client data on their devices, the LLMs can be fed harmful and misleading information. Hence, it is necessary to develop guardrails on what kind of data should be filtered in, to finetune LLMs with crowd-sourced compute resources. ", "page_idx": 18}, {"type": "text", "text": "E SPRY Pseudocode ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Algorithm 1 shows the workflow of SPRY. ", "page_idx": 19}, {"type": "image", "img_path": "dGQtja9X2C/tmp/2efb52ed8493b7680e89cd170b0f928a6c8fa14ac35f4ad9ec6c772b28846028.jpg", "img_caption": [], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "The function MAPLAYERSTOCLIENTS on Line 14 in Algorithm 1 shows how we have assigned only a few trainable layers to each client in FL, to make Forward-mode AD more effective at generating better estimation of the gradients. In function CLIENTTRAIN on Line 23 of Algorithm 1; each client $m$ gets a copy of the entire language model ${\\pmb w}_{m}^{(r)}$ and a list trainable_layers of parameter names the client $m$ has to train. A client $m$ freezes the parameters that are not included in its trainable_layers. And for each of the parameter $\\overline{{w}}_{m}^{(r)}$ which need to be trained, SPRY generates a corresponding random perturbation v using a normal distribution N(0, Iw(mr) .shape). ", "page_idx": 19}, {"type": "text", "text": "aOrne cleo ca acllliye nutp $m$ theads  woibttha ionpetdi mfoirzewrasr ldi kger aSdiGenDt so or f AalDl AthMe.  trTahine aubpled aptaerda tmraeitenras $\\overline{{\\pmb{w}}}_{m}^{(r)}$ ,r tahmoestee rpsa taerres $\\overline{{\\pmb{w}}}_{m}^{(r)}$ sent back to the server. The server has a mapping of parameter names to client IDs, and hence it builds $\\pmb{w}^{\\prime(r)}$ by using $\\pmb{\\overline{{\\upsilon}}}_{m}^{(r)}\\ \\forall m\\in[M]$ . If there are multiple clients mapped to the same parameter, then we take a weighted average (similar to FEDAVG) of all the parameters to build $\\pmb{w}^{\\prime(r)}$ . SPRY uses adaptive optimizers like FEDYOGI at server-side on effective gradients $\\Delta={\\pmb w}^{\\prime(r)}-{\\pmb w}^{(r)}$ to reduce the noise of forward gradients. ", "page_idx": 19}, {"type": "text", "text": "F Communication and Computation Costs ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "F.1 Communication Costs ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Table 2 illustrates communication costs of SPRY and its backpropagation- and finite difference- based baselines. A discussion on communication modes of SPRY is also given in Section 3.2, \u201cPer-Epoch Communication\u201d and \u201cPer-Iteration Communication\u201d. ", "page_idx": 20}, {"type": "table", "img_path": "dGQtja9X2C/tmp/baa7ec6e0b995138f9f1a46df064a02e4b22bdb9b4e4df45a6e035377395c5cc.jpg", "table_caption": ["Table 2: Communication cost of SPRY and all its baselines. $M$ is the count of participation clients. Total count of trainable parameters of a global model is $w_{g}=w_{\\ell}L$ (for simplicity, we assume that each layer has $w_{\\ell}$ parameters). "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "Here we discuss the costs related to those communication modes: ", "page_idx": 20}, {"type": "text", "text": "Per-epoch Communication. SPRY\u2019s client-to-server communication cost does not scale linearly with clients like in its backpropagation and finite-difference counterparts, but instead decreases or stays constant for $L$ as more clients are present. Server-to-client communication cost is lower in SPRY due to only sending one layer per client when $M>L$ or $\\frac{L}{M}$ layers per client otherwise. This result follows from the below observation: ", "page_idx": 20}, {"type": "text", "text": "Backpropagation-based and finite-difference-based methods have a communication cost of $w_{g}$ , where $w_{g}$ represents the global model size. Each client in $[M]$ (set of participating clients) receives all trainable parameters from the server, requiring the server to send a total of $w_{g}\\times M$ parameters each round. ", "page_idx": 20}, {"type": "text", "text": "SPRY\u2019s communication cost per epoch is $\\begin{array}{r}{w_{\\ell}\\operatorname*{max}(\\frac{L}{M},1)}\\end{array}$ , where $L$ is the layer count and $w_{\\ell}$ is the count of parameters for each layer. Each client sends a subset of trainable parameters, incurring a communication cost of wM\u2113L parameters for $L>M$ , and $w_{\\ell}$ for $L\\leq M$ . When $L\\leq M$ , each client gets 1 layer, hence the communication for each client is $w_{\\ell}$ . ", "page_idx": 20}, {"type": "text", "text": "Per-iteration Communication. SPRY accrues lower communication cost than the finite difference and backpropagation counterparts due to the layer splitting strategy, and the server\u2019s ability to compute gradients based on the $\\mathtt{j v p}$ value. This is because: ", "page_idx": 20}, {"type": "text", "text": "The communication cost from client to server for forward-mode AD and finite differences is 1. This is due to an FL round that involves (1) server selecting a random seed, (2) server sending it with trainable parameters to clients, (3) clients generating perturbations based on the seed, (4) deriving and sending back a scalar or finite difference scalar to the server, and then (5) server computing gradients by multiplying the derived perturbations with the seed. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "The server to client communication is $(w_{g}+1)\\times M$ , where the $\\bullet_{+1}\\circ$ is due the randomness seed. ", "page_idx": 21}, {"type": "text", "text": "F.2 Computation Costs ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Table 3 shows the computation costs of SPRY and its baselines, where the client-side cost is for each iteration, and the server-side cost is for each round. ", "page_idx": 21}, {"type": "text", "text": "Briefly, SPRY\u2019s client-side computation cost is traded off by a faster convergence to higher accuracy through better gradient approximations compared to finite difference-based methods. Furthermore, SPRY is the least computationally expensive on the server side due to needing to aggregate fewer parameters from the clients. ", "page_idx": 21}, {"type": "text", "text": "Table 3 assumes that matrix multiplication costs $c$ for each layer, resulting in a forward pass cost of $c$ The cost of backpropagation is $2c$ because the computation of the current layer\u2019s weight gradient is $c$ , and the cost of computing the previous layer\u2019s activation gradient is another $c$ . $\\mathtt{j v p}$ computation in SPRY takes additional cost of $c$ for each layer. Moreover, since $\\mathtt{j v p}$ calculation happens through column-by-column vector multiplications (Sec 3.1 of [24]), the related overhead is quantified by $v$ . ", "page_idx": 21}, {"type": "table", "img_path": "dGQtja9X2C/tmp/56fc582732322fa86f5901e1dd0a6e557da36f6da38c60d5dbacb62b8550fa97.jpg", "table_caption": ["Table 3: Computation cost of SPRY and all its baselines. The client-side cost is for each iteration, and the server-side cost is for each round. $L$ is the layer count, $M$ is the participating client count, $c$ is the cost of matrix multiplication for each layer. $v$ is the overhead related to column-by-column vector multiplications of $\\mathtt{j v p}$ . $w_{\\ell}$ is the size of each layer and hence size of each layer\u2019s perturbation too. $K$ is the perturbation count per iteration. $K=1$ for SPRY and FEDMEZO, and $\\sim20$ for BAFFLE and ", "FWDLLM. "], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "Client-side per-iteration computation cost. Backpropagation needs 3 matrix multiplication operations per layer. For zero-order methods, there are 2 matrix multiplications (incurred due to two forward passes) per layer, and per perturbation within a training iteration; and additional overhead $w_{\\ell}K L$ for perturbation generation. MEZO requires generation of perturbations thrice for the same seed (Algorithm 1 in MEZO [18]). ", "page_idx": 21}, {"type": "text", "text": "SPRY \u2019s computation cost is $\\begin{array}{r}{2\\times\\operatorname*{max}(\\frac{L}{M},1)\\times(c+v)+w_{\\ell}L.}\\end{array}$ Since SPRY allocates at most $\\frac{L}{M}$ layers to each client, the computation cost only scales with $\\operatorname*{max}(\\frac{L}{M},1)$ , against its counterparts scaling with $L$ . However, forward-mode AD computes $\\mathtt{j v p}$ column-wise, while its counterpart $\\mathtt{v j p}$ in backpropagation is computed row-wise. This results in time overhead ( ) if the number of trainable parameters exceeds the output size (1 as loss is scalar), which is the case for neural networks. Therefore, SPRY\u2019s per-iteration computation cost is higher compared to other approaches. ", "page_idx": 22}, {"type": "text", "text": "Note that the per-iteration computation cost of SPRY is not the whole picture. It takes fewer communication rounds to reach higher accuracy due to better gradient approximation of forwardmode AD than finite difference methods. This is why \"Time to Convergence\" (Section 5.3) discusses a fair comparison of SPRY\u2019s runtime and prediction performance. ", "page_idx": 22}, {"type": "text", "text": "Server-side per-round computation cost. On the server side, SPRY is the least computationally demanding. SPRY needs to aggregate a subset of layer weights from only the clients that were assigned to those layers, while its counterparts need to aggregate all layers from all clients. ", "page_idx": 22}, {"type": "text", "text": "Computation cost on the server-side changes based on the communication frequency per-iteration communication incurs an additional overhead of $\\begin{array}{r}{w_{\\ell}L(\\frac{M}{L}+1)}\\end{array}$ and $w_{\\ell}L(M\\bar{+}\\,1)$ (generation of perturbations at the server-side, and multiplying those perturbations with aggregate of the $\\mathtt{j v p}$ values received from the clients) for SPRY and its zero-order counterparts respectively. ", "page_idx": 22}, {"type": "table", "img_path": "dGQtja9X2C/tmp/279311a965c6fb7b47a65409c11c55564e3215d3e6f76295882ae447ac64b308.jpg", "table_caption": ["Table 4: Generalized $(A c c_{g})$ and personalized $(A c c_{p})$ accuracies (the higher, the better) for SPRY and its backpropagation and zero-order based counterparts on various language model architectures. The datasets are split with Dir $\\alpha=0.1$ . "], "table_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "dGQtja9X2C/tmp/612533789e291d6e17a357474680099fe3a28de33f3ff21086296fd629da1d5c.jpg", "img_caption": ["(a) Effect of different PEFT (b) Effect of per-epoch and per-iteration (c) Changing LORA $r$ and $\\alpha$ for methods on SPRY communication SPRY ", "Figure 4: Ablation studies on PEFT methods, communication frequency, and LORA hyperparameters. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "G Ablation Studies ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Here we will dive into various components of SPRY and see their impact on the performance of SPRY. ", "page_idx": 23}, {"type": "text", "text": "SPRY can Generalize to Different Language Model Architectures. Table 4 shows generalized and personalized accuracies $A c c_{g}$ and $A c c_{p}$ for homogeneous data splits for language model architectures other than RoBERTa Large. ", "page_idx": 23}, {"type": "text", "text": "For zero-order gradients, we show the results of the best-performing method, FWDLLM $^+$ . We see a similar trend of SPRY outperforming FWDLLM $^+$ by $3.15\\!-\\!10.25\\%$ for generalized accuracy, and by $2.75\\!-\\!12.37\\%$ for personalized accuracy, exhibiting how SPRY is independent of model architectures. SPRY also comes as close as $4.44\u20139.71\\%$ to the best-performing backpropagation-based method. ", "page_idx": 23}, {"type": "text", "text": "SPRY Supports Other PEFT Methods. Figure 4a shows the generalized accuracy of SPRY using three different PEFT methods: LORA, IA3, and BITFIT. We also experiment with finetuning only classifier layers, calling it CLASSIFIER-ONLY. LORA (with $0.3241\\%$ of the total parameters of RoBERTa Large) outperforms IA3 (with $0.3449\\%$ of the total parameters) by $10.60\\%$ , while BITFIT fails to converge for all datasets. Only training classifier layers is worse than finetuning LORA weights by $16.53\\%$ . The observation on comparison of LORA with IA3 is consistent with the work benchmarking various PEFT methods [56]. BITFIT has been observed to fail on LLMs [57]. Furthermore, unlike IA3, LORA has been shown to be successful at finetuning quantized billion-sized models in QLORA [58], making it a strong candidate for our work. ", "page_idx": 23}, {"type": "text", "text": "Effects of Communication Frequency. One way to reduce the noise introduced by the random perturbations in gradient computation is, to communicate the gradients back to the server every iteration instead of every few epochs. Figure 4b shows results of per-epoch and per-iteration communication variants of SPRY and FEDAVG. ", "page_idx": 23}, {"type": "image", "img_path": "dGQtja9X2C/tmp/bcb6a0f49fdb41c61ee82cf04d078bb7cfd94b6f0f93c77ff1cc22c1e9c3c3e0.jpg", "img_caption": ["Figure 5: Ablation studies on perturbation counts, participating client counts, and layer splitting strategy. "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "By communicating each iteration, we see a boost of $4.47\\%$ in the accuracy of SPRY, only $0.92\\%$ and $0.96\\%$ away from the accuracy of FEDAVG and FEDSGD respectively. Furthermore, as shown in Figure 4b, the convergence speed of SPRY also improves by communicating each iteration. ", "page_idx": 24}, {"type": "text", "text": "As discussed in Section 3, to reduce the trade-off between performance gains and communication cost per iteration, each client can send only the jvp scalar to the server instead of transmitting all the assigned trainable weights [20]. With the seed value of the randomness, the server can then generate the random perturbation vector $\\pmb{v}$ , which was used by all the clients to generate their respective $\\mathtt{j v p}$ values. Then the random perturbation is multiplied with the received $\\mathtt{j v p}$ values of all clients, to compute gradients. ", "page_idx": 24}, {"type": "text", "text": "Effects of the Number of Trainable Weights. Figure 4c displays the effect of changing trainable LORA parameter count on the prediction performance of SPRY. For DistilBERT Base (total parameter count of 66M), LORA reduces the trainable parameter count to 0.61M $(0.91\\%)$ , $0.74\\mathrm{M}$ $(1.11\\%)$ , 0.89M $(1.33\\%)$ , and 1.18M $(1.77\\%)$ with LORA hyperparameter settings of $(r{=}1,\\alpha{=}1)$ ), $r{=}8$ , $\\alpha{=}16\\rangle$ ), $r{=}16$ , $\\alpha{=}16$ ), and $r{=}32$ , $\\alpha{=}32$ ). ", "page_idx": 24}, {"type": "text", "text": "SPRY achieves the highest accuracy of $84.90\\%$ with $r{=}1$ , $\\alpha{=}1$ ) setting, which has the smallest trainable parameter count. The accuracy increases as the layer size decreases since fewer perturbed weights provide less noisy gradients. ", "page_idx": 24}, {"type": "text", "text": "Effects of the Number of Perturbations per Batch. The effect of increasing the number of perturbations per batch and hence the number of $\\mathtt{j v p}$ evaluations for a batch is shown in Figure 5a for the SST2 dataset. Here, gradients generated from each random perturbation and their corresponding jvp values are averaged to update the model. We observe that increasing $K$ (perturbations per batch) for Forward-mode AD has little to no impact on the end prediction performance of SPRY, with $K\\,=\\,100$ improving the generalized test accuracy by $1.1\\%$ over $K=1$ . However, the benefits of increasing the perturbation count per batch are seen in the convergence speed. Setting $K=10$ achieves a steady state (of accuracy ${\\sim}86\\%$ ) around $200^{\\mathrm{th}}$ round, while the setting with $K=1$ takes 500 rounds. The improvements in convergence speed are saturated for $K>10$ . This shows that more perturbations reduce the gradient estimation noise only to an extent. ", "page_idx": 24}, {"type": "text", "text": "Effects of the Number of Participating Clients per Round. Figure 5b shows how changing the per-round number of participating clients $C$ influences SPRY on the SST2 dataset. Increasing client count increases the prediction performance of SPRY. With the total client count fixed to 100, the three settings $C\\,=\\,10$ , $C\\,=\\,50$ , and $C\\,=\\,100$ produce accuracies of $85.14\\%$ , $86.56\\%$ , and $88.08\\%$ , respectively. Similar to the findings of Section G, we also see an improvement in the convergence speed as the participating client count increases. To achieve an accuracy of ${\\sim}85\\%$ ; $C=10$ , $C=50$ , $C=100$ require 500, 450, and 150 rounds respectively. The performance gains and faster convergence are due to more clients training the weights of the same layers. ", "page_idx": 24}, {"type": "text", "text": "The Importance of Splitting Layers. To understand the effects of splitting, we compare the results of the following two experiments: (a) With FEDAVGSPLIT, we apply the strategy of splitting trainable layers across clients (Section 3.1) to backpropagation-based FEDAVG, and (b) With FEDFGD, we omit the splitting strategy of SPRY. ", "page_idx": 24}, {"type": "text", "text": "Figure 5c shows the performance of FEDAVG and FEDAVGSPLIT against FEDFGD and SPRY for two LMs: RoBERTa Large (355M) and BERT Base (110M). We observe that FEDAVGSPLIT fails to achieve similar accuracy for both models with a drop of $2.60\\%$ and $10.00\\%$ . This is because in FEDAVGSPLIT, fewer clients are training each subset of weights. Moreover, we see a similar accuracy with an absolute difference of $2.70\u20133.61\\%$ between FEDAVGSPLIT and SPRY, since the trainable weight count per client is low. FEDYOGISPLIT follows the same observation of not achieving similar accuracy to FEDYOGI if the trainable weights are split across clients. On the contrary, FEDFGD converges for the smaller model BERT base, albeit 150 rounds slower than SPRY, and with $2.87\\%$ accuracy drop. But as the size of trainable weights increases, e.g., for RoBERTa Large, FEDFGD fails to converge. This proves the necessity of splitting layers for Forward-mode AD so that each client has fewer trainable weights to perturb. ", "page_idx": 25}, {"type": "text", "text": "H Additional Results ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "H.1 Generalized Performance Curves ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Generalized results on homogeneous and heterogeneous clients with Dir $\\alpha=1.0$ and $\\alpha=0.1$ are shown in (a) Figures 6 and 8 for RoBERTa Large, Llama2-7B, OPT6.7B, OPT13B; and (b) Figure 7 ", "page_idx": 26}, {"type": "image", "img_path": "dGQtja9X2C/tmp/d6a0fd5dcca673b672bf601f8896acf644991f088338117975d6ba0e87729b95.jpg", "img_caption": ["Figure 6: Generalized accuracy / F1 score / Exact matches for homogeneous clients (Dirichlet $\\alpha=1.0)$ ) setting "], "img_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "dGQtja9X2C/tmp/0fc979f1e45b1c8caef0b0c45a717670f99466647ca20d91496a3c9e955c5bc1.jpg", "img_caption": ["(a) AG News with BERT Base "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "dGQtja9X2C/tmp/16541dddc8fa7a61db507b64ffd89bd29d60d2b1dd564fceb6dfab2e67a933df.jpg", "img_caption": ["(b) SST2 with DistilBERT Base "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "dGQtja9X2C/tmp/9cb41d33bc6a2aa8cb1eb189329976a828acdcda9b99ab55942059a804426a20.jpg", "img_caption": ["(c) SNLI with BERT Large "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "dGQtja9X2C/tmp/ed2697d59e78d1c57a498c699dc9a90081e06382144d6e204e0947dd1e56fbf1.jpg", "img_caption": ["(d) Yahoo with DistilBERT Base "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "dGQtja9X2C/tmp/461fab08a7bd687ca1b0d433ba7b8f2e8c8e7a5e3485c348dc4a850a76676dd4.jpg", "img_caption": ["(e) Yelp with Albert Large v2 "], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "Figure 7: Generalized accuracy /F1 score / Exact matches for homogeneous clients (Dirichlet $\\alpha=1.0,$ ) setting for a variety of language models ", "page_idx": 27}, {"type": "image", "img_path": "dGQtja9X2C/tmp/12a1410711c38c90816b53e650299298522362f9aa6cae25e0e1d09281452c8f.jpg", "img_caption": ["(a) AG News with RoBERTa Large "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "dGQtja9X2C/tmp/a584fdf4249aa21b206717cf73b6dcef697697dd44155dcb75c39ed798632d40.jpg", "img_caption": ["(b) SST2 with RoBERTa Large "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "dGQtja9X2C/tmp/48ba829ac4c9d003a37b224dc76248ad5820bf0413cddb1ae50711f6e4f34700.jpg", "img_caption": ["(c) SNLI with RoBERTa Large "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "dGQtja9X2C/tmp/c578b73946a0474a89e3b0750a89d3f19ee3b3fcf375a32674d8a124b0424e3b.jpg", "img_caption": ["(d) MNLI with RoBERTa Large "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "dGQtja9X2C/tmp/1165a5c447805cc4b051428484821c22c938af490b2d0810441f828ac87b92a3.jpg", "img_caption": ["(e) Yahoo with RoBERTa Large "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "dGQtja9X2C/tmp/d18fd79d8f0478f34b5cf262a896dfafb7b2f4705133055148205ff1ad93fd32.jpg", "img_caption": ["(f) Yelp with RoBERTa Large "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "dGQtja9X2C/tmp/dfe820f5c1ce70518dccbc7a967da3ff77bc49ab93c5ce955507879d35fe38cd.jpg", "img_caption": ["(g) MultiRC with Llama2-7B "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "dGQtja9X2C/tmp/a4c6eb0d120c8d5f4897c64e56242f8d491dc67ea3b83595a6833d485bf849eb.jpg", "img_caption": ["(h) SQuADv2 with OPT6.7B "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "dGQtja9X2C/tmp/f438efb5d389b8287ff3be3738f6dafd1b8a5d82c3bdf0e0444442a5774aebb6.jpg", "img_caption": ["(i) SQuADv2 with OPT6.7B "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "dGQtja9X2C/tmp/57061272fdec93f37349d240437e283332bcd718bb7e45eb64da65ef44ca0368.jpg", "img_caption": ["(j) SQuADv2 with OPT13B "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "dGQtja9X2C/tmp/52929d5f888d1dd5f4e2907ea0eb2c9eed5fe260f6af972ba59d154b523b3271.jpg", "img_caption": ["Figure 8: Generalized accuracy / F1 score / Exact matches for heterogeneous clients (Dirichlet $\\alpha=0.1$ ) setting ", "(k) SQuADv2 with OPT13B "], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "H.2 Personalized Performance Curves ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Personalized results on homogeneous and heterogeneous clients with Dir $\\alpha=1.0$ and $\\alpha=0.1$ are shown in (a) Figures 9 and 11 for RoBERTa Large, Llama2-7B, OPT6.7B, OPT13B; and (b) Figure 10 for BERT Large, BERT Base, DistilBert Base, Albert Large v2. ", "page_idx": 29}, {"type": "text", "text": "Table 5 shows accuracy and F1 scores of SPRY and its backpropagation and zero-order based counterparts. ", "page_idx": 29}, {"type": "image", "img_path": "dGQtja9X2C/tmp/9e320e84c18089297e4e118da0058fd2d57ad463eb7ded8650790d6a323ecb8e.jpg", "img_caption": ["Figure 9: Personalized accuracy / F1 score / Exact matches for homogeneous clients (Dirichlet $\\alpha=1.0)$ ) setting "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "dGQtja9X2C/tmp/bea55b5ea1e9fe475dbb90ea427acfb54de6a15ba12f79f054a096ffc4f9844a.jpg", "img_caption": ["(d) Yahoo with DistilBERT Base ", "Figure 10: Personalized accuracy / F1 score / Exact matches for homogeneous clients (Dirichlet $\\alpha=1.0$ ) setting for a variety of language models ", "(e) Yelp with Albert Large v2 "], "img_footnote": [], "page_idx": 30}, {"type": "table", "img_path": "dGQtja9X2C/tmp/229f499e2079d605a072196cbd46fd8aa6e472607e7daf149dcb0f193a134b77.jpg", "table_caption": ["Table 5: Personalized accuracy $(A c c_{p})$ for SPRY and its backpropagation- and zero-order-based counterparts on RoBERTa Large and LLMs. SQuADv2 uses F1 score. $\\uparrow$ shows that higher values are better. The datasets are split with Dir $\\alpha=0.1$ . $\\diamondsuit=$ Llama2-7B. $\\star=\\mathrm{OPT}6.7\\mathrm{B}$ . $\\boxed{\\square}=\\mathrm{OPT}13\\mathbf{B}$ . SPRY significantly outperforms the best-performing zero-order-based methods. "], "table_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "dGQtja9X2C/tmp/2c6e4e8a6536d1a56732bd53b02c74138aa758d9a4c0b2a8dc99662a6c1490d7.jpg", "img_caption": ["(a) AG News with RoBERTa Large "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "dGQtja9X2C/tmp/238b1e9562766e9dd79440f0720008650fbdfb064d96d0e379c43abe474390f3.jpg", "img_caption": ["(b) SST2 with RoBERTa Large "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "dGQtja9X2C/tmp/1a34b4ae2374458235451e8f90b9243e6a945ef6afa2269409a56e0fa84d32a1.jpg", "img_caption": ["(c) SNLI with RoBERTa Large "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "dGQtja9X2C/tmp/65118fbe497a403569c76d3ea8da0834d1deb25d628c354779c273263690bdd7.jpg", "img_caption": ["(d) MNLI with RoBERTa Large "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "dGQtja9X2C/tmp/20782d8650f2c36bc71d03b27572571d769da3fe1dfdd340092926bbd9ea0637.jpg", "img_caption": ["(e) Yahoo with RoBERTa Large "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "dGQtja9X2C/tmp/46ec9ed03d6a8a5a0da9186cd2b74106a1afbfff11559a85f2dd45407df87bb0.jpg", "img_caption": ["(f) Yelp with RoBERTa Large "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "dGQtja9X2C/tmp/39c2ac8b79688c91a58f0f156ec527ff043b8ad9ecccad57bb03e989bbf4fa05.jpg", "img_caption": ["(g) MultiRC with Llama2-7B "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "dGQtja9X2C/tmp/517f5ec5199f61c1ceea3cfc13cce1e032029fcca841da060094dd0ebda554ea.jpg", "img_caption": ["(h) SQuADv2 with OPT6.7B "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "dGQtja9X2C/tmp/5742550d9e38e76afdd3b3db4533a4cef251ae930a6b60f907d03555a8e0fc97.jpg", "img_caption": ["(i) SQuADv2 with OPT6.7B "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "dGQtja9X2C/tmp/161844a5f3cead04f0b76925ea37c6f56903177ed27acc40a7814c7c73b3c770.jpg", "img_caption": ["(k) SQuADv2 with OPT13B "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "dGQtja9X2C/tmp/bef089c0841f510cf2e3cec648b4c641321bc5afd7ae5f6d5d6d9124e8525c1e.jpg", "img_caption": ["(j) SQuADv2 with OPT13B ", "Figure 11: Personalized accuracy / F1 score / Exact matches for heterogeneous clients (Dirichlet $\\alpha=0.1$ ) setting "], "img_footnote": [], "page_idx": 31}, {"type": "text", "text": "H.3 Experiment Variance ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Tables 6 and 7 show the variance of running the same experiments thrice with the random seeds 0, 1, and 2. ", "page_idx": 32}, {"type": "table", "img_path": "dGQtja9X2C/tmp/7cb68156e3fd9aa996987abe4300a31511a5c64b00b43027a6be22be7aa6c151.jpg", "table_caption": ["Table 6: Experimental variance $(\\pm)$ for SPRY and its counterparts on RoBERTa Large. "], "table_footnote": [], "page_idx": 32}, {"type": "table", "img_path": "dGQtja9X2C/tmp/b28bc0dfca22122a8e7447fa1c77d6c27e2e4854431f318df0b503de886e21b8.jpg", "table_caption": ["Table 7: Experimental variance $(\\pm)$ for generalized ( $\\mathit{A c c}_{g}$ for MultiRC / $F1_{g}$ for SQuADv2) and personalized $A c c_{p}$ for MultiRC / $F1_{p}$ for SQuADv2) accuracy or F1 score for SPRY and its counterparts. $\\diamondsuit=$ Llama2 7B. \u22c6= OPT 6.7B. \u25a1 $=$ OPT 13B. "], "table_footnote": [], "page_idx": 32}, {"type": "text", "text": "I Proofs ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "I.1 Basics ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Server Update. The server update of SPRY uses adaptive optimizer FEDYOGI. However, to simplify the proofs without losing generality, we use the server update of FEDADAM [25]. FEDADAM has the exact update rule as FEDYOGI but without a sign function in its calculation of the second moment of the gradients (See Algorithm 2 of AFO [25]). ", "page_idx": 33}, {"type": "text", "text": "Hence, the server update of SPRY is ", "page_idx": 33}, {"type": "equation", "text": "$$\nw^{(r)}\\gets w^{(r-1)}+\\eta\\frac{\\Delta^{(r)}}{\\sqrt{\\Lambda^{(r)}}+\\tau}\\qquad\\forall\\,\\mathrm{trainable}\\,\\,\\mathrm{weights}\\,\\,w^{(r)}\\in[d].\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "$\\Delta^{(r)}$ is the square of accumulated gradients from all clients. $\\Lambda^{(r)}$ is the second moment of $\\Delta^{(r)}$ . $\\tau$ is a small positive real number, to prevent division by zero errors. Note that we are assuming flattened weights w \u2208Rdwithout the loss of generality. ", "page_idx": 33}, {"type": "text", "text": "With SPRY, the aim is to solve the following optimization problem: ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{w\\in\\mathbb{R}^{d}}f(w)=\\frac{1}{m}\\sum_{m=1}^{M}F_{m}(w_{\\overline{{m}}}),\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where $\\begin{array}{r}{\\overline{{m}}\\,\\in\\,\\left[\\frac{(m-1)d}{M}+1,\\frac{m d}{M}\\right]}\\end{array}$ , $F_{m}(w_{\\overline{{m}}})=\\mathbb{E}_{(x,y)\\sim\\mathcal{D}_{m}}[f_{m}(w_{\\overline{{m}}},(x,y))]$ is the objective function, $\\mathcal{D}_{m}$ is the dataset, and $f_{m}$ is the loss function of a client $m\\in[M]$ . ", "page_idx": 33}, {"type": "text", "text": "Accumulated Gradients. With SPRY, each client trains a subset of weights $w_{m}$ . In a low participation rate setting, each $w_{m}$ is only trained by one of the participating clients from the set of available clients $\\mathcal{M}$ . Although we make our analysis more generally applicable by showing multiple clients training the same $w_{m}$ . ", "page_idx": 33}, {"type": "text", "text": "The true global gradients can be written as, ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\nabla f(w)=\\left[\\frac{1}{\\widetilde M}\\sum_{m\\in\\widetilde M}\\nabla F(w_{\\overline{{m}}})\\ \\Big|\\ \\overline{m}\\in\\left[\\frac{(m-1)d}{M}+1,\\frac{m d}{M}\\right],\\widetilde M\\subset\\mathcal M\\right]\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where $\\widetilde{\\mathcal{M}}$ is a set of clients training the subset of the weights $w_{m}$ . $\\widetilde{M}$ is the size of $\\widetilde{\\mathcal{M}}$ . ", "page_idx": 33}, {"type": "text", "text": "Client Update. The directional derivative of Forward-mode AD is denoted as $\\nabla\\hat{f}_{v}(w;(x,y))$ , where $v\\in\\mathbb{R}^{d}$ is the random perturbation of weights $w$ and $(x,y)$ are sampled from a dataset $\\mathcal{D}$ . For each client $m$ , through Forward-mode AD, we have $\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};(x,y))=(\\nabla\\hat{f}_{m,v}(w_{\\overline{{m}}};(x,y))$ \u00b7 $v_{\\overline{{m}}})$ to estimate the true gradient $\\nabla F_{m}(w_{m})$ : ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\mathbb{E}_{v_{m},\\mathcal{D}_{m}}\\left[\\nabla\\hat{f}_{m}(w_{m},v_{m};\\mathcal{D}_{m})\\right]=\\frac{1}{D K}\\sum_{(x,y)\\sim\\mathcal{D}_{m}}\\sum_{i=1}^{K}\\mathbb{E}_{v_{i},\\overline{{m}},(x,y)}\\left[\\nabla f_{m}(w_{m};(x,y))v_{i},\\overline{{m}}^{T}_{i},\\overline{{m}}\\right]\n$$", "text_format": "latex", "page_idx": 33}, {"type": "equation", "text": "$$\n\\mathbb{E}_{v_{m},D_{m}}\\left[\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};\\mathcal{D}_{m})\\right]=\\nabla F_{m}(w_{\\overline{{m}}})\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Here, the expectation is under the randomness of sampled data $\\mathcal{D}$ , and random perturbation $v$ . $K$ is the number of perturbations per batch. SPRY uses $K=1$ by default, but here we aim to make our analysis more general to see the impact of $K$ on various properties of SPRY. ", "page_idx": 33}, {"type": "text", "text": "I.2 Assumptions ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "We will be using the following assumptions to derive the first and second moment of the forward gradient and to calculate the rate of convergence of SPRY, ", "page_idx": 33}, {"type": "text", "text": "Assumption I.1 (Smoothness). The gradient of function $F_{m}$ is $L$ -Lipschitz, ", "page_idx": 33}, {"type": "text", "text": "Assumption I.2 (Bounded Global Variance (Assumption 2 in AFO [25])). The variance of the global objective function $f$ is bounded by $\\sigma_{g}$ as ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\frac{1}{M}\\sum_{m=1}^{M}||\\left[\\nabla F_{m}(w_{m})\\right]_{j}-\\left[\\nabla f(w_{m})\\right]_{j}||^{2}\\leq\\sigma_{g,j}^{2};\\,\\forall m\\in[M],w\\in\\mathbb{R}^{d}\\mathrm{~and~}\\forall j\\in[d],\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $\\nabla F_{m}$ is the true gradient of client $m$ . As defined earlier, $\\begin{array}{r}{\\overline{{m}}\\in\\left[\\frac{(m-1)d}{M}+1,\\frac{m d}{M}\\right]}\\end{array}$ ", "page_idx": 34}, {"type": "text", "text": "Assumption I.3 (Bounded Gradients (Assumption 3 in AFO [25])). The function $f_{m}(w;(x,y))$ has $G$ -bounded gradients such that for any client $m\\in[M]$ , weights $w\\,\\in\\,\\mathbb{R}^{d}$ , and sampled data $(x,y)\\sim\\ensuremath{\\mathcal{D}_{m}}$ ; we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n|\\left[\\nabla f_{m}(w;(x,y))\\right]_{j}|<G,\\,\\forall j\\in[d]\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "I.3 First and Second Moments of Forward Gradients ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "We first prove that in SPRY, estimation of $\\nabla f$ by the accumulated forward mode gradients $\\nabla\\hat{f}$ across all clients of an arbitrary round $r$ , depends on the heterogeneity across client datasets. Statements on homogeneous data have been proven for FGD [23] and MEZO [18] in single-client or centralized settings. Here we focus on the specific federated setting of SPRY, where gradients are accumulated differently than in traditional FEDAVG [1]. In SPRY, we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n7f(w)=\\mathbb{E}_{v}\\left[\\nabla\\hat{f}(w,v)\\right]=\\left[\\frac{1}{\\widetilde{M}}\\sum_{m\\in\\widetilde{\\mathcal{M}}}\\mathbb{E}\\left[\\nabla\\hat{f}_{m}(w_{m},v_{m};\\mathcal{D}_{m})\\right]\\Big|\\,\\forall\\widetilde{\\mathcal{M}}\\subset\\mathcal{M};\\overline{{m}}\\in\\left[\\frac{(m-1)d}{M}+1,\\frac{\\zeta}{L}\\right]\\right].\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $w$ represents weights, $v$ are their corresponding perturbations, and $\\mathcal{D}_{m}$ is the dataset of client $m$ . ", "page_idx": 34}, {"type": "text", "text": "We omit the round index of the model weights $w$ and their perturbations $v$ for this section since the same relationship will hold for any arbitrary round $r$ . ", "page_idx": 34}, {"type": "text", "text": "Theorem I.4 (Estimation of the Global Gradient). In SPRY, global forward gradient $\\nabla\\hat{f}$ of the trainable weights $w\\in\\mathbb{R}^{d}$ , with the corresponding weight perturbations $\\boldsymbol{v}\\in\\mathbb{R}^{d}$ , computed by $M$ participating clients is estimated in terms of true global gradient $\\nabla f$ as, ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{v,\\mathcal{D}}[\\nabla\\hat{f}(w,v;\\mathcal{D})]=\\nabla f(w)}\\\\ &{\\qquad\\qquad+\\underbrace{1}_{\\widetilde{M}}\\left[\\underbrace{\\sum_{m\\in\\widetilde{\\mathcal{M}}_{1}}\\sum_{c=1}^{C}\\alpha_{m,c}\\mathbb{E}_{(x,y_{c})\\in\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{\\left[1,\\frac{d}{M}\\right]},v_{\\left[1,\\frac{d}{M}\\right]};(x,y_{c}))\\right]}_{\\sum_{m\\in\\widetilde{\\mathcal{M}}_{2}}\\sum_{c=1}^{C}\\alpha_{m,c}\\mathbb{E}_{(x,y_{c})\\in\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{\\left[\\frac{d}{M}+1,\\frac{2d}{M}\\right]},v_{\\left[\\frac{d}{M}+1,\\frac{2d}{M}\\right]};(x,y_{c}))\\right]}\\right]^{T}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\vdots}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $C$ is total number of classes and $\\begin{array}{r}{\\alpha_{m,c}\\,=\\,\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)}\\end{array}$ . For a class $c$ , $n_{c}$ is its sample count, $\\alpha_{c}$ is its Dirichlet concentration parameter. For a client $m$ ; $n_{m,c}$ is the sample count of the $c^{t h}$ class, and $\\mathcal{D}_{m}$ is the size of the data of client $m$ . The global data is $\\begin{array}{r}{\\mathcal{D}=\\sum_{m\\in\\mathcal{M}}\\mathcal{D}_{m}}\\end{array}$ . $\\widetilde{\\mathcal{M}}$ is the set of clients training an arbitrary subset of weights, $\\widetilde{M}=|\\widetilde{\\mathcal{M}}_{i}|$ ; $\\forall i\\in[M/d]$ . ", "page_idx": 34}, {"type": "text", "text": "Proof. Suppose the global dataset $\\mathcal{D}$ is defined as a combination of all $\\mathcal{D}_{m}$ . Hence, ${\\mathcal{D}}=\\cup_{m\\in[M]}{\\mathcal{D}}_{m}$ . In SPRY, the global forward gradient is defined as ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{v,\\mathcal{D}}[\\nabla\\hat{f}(w,v;\\mathcal{D})]=\\mathbb{E}\\left[\\begin{array}{c}{\\frac{1}{\\widetilde{M}}\\sum_{m\\in\\widetilde{\\mathcal{M}}_{1}}\\nabla\\hat{f}_{m}(w_{\\left[1,\\frac{d}{M}\\right]},v_{\\left[1,\\frac{d}{M}\\right]};\\mathcal{D})}\\\\ {\\frac{1}{\\widetilde{M}}\\sum_{m\\in\\widetilde{\\mathcal{M}}_{2}}\\nabla\\hat{f}_{m}(w_{\\left[\\frac{d}{M}+1,\\frac{2d}{M}\\right]},v_{\\left[\\frac{d}{M}+1,\\frac{2d}{M}\\right]};\\mathcal{D})}\\\\ {\\vdots}\\\\ {\\frac{1}{\\widetilde{M}}\\sum_{m\\in\\widetilde{\\mathcal{M}}_{M/d}}\\nabla\\hat{f}_{m}(w_{\\left[\\frac{(M-1)d}{M}+1,d\\right]},v_{\\left[\\frac{(M-1)d}{M}+1,d\\right]};\\mathcal{D})}\\end{array}\\right]^{T}}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "To combine the gradient estimates from the above equation for all clients $m\\in\\mathcal{M}$ , we first consider the bias $b_{m}$ between the gradient estimate under (a) Globally combined data $\\mathcal{D}$ and ${\\bf(b)}$ Data $\\mathcal{D}_{m}$ of an arbitrary client $m$ . ", "page_idx": 35}, {"type": "text", "text": "Measuring the dataset bias. Note that we consider samples $(x,y)$ of $\\mathcal{D}_{m}$ to be sampled from $\\mathcal{D}$ , since $\\mathcal{D}_{m}\\subset\\mathcal{D}$ . ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{v_{m},\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};\\mathcal{D})\\right]=\\mathbb{E}_{v_{\\overline{{m}}},\\mathcal{D}_{m}}\\left[\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};\\mathcal{D}_{m})\\right]+b_{m}}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Computing the bias term $b$ requires information on dataset distribution. In $\\mathrm{FL}$ settings, Dirichlet distribution to spread the data into heterogeneous splits is a popular way to simulate heterogeneity [37]. The biased dataset $\\mathcal{D}_{m}$ is sampled from the combined dataset $\\mathcal{D}$ using the Dirichlet distribution. This allows us to utilize the properties of the distribution to derive the relationship between forward gradients on global data and on individual local data: ", "page_idx": 35}, {"type": "text", "text": "For classification tasks, let\u2019s say $\\mathcal{D}$ has $C$ total classes: $y_{1},\\ldots,y_{C}$ . We have $\\alpha_{1},\\ldots,\\alpha_{C}$ as concentration parameters of the Dirichlet distribution. The expected forward gradient for the combined dataset $\\mathcal{D}$ can be expressed as a weighted sum of the expected forward gradients for each class $C$ : ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{E}_{v_{\\overline{{m}}},\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};\\mathcal{D})\\right]=\\sum_{c=1}^{C}\\frac{n_{c}}{|\\mathcal{D}|}\\mathbb{E}_{v_{\\overline{{m}}},(x,y_{c})\\in\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};(x,y_{c}))\\right],\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where $n_{c}$ is the sample count of class $c$ . And for the biased dataset $\\mathcal{D}_{m}$ sampled with Dirichlet concentration parameters $\\alpha_{1},\\ldots,\\alpha_{C}$ , the expected forward gradient can be expressed as, ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{E}_{v_{m},\\mathcal{D}_{m}}\\left[\\nabla\\hat{f}_{m}(w_{m},v_{m};\\mathcal{D}_{m})\\right]=\\sum_{c=1}^{C}\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\mathbb{E}_{v_{\\overline{{m}}},(x,y_{c})\\in\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};(x,y_{c}))\\right],\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where $n_{m,c}$ is the sample count of class $c$ for client $m$ . ", "page_idx": 35}, {"type": "text", "text": "Subtracting Equation 16 from Equation 15, ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r}{b_{m}=\\mathbb{E}_{v_{\\overline{{m}}},\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};\\mathcal{D})\\right]-\\mathbb{E}_{v_{\\overline{{m}}},\\mathcal{D}_{m}}\\left[\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};\\mathcal{D}_{m})\\right]}\\\\ {=\\displaystyle\\sum_{c=1}^{C}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)\\mathbb{E}_{v_{\\overline{{m}}},(x,y_{c})\\in\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};(x,y_{c}))\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "For any $\\begin{array}{r}{\\overline{{m}}\\in\\left[\\frac{(m-1)d}{M}+1,\\frac{m d}{M}\\right]}\\end{array}$ , we have $\\mathbb{E}_{v_{\\overline{{m}}},\\mathcal{D}_{m}}\\left[\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};\\mathcal{D}_{m})\\right]=F_{m}(w)$ from Lemma 1 in FGD [23]. ", "page_idx": 35}, {"type": "text", "text": "Plugging in the above result and Equation 18 in Equation 14, ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{v_{m},\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};\\mathcal{D})\\right]=\\mathbb{E}_{v_{\\overline{{m}}},\\mathcal{D}_{m}}\\left[\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};\\mathcal{D}_{m})\\right]+b_{m}}\\\\ &{\\qquad\\quad=\\nabla F_{m}(w_{\\overline{{m}}})+\\displaystyle\\sum_{c=1}^{C}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)\\mathbb{E}_{v_{\\overline{{m}}},(x,y_{c})\\in\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};(x,y_{c}))\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "For $i^{t h}$ row in Equation 13, ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{c l}{\\displaystyle\\mathbb{E}_{v_{m},\\mathcal{D}}\\left[\\nabla\\hat{f}_{i}(w_{m},v_{m};\\mathcal{D})\\right]=\\frac{1}{\\widetilde{M}}\\displaystyle\\sum_{m\\in\\widetilde{\\mathcal{M}}_{1}}\\mathbb{E}_{v_{m},\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{m},v_{m};\\mathcal{D})\\right]}&{\\displaystyle(200\\ u^{2})}\\\\ {\\displaystyle}&{\\displaystyle=\\frac{1}{\\widetilde{M}}\\displaystyle\\sum_{m\\in\\widetilde{\\mathcal{M}}_{1}}\\left(\\nabla F_{m}(w_{m})+\\sum_{c=1}^{C}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)\\mathbb{E}_{v_{m},(x,y_{c})\\in\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{m},v_{m};(x,y_{c})\\right)\\right]\\right.}\\\\ {\\displaystyle}&{\\displaystyle\\left.(21\\\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Putting Equation 22 in Equation 13, ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{f}(w,v;D)}\\\\ &{\\left[\\begin{array}{c}{\\nabla f(w_{[\\hat{x},\\hat{y}]})+\\frac{1}{M}\\sum_{m\\in\\hat{\\mathcal{M}}_{1}}\\sum_{c=1}^{C}\\left(\\frac{\\mu_{\\hat{x}}}{|\\mathcal{P}|}-\\frac{n_{m},\\omega_{u}}{|\\mathcal{S}|}\\right)\\mathbb{E}_{(x,y)\\in\\mathcal{P}}\\left[\\nabla\\hat{f}_{m}(w_{[\\hat{x},\\hat{y}]},v_{[\\hat{x}]};\\hat{x},y)\\right]}\\\\ {\\nabla f(w_{[\\hat{x}+1,\\hat{y}]})+\\frac{1}{M}\\sum_{m\\in\\hat{\\mathcal{M}}_{2}}\\sum_{c=1}^{C}\\left(\\frac{\\mu_{\\hat{x}}}{|\\mathcal{P}|}-\\frac{n_{m},\\omega_{u}}{|\\mathcal{S}|}\\right)\\mathbb{E}_{(x,y)\\in\\mathcal{P}}\\left[\\nabla\\hat{f}_{m}(w_{[\\hat{x}+1,\\hat{y}]}),v_{[\\hat{x}+1,\\hat{y}]}\\right]}\\end{array}\\right.}\\\\ &{\\qquad\\left[\\begin{array}{c}{\\nabla f(w_{[\\hat{x},\\hat{x}]})}\\\\ {\\nabla f(w_{[\\hat{x}+1,\\hat{y}]})}\\end{array}\\right]^{T}+\\frac{1}{M}\\left[\\begin{array}{c}{\\sum_{m\\in\\hat{\\mathcal{M}}_{1}}\\sum_{c=1}^{C}\\left(\\frac{\\mu_{\\hat{x}}}{|\\mathcal{P}|}-\\frac{n_{m},\\omega_{u}}{|\\mathcal{P}|}\\right)\\mathbb{E}_{(x,y)\\in\\mathcal{P}}\\left[\\nabla\\hat{f}_{m}(w_{[\\hat{x},\\hat{y}]},v_{[\\hat{x}]})\\right]}\\\\ {\\vdots}\\\\ {\\sum_{m\\in\\hat{\\mathcal{M}}_{2}}\\sum_{c=1}^{C}\\left(\\frac{\\mu_{\\hat{x}}}{|\\mathcal{P}|}-\\frac{n_{m},\\omega_{u}}{|\\mathcal{P}|}\\right)\\mathbb{E}_{(x,y)\\in\\mathcal{P}}\\left[\\nabla\\hat{f}_{m}(w_{[\\hat{x},\\hat{y}]},v_{[\\hat{x}]})\\right]}\\end{array}\\right.}\\\\ &{\\qquad\\qquad\\vdots}\\\\ &{\\qquad\\qquad\\qquad\\left.\\nabla f(w)+\\frac{1}{M}\\left[\\begin{array}\n$$$$\n\\nabla f(w)+\\frac{1}{\\widetilde{M}}\\left[\\sum_{m\\in\\widetilde{M}_{1}}\\sum_{c=1}^{C}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)\\mathbb{E}_{(x,y_{c})\\in\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{[1,\\frac{d}{M}]},v_{[1,\\frac{d}{M}]};(x,y_{c}))\\right]\\right.\\qquad\\qquad\\qquad\\left.}\n$$$_T$ ", "text_format": "latex", "page_idx": 36}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Next, we formulate the norm of the forward gradient $\\nabla\\hat{f}$ . ", "page_idx": 36}, {"type": "text", "text": "Lemma I.5 (Norm of the Forward Gradient). Under Assumption I.2, and at the participation rate of s, $M$ participating clients training weights $w\\in\\mathbb{R}^{d}$ through random perturbations $\\boldsymbol{v}\\in\\mathbb{R}^{d}$ in SPRY derives the accumulated forward gradient $\\nabla\\hat{f}(w,v;\\mathcal{D})$ such that, ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{v,\\mathcal{D}}||\\nabla\\hat{f}(w,v;\\mathcal{D})||^{2}=\\mathbb{E}||\\nabla f(w)||^{2}\\left(1+\\left(\\frac{2(3d+K-1)}{\\widetilde M K}\\right)\\displaystyle\\sum_{m\\in\\mathcal{M}}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}\\right)}\\\\ {+\\left(\\frac{2\\sigma_{g}^{2}(1-s)(3d+K-1)}{\\widetilde M K}\\right)\\displaystyle\\sum_{m\\in\\mathcal{M}}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2},\\ (27)}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where $\\mathcal{D}$ is the combination of datasets of all $M$ clients, $K$ is the number of perturbations per batch, $\\widetilde{M}$ is the count of clients training a particular weight subset, $\\sigma_{g}^{2}$ is the upper bound of the global gradient variance. For a total of $C$ classes in $\\mathcal{D}$ , we define $n_{c}$ as the sample count of the $c^{t h}$ class, $\\alpha_{c}$ is Dirichlet concentration parameter for the $c^{t h}$ class, $\\mathcal{D}$ is the size of the global data. For a client $m$ ; $n_{m,c}$ is the sample count of the $c^{t h}$ class for client $m$ , and $\\mathcal{D}_{m}$ is the size of the data of client $m$ . ", "page_idx": 36}, {"type": "text", "text": "Proof. The proof follows a similar style of Lemma 2 in MEZO [18]. The difference in our setting is that we have $\\nabla\\hat{f}(w,v;\\mathcal{D})$ which is an aggregate of $\\nabla\\hat{f}_{m}(w,v;D)$ derived from the federated clients, while MEZO has results under the setting of a single client. ", "page_idx": 36}, {"type": "text", "text": "From Theorem I.4 we have, ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Xi_{v,\\mathcal{D}}\\left[\\nabla\\hat{f}(w,v;\\mathcal{D})\\right]}\\\\ &{\\qquad=\\left[\\begin{array}{c c c}{\\nabla f(w_{\\left[1,\\frac{d}{M}\\right]})+\\frac{1}{\\overline{{M}}}\\sum_{m\\in\\widetilde{M}_{1}}\\sum_{c=1}^{C}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)\\mathbb{E}_{(x,y_{c})\\in\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{\\left[1,\\frac{d}{M}\\right]},v_{\\left[1,\\frac{d}{M}\\right]};\\right.\\right.}\\\\ {\\left.\\left.=\\left[\\nabla f(w_{\\left[\\frac{d}{M}+1,\\frac{2d}{M}\\right]})+\\frac{1}{\\overline{{M}}}\\sum_{m\\in\\widetilde{M}_{2}}\\sum_{c=1}^{C}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)\\mathbb{E}_{(x,y_{c})\\in\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{\\left[\\frac{d}{M}+1,\\frac{2d}{M}\\right]},v_{\\left[\\frac{d}{M}+1,\\frac{2d}{M}\\right]};\\right.\\right.}\\\\ {\\vdots}&{\\vdots}&{\\ddots}\\end{array}\\right]\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\upzeta_{v_{m},(x,y_{c})\\sim\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};(x,y_{c}))\\right]=\\frac{1}{|\\mathcal{D}|K}\\sum_{(x,y_{c})\\sim\\mathcal{D}}\\sum_{i\\in[K]}\\mathbb{E}\\left[\\left(\\nabla f_{m}\\left(w_{\\overline{{m}}};(x,y_{c})\\right)\\cdot v_{i,\\overline{{m}}}\\right)v_{i,\\overline{{m}}}^{T}\\right],\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "using Equation 10. The right hand side expectation is also under the randomness of partial perturbations. Here, $K$ is perturbation count, and $|\\mathcal D|$ is the size of the combined dataset ${\\mathcal{D}}=\\cup_{m\\in[M]}{\\mathcal{D}}_{m}$ . ", "page_idx": 37}, {"type": "text", "text": "To compute the second moment for a client $m$ , ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathfrak{L}_{v_{m},(x,y_{c})\\sim\\mathcal{D}}\\left[\\nabla\\hat{f}_{m}(w_{m},v_{\\overline{{m}}};(x,y_{c}))\\cdot\\nabla\\hat{f}_{m}(w_{\\overline{{m}}},v_{\\overline{{m}}};(x,y_{c}))^{T}\\right]}\\\\ &{\\qquad\\qquad=\\cfrac{1}{|\\mathcal{D}|^{2}K^{2}}\\underset{(x,y_{c}\\sim\\mathcal{D})}{\\sum}\\underset{i\\in[K]}{\\sum}\\mathbb{E}\\left[\\left(\\nabla f_{m}(w_{\\overline{{m}}};(x,y_{c}))v_{i,\\overline{{m}}}v_{i,\\overline{{m}}}^{T}\\right)\\cdot\\left(\\nabla f_{m}(w_{\\overline{{m}}};(x,y_{c}))^{T}v_{j,\\overline{{m}}}v_{i,\\overline{{m}}}\\right)\\cdot\\nabla\\hat{f}_{m}(w_{\\overline{{m}}};(x,y_{c}))\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "For simplicity, let $a$ and $b$ be two arbitrary vectors representing $\\mathbb{E}\\left[\\nabla f_{m}(w_{\\overline{{m}}};(x,y_{c}))\\right]$ and $\\mathbb{E}\\left[\\nabla f_{m}(w_{\\overline{{m}}};(\\overline{{x}},\\overline{{y}}_{c}))^{T}\\right]$ , respectively. ", "page_idx": 37}, {"type": "text", "text": "For the sum over all perturbations, we have two cases (all the expectations are under the randomness of partial $v$ ), ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[v_{i,\\overline{{m}}}v_{i,\\overline{{m}}}^{T}\\;a b^{T}\\;v_{j,\\overline{{m}}}v_{j,\\overline{{m}}}^{T}\\right]=\\mathbb{E}\\left[v_{i,\\overline{{m}}}v_{i,\\overline{{m}}}^{T}\\right]\\cdot a b^{T}\\cdot\\mathbb{E}\\left[v_{j,\\overline{{m}}}v_{j,\\overline{{m}}}^{T}\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "equation", "text": "$$\n=I\\cdot a b^{T}\\cdot I=a b^{T}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "2. If $i=j$ . (Occurs $K$ times) ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[v_{i,\\overline{{m}}}v_{i,\\overline{{m}}}^{T}\\;a b^{T}\\;v_{j,\\overline{{m}}}v_{j,\\overline{{m}}}^{T}\\right]=\\mathbb{E}\\left[v_{i,\\overline{{m}}}v_{i,\\overline{{m}}}^{T}\\;a b^{T}\\;v_{i,\\overline{{m}}}v_{i,\\overline{{m}}}^{T}\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}_{v_{i}}\\left[v_{i}^{4}\\right]\\langle a,b\\rangle}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "For all such $v_{i}$ with $i\\in[K]$ , ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{v}[v^{\\otimes4}]\\langle a,b\\rangle=3d\\operatorname{Sym}(I^{\\otimes4})\\langle a,b\\rangle}\\\\ &{\\qquad\\qquad\\qquad=2d\\cdot a b^{T}+d\\cdot I\\cdot a^{T}b}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Plugging in the results of the above two cases in Equation 29, ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\therefore\\mathbb{E}\\left[\\nabla\\hat{f}_{m}(w_{m},v_{m};(x,y_{c}))\\cdot\\nabla\\hat{f}_{m}(w_{m},v_{m};(x,y_{c}))^{T}\\right]}\\\\ &{\\qquad=\\frac{1}{|\\mathcal{D}|^{2}K^{2}}\\displaystyle\\sum_{(x,y_{c}\\sim\\mathcal{D})}\\left[K(K-1)a b^{T}+2d K a b^{T}+d K\\cdot I\\cdot a^{T}b\\right]}\\\\ &{\\qquad\\qquad\\qquad(\\frac{1}{c^{\\frac{y}{2}}s_{c}\\sim\\mathcal{D})}}\\\\ &{\\qquad=\\frac{1}{|\\mathcal{D}|^{2}K}\\displaystyle\\sum_{(x,y_{c}\\sim\\mathcal{D})}\\left[(2d+K-1)\\mathbb{E}\\left[\\nabla f_{m}(w_{m};(x,y_{c}))\\nabla f_{m}(w_{m};(\\overline{{x}},\\overline{{y}}_{c}))^{T}\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\times\\frac{1}{c^{\\frac{y}{2}}s_{c}\\sim\\mathcal{D}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad+\\,d\\cdot I\\cdot\\mathbb{E}\\left[\\nabla f_{m}(w_{m};(x,y_{c}))\\nabla f_{m}(w_{m};(\\overline{{x}},\\overline{{y}}_{c}))^{T}\\right]\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Here, the randomness is under the sampled data. ", "page_idx": 37}, {"type": "text", "text": "For the sum over samples of $\\mathcal{D}$ , we have two cases, ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\nabla f_{m}(w_{\\overline{{m}}};(x,y_{c}))\\nabla f_{m}(w_{\\overline{{m}}};(\\overline{{x}},\\overline{{y}}_{c}))^{T}]=\\nabla F_{m}(w_{\\overline{{m}}})\\nabla F_{m}(w_{\\overline{{m}}})^{T}}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "2. If $(x,y_{c})=(\\overline{{x}},\\overline{{y}}_{c})$ . (Occurs $|\\mathcal D|$ times) ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\nabla f_{m}(w_{\\overline{{m}}};(x,y_{c}))\\nabla f_{m}(w_{\\overline{{m}}};(\\overline{{x}},\\overline{{y}}_{c}))^{T}]=\\nabla F_{m}(w_{\\overline{{m}}})\\nabla F_{m}(w_{\\overline{{m}}})^{T}+\\Sigma(w_{\\overline{{m}}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Combining both the cases, we get ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{(x,y_{c})\\sim\\mathcal{D}}[\\nabla f_{m}(w_{\\overline{{m}}};(x,y_{c}))\\nabla f_{m}(w_{\\overline{{m}}};(\\overline{{x}},\\overline{{y}}_{c}))^{T}]=|\\mathcal{D}|^{2}\\nabla F_{m}(w_{\\overline{{m}}})\\nabla F_{m}(w_{\\overline{{m}}})^{T}+|\\mathcal{D}|\\cdot\\Sigma(w_{\\overline{{m}}})\\nabla f_{m}(w_{\\overline{{m}}})^{T},}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Plugging in Equation 40 in Equation 37, ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{E}_{v_{m},(x,y_{0})\\sim\\mathcal{D}}[\\nabla\\widehat{f}_{m}(w_{m},v_{m};(x,y_{\\ell}))\\nabla\\widehat{f}_{m}(w_{m},v_{m};(x,y_{\\ell}))^{T}]}\\qquad}&{}\\\\ &{=\\frac{1}{|\\mathcal{D}|^{2}K}\\Bigg[(2d+K-1)|\\mathcal{D}|(|\\mathcal{D}|\\nabla F_{m}(w_{m})\\nabla F_{m}(w_{m})^{T}+\\Sigma(w_{m}))}\\\\ &{\\qquad\\qquad+d\\cdot|\\mathcal{D}|\\left(|\\mathcal{D}|\\cdot||\\nabla F_{m}(w_{m})||^{2}+\\mathfrak{u}(\\Sigma(w_{m}))\\right)\\Bigg]}\\\\ &{=\\frac{(2d+K-1)}{K}\\left(\\nabla F_{m}(w_{m})\\nabla F_{m}(w_{m})^{T}+\\frac{1}{|\\mathcal{D}|}\\Sigma(w_{m})\\right)}\\\\ &{\\qquad+\\frac{d}{K}\\left(||\\nabla F_{m}(w_{m})||^{2}+\\frac{1}{|\\mathcal{D}|}\\mathfrak{t}(\\Sigma(w_{m}))\\right)}\\\\ &{=\\frac{3d+K-1}{K}\\mathbb{E}_{(x,y_{\\ell})\\sim\\mathcal{D}}|\\nabla f_{m}(w_{m};(x,y_{\\ell}))|^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Hence for client $m$ , the expected norm of forward gradients under randomness of perturbations $v$ is, ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathbb{E}_{v_{m},(x,y_{c})\\sim\\mathcal{D}}||\\nabla\\hat{f}_{m}(w_{m},v_{m};(x,y_{c}))||^{2}=\\frac{3d+K-1}{K}\\mathbb{E}_{(x,y_{c})\\sim\\mathcal{D}}||\\nabla f_{m}(w_{m};(x,y_{c}))||^{2}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad=\\frac{3d+K-1}{K}||\\nabla F_{m}(w_{m})||^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "For $i^{t h}$ row of $\\mathbb{E}\\left[\\nabla\\hat{f}(w,v;\\mathcal{D})\\right]$ of Equation 28, ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\mathbb{E}\\left\\|\\nabla\\hat{f}_{i}(w_{[\\frac{(i-1)d}{M}+1,\\frac{i d}{M}]},v_{[\\frac{(i-1)d}{M}+1,\\frac{i d}{M}]};\\mathcal{D})\\right\\|^{2}=\\mathbb{E}\\left\\|\\nabla f_{i}(w_{[\\frac{(i-1)d}{M}+1,\\frac{i d}{M}]})\\right\\|^{2}}\\\\ {\\quad+\\displaystyle\\frac{1}{(\\widetilde{M})^{2}}\\sum_{m\\in\\widetilde{M}_{i}}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}\\mathbb{E}_{(x,y_{c})\\sim\\mathcal{D}}\\left\\|\\nabla\\hat{f}_{m}(w_{[\\frac{(i-1)d}{M}+1,\\frac{i d}{M}]},v_{[\\frac{(i-1)d}{M}+1,\\frac{i d}{M}]};(x,y_{c}))\\right\\|}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "The left-hand side expectation under the randomness of sampled data $\\mathcal{D}$ and subset of random perturbations $v$ . ", "page_idx": 38}, {"type": "text", "text": "Plugging in Equation 45 in the above equation and using $\\begin{array}{r}{\\overline{{\\boldsymbol{i}}}=\\left[\\frac{(i-1)\\boldsymbol{d}}{M}+1,\\frac{i d}{M}\\right]}\\end{array}$ , ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\mathbb{\\Sigma}_{v_{i};\\mathcal{D}}\\left|\\left|\\nabla\\hat{f}_{i}(w_{i},v_{i};\\mathcal{D})\\right|\\right|^{2}=\\mathbb{E}\\left||\\nabla f_{i}(w_{i})|\\right|^{2}+\\frac{(3d+K-1)}{(\\widetilde{M})^{2}K}\\sum_{m\\in\\widetilde{\\mathcal{M}}_{i}}||\\nabla F_{m}(w_{i})||^{2}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}}{|\\mathcal{D}_{r}|}\\right)^{2},\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Since $\\nabla\\hat{f}_{i}$ , $\\widetilde{\\forall\\mathcal{M}}\\subset\\mathcal{M}$ are independent of each other, we can compute the norm of $\\nabla\\hat{f}$ as follows, ", "page_idx": 39}, {"type": "equation", "text": "$$\n||\\nabla\\hat{f}(w,v;\\mathcal{D})||^{2}=\\mathbb{E}||\\nabla f(w)||^{2}+\\left(\\frac{3d+K-1}{(\\widetilde{M})^{2}K}\\right)\\sum_{m\\in\\mathcal{M}}\\left|\\left|\\nabla F_{m}(w_{m})\\right|\\right|^{2}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "equation", "text": "$$\n\\mathbb{E}||\\nabla f(w)||^{2}+\\left(\\frac{3d+K-1}{(\\widetilde{M})^{2}K}\\right)\\sum_{m\\in\\mathcal{M}}\\bigg|\\bigg|\\nabla F_{m}(w_{m})-\\nabla f(w_{m})+\\nabla f(w_{m})\\bigg|\\bigg|^{2}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|D|}-\\frac{n_{m,c}\\sigma_{t,m}}{|D_{m}|}\\right)\\bigg|^{2}.\n$$", "text_format": "latex", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{=\\mathbb{E}||\\nabla f(w)||^{2}+\\displaystyle\\left(\\frac{2(3d+K-1)}{(\\widetilde{M})^{2}K}\\right)\\sum_{m\\in\\mathcal{M}}\\left|\\left|\\nabla F_{m}(w_{\\overline{{m}}})-\\nabla f(w_{\\overline{{m}}})\\right|\\right|^{2}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}}}\\\\ {{+\\left(\\frac{2(3d+K-1)}{(\\widetilde{M})^{2}K}\\right)\\displaystyle\\sum_{m\\in\\mathcal{M}}\\left|\\left|\\nabla f(w_{\\overline{{m}}})\\right|\\right|^{2}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Using Assumption I.2 and limited participation rate of $s$ , ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\mathsf{\\Sigma}_{v,D}||\\nabla\\hat{f}(w,v;\\mathcal{D})||^{2}=\\mathbb{E}||\\nabla f(w)||^{2}+\\left(\\frac{2\\sigma_{g}^{2}(1-s)(3d+K-1)}{\\widetilde{M}K}\\right)\\sum_{m\\in M}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}}\\\\ {\\displaystyle+\\left(\\frac{2(3d+K-1)}{\\widetilde{M}K}\\right)\\mathbb{E}\\,||\\nabla f(w)||^{2}\\sum_{m\\in M}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Rearranging the terms, we get, ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{v,\\mathcal{D}}||\\nabla\\hat{f}(w,v;\\mathcal{D})||^{2}=\\mathbb{E}||\\nabla f(w)||^{2}\\left(1+\\left(\\frac{2(3d+K-1)}{\\widetilde M K}\\right)\\displaystyle\\sum_{m\\in\\mathcal{M}}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}\\right)}\\\\ {+\\left(\\frac{2\\sigma_{g}^{2}(1-s)(3d+K-1)}{\\widetilde M K}\\right)\\displaystyle\\sum_{m\\in\\mathcal{M}}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}~(52)}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "I.4 Convergence Rate of SPRY ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "The general template for the convergence analysis of SPRY is similar to FEDADAM, hence we will follow Theorem 2 of AFO [25]. Our aim here is to highlight the differences in treatment of our gradient estimator $\\nabla\\hat{f}_{m}\\;\\forall m\\in[M]$ , and the aggregate global gradient $\\nabla f$ as shown in Equation 9. ", "page_idx": 39}, {"type": "text", "text": "Theorem I.6. Under the assumptions on $L$ -smoothness (Asmp I.1), bounded global variance $\\sigma_{g}^{2}$ of accumulated gradients (Asmp I.2), and bound on gradient magnitude $G$ (Asmp I.3) and the following conditions on the local learning rate \u03b7\u2113, ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\eta_{\\ell}=\\operatorname*{min}\\left\\{\\mathcal{O}\\left(\\frac{\\tau^{2}}{\\sqrt{\\beta_{2}}\\eta G L}\\right)^{\\frac12},\\mathcal{O}\\left(\\frac{1}{\\sqrt{\\beta_{2}}G}\\right),\\mathcal{O}\\left(\\frac{\\tau^{3}}{\\sqrt{\\beta_{2}}\\sqrt{1-\\beta_{2}}G^{2}}\\right)^{\\frac12},\\right.}\\\\ &{\\qquad\\qquad\\qquad\\left.\\mathcal{O}\\left(\\frac{\\widetilde{M}K}{\\beta_{2}G\\left(3d+K-1\\right)\\sum_{m\\in[M]}\\sum_{c\\in[C]}\\alpha_{m,c}^{2}}\\right)\\right\\};}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "SPRY satisfies the following bound, ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{min}_{0\\le r\\le R}\\mathbb{E}_{r}||\\nabla f(w^{(r)})||^{2}\\le\\frac{f(w^{(0)})-\\mathbb{E}_{R}[f(w^{(R)})]}{\\eta R}}\\\\ &{\\qquad+\\left(2+\\frac{\\eta\\eta_{\\ell}L}{2\\tau^{2}}+\\frac{\\sqrt{1-\\beta_{2}}G\\eta_{\\ell}}{\\tau^{3}}\\right)\\left(\\frac{\\sigma_{g}^{2}(1-s)(3d+K-1)}{\\widetilde{M}K}\\right)\\sum_{m\\in\\mathcal{M}}\\sum_{c\\in[C]}\\alpha_{m,c}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "where $R$ is the total round count, $w\\,\\in\\,\\mathbb{R}^{d}$ are the trainable weights, $\\boldsymbol{v}\\in\\mathbb{R}^{d}$ are the random perturbations, $K$ is the count of random perturbations per batch, $\\eta$ is the global learning rate, $\\tau$ is adaptability hyperparameter, $s$ is client sampling rate. The rest of the symbols are defined in Theorem I.4. ", "page_idx": 40}, {"type": "text", "text": "Proof. As shown in Equation 7, an update of the model weights $w$ at server-side in SPRY looks like, ", "page_idx": 40}, {"type": "equation", "text": "$$\nw^{(r+1)}=w^{(r)}+\\eta\\frac{\\Delta^{(r)}}{\\sqrt{\\Lambda^{(r)}}+\\tau}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Using Assumption I.1 and then the server-side update rule, we have ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f(w^{(r+1)})\\leq f(w^{(r)})+\\left\\langle\\nabla f(w^{(r)}),w^{(r+1)}-w^{(r)}\\right\\rangle+\\displaystyle\\frac{L}{2}||w^{(r+1)}-w^{(r)}||^{2}}\\\\ &{\\quad\\quad\\quad=f(w^{(r)})+\\eta\\left\\langle\\nabla f(w^{(r)}),\\frac{\\Delta^{(r)}}{\\sqrt{\\Lambda^{(r)}}+\\tau}\\right\\rangle+\\displaystyle\\frac{\\eta^{2}L}{2}\\sum_{i\\in[d]}\\frac{(\\Delta_{i}^{(r)})^{2}}{\\left(\\sqrt{\\Lambda_{i}^{(r)}}+\\tau\\right)^{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Taking expectation over randomness of round $r$ and simplifying the terms, ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{\\tilde{c}}_{r}[f(w^{(r+1)})]\\leq f(w^{(r)})+\\eta\\underbrace{\\Bigg\\langle\\nabla f(w^{(r)}),\\mathbb{E}_{r}\\left[\\frac{\\Delta^{(r)}}{\\sqrt{\\beta\\Lambda^{(r-1)}}+\\tau}\\right]\\Bigg\\rangle}_{R_{1}}+\\frac{\\eta^{2}L}{2}\\sum_{i\\in[d]}\\mathbb{E}_{r}\\left[\\frac{(\\Delta_{i}^{(r)})^{2}}{(\\sqrt{\\Lambda_{i}^{(r)}}+\\tau)^{2}}\\right]}}\\\\ &{}&{+\\,\\eta\\underbrace{\\Bigg\\langle\\nabla f(w^{(r)}),\\mathbb{E}_{r}\\left[\\frac{\\Delta^{(r)}}{\\sqrt{\\Lambda^{(r)}}+\\tau}-\\frac{\\Delta^{(r)}}{\\sqrt{\\beta\\Lambda^{(r-1)}}+\\tau}\\right]\\Bigg\\rangle}_{R_{2}}\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Bounds for $R_{2}$ are derived in the exactly same manner as \u201cBounding $R_{2}{}^{,}$ in Theorem 2 of FEDADAM [25], ", "page_idx": 40}, {"type": "equation", "text": "$$\nR_{2}\\leq\\sqrt{1-\\beta_{2}}\\mathbb{E}_{r}\\sum_{j=1}^{d}\\frac{G}{\\tau}\\times\\left[\\frac{(\\Delta_{j}^{(r)})^{2}}{\\sqrt{\\Lambda_{j}^{(r)}}+\\tau}\\right]\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Bounding $R_{1}$ has a different treatment due to the distinct aggregation strategy of SPRY: ", "page_idx": 40}, {"type": "equation", "text": "$$\nR_{1}=\\left<\\nabla f(w^{(r)}),\\mathbb{E}_{r}\\left[\\frac{\\Delta^{(r)}}{\\sqrt{\\beta\\Lambda^{(r-1)}}+\\tau}\\right]\\right>\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Since $\\Delta^{(r)}$ is piece-wise made of aggregations of forward gradients for several parts of the model weights, as shown in Equation 12, we first center each gradient piece for the computation of the squared norm, ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\therefore R_{1}=\\left\\langle\\nabla f(w^{(r)}),\\mathbb{E}_{r}\\left[\\frac{-\\eta_{\\ell}\\nabla\\hat{f}(w^{(r)},v^{(r)},\\mathcal{D})}{\\sqrt{\\beta\\Lambda^{(r-1)}}+\\tau}\\right]\\right\\rangle\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Using $a b\\leq(a^{2}+b^{2})/2$ , ", "page_idx": 40}, {"type": "equation", "text": "$$\nR_{1}\\leq-\\frac{\\eta_{\\ell}}{2}\\sum_{j\\in[d]}\\frac{[\\nabla f(w^{(r)})]^{2}}{\\sqrt{\\beta\\Lambda_{j}^{(r-1)}}+\\tau}+\\frac{\\eta_{\\ell}}{2}\\mathbb{E}_{r}||\\nabla\\hat{f}(w^{(r)},v^{r},\\mathcal{D})||^{2}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Using the result of Lemma I.5, ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle,R_{1}\\leq-\\frac{\\eta_{\\ell}}{2}\\sum_{j\\in[d]}\\frac{[\\nabla f(w^{(r)})]^{2}}{\\sqrt{\\beta\\Lambda_{j}^{(r-1)}}+\\tau}+\\frac{\\eta_{\\ell}}{2}\\left(\\frac{2\\sigma_{g}^{2}(1-s)(3d+K-1)}{\\widetilde M K}\\right)\\sum_{m\\in M}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal D|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal D_{m}|}\\right)^{2}}\\\\ {\\displaystyle\\qquad+\\,\\frac{\\eta_{\\ell}}{2}\\left(1+\\left(\\frac{2(3d+K-1)}{\\widetilde M K}\\right)\\sum_{m\\in M}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal D|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal D_{m}|}\\right)^{2}\\right)\\mathbb{E}_{r}\\|\\nabla f(w^{(r)})\\|^{2}}\\\\ {\\displaystyle\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Putting $R_{1}$ and $R_{2}$ bounds in Equation 58, ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{E}_{r}[f(w^{(r+1)})]\\leq f(w^{(r)})-\\frac{\\eta\\eta_{\\ell}}{2}\\sum_{\\ell\\in[d]}\\frac{[\\nabla f(w^{(r)})]^{2}}{\\sqrt{\\beta\\Lambda_{j}^{(r-1)}}+\\tau}}}\\\\ &{\\quad+\\,\\frac{\\eta\\eta_{\\ell}}{2}\\left(\\frac{2\\sigma_{\\ell}^{2}(1-s)(3A+K-1)}{\\widetilde{M}K}\\right)\\sum_{m\\in M_{\\star}\\in[c]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}}\\\\ &{\\quad+\\,\\frac{\\eta\\eta_{\\ell}}{2}\\left(1+\\left(\\frac{2(3d+K-1)}{\\widetilde{M}K}\\right)\\sum_{m\\in M_{\\star}\\in[c]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}\\right)\\mathbb{E}_{r}|\\nabla f(w^{(r)})}\\\\ &{\\quad+\\,\\frac{\\eta^{2}L}{2}\\sum_{\\ell\\in[d]}\\mathbb{E}_{r}\\left[\\frac{(\\Delta_{i}^{(r)})^{2}}{\\Lambda_{i}^{(r)}+\\tau^{2}}\\right]+\\frac{\\eta\\sqrt{1-\\beta_{2}}G}{\\tau}\\sum_{\\ell\\in[d]}\\mathbb{E}_{r}\\left[\\frac{(\\Delta_{i}^{(r)})^{2}}{\\sqrt{\\Lambda_{i}^{(r)}}+\\tau}\\right]\\qquad(64)}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Summing over $r=0$ to $R-1$ and using telescoping sum, we get ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{z}_{R}[f(w^{(t)})]\\leq f(w^{(0)})-\\frac{\\eta\\eta_{t}}{2}\\sum_{r=0}^{R-1}\\sum_{\\ell\\in\\mathcal{T}}\\frac{\\left|\\nabla f(w^{(t)})\\right|^{2}}{\\sqrt{\\beta\\Delta_{j}^{(r-1)}}+\\tau}}\\\\ &{\\qquad\\qquad\\qquad+\\frac{\\eta\\eta_{t}R}{2}\\left(\\frac{2\\sigma_{g}^{2}(1-s)(3d+K-1)}{\\widetilde M K}\\right)\\sum_{m\\in\\mathcal{M}_{\\epsilon}\\in\\mathcal{T}\\backslash\\left(\\frac{n_{c}}{\\beta}\\right)}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,\\epsilon}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}}\\\\ &{\\qquad+\\frac{\\eta\\eta_{t}}{2}\\left(1+\\left(\\frac{2(3d+K-1)}{\\widetilde M K}\\right)\\sum_{m\\in\\mathcal{M}_{\\epsilon}\\in\\mathcal{C}\\backslash\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,\\epsilon}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}}\\right)\\underset{r=0}{\\overset{R-1}{\\sum}}\\mathbb{E}_{r}\\Vert\\nabla f(w^{\\prime})}\\\\ &{\\qquad+\\left(\\frac{\\eta^{2}L}{2}+\\frac{\\eta\\sqrt{1-\\beta_{2}}G}{\\tau}\\right)\\underset{r\\geq0}{\\overset{R-1}{\\sum}}\\sum_{k\\in\\mathcal{V}\\backslash\\left[\\frac{(\\Delta_{k}^{(r)})^{2}}{\\widetilde A_{k}^{(r)}+\\tau^{2}}\\right]}}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Bounding $R_{4}$ follows a similar derivation as \u201cBounding $R_{1}$ \u201d, ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{{R_{4}}=\\mathbb{E}\\displaystyle\\sum_{r=0}^{R-1}\\sum_{i\\in[d]}\\frac{(\\Delta_{i}^{(r)})^{2}}{\\Lambda_{i}^{(r)}+\\tau^{2}}=\\mathbb{E}\\displaystyle\\sum_{r=0}^{R-1}\\sum_{i\\in[d]}\\frac{[-\\eta\\ell\\nabla\\hat{f}(w^{(r)},v^{(r)},\\mathcal{D})]_{i}^{2}}{\\Lambda_{i}^{(r)}+\\tau^{2}}}\\\\ &{\\phantom{\\sum_{a}^{a}}\\le\\eta_{\\ell}^{2}\\mathbb{E}\\displaystyle\\sum_{r=0}^{R-1}\\left\\|\\frac{\\nabla\\hat{f}(w^{(r)},v^{(r)},\\mathcal{D})}{\\tau^{2}}\\right\\|^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Using Lemma I.5 once again, ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\therefore R_{4}\\leq\\frac{\\eta_{\\ell}^{2}}{\\tau^{2}}\\left(1+\\left(\\frac{2(3d+K-1)}{\\widetilde M K}\\right)\\sum_{m\\in\\cal M}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}\\right)\\mathbb{E}\\sum_{r=0}^{R-1}||\\nabla f(w^{(r)})||^{2}}\\\\ {+\\,\\frac{\\eta_{\\ell}^{2}}{\\tau^{2}}\\left(\\frac{2\\sigma_{g}^{2}(1-s)R(3d+K-1)}{\\widetilde M K}\\right)\\sum_{m\\in\\cal M}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}\\,\\qquad\\qquad(6)}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Updating Equation 65 with the bounds of $R_{4}$ , ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{H}[f(w^{(R)})]\\leq f(w^{(0)})-\\frac{\\eta\\eta}{2}\\displaystyle\\sum_{r=0}^{R-1}\\sum_{\\ell\\in[d]}\\frac{\\left[\\nabla f(w^{(r)})\\right]^{2}}{\\sqrt{\\beta\\lambda_{j}}}}\\\\ &{\\qquad+\\frac{\\eta\\eta\\gamma R}{2}\\left(\\frac{2\\sigma_{g}^{2}(1-s)(3d+K-1)}{\\sqrt{d K}}\\right)\\displaystyle\\sum_{m\\in A\\setminus C[c]}\\left(\\frac{n_{r}}{|D|}-\\frac{n_{m,\\alpha\\in C}}{|D|}\\right)^{2}}\\\\ &{\\qquad+\\frac{\\eta\\eta\\gamma}{2}\\left(1+\\left(\\frac{2(3d+K-1)}{\\sqrt{d K}}\\right)\\displaystyle\\sum_{m\\in A\\setminus C[c]}\\left(\\frac{n_{x}}{|D|}-\\frac{n_{m,\\alpha\\in C}}{|D_{m}|}\\right)^{2}\\right)\\displaystyle\\sum_{r=0}^{R-1}\\mathbb{E}_{r}|\\nabla f(w^{(r)})|^{2}}\\\\ &{\\qquad+\\left(\\frac{\\eta^{2}L}{2}+\\frac{\\eta\\sqrt{1-\\beta_{2}}G}{\\tau}\\right)\\displaystyle\\frac{\\eta_{r}^{2}}{\\tau}\\left(1+\\left(\\frac{2(3d+K-1)}{\\sqrt{d K}}\\right)\\displaystyle\\sum_{m\\in A\\setminus C[c]}\\left(\\frac{n_{r}}{|D|}-\\frac{n_{m,\\alpha\\in C}}{|D|}\\right)^{2}\\right)\\displaystyle\\sum_{r=0}^{R}}\\\\ &{\\qquad+\\left(\\frac{\\eta^{2}L}{2}+\\frac{\\eta\\sqrt{1-\\beta_{2}}G}{\\tau}\\right)\\displaystyle\\frac{\\eta_{r}^{2}}{\\tau^{2}}\\left(\\frac{2\\sigma_{g}^{2}(1-s)R(3d+K-1)}{\\sqrt{d K}}\\right)\\displaystyle\\sum_{m\\in A\\setminus C[c]}\\left(\\frac{n_{r}}{|D|}-\\frac{n_{m,\\alpha\\in C}}{|D_{m}|}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Rearranging the terms, ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{r=0}{\\overset{!}{\\sum}}\\underset{\\varphi\\in[\\dot{\\pi}]}{\\sum}\\frac{\\vert\\nabla f(w^{(r)})\\vert^{2}}{\\sqrt{\\beta}\\Lambda^{\\int-1}}+\\frac{f\\left(w^{(0)}\\right)-\\mathbb{E}_{R}[f(w^{(R)})]}{\\eta}}\\\\ &{\\quad\\quad+\\left(\\frac{2R e_{0}^{2}(1-s)(3d+K-1)}{\\sqrt{d K}}\\right)\\underset{m\\in\\mathbb{A}\\times\\{c\\}}{\\sum}\\left(\\frac{n_{c}}{\\vert\\mathcal{D}\\vert}-\\frac{n_{m},\\alpha_{c}}{\\vert\\mathcal{D}\\vert}\\right)^{2}}\\\\ &{\\quad\\quad+\\left(1+\\left(\\frac{2(3d+K-1)}{\\tilde{M}K}\\right)\\underset{m\\in\\mathbb{A}\\times\\{c\\}}{\\sum}\\left(\\frac{n_{c}}{\\vert\\mathcal{D}\\vert}-\\frac{n_{m},\\alpha_{c}}{\\vert\\mathcal{D}\\vert}\\right)^{2}\\right)\\underset{r=0}{\\overset{...}{\\sum}}\\mathbb{E}_{r}\\Vert\\nabla f(w^{(r)})\\Vert^{2}}\\\\ &{\\quad\\quad+\\left(\\eta L+\\frac{2\\sqrt{1-\\beta}\\mathcal{L}}{\\tau}\\right)\\frac{\\eta_{r}}{\\tau^{2}}\\left(1+\\left(\\frac{2(3d+K-1)}{\\tilde{M}K}\\right)\\underset{m\\in\\mathbb{A}\\times\\{c\\}}{\\sum}\\left(\\frac{n_{c}}{\\vert\\mathcal{D}\\vert}-\\frac{n_{m},\\alpha_{c}}{\\vert\\mathcal{D}\\vert}\\right)\\right)\\underset{r=0}{\\overset{...}{\\sum}}\\mathbb{E}_{r}\\Vert\\nabla f(w^{(r)})\\Vert^{2}\\underset{r=0}{\\overset{...}{\\sum}}\\mathbb{E}_{r}\\Vert\\nabla f(w^{(r)})\\Vert}\\\\ &{\\quad\\quad+\\left(\\frac{\\eta L}{2}+\\frac{\\sqrt{1-\\beta}\\mathcal{L}}{\\tau}\\right)\\frac{\\eta_{r}}{\\tau^{2}}\\left(\\frac{R e_{0}^{2}(1-s)(3d+K-1)}{\\tilde{M}K}\\right)\\underset{m\\in\\mathbb{A}\\times\\{c\\}}{\\sum}\\left(\\frac{n_{c}}{\\vert\\mathcal{D}\\vert}-\\frac{n_{m},\\alpha_{c}}{\\vert\\mathcal{D}\\vert}\\right)^{2}\\underset{r=0}{\\overset{...}{\\sum}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Getting a lower bound for the left hand side term through using the fact $\\sqrt{\\Lambda^{(r-1)}}\\,\\le\\,\\eta_{\\ell}K G$ from Theorem 2 of AFO [25], ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\sum_{r=0}^{R-1}\\sum_{j=1}^{d}\\frac{\\mathbb{E}_{r}[\\nabla f(w^{(r)})]_{j}^{2}}{\\sqrt{\\beta_{2}\\Lambda_{j}^{(r-1)}}+\\tau}\\ge\\sum_{r=0}^{R-1}\\sum_{j=1}^{d}\\frac{\\mathbb{E}_{r}[\\nabla f(w^{(r)})]_{j}^{2}}{\\sqrt{\\beta_{2}}\\eta_{\\ell}K G+\\tau}\\ge\\frac{R}{\\sqrt{\\beta_{2}}\\eta_{\\ell}K G+\\tau}\\operatorname*{min}_{0\\le r\\le R}\\mathbb{E}_{r}\\|\\nabla f(w^{(r)})\\|^{2}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\cdot\\frac{R}{\\sqrt{\\beta_{2}}\\eta_{t}K G+\\tau}\\operatorname*{min}_{0\\le r\\le R}\\mathbb{E}_{r}|\\nabla f(w^{(r)})||^{2}\\le\\frac{f(w^{(0)})-\\mathbb{E}_{R}[f(w^{(R)})]}{\\eta}}\\\\ &{\\qquad+\\left(2+\\frac{\\eta\\eta_{t}L}{2\\tau^{2}}+\\frac{\\sqrt{1-\\beta_{2}}G\\eta_{t}}{\\tau^{3}}\\right)\\left(\\frac{R\\sigma_{g}^{2}(1-s)(3d+K-1)}{\\widetilde{M}K}\\right)\\sum_{m\\in\\cal A}\\sum_{c\\in[c]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)}\\\\ &{\\qquad+\\left(1+\\left(\\frac{2(3d+K-1)}{\\widetilde{M}K}\\right)\\sum_{m\\in\\cal A}\\sum_{c\\in[c]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}\\right)\\mathbb{E}_{r=0}^{\\ R-1}|\\nabla f(w^{(r)})||^{2}}\\\\ &{\\qquad+\\left(\\eta L+\\frac{2\\sqrt{1-\\beta_{2}}G}{\\tau}\\right)\\frac{\\eta_{t}}{\\tau^{2}}\\left(1+\\left(\\frac{2(3d+K-1)}{\\widetilde{M}K}\\right)\\sum_{m\\in\\cal A}\\sum_{c\\in[c]}\\left(\\frac{n_{c}}{|\\mathcal{D}|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal{D}_{m}|}\\right)^{2}\\right)\\mathbb{E}_{r=0}^{\\ R-1}}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Considering the coefficients of $\\mathbb{E}||\\nabla f(w^{(r)})||^{2}$ terms, conditioning on the following inequality, ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\frac{R}{\\sqrt{\\beta_{2}}\\eta_{\\ell}K G+\\tau}\\ge\\left(\\frac{\\eta\\eta_{\\ell}L}{\\tau^{2}}+\\frac{2\\eta_{\\ell}\\sqrt{1-\\beta_{2}}G}{\\tau^{3}}+1\\right)\\left(1+\\frac{2(3d+K-1)}{\\widetilde M K}\\sum_{m\\in[M]}\\sum_{c\\in[C]}\\left(\\frac{n_{c}}{|\\mathcal D|}-\\frac{n_{m,c}\\partial_{m,c}}{|\\mathcal D_{m}|}\\right)\\right),\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "We get the following condition on the local learning rate, ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\eta_{\\ell}=\\operatorname*{min}\\left\\{\\mathcal{O}\\left(\\frac{\\tau^{2}}{\\sqrt{\\beta_{2}}\\eta G L}\\right)^{\\frac{1}{2}},\\mathcal{O}\\left(\\frac{1}{\\sqrt{\\beta_{2}}G}\\right),\\mathcal{O}\\left(\\frac{\\tau^{3}}{\\sqrt{\\beta_{2}}\\sqrt{1-\\beta_{2}}G^{2}}\\right)^{\\frac{1}{2}},\\right.}\\\\ &{\\qquad\\qquad\\qquad\\left.\\mathcal{O}\\left(\\frac{\\widetilde{M}K}{\\beta_{2}G\\left(3d+K-1\\right)\\sum_{m\\in[M]}\\sum_{c\\in[C]}\\Big(\\frac{n_{c}}{|D|}-\\frac{n_{m,c}\\alpha_{c}}{|D_{m}|}\\Big)^{2}}\\right)\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "for the following bound on the gradient norm, ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{)\\leq r\\leq R}{\\operatorname*{min}}\\mathbb{E}_{r}||\\nabla f(w^{(r)})||^{2}\\leq\\frac{f(w^{(0)})-\\mathbb{E}_{R}[f(w^{(R)})]}{\\eta R}}\\\\ &{\\qquad+\\left(2+\\frac{\\eta\\eta_{\\ell}L}{2\\tau^{2}}+\\frac{\\sqrt{1-\\beta_{2}}G\\eta_{\\ell}}{\\tau^{3}}\\right)\\left(\\frac{\\sigma_{g}^{2}(1-s)(3d+K-1)}{\\widetilde M K}\\right)\\underset{m\\in\\mathcal{M}}{\\sum}_{K}\\underset{c\\in[C]}{\\sum}\\left(\\frac{n_{c}}{|\\mathcal D|}-\\frac{n_{m,c}\\alpha_{c}}{|\\mathcal D_{m}|}\\right)^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 44}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 44}, {"type": "text", "text": "Justification: The claims on (a) SPRY consuming significantly less memory than its backpropagation-based counterparts, (b) SPRY achieving higher accuracy than its zeroorder counterparts, and comparable accuracy to the backpropagation-based counterparts, (c) SPRY running faster in terms of wallclock time to convergence than its zero-order counterparts are proved in Section 5.2, 5.1, and 5.3 respectively. The theoretical claims are discussed and proved in Section 4 and Appendix I. The claims on direct application of Forward-mode AD in an FL setup being inefficient and inaccurate are supported by experiments shown in Appendix G. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 44}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 44}, {"type": "text", "text": "Justification: The limitations and potential paths for future work are discussed in Appendix C. Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 44}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: The assumptions and proofs are listed in detail in Appendix I. ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 45}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: The details about implementation and experimental setup are given at the onset of Section 5. The pseudocode is in Appendix E, and each part of SPRY is explained in Section 3. ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. ", "page_idx": 45}, {"type": "text", "text": "In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 46}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 46}, {"type": "text", "text": "Justification: The source code is currently available as supplementary material accompanying this work and an anonymized version is also available here. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 46}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 46}, {"type": "text", "text": "Justification: The experimental setting is described in Section 5. Full details about datasets, their splits, and hyperparameters are given in Appendix B. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 46}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 46}, {"type": "text", "text": "Justification: Experimental variance related to the main results in the paper, across 3 differently seeded runs is given in Appendix H.3. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. ", "page_idx": 46}, {"type": "text", "text": "\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 47}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 47}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 47}, {"type": "text", "text": "Justification: Compute resources are discussed at the onset of Section 5. Details on memory consumption are given in Section 5.2. Time to convergence is discussed in Section 5.3. ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 47}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 47}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Justification: Our work does not involve human subjects. All the experiments are done on open-source datasets, which are widely used in the natural language community. Moreover, the goal of SPRY is to enable crowd-sourcing compute resources to finetune LLMs, without making private data accessible to a third party. ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 47}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 47}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Justification: The positive and negative broader impact is discussed in Appendix D. Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 48}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 48}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Justification: We have not created any new models or new data. Our main goal is to finetune the existing pre-trained language models. The datasets we have used are open-source, and free-to-use. The license information of datasets is given in Appendix B. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 48}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 48}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 48}, {"type": "text", "text": "Justification: Licenses for all the datasets are stated in Appendix B. Our work is within the usage bounds of each of the datasets. Dataset URLs are also provided under the references section. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 49}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 49}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 49}, {"type": "text", "text": "Justification: The source code (also available as a supplemental material) of SPRY comes with a detailed README.md, explaining how to run the presented experiments of our algorithm and its counterpart baselines. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 49}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 49}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 49}, {"type": "text", "text": "Justification: Our work does not involve crowdsourcing and research with human subjects. Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 49}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 49}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 50}, {"type": "text", "text": "Justification: Our work does not involve research with or on human subjects. Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 50}]