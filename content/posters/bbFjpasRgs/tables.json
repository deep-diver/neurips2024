[{"figure_path": "bbFjpasRgs/tables/tables_7_1.jpg", "caption": "Table 3: Efficiency gains for semantic segmentation with risk control via UCB (Prop. 2) on Cityscapes. We evaluate for different risks (\u00a7 3.2), confidence measures (\u00a7 5.2) and risk levels \u20ac. Displayed values denote relative improvement over last-layer exiting (in %) in terms of mean exit layer or floating-point operations (GFLOPS). The test risk is successfully controlled in all cases.", "description": "This table presents the efficiency gains achieved by using different risk control methods and confidence measures for semantic segmentation on the Cityscapes dataset.  It shows the improvement in mean exit layer and GFLOPS over the last-layer exiting method, while maintaining the user-specified risk level. The results are broken down by different risk types, confidence measures (Top-1, Top-Diff, Entropy), and aggregation methods (Mean, Quantile, Patch).", "section": "5.2 Semantic Segmentation"}, {"figure_path": "bbFjpasRgs/tables/tables_19_1.jpg", "caption": "Table 2: Efficiency gains for various EENNs on ImageNet, for risk control via CRC (Prop. 1) or UCB (Prop. 2) and calibration set size n \u2208 {100, 1000}. Displayed values denote relative improvement over last-layer exiting in terms of mean exit layer (in %). The test risk is successfully controlled in all cases. Results focus on small risk levels e \u2208 {0.01, 0.05}, which are of higher practical interest.", "description": "This table presents the efficiency gains achieved by different Early-Exit Neural Networks (EENNs) on the ImageNet dataset when employing risk control methods.  It shows the relative improvement in the average exit layer (and thus computational savings) for various risk levels (epsilon) and calibration set sizes, using two different risk control approaches (CRC and UCB).  The table is separated into four parts, each illustrating a combination of risk metric (performance gap or consistency) and risk control method.", "section": "5.1 Image Classification"}, {"figure_path": "bbFjpasRgs/tables/tables_22_1.jpg", "caption": "Table 2: Efficiency gains for various EENNs on ImageNet, for risk control via CRC (Prop. 1) or UCB (Prop. 2) and calibration set size n \u2208 {100, 1000}. Displayed values denote relative improvement over last-layer exiting in terms of mean exit layer (in %). The test risk is successfully controlled in all cases. Results focus on small risk levels e \u2208 {0.01, 0.05}, which are of higher practical interest.", "description": "This table shows the efficiency gains achieved by different early-exit neural network models on the ImageNet dataset for various risk control levels.  The efficiency gains are measured as the relative improvement in the mean exit layer compared to a full network evaluation. The table considers different risk metrics and model architectures, providing a comprehensive evaluation of the proposed risk control method's effectiveness.", "section": "5.1 Image Classification"}, {"figure_path": "bbFjpasRgs/tables/tables_22_2.jpg", "caption": "Table 2: Efficiency gains for various EENNs on ImageNet, for risk control via CRC (Prop. 1) or UCB (Prop. 2) and calibration set size n \u2208 {100, 1000}. Displayed values denote relative improvement over last-layer exiting in terms of mean exit layer (in %). The test risk is successfully controlled in all cases. Results focus on small risk levels \u2208 {0.01, 0.05}, which are of higher practical interest.", "description": "This table shows the efficiency gains achieved by different Early-Exit Neural Networks (EENNs) on the ImageNet dataset when employing risk control methods.  The gains are presented as the percentage improvement in the average exit layer compared to a model using the full network.  Two risk control methods are compared: Conformal Risk Control (CRC) and Upper Confidence Bound (UCB), each tested with calibration set sizes of 100 and 1000.  The table is broken down by risk type (performance gap and consistency, both for predictions and distributions), and shows the results for different risk levels (0.01 and 0.05).", "section": "5.1 Image Classification"}, {"figure_path": "bbFjpasRgs/tables/tables_22_3.jpg", "caption": "Table 2: Efficiency gains for various EENNs on ImageNet, for risk control via CRC (Prop. 1) or UCB (Prop. 2) and calibration set size n \u2208 {100, 1000}. Displayed values denote relative improvement over last-layer exiting in terms of mean exit layer (in %). The test risk is successfully controlled in all cases. Results focus on small risk levels e \u2208 {0.01, 0.05}, which are of higher practical interest.", "description": "This table shows the efficiency gains achieved by different Early-Exit Neural Networks (EENNs) on the ImageNet dataset when using risk control.  The efficiency is measured as the relative improvement in the mean exit layer compared to a full network. Two risk control methods, CRC and UCB, are compared at two different calibration set sizes (n=100 and n=1000).  Results for low risk levels (0.01 and 0.05) are highlighted, as these are more relevant in practical applications.", "section": "5.1 Image Classification"}, {"figure_path": "bbFjpasRgs/tables/tables_22_4.jpg", "caption": "Table 2: Efficiency gains for various EENNs on ImageNet, for risk control via CRC (Prop. 1) or UCB (Prop. 2) and calibration set size n \u2208 {100, 1000}. Displayed values denote relative improvement over last-layer exiting in terms of mean exit layer (in %). The test risk is successfully controlled in all cases. Results focus on small risk levels e \u2208 {0.01, 0.05}, which are of higher practical interest.", "description": "This table presents the efficiency gains achieved by different early-exit neural networks (EENNs) on the ImageNet dataset.  The gains are calculated as the relative improvement in the mean exit layer compared to a full model, after applying risk control techniques (CRC and UCB) to manage the risk of early-exiting.  Results are shown for different risk levels (epsilon) and calibration set sizes.  The focus is on small risk levels (0.01 and 0.05) which are more relevant to practical applications.", "section": "5.1 Image Classification"}, {"figure_path": "bbFjpasRgs/tables/tables_24_1.jpg", "caption": "Table 3: Efficiency gains for semantic segmentation with risk control via UCB (Prop. 2) on Cityscapes. We evaluate for different risks (\u00a7 3.2), confidence measures (\u00a7 5.2) and risk levels \u20ac. Displayed values denote relative improvement over last-layer exiting (in %) in terms of mean exit layer or floating-point operations (GFLOPS). The test risk is successfully controlled in all cases.", "description": "This table presents the efficiency gains achieved by using the proposed risk control method for semantic segmentation on the Cityscapes dataset.  It shows the improvements in terms of mean exit layer and GFLOPS, categorized by different risk types, confidence measures, and risk levels. The results demonstrate the effectiveness of the method while maintaining controlled risk levels. ", "section": "5.2 Semantic Segmentation"}, {"figure_path": "bbFjpasRgs/tables/tables_24_2.jpg", "caption": "Table 3: Efficiency gains for semantic segmentation with risk control via UCB (Prop. 2) on Cityscapes. We evaluate for different risks (\u00a7 3.2), confidence measures (\u00a7 5.2) and risk levels \u20ac. Displayed values denote relative improvement over last-layer exiting (in %) in terms of mean exit layer or floating-point operations (GFLOPS). The test risk is successfully controlled in all cases.", "description": "This table presents the efficiency gains achieved using different risk control strategies for semantic segmentation on the Cityscapes dataset.  It shows the improvement in terms of the average number of layers processed and the number of floating-point operations (FLOPS) compared to using the full model. Various risk levels, confidence measures, and risk types are used to assess the impact on efficiency. The test risk is consistently controlled in all scenarios.", "section": "5.2 Semantic Segmentation"}, {"figure_path": "bbFjpasRgs/tables/tables_24_3.jpg", "caption": "Table 3: Efficiency gains for semantic segmentation with risk control via UCB (Prop. 2) on Cityscapes. We evaluate for different risks (\u00a7 3.2), confidence measures (\u00a7 5.2) and risk levels e. Displayed values denote relative improvement over last-layer exiting (in %) in terms of mean exit layer or floating-point operations (GFLOPS). The test risk is successfully controlled in all cases.", "description": "This table presents the efficiency gains obtained from using different risk control methods and confidence measures for semantic segmentation on the Cityscapes dataset.  It shows improvements in mean exit layer and GFLOPS, indicating faster inference speeds while maintaining controlled risk levels.", "section": "5.2 Semantic Segmentation"}, {"figure_path": "bbFjpasRgs/tables/tables_24_4.jpg", "caption": "Table 2: Efficiency gains for various EENNs on ImageNet, for risk control via CRC (Prop. 1) or UCB (Prop. 2) and calibration set size n \u2208 {100, 1000}. Displayed values denote relative improvement over last-layer exiting in terms of mean exit layer (in %). The test risk is successfully controlled in all cases. Results focus on small risk levels e \u2208 {0.01, 0.05}, which are of higher practical interest.", "description": "This table presents the efficiency gains achieved by different early-exit neural network models on the ImageNet dataset when employing risk control methods.  It shows the relative improvement in the average exit layer (and thus computational speedup) compared to using the full model, for various risk levels (0.01 and 0.05) and different risk control techniques (CRC and UCB). The results are presented separately for different model architectures (MSDNet, DVIT, L2W-DEN, Dyn-Perc) and for two different calibration set sizes (n=100 and n=1000). The table demonstrates that substantial efficiency gains can be obtained even while maintaining the specified risk level.", "section": "5.1 Image Classification"}]