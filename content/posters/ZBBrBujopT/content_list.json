[{"type": "text", "text": "Online Control in Population Dynamics ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Noah Golowich\u02da Elad Hazan: Zhou Lu; Dhruv Rohatgi\u00a7 Y. Jennifer Sun\u00b6 ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The study of population dynamics originated with early sociological works but has since extended into many fields, including biology, epidemiology, evolutionary game theory, and economics. Most studies on population dynamics focus on the problem of prediction rather than control. Existing mathematical models for population control are often restricted to specific, noise-free dynamics, while real-world population changes can be complex and adversarial. ", "page_idx": 0}, {"type": "text", "text": "To address this gap, we propose a new framework based on the paradigm of online control. We first characterize a set of linear dynamical systems that can naturally model evolving populations. We then give an efficient gradient-based controller for these systems, with near-optimal regret bounds with respect to a broad class of linear policies. Our empirical evaluations demonstrate the effectiveness of the proposed algorithm for population control even in non-linear models such as SIR and replicator dynamics. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Dynamical systems involving populations are ubiquitous in describing processes that arise in natural environments. As one example, the SIR model [26] is a fundamental concept in epidemiology, used to describe the spread of infectious diseases within a population. It divides the population into three groups \u2013 Susceptible (S), Infected (I) and Removed (R). A susceptible individual has not contracted the disease but has the chance to be infected if interacting with an infected individual. A removed individual either has recovered from the disease and gained immunity or is deceased. The population evolves over time according to three ordinary differential equations: ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\frac{d S}{d t}=-\\beta I S\\;,\\;\\frac{d I}{d t}=\\beta I S-\\theta I\\;,\\;\\frac{d R}{d t}=\\theta I,\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "for constants $\\beta,\\theta>0$ representing the infection and recovery rate, respectively. Numerous extensions of this basic model have been proposed to better capture how epidemics evolve and spread [8]. ", "page_idx": 0}, {"type": "text", "text": "Beyond epidemiology, population dynamics naturally arise in many other fields, notably evolutionary game theory [23], biology [14, 7], and the analysis of genetic algorithms [39, 25]. For any dynamical system, it is natural to ask how it might best be controlled. For instance, controlling the spread of an infectious disease while minimizing externalities is a problem of significant societal importance. ", "page_idx": 0}, {"type": "text", "text": "In many natural models, these dynamics tend to be nonlinear, so the control problem is often computationally intractable. Existing algorithms are designed on a case-by-case basis by positing a specific system of differential equations, and then numerically or analytically solving for the optimal controller. Unfortunately, this approach is not robust to adversarial shocks to the system and cannot adapt to time-varying cost functions. ", "page_idx": 0}, {"type": "text", "text": "A new approach for population control. In this paper we propose a generic and robust methodology for population control, drawing on the framework and tools from online non-stochastic control theory to obtain a computationally efficient gradient-based method of control. In online non-stochastic control, at every time $t=1,\\dots,T$ , the learner is faced with a state $x_{t}$ and must choose a control $u_{t}$ . The learner then incurs cost according to some time-varying cost function $c_{t}(x_{t},u_{t})$ evaluated at the current state/control pair, and the state evolves as: ", "page_idx": 1}, {"type": "equation", "text": "$$\nx_{t+1}:=f(x_{t},u_{t})+w_{t},\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $f$ describes the (known) discrete-time dynamics, $x_{t+1}$ is the next state, and $w_{t}$ is an adversarially-chosen perturbation. A policy is a mapping from states to controls. The goal of the learner is to minimize regret with respect to some rich policy class $\\Pi$ , formally defined by ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathbf{regret}_{\\Pi}=\\sum_{t=1}^{T}c_{t}(x_{t},u_{t})-\\operatorname*{min}_{\\pi\\in\\Pi}\\sum_{t=1}^{T}c_{t}(x_{t}^{\\pi},u_{t}^{\\pi}),\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $(x_{t}^{\\pi},u_{t}^{\\pi})$ is the state/control pair at time $t$ had policy $\\pi$ been carried out since time 1. ", "page_idx": 1}, {"type": "text", "text": "As with prior work in online control [1], our method is theoretically grounded by regret guarantees for a broad class of Linear Dynamical Systems (LDSs). The key algorithmic and technical challenge we overcome is that prior methods only give regret bounds against comparator policies that strongly stabilize the LDS (Definition 4). Such policies force the magnitude of the state to decrease exponentially fast in the absence of noise. Unfortunately, for applications to population dynamics, even the assumption that such policies exist \u2013 let alone perform well \u2013 is fundamentally unreasonable, since it essentially implies that the population can be made to exponentially shrink. ", "page_idx": 1}, {"type": "text", "text": "A priori, one might hope to generically overcome this issue, by broadening the comparator class to all policies that marginally stabilize the LDS (informally, these are policies under which the magnitude of the state does not blow up). But we show that, in general, it is impossible to achieve sub-linear regret against that class \u2013 a result that may be of independent interest in online control:6 ", "page_idx": 1}, {"type": "text", "text": "Theorem 1 (Informal statement of Theorem 25). There is a distribution $\\mathcal{D}$ over LDSs with state space and control space given by $\\mathbb{R}$ , such that any online control algorithm on a system $\\mathcal{L}\\sim\\mathcal{D}$ incurs expected regret $\\Omega(T)$ against the class of time-invariant linear policies that marginally stabilize $\\mathcal{L}$ . ", "page_idx": 1}, {"type": "text", "text": "For general LDSs, it\u2019s not obvious if there is a natural \u201cintermediate\u201d comparator class that does not require strong stabilizability and does enable control with low regret. However, systems that model populations possess rich additional structure, since they can be interpreted as controlled Markov chains.7 In this paper, leveraging that structure, we design an algorithm GPC-Simplex for online control that applies to LDSs constrained to the simplex (Definition 3), and achieves strong regret bounds against a natural comparator class of policies with bounded mixing time (Definition 6). ", "page_idx": 1}, {"type": "text", "text": "1.1 Our Results ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Throughout this work, we model a population as a distribution over $d$ different categories, evolving over $T$ discrete timesteps. For simplicity, we assume that $u_{t}$ is a $d_{\\cdot}$ -dimensional real vector. ", "page_idx": 1}, {"type": "text", "text": "Theoretical guarantees for online population control. We introduce the simplex $L D S$ model (Definition 3), which is a modification of the standard LDS model (Definition 9) that ensures the states $(x_{t})_{t}$ always represent valid distributions, i.e. never leave the simplex $\\Delta^{d}$ . Informally, given state $x_{t}\\in\\Delta^{d}$ and control $u_{t}\\in\\mathbb{R}_{\\geq0}^{d}$ with $\\|u_{t}\\|_{1}\\leqslant1$ , the next state is ", "page_idx": 1}, {"type": "equation", "text": "$$\nx_{t+1}=\\left(1-\\gamma_{t}\\right)\\cdot\\left[\\left(1-\\|u_{t}\\|_{1}\\right)A x_{t}+B u_{t}\\right]+\\gamma_{t}\\cdot w_{t},\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $A,B$ are known stochastic matrices, $\\gamma_{t}\\in[0,1]$ is the observed perturbation strength,8 and $w_{t}\\,\\in\\,\\Delta^{d}$ is an unknown perturbation. The perturbation $w_{t}$ can be interpreted as representing an ", "page_idx": 1}, {"type": "text", "text": "adversary that can add individuals from a population with distribution $w_{t}$ to the population under study.   \nIntuitively, $u_{t}$ represents a distribution over $d$ possible interventions as well as a \u201cnull intervention\u201d. ", "page_idx": 2}, {"type": "text", "text": "For any simplex LDS $\\mathcal{L}$ and mixing time parameter $\\tau>0$ , we define a class $\\kappa_{\\tau}^{\\triangle}(\\mathcal{L})$ (Definition 6), which roughly consists of the linear time-invariant policies under which the state of the system would mix to stationarity in time $\\tau$ , in the absence of noise. Our main theoretical contribution is an algorithm GPC-Simplex that achieves low regret against this policy class: ", "page_idx": 2}, {"type": "text", "text": "Theorem 2 (Informal version of Theorem 7). Let $\\mathcal{L}$ be a simplex $L D S$ on $\\Delta^{d}$ , and let $\\tau>0$ . For any adversarially-chosen perturbations $(w_{t})_{t}$ , perturbation strengths $(\\gamma_{t})_{t}$ , and convex and Lipschitz cost functions $(c_{t})_{t}$ , the algorithm GPC-Simplex performs $T$ steps of online control on $\\mathcal{L}$ with regret $\\tilde{O}(\\tau^{7/2}\\sqrt{d T})$ against $\\kappa_{\\tau}^{\\triangle}(\\mathcal{L})$ . ", "page_idx": 2}, {"type": "text", "text": "Finally, analogously Theorem 1, we show that the mixing time assumption cannot be removed: it is impossible to achieve sub-linear regret (for online control of a simplex LDS) against the class of all linear time-invariant policies (Theorem 8). ", "page_idx": 2}, {"type": "text", "text": "Experimental evaluations. To illustrate the practicality of our results, we apply (a generalization of) GPC-Simplex to controlled versions of (a) the SIR model for disease transmission (Section 4), and (b) the replicator dynamics from evolutionary game theory (Appendix H). In the former, closed-form optimal controllers are known in the absence of perturbations [27]. We find that GPC-Simplex learns characteristics of the optimal control (e.g. the \u201cturning point\u201d phase transition where interventions stop once herd immunity is reached). Moreover, our algorithm is robust even in the presence of adversarial perturbations, where previous theoretical results no longer apply. In the latter, we demonstrate that even when the control affects the population only indirectly, through the replicator dynamics payoff matrix, GPC-Simplex can learn to control the population effectively, and is more robust to noisy cost functions than a one-step best response controller. ", "page_idx": 2}, {"type": "text", "text": "1.2 Related work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Online non-stochastic control. In recent years, the machine learning community has witnessed an increasing interest in non-stochastic control problems (e.g. [1, 38, 19]). Unlike the classical setting of stochastic control, in non-stochastic control the dynamics are subject to time-varying, adversarially chosen perturbations and cost functions. See [21] for a survey of prior results. Most relevant to our work is the Gradient Perturbation Controller (GPC) for controlling general LDSs [1]. All existing controllers only provide provable regret guarantees against policies that strongly stabilize the system. ", "page_idx": 2}, {"type": "text", "text": "Population growth models. There is extensive research on modeling the evolution of populations in sociology, biology and economics. Besides the pioneering work of [33], notable models include the SIR model from epidemiology [26], the Lotka\u2013Volterra model for predator-prey dynamics [32, 40] and the replicator dynamics from evolutionary game theory [23]. Recent years have seen intensive study of controlled versions of the SIR model \u2013 see e.g. empirical work [10], vaccination control models [13], and many others [15, 12, 30, 17]. Most relevant to our work is the quarantine control model, where the control reduces the effective transmission rate. Some works consider optimal control in the noiseless setting [27, 5]; follow-up work [34] considers a budget constraint on the control. None of these prior works can handle the general case of adversarial noise and cost functions. ", "page_idx": 2}, {"type": "text", "text": "2 Definitions and setup ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Notation. Denote $\\mathbb{S}^{d}:=\\left\\{M\\in[0,1]^{d\\times d}\\,:\\,\\sum_{i=1}^{d}M_{i,j}=1\\,\\forall j\\in[d]\\right\\}$ as the set of $d\\times d$ columnstochastic matrices. For $a>0$ , define $\\mathbb{S}_{a}^{d}:=\\{a\\cdot M\\,:\\,M\\in\\mathbb{S}^{d}\\}$ and $\\begin{array}{r}{\\mathring{\\mathbb{S}}_{\\leqslant a}^{d}:=\\bigcup_{0\\leqslant a^{\\prime}\\leqslant a}\\mathbb{S}_{a^{\\prime}}^{d}}\\end{array}$ . Let $\\Delta^{d}$ denote the simplex in $\\mathbb{R}^{d}$ . Similarly, we define $\\Delta_{\\alpha}^{d}:=\\alpha\\cdot\\Delta^{d}$ and $\\textstyle\\Delta_{\\leqslant\\alpha}^{d}:=\\bigcup_{0\\leqslant\\alpha^{\\prime}\\leqslant\\alpha}\\Delta_{\\alpha^{\\prime}}^{d}$ . Given a square matrix $M\\in\\mathbb{R}^{d\\times d}$ , let $M_{\\cdot,j}$ denote the $j$ th column of $M$ . We consid e\u0164r the following matrix norms: $\\lVert M\\rVert$ denotes the spectral norm of $M$ , $\\begin{array}{r}{\\|M\\|_{2,1}^{2}:=\\sum_{j=1}^{d}\\|M_{\\cdot,j}\\|_{1}^{2}}\\end{array}$ is the sum of the squares of the $\\ell_{1}$ norms of the columns of $M$ , and $\\begin{array}{r}{\\|M\\|_{1\\to1}:=\\operatorname*{sup}_{x\\in\\mathbb{R}^{d}:\\|x\\|_{1}=1}\\|M x\\|_{1}}\\end{array}$ . ", "page_idx": 2}, {"type": "text", "text": "2.1 Dynamical systems ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The standard model in online control is the linear dynamical system $(L D S)$ . We define a simplex LDS to be an LDS where the state of the system always lies in the simplex. This requires enforcing certain constraints on the transition matrices, the control, and the noise: ", "page_idx": 3}, {"type": "text", "text": "Definition 3 (Simplex LDS). Let $d\\in\\mathbb{N}$ . A simplex LDS on $\\Delta^{d}$ is a tuple ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{L}=(A,B,\\mathcal{Z},x_{1},(\\gamma_{t})_{t\\in\\mathbb{N}},(w_{t})_{t\\in\\mathbb{N}},(c_{t})_{t\\in\\mathbb{N}}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $A,B\\in\\mathbb{S}^{d}$ are the transition matrices; $\\mathcal{T}\\subseteq\\Delta_{\\leqslant1}^{d}$ is the valid control set; $x_{1}\\in\\Delta^{d}$ is the initial state; $\\gamma_{t}\\in[0,1]$ , $w_{t}\\in\\Delta^{d}$ are the noise strength and noise value at time $t$ ; and $c_{t}:\\Delta^{d}\\times\\mathcal{T}\\rightarrow\\mathbb{R}$ is the cost function at time $t$ . These parameters define a dynamical system where the state at time $t=1$ is $x_{1}$ . For each $t\\geqslant1$ , given state $x_{t}$ and control $u_{t}\\in\\mathcal{Z}$ at time $t$ , the state at time $t+1$ is ", "page_idx": 3}, {"type": "equation", "text": "$$\nx_{t+1}=(1-\\gamma_{t})\\cdot[(1-\\|u_{t}\\|_{1})A x_{t}+B u_{t}]+\\gamma_{t}\\cdot w_{t},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "and the cost incurred at time $t$ is $c_{t}(x_{t},u_{t})$ . ", "page_idx": 3}, {"type": "text", "text": "Note that since the set of possible controls $\\mathcal{T}$ is contained in $\\Delta_{\\leqslant1}^{d}$ , the states $(x_{t})_{t}$ are guaranteed to remain within the simplex for all $t$ . In this paper, we will assume that $\\textstyle{\\mathcal{T}}=\\bigcup_{\\alpha\\in[\\underline{{\\alpha}},\\overline{{\\alpha}}]}\\Delta_{\\alpha}^{d}$ , for some parameters $\\underline{{\\alpha}},\\overline{{\\alpha}}\\in[0,1]$ , which represent lower and upper bounds on the str ength of the control. ", "page_idx": 3}, {"type": "text", "text": "Online non-stochastic control. Let $\\mathcal{L}\\;=\\;(A,B,x_{1},(\\gamma_{t})_{t\\in\\mathbb{N}},(w_{t})_{t\\in\\mathbb{N}},(c_{t})_{t\\in\\mathbb{N}},\\mathcal{Z})$ be a simplex LDS and let $T\\in\\mathbb{N}^{+}$ . We assume that the transition matrices $A,B$ are known to the controller at the beginning of time, but the perturbations $(w_{t})_{t=1}^{T}$ are unknown. At each step $1\\leqslant t\\leqslant T$ , the controller observes $x_{t}$ and $\\gamma_{t}$ , plays a control $u_{t}\\in\\mathcal{Z}$ , and then observes the cost function $c_{t}$ and incurs cost $c_{t}(x_{t},u_{t})$ . The system then evolves according to Eq. (4). Note that our assumption that the controller observes $\\gamma_{t}$ contrasts with some of the existing work on nonstochastic control [1, 21], in which no information about the adversarial disturbances is known. In Appendix B, we justify the learner\u2019s ability to observe $\\gamma_{t}$ by observing that in many situations, the learner observes the counts of individuals in a populations (in addition to their proportions, represented by the state $x_{t}$ ), and that this additional information allows computation of $\\gamma_{t}$ . ", "page_idx": 3}, {"type": "text", "text": "The goal of the controller is to minimize regret with respect to some class $\\kappa=\\kappa(\\mathcal{L})$ of comparator policies. Formally, for any fixed dynamical system and any time-invariant and Markovian policy $\\dot{K}:\\Delta^{d}\\rightarrow\\mathcal{Z}$ , let $\\bar{({x}_{t}(K))_{t}}$ and $(u_{t}(K))_{t}$ denote the counterfactual sequences of states and controls that would have been obtained by following policy $K$ . Then the regret of the controller on observed sequences $(x_{t})_{t}$ and $(u_{t})_{t}$ with respect to $\\kappa$ is ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{regret}_{K}:=\\sum_{t=1}^{T}c_{t}(x_{t},u_{t})-\\operatorname*{inf}_{K\\in{K}}\\sum_{t=1}^{T}c_{t}(x_{t}(K),u_{t}(K)).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The following assumption on the cost functions of $\\mathcal{L}$ is standard in online control [1, 3, 38, 37]: ", "page_idx": 3}, {"type": "text", "text": "Assumption 1. The cost functions $c_{t}:\\Delta^{d}\\times\\mathcal{T}\\rightarrow\\mathbb{R}$ are convex and $L$ -Lipschitz, in the following sense: for all $x,x^{\\prime}\\in\\Delta^{d}$ and $u,u^{\\prime}\\in\\mathcal{T}$ , we have $|c_{t}(x,u)-c_{t}(x^{\\prime},u^{\\prime})|\\leqslant L\\cdot(\\|x-x^{\\prime}\\|_{1}+\\|u-u^{\\prime}\\|_{1})$ . ", "page_idx": 3}, {"type": "text", "text": "2.2 Comparator class and spectral conditions ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In prior works on non-stochastic control for linear dynamical systems [1], the comparator class $\\mathcal{K}=\\mathcal{K}_{\\kappa,\\rho}(\\mathcal{L})$ is defined to be the set of linear, time-invariant policies $x\\mapsto K x$ where $K\\in\\mathbb{R}^{d\\times d}$ $(\\kappa,\\rho)$ -strongly stabilizes $\\mathcal{L}$ : ", "page_idx": 3}, {"type": "text", "text": "Definition 4. A matrix $M\\in\\mathbb{R}^{d\\times d}$ is $(\\kappa,\\rho)$ -strongly stable if there is a matrix $H\\in\\mathbb{R}^{d\\times d}$ so that $\\|H^{-1}M H\\|\\leqslant1-\\rho$ and $\\lVert M\\rVert,\\lVert H\\rVert,\\lVert H^{-1}\\rVert\\,\\leqslant\\,\\kappa$ . A matrix $K\\in\\mathbb{R}^{d\\times d}$ is said to $(\\kappa,\\rho)$ -strongly stabilize an LDS with transition matrices $A,\\stackrel{\\cdot}{B}\\in\\mathbb{R}^{d\\times d}$ if $A+B K$ is $(\\kappa,\\rho)$ -strongly stable. ", "page_idx": 3}, {"type": "text", "text": "The regret bounds against $\\kappa_{\\kappa,\\rho}(\\mathcal{L})$ scale with $\\rho^{-1}$ , and so are vacuous for $\\rho=0$ [1]. Unfortunately, in the simplex LDS setting, no policies satisfy the analogous notion of strong stability (see discussion in Section 3) unless $\\rho=0$ . Intuitively, the reason is that a $(\\kappa,\\rho)$ -strongly stable policy with $\\rho>0$ makes the state converge to 0 in the absence of noise. ", "page_idx": 3}, {"type": "text", "text": "What is a richer but still-tractable comparator class for a simplex LDS? We propose the class of linear, time-invariant policies under which (a) the state of the LDS mixes, when viewed as a distribution, and (b) the level of control $\\left\\Vert u_{t}\\right\\Vert_{1}$ is independent of the state $x_{t}$ . Formally, we make the following definitions: ", "page_idx": 4}, {"type": "text", "text": "Definition 5. Given $t\\in\\mathbb{N}$ and a matrix $X\\in\\mathbb{S}^{d}$ with unique stationary distribution $\\pi\\in\\Delta^{d}$ , we define $D_{X}(t)\\,:=\\,\\operatorname*{sup}_{p\\in\\Delta^{d}}\\|X^{t}p-\\pi\\|_{1}$ and $\\bar{D}_{X}(t):=\\operatorname*{sup}_{p,q\\in\\Delta^{d}}\\|X^{t}\\cdot(\\stackrel{.}{p}-q)\\|_{1}$ . Moreover we define $\\begin{array}{r}{t^{\\mathsf{m i x}}(X,\\varepsilon):=\\operatorname*{min}_{t\\in\\mathbb{N}}\\{t:\\,D_{X}(t)\\leqslant\\varepsilon\\}}\\end{array}$ for each $\\epsilon>0$ , and we write $t^{\\mathsf{m i x}}(X):=t^{\\mathsf{m i x}}(X,1/4)$ .9 ", "page_idx": 4}, {"type": "text", "text": "Definition 6 (Mixing a simplex LDS). Let $\\mathcal{L}$ be a simplex LDS with transition matrices $A,B\\in\\mathbb{S}^{d}$ and control set $\\begin{array}{r}{\\mathcal{T}=\\breve{\\bigcup}_{\\alpha\\in[\\underline{{\\alpha}},\\overline{{\\alpha}}]}\\,\\Delta_{\\alpha}^{d}}\\end{array}$ . A matrix $K\\in\\mathbb{S}_{[\\underline{{\\alpha}},\\overline{{\\alpha}}]}^{d}$ Srd\u03b1,\u03b1s is said to \u03c4-mix L if tmixpAKq \u010f \u03c4, where ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{A}_{K}:=(1-\\|K\\|_{1\\rightarrow1})\\cdot A+B K\\in\\mathbb{S}^{d}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We define the comparator class $K_{\\tau}^{\\triangle}=K_{\\tau}^{\\triangle}({\\mathcal L})$ as the set of linear, time-invariant policies $x\\mapsto K x$ where $K\\in\\mathbb{S}_{[\\underline{{\\alpha}},\\overline{{\\alpha}}]}^{d}\\ \\tau$ -mixes $\\mathcal{L}$ . ", "page_idx": 4}, {"type": "text", "text": "Notice that for any $K\\in\\mathbb{S}_{[\\underline{{\\alpha}},\\overline{{\\alpha}}]}^{d}$ Srd\u03b1,\u03b1s, the linear policy ut :\u201c Kxt always plays controls in the control set $\\mathcal{T}$ , and the dynamics Eq. (4) under this policy can be written as $x_{t+1}=(1-\\gamma_{t})\\cdot\\mathbb{A}_{K}x_{t}+\\gamma_{t}\\cdot w_{t}$ . ", "page_idx": 4}, {"type": "text", "text": "Notice that by considering the comparator class $\\kappa_{\\tau}^{\\triangle}$ , we require the control norm to be independent of the state. This assumption is needed for technical reasons: without it, since $A x$ is multiplied by $1-\\|u\\|_{1}$ in the transition dynamics (see Equation (4)), even a \u201clinear\u201d policy $u:=K x$ does not induce a linear transition. Hence, it would no longer be clear how one might define mixing time of a linear policy. It is a very interesting question whether there is a more natural (yet still tractable) definition of a simplex LDS that avoids this issue. ", "page_idx": 4}, {"type": "text", "text": "3 Online Algorithm and Theoretical Guarantee ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we describe our main upper bound and accompanying algorithm for the setting of online control in a simplex LDS $\\mathcal{L}$ . As discussed above, we assume that the set of valid controls is given by $\\begin{array}{r}{\\mathcal{T}=\\bigcup_{\\alpha\\in[\\underline{{\\alpha}},\\overline{{\\alpha}}]}\\Delta_{\\alpha}^{d}}\\end{array}$ , for some constants $0\\leqslant\\underline{{\\alpha}}\\leqslant\\overline{{\\alpha}}\\leqslant1$ , representing lower and upper bounds on the st re\u0164ngth of the control.10 ", "page_idx": 4}, {"type": "text", "text": "For convenience, we write $\\alpha_{t}:=\\|u_{t}\\|_{1}$ and $u_{t}^{\\prime}\\,=\\,u_{t}/\\alpha_{t}\\,\\in\\,\\Delta^{d}$ (if $\\alpha_{t}\\,=\\,0$ , we set $u_{t}^{\\prime}:=0\\,$ ). The dynamical system Eq. (4) can then be expressed as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\nx_{t+1}=(1-\\gamma_{t})\\cdot((1-\\alpha_{t})\\cdot A x_{t}+\\alpha_{t}\\cdot B u_{t}^{\\prime})+\\gamma_{t}\\cdot w_{t}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We aim to obtain a regret guarantee as in Eq. (3) with respect to some rich class of comparator policies $\\kappa^{\\triangle}$ . As is typical in existing work on linear nonstochastic control, we take $\\kappa^{\\triangle}$ to be a class of time-invariant linear policies, i.e. policies that choose control $u_{t}:=K x_{t}$ at time $t$ for some matrix $K\\in\\mathbb{R}^{d\\times d}$ . In the standard setting of nonstochastic control, it is typically further assumed that all policies in the comparator class strongly stabilize the LDS (Definition 4).11 The naive generalization of such a requirement in our setting would be that $\\mathbb{A}_{K}$ is strongly stable; however, this is impossible, since no stochastic matrix can be strongly stable. Instead, we aim to compete against the class $K^{\\triangle}=K_{\\tau}^{\\triangle}({\\mathcal{L}})$ of time-invariant linear policies that (a) have fixed level of control in $[\\underline{{\\alpha}},\\overline{{\\alpha}}]$ , and (b) $\\tau$ -mix $\\mathcal{L}$ (Definition 6). We view the second condition as a natural distributional analogue of strong stabilizability; the first condition is needed for $\\tau$ -mixing to even be well-defined. ", "page_idx": 4}, {"type": "text", "text": "Algorithm description. Our main algorithm, GPC-Simplex (Algorithm 1), is a modification of the GPC algorithm [1, 21]. As a refresher, GPC chooses the controls $u_{t}$ by learning a disturbance-action policy: a policy $\\begin{array}{r}{u_{t}\\;:=\\;\\bar{K}x_{t}\\,+\\sum_{i=1}^{H}M^{[i]}w_{t-i}}\\end{array}$ , where $\\bar{K}$ is a known, fixed matrix that strongly stabilizes the LDS; $w_{t-1},\\dots,w_{t-H}$ are the recent noise terms; and $M^{[1]},\\dots,M^{[H]}$ are learnable, matrix-valued parameters which we abbreviate as $M^{[1:H]}$ . The key advantage of this parametrization of policies (as opposed to a simpler parametrization such as $u_{t}=K x_{t}$ for a parameter $K$ ) is that the entire trajectory is linear in the parameters, and not a high-degree polynomial. Thus, optimizing the cost of a trajectory over the class of disturbance-action policies is a convex problem in $\\big[M^{[1:H]}$ . ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "But why is the class of disturbance-action policies expressive enough to compete against the comparator class? This is where GPC crucially uses strong stabilizability. Notice that in the absence of noise, every disturbance-action policy is identical to the fixed policy $u_{t}:=\\bar{K}x_{t}$ . This is fine when $\\bar{K}$ and the comparator class are strongly stabilizing, since in the absence of noise, all strongly stabilizing policies rapidly force the state to 0, and thus incur very similar costs in the long run. But in the simplex LDS setting, strong stabilizability is impossible. While all policies in $\\bar{\\kappa}^{\\triangle}$ mix the LDS, they may mix to different states, which may incur different costs. There is no reason to expect that an arbitrary $\\bar{K}\\in{\\kappa}^{\\triangle}$ , chosen before observing the cost functions, will have low regret against all policies in $\\gamma\\triangle$ . ", "page_idx": 5}, {"type": "text", "text": "We fix this issue by enriching the class of disturbance-action policies with an additional parameter $p\\in\\Delta^{d}$ which, roughly speaking, represents the desired stationary distribution to which $x_{t}$ would converge, in the absence of noise, as $t\\to\\infty$ . It is unreasonable to expect prior knowledge of the optimal choice of $p$ , which depends on the not-yet-observed cost functions. Thus, GPC-Simplex instead learns $p$ together with $M^{[1:H]}$ . We retain the property that the requisite online learning problem is convex in the parameters, and therefore can be efficiently solved via an online convex optimization algorithm (as discussed in Appendix C.1, we use lazy mirror descent, LazyMD). One advantage of GPC-Simplex over GPC is that the former requires no knowledge of the fixed \u201creference\u201d policy $\\bar{K}$ (which, in the context of GPC, had to be strongly stabilizing). While such K\u00af is needed in the context of GPC to bound a certain approximation error involving the cost functions, in the context of GPC-Simplex this approximation error may be bounded by some simple casework involving properties of stochastic matrices (see Appendix C.3). ", "page_idx": 5}, {"type": "text", "text": "Formally, for parameters $a_{0}~\\in~[\\underline{{\\alpha}},\\overline{{\\alpha}}]$ and $H\\ \\in\\ \\mathbb{N}$ , GPC-Simplex considers a class of policies parametrized by the set $\\overline{{{\\chi_{d,H,a_{0}}}}}_{\\overline{{\\alpha}}}\\ :=\\ \\bigcup_{a\\in[a_{0},\\overline{{\\alpha}}]}\\Delta_{a}^{d}\\ \\times\\ (\\mathbb{S}_{a}^{d})^{H}$ . We abbreviate elements $(p,(M^{[1]},\\ldots,M^{[H]}))\\;\\in\\;{\\mathcal{X}}_{d,H,a_{0},{\\overline{{\\alpha}}}}$ by $(p,M^{[1:H]})$ . The high level idea of GPC-Simplex, like that of GPC, is to perform online convex optimization on the domain $\\mathcal{X}_{d,H,a_{0},\\overline{{\\alpha}}}$ (Line 10). At each time $t$ , the current iterate $(p_{t},M_{t}^{[1:H]})$ , which defines a policy $\\pi^{p_{t},M_{t}^{[1:H]}}$ , is used to choose the control $u_{t}$ . The optimization subroutine then receives a new loss function $\\ell_{t}:\\mathcal{X}_{d,H,a_{0},\\overline{{\\alpha}}}\\to\\mathbb{R}$ based on the newly observed cost function $c_{t}$ . As with GPC, showing that this algorithm works requires showing that the policy class is sufficiently expressive. Unlike for GPC, our comparator policies are not strongly stabilizing, so new ideas are required for the proof. ", "page_idx": 5}, {"type": "text", "text": "We next formally define the policy \u03c0p,M r1:Hs associated with parameters $(p,M^{[{1:H}]})$ , and the loss function $\\ell_{t}$ used to update the optimization algorithm at time $t$ . ", "page_idx": 5}, {"type": "text", "text": "Parametrization of policies. First, for $t\\in[T]$ and $i\\in\\mathbb{N}^{+}$ , we define the weights ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\lambda_{t,i}:=\\gamma_{t-i}\\cdot\\prod_{j=1}^{i-1}(1-\\gamma_{t-j}),\\qquad\\bar{\\lambda}_{t,i}:=\\prod_{j=1}^{i}(1-\\gamma_{t-j}),\\qquad\\lambda_{t,0}:=1-\\sum_{i=1}^{H}\\lambda_{t,i}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We write $w_{0}:=x_{1}$ , $\\gamma_{0}=1$ , and $w_{t}=0$ for $t<0$ as a matter of convention.12 $\\lambda_{t,i}$ can be interpreted as the \u201cinfluence of perturbation $w_{t-i}$ on the state $x_{t}\\,^{,,}$ , and ${\\bar{\\lambda}}_{t,i}$ can be interpreted as the \u201cinfluence of perturbations prior to time step $t-i$ on the state $x_{t}^{\\,\\,\\,\\,\\,}$ . An element $(p,M^{[{1:H}]})\\in\\mathcal{X}_{d,H,a_{0},\\overline{{\\alpha}}}$ induces a policy13 at time t, denoted \u03c0tp,M r1:Hs, via the following variant of the disturbance-action control [1]: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\pi_{t}^{p,M^{[1:H]}}(\\delta_{t-1:t-H}):=\\lambda_{t,0}\\cdot p+\\sum_{j=1}^{H}\\lambda_{t,j}\\cdot M^{[j]}\\delta_{t-j}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "In Line 6 of GPC-Simplex, the control $u_{t}$ is chosen to be $\\pi_{t}^{p_{t},M_{t}^{[1:H]}}(w_{t-1:t-H})$ , which belongs to $\\Delta_{\\parallel p_{t}\\parallel_{1}}^{d}$ (using $\\begin{array}{r}{\\sum_{i=0}^{H}\\lambda_{t,i}=1\\rangle}\\end{array}$ ) and hence to the constraint set $\\mathcal{T}$ (since $\\|p_{t}\\|_{1}\\in[a_{0},\\overline{{\\alpha}}]\\subset[\\underline{{\\alpha}},\\overline{{\\alpha}}])$ . ", "page_idx": 5}, {"type": "text", "text": "Require: Linear system $A,B$ , mixing time $\\tau>0$ for comparator class, horizon parameter $H\\in\\mathbb{N}$ , set of valid controls $\\begin{array}{r}{\\mathcal{T}=\\bigcup_{\\alpha\\in[\\underline{{\\alpha}},\\overline{{\\alpha}}]}\\alpha\\cdot\\Delta^{d}}\\end{array}$ , total number of time steps $T$ .   \n1: Write $\\tau_{A}:=t^{\\mathsf{m i x}}(A)$ , an d \u0164define $a_{0}:=\\operatorname*{max}\\{\\underline{{\\alpha}},\\operatorname*{min}\\{\\overline{{\\alpha}},\\mathbb{1}\\{\\tau_{A}>4\\tau\\}/(96\\tau)\\}\\}$ .   \n2: Initialize an instance LazyMD of mirror descent (Algorithm 2) for the domain $\\mathcal{X}_{d,H,a_{0},\\overline{{\\alpha}}}$ with? the regularizer $R_{d,H}$ (defined in Appendix C.1) and step size $\\eta=c\\sqrt{d H\\ln(d)}/(L\\tau^{2}\\log^{2}(T)\\sqrt{T})$ ,   \n3: Initialize $c$ $\\begin{array}{r}{\\big(p_{1},M_{1}^{[1:H]}\\big)\\gets\\arg\\operatorname*{min}_{(p,M^{[1:H]})\\in\\mathcal{X}_{d,H,a_{0},\\overline{{\\alpha}}}}R_{d,H}\\big(p,M^{[1:H]}\\big).}\\end{array}$ $x_{1}\\in\\Delta^{d}$   \n5: for $1\\leqslant t\\leqslant T$ do   \n6: Choose control $\\begin{array}{r}{\\boldsymbol{u}_{t}:=\\lambda_{t,0}\\cdot\\boldsymbol{p}_{t}+\\sum_{i=1}^{H}M_{t}^{[i]}\\cdot\\lambda_{t,i}\\cdot w_{t-i},}\\end{array}$ .   \n7: Receive cost $c_{t}(x_{t},u_{t})$ .   \n8: Observe $x_{t+1},\\gamma_{t}$ and compute $\\begin{array}{r}{w_{t}=\\gamma_{t}^{-1}(x_{t+1}-(1-\\gamma_{t})[(1-\\|u_{t}\\|_{1})A x_{t}+B u_{t}]).}\\end{array}$ $(I f\\gamma_{t}=0$ , then set $w_{t}=0.$ .)   \n9: Define loss function $\\ell_{t}(p,M^{[1:H]}):=c_{t}\\big(x_{t}(p,M^{[1:H]}),u_{t}(p,M^{[1:H]})\\big).$   \n10: Update $\\left(p_{t+1},M_{t+1}^{[1:H]})\\gets\\texttt{L a z y M D}_{t}\\big(\\ell_{t};\\left(p_{t},M_{t}^{[1:H]}\\right)\\big)$ q. ", "page_idx": 6}, {"type": "text", "text": "Loss functions. For $(p,M^{[{1:H}]})\\in\\mathcal{X}_{d,H,a_{0},\\overline{{\\alpha}}}$ , we let $x_{t}(p,M^{[1:H]})$ and $u_{t}(p,M^{[1:H]})$ denote the state and control at step t obtained by following the policy \u03c0sp,M r1:Hs at all time steps $s$ prior to $t$ (see Eqs. (20) and (21) in the appendix for precise definitions). We then define $\\ell_{t}(p,M^{[{1}:H]})$ to be the evaluation of the adversary\u2019s cost function $c_{t}$ on the state-action pair $(x_{t}(p,M^{[1:H]}),u_{t}(p,M^{[1:H]}))$ (Line 9). ", "page_idx": 6}, {"type": "text", "text": "Main guarantee and proof overview. Theorem 7 gives our regret upper bound for GPC-Simplex: Theorem 7. Let $d,T\\in\\mathbb{N}$ and $\\tau>0$ . Let $\\mathcal{L}=(A,B,\\mathcal{Z},x_{1},(\\gamma_{t})_{t\\in\\mathbb{N}},(w_{t})_{t\\in\\mathbb{N}},(c_{t})_{t\\in\\mathbb{N}})$ be a simplex $L D S$ with cost functions $(c_{t})_{t}$ satisfying Assumption $^{\\,l}$ for some $L>0$ . Set $H:=\\tau\\lceil\\log(2L T^{3})\\rceil$ . Then the iterates $(x_{t},u_{t})_{t=1}^{T}$ of GPC-Simplex (Algorithm $^{\\,l}$ ) with input $(A,B,\\tau,H,\\mathcal{I},\\dot{T})$ satisfy: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbf{regret}_{K_{\\tau}^{\\triangle}(\\mathcal{L})}:=\\sum_{t=1}^{T}c_{t}(x_{t},u_{t})-\\operatorname*{inf}_{K\\in K_{\\tau}^{\\triangle}(\\mathcal{L})}\\sum_{t=1}^{T}c_{t}(x_{t}(K),u_{t}(K))\\leqslant\\tilde{O}(L\\tau^{7/2}d^{1/2}\\sqrt{T}),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\tilde{O}(\\cdot)$ hides only universal constants and poly-logarithmic dependence in $T$ . Moreover, the time complexity of GPC-Simplex is poly $(d,T)$ . ", "page_idx": 6}, {"type": "text", "text": "While for simplicity we have stated our results for obliviously chosen $(\\gamma_{t})_{t},(w_{t})_{t},(c_{t})_{t}$ , since GPC-Simplex is deterministic the result also holds when these parameters are chosen adaptively by an adversary. See Appendix C for the formal proof of Theorem 7. ", "page_idx": 6}, {"type": "text", "text": "Lower bound. We also show that the mixing assumption on the comparator class $\\kappa_{\\tau}^{\\triangle}(\\mathcal{L})$ (Definition 6) cannot be removed. In particular, without that assumption, if the valid control set $\\mathcal{T}$ is restricted to controls $u_{t}$ of norm at mostly roughly ${\\cal O}(1/T)$ , then linear regret is unavoidable.14 ", "page_idx": 6}, {"type": "text", "text": "Theorem 8 (Informal statement of Theorem 30). Let $\\beta>0$ be a sufficiently large constant. For any $T\\in\\mathbb{N}$ , there is a distribution $\\mathcal{D}$ over simplex LDSs with state space $\\dot{\\Delta}^{2}$ and control space $\\textstyle\\bigcup_{\\alpha\\in[0,\\beta/T]}\\Delta_{\\alpha}^{2}$ , such that any online control algorithm on a system $\\mathscr{L}\\sim\\mathscr{D}$ incurs expected regret $\\Omega(T)$ against the class of all time-invariant linear policies $x\\mapsto K x$ where $K\\in\\bigcup_{\\alpha\\in[0,\\beta/T]}\\mathbb{S}_{\\alpha}^{d}$ . ", "page_idx": 6}, {"type": "text", "text": "4 Experimental Evaluation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The previous sections focused on linear systems, but in fact GPC-Simplex can be easily modified to control non-linear systems, for similar reasons as in prior work [2]. It suffices for the dynamics to ", "page_idx": 6}, {"type": "text", "text": "have the form ", "page_idx": 7}, {"type": "equation", "text": "$$\nx_{t+1}:=(1-\\gamma_{t})f(x_{t},u_{t})+\\gamma_{t}w_{t}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "for known $f$ , observed $\\gamma_{t}$ , and unknown $w_{t}$ . See Appendix E for discussion of the needed modifications and other implementation details. Relevant code is open-sourced in [16]. ", "page_idx": 7}, {"type": "text", "text": "As a case study, in this section we apply GPC-Simplex (Algorithm 1) to a disease transmission model \u2013 specifically, a controlled generalization of the SIR model introduced earlier. In Appendix H we apply GPC-Simplex to a controlled version of the replicator dynamics from evolutionary game theory. ", "page_idx": 7}, {"type": "text", "text": "A controlled disease transmission model. The Susceptible-Infectious-Recovered (SIR) model is a basic model for the spread of an epidemic [26]. The SIR model has been extensively studied since last century [36, 41, 4, 24, 6] and attracted renewed interest during the COVID-19 pandemic [10, 29, 9]. As discussed previously, this model posits that a population consists of susceptible (S), infected $(\\mathbf{I})$ , and recovered $(\\bf R)$ individuals. When a susceptible individual comes into contact with an infected individual, the susceptible individual becomes infected at some \u201ctransmission rate\u201d $\\beta$ . Infected patients become uninfected and gain immunity at some \u201crecovery rate\u201d $\\theta$ . We consider a natural generalization of the standard dynamics Eq. (1) where recovered individuals may also lose immunity at a rate of $\\xi$ . Formally, in the absence of control, the population evolves over time according to the following system of differential equations: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\frac{d S}{d t}=-\\beta I S+\\xi R,\\,~~\\frac{d I}{d t}=\\beta I S-\\theta I,\\,~~\\frac{d R}{d t}=\\theta I-\\xi R,\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Typically, $\\beta>\\theta>\\xi$ . We normalize the total population to be 1, and thus $x=[S,I,R]\\in\\Delta^{3}$ . Next, we introduce a variable called the preventative control $u_{t}\\in\\Delta^{2}$ , which has the effect of decreasing the transmission rate $\\beta$ , and adversarial perturbations $w_{t}$ , which allow for model misspecification. Incorporating these changes to the forward discretization of Eq. (10) gives the following dynamics: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\left[\\!\\!\\begin{array}{c c c}{S_{t+1}}\\\\ {I_{t+1}}\\\\ {R_{t+1}}\\end{array}\\!\\!\\right]=(1-\\gamma_{t})\\left(\\!\\!\\begin{array}{c c c}{\\!\\!\\left[\\!\\!1-\\beta I_{t}}&{\\!\\!\\!0}&{\\!\\!\\!\\xi}\\\\ {0}&{\\!\\!\\!1-\\theta}&{\\!\\!\\!0}\\\\ {0}&{\\!\\!\\!\\theta}&{\\!\\!\\!1-\\xi}\\end{array}\\!\\!\\right]\\left[\\!\\!\\begin{array}{c}{S_{t}}\\\\ {I_{t}}\\\\ {R_{t}}\\end{array}\\!\\!\\right]+\\left[\\!\\!\\begin{array}{c c c}{\\!\\!\\beta I_{t}S_{t}}&{\\!\\!\\!0}\\\\ {0}&{\\!\\!\\!\\beta I_{t}S_{t}}\\\\ {0}&{\\!\\!\\!0}\\end{array}\\!\\!\\right]u_{t}\\right)+\\gamma_{t}w_{t}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The control $u_{t}\\in\\Delta^{2}$ represents a distribution over transmission prevention protocols: $u_{t}=[1,0]$ represents full-scale prevention, whereas $u_{t}=[0,1]$ represents that no prevention measure is imposed. Concretely, the effective transmission rate under control $u_{t}$ is $\\beta\\cdot u_{t}(2)$ . ", "page_idx": 7}, {"type": "text", "text": "Parameters and cost function. To model a highly infectious pandemic, we consider Eq. (11) with parameters $\\beta=0.5$ , $\\theta=0.03$ , and $\\xi=0.005$ . Suppose we want to control the number of infected individuals by modulating a (potentially expensive) prevention protocol $u_{t}$ . To model this setting, the cost function includes (1) a quadratic cost for infected individuals $I_{t}$ , and (2) a cost that is bilinear in the magnitude of prevention and the susceptible individuals: ", "page_idx": 7}, {"type": "equation", "text": "$$\nc_{t}(x_{t},u_{t})=c_{3}\\cdot x_{t}(2)^{2}+c_{2}\\cdot x_{t}(1)\\cdot u_{t}(1),\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\boldsymbol{x}_{t}=\\left[S_{t},I_{t},R_{t}\\right]$ . Typically $c_{3}\\geqslant c_{2}>0$ to model the high cost of infection. ", "page_idx": 7}, {"type": "text", "text": "In Fig. 1, we compare GPC-Simplex against two baselines \u2013 (a) always executing $u_{t}=[1,0]$ (i.e. full prevention), and (b) always executing $u_{t}=[0,1]$ (i.e. no prevention) \u2013 for $T=200$ steps in the above model with no perturbations. We observe that GPC-Simplex suppresses the transmission rate via high prevention at the initial stage of the disease outbreak, then relaxes as the outbreak is effectively controlled. Moreover, GPC-Simplex outperforms both baselines in terms of cumulative cost. See Appendix F for additional experiments exhibiting the robustness of GPC-Simplex to perturbations (i.e. non-zero $\\gamma_{t}$ \u2019s) and different model parameters. ", "page_idx": 7}, {"type": "text", "text": "4.1 Controlling hospital flows: reproducing a study by [27] ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We now turn to the recent work [27], which also studies a controlled SIR model. Similar to above, they considered a control that temporarily reduces the rate of contact within a population. In one scenario (inspired by the COVID-19 pandemic), they considered a cost function that penalizes ", "page_idx": 7}, {"type": "image", "img_path": "ZBBrBujopT/tmp/d4229b4496604adb6ef2886ab39a85a59543e79848ca4b9051fe5bd01109a277.jpg", "img_caption": ["Figure 1: Control with cost function (12) for $T=200$ steps: initial distribution $x_{1}=[0.9,0.1,0.0]$ ; parameters $c_{3}=10$ , $c_{2}=1$ ; no noise. Left/Middle: Cost and cumulative cost over time of GPC-Simplex versus baselines. Right: control $u_{t}(2)$ (proportional to effective transmission rate) played by GPC-Simplex over time. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "medical surges, i.e. when the number of infected exceeds a threshold $y_{\\mathrm{max}}$ determined by hospital capacities. Formally, they define the cost of a trajectory $(x_{t},u_{t})_{t=1}^{T}$ as ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\frac{W_{0}(-3x_{T}(1)e^{-3(x_{T}(1)+x_{T}(2))})}{3}+\\int_{0}^{T}\\left[c_{2}\\cdot u_{t}(1)^{2}+\\frac{c_{3}(x_{t}(2)-y_{\\operatorname*{max}})}{1+e^{-100(x_{t}(2)-y_{\\operatorname*{max}})}}\\right]d t,\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $W_{0}$ is the principal branch of Lambert\u2019s $W$ -function, and $c_{2},c_{3}$ are hyperparameters. The system parameters used by [27] are $\\beta\\,=\\,0.3,\\theta\\,=\\,0.1,\\xi\\,=\\,0$ . In the absence of noise and with a known cost function, [27] is able to compute the approximate solutions of the associated HamiltonJacobi-Bellman equations for various choices of $c_{2},c_{3}$ . ", "page_idx": 8}, {"type": "text", "text": "In Fig. 2, we show that GPC-Simplex (with a slightly modified instantaneous version of Eq. (13)) in fact matches the optimal solution analytically computed by [28]. See Appendix G for further experimental details, including the exact model parameters and cost function. ", "page_idx": 8}, {"type": "image", "img_path": "ZBBrBujopT/tmp/f46fe3ea805ddc9c9556deadf3382c3aedffee903f1169f7b4448d7e0bb80471.jpg", "img_caption": ["Figure 2: Controlling hospital flows for $T\\;=\\;100$ steps: initial distribution r0.9, 0.01, 0.09s; parameters $y_{m a x}=0.1$ , $c_{2}=0.01$ , $c_{3}=100$ . Left: The dashed red line shows the number of infected over time under no control; note that $y_{\\mathrm{max}}$ (shown in dashed purple line) is significantly exceeded. The solid yellow and blue lines show the number of infected and susceptible under GPC-Simplex, which closely match the optimal solutions computed by [28] (dashed yellow and blue). Right: GPC-Simplex control (solid) vs. optimal control (dashed). "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "NG is supported by a Fannie & John Hertz Foundation Fellowship and an NSF Graduate Fellowship. EH, ZL and JS gratefully acknowledge funding from the National Science Foundation, the Office of Naval Research, and Open Philanthropy. DR is supported by a U.S. DoD NDSEG Fellowship. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Naman Agarwal, Brian Bullins, Elad Hazan, Sham Kakade, and Karan Singh. Online control with adversarial disturbances. In International Conference on Machine Learning, pages 111\u2013119. PMLR, 2019. [2] Naman Agarwal, Elad Hazan, Anirudha Majumdar, and Karan Singh. A regret minimization approach to iterative learning control. In International Conference on Machine Learning, pages 100\u2013109. PMLR, 2021.   \n[3] Naman Agarwal, Elad Hazan, and Karan Singh. Logarithmic regret for online control. Advances in Neural Information Processing Systems, 32, 2019. [4] Linda JS Allen. Some discrete-time si, sir, and sis epidemic models. Mathematical biosciences, 124(1):83\u2013105, 1994. [5] Roc\u00edo Balderrama, Javier Peressutti, Juan Pablo Pinasco, Federico Vazquez, and Constanza S\u00e1nchez de la Vega. Optimal control for a sir epidemic model with limited quarantine. Scientific Reports, 12(1):12583, 2022. [6] Ottar N Bj\u00f8rnstad, B\u00e4rbel F Finkenst\u00e4dt, and Bryan T Grenfell. Dynamics of measles epidemics: estimating scaling of transmission rates using a time series sir model. Ecological monographs, 72(2):169\u2013184, 2002.   \n[7] Fred Brauer, Carlos Castillo-Chavez, and Carlos Castillo-Chavez. Mathematical models in population biology and epidemiology, volume 2. Springer, 2012. [8] Tom Britton. Stochastic epidemic models: a survey. Mathematical biosciences, 225(1):24\u201335, 2010. [9] Yi-Cheng Chen, Ping-En Lu, Cheng-Shang Chang, and Tzu-Hsuan Liu. A time-dependent sir model for covid-19 with undetectable infected persons. Ieee transactions on network science and engineering, 7(4):3279\u20133294, 2020.   \n[10] Ian Cooper, Argha Mondal, and Chris G Antonopoulos. A sir model assumption for the spread of covid-19 in different communities. Chaos, Solitons & Fractals, 139:110057, 2020.   \n[11] Ross Cressman and Yi Tao. The replicator equation and other game dynamics. Proceedings of the National Academy of Sciences, 111(supplement_3):10810\u201310817, 2014.   \n[12] Adil El-Alami Laaroussi, Mostafa Rachik, and Mohamed Elhia. An optimal control problem for a spatiotemporal sir model. International Journal of Dynamics and Control, 6:384\u2013397, 2018.   \n[13] Mohamed Elhia, Mostafa Rachik, and Elhabib Benlahmar. Optimal control of an sir model with delay in state and control variables. International scholarly research notices, 2013, 2013.   \n[14] Herbert I Freedman. Deterministic mathematical models in population ecology. (No Title), 1980.   \n[15] Nicole M Gatto and Henry Schellhorn. Optimal control of the sir model in the presence of transmission and treatment uncertainty. Mathematical biosciences, 333:108539, 2021.   \n[16] Noah Golowich, Elad Hazan, Zhou Lu, Dhruv Rohatgi, and Y. Jennifer Sun. Population control, 2024. https://github.com/jysun105/population_control.   \n[17] EV Grigorieva, EN Khailov, and A Korobeinikov. Optimal control for a sir epidemic model with nonlinear incidence rate. Mathematical Modelling of Natural Phenomena, 11(4):89\u2013104, 2016.   \n[18] Elad Hazan. Introduction to online convex optimization, 2019.   \n[19] Elad Hazan, Sham Kakade, and Karan Singh. The nonstochastic control problem. In Algorithmic Learning Theory, pages 408\u2013421. PMLR, 2020.   \n[20] Elad Hazan, Holden Lee, Karan Singh, Cyril Zhang, and Yi Zhang. Spectral flitering for general linear dynamical systems. Advances in Neural Information Processing Systems, 31, 2018.   \n[21] Elad Hazan and Karan Singh. Introduction to online nonstochastic control. arXiv preprint arXiv:2211.09619, 2022.   \n[22] Elad Hazan, Karan Singh, and Cyril Zhang. Learning linear dynamical systems via spectral filtering. Advances in Neural Information Processing Systems, 30, 2017.   \n[23] Josef Hofbauer and Karl Sigmund. Evolutionary games and population dynamics. Cambridge university press, 1998.   \n[24] Chunyan Ji, Daqing Jiang, and Ningzhong Shi. The behavior of an sir epidemic model with stochastic perturbation. Stochastic analysis and applications, 30(5):755\u2013773, 2012.   \n[25] Sourabh Katoch, Sumit Singh Chauhan, and Vijay Kumar. A review on genetic algorithm: past, present, and future. Multimedia tools and applications, 80:8091\u20138126, 2021.   \n[26] William Ogilvy Kermack and Anderson G McKendrick. A contribution to the mathematical theory of epidemics. Proceedings of the royal society of london. Series A, Containing papers of a mathematical and physical character, 115(772):700\u2013721, 1927.   \n[27] David I Ketcheson. Optimal control of an sir epidemic through finite-time non-pharmaceutical intervention. Journal of mathematical biology, 83(1):7, 2021.   \n[28] David I Ketcheson. Sir-control-code. optimal control of an sir epidemic through finite-time non-pharmaceutical intervention, 2021.   \n[29] Nikolay A Kudryashov, Mikhail A Chmykhov, and Michael Vigdorowitsch. Analytical features of the sir model and their applications to covid-19. Applied Mathematical Modelling, 90:466\u2013 473, 2021.   \n[30] Urszula Ledzewicz and Heinz Sch\u00e4ttler. On optimal singular controls for a general sir-model with vaccination and treatment. In Conference Publications, volume 2011, pages 981\u2013990. Conference Publications, 2011.   \n[31] David A. Levin, Yuval Peres, and Elizabeth L. Wilmer. Markov chains and mixing times. American Mathematical Society, 2006.   \n[32] Alfred J Lotka. Contribution to the theory of periodic reactions. The Journal of Physical Chemistry, 14(3):271\u2013274, 2002.   \n[33] Thomas Robert Malthus. An Essay on the Principle of Population Or a View of Its Past and Present Effects on Human Happiness, an Inquiry Into Our Prospects Respecting the Future Removal Or Mitigation of the Evils which it Occasions by Rev. TR Malthus. Reeves and Turner, 1872.   \n[34] Emilio Molina and Alain Rapaport. An optimal feedback control that minimizes the epidemic peak in the sir model under a budget constraint. Automatica, 146:110596, 2022.   \n[35] Arkadij Semenovic\u02c7 Nemirovskij and David Borisovich Yudin. Problem complexity and method efficiency in optimization. 1983.   \n[36] Boris Shulgin, Lewi Stone, and Zvia Agur. Pulse vaccination strategy in the sir epidemic model. Bulletin of mathematical biology, 60(6):1123\u20131148, 1998.   \n[37] Max Simchowitz. Making non-stochastic control (almost) as easy as stochastic. Advances in Neural Information Processing Systems, 33:18318\u201318329, 2020.   \n[38] Max Simchowitz, Karan Singh, and Elad Hazan. Improper learning for non-stochastic control. In Conference on Learning Theory, pages 3320\u20133436. PMLR, 2020.   \n[39] Mandavilli Srinivas and Lalit M Patnaik. Genetic algorithms: A survey. computer, 27(6):17\u201326, 1994.   \n[40] Vito Volterra. Fluctuations in the abundance of a species considered mathematically. Nature, 118(2972):558\u2013560, 1926.   \n[41] Gul Zaman, Yong Han Kang, and Il Hyo Jung. Stability analysis and optimal vaccination of an sir epidemic model. BioSystems, 93(3):240\u2013249, 2008. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "Contents ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Introduction 1   \n1.1 Our Results 2   \n1.2 Related work 3   \n2 Definitions and setup 3   \n2.1 Dynamical systems 4   \n2.2 Comparator class and spectral conditions . 4 ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "3 Online Algorithm and Theoretical Guarantee 5 ", "page_idx": 12}, {"type": "text", "text": "4 Experimental Evaluation 7   \n4.1 Controlling hospital flows: reproducing a study by [27] 8 ", "page_idx": 12}, {"type": "text", "text": "A Additional preliminaries 14 ", "page_idx": 12}, {"type": "text", "text": "B Discussion on the observation model 14 ", "page_idx": 12}, {"type": "text", "text": "C Proof of Theorem 7 14   \nC.1 Preliminaries on mirror descent 15   \nC.2 Approximation of linear policies 18   \nC.3 Bounding the memory mismatch error 19   \nC.4 Proof of Theorem 7 22   \nD Proof of Lower Bounds 25   \nD.1 Proof of Theorem 1 25   \nD.2 Proof of Theorem 8 28 ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "E Implementation details 30 ", "page_idx": 12}, {"type": "text", "text": "F Experiments: Controlled SIR model 31   \nF.1 Control in presence of perturbations 31   \nF.2 Alternative parameter settings 31 ", "page_idx": 12}, {"type": "text", "text": "G Experiments: Controlling hospital flows 32 ", "page_idx": 12}, {"type": "text", "text": "H Experiments: Controlled replicator dynamics 35 ", "page_idx": 12}, {"type": "text", "text": "Discussions 36   \nI.1 Broader impacts . . 36   \nI.2 Computational Resources for Experiments 37 ", "page_idx": 12}, {"type": "text", "text": "A Additional preliminaries ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "For completeness, we recall the definition of a standard LDS [21]. ", "page_idx": 13}, {"type": "text", "text": "Definition 9 (LDS). Let $d_{x},d_{u}\\in\\mathbb{N}$ . A linear dynamical system (LDS) is described by a tuple $\\mathcal{L}\\;=\\;\\left(A,B,x_{1},(w_{t})_{t\\in\\mathbb{N}},(c_{t})_{t\\in\\mathbb{N}}\\right)$ where $A\\,\\in\\,\\mathbb{R}^{d_{x}\\times d_{x}}$ , $B\\,\\in\\,\\overline{{\\mathbb{R}^{d_{x}\\times d_{u}}}}$ are the transition matrices; $x_{1}\\in\\mathbb{R}^{d_{x}}$ is the initial state; $w_{t}\\in\\mathbb{R}^{d_{x}}$ is the noise value at time $t$ ; and $c_{t}:\\mathbb{R}^{d_{x}}\\,\\times\\,\\mathbb{R}^{d_{u}}\\to\\mathbb{R}$ is the cost function at time $t$ . For each $t\\geqslant1$ , given state $\\boldsymbol{x}_{t}\\in\\mathbb{R}^{d_{x}}$ and control $u_{t}\\in\\mathbb{R}^{d_{u}}$ at time $t$ , the state at time $t+1$ is given by ", "page_idx": 13}, {"type": "equation", "text": "$$\nx_{t+1}:=A x_{t}+B u_{t}+w_{t},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "and the instantaneous cost incurred at time $t$ is given by $c_{t}(x_{t},u_{t})$ . ", "page_idx": 13}, {"type": "text", "text": "B Discussion on the observation model ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Our main algorithm GPC-Simplex for online control of simplex LDSs assumes that for each $t$ , the perturbation strength $\\gamma_{t}$ is observed by the controller at the same time as it observes $x_{t+1}$ (the algorithm does not require the entire sequence $(\\gamma_{t})_{t}$ to be known in advance). In this appendix we discuss (a) why this is a crucial technical assumption for the algorithm, and (b) why it is a reasonable assumption in many natural population models. ", "page_idx": 13}, {"type": "text", "text": "First we explain why is it technically important for GPC-Simplex that the controller observes $\\gamma_{t}$ . Recall that like the algorithm GPC from [1], GPC-Simplex is a disturbance-action controller, meaning that the control at time $t$ is computed based on previous disturbances $w_{t-i}$ . In the standard LDS model (Definition 9) studied by [1], it\u2019s clear that $w_{t-1}$ can be computed from $x_{t-1}$ , $u_{t-1},x_{t}$ , using the fact that $A,B$ are known. However, in the simplex LDS model, if $\\gamma_{t-1}$ is not directly observed, then in fact $w_{t-1}$ may not be uniquely identifiable given $x_{t-1},u_{t-1},x_{t}$ . This is why GPC-Simplex requires observing the parameters $\\gamma_{t}$ . It is an interesting open problem whether this assumption can be removed. ", "page_idx": 13}, {"type": "text", "text": "Second, we argue that in many practical applications, it is reasonable for $\\gamma_{t-1}$ to be observed along with the population state $x_{t}$ . The reason is that often the controller can observe not just the proportions of individuals of different categories in a population but also the total population size. ", "page_idx": 13}, {"type": "text", "text": "Formally, consider a population which has $N_{t}$ individuals at time $t$ . Thus, if the distribution of the population across $d$ categories is described by $x_{t}\\,\\in\\,\\Delta^{d}$ , then for each $i\\,\\in\\,[d]$ there are ${\\cal N}_{t}(x_{t})_{i}$ individuals in category $i$ . Suppose that under control $u_{t}\\mathrm{~\\in~}\\mathcal{Z}$ , this population evolves to a new distribution $(1-\\|\\bar{u_{t}}\\|_{1})A x_{t}+\\bar{B}u_{t}$ , but then the adversary adds $n_{t}$ new individuals to the population, whose distribution over categories is given by $w_{t}\\in\\Delta^{d}$ . Then if we write $\\bar{x}_{t}\\in\\mathbb{R}_{\\geq0}^{d}$ to denote the vector of counts of individuals in each category at time $t$ , it holds that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\bar{x}_{t+1}=N_{t}\\big((1-\\|u_{t}\\|_{1})A x_{t}+B u_{t}\\big)+n_{t}w_{t}}&{{}}\\\\ {=N_{t+1}\\left((1-\\gamma_{t})((1-\\|u_{t}\\|_{1})A x_{t}+B u_{t})+\\gamma_{t}w_{t}\\right)}&{{}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $N_{t+1}=N_{t}{+}n_{t}$ is the total number of individuals at time $t{+}1$ , and we write $\\gamma_{t}:=n_{t}/(N_{t}{+}n_{t})$ . Thus, the distribution of the population across the $d$ categories at time $t+1$ is ", "page_idx": 13}, {"type": "equation", "text": "$$\nx_{t+1}=\\frac{\\bar{x}_{t+1}}{N_{t+1}}=\\bigl(1-\\gamma_{t}\\bigr)\\bigl(\\bigl(1-\\|u_{t}\\|_{1}\\bigr)A x_{t}+B u_{t}\\bigr)+\\gamma_{t}w_{t}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "which is exactly the update rule from Definition 3. Moreover, if the controller observes the total population counts $N_{t},N_{t+1}$ in addition to $x_{t},u_{t},x_{t+1}$ , then it may compute $\\gamma_{t}=(N_{t+1}-N_{t})/N_{t+1}$ as well as $w_{t}$ (using knowledge of $A,B)$ , which is what we wanted to show. ", "page_idx": 13}, {"type": "text", "text": "C Proof of Theorem 7 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we prove Theorem 7. We begin with an overview of this section that outlines the structure and the main idea behind the proof of Theorem 7. ", "page_idx": 13}, {"type": "text", "text": "Overview. GPC-Simplex (Algorithm 1) essentially runs mirror descent on the loss functions $\\ell_{t}(p,M^{[{1}:H]})$ constructed in Line 9. In particular, the loss at time $t$ measures the counterfactual cost of following the policy \u03c0p,M r1:Hs for the first $t$ timesteps. Thus, the regret of GPC-Simplex against the comparator class $\\dot{\\kappa}_{\\tau}^{\\triangle}(\\mathcal{L})$ (Definition 6) can be bounded by the following decomposition: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left|\\mathrm{Approximation~error~of~comparator~class}\\right|+\\left[\\mathrm{Mismatch~error~of~costs}\\right]+\\left[\\mathrm{Lazy^{\\mathrm{MiD~regret}}}\\right]\\left[\\mathrm{Asmatch~of~two~progent}\\right]\\left[\\mathrm{Asmatch~of~two~progent}\\right]\\left[\\mathrm{Asmatch~of~two~progent}\\right]\\,,\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "In more detail: ", "page_idx": 14}, {"type": "text", "text": "\u2022 Approximation error of comparator class. Since GPC-Simplex is only optimizing over policies of the form $\\pi^{p,M^{[1:H]}}$ for $(p,M^{[{1:H}]})\\in\\mathcal{X}_{d,H,a_{0},\\overline{{\\alpha}}}$ , we must show that every policy in the comparator class can be approximated by some policy $\\pi^{p,M^{[1:H]}}$ . This is accomplished by Lemma 17. ", "page_idx": 14}, {"type": "text", "text": "\u2022 Mismatch error of costs. The cost incurred by the mirror descent algorithm LazyMD at time $t$ is $\\ell_{t}(p_{t},M_{t}^{[1:H]})$ , which is the counterfactual cost at time $t$ had the current policy $\\pi^{p_{t},M_{t}^{[1:H]}}$ been carried out from the beginning of the time. However, the cost actually incurred by the controller at time $t$ is $c_{t}(x_{t},u_{t})$ , which is the cost incurred by following policy \u03c0ps,M sr1:Hs at time $t$ , for each $s\\leqslant t$ . Thus, there is a mismatch between the loss that GPC-Simplex is optimizing and the loss that GPC-Simplex needs to optimize. This mismatch can be bounded using the stability of mirror descent along with a mixing argument; see Lemma 21. ", "page_idx": 14}, {"type": "text", "text": "LazyMD regret. GPC-Simplex uses LazyMD as its subroutine for mirror descent. The regret of LazyMD can be bounded by standard guarantees; see Corollary 15. ", "page_idx": 14}, {"type": "text", "text": "C.1 Preliminaries on mirror descent ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We begin with some preliminaries regarding mirror descent. Let $\\mathcal{X}\\subset\\mathbb{R}^{d}$ be a convex compact set, and let $R:\\mathcal{X}\\to\\mathbb{R}$ be a convex function. We consider the Lazy Mirror Descent algorithm LazyMD (also known as Following the Regularized Leader) for online convex optimization on $\\mathcal{X}$ . Given an offilne optimization oracle over $\\mathcal{X}$ , the function $R$ , and a parameter $\\eta>0$ , LazyMD chooses each iterate $z_{t}$ based on the historical loss functions $\\ell_{s}:\\mathcal{X}\\to\\mathbb{R}$ (for $s\\in[t-1]$ ) as described in Algorithm 2. ", "page_idx": 14}, {"type": "text", "text": "Algorithm 2 LazyMD: Lazy Mirror Descent [35] ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Require: Offline convex optimization oracle over set $\\mathcal{X}\\,\\subset\\,\\mathbb{R}^{d}$ ; convex regularization function $R:\\mathcal{X}\\to\\mathbb{R}$ ; step size $\\eta>0$ ; loss functions $\\ell_{1},\\dots,\\ell_{T}$ where $\\ell_{t}$ is revealed after iteration $t$ . 1: for $t\\geqslant1$ do ", "page_idx": 14}, {"type": "text", "text": "2: Compute and output the solution to the following convex optimization problem: ", "page_idx": 14}, {"type": "equation", "text": "$$\nz_{t}:=\\arg\\operatorname*{min}_{z\\in\\mathcal{X}}\\sum_{s=1}^{t-1}\\langle z,\\nabla\\ell_{s}(z_{s})\\rangle+\\frac{1}{\\eta}R(z),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "3: Receive loss function $\\ell_{t}:\\mathcal{X}\\to\\mathbb{R}$ . ", "page_idx": 14}, {"type": "text", "text": "The following lemma bounds the regret of LazyMD against the single best $z\\in\\mathcal{X}$ (in hindsight), for an appropriately chosen step size $\\eta$ . ", "page_idx": 14}, {"type": "text", "text": "Lemma 10 (Mirror descent). Suppose that $\\mathcal{X}\\subset\\mathbb{R}^{d}$ is convex and compact, and let $\\lVert\\cdot\\rVert$ be a norm on $\\mathbb{R}^{d}$ . Let $R:\\mathcal{X}\\to\\mathbb{R}$ be a 1-strongly convex function with respect to $\\left\\Vert\\cdot\\right\\Vert$ . Let $L>0$ , and let $\\begin{array}{r}{\\rho:=\\operatorname*{max}_{z\\in\\mathcal{X}}R(z)-\\operatorname*{min}_{z\\in\\mathcal{X}}R(z)}\\end{array}$ . ", "page_idx": 14}, {"type": "text", "text": "Fix an arbitrary sequence of loss functions $\\ell_{t}:\\mathcal{X}\\to\\mathbb{R}$ which are each convex and $L$ -Lipschitz with respect to $\\|\\cdot\\|$ . Then the iterate?s $z_{t}$ of LazyMD (Eq. (14)) with an optimization oracle over $\\mathcal{X}$ , regularizer $R$ , step size $\\eta=\\sqrt{\\rho}/(L\\sqrt{2T})$ , and loss functions $\\ell_{1},\\dots,\\ell_{T}$ satisfy: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\ell_{t}(z_{t})-\\operatorname*{min}_{z\\in\\mathcal{X}}\\sum_{t=1}^{T}\\ell_{t}(z)\\leqslant L{\\sqrt{8\\rho T}}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Moreover, for each $t\\in[T-1]$ , it holds that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|z_{t}-z_{t+1}\\|\\leqslant{\\sqrt{\\frac{\\rho}{2T}}}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Lemma 10 is essentially standard but we provide a proof for completeness. ", "page_idx": 15}, {"type": "text", "text": "Proof of Lemma $I O$ . By [18, Theorem 5.2], it holds that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\ell_{t}(z_{t})-\\operatorname*{min}_{z\\in\\mathcal{X}}\\ell_{t}(z)\\leqslant2\\eta\\sum_{t=1}^{T}\\|\\nabla\\ell_{t}(z_{t})\\|_{\\star}^{2}+\\frac{\\rho}{\\eta}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\|\\cdot\\|_{\\star}:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}$ is the dual norm of $\\lVert\\cdot\\rVert$ , defined by $\\|y\\|_{\\star}:=\\operatorname*{max}_{\\|z\\|\\leqslant1}\\langle y,z\\rangle$ . Recall that a convex $L$ -Lipschitz loss function $\\ell_{t}$ satisfies $\\|\\nabla\\ell_{t}(z)\\|_{\\star}\\leqslant L$ for all $z\\in\\mathcal{X}$ . Thus, the above regret bound simplifies to ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\ell_{t}(z_{t})-\\operatorname*{min}_{z\\in\\mathcal{X}}\\ell_{t}(z)\\leqslant2\\eta T L^{2}+\\frac{\\rho}{\\eta}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Substituting in $\\begin{array}{r}{\\eta=\\frac{\\sqrt{\\rho}}{L\\sqrt{2T}}}\\end{array}$ yields Eq. (15). To establish the movement bound Eq. (16), we argue as follows. Consider any $y_{1},y_{2}\\in\\mathbb{R}^{d}$ and define, for $i\\in\\{1,2\\}$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\nw_{i}:=\\arg\\operatorname*{min}_{z\\in\\mathcal{X}}\\langle y_{i},z\\rangle+R(z).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The definition of $w_{2}$ implies that ", "page_idx": 15}, {"type": "equation", "text": "$$\nR(w_{1})-\\langle y_{2},w_{2}\\rangle+\\langle y_{2},w_{1}\\rangle\\geqslant R(w_{2})\\geqslant R(w_{1})+\\langle\\nabla R(w_{1}),w_{2}-w_{1}\\rangle+\\frac{1}{2}\\left\\|w_{2}-w_{1}\\right\\|^{2}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the second inequality is by 1-strong convexity of $R$ . Simplifying, we get ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\|w_{1}-w_{2}\\|^{2}\\leqslant\\langle y_{2},w_{1}-w_{2}\\rangle+\\langle\\nabla R(w_{1}),w_{2}-w_{1}\\rangle.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Symmetrically, the definition of $w_{1}$ together with strong convexity implies that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac12\\|w_{1}-w_{2}\\|^{2}\\leqslant\\left\\langle y_{1},w_{2}-w_{1}\\right\\rangle+\\left\\langle\\nabla R(w_{2}),w_{1}-w_{2}\\right\\rangle\\!.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Adding the two above displays gives ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|w_{1}-w_{2}\\right\\|^{2}\\leqslant\\langle y_{2}-y_{1},w_{1}-w_{2}\\rangle+\\langle\\nabla R(w_{1})-\\nabla R(w_{2}),w_{2}-w_{1}\\rangle}\\\\ &{\\qquad\\qquad\\leqslant\\|y_{2}-y_{1}\\|_{\\star}\\cdot\\|w_{1}-w_{2}\\|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the second inequality uses convexity of $R$ (which gives $\\langle\\nabla R(w_{1})-\\nabla R(w_{2}),w_{1}-w_{2}\\rangle\\geqslant0\\rangle$ . It follows that $\\|w_{1}-w_{2}\\|\\leqslant\\|y_{1}-y_{2}\\|_{\\star}$ . Setting $\\begin{array}{r}{y_{1}:=\\eta\\sum_{s=1}^{t-1}\\nabla\\ell_{s}(z_{s})}\\end{array}$ and $\\begin{array}{r}{y_{2}:=\\eta\\sum_{s=1}^{t}\\nabla\\ell_{s}(z_{s})}\\end{array}$ , and recalling the definitions of $z_{t},z_{t+1}$ from Eq. (14), w e \u0159get ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\boldsymbol{z}_{t}-\\boldsymbol{z}_{t+1}\\|\\leqslant\\|\\eta\\nabla\\ell_{t}(\\boldsymbol{z}_{t})\\|_{\\star}\\leqslant\\eta L\\leqslant\\sqrt{2\\rho/T},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "as desired. ", "page_idx": 15}, {"type": "text", "text": "We next apply Lemma 10 to the domain used in GPC-Simplex. Recall that, given $d,H\\in\\mathbb{N}$ and real numbers $0\\leqslant a\\leqslant b\\leqslant1$ , we have defined $\\textstyle\\mathcal{X}_{d,H,a,b}:=\\bigcup_{a^{\\prime}\\in[a,b]}^{}\\Delta_{a^{\\prime}}^{d}\\,\\times\\,(\\mathbb{S}_{a^{\\prime}}^{d})^{\\overline{{H}}}$ . ", "page_idx": 15}, {"type": "text", "text": "Definition 11 (Entropy of a sub-distribution). Let $d\\in\\mathbb{N}$ . We define the function $\\mathrm{Ent}:\\Delta_{\\leqslant1}^{d}\\rightarrow\\mathbb{R}_{\\geqslant0}$ by ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname{Ent}(v):=v^{\\mathrm{c}}\\ln{\\frac{1}{v^{\\mathrm{c}}}}+\\sum_{j=1}^{d}v_{j}\\ln{\\frac{1}{v_{j}}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where for any vector $\\boldsymbol{v}\\in\\mathbb{R}^{d}$ we write $\\begin{array}{r}{v^{\\mathrm{c}}:=1-\\sum_{j=1}^{d}v_{j}\\in\\mathbb{R}}\\end{array}$ . ", "page_idx": 15}, {"type": "text", "text": "Lemma 12. Let $d\\in\\mathbb{N}$ and $u,v\\in\\Delta_{\\leq1}^{d}$ . Then ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\langle\\nabla_{u}\\operatorname{Ent}(u)-\\nabla_{v}\\operatorname{Ent}(v),u-v\\rangle\\leqslant-\\left\\|u-v\\right\\|_{1}^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "That is, $v\\mapsto-\\operatorname{Ent}(v)$ is 1-strongly convex on $\\Delta_{\\leqslant1}^{d}$ with respect to $\\left\\Vert\\cdot\\right\\Vert_{1}$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. Let $p$ be the probability mass function on $[d+1]$ with $p_{i}=u_{i}$ for all $i\\in[d]$ , and let $q$ be the probability mass function on $[d+1]$ with $p_{i}=v_{i}$ for all $i\\in[d]$ . Then it can be checked that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle\\nabla_{u}\\operatorname{Ent}(u)-\\nabla_{v}\\operatorname{Ent}(v),v-u\\rangle=\\operatorname{KL}(p||q)+\\operatorname{KL}(q||p)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\quad\\geqslant\\operatorname{TV}(p,q)^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\quad\\geqslant\\|u-v\\|_{1}^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the first inequality is by Pinsker\u2019s inequality. ", "page_idx": 16}, {"type": "text", "text": "Definition 13 (Regularizer for mirror descent in GPC-Simplex). Let $d,H\\in\\mathbb{N}$ and $0\\leqslant a\\leqslant b\\leqslant1$ . We define $R_{d,H}\\;:\\;\\mathcal{X}_{d,H,a,b}\\;\\to\\;\\mathbb{R}_{\\leqslant0}$ as follows (omitting the domain\u2019s dependence on $a,b$ for notational simplicity): ", "page_idx": 16}, {"type": "equation", "text": "$$\nR_{d,H}(p,M^{[1:H]}):=-\\operatorname{Ent}(p)-\\sum_{h=1}^{H}\\sum_{j=1}^{d}\\operatorname{Ent}(M_{\\cdot,j}^{[h]}).,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Definition 14 (Norm for analysis of mirror descent in GPC-Simplex). Let $d,H\\in\\mathbb{N}$ , and identify $\\mathbb{R}^{d+H d^{2}}$ with $\\mathbb{R}^{d}\\times(\\mathbb{R}^{d\\times d})^{H}$ . We define a norm $\\|\\cdot\\|_{d,H}$ on $\\mathbb{R}^{d+H d^{2}}$ as follows: for $p\\in\\mathbb{R}^{d},M^{[1:H]}\\in$ $(\\mathbb{R}^{d\\times d})^{H}$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\left\\|(p,M^{[1:H]})\\right\\|_{d,H}^{2}:=\\|p\\|_{1}^{2}+\\sum_{h=1}^{H}\\sum_{j=1}^{d}\\left\\|M_{\\cdot,j}^{[h]}\\right\\|_{1}^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Corollary 15. Let $d,H\\in\\mathbb{N}$ and $0\\leqslant a\\leqslant b\\leqslant1$ . Consider an arbitrary sequence of cost functions $\\ell_{t}:\\mathcal{X}_{d,H,a,b}\\to\\mathbb{R}$ which are convex and $L$ -Lipschitz with respect to $\\|\\cdot\\|_{d,H}$ . Then the iterates $z_{t}$ of LazyMD with $\\eta=\\sqrt{2d H\\ln(d)}/(L\\sqrt{T})$ , regularizer $R_{s}$ , and loss functions $\\ell_{1},\\dots,\\ell_{T}$ satisfy the following regret guaraantee: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\ell_{t}((p_{t},M_{t}^{[1:H]}))-\\operatorname*{min}_{(p,M^{[1:H]})\\in\\mathcal{X}_{d,H,a,b}}\\sum_{t=1}^{T}\\ell_{t}((p,M^{[1:H]}))\\leqslant L\\sqrt{32d H\\ln(d)\\cdot T}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Moreover, for \u03b2 :\u201c 2d?H lnpdq, for all $t\\in[T-1],$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|p_{t}-p_{t+1}\\|_{1}\\leqslant\\beta,\\qquad\\operatorname*{max}_{h\\in[H]}\\left\\|M_{t}^{[h]}-M_{t+1}^{[h]}\\right\\|_{1\\to1}\\leqslant\\beta.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. Note that the set of $(p,M^{[{1:H}]})$ where $p\\,\\in\\,\\mathbb{R}^{d}$ and $M^{[{1:H}]}\\,\\in\\,(\\mathbb{R}^{d\\times d})^{H}$ can be identified with $\\mathbb{R}^{d+H d^{2}}$ . We apply Lemma 10 with $\\mathcal{X}\\,:=\\,\\mathcal{X}_{d,H,a,b}$ , $R\\,=\\,R_{d,H}$ , and the norm $\\|\\cdot\\|_{d,H}$ . It is straightforward to check that $\\mathcal{X}$ is convex and compact in $\\mathbb{R}^{d+H d^{2}}$ . By Lemma 12, we have that $R_{d,H}$ is 1-strongly convex with respect to the norm $\\|\\cdot\\|_{d,H}$ . Moreover, note that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{(p,M^{[1:H]})\\in\\mathcal{X}_{d,H,a,b}}{\\operatorname*{max}}R_{d,H}((p,M^{[1:H]}))-\\underset{(p,M^{[1:H]})\\in\\mathcal{X}_{d,H,a,b}}{\\operatorname*{min}}R_{d,H}((p,M^{[1:H]}))}\\\\ &{\\qquad\\qquad\\leqslant(1+d H)\\ln(d+1)}\\\\ &{\\leqslant4d H\\ln(d)}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "since $0\\,\\leqslant\\,\\mathrm{Ent}(v)\\,\\leqslant\\,\\ln(d+1)$ for all $v\\,\\in\\,\\Delta_{\\leqslant1}^{d}$ . Thus, Lemma 10 implies the claimed bounds Eqs. (18) and (19), where to prove Eq. (19) we are using the fact that $\\begin{array}{r}{\\|C\\|_{1\\to1}^{-}=\\operatorname*{max}_{j\\in[d]}\\|C._{,j}\\|_{1}\\leqslant}\\end{array}$ j d }C\u00a8,j}2 for all C P Rd\u02c6d. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "C.2 Approximation of linear policies ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Henceforth fix a simplex LDS $\\mathcal{L}=(A,B,\\mathcal{T},x_{1},(\\gamma_{t})_{t},(w_{t})_{t},(c_{t})_{t})$ on $\\Delta^{d}$ , where $\\textstyle{\\mathcal{T}}=\\bigcup_{\\alpha\\in[\\underline{{\\alpha}},\\overline{{\\alpha}}]}\\Delta_{\\alpha}^{d}$ for some constants $0\\leqslant\\underline{{\\alpha}}\\leqslant\\overline{{\\alpha}}\\leqslant1$ . ", "page_idx": 17}, {"type": "text", "text": "Recall that any choice of parameters $(p,M^{[{1:H}]})\\in\\mathcal{X}_{d,H,a,b}$ (for some hyperparameters $H\\in\\mathbb{N}$ and \u03b1 \u010f a \u010f b \u010f \u03b1) induces, via Eq. (8), a set of policies p\u03c0sp,M r1:Hsq sPrT s. The policy \u03c0sp,M r1:Hst akes as input the disturbances $w_{s-1},\\dots,w_{s-H}$ observed at the time steps before step $s$ , and outputs a control for step $s$ . Recall that, in Algorithm 1, we used $x_{t}(p,M^{[1:H]}\\bar{)},u_{t}(p,M^{[1:H]})$ to denote the state and control at time step t one would observe by playing the control \u03c0sp,M r1:Hsp $\\pi_{s}^{p,M^{[1:H]}}(w_{s-1:s-H})$ at step $s$ , for each $1\\leqslant s\\leqslant t$ . ", "page_idx": 17}, {"type": "text", "text": "Formally, we have the following expressions for $x_{t}(p,M^{[1:H]}),u_{t}(p,M^{[1:H]})$ : ", "page_idx": 17}, {"type": "text", "text": "Fact 16. For any $(p,M^{[{1:H}]})\\in\\mathcal{X}_{d,H,a,b}$ and $t\\in[T]$ , it holds that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\cdot t(p,M^{[1:H]})=\\sum_{i=1}^{t}\\alpha_{t,i}^{p,M^{[1:H]}}\\cdot A^{i-1}\\cdot\\left(\\lambda_{t-i,0}\\bar{\\lambda}_{t,i}\\cdot B\\cdot p+B\\sum_{j=1}^{H}\\lambda_{t,i+j}\\cdot M^{[j]}\\cdot w_{t-i-j}+\\lambda_{t,i}\\cdot w_{t-i-j}\\cdot w_{t-j}\\right).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\nu_{t}(\\boldsymbol{p},\\boldsymbol{M}^{[1:H]})=\\pi_{t}^{\\boldsymbol{p},\\boldsymbol{M}^{[1:H]}}(w_{t-1:t-H})=\\lambda_{t,0}\\cdot\\boldsymbol{p}+\\sum_{j=1}^{H}\\lambda_{t,j}\\cdot\\boldsymbol{M}^{[j]}\\cdot\\boldsymbol{w}_{t-j},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. This follows unrolling Eq. (6) with the controls us :\u201c \u03c0sp,M r1:Hsp $u_{s}:=\\pi_{s}^{p,M^{[1:H]}}(w_{s-1:s-H})$ , and recalling the definitions in Eq. (7) and the conventions $w_{0}:=x_{1}$ , $\\gamma_{0}=1$ , and $w_{t}=0$ for $t<0$ . \u53e3 ", "page_idx": 17}, {"type": "text", "text": "In a sense, Algorithm 1 performs online convex optimization over the set of such policies. Even if we can manage to show that doing so yields a good regret guarantee with respect to the class of policies $\\left\\{\\pi_{t}^{p,M^{[1:H]}}\\;:\\;\\left(p,M^{[1:H]}\\right)\\in\\mathcal{X}_{d,H,a,b}\\right\\}$ for some choices of $H,a,b$ , why should this imply a good regret guarantee with respect to the class $\\kappa_{\\tau}^{\\triangle}(\\mathcal{L})$ of linear policies (see Definition 6)? Lemma 17 bridges this gap, showing that any policy in $\\kappa_{\\tau}^{\\triangle}(\\mathcal{L})$ can be approximated by a policy of the form $(\\pi_{s}^{p,M^{[1:H]}})_{s\\in[T]}$ . ", "page_idx": 17}, {"type": "text", "text": "Lemma 17 (Approximation). Suppose that the cost functions $c_{1},\\ldots,c_{T}$ of $\\mathcal{L}$ satisfy Assumption $^{\\,l}$ with Lipschitz parameter $L$ . Fix $\\tau>0$ , $\\varepsilon\\in(0,1)$ , and any $K^{\\star}\\in\\mathbb{S}_{\\leqslant1}^{d}$ such that $t^{\\mathsf{m i x}}(\\mathbb{A}_{K^{\\star}})\\leqslant\\tau$ . Write $\\alpha^{\\star}:=\\|K^{\\star}\\|_{1\\rightarrow1}$ . I $f H\\geqslant\\tau\\lceil\\log_{2}(2L T^{2}/\\varepsilon)\\rceil,$ , then there is some $(p,M^{[{1:H}]})\\in\\Delta_{\\alpha^{\\star}}^{d}\\,\\times\\,(\\mathbb{S}_{\\alpha^{\\star}}^{d})^{H}$ such that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}c_{t}(x_{t}(p,M^{[1:H]}),u_{t}(p,M^{[1:H]}))-\\sum_{t=1}^{T}c_{t}(x_{t}(K^{\\star}),u_{t}(K^{\\star}))\\leqslant\\varepsilon,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $x_{t}(K^{\\star}),u_{t}(K^{\\star})$ denote the state and control that one would observe at time step $t$ if one were to play according to the policy $x\\mapsto K^{\\star}x$ at all time steps $1\\leqslant s\\leqslant t$ . ", "page_idx": 17}, {"type": "text", "text": "Proof. For each $t$ , if the controls $u_{t}$ are chosen to satisfy $u_{t}:=K^{\\star}\\cdot x_{t}$ , then we have $\\alpha_{t}:=\\|K^{\\star}\\|_{1\\rightarrow1}$ . Moreover, for $1\\leqslant t\\leqslant T$ , we can write ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle x_{t}(K^{\\star})=\\sum_{i=1}^{t}(\\mathbb{A}_{K^{\\star}})^{i-1}\\cdot\\left(\\prod_{j=1}^{i-1}(1-\\gamma_{t-j})\\right)\\cdot\\gamma_{t-i}w_{t-i}=\\sum_{i=1}^{t}\\mathbb{A}_{K^{\\star}}^{i-1}\\cdot\\lambda_{t,i}\\cdot w_{t-i},}}\\\\ {{\\displaystyle u_{t}(K^{\\star})=K^{\\star}\\cdot x_{t}(K^{\\star})=\\sum_{i=1}^{t}K^{\\star}\\mathbb{A}_{K^{\\star}}^{i-1}\\cdot\\lambda_{t,i}\\cdot w_{t-i}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\mathbb{A}_{K^{\\star}}$ was defined in Eq. (5). By the assumption that $t^{\\mathsf{m i x}}(\\mathbb{A}_{K^{\\star}})\\leqslant\\tau$ , there is some unique $p^{\\prime}\\,\\in\\,\\Delta^{d}$ such that that $\\mathbb{A}_{K^{\\star}}\\,\\cdot\\,p^{\\prime}\\;=\\;p^{\\prime}$ (see Definition 5). Moreover, by our bound on $H$ and ", "page_idx": 17}, {"type": "text", "text": "Lemma 18, for any $i>H$ and $q\\in\\Delta^{d}$ we have $\\begin{array}{r}{\\left\\|\\mathbb{A}_{K^{\\star}}^{i-1}q-p^{\\prime}\\right\\|_{1}\\leqslant(1/2)^{H/\\tau}\\leqslant\\varepsilon/(2L T^{2})}\\end{array}$ . Using that $\\begin{array}{r}{\\lambda_{t,0}=\\sum_{i=H+1}^{t}\\lambda_{t,i}}\\end{array}$ by the definition in Eq. (7),\u203a ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\left\\|\\displaystyle\\sum_{i=H+1}^{t}\\boldsymbol{K}^{\\star}\\mathbb{A}_{K^{\\star}}^{i-1}\\lambda_{t,i}w_{t-i}-\\lambda_{t,0}\\cdot\\boldsymbol{K}^{\\star}p^{\\prime}\\right\\|_{1}=\\displaystyle\\left\\|\\boldsymbol{K}^{\\star}\\displaystyle\\sum_{i=H+1}^{t}\\lambda_{t,i}(\\mathbb{A}_{K^{\\star}}^{i-1}w_{t-i}-p^{\\prime})\\right\\|_{1}}&{}\\\\ {\\leqslant\\displaystyle\\sum_{i=H+1}^{t}\\lambda_{t,i}\\cdot\\big\\|\\mathbb{A}_{K^{\\star}}^{i-1}w_{t-i}-p^{\\prime}\\big\\|_{1}\\leqslant\\varepsilon/(2L T^{2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For $1\\leqslant i\\leqslant H$ , let us define $M^{[i]}:=K^{\\star}\\mathbb{A}_{K^{\\star}}^{i-1}\\in\\mathbb{S}_{\\alpha^{\\star}}^{d}$ and $p:=K^{\\star}\\cdot p^{\\prime}\\in\\Delta_{\\alpha^{\\star}}^{d}$ . Using Eqs. (21) and (24), we have that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\left\\|u_{t}(K^{\\star})-u_{t}(p,M^{[1:H]})\\right\\|_{1}=\\left\\|\\displaystyle\\sum_{i=1}^{t}K^{\\star}\\mathbb{A}_{K^{\\star}}^{i-1}\\lambda_{t,i}w_{t-i}-\\lambda_{t,0}p-\\displaystyle\\sum_{j=1}^{H}\\lambda_{t,j}M^{[j]}w_{t-j}\\right\\|_{1}}}\\\\ &{=\\left\\|\\displaystyle\\sum_{i=H+1}^{t}K^{\\star}\\mathbb{A}_{K^{\\star}}^{i-1}\\lambda_{t,i}w_{t-i}-\\lambda_{t,0}\\cdot K^{\\star}p^{\\prime}\\right\\|_{1}}\\\\ &{\\leqslant\\varepsilon/(2L T^{2}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the final inequality uses Eq. (25). ", "page_idx": 18}, {"type": "text", "text": "Next, we may bound the difference in state vectors using Eq. (26), as follows: for any sequence of $(u_{i})_{i=1}^{t}$ with $\\left\\|u_{i}\\right\\|_{1}=\\alpha^{\\star}$ for all $i$ , we can expand Eq. (6) to get ", "page_idx": 18}, {"type": "equation", "text": "$$\nx_{t}=\\sum_{i=1}^{t}(1-\\alpha^{\\star})^{i-1}A^{i-1}(\\bar{\\lambda}_{t,i}B u_{t-i}+\\lambda_{t,i}w_{t-i}).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Thus, for any $t\\in[T]$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\left\\|x_{t}(K^{\\star})-x_{t}(p,M^{[1:H]})\\right\\|_{1}\\leqslant\\displaystyle\\sum_{i=1}^{t}(1-\\alpha^{\\star})^{i-1}\\bar{\\lambda}_{t,i}\\cdot\\left\\|A^{i-1}B\\cdot\\left(u_{t-i}(K^{\\star})-u_{t-i}(p,M^{[1:H]})\\right)\\right\\|_{1}}\\\\ {\\leqslant\\displaystyle\\frac{\\varepsilon}{2L T^{2}}\\cdot\\displaystyle\\sum_{i=1}^{t}\\bar{\\lambda}_{t,i}}\\\\ {\\leqslant\\displaystyle\\frac{\\varepsilon}{2L T}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "By Eqs. (26) and (27) and Assumption 1, it follows that, for each $t\\in[T]$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left|c_{t}(x_{t}(p,M^{[1:H]}),u_{t}(p,M^{[1:H]}))-c_{t}(x_{t}(K^{\\star}),u_{t}(K^{\\star}))\\right|\\leqslant\\varepsilon/T,\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "which yields the \u02c7claimed bound Eq. (22). ", "page_idx": 18}, {"type": "text", "text": "The following facts about distance to stationarity are well-known (see e.g. [31, Section 4.4]): ", "page_idx": 18}, {"type": "text", "text": "Lemma 18. Let $X\\in\\mathbb{S}^{d}$ have a unique stationary distribution $\\pi$ . Then the following inequalities hold for any $c,t\\in\\mathbb{N}$ : ", "page_idx": 18}, {"type": "text", "text": "C.3 Bounding the memory mismatch error ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In this section, we prove Lemma 21, which allows us to show that an algorithm with bounded aggregate loss with respect to the loss functions $\\ell_{t}$ defined on Line 9 of Algorithm 1 in fact has bounded aggregate cost with respect to the cost functions $c_{t}$ chosen by the adversary. ", "page_idx": 18}, {"type": "text", "text": "First, we introduce two useful lemmas on the mixing time of matrices (Definition 5). ", "page_idx": 18}, {"type": "text", "text": "Lemma 19. Let $X\\in\\mathbb{S}^{d}$ have a unique stationary distribution. Let $Y\\in\\mathbb{S}^{d}$ satisfy $\\|X-Y\\|_{1\\to1}\\leqslant\\delta$ . Then for any $t\\in\\mathbb{N}$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\nD_{Y}(t)\\leqslant2t\\delta+2D_{X}(t).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. For any $v\\in\\Delta^{d}$ , we have $\\begin{array}{r}{\\|\\boldsymbol{X}\\boldsymbol{v}-\\boldsymbol{Y}\\boldsymbol{v}\\|_{1}\\leqslant\\delta}\\end{array}$ . A hybrid argument then yields that for any $t\\geqslant1$ , $\\|X^{t}\\bar{v}-Y^{t}v\\|_{1}\\leqslant t\\delta$ . Then ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\bar{D}_{Y}(t)\\leqslant\\operatorname*{sup}_{p,q\\in\\Delta^{d}}\\left\\|Y^{t}(p-q)\\right\\|_{1}\\leqslant2t\\delta+\\operatorname*{sup}_{p,q\\in\\Delta^{d}}\\left\\|X^{t}(p-q)\\right\\|_{1}\\leqslant2t\\delta+\\bar{D}_{X}(t)\\leqslant2t\\delta+2D_{X}(t),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the first and last inequalities apply the first item of Lemma 18. ", "page_idx": 19}, {"type": "text", "text": "Lemma 20. Suppose that $A,B\\in\\mathbb{S}^{d}$ , $K^{\\star}\\in\\mathbb{S}_{\\leqslant1}^{d}$ satisfy $t^{\\mathrm{mix}}(A)>4\\cdot t^{\\mathrm{mix}}(\\mathbb{A}_{K^{\\star}})$ . Then $\\|K^{\\star}\\|_{1\\to1}>$ $1/(96\\cdot t^{\\sf m i x}(\\mathbb{A}_{K^{\\star}}))$ . ", "page_idx": 19}, {"type": "text", "text": "Proof. Let us write $\\tau:=\\,t^{\\mathrm{mix}}(\\mathbb{A}_{K^{\\star}})$ and $\\alpha^{\\star}:=\\|K^{\\star}\\|_{1\\rightarrow1}$ , so that $\\mathbb{A}_{K^{\\star}}\\,=\\,(1-\\alpha^{\\star})\\cdot A\\,+\\,B K^{\\star}$ . Suppose for the purpose of contradiction that $\\alpha^{\\star}\\,\\leqslant\\,\\bar{1}/(96\\tau)$ . We have that $\\|A-\\mathbb{A}_{K^{\\star}}\\|_{1\\rightarrow1}\\leqslant$ $2\\alpha^{\\star}$ . By Lemma 18 and Definition 5, we have $\\bar{D}_{\\mathbb{A}_{K^{\\star}}}(\\tau)\\,\\leqslant\\,2D_{\\mathbb{A}_{K^{\\star}}}(\\tau)\\,\\leqslant\\,1/2$ , so $D_{\\mathbb{A}_{K^{\\star}}}(4\\tau)\\ \\leqslant$ $\\bar{D}_{\\mathbb{A}_{K^{\\star}}}(4\\tau)\\leqslant1/16$ . Using Lemma 19 and the assumption on $\\alpha^{\\star}$ , ", "page_idx": 19}, {"type": "equation", "text": "$$\nD_{A}(4\\tau)\\leqslant12\\tau\\alpha^{\\star}+2D_{\\mathbb{A}_{K^{\\star}}}(4\\tau)\\leqslant12\\tau\\alpha^{\\star}+1/8\\leqslant1/4,\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "meaning that $t^{\\mathrm{mix}}(A)\\leqslant4\\tau$ . ", "page_idx": 19}, {"type": "text", "text": "The last step is to bound the memory mismatch error. ", "page_idx": 19}, {"type": "text", "text": "Lemma 21 (Memory mismatch error). Suppose that $(c_{t})_{t}$ satisfy Assumption 1 with Lipschitz parameter $L$ . Let $\\tau,\\beta\\;>\\;0,$ , and suppose that $\\kappa_{\\tau}^{\\triangle}(\\mathcal{L})$ is nonempty. Consider the execution of GPC-Simplex (Algorithm $^{\\,l}$ ) on $\\mathcal{L}$ with input $\\tau$ . If the iterates $(p_{t},M_{t}^{[1:H]})_{t\\in[T]}$ satisfy ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\|p_{t}-p_{t+1}\\|_{1}\\leqslant\\beta,\\qquad\\operatorname*{max}_{i\\in[H]}\\left\\|M_{t}^{[i]}-M_{t+1}^{[i]}\\right\\|_{1\\to1}\\leqslant\\beta,\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "then for each $t\\in[T]$ , the loss function $\\ell_{t}$ computed at time step $t$ satisfies ", "page_idx": 19}, {"type": "equation", "text": "$$\n|\\ell_{t}(p_{t},M_{t}^{[1:H]})-c_{t}(x_{t},u_{t})|\\leqslant O\\left(L\\tau^{3}\\beta\\log^{3}(1/\\beta)\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. Recall that $u_{t}\\in\\Delta^{d}$ denotes the control chosen in step $t$ of Algorithm 1. We write $\\alpha_{t}:=\\|u_{t}\\|_{1}$ and, for $i\\in[t]$ , $\\begin{array}{r}{\\alpha_{t,i}:=\\prod_{j=1}^{i-1}(1-\\alpha_{t-j})}\\end{array}$ . Note that $\\alpha_{t}=\\left\\|p_{t}\\right\\|_{1}=\\left\\|M_{t}^{[h]}\\right\\|_{1\\to1}$ for each $h\\in[H]$ , by definition of Xd,H,a0,\u03b1. ", "page_idx": 19}, {"type": "text", "text": "Let us fix $t\\,\\in\\,[T]$ , and write $p\\,:=\\,p_{t},M^{[1:H]}\\;:=\\;M_{t}^{[1:H]}$ . By Eq. (6), the state $x_{t}$ at step $t$ of Algorithm 1 can be written as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\nx_{t}=\\sum_{i=1}^{t}\\alpha_{t,i}\\cdot A^{i-1}\\cdot\\left(\\lambda_{t-i,0}\\bar{\\lambda}_{t,i}B p_{t-i}+B\\sum_{j=1}^{H}M_{t-i}^{[j]}\\lambda_{t,i+j}w_{t-i-j}+\\lambda_{t,i}w_{t-i}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "By assumption that $\\kappa_{\\tau}^{\\triangle}(\\mathcal{L})$ is nonempty, there is some $K^{\\star}\\in\\mathbb{S}_{[\\underline{{\\alpha}},\\overline{{\\alpha}}]}^{d}$ Srd\u03b1,\u03b1s satisfying tmixpAK\u2039q \u010f \u03c4. Let us write $\\alpha^{\\star}:=\\|K^{\\star}\\|_{1\\rightarrow1}$ , so that $\\mathbb{A}_{K^{\\star}}=(1-\\alpha^{\\star})A+B K^{\\star}$ . Moreover, recall we have written in Algorithm 1 that $\\tau_{A}:=t^{\\mathsf{m i x}}(A)$ . ", "page_idx": 19}, {"type": "text", "text": "For $1\\leqslant i\\leqslant t$ , define ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{v_{i}:=\\lambda_{t-i,0}\\bar{\\lambda}_{t,i}B p_{t-i}+B\\displaystyle\\sum_{j=1}^{H}M_{t-i}^{[j]}\\lambda_{t,i+j}w_{t-i-j}+\\lambda_{t,i}w_{t-i},}}\\\\ {{v_{i}^{\\prime}:=\\lambda_{t-i,0}\\bar{\\lambda}_{t,i}B p+B\\displaystyle\\sum_{j=1}^{H}M^{[j]}\\lambda_{t,i+j}w_{t-i-j}+\\lambda_{t,i}w_{t-i}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Note that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname*{max}\\{\\|v_{i}\\|_{1}\\,,\\|v_{i}^{\\prime}\\|_{1}\\,,\\|v_{i}-v_{i}^{\\prime}\\|_{1}\\}\\leqslant\\lambda_{t-i,0}\\bar{\\lambda}_{t,i}+\\sum_{j=1}^{H}\\lambda_{t,i+j}+\\lambda_{t,i}\\leqslant1.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Next, using Eq. (29) and Eq. (20), we have ", "page_idx": 20}, {"type": "equation", "text": "$$\nx_{t}-x_{t}(p,M^{[1:H]})=\\sum_{i=1}^{t}\\left(\\alpha_{t,i}\\cdot A^{i-1}\\cdot v_{i}-\\alpha_{t,i}^{p,M^{[1:H]}}\\cdot A^{i-1}\\cdot v_{i}^{\\prime}\\right).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The condition Eq. (28) together with the triangle inequality gives that $\\|B p_{t-i}-B p\\|_{1}\\,\\leqslant\\,i\\beta$ and $\\left\\|B M_{t-i}^{[j]}w_{t-i-j}-B M^{[j]}w_{t-i-j}\\right\\|_{1}\\leqslant i\\beta$ for all $i,j\\geqslant1$ , as well as $|\\alpha_{t-i}-\\alpha_{t}|\\leqslant i\\beta$ for all $i\\geqslant1$ . I\u203at follows that }vi \u00b4 vi1}1 \u010f i\u03b2 an\u203ad |\u03b1t,i \u00b4 \u03b1tp,,iM $|\\alpha_{t,i}-\\alpha_{t,i}^{p,M^{[1:H]}}|\\leqslant i^{2}\\beta$ for all $i\\geqslant1$ and that for any $\\ell\\geqslant1$ , $\\sum_{i=1}^{\\ell}\\alpha_{t,i}\\cdot\\|v_{i}\\|_{1}-\\sum_{i=1}^{\\ell}\\alpha_{t,i}^{p,M^{[1:H]}}\\cdot\\left\\|v_{i}^{\\prime}\\right\\|_{1}\\bigg|\\leqslant\\left|\\sum_{i=1}^{\\ell}|\\alpha_{t,i}-\\alpha_{t,i}^{p,M^{[1:H]}}|\\cdot\\left\\|v_{i}\\right\\|_{1}\\right|+\\sum_{i=1}^{\\ell}\\alpha_{t,i}^{p,M^{[1:H]}}\\cdot\\left\\|v_{i}-v_{i}^{\\prime}\\right\\|_{1}$ ", "page_idx": 20}, {"type": "text", "text": "Using Eq. (32) and the fact that $\\begin{array}{r}{\\sum_{i=1}^{t}\\alpha_{t,i}\\left\\Vert v_{i}\\right\\Vert_{1}=\\sum_{i=1}^{t}\\alpha_{t,i}^{p,M^{[1:H]}}\\left\\Vert v_{i}^{\\prime}\\right\\Vert_{1}=1}\\end{array}$ , we see ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\left|\\sum_{i=\\ell+1}^{t}\\alpha_{t,i}\\cdot\\left\\|v_{i}\\right\\|_{1}-\\sum_{i=\\ell+1}^{t}\\alpha_{t,i}^{p,M^{\\left[1:H\\right]}}\\cdot\\left\\|v_{i}^{\\prime}\\right\\|_{1}\\right|\\leqslant\\ell^{3}\\beta.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We consider the followi\u02c7ng two cases: ", "page_idx": 20}, {"type": "text", "text": "Case 1: $\\tau_{A}\\leqslant4\\tau$ . Write $t_{0}\\,=\\,\\lfloor\\tau_{A}\\log_{2}(1/\\beta)\\rfloor$ . Let the stationary distribution of $A$ be denoted $p^{\\star}\\in\\Delta^{d}$ . By Lemma 18, we have that for all $i\\geqslant1$ , $\\|A^{i}\\cdot p-p^{\\star}\\|_{1}\\,\\leqslant\\,D_{A}(i)\\,\\leqslant\\,1/2^{\\lfloor i/\\tau_{A}\\rfloor}$ . Now, using Eq. (31), we may compute ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|x_{i}-x_{i}(B)^{(k+1)}\\right|_{1}}\\\\ &{\\le\\left|\\displaystyle\\sum_{k=1}^{k}\\left(m_{k-1}\\cdot A^{-k-1}\\cdot m-\\alpha_{k,i}^{k,k,n}\\cdot A^{-k-1}\\cdot e^{k}\\right)\\right|_{1}}\\\\ &{\\qquad+\\left|\\displaystyle\\sum_{s=1}^{k}m_{k-1}\\cdot(A^{-k-1}\\cdot m-\\left|s\\right|_{1})\\cdot p^{k}\\right|^{(k+1)}\\cdot p^{k-1}\\sigma_{k,i}^{k,k,n}\\cdot\\left(A^{-k-1}\\cdot e^{k}-\\left|b\\right|_{1}^{s},p^{k}\\right)\\right|_{1}}\\\\ &{\\qquad+\\left|\\displaystyle\\sum_{s=1}^{k}m_{k-1}\\cdot\\left(m_{k-1}\\cdot\\left|b\\right|_{1}^{s},p^{k}-\\sigma_{k,i}^{k,k,n}\\cdot\\left|b\\right|_{1}^{s}\\right)\\cdot p^{k}\\right|_{1}}\\\\ &{\\le\\displaystyle\\sum_{s=1}^{k}\\left(m_{k-1}\\cdot\\left|b^{-k-1}\\cdot(m-s)\\right|_{1}+\\left|m_{k-1}\\cdot\\sigma_{k,i}^{k,k,n}\\right|_{1}^{s},|r|_{1}^{s}\\right)}\\\\ &{\\qquad+\\displaystyle\\sum_{s=1}^{k}\\left(m_{k-1}\\cdot\\left|b^{-k-1}\\cdot(m-s)\\right|_{1}+\\left|m_{k-1}\\cdot\\sigma_{k,i}^{k,k,n}\\right|_{1}^{s},|r|_{1}^{s}\\right)}\\\\ &{\\qquad+\\displaystyle\\sum_{s=1}^{k}\\left(m_{k-1}\\cdot\\left|b^{-k-1}\\cdot e^{-\\left|b\\right|_{1}^{s}}\\right)\\cdot p^{k}\\right|_{1}+\\alpha_{1,1}^{k}\\frac{1}{\\varepsilon}\\left|k^{-1}\\cdot e^{k}-\\left|b^{-k}\\right|_{1}^{s},p^{k}\\right|_{1}\\right)+\\eta_{0}^{k}\\alpha_{1,2}^{k}}\\\\ &{\\le\\left(\\displaystyle\\beta^{2}+\\frac{1}{\\varepsilon}\\right)^{k}\\frac{\\rho^{2}}{\\rho}\\left(m_{k-1}\\cdot\\left|b^{-k}\\right|_{1}^{s},\\frac{1}{\\varepsilon}\\right)^{2}-\\alpha_{k,1}^{k}\\beta \n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "for some universal constants $C,C^{\\prime}$ . Above, the first inequality uses the triangle inequality, the second $\\left\\|v_{i}-v_{i}^{\\prime}\\right\\|_{1}\\leqslant i\\beta$ $\\overline{{|\\alpha_{t,i}-\\alpha_{t,i}^{p,M}|}}\\leqslant i^{2}\\beta$ , $\\|v_{i}^{\\prime}\\|_{1}\\leqslant1$ . The fourth inequality uses the bound $\\begin{array}{r}{\\sum_{i=1+t_{0}}^{t}2^{-\\lfloor i/\\tau_{A}\\rfloor}\\leqslant O(\\tau_{A}\\beta)\\leqslant O(t_{0}\\beta)}\\end{array}$ . ", "page_idx": 20}, {"type": "text", "text": "Case 2: $\\tau_{A}\\;>\\;4\\tau$ . In this case, we claim that $a_{0}\\;\\geqslant\\;1/(96\\tau)$ . By choice of $a_{0}$ in Line 1 of Algorithm 1 and the fact that $\\tau_{A}>4\\tau$ , it suffices to show that $\\overline{{\\alpha}}\\geqslant1/(96\\tau)$ : to see this, note that $\\tau_{A}\\'=t^{\\mathsf{m i x}}(A)\\,>\\,4\\tau\\geqslant4\\cdot t^{\\mathsf{m i x}}(\\mathbb{A}_{K^{\\star}})$ , so Lemma 20 gives that $\\|K^{\\star}\\|_{1\\rightarrow1}>1/(96\\cdot t^{\\sf m i x}(\\mathbb{A}_{K^{\\star}}))\\geqslant$ $1/(96\\tau)$ . But $\\|K^{\\star}\\|_{1\\to1}\\,\\leqslant\\,\\overline{{\\alpha}}$ , and thus $\\overline{{\\alpha}}\\,>\\,1/(96\\tau)$ . This proves that $a_{0}\\;\\geqslant\\;1/(96\\tau)$ . Hence $\\dot{\\alpha_{i}}\\geqslant\\dot{a_{0}}\\geqslant1/(96\\tau)$ , by definition of $\\mathcal{X}_{d,H,a_{0},\\overline{{\\alpha}}}$ , for all $i\\in[T]$ . ", "page_idx": 20}, {"type": "text", "text": "Write $t_{0}:=\\lfloor200\\tau\\cdot\\log(1/\\beta)\\rfloor$ . Then for any $i>t_{0}$ , ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\operatorname*{max}\\{\\alpha_{t,i},\\alpha_{t,i}^{p,M^{[1:H]}}\\}\\leqslant(1-a_{0})^{i-1}\\leqslant(1-1/(96\\tau))^{\\lfloor200\\tau\\cdot\\log(1/\\beta)\\rfloor}\\leqslant O(\\beta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Again using Eq. (31), ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left\\|x_{t}-x_{t}(p,M^{[1:H]})\\right\\|_{1}\\leqslant\\displaystyle\\sum_{i=1}^{t_{0}}\\Big(|\\alpha_{t,i}-\\alpha_{t,i}^{p,M^{[1:H]}}|+\\alpha_{t,i}\\cdot\\left\\|v_{i}-v_{i}^{\\prime}\\right\\|_{1}\\Big)+\\displaystyle\\sum_{i=t_{0}+1}^{t}\\left(\\alpha_{t,i}+\\alpha_{t,i}^{p,M^{[1:H]}}\\right)}\\\\ {\\leqslant\\displaystyle\\sum_{i=1}^{t_{0}}\\left(i^{2}\\beta+i\\beta\\right)+\\displaystyle\\sum_{i=t_{0}+1}^{t}O(\\beta)\\cdot\\left(1-a_{0}\\right)^{i-t_{0}-1}}&{(35)}\\\\ {\\leqslant C t_{0}^{3}\\beta+C\\beta/a_{0}}\\\\ &{\\leqslant C^{\\prime}\\tau^{3}\\log^{3}(1/\\beta)\\cdot\\beta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "for some constants $C,C^{\\prime}$ . Above, the first inequality uses Eq. (30); the second inequality uses the previously derived bounds $\\begin{array}{r}{\\bigl|\\alpha_{t,i}-\\alpha_{t,i}^{p,M^{[1:H]}}\\bigr|\\stackrel{\\cdot}{\\leqslant}i^{2}\\beta}\\end{array}$ and $\\left\\|v_{i}-v_{i}^{\\prime}\\right\\|_{1}\\leqslant i\\beta$ ; and the final inequality uses that $a_{0}\\geqslant1/(96\\tau)$ . ", "page_idx": 21}, {"type": "text", "text": "In both cases, we have $\\left\\|x_{t}-x_{t}(p,M^{[1:H]})\\right\\|_{1}\\leqslant C^{\\prime}\\tau^{3}\\beta\\log^{3}(1/\\beta)$ for some universal constant $C^{\\prime}$ . By definition, the contr\u203a\u203aol $u_{t}$ chosen by Alg\u203a\u203aorithm 1 at time step $t$ is exactly $u_{t}\\,=\\,u_{t}\\bigl(p,M^{[1:H]}\\bigr)$ . Thus, using $L$ -Lipschitzness of $c_{t}$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\ell_{t}(p,M^{[1:H]})-c_{t}(x_{t},u_{t})\\right|=\\left|c_{t}(x_{t}(p,M^{[1:H]}),u_{t}(p,M^{[1:H]}))-c_{t}(x_{t},u_{t})\\right|}\\\\ &{\\qquad\\qquad\\qquad\\leqslant L\\cdot\\left\\|x_{t}-x_{t}(p,M^{[1:H]})\\right\\|_{1}}\\\\ &{\\qquad\\qquad\\qquad\\leqslant C^{\\prime}L\\tau^{3}\\beta\\log^{3}(1/\\beta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "as desired. ", "page_idx": 21}, {"type": "text", "text": "C.4 Proof of Theorem 7 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Before proving Theorem 7, we establish that the loss functions $\\ell_{t}$ used in GPC-Simplex are Lipschitz. Lemma 22. Let $X\\in\\mathbb{S}^{d}$ with $\\tau:=t^{\\mathrm{mix}}(X)<\\infty$ . Then for any $i\\in\\mathbb N$ and $\\boldsymbol{v}\\in\\mathbb{R}^{d}$ with $\\langle\\mathbb{1},v\\rangle=0,$ , it holds that $\\left\\|X^{i}v\\right\\|_{1}\\leqslant2^{-\\left\\lfloor i/\\tau\\right\\rfloor}\\left\\|v\\right\\|_{1}$ . ", "page_idx": 21}, {"type": "text", "text": "Proof. Fix $\\boldsymbol{v}\\in\\mathbb{R}^{d}$ with $\\langle\\mathbb{1},v\\rangle\\,=\\,0$ . We can write $v\\,=\\,v^{+}\\,-\\,v^{-}$ , where $\\boldsymbol{v}^{+},\\boldsymbol{v}^{-}\\,\\in\\,\\mathbb{R}_{\\ge0}^{d}$ are the non-negative and negative components of $v$ respectively. We have $\\begin{array}{r}{\\|v^{+}\\|_{1}\\,=\\,\\|v^{-}\\|_{1}\\,=\\,\\frac{1}{2}\\|v\\|_{1}}\\end{array}$ since $\\langle\\mathbb{1},v\\rangle=0$ . Let $u_{1}:=2v^{+}/\\|v\\|_{1}$ and $u_{2}:=2v^{-}/\\|v\\|_{1}$ , so that $u_{1},u_{2}\\in\\Delta^{d}$ . By Lemma 18 and the definition of $t^{\\mathsf{m i x}}(X)$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\|X^{i}(u_{1}-u_{2})\\|_{1}\\leqslant\\bar{D}_{X}(i)\\leqslant\\bar{D}_{X}(\\tau)^{\\lfloor i/\\tau\\rfloor}\\leqslant(2D_{X}(\\tau))^{\\lfloor i/\\tau\\rfloor}\\leqslant2^{-\\lfloor i/\\tau\\rfloor}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Thus, $\\|X^{\\tau}v\\|_{1}\\leqslant2^{-\\lfloor i/\\tau\\rfloor}\\|v\\|_{1}$ . ", "page_idx": 21}, {"type": "text", "text": "Lemma 23 (Lipschitzness of $\\ell_{t}$ ). Let $\\tau\\,>\\,0$ , and suppose that $\\kappa_{\\tau}^{\\triangle}(\\mathcal{L})$ is nonempty. For each $t\\in[T]$ , the loss function $\\ell_{t}(p,M^{[1:H]})=c_{t}\\big(x_{t}(p,M^{[1:H]}),u_{t}(p,M^{[1:H]})\\big)$ (as defined on Line $^{\\,g}$ of Algorithm $^{\\,l}$ ) is $\\scriptstyle{\\dot{O}}(L\\tau^{2})$ -Lipschitz with respect to the norm $\\|\\cdot\\|_{d,H}$ in $\\mathcal{X}_{d,H,a_{0},\\overline{{\\alpha}}}$ . ", "page_idx": 21}, {"type": "text", "text": "Proof. By $L$ -Lipschitzness of $c_{t}$ with respect to $\\left\\Vert\\cdot\\right\\Vert_{1}$ , it suffices to show that for any $(p_{1},M_{1}^{[1:H]}),(p_{2},M_{2}^{[1:H]})\\in\\mathcal{X}_{d,H,a_{0},\\overline{{\\alpha}}}$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|x_{t}(p_{1},M_{1}^{[1:H]})-x_{t}(p_{2},M_{2}^{[1:H]})\\right\\|_{1}\\leqslant O(\\tau^{2})\\left\\|(p_{1},M_{1}^{[1:H]})-(p_{2},M_{2}^{[1:H]})\\right\\|_{d,H}}\\\\ &{\\left\\|u_{t}(p_{1},M_{1}^{[1:H]})-u_{t}(p_{2},M_{2}^{[1:H]})\\right\\|_{1}\\leqslant O(\\tau^{2})\\left\\|(p_{1},M_{1}^{[1:H]})-(p_{2},M_{2}^{[1:H]})\\right\\|_{d,H}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Fix $(p_{1},M_{1}^{[1:H]}),(p_{2},M_{2}^{[1:H]})\\in\\mathcal{X}_{d,H,a_{0},\\overline{{\\alpha}}}$ , and write ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\varepsilon:=\\operatorname*{max}\\left\\{\\left\\|p_{1}-p_{2}\\right\\|_{1},\\operatorname*{max}_{j\\in[H]}\\left\\|M_{1}^{[j]}-M_{2}^{[j]}\\right\\|_{1\\to1}\\right\\}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Since $\\varepsilon\\leqslant\\left\\|(p_{1},M_{1}^{[1:H]})-(p_{2},M_{2}^{[1:H]})\\right\\|_{d,H}\\!\\!\\!.$ , it suffices to show that Eqs. (36) and (37) hold with $\\varepsilon$ on the righ\u203at-hand sides. ", "page_idx": 22}, {"type": "text", "text": "To verify Eq. (36) in this manner, we define, for $b\\in\\{1,2\\}$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\nv_{i,b}:=\\lambda_{t-i,0}\\bar{\\lambda}_{t,i}\\cdot B\\cdot p_{b}+B\\sum_{j=1}^{H}\\lambda_{t,i+j}\\cdot M_{b}^{[j]}\\cdot w_{t-i-j}+\\lambda_{t,i}\\cdot w_{t-i}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Since $\\begin{array}{r}{\\lambda_{t-i,0}\\bar{\\lambda}_{t,i}\\,+\\,\\lambda_{t,i}\\,+\\,\\sum_{j=1}^{H}\\lambda_{t,i+j}\\,\\,\\leqslant\\,\\,1}\\end{array}$ , we have $\\left\\|v_{i,b}\\right\\|_{1}\\,\\leqslant\\,1$ for each $i\\ \\in\\ [t],b\\ \\in\\ \\{1,2\\}$ . Moreover, $\\begin{array}{r}{\\|v_{i,1}-v_{i,2}\\|_{1}\\leqslant(\\lambda_{t-i,0}\\bar{\\lambda}_{t,i}+\\sum_{j=1}^{H}\\lambda_{t,i+j})\\cdot\\varepsilon\\leqslant\\varepsilon}\\end{array}$ . Write $\\sigma_{1}:=\\left\\|p_{1}\\right\\|_{1},\\sigma_{2}:=\\left\\|p_{2}\\right\\|_{1}$ , so that $|\\sigma_{1}-\\sigma_{2}|\\leqslant\\varepsilon$ and $|(1-\\sigma_{1})^{i}-(1-\\sigma_{2})^{i}|\\leqslant i\\varepsilon$ for all $i\\geqslant1$ . Also note that for each $b\\in\\{1,2\\}$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{i=1}^{t}(1-\\sigma_{b})^{i-1}\\cdot\\|v_{i,b}\\|_{1}=\\sum_{i=1}^{t}(1-\\sigma_{b})^{i-1}\\cdot\\bar{\\lambda}_{t,i-1}\\cdot\\big((1-\\gamma_{t-i})\\cdot\\sigma_{b}+\\gamma_{t-i}\\big)}}\\\\ &{}&{\\qquad=\\displaystyle\\sum_{i=1}^{t}(1-\\sigma_{b})^{i-1}\\cdot\\bar{\\lambda}_{t,i-1}\\cdot\\big(1-(1-\\gamma_{t-i})(1-\\sigma_{b})\\big)=1,}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the final equality follows since $\\gamma_{0}=1$ . ", "page_idx": 22}, {"type": "text", "text": "By Eq. (20), we have ", "page_idx": 22}, {"type": "equation", "text": "$$\nx_{t}(p_{1},M_{1}^{[1:H]})-x_{t}(p_{2},M_{2}^{[1:H]})=\\sum_{i=1}^{t}\\left((1-\\sigma_{1})^{i-1}A^{i-1}\\cdot v_{i,1}-(1-\\sigma_{2})^{i-1}A^{i-1}\\cdot v_{i,2}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We consider two cases, depending on the mixing time $\\tau_{A}:=t^{\\mathsf{m i x}}(A)$ of $A$ : ", "page_idx": 22}, {"type": "text", "text": "Case 1: $\\tau_{A}\\leqslant4\\tau$ . Let the stationary distribution of $A$ be denoted $p^{\\star}\\in\\Delta^{d}$ . Then ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\mathbb{E}^{d}}\\left(\\mathbb{J}_{\\mathbb{E}^{d}}\\nu_{1},\\mathbb{H}_{\\sigma}^{\\nu_{1};\\mathbb{H}_{\\sigma}^{\\nu_{1}}}\\right)\\mathbb{E}_{\\mathbb{E}^{d}}\\left[\\exp\\left(-\\nu_{2}\\right)\\Big(\\sum_{\\nu=1}^{\\nu}\\Big(\\sum_{\\nu=1}^{\\nu}\\Big(\\sum_{\\nu=1}^{\\nu}\\Big(\\sum_{\\nu=1}^{\\nu}\\Big(\\sum_{\\nu=1}^{\\nu}\\Big(\\sum_{\\nu=1}\\Big(\\nu_{1}\\Big)^{\\nu}\\Big(\\sum_{\\nu=1}\\Big(\\sum_{\\nu=1}\\Big(\\nu_{1}\\Big)\\Big\\Big(\\sum_{\\nu=1}\\Big(\\sum_{\\nu=1}\\Big\\Big(\\nu_{1}\\Big)\\Big\\Big(\\sum_{\\nu=1}\\Big(\\nu_{1}\\Big)\\Big\\Big(\\sum_{\\nu=1}\\Big(\\nu_{1}\\Big)\\Big\\Big(\\sum_{\\nu=1}\\Big(\\alpha_{1}\\Big-\\Big(\\sum_{\\nu=1}\\Big\\Big(\\nu_{1}\\Big)\\Big\\Big)\\Big\\Big)\\Big\\Big\\Big)\\Big\\Big)\\right)\\Big)\\right)}\\\\ &{=\\bigg|\\sum_{\\nu=1}^{\\nu}\\Big(((1-\\sigma))^{-1}\\Big(\\sum_{\\nu=1}^{\\nu}\\Big(\\sum_{\\nu=1}\\Big(\\sum_{\\nu=1}\\Big(\\sum_{\\nu=1}\\Big(\\sum_{\\nu=1}\\Big(\\sum_{\\nu=1}\\Big(\\sum_{\\nu=1}\\Big\\Big(\\sum_{\\nu=1}\\Big\\Big(_{\\nu=1}\\Big(\\sum_{\\nu=1}\\Big\\Big(\\sum_{\\nu=1}\\Big\\Big(_{\\nu=1}\\Big)\\Big\\Big(\\sum_{\\nu=1}\\Big\\Big(\\sum_{\\nu=1}\\Big\\Big(\\Big(\\sum_{\\nu=1}\\Big\\Big(\\bigg(\\nu_{1}\\Big)\\Big\\Big)\\Big\\Big)\\Big\\Big)\\Big\\Big)\\Big)\\Big)\\Big)\\Big)}\\\\ &{\\qquad+\\bigg|\\sum_{\\nu=1}^{\\nu}\\Big((1-\\sigma))^{-1}\\Big|\\exp_{\\nu,1}\\Big(-(1-\\sigma))^{-1}\\Big|\\exp_{\\nu,2}\\Big(\\sum_{\\nu=1}\\Big(\\Big(1-\\Big(\\sum_{\\nu=1}\\Big(\\sum_{\\nu=1}\\Big(\\sum_{\\nu=1}\\Big(\\Big( \n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "for some constants $C,C^{\\prime}$ . Above, the second equality uses Eq. (38), and the second inequality uses Lemma 22 together with the fact that $A^{i-1}p^{\\star}=\\dot{p}^{\\star}$ and ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\langle\\mathbb{1},\\left((1-\\sigma_{1})^{i-1}v_{i,1}-(1-\\sigma_{2})^{i-1}v_{i,2}\\right)-\\left((1-\\sigma_{1})^{i-1}\\left\\|v_{i,1}\\right\\|_{1}-(1-\\sigma_{2})^{i-1}\\left\\|v_{i,2}\\right\\|_{1}\\right)\\right\\rangle=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "The final inequality uses the assumption that $\\tau_{A}\\leqslant4\\tau$ . ", "page_idx": 23}, {"type": "text", "text": "Case 2: $\\tau_{A}>4\\tau$ . In this case, the assumption that $\\kappa_{\\tau}^{\\triangle}(\\mathcal{L})$ is nonempty together with the choice of $a_{0}$ in Line 1 of Algorithm 1 and Lemma 20 gives that $a_{0}>1/(96\\tau)$ . See Case 2 of the proof of Lemma 21 for more details of this argument, which uses the fact that $\\tau_{A}>96\\tau$ . ", "page_idx": 23}, {"type": "text", "text": "Since $(p_{b},M_{b}^{[1:H]})\\in\\mathcal{X}_{d,H,a_{0},\\overline{{\\alpha}}}$ for $b\\in\\{1,2\\}$ , we have $\\sigma_{1},\\sigma_{2}\\geqslant a_{0}>1/(96\\tau)$ . We may compute ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|x_{t}(p_{1},M_{1}^{[1,H]})-x_{t}(p_{2},M_{2}^{[1,H]})\\right|_{1}}\\\\ &{=\\left|\\displaystyle\\sum_{i=1}^{t}\\left((1-\\sigma_{1})^{i-1}A^{i-1}v_{i,1}-(1-\\sigma_{2})^{i-1}A^{i-1}v_{i,2}\\right)\\right|_{1}}\\\\ &{\\leqslant\\displaystyle\\sum_{i=1}^{t}|(1-\\sigma_{1})^{i-1}-(1-\\sigma_{2})^{i-1}|+\\displaystyle\\sum_{i=1}^{t}(1-\\sigma_{1})^{i-1}\\left|\\|v_{i,1}-v_{i,2}\\right\\|_{1}}\\\\ &{\\leqslant\\displaystyle\\sum_{i=2}^{t}\\sum_{j=1}^{i-1}|\\sigma_{1}-\\sigma_{2}|(1-\\sigma_{1})^{j-1}(1-\\sigma_{2})^{i-1-j}+\\varepsilon\\displaystyle\\sum_{i=1}^{t}(1-\\sigma_{1})^{i-1}}\\\\ &{\\leqslant\\displaystyle\\sum_{i=2}^{t}(1-1)\\varepsilon(1-1/(96\\tau))^{i-2}+\\varepsilon\\displaystyle\\sum_{i=1}^{t}(1-1/(96\\tau))^{i-1}}\\\\ &{\\leqslant C^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "for some constant $C$ . ", "page_idx": 23}, {"type": "text", "text": "Thus, in both cases above, we have $\\left\\|x_{t}(p_{1},M_{1}^{[1:H]})-x_{t}(p_{2},M_{2}^{[1:H]})\\right\\|_{1}\\leqslant O(\\tau\\varepsilon)$ , which verifies Eq. (36). ", "page_idx": 23}, {"type": "text", "text": "The proof of Eq. (37) is much simpler: we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\left\\|u_{t}(p_{1},M_{1}^{[1:H]})-u_{t}(p_{2},M_{2}^{[1:H]})\\right\\|_{1}\\leqslant\\lambda_{t,0}\\cdot\\|p_{1}-p_{2}\\|_{1}+\\sum_{j=1}^{H}\\lambda_{t,j}\\cdot\\left\\|M_{1}^{[j]}-M_{2}^{[j]}\\right\\|_{1\\rightarrow1}\\leqslant\\varepsilon,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "since $\\lambda_{t,0}+\\cdot\\cdot\\cdot+\\lambda_{t,H}=1$ . ", "page_idx": 23}, {"type": "text", "text": "Proof of Theorem 7. Set \u03b2 \u201c 2d?H ln d, $\\varepsilon=1/T$ , and $K_{\\tau}^{\\triangle}:=K_{\\tau}^{\\triangle}({\\mathcal L})$ . We will apply Corollary 15 to the sequence of iterates $(p_{t},M_{t}^{[1:H]})$ M tr1:Hsq produced in Algorithm 1, for the domain Xd,H,a0,\u03b1 (i.e., $a\\,=\\,a_{0},b\\,=\\,{\\overline{{\\alpha}}})$ . Note that Lemma 23 gives that $\\ell_{t}$ is $O(L\\tau^{2})$ -Lipschitz, for each $t\\,\\in\\,[T]$ . Thus Corollary 15 guarantees a regret bound (with respect to $\\mathcal{X}_{d,H,a_{0},\\overline{{\\alpha}}})$ of $O(L\\tau^{2}\\sqrt{d H\\ln(d)\\dot{T}})$ . Moreover, Eq. (19) of Corollary 15 ensures that the precondition Eq. (28) of Lemmaa 21 is satisfied. Thus, we may bound ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{t=1}^{T}c_{t}(x_{t},u_{t})-\\operatorname*{inf}_{K\\in\\mathbb{K}_{r}^{\\Delta}}\\sum_{t=1}^{T}c_{t}(x_{t}(K),u_{t}(K))}}\\\\ &{\\leqslant\\sum_{t=1}^{T}\\ell_{t}(p_{t},M_{t}^{[1:H]})-\\operatorname*{inf}_{K\\in\\mathbb{K}_{r}^{\\Delta}}\\sum_{t=1}^{T}c_{t}(x_{t}(K),u_{t}(K))+O(T\\cdot L\\tau^{3}\\log^{3}(1/\\beta)\\beta)}\\\\ &{\\leqslant\\sum_{t=1}^{T}\\ell_{t}(p_{t},M_{t}^{[1:H]})-\\operatorname*{inf}_{(p,M^{[1:H]})\\in\\mathcal{K}_{d},\\mu,u_{0},\\pi,t=1}^{\\mathrm{~T~}}c_{t}(x_{t}(p,M^{[1:H]}),u_{t}(p,M^{[1:H]}))}\\\\ &{\\quad+O(T\\cdot L\\tau^{3}\\log^{3}(1/\\beta)\\beta)+\\varepsilon}\\\\ &{=\\sum_{t=1}^{T}\\ell_{t}(p_{t},M_{t}^{[1:H]})-\\operatorname*{inf}_{(p,M^{[1:H]})\\in\\mathcal{K}_{d},\\mu,u_{0},\\pi,t=1}^{\\mathrm{~T~}}\\sum_{t}\\ell_{t}(p,M^{[1:H]})}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad+\\,O(T\\cdot L\\tau^{3}\\log^{3}(1/\\beta)\\beta)+\\varepsilon}\\\\ &{\\leqslant L\\tau^{2}\\sqrt{d H\\ln(d)T}+O(T\\cdot L\\tau^{3}\\log^{3}(1/\\beta)\\beta)+\\varepsilon,}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the first inequality uses Lemma 21 together with Eq. (19) of Corollary 15, and the second inequality uses Lemma 17 with $\\epsilon\\ \\mathrm{~\\,~}=\\ 1/T$ (by the theorem assumption, the inequality $H\\geqslant\\tau[\\bar{\\log}_{2}(2L T^{2}/\\epsilon)]$ is indeed satisfied). Note that for the second inequality to hold, we also need that $\\|K\\|_{1\\to1}\\geqslant a_{0}$ for all $K\\in\\ K_{\\tau}^{\\triangle}$ , which in particular requires (by Line 1) that $\\|K\\|_{1\\to1}\\geqslant1/(96\\tau)$ if $t^{\\mathsf{m i x}}(A)>4\\tau$ . But if $t^{\\mathsf{m i x}}(A)>4\\tau$ , then for any $K\\in{\\ K}_{\\tau}^{\\triangle}$ we have $t^{\\mathsf{m i x}}(A)>4\\cdot t^{\\mathsf{m i x}}(\\mathbb{A}_{K})$ and hence $\\|\\dot{K}\\|_{1\\to1}\\geqslant1/(96\\tau)$ by Lemma 20. Finally, the equality above uses the definition of $\\ell_{t}$ in Algorithm 1, and the final inequality uses the regret bound of Corollary 15. By our choice of $\\beta,\\varepsilon$ , we see that the overall policy regret is $\\tilde{O}(L\\tau^{7/2}d^{1/2}\\sqrt{T})$ , as desired. \u53e3 ", "page_idx": 24}, {"type": "text", "text": "D Proof of Lower Bounds ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In this section, we formally state and prove the regret lower bounds Theorem 1 and Theorem 8. The former states that the comparator class for online control of standard LDSs cannot be broadened to all marginally stable (time-invariant, linear) policies; the latter states that the mixing time assumption cannot be removed from the comparator class for online control of simplex LDSs. Both results hold even in constant dimension. ", "page_idx": 24}, {"type": "text", "text": "The basic idea is the same for both proofs: we construct two systems $\\mathcal{L}^{0},\\mathcal{L}^{1}$ which are identical until time $T/2$ , but then at time $T/2$ experience differing perturbations of constant magnitude. The costs are zero until time $T/2$ , after which they penalize distance to a prescribed state (and can in fact be taken to be the same for both systems). The optimal strategy in the first $T/2$ time steps therefore depends on which system the controller is in, but the controller does not observe this until time $T/2$ , and hence will necessarily incur regret with respect to the optimal policy. ", "page_idx": 24}, {"type": "text", "text": "Formalizing this intuition requires two additional pieces: first, for both systems there must be a near-optimal time-invariant linear policy. This can be achieved by careful design of the dynamics, perturbations, and costs. Second, if the controller finds itself in a high-cost state at time $T/2+1$ , it must be unable to reach a low-cost state without incurring $\\Omega(T)$ total cost along the way. In the standard LDS setting, we achieve this by setting the transition matrices $A,B$ so that $\\|B\\|={\\bar{O}}(1/T)$ (i.e. so constant-size controls have small effect on the state) and adding a penalty of $\\lvert u_{t}\\rvert$ to the cost for $t>T/2$ . In the simplex LDS setting, we achieve this by our choice of the valid constraint set $\\mathcal{T}$ (which enforces that $\\bar{\\|u_{t}\\|_{1}}=O(1/T)$ for all $t$ ). ", "page_idx": 24}, {"type": "text", "text": "See Fig. 3 for a pictorial explanation of the proof in the simplex LDS setting. ", "page_idx": 24}, {"type": "text", "text": "D.1 Proof of Theorem 1 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In this section we give a formal statement and proof of Theorem 1. Recall the definition of an LDS (Definition 9). We define the class $\\ K_{\\kappa}(\\mathcal{L})$ of policies that $\\kappa$ -marginally stabilize $\\mathcal{L}$ below; it is equivalent to the class $\\kappa_{\\kappa,\\rho}(\\mathcal{L})$ of policies that $(\\kappa,\\rho)$ -strongly stabilize $\\mathcal{L}$ (Definition 4) with $\\rho=0$ . ", "page_idx": 24}, {"type": "text", "text": "Definition 24 (Marginal stabilization). A matrix $M\\in\\mathbb{R}^{d\\times d}$ is $\\kappa$ -marginally stable if there is a matrix $H\\in\\mathbb{R}^{d\\times d}$ so that $\\left\\|H^{-1}M H\\right\\|\\leqslant1$ and $\\left\\Vert M\\right\\Vert,\\left\\Vert H\\right\\Vert,\\left\\Vert H^{-1}\\right\\Vert\\leqslant\\kappa$ . A matrix $K\\in\\mathbb{R}^{d\\times d}$ is said to $\\kappa$ -marginally stabil\u203a\u203aize an LDS\u203a\u203a with transition matric\u203a\u203aes $A,\\stackrel{\\cdot}{B}\\in\\mathbb{R}^{d\\times d}$ if $A+B K$ is $\\kappa$ -marginally stable. For $\\kappa\\,>\\,0$ and an LDS $\\mathcal{L}$ on $\\mathbb{R}^{d}$ , we define $\\ K_{\\kappa}(\\mathcal{L})$ to be the set of linear, time-invariant policies $x\\mapsto K x$ where $K\\in\\mathbb{R}^{d\\times d}\\kappa$ -marginally stabilizes $\\mathcal{L}$ . ", "page_idx": 24}, {"type": "text", "text": "We also introduce a standard regularity assumption on cost functions:15 ", "page_idx": 24}, {"type": "text", "text": "Assumption 2. Let $L\\,>\\,0$ . We say that cost functions $(c_{t})_{t}$ , where $c_{t}\\,:\\,\\mathbb{R}^{d_{x}}\\,\\times\\,\\mathbb{R}^{d_{u}}\\,\\to\\,\\mathbb{R}$ , are $L$ -regular $i f c_{t}$ is convex and $L$ -Lipschitz with respect to the Euclidean norm for all $t$ . ", "page_idx": 24}, {"type": "text", "text": "Theorem 25 (Formal statement of Theorem 1). Let Alg be any randomized algorithm for online control with the following guarantee: ", "page_idx": 24}, {"type": "image", "img_path": "ZBBrBujopT/tmp/c86a52347c659f2ab47917dd149eb720e1fc17eb297f148ae856b5dc0cf3b10c.jpg", "img_caption": ["Figure 3: An intuitive illustration of $x_{t}(2)$ in the lower bound for simplex LDS (Theorem 30). The blue curve is the trajectory of $\\pi^{0}$ , the \u201cdecreasing\" comparator policy, in the system ${\\mathcal{L}}^{0}$ , which has the smaller perturbation. The green curve is $\\pi^{1}$ , the \u201clazy\" comparator policy, in the system ${\\mathcal{L}}^{1}$ , which has the larger perturbation. The orange curves correspond to the trajectories of an arbitrary policy $\\pi$ under the two different perturbation sequences. The sum of regret under the two perturbation sequences is equal to the area $S_{1}+S_{2}+S_{3}$ , which is shown to be $\\Omega(T)$ for any $h$ . "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "Let $d,T\\,\\in\\,\\mathbb{N}$ and $\\kappa\\,>\\,0$ , and let $\\mathcal{L}\\,=\\,(A,B,x_{1},(w_{t})_{t},(c_{t})_{t})$ be an $L D S$ with state space and control space $\\mathbb{R}^{d}$ ; $L$ -regular cost functions $(c_{t})_{t}$ (Assumption 2); and perturbations $(w_{t})_{t}$ satisfying $\\|w_{t}\\|_{2}\\,\\leqslant\\,L$ for all $t$ . Then the iterates $(x_{t},u_{t})_{t=1}^{T}$ produced by ${\\tt A L g}$ with input $(A,B,\\kappa,T)$ on interaction with $\\mathcal{L}$ satisfy ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbf{regret}_{K_{\\kappa}(\\mathcal{L})}:=\\mathbb{E}\\left[\\sum_{t=1}^{T}c_{t}(x_{t},u_{t})\\right]-\\operatorname*{inf}_{K\\in K_{\\kappa}(\\mathcal{L})}\\sum_{t=1}^{T}c_{t}(x_{t}^{\\mathcal{L},K},u_{t}^{\\mathcal{L},K})\\leqslant f(d,\\kappa,L,T)\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where pxtL,K, utL,Kq are the iterates produced by following policy $x\\mapsto K x$ in system $\\mathcal{L}$ for all $t\\in[T]$ . ", "page_idx": 25}, {"type": "text", "text": "Remark 26. In the above theorem statement, if $\\ K_{\\kappa}(\\mathcal{L})$ were replaced with $\\kappa_{\\kappa,\\rho}(\\mathcal{L})$ , the class of linear time-invariant policies that $(\\kappa,\\rho)$ -strongly stabilize $\\mathcal{L}$ , then the main result of [1] would imply that in fact there is a (deterministic) algorithm GPC with regret at most poly $(d,\\kappa,L,\\rho^{-1})\\!\\cdot\\!\\sqrt{T}\\log(T)$ on any LDS $\\mathcal{L}$ satisfying the above conditions. Thus, Theorem 25 indeed provides a converse to [1]. ", "page_idx": 25}, {"type": "text", "text": "We prove Theorem 25 by constructing a simple distribution over LDSs on which any algorithm must incur $\\Omega(T)$ regret in expectation. Let $\\beta\\geqslant2$ be a constant that we will determine later, and fix $T\\geqslant\\beta$ . Recall that we denote an LDS on $\\mathbb{R}^{d}$ using the notation $\\mathcal{L}=\\left(A,B,x_{1},(w_{t})_{t},(c_{t})_{t}\\right)$ , where $A,B\\in\\mathbb{R}^{d\\times d}$ . We define two LDSs on $\\mathbb{R}$ as follows: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}^{0}:=(1,-\\beta/T,x_{1},(w_{t}^{0})_{t},(c_{t})_{t}),}\\\\ {\\mathcal{L}^{1}:=(1,-\\beta/T,x_{1},(w_{t}^{1})_{t},(c_{t})_{t}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the (common) initial state is $x_{1}=1$ , the (common) cost functions $(c_{t})_{t}$ are defined as ", "page_idx": 25}, {"type": "equation", "text": "$$\nc_{t}(x,u):=\\left\\{{\\left|x\\right|}+{\\left|u\\right|}\\quad\\mathrm{if~}t>T/2\\atop0\\right.,\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "the perturbations of ${\\mathcal{L}}^{0}$ are $w_{t}^{0}:=0$ for all $t$ , and the perturbations of ${\\mathcal{L}}^{1}$ are ", "page_idx": 26}, {"type": "equation", "text": "$$\nw_{t}^{1}:={\\binom{-1}{0}}\\quad{\\mathrm{~if~}}t=T/2\\ .\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "For simplicity, we assume that $T/2$ is an integer. Thus, at all times $t\\neq T/2$ , the two systems have identical dynamics ", "page_idx": 26}, {"type": "equation", "text": "$$\nx_{t+1}:=x_{t}-\\frac{\\beta}{T}u_{t},\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "but at time $t=T/2$ , system ${\\mathcal{L}}^{1}$ experiences a negative perturbation of magnitude 1, whereas ${\\mathcal{L}}^{0}$ does not. The following lemma characterizes the performance of two time-invariant linear policies $\\pi^{0},\\pi^{1}$ for $\\mathcal{L}^{0},\\mathcal{L}^{1}$ respectively: ", "page_idx": 26}, {"type": "text", "text": "Lemma 27. Define $\\pi^{0},\\pi^{1}:\\mathbb{R}\\to\\mathbb{R}$ by $\\pi^{0}(x)=x$ and $\\pi^{1}(x)=0$ . Then: ", "page_idx": 26}, {"type": "text", "text": "\u2022 Policy $\\pi^{0}$ is an element of $K_{1}(\\mathcal{L}^{0})$ , and the iterates $(x_{t}^{\\mathcal{L}^{0},\\pi^{0}},u_{t}^{\\mathcal{L}^{0},\\pi^{0}})_{t=1}^{T}$ produced by following $\\bar{\\pi}^{0}$ in system ${\\mathcal{L}}^{0}$ satisfy ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}c_{t}\\big(x_{t}^{\\mathcal{L}^{0},\\pi^{0}},u_{t}^{\\mathcal{L}^{0},\\pi^{0}}\\big)\\leqslant\\frac{2T}{\\beta}e^{-\\beta/2}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "\u2022 Policy $\\pi^{1}$ is an element of $K_{1}(\\mathcal{L}^{1})$ , and the iterates $(x_{t}^{\\mathcal{L}^{1},\\pi^{1}},u_{t}^{\\mathcal{L}^{1},\\pi^{1}})_{t=1}^{T}$ utL1,\u03c01qtT\u201c1 produced by following $\\bar{\\pi}^{1}$ in system ${\\mathcal{L}}^{1}$ satisfy ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}c_{t}(x_{t}^{\\mathcal{L}^{1},\\pi^{1}},u_{t}^{\\mathcal{L}^{1},\\pi^{1}})=0.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Proof. Note that $\\pi^{0},\\pi^{1}$ are both time-invariant linear policies. The inclusion $\\pi^{0}\\;\\in\\;K_{1}({\\mathcal L}^{0})$ is immediate from the fact that ${\\mathcal{L}}^{0}$ has transitions $A=1,B\\,=\\,-\\beta/T$ , and $|A+B|\\leqslant1$ . Similarly, $\\pi^{1}\\in\\mathcal{K}_{1}(\\mathcal{L}^{1})$ because $|A|\\leqslant1$ . To bound the total cost of $\\pi^{0}$ on ${\\mathcal{L}}^{0}$ , note that $u_{t}^{\\mathcal{L}^{0},\\pi^{0}}=x_{t}^{\\mathcal{L}^{0},\\pi^{0}}=$ $(1-\\beta/\\dot{T})^{t-1}$ for all $t\\in[T]$ . Hence, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}c_{t}\\big(x_{t}^{\\mathcal{L}^{0},\\pi^{0}},u_{t}^{\\mathcal{L}^{0},\\pi^{0}}\\big)=2\\sum_{t=T/2+1}^{T}\\left(1-\\frac{\\beta}{T}\\right)^{t-1}\\leqslant\\frac{2T}{\\beta}\\left(1-\\frac{\\beta}{T}\\right)^{T/2}\\leqslant\\frac{2T}{\\beta}e^{-\\beta/2}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Moreover, we have $x_{t}^{\\mathcal{L}^{1},\\pi^{1}}=\\mathbb{1}[t\\leqslant T/2]$ and $u_{t}^{\\mathcal{L}^{1},\\pi^{1}}=0$ for all $t\\in[T]$ , from which it is clear that $\\begin{array}{r}{\\sum_{t=1}^{T}c_{t}(x_{t}^{\\mathcal{L}^{1},\\pi^{1}},u_{t}^{\\mathcal{L}^{1},\\bar{\\pi}^{1}})=0}\\end{array}$ . \u53e3 ", "page_idx": 26}, {"type": "text", "text": "Next, we show that the total cost of any trajectory $(x_{t},u_{t})_{t=1}^{T}$ can be lower bounded in terms of $|x_{T/2+1}|$ in both ${\\mathcal{L}}^{0}$ and ${\\mathcal{L}}^{1}$ : ", "page_idx": 26}, {"type": "text", "text": "Lemma 28. Let ${\\tt A L g}$ be any randomized algorithm for online control, and let $b\\in\\{0,1\\}$ . The (random) trajectory $(x_{t},u_{t})_{t=1}^{T}$ produced by Alg in system ${\\mathcal{L}}^{b}$ satisfies the inequality ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}c_{t}(x_{t},u_{t})=\\sum_{t=T/2+1}^{T}|x_{t}|+|u_{t}|\\geqslant\\frac{T}{2\\beta}|x_{T/2+1}|\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "with probability 1. ", "page_idx": 26}, {"type": "text", "text": "Proof. By definition of $\\mathcal{L}^{0},\\mathcal{L}^{1}$ , any valid trajectory in ${\\mathcal{L}}^{b}$ satisfies $\\begin{array}{r}{|u_{t}|~=~\\frac{T}{\\beta}|x_{t+1}-x_{t}|}\\end{array}$ for all $T/2<t<T$ . We consider two cases: ", "page_idx": 26}, {"type": "text", "text": "1. If $\\begin{array}{r}{\\operatorname*{min}_{T/2<t\\ll T}|x_{t}|\\geqslant\\frac{1}{2}|x_{T/2+1}|}\\end{array}$ , then ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{t=T/2+1}^{T}|x_{t}|+|u_{t}|\\geqslant\\frac{T}{4}|x_{T/2+1}|\\geqslant\\frac{T}{2\\beta}|x_{T/2+1}|\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "since $\\beta\\geqslant2$ . ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{t=T/2+1}^{T}|x_{t}|+|u_{t}|\\geqslant\\frac{T}{\\beta}\\sum_{t=T/2+1}^{T-1}|x_{t+1}-x_{t}|\\geqslant\\frac{T}{\\beta}\\left||x_{T/2+1}|-\\operatorname*{min}_{T/2<t\\leqslant T}|x_{t}|\\right|\\geqslant\\frac{T}{2\\beta}|x_{T/2+1}|\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "by the triangle inequality. ", "page_idx": 27}, {"type": "text", "text": "In both cases the claimed inequality holds. ", "page_idx": 27}, {"type": "text", "text": "We can now prove Theorem 25. ", "page_idx": 27}, {"type": "text", "text": "Proof of Theorem 25. Let $b\\sim\\mathrm{Unif}(\\{0,1\\})$ be an unbiased random bit, and let $(x_{t},u_{t})_{t=1}^{T}$ be the (random) trajectory produced by executing ${\\tt A L g}$ on ${\\mathcal{L}}^{b}$ . On the one hand, by Eq. (41) applied to ${\\mathcal{L}}^{0}$ and ${\\mathcal{L}}^{1}$ , we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{E}\\left[\\sum_{t=1}^{T}c_{t}(x_{t},u_{t})\\right]}}\\\\ &{\\leq f(1,1,1,T)+\\frac{1}{2}\\left(\\underset{K\\in K_{1}(\\mathcal{L}^{0})}{\\operatorname*{inf}}\\sum_{t=1}^{T}c_{t}(x_{t}^{\\mathcal{L}^{0},K},u_{t}^{\\mathcal{L}^{0},K})+\\underset{K\\in K_{1}(\\mathcal{L}^{1})}{\\operatorname*{inf}}\\sum_{t=1}^{T}c_{t}(x_{t}^{\\mathcal{L}^{1},K},u_{t}^{\\mathcal{L}^{1},K})\\right)}\\\\ &{\\leqslant f(1,1,1,T)+\\frac{T}{\\beta}e^{-\\beta/2}}&{(4)}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the first inequality uses the fact that the cost functions $(c_{t})_{t}$ are convex and 1-Lipschitz and that $|w_{t}^{0}|,|w_{t}^{1}|\\leqslant1$ for all $t\\in[T]$ ; and the second inequality is by Lemma 27. On the other hand, by Lemma 28, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{E}\\left[\\sum_{t=1}^{T}c_{t}(x_{t},u_{t})\\right]\\geqslant\\frac{T}{2\\beta}\\mathbb{E}[|x_{T/2+1}|]}\\quad}&{}\\\\ &{=\\frac{T}{2\\beta}\\mathbb{E}\\left[\\left|x_{T/2}-\\frac{\\beta}{T}u_{T/2}-b\\right|\\right]\\quad}&{}\\\\ &{\\stackrel{(\\star)}{=}\\frac{T}{2\\beta}\\left(\\frac{1}{2}\\mathbb{E}\\left[\\left|x_{T/2}-\\frac{\\beta}{T}u_{T/2}\\right|\\right]+\\frac{1}{2}\\mathbb{E}\\left[\\left|x_{T/2}-\\frac{\\beta}{T}u_{T/2}-1\\right|\\right]\\right)}\\\\ &{\\geqslant\\frac{T}{4\\beta}\\left(\\mathbb{E}\\left[x_{T/2}-\\frac{\\beta}{T}u_{T/2}\\right]+\\left|\\mathbb{E}\\left[x_{T/2}-\\frac{\\beta}{T}u_{T/2}\\right]-1\\right|\\right)\\geqslant\\frac{T}{4\\beta},}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the key equality $(\\star)$ uses the fact that $\\mathcal{L}^{0},\\mathcal{L}^{1}$ are id\u02c7entical up until and inclu\u02c7ding time $T/2$ , and hence $(x_{T/2},u_{T/2})$ is independent of $b$ . Comparing Eq. (43) with Eq. (42) yields that ", "page_idx": 27}, {"type": "equation", "text": "$$\nf(1,1,1,T)\\geqslant\\frac{T}{4\\beta}-\\frac{T}{\\beta}e^{-\\beta/2}=\\Omega(T)\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "for any sufficiently large constant $\\beta$ . ", "page_idx": 27}, {"type": "text", "text": "D.2 Proof of Theorem 8 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Definition 29. Let $0\\leqslant\\underline{{\\alpha}}\\leqslant\\overline{{\\alpha}}\\leqslant1$ and let $\\begin{array}{r}{\\mathcal{T}:=\\bigcup_{\\alpha\\in[\\underline{{\\alpha}},\\overline{{\\alpha}}]}\\Delta_{\\alpha}^{d}}\\end{array}$ . We define $\\kappa({\\mathcal{T}})$ to be the set of linear, time-invariant policies $x\\mapsto K x$ where $K\\in\\bigcup_{\\alpha\\in[\\underline{{\\alpha}},\\overline{{\\alpha}}]}\\mathbb{S}_{\\alpha}^{d}$ . ", "page_idx": 27}, {"type": "text", "text": "Theorem 30 (Formal statement of Theorem 8). L et Alg be any randomized algorithm for online   \ncontrol with the following guarantee: Let $d,T\\quad\\in\\quad\\mathbb{N}$ and $\\begin{array}{r l r}{{\\mathcal T}}&{{}:=}&{\\bigcup_{\\alpha\\in[0,\\overline{{\\alpha}}]}\\Delta_{\\alpha}^{d}}\\end{array}$ for some $\\begin{array}{r l r}{\\overline{{\\alpha}}}&{{}\\in}&{(0,1)}\\end{array}$ . Let $\\begin{array}{r l}{\\mathcal{L}}&{{}=}\\end{array}$ $(A,B,\\mathcal{I},x_{1},(\\gamma_{t})_{t},(w_{t})_{t},(c_{t})_{t})$ be a \u0164simplex LDS with state space $\\Delta^{d}$ and cost functions $(c_{t})_{t}$ satisfying Assumption $^{\\,l}$ with Lipschitz parameter $L>0$ . Then the iterates $(x_{t},u_{t})_{t=1}^{T}$ produced by ${\\tt A L g}$ with input $(A,B,{\\mathcal{T}},T)$ on interaction with $\\mathcal{L}$ satisfy $\\mathbf{regret}_{K(\\mathcal{Z})}:=\\mathbb{E}\\left[\\sum_{t=1}^{T}c_{t}(x_{t},u_{t})\\right]-\\operatorname*{inf}_{K\\in\\mathcal{K}(\\mathcal{Z})}\\sum_{t=1}^{T}c_{t}(x_{t}^{\\mathcal{L},K},u_{t}^{\\mathcal{L},K})\\leqslant f(d,L,\\overline{{\\alpha}},T)$ (44) ", "page_idx": 27}, {"type": "text", "text": "where $(\\underline{{x}}_{t_{-}}^{\\mathcal{L},K},u_{t}^{\\mathcal{L},K})_{t=1}^{T}$ are the iterates produced by following policy $x\\mapsto K x$ in system $\\mathcal{L}$ for all $t\\in[T]$ . ", "page_idx": 28}, {"type": "text", "text": "For any sufficiently large constant $\\beta$ , if we define $\\overline{{\\alpha}}(T):=\\beta/T$ , then $f(1,1,\\overline{{\\alpha}}(T),T)=\\Omega(T)$ . ", "page_idx": 28}, {"type": "text", "text": "We define two simplex LDSs on $\\Delta^{2}$ as follows: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}^{0}:=(I_{2},I_{2},\\mathcal{Z},x_{1},(\\gamma_{t})_{t},(w_{t}^{0})_{t},(c_{t})_{t})}\\\\ {\\mathcal{L}^{1}:=(I_{2},I_{2},\\mathcal{Z},x_{1},(\\gamma_{t})_{t},(w_{t}^{1})_{t},(c_{t})_{t})}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where $I_{2}\\in\\mathbb{R}^{2\\times2}$ is the identity matrix, the (common) valid control set is $\\textstyle{\\mathcal{T}}:=\\bigcup_{\\alpha\\in[0,\\beta/T]}\\Delta_{\\alpha}^{d}$ , the (common) initial state is $x_{1}=(0,1)$ , the (common) cost functions $(c_{t})_{t}$ are def in\u0164ed as ", "page_idx": 28}, {"type": "equation", "text": "$$\nc_{t}(x,u):={\\binom{|x(2)-1/2|}{0}}\\quad{\\mathrm{if~}}t>T/2}\\,,\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "the (common) perturbation strengths are $\\begin{array}{r}{\\gamma_{t}\\;:=\\;\\frac12\\,\\mathbb{1}[t\\;=\\;T/2]}\\end{array}$ , and the perturbations of ${\\mathcal{L}}^{0}$ are $w_{t}^{0}:=(1/2,1/2)$ for all $t$ whereas the perturbations of ${\\mathcal{L}}^{1}$ are $w_{t}^{1}:=(1,0)$ for all $t$ . Thus, for both systems, the dynamics are described by ", "page_idx": 28}, {"type": "equation", "text": "$$\nx_{t+1}:=(1-\\|u_{t}\\|_{1})x_{t}+u_{t}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "for all $t\\neq T/2$ . ", "page_idx": 28}, {"type": "text", "text": "Lemma 31. Define $\\pi^{0},\\pi^{1}:\\Delta^{2}\\,\\rightarrow\\bigcup_{\\alpha\\in[0,1]}\\Delta^{d}$ by $\\textstyle\\pi^{0}(x):=\\,{\\frac{\\beta}{T}}(1/2,1/2)$ and $\\pi^{1}(x):=\\:(0,0)$ . Then $\\pi^{0},\\pi^{1}\\in K(\\mathbb{Z})$ , and: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The iterates $(x_{t}^{\\mathcal{L}^{0},\\pi^{0}},u_{t}^{\\mathcal{L}^{0},\\pi^{0}})_{t=1}^{T}$ produced by following $\\pi^{0}$ in system ${\\mathcal{L}}^{0}$ satisfy ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}c_{t}(x_{t}^{\\mathcal{L}^{0},\\pi^{0}},u_{t}^{\\mathcal{L}^{0},\\pi^{0}})\\leqslant\\frac{T}{\\beta}e^{-\\beta/2}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "\u2022 The iterates pxtL1,\u03c01, $(x_{t}^{\\mathcal{L}^{1},\\pi^{1}},u_{t}^{\\mathcal{L}^{1},\\pi^{1}})_{t=1}^{T}$ $\\pi^{1}$ ${\\mathcal{L}}^{1}$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}c_{t}(x_{t}^{\\mathcal{L}^{1},\\pi^{1}},u_{t}^{\\mathcal{L}^{1},\\pi^{1}})=0.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof. The fact that $\\pi^{0},\\pi^{1}\\in K(\\mathbb{Z})$ is immediate from Definition 29 and the choice of $\\mathcal{T}$ . To bound the total cost of $\\pi^{0}$ on ${\\mathcal{L}}^{0}$ , note that $x_{t+1}^{\\mathcal{L}^{0},\\pi^{0}}(2)-1/2=(1-\\beta/T)(x_{t}(2)-1/2)$ for all $t\\neq T/2$ , and $x_{t+1}^{\\mathcal{L}^{0},\\pi^{0}}(2)-1/2=(1/2)(1-\\beta/T)(x_{t}(2)-1/2)$ for $t=T/2$ . Thus, ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}c_{t}(x_{t}^{\\mathcal{L}^{0},\\pi^{0}},u_{t}^{\\mathcal{L}^{0},\\pi^{0}})=\\sum_{t=T/2+1}^{T}|x_{t}^{\\mathcal{L}^{0},\\pi^{0}}(2)-1/2|\\leqslant\\sum_{t=T/2+1}^{T}(1-\\beta/T)^{t-1}\\leqslant\\frac{T}{\\beta}e^{-\\beta/2}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Moreover, we have $x_{t}^{\\mathcal{L}^{1},\\pi^{1}}\\,=\\,(0,1)$ for all $t\\leqslant T/2$ and $x_{t}^{\\mathcal{L}^{1},\\pi^{1}}\\,=\\,(1/2,1/2)$ for all $t>T/2$ , so indeed tT\u201c1 ctpxtL $\\begin{array}{r}{\\sum_{t=1}^{T}c_{t}\\big(x_{t}^{\\mathcal{L}^{1},\\pi^{1}},u_{t}^{\\mathcal{L}^{1},\\pi^{1}}\\big)=0}\\end{array}$ utL1,\u03c01q \u201c 0 as claimed. \u53e3 ", "page_idx": 28}, {"type": "text", "text": "Lemma 32. Let ${\\tt A L g}$ be any randomized algorithm for online control, and let $b\\in\\{0,1\\}$ . The (random) trajectory $(x_{t},u_{t})_{t=1}^{T}$ produced by ${\\tt A L g}$ in system ${\\mathcal{L}}^{b}$ satisfies the inequality ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}c_{t}(x_{t},u_{t})=\\sum_{t=T/2+1}^{T}|x_{t}(2)-1/2|\\geqslant\\frac{T}{8\\beta}|x_{T/2+1}(2)-1/2|^{2}-1.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof. By definition of $\\mathcal{L}^{0},\\mathcal{L}^{1}$ and the valid control set $\\mathcal{T}$ , any valid trajectory in ${\\mathcal{L}}^{b}$ satisfies $\\left\\|x_{t}-x_{t+1}\\right\\|_{1}\\leqslant2\\left\\|u_{t}\\right\\|_{1}\\leqslant2\\beta/T$ for all $T/2<t<T$ . It follows that $\\bar{|x_{t+1}(2)-1/2|}\\geqslant|x_{t}(2)-$ $1/2|-2\\beta/T$ for all such $t$ , and hence ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sum_{t=T/2+1}^{T}|x_{t}(2)-1/2|\\geqslant\\sum_{n=1}^{T/2}\\operatorname*{max}\\left(0,|x_{T/2+1}(2)-1/2|-\\frac{2\\beta n}{T}\\right)\n$$", "text_format": "latex", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\ p\\left.\\frac{|x_{T/2+1}(2)-1/2|}{2}\\cdot\\left\\lfloor\\frac{T}{4\\beta}|x_{T/2+1}(2)-1/2|\\right\\rfloor}\\\\ {\\displaystyle\\ p\\left.\\frac{T}{8\\beta}|x_{T/2+1}(2)-1/2|^{2}-1\\right\\rfloor}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "as claimed. ", "page_idx": 29}, {"type": "text", "text": "Proof of Theorem 30. Let $b\\sim\\mathrm{Unif}(\\{0,1\\})$ be an unbiased random bit, and let $(x_{t},u_{t})_{t=1}^{T}$ be the (random) trajectory produced by executing ${\\tt A L g}$ on ${\\mathcal{L}}^{b}$ . On the one hand, by Eq. (44) applied to ${\\mathcal{L}}^{0}$ and ${\\mathcal{L}}^{1}$ , we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}c_{t}(x_{t},u_{t})\\right]}\\\\ &{\\qquad\\leqslant f(1,1,\\beta/T,T)+\\frac{1}{2}\\left(\\displaystyle\\operatorname*{inf}_{K\\in K(T)}\\sum_{t=1}^{T}c_{t}(x_{t}^{\\underline{{c}}^{0},K},u_{t}^{\\underline{{c}}^{0},K})+\\operatorname*{inf}_{K\\in K(T)}\\sum_{t=1}^{T}c_{t}(x_{t}^{\\underline{{c}}^{1},K},u_{t}^{\\underline{{c}}^{1},K})\\right)}\\\\ &{\\qquad\\leqslant f(1,1,\\beta/T,T)+\\frac{T}{2\\beta}e^{-\\beta/2}}\\end{array}(4,\\underline{{\\tilde{c}}}),\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the first inequality uses the definition of $\\mathcal{T}$ and the fact that the cost functions $(c_{t})_{t}$ are convex and 1-Lipschitz per Assumption 1; and the second inequality is by Lemma 31. On the other hand, by Lemma 32, we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad+\\mathbb{E}\\left[\\sum_{i=1}^{T}c_{i}(x_{t},u_{t})\\right]}\\\\ &{\\geq\\frac{T}{8\\beta}\\mathbb{E}[(x_{T/2+1}(2)-1/2)^{2}]}\\\\ &{=\\frac{T}{8\\beta^{3}}\\mathbb{E}\\left[\\left(\\frac{(1-\\|u_{T/2}\\|_{\\frac{1}{2}T/2}(2)+u_{T/2}(2)}{2}-\\frac{1+b}{4}\\right)^{2}\\right]}\\\\ &{\\stackrel{{()}}{\\simeq}\\frac{T}{8\\beta}\\left(\\frac{1}{2}\\mathbb{E}\\left[\\left(\\frac{(1-\\|u_{T/2}\\|_{\\frac{1}{2}T/2}(2)+u_{T/2}(2)}{2}-\\frac{1}{4}\\right)^{2}\\right]+\\frac{1}{2}\\mathbb{E}\\left[\\left(\\frac{(1-\\|u_{T/2}\\|_{\\frac{1}{2}T/2}(2)+u_{T})}{2}\\right.\\right.\\right.}\\\\ &{\\left.\\left.\\left.\\times\\frac{T}{16\\beta}\\left(\\left(\\mathbb{E}\\left[\\frac{(1-\\|u_{T/2}\\|_{\\frac{1}{2}T/2}(2)+u_{T/2}(2)}{2}\\right]-\\frac{1}{4}\\right)^{2}+\\left(\\mathbb{E}\\left[\\frac{(1-\\|u_{T/2}\\|_{\\frac{1}{2}T/2}(2)+u_{T/2}(2)}{2}\\right.\\right.\\right.}\\\\ &{\\left.\\left.\\left.\\left.\\times\\frac{T}{16}\\right]\\right.\\right.\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the key equality $(\\star)$ uses the fact that $\\mathcal{L}^{0},\\mathcal{L}^{1}$ are identical up until and including time $T/2$ , and hence $(x_{T/2},u_{T/2})$ is independent of $b$ . Comparing Eq. (46) with Eq. (45) yields that ", "page_idx": 29}, {"type": "equation", "text": "$$\nf(1,1,\\beta/T,T)\\geqslant\\frac{T}{1024\\beta}-1-\\frac{T}{2\\beta}e^{-\\beta/2}=\\Omega(T)\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "for any sufficiently large constant $\\beta$ . ", "page_idx": 29}, {"type": "text", "text": "E Implementation details ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "In this section we describe the version of GPC-Simplex (Algorithm 1) implemented for our experiments. First, the dynamical systems in our experiments are non-linear. The GPC-Simplex algorithm is still practical and applicable in such settings \u2013 concretely, any setting with update rule Eq. (9) \u2013 but of course several modifications/generalizations must be made: ", "page_idx": 29}, {"type": "text", "text": "1. The algorithm takes as input the function $f$ describing the dynamics in Eq. (9), rather than transition matrices $A,B$ . Accordingly, in Line 8, the expression $(1-\\|\\bar{u}_{t}\\|_{1})A x_{t}+B u_{t}$ (which exactly corresponds to the noiseless update rule in a simplex LDS) is replaced by $f(x_{t},u_{t})$ . Moreover, in Line 9, the hypothetical iterates $x_{t}(p,M^{[1:H]}),u_{t}(p,M^{[1:H]})$ under policy \u03c0p,M r1:Hs are computed using the update rule $f$ . ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "2. The algorithm directly takes as input a learning rate $\\eta$ for the mirror descent subroutine, rather than the mixing time bound $\\tau$ . In our experiments, we always set $\\eta:=\\sqrt{d H\\ln(H)}/(2\\sqrt{T})$ .   \n3. We always parametrize our systems so that the valid control set is the sapace of distributions $\\Delta^{d}$ . Hence, the domain used for mirror descent is $\\mathcal{X}_{d,H,1,1}$ . Mirror descent is implemented by exponential weights updates with learning rate $\\eta$ and uniform initialization. ", "page_idx": 30}, {"type": "text", "text": "We remark that the above (natural) modifications to GPC-Simplex are analogous to the modifications to GPC made by [2] to perform online control for nonlinear systems. ", "page_idx": 30}, {"type": "text", "text": "F Experiments: Controlled SIR model ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "In this section, we provide additional experiments in the controlled SIR model. Specifically, in Appendix F.1 we provide experimental evaluations when there are perturbations to the system (i.e. $\\gamma_{t}$ is not always 0 in Eq. (9)). In Appendix F.2 we vary the parameters of the SIR model. ", "page_idx": 30}, {"type": "text", "text": "F.1 Control in presence of perturbations ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "We experiment with the SIR system Eq. (11) with the following parameters: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\beta=0.5,~~\\theta=0.03,~~\\xi=0.005,\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "and cost function given by: ", "page_idx": 30}, {"type": "equation", "text": "$$\nc_{t}(x_{t},u_{t})=c_{3}\\cdot x_{t}(2)^{2}+c_{2}\\cdot x_{t}(1)u_{t}(1).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "We test the performance of our algorithm on $\\left(c_{2},c_{3}\\right)=\\left(1,5\\right)$ . In addition, we add a perturbation sequence $w_{t}^{-}=[0,1,0],\\forall1\\leqslant t\\leqslant^{2}00.\\;\\gamma_{t}\\sim0.01\\cdot\\mathrm{{Ber}}(0.2),\\forall1\\leqslant t\\leqslant200.$ . ", "page_idx": 30}, {"type": "text", "text": "Fig. 4 shows comparison of the costs over $T\\,=\\,200$ time steps incurred by GPC-simplex to that of always executing $u_{t}\\,=\\,[1,0]$ (full prevention) and that of always executing $u_{t}\\,=\\,[0,1]$ (no prevention). In addition to cost, we plot the value of $u_{t}(2)$ over time, representing how relaxed prevention measure evolves over time according to GPC-simplex. ", "page_idx": 30}, {"type": "text", "text": "F.2 Alternative parameter settings ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "We experiment with two SIR systems with different set of parameters. The first uses the following parameters: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\beta=0.5,~~\\theta=0.03,~~\\xi=0.005,\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "whereas the second uses the following parameters: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\beta=0.3,~~\\theta=0.05,~~\\xi=0.001.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "In both cases, the cost function is: ", "page_idx": 30}, {"type": "equation", "text": "$$\nc_{t}(x_{t},u_{t})=c_{3}\\cdot x_{t}(2)^{2}+c_{2}\\cdot x_{t}(1)u_{t}(1).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "For both experiments, we test the performance of our algorithm on different choices of parameters for the cost function. In particular, we test the parameter tuples: ", "page_idx": 30}, {"type": "equation", "text": "$$\n(c_{2},c_{3})\\in\\{(1,20),(1,10),(1,5),(1,1)\\}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Figs. 5 and 6 show comparison of the costs over $T=200$ time steps incurred by GPC-Simplex to that of always executing $u_{t}=[1,0]$ (full prevention) and that of always executing $u_{t}=[0,1]$ (no prevention). Specifically, Fig. 5 uses the first set of parameters above, and Fig. 6 uses the second set. In addition to cost, we plot the value of $u_{t}(2)$ over time, representing how the effective transmission rate evolves over time according to GPC-Simplex. ", "page_idx": 30}, {"type": "text", "text": "We notice that our algorithm consistently outperforms the two baselines. No matter how we set the parameters, our algorithm will outperform the full-intervention baseline since its cumulative cost grows linearly with time. As $c_{3}$ gets larger, the gap between our algorithm and the no-intervention baseline becomes smaller, since the optimal policy with a high cost on control is basically playing no control. ", "page_idx": 30}, {"type": "image", "img_path": "ZBBrBujopT/tmp/16c5e18b349d20ebc5e15a558085ed70ca01ded488f163fe8e28ed5ef8bac0c9.jpg", "img_caption": ["Figure 4: SIR with perturbations. $T=200$ . Initial state $x_{1}=[0.9,0.1,0]$ . GPC-Simplex parameter $H=5$ . Top: Perturbation sequence: $w_{t}\\,=\\,[0,1,0]$ , $\\forall1\\leqslant t\\leqslant200$ . $\\gamma_{t}^{-}\\sim0.01\\cdot\\bar{\\mathrm{Ber}}(0.2),\\bar{\\forall}1\\leqslant\\bar{t}\\leqslant200$ . Bottom: Perturbation sequence: $\\forall t$ , $w_{t}$ is a normalized uniform random vector. $\\gamma_{t}=0.01$ , $\\forall1\\leqslant t\\leqslant200$ . "], "img_footnote": [], "page_idx": 31}, {"type": "text", "text": "G Experiments: Controlling hospital flows ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "In this section, we provide more details regarding the setup and experiments in Section 4.1. ", "page_idx": 31}, {"type": "text", "text": "The continuous time dynamical system considered by [27] is the following: let $S(t),I(t)$ denote the susceptible and infected fraction of the population at time $t_{\\cdot}$ , and let $\\sigma(t)$ denote the control at time $t$ The system has some initial state $(S(0),I(0))$ in the set ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{D}:=\\{(x_{0},y_{0}):x_{0}>0,y_{0}>0,x_{0}+y_{0}\\leqslant1\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "reflecting the constraint that $S(0),I(0)$ represent disjoint proportions of a population, and the system evolves according to the differential equation ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{S^{\\prime}(t)=-\\gamma\\sigma(t)I(t)S(t),}}\\\\ {{I^{\\prime}(t)=\\gamma\\sigma(t)I(t)S(t)-\\gamma I(t).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where $\\gamma\\,>\\,0$ is some fixed model parameter, and the control $\\sigma(t)$ models a non-pharmaceutical intervention (NPI) inducing a time-dependent reproduction number $\\sigma(t)\\in[0,\\sigma_{0}]$ , where $\\sigma_{0}$ is the base reproduction number in the absence of interventions. In most examples in [27], including the example of controlling hospital flows, the parameter settings $\\sigma_{0}\\,=\\,3$ and $\\gamma=0.1$ are used. This means that the natural discretization of Eq. (48) is in fact equivalent to Eq. (11) with transmission rate $\\beta:=\\gamma\\sigma_{0}=0.3$ , recovery rate $\\theta:=\\gamma=0.1$ , loss-of-immunity rate $\\xi:=0$ , no perturbations (i.e. $\\gamma_{t}=0$ for all $t$ ), and control ", "page_idx": 31}, {"type": "equation", "text": "$$\nu_{t}:=\\left(1-\\frac{\\sigma(t)}{\\sigma_{0}},\\frac{\\sigma(t)}{\\sigma_{0}}\\right),\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "at each time $t$ . ", "page_idx": 31}, {"type": "image", "img_path": "ZBBrBujopT/tmp/7f10faaeb888c8749fd208c2902ac9202c91446573418ba0fcd5679be8f52fe1.jpg", "img_caption": ["Figure 5: Control with costs: control over $T\\,=\\,200$ steps. $\\gamma_{t}~=~0$ , @t. SIR parameters: $\\beta\\,=\\,0.5,\\theta\\,=$ $0.03,\\xi\\,=\\,0.005$ . Initial state $x_{1}\\,=\\,[0.9,0.1,0]$ . GPC-Simplex parameters: $H\\,=\\,5$ . Left: instantaneous cost over time, compared with that of no control (green) and full control (orange). Middle: cumulative cost over time. Right: $u_{t}(2)$ output by GPC-Simplex over time. $\\left(c_{2},c_{3}\\right)$ values (from top to bottom rows): $(1,20),(1,10),(1,5),(1,1)$ . "], "img_footnote": [], "page_idx": 32}, {"type": "text", "text": "The goal in [27] is the following: given an initial state $(S(0),I(0))$ along with a horizon length $T>0$ and the parameters listed above, choose an admissible control function $\\sigma:[0,T]\\rightarrow[0,\\sigma_{0}]$ to minimize the loss ", "page_idx": 32}, {"type": "equation", "text": "$$\nJ:=-S_{\\infty}(S(T),I(T),\\sigma_{0})+\\int_{0}^{T}L(S(t),I(t),\\sigma(t))d t,\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where $L(S(t),I(t),\\sigma(t))$ is the instantaneous cost at time $t$ , and the extra term $S_{\\infty}(S(T),I(T),\\sigma_{0})$ incentivizes the state of the system at time $T$ to lead to a favorable long-term trajectory (in the absence of any interventions after time $T$ ). In [27], the following formula for $S_{\\infty}$ is given; see that paper for further discussion: ", "page_idx": 32}, {"type": "equation", "text": "$$\nS_{\\infty}(S,I,\\sigma_{0})=\\frac{W_{0}\\big(-\\sigma_{0}I e^{-\\sigma_{0}(S+I)}\\big)}{\\sigma_{0}}.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "image", "img_path": "ZBBrBujopT/tmp/e38394983ee9495c88b9041605381ebf3cb8f0a5367d3e155e0d4fbb1b3e6243.jpg", "img_caption": ["Figure 6: Control with costs: control over $T\\,=\\,200$ steps. $\\gamma_{t}~=~0$ , @t. SIR parameters: $\\beta\\,=\\,0.3,\\theta\\,=$ $0.05,\\xi\\,=\\,0.001$ . Initial state $x_{1}\\,=\\,[0.9,0.1,0]$ . GPC-Simplex parameters: $H\\,=\\,5$ . Left: instantaneous cost over time, compared with that of no control (green) and full control (orange). Middle: cumulative cost over time. Right: $u_{t}(2)$ output by GPC-Simplex over time. $\\left(c_{2},c_{3}\\right)$ values (from top to bottom rows): $(1,20),(1,10),(1,5),(1,1)$ . "], "img_footnote": [], "page_idx": 33}, {"type": "text", "text": "The instantaneous cost is modeled by [27] as follows: ", "page_idx": 33}, {"type": "equation", "text": "$$\nL(S(t),I(t),\\sigma(t))=c_{2}\\cdot\\left(1-\\frac{\\sigma(t)}{\\sigma_{0}}\\right)^{2}+\\frac{c_{3}\\cdot(I(t)-y_{\\mathrm{max}})}{1+e^{-100(I(t)-y_{\\mathrm{max}})}},\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where $c_{2},c_{3}$ are some parameters determining the cost of preventing disease transmission and the cost of a medical surge (i.e. when the proportion of infected individuals exceeds $y_{\\mathrm{{max}}}$ ). Notice that the second term above will indeed be very small in magnitude unless $I(t)$ exceeds $y_{\\mathrm{max}}$ . ", "page_idx": 33}, {"type": "text", "text": "Note that GPC-Simplex cannot directly handle end-of-trajectory losses such as the term $S_{\\infty}(S(T),I(T),\\sigma_{0})$ . Thus, in our evaluation of GPC-Simplex on this system, we instead incorporate $S_{\\infty}$ into the instantaneous cost functions. Concretely, we use the following cost function at ", "page_idx": 33}, {"type": "text", "text": "time $t$ : ", "page_idx": 34}, {"type": "equation", "text": "$$\nc_{t}(x_{t},u_{t})=-S_{\\infty}(x_{t}(1),x_{t}(2),\\sigma_{0})+c_{2}\\cdot u_{t}(1)^{2}+\\frac{c_{3}(x_{t}(2)-y_{\\operatorname*{max}})}{1+e^{-100(x_{t}(2)-y_{\\operatorname*{max}})}}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Recall that we write $\\boldsymbol{x}_{t}=\\left(S_{t},I_{t},R_{t}\\right)$ and $u_{t}(1)=1-\\sigma(t)/\\sigma_{0}$ , so modulo the addition of $S_{\\infty}$ to all times $t<T$ and the conversion from continuous time to discrete time, our loss is analogous to that of [27]. ", "page_idx": 34}, {"type": "text", "text": "H Experiments: Controlled replicator dynamics ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "The replicator equation is a basic model in evolutionary game theory that describes how individuals in a population will update their strategies over time based on their payoffs from repeatedly playing a game with random opponents from the population [11]. The basic principle is that strategies (or traits) that perform better than average in a given environment will, over time, increase in frequency within the population, whereas strategies that perform worse than average will become less common. ", "page_idx": 34}, {"type": "text", "text": "Formally, consider a normal-form two-player game with $d$ possible strategies and payoff matrix $M\\in\\mathbb{R}^{d\\times d}$ . A population at time $t$ is modelled by the proportion of individuals that currently favor each strategy, and thus can be summarized by a distribution $\\boldsymbol{x}(t)\\in\\ensuremath{\\mathbb{R}}^{d}$ . The fitness of an individual playing strategy $i\\in[d]$ in a population with strategy distribution $x\\in\\Delta^{d}$ is defined to be ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathrm{fitness}_{M,x}(i):=e_{i}^{\\top}M x,\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $e_{i}\\in\\mathbb{R}^{d}$ is the indicator vector for strategy $i$ . That is, fitness ${\\cal M},x^{\\left(i\\right)}$ is simply the expected payoff of playing strategy $i$ against a random individual from the population. The replicator dynamics posit that the population\u2019s distribution over strategies $x(t)$ will evolve according to the following differential equation: ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\frac{d x_{i}(t)}{d t}:=x_{i}(t)\\cdot\\big(\\mathrm{fimess}_{M,x(t)}(i)-\\mathbb{E}_{j\\sim x}\\mathrm{fimess}_{M,x(t)}(j)\\big)=x_{i}(t)\\cdot\\big(e_{i}^{\\top}M x(t)-x(t)^{\\top}M x(t)\\big).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "It is straightforward to check that this differential equation preserves the invariant that $x(t)$ is a distribution. This equation can induce various types of dynamics depending on the initialization and payoff matrix $M$ : the distribution may converge to an equilibrium, or it may cycle, or it may even exhibit chaotic behavior [11]. In this study we focus on a simple (time-discretized) replicator equation \u2013 namely, the equation induced by a generalized Rock-Paper-Scissors game \u2013 when the payoffs may be controlled. ", "page_idx": 34}, {"type": "text", "text": "Controlled Rock-Paper-Scissors. The standard Rock-Paper-Scissors game has $d=3$ and payoff matrix ", "page_idx": 34}, {"type": "equation", "text": "$$\nM:=\\left[{\\begin{array}{c c c}{0}&{1}&{-1}\\\\ {-1}&{0}&{1}\\\\ {1}&{-1}&{0}\\end{array}}\\right].\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Consider a setting where the game is run by an external agent that is allowed to set the payoffs. For simplicity, we assume that the game remains zero-sum and the rewards sum to 1, so the payoff matrix is now ", "page_idx": 34}, {"type": "equation", "text": "$$\nM(u):=\\left[{\\begin{array}{c c c}{0}&{u_{1}}&{-u_{3}}\\\\ {-u_{1}}&{0}&{u_{2}}\\\\ {u_{3}}&{-u_{2}}&{0}\\end{array}}\\right]\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "for a control vector $u\\in\\Delta^{3}$ . The discrete-time analogue of the replicator equation with this controlled payoff matrix $M(u)$ is ", "page_idx": 34}, {"type": "equation", "text": "$$\nx_{t+1}=f(x_{t},u_{t}):=x_{t}+\\eta\\left[x_{t1}\\cdot e_{1}^{\\top}M(u_{t})x_{t}\\right]\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $x_{t},u_{t}\\in\\Delta^{3}$ are the population distribution and control at time $t$ respectively, and $\\eta\\in(0,1)$ is the rate of evolution. Note that the term $x_{t}M(u_{t})x_{t}$ does not need to appear in Eq. (50) because $M(u_{t})$ is always zero-sum. Also, since $\\eta\\leqslant1$ and all entries of $M(u_{t})$ are at most 1 in magnitude, if $x_{t}$ is a distribution then $x_{t+1}$ will remain a distribution. We omit noise in this study, so Eq. (50) is a special case of Eq. (9) with $\\gamma_{t}=0$ for all $t$ . ", "page_idx": 34}, {"type": "image", "img_path": "ZBBrBujopT/tmp/a8cf9593a9c44d9d0fb244dbda73d8cb3c586af19586a9401acc43441998a49c.jpg", "img_caption": ["(a) Instantaneous cost achieved by GPC-Simplex over(b) Proportions of the population playing strategies time, compared to default Rock-Paper-Scissors control\u201crock\u201d, \u201cpaper\u201d, and \u201cscissors\u201d over time under control and Best Response control (dashed orange). by GPC-Simplex. ", "Figure 7: Experimental results for dynamical system with horizon $T\\,=\\,100$ , uniform initial state, update rule Eq. (50) with $\\eta~=~1/4$ , no perturbations, and time-invariant cost function $c_{t}(x_{t},u_{t})~=~x_{t1}^{2}$ for all times $t$ . GPC-Simplex was implemented as described in Appendix E. The Best Response controller at each time $t$ picks the control ${\\boldsymbol u}$ that minimizes $c_{t-1}(f(x_{t},u),u)$ . The default controller picks the uniform control $u=\\grave{(1/3,1/3,1/3)}$ . "], "img_footnote": [], "page_idx": 35}, {"type": "text", "text": "Parameters and cost function. We define a (nonlinear) dynamical system with uniform initial state $x_{1}=(1/3,1/3,1/3)$ , update rule Eq. (50) with $\\eta=1/4$ , and $T=100$ timesteps. We consider the fixed cost function ", "page_idx": 35}, {"type": "equation", "text": "$$\nc(x_{t},u_{t}):=x_{t1}^{2},\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "which can be thought of as penalizing the strategy \u201crock\u201d. ", "page_idx": 35}, {"type": "text", "text": "Results. We compare GPC-Simplex (implemented as described in Appendix E) with a baseline control that simply uses the standard Rock-Paper-Scissors payoff matrix (up to scaling) induced by $u\\,=\\,(1/3,1/3,\\dot{1}/3)\\,\\in\\,\\Delta^{3}$ . As shown in Fig. 7a, GPC-Simplex (shown in blue) significantly outperforms this baseline (shown in green), learning to alter the payoff in such a way that the population tends to avoid the \u201crock\u201d strategy. The evolution of the dsitribution over time under GPC-Simplex is shown in Fig. 7b. ", "page_idx": 35}, {"type": "text", "text": "For completeness, we also compare GPC-Simplex against the \u201cBest Response\u201d strategy (shown in dashed orange) that essentially performs 1-step optimal control, using the fact that the cost function for this example is time-invariant. While both controllers eventually learn a good policy, Fig. 7a clearly shows that Best Response learns faster. However, it is strongly exploiting the time-invariance of the cost function, since in general, this algorithm computes the best response with respect to the previous cost function rather than the current cost function, which it does not observe until after playing a control. In Fig. 8, we consider a slightly modified system where the cost function includes a cost on the control with probability $1/2$ . In this setting, we see that GPC-Simplex still eventually learns a good policy, whereas Best Response and the default control incur large costs through the trajectory. Best Response in particular suffers greatly due to the time-varying nature of the costs. ", "page_idx": 35}, {"type": "text", "text": "I Discussions ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "I.1 Broader impacts ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Our work provides a robust algorithm with theoretical justifications for practical control problems that might be applicable to problems such as disease control. The experiments performed are preliminary. More careful empirical verification is necessary before our algorithm can be responsibly implemented in high-impact scenarios. Excluding the scenario of ill intention, we do not anticipate any negative social impact. ", "page_idx": 35}, {"type": "image", "img_path": "ZBBrBujopT/tmp/871c3d48c3f77a9fc62bc93adc814bb1b8571e894cdaf0d4ce003f8521b3ea08.jpg", "img_caption": ["Figure 8: Experimental results for dynamical system with horizon $T\\,=\\,200$ , uniform initial state, update rule Eq. (50) with $\\eta=1/4$ , no perturbations, and random cost function which is either $c_{t}(x_{t},u_{t})\\,=\\,\\tilde{x}_{t1}^{2}$ or $c_{t}(x_{t},\\dot{u}_{t})\\,=\\,x_{t1}^{2}+^{\\prime}u_{t3}^{2}$ with equal probability. GPC-Simplex was implemented as described in Appendix E. The Best Response controller at each time $t$ picks the control ${\\boldsymbol u}$ that minimizes $c_{t-1}(f(x_{t},u),u)$ . The default controller picks the uniform control $u=(1/3,1/3,1/3)$ . The plot shows the cost achieved by GPC-Simplex over time, compared to default Rock-Paper-Scissors control and Best Response control (dashed orange). Due to the non-continuity induced by the random cost functions, the loss plotted at time $t$ is the average loss of the controller across the last $\\operatorname*{min}(t,15)$ time steps. "], "img_footnote": [], "page_idx": 36}, {"type": "text", "text": "I.2 Computational Resources for Experiments ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "The experiments in this work are simulations and relatively small-scaled. They were run on Google Colab with default compute resources. For each experiment, the time required to roll-out one trajectory using GPC-Simplex was less than 10 minutes. ", "page_idx": 36}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Justification: The main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 37}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: The paper discussed the limitations of the work. Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 37}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Justification: For each theoretical result, the paper provides the full set of assumptions and a complete (and correct) proof.   \nGuidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results. \u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced. ", "page_idx": 37}, {"type": "text", "text": "\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems. \u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. \u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. \u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 38}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: The paper fully discloses all the information needed to reproduce the main experimental results of the paper.   \nGuidelines:   \n\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 38}, {"type": "text", "text": "", "page_idx": 38}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes]   \nJustification: We provide a link to the anonymous repository containing our code. Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code. \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details. \u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not ", "page_idx": 38}, {"type": "text", "text": "including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 39}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 39}, {"type": "text", "text": "Justification: The paper specifies all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 39}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate   \ninformation about the statistical significance of the experiments?   \nAnswer: [No] ", "page_idx": 39}, {"type": "text", "text": "Justification: The experiments are primarily deterministic; the experiments with randomness are provided largely as proof-of-concept. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 39}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 40}, {"type": "text", "text": "Justification: See Appendix J.2. Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 40}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] ", "page_idx": 40}, {"type": "text", "text": "Justification: The research conforms to the Code of Ethics. Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 40}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] Justification: See Appendix J.1. Guidelines: ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 40}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA]   \nJustification: the paper poses no such risks.   \nGuidelines: \u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 40}, {"type": "text", "text": "", "page_idx": 41}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: we cite the original paper that produced the code package or dataset. Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 41}, {"type": "text", "text": "13. New Assets ", "page_idx": 41}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation   \nprovided alongside the assets?   \nAnswer: [NA] ", "page_idx": 41}, {"type": "text", "text": "Justification: the paper does not release new assets. Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 41}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?   \nAnswer: [NA]   \nustification: the paper does not involve crowdsourcing nor research with human subjects.   \nGuidelines: \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. \u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. ", "page_idx": 41}, {"type": "text", "text": "", "page_idx": 41}, {"type": "text", "text": "\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 42}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 42}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 42}, {"type": "text", "text": "Answer: [NA]   \nustification: the paper does not involve crowdsourcing nor research with human subjects.   \nGuidelines: \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. \u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. \u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. \u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 42}]