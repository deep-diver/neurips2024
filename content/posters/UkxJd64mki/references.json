{"references": [{"fullname_first_author": "Jason Wei", "paper_title": "Chain of thought prompting elicits reasoning in large language models", "publication_date": "2022-12-01", "reason": "This paper introduces the chain-of-thought prompting method, which is a foundational technique for improving LLM reasoning abilities and is directly relevant to StrategyLLM's approach."}, {"fullname_first_author": "Takeshi Kojima", "paper_title": "Large language models are zero-shot reasoners", "publication_date": "2022-12-01", "reason": "This paper demonstrates the zero-shot reasoning capabilities of LLMs, providing a theoretical basis for StrategyLLM's inductive reasoning component."}, {"fullname_first_author": "Xuezhi Wang", "paper_title": "Self-consistency improves chain of thought reasoning in language models", "publication_date": "2023-04-01", "reason": "This paper introduces the self-consistency method, a technique used by StrategyLLM to enhance the reliability of LLM-generated solutions."}, {"fullname_first_author": "Mor Geva", "paper_title": "Did Aristotle use a laptop? A question answering benchmark with implicit reasoning strategies", "publication_date": "2021-07-01", "reason": "This paper provides a benchmark dataset (StrategyQA) used to evaluate StrategyLLM, demonstrating its performance across diverse reasoning tasks."}, {"fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring mathematical problem solving with the MATH dataset", "publication_date": "2021-12-01", "reason": "This paper introduces the MATH benchmark dataset, a key evaluation resource for StrategyLLM's mathematical reasoning capabilities."}]}