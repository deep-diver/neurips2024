[{"figure_path": "fVRCsK4EoM/figures/figures_1_1.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure displays a visual comparison of image inpainting results between the Runway model and the PrefPaint model proposed in the paper.  Multiple image examples are shown, each with a prompt (the incomplete image) and the results produced by both models. The purpose is to highlight the visual improvements achieved by aligning the diffusion model with human preferences using the reinforcement learning approach presented in the paper. The PrefPaint model demonstrates significantly improved visual quality and more natural-looking inpainting results compared to Runway.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_3_1.jpg", "caption": "Figure 2: Experimental plot of reward prediction error vs. ||z||v\u22121 on the validation set, where a dashed line is an upper boundary of error, positively relative to ||z||v\u22121.", "description": "This figure shows the experimental results related to the theoretical analysis of the reward model's error.  The x-axis represents the norm of the reward embedding vector (||z||v\u22121), while the y-axis shows the error in predicting the reward.  The plot demonstrates that the reward prediction error has a positive correlation with the norm of the reward embedding vector, and that a dashed line acts as an upper bound of the error.  This supports the theoretical findings presented in the paper, which establishes an upper bound on the reward model's error.", "section": "3.2 Bounding Reward Model Error"}, {"figure_path": "fVRCsK4EoM/figures/figures_4_1.jpg", "caption": "Figure 3: Statistical characteristics of the dataset we constructed. (a) the score distribution of the images across different selected datasets; (b) the comparison between the distribution of the average score and score for details; (c) and (d) show the numbers of images with different mask ratios on the outpainting and warping splits, respectively.", "description": "This figure presents the statistical characteristics of the dataset used in the PrefPaint model.  Subfigure (a) shows the distribution of overall scores across four different datasets (ADE20k, ImageNet, KITTI, and DIV2k). Subfigure (b) displays a scatter plot comparing the overall score and the detail score for each image, showing their correlation. Subfigures (c) and (d) present histograms illustrating the distribution of the percentage of masked regions in the outpainting and warping image sets, respectively.  These visualizations provide insights into the composition and characteristics of the dataset used for training and evaluating the PrefPaint model.", "section": "4 Human Preference-Centric Dataset for Reward"}, {"figure_path": "fVRCsK4EoM/figures/figures_6_1.jpg", "caption": "Figure 5: Visual comparisons of our approach and SOTA methods. The prompted images of 5th and 7th rows are generated by boundary cropping, while the remaining rows by warping. All images were generated with the same random seeds.", "description": "This figure presents a visual comparison of image inpainting results between the proposed method (PrefPaint) and several state-of-the-art (SOTA) methods.  The comparison is done on various images with missing regions created through two different methods: warping and boundary cropping. Each row shows the same prompt image (the incomplete image with a missing part) followed by results from different inpainting models (Kandinsky, SD v1.5, SD v2.1, Palette, SD xl++, Compvis, Runway, and the proposed method PrefPaint). The use of the same random seeds ensures that differences are due solely to the models and not random variations in the generation process. The visual results demonstrate PrefPaint's ability to generate inpainted images that are more aligned with human preferences.", "section": "5 Experiments"}, {"figure_path": "fVRCsK4EoM/figures/figures_8_1.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure presents a visual comparison of image inpainting results between the Runway model and the PrefPaint model (the proposed method).  Multiple examples are shown across various image categories (e.g., buildings, animals, cars), each demonstrating the improvement in visual appeal and quality achieved by aligning the diffusion model with human preferences using reinforcement learning. The differences highlight how PrefPaint generates more natural and contextually appropriate inpainted regions compared to the original Runway model, which sometimes produces less visually pleasing or unrealistic results.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_8_2.jpg", "caption": "Figure B-3: Application of novel view synthesis on KITTI dataset, where we visualize 8 scenes from (a) to (h) with corresponding prompt warped image, given view and reconstruction result.", "description": "This figure shows eight examples of novel view synthesis on the KITTI dataset using the proposed method. Each example consists of three images: (1) the prompt image which provides the input context for the inpainting task, (2) the given view which shows the original viewpoint before warping, and (3) the result which depicts the generated novel view after inpainting. The results demonstrate that the proposed method effectively fills missing or damaged parts of the images, providing plausible and consistent results.", "section": "B More Application Visual Demonstrations"}, {"figure_path": "fVRCsK4EoM/figures/figures_9_1.jpg", "caption": "Figure 8: Visualization of various image in-painting results and associated rewards from our model. Our model effectively evaluates in-painting reconstructions based on human preference.", "description": "This figure shows several examples of image inpainting results generated by the model, along with their associated reward scores.  The purpose is to visually demonstrate the model's ability to assess the quality of inpainting reconstructions based on human preferences.  Each row presents a series of inpainting results for the same input, highlighting the variations in quality and the corresponding reward scores.", "section": "More Visualizations"}, {"figure_path": "fVRCsK4EoM/figures/figures_9_2.jpg", "caption": "Figure 9: Reward error distributions of the proposed reward model. The distribution of reward error percentages is depicted on the y-axis to the right.", "description": "This figure shows the distribution of reward errors from the proposed reward model. The x-axis represents the reward errors, and the y-axis shows the number of samples with those errors.  A visual representation shows that the majority of errors are clustered around zero, indicating a high level of accuracy in reward estimation.", "section": "5.2 Ablation Study"}, {"figure_path": "fVRCsK4EoM/figures/figures_17_1.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure presents a visual comparison of image inpainting results between the \"Runway\" model and the proposed PrefPaint model.  It shows several examples of images with missing parts, along with the inpainting results produced by each method. The goal is to highlight the improved visual quality and aesthetic appeal of the inpainting generated by PrefPaint compared to the baseline Runway model, demonstrating the effectiveness of aligning the diffusion model with human preferences.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_17_2.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure showcases visual comparisons between the results obtained using the \"Runway\" diffusion-based image inpainting model and the model aligned using the method proposed in the paper.  It demonstrates the improvement in image quality and visual appeal achieved by aligning the model with human aesthetic preferences. The comparison is shown for several different images, illustrating that the proposed method consistently produces better results across various scenarios.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_17_3.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure shows a visual comparison of image inpainting results between the Runway model and the PrefPaint model proposed in the paper.  The figure consists of several sets of images; in each set, the first image is the original prompt image (incomplete image with missing regions). The second image is the inpainting result generated by the Runway model and the third image is the inpainting result generated by the PrefPaint model.  The comparison aims to highlight the improvements in visual appeal and quality achieved by aligning the diffusion model with human preferences using the proposed reinforcement learning approach.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_17_4.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure presents a visual comparison of image inpainting results between the Runway model and the PrefPaint model (the authors' proposed method).  The figure showcases several examples across various image categories, each showing the original image with a masked region, the Runway inpainting result, and the PrefPaint inpainting result.  The purpose is to visually demonstrate the improved quality and visual appeal of the inpainting results achieved by aligning the diffusion model with human preferences, as proposed by the PrefPaint method.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_17_5.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure presents a visual comparison of image inpainting results between the Runway model and the proposed PrefPaint model.  The figure shows several examples of images with missing parts, followed by the inpainting results produced by each model. The purpose is to illustrate the improvement in visual quality and alignment with human aesthetic standards achieved by PrefPaint compared to the baseline Runway model. Each row displays a different image scenario with the prompt (input), and then the results of the Runway model followed by the PrefPaint model. This visual comparison showcases the superiority of the proposed model in generating visually pleasing and coherent inpainted images.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_17_6.jpg", "caption": "Figure 6: Results of image FOV enlargement by our method on two scenes (a) and (b), where the prompt region (the given image) is delineated by the central area between white dashed lines.", "description": "This figure shows the results of applying the proposed image FOV enlargement method on two different scenes.  The left side of each pair displays the input prompt image (the given image), while the right side showcases the enlarged output image produced by the method.  The white dashed lines in the output images highlight the boundary of the original input prompt.", "section": "More Application Visual Demonstrations"}, {"figure_path": "fVRCsK4EoM/figures/figures_18_1.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure presents a visual comparison of image inpainting results between the Runway model and the PrefPaint model (the authors' proposed method). It shows several examples of images with missing parts, and for each example it displays side-by-side the inpainting results produced by both the Runway model and the PrefPaint model. The goal is to demonstrate the improvement in the quality and visual appeal of the inpainted images achieved by aligning the diffusion model with human preference using the proposed reinforcement learning framework.  The image categories represented are diverse, and the results clearly show that the PrefPaint model produces visually more plausible and aesthetically pleasing results than the Runway model.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_18_2.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure shows a visual comparison of image inpainting results between the Runway model and the PrefPaint model (the authors' proposed method).  For several different images and prompts (different scenes and missing sections), the figure shows three columns: the original incomplete image, the inpainting result from the Runway model, and the inpainting result from the PrefPaint model.  The goal is to demonstrate the improved visual quality and aesthetic appeal achieved by aligning the diffusion model with human preferences using the PrefPaint approach.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_18_3.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure shows a visual comparison of image inpainting results between the Runway model and the PrefPaint model proposed in the paper.  Multiple image examples across different categories (e.g., buildings, animals, cars) are shown.  For each category, the left column displays the results obtained by the Runway model, and the right column shows the results generated by the PrefPaint model. The goal of the figure is to visually demonstrate the improved quality and visual appeal of the inpainted images produced by PrefPaint, which aligns the inpainting results more closely with human aesthetic preferences.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_18_4.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure shows a visual comparison of image inpainting results between the Runway model and the PrefPaint model (the model proposed in the paper).  For several different images and prompts (e.g., a building, an animal, and cars), the figure displays three inpainted versions side by side: the original Runway result, a result from a baseline model (Runway), and a result from the PrefPaint model. The visual difference shows how the PrefPaint model, guided by human preferences, improves upon the quality and visual appeal of the inpainted images compared to the baseline method.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_18_5.jpg", "caption": "Figure A-2: Illustration of different scoring examples on the feeling of local texture.", "description": "This figure in the Appendix of the paper shows examples of image inpainting results with their corresponding scores and explanations, illustrating the assessment criteria related to the \"Feeling of Local Texture\".  The scores range from 0 to 7, with higher scores indicating better quality and consistency with objective facts. Each example highlights a specific aspect of texture quality, such as the presence of unrealistic textures, partially incomplete objects, or overall consistency of texture with surrounding elements.", "section": "A Dataset Details"}, {"figure_path": "fVRCsK4EoM/figures/figures_18_6.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure presents a visual comparison of image inpainting results between the Runway model and the PrefPaint model proposed in the paper.  The figure displays several examples, each showing the same incomplete image (prompt) followed by the inpainting generated using the Runway model and then the PrefPaint model. The comparison aims to demonstrate the improvement in visual appeal and quality achieved by aligning the diffusion model with human preferences, as implemented in the PrefPaint method.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_19_1.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure displays a visual comparison of image inpainting results between the Runway model and the PrefPaint model (the authors' proposed method).  It shows several examples of images with masked regions, and the results of inpainting those regions using both models. The purpose is to visually demonstrate the improvement in visual quality and realism achieved by the PrefPaint method, which aligns the image inpainting diffusion model with human aesthetic preferences. Each row represents a different image, with the \"Runway\" results shown first, and then the improved results produced by the PrefPaint model.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_19_2.jpg", "caption": "Figure 8: Visualization of various image in-painting results and associated rewards from our model. Our model effectively evaluates in-painting reconstructions based on human preference.", "description": "This figure shows several examples of image inpainting results generated by the model, along with the associated reward scores. The reward scores are based on human preferences, and the figure illustrates the model's ability to evaluate the quality of the inpainting results based on these preferences.", "section": "More Visualizations"}, {"figure_path": "fVRCsK4EoM/figures/figures_19_3.jpg", "caption": "Figure A-1: Labeling platform demonstration. In each group, from top left to bottom right, are reconstruction 1, 2, 3 and the prompt image.", "description": "This figure shows the labeling platform used in the paper.  Each group of images consists of three different inpainting results (reconstructions 1, 2, and 3) and the original prompt image (the incomplete image).  The platform allows annotators to provide scores based on three criteria: structural rationality, feeling of local texture, and overall feeling.  These scores are used in the training of the reward model.", "section": "A Dataset Details"}, {"figure_path": "fVRCsK4EoM/figures/figures_19_4.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure shows a visual comparison of image inpainting results between the Runway model and the model developed by the authors using their proposed method.  The figure is structured in rows, each row representing a different image with missing sections, and within each row, there are multiple columns showing the results from both methods. The goal is to demonstrate how the authors' approach improves the quality and visual appeal of inpainted images. The improvements are visible across various scenarios, suggesting a generally superior performance for image inpainting.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_19_5.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure shows a visual comparison of image inpainting results between the Runway model and the proposed PrefPaint model.  For several different images with missing sections, it displays side-by-side comparisons of the results from both models.  The goal is to highlight the improved visual quality and aesthetic appeal of the inpainting achieved by the PrefPaint model, which aligns with human preferences.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_20_1.jpg", "caption": "Figure 1: Visual comparisons of the results by the diffusion-based image inpainting model named \"Runway\", and the aligned model through the proposed method.", "description": "This figure shows a visual comparison of image inpainting results between the Runway model and the proposed PrefPaint model.  For several different image prompts (different scenes and objects), it displays the original incomplete image, the inpainting result from the Runway model, and the inpainting result from the PrefPaint model. The goal is to highlight the improvement in visual quality and aesthetic appeal achieved by aligning the diffusion model with human preferences using the reinforcement learning approach described in the paper.", "section": "1 Introduction"}, {"figure_path": "fVRCsK4EoM/figures/figures_21_1.jpg", "caption": "Figure B-2: Application of FOV enlargement, where we visualize 9 scenes from (a) to (i) with corresponding prompt cropped image and enlarged result.", "description": "This figure demonstrates the effectiveness of the proposed method for image field-of-view (FOV) enlargement. Nine different scenes are shown, each with its corresponding prompt image (cropped to the center) and the enlarged result generated using the method.  The results demonstrate that the proposed method can consistently produce meaningful and visually pleasing enlargements across diverse image styles, including paintings, nature photography, and even Chinese paintings.", "section": "B More Application Visual Demonstrations"}, {"figure_path": "fVRCsK4EoM/figures/figures_22_1.jpg", "caption": "Figure B-3: Application of novel view synthesis on KITTI dataset, where we visualize 8 scenes from (a) to (h) with corresponding prompt warped image, given view and reconstruction result.", "description": "This figure shows eight examples of novel view synthesis on the KITTI dataset. Each example includes three images: the prompt (input), the warped given view, and the reconstructed result from the PrefPaint model.  The warped given view shows the missing regions that the model is tasked with inpainting. The results demonstrate the model's ability to generate realistic and coherent novel views from incomplete inputs.", "section": "B More Application Visual Demonstrations"}, {"figure_path": "fVRCsK4EoM/figures/figures_22_2.jpg", "caption": "Figure B-3: Application of novel view synthesis on KITTI dataset, where we visualize 8 scenes from (a) to (h) with corresponding prompt warped image, given view and reconstruction result.", "description": "This figure shows eight examples of novel view synthesis using the PrefPaint model on the KITTI dataset.  Each example displays three images: the original prompt image (a warped image with missing parts), the original \"given\" view from which the prompt was created, and the inpainting result produced by PrefPaint.  The figure demonstrates the model's ability to generate plausible and coherent novel viewpoints, especially in challenging scenes with irregular and large missing areas.", "section": "More Application Visual Demonstrations"}, {"figure_path": "fVRCsK4EoM/figures/figures_23_1.jpg", "caption": "Figure C-5: Detailed score statistics of the proposed dataset.", "description": "This figure shows the detailed score statistics of the proposed dataset, broken down by different datasets (ADE20K, KITTI, ImageNet, and Div2k) and inpainting types (Warping and Outpainting).  Each subfigure is a histogram representing the distribution of reward scores for a specific dataset and inpainting type. The histograms visualize the frequency of different score ranges, providing insights into the overall quality distribution of the inpainted images and the balance of various scores within the dataset. This analysis helps in understanding the characteristics of the dataset used to train the reward model and assessing the reliability of the reward model's predictions.", "section": "C Reward Scoring Statistics & Reward Normalization Configuration"}, {"figure_path": "fVRCsK4EoM/figures/figures_24_1.jpg", "caption": "Figure 5: Visual comparisons of our approach and SOTA methods. The prompted images of 5th and 7th rows are generated by boundary cropping, while the remaining rows by warping. All images were generated with the same random seeds.", "description": "This figure provides a visual comparison of the image inpainting results generated by the proposed method and several state-of-the-art (SOTA) methods.  The results are shown for both outpainting (boundary cropping) and inpainting (warping) scenarios. Each row represents a different prompt image, and the columns show the results from different methods, including the proposed PrefPaint, alongside methods like Kandinsky, SD v1.5, Palette, SD xl++, Compvis, and Runway. The use of the same random seeds for all methods helps to isolate the impact of the different algorithms on the quality of the generated images. The figure is intended to showcase the visual improvements achieved by the proposed PrefPaint model compared to other established models.", "section": "5 Experiments"}, {"figure_path": "fVRCsK4EoM/figures/figures_25_1.jpg", "caption": "Figure 5: Visual comparisons of our approach and SOTA methods. The prompted images of 5th and 7th rows are generated by boundary cropping, while the remaining rows by warping. All images were generated with the same random seeds.", "description": "This figure presents a visual comparison of the image inpainting results produced by the proposed method and several state-of-the-art (SOTA) methods.  The top row shows the original prompt images, with subsequent rows displaying the inpainting results from different methods, including the proposed method. The figure highlights the differences in image quality and visual appeal. The different inpainting methods are compared side by side for the same prompt, allowing for direct visual comparison and illustrating the relative strengths of each technique.  Half of the prompts were generated by warping and the other half by boundary cropping, showing that our method works for both.", "section": "5 Experiments"}, {"figure_path": "fVRCsK4EoM/figures/figures_26_1.jpg", "caption": "Figure D-8: Qualitative comparison of different sampling times of the proposed method.", "description": "This figure shows the results of running the proposed image inpainting method 5 times with different random seeds. Each row represents a different prompt image, and each column represents one of the five runs. The consistency of the results across the different runs demonstrates the robustness and stability of the proposed method.", "section": "D More Visualizations"}, {"figure_path": "fVRCsK4EoM/figures/figures_28_1.jpg", "caption": "Figure F-1: Training curves of different experimental setups.", "description": "This figure shows the training curves for four different experimental setups: BaseLine, 1.4BaseLine, 1.4Boundary, and Ours. The x-axis represents the number of training steps, and the y-axis represents the mean rewards. The curves show that the 1.4Boundary (Ours) approach converges faster than the other approaches, reaching a mean reward of around 0.35 earlier than the others. This indicates that the proposed method is more efficient in terms of training time.", "section": "F Details & Reward"}]