{"importance": "This paper is crucial for researchers working on securing large language models (LLMs). It directly addresses the vulnerability of existing watermarking techniques to spoofing attacks, a critical concern for LLM safety and accountability. **The proposed bi-level signature scheme, Bileve, offers a novel approach to enhance the reliability and robustness of LLM provenance verification, providing valuable insights for future research in this area.**  The findings have significant implications for developing more secure and trustworthy LLMs and for regulating their use responsibly. The experiments with various LLMs provide a solid foundation for future developments.", "summary": "Bileve: a novel bi-level signature secures text provenance in LLMs against spoofing, enhancing detectability and reliability via fine-grained integrity checks and coarse-grained source tracing.", "takeaways": ["Bileve, a bi-level signature scheme, effectively defends against spoofing attacks by embedding fine-grained and coarse-grained signatures.", "Compared to single-level approaches, Bileve's bi-level design enhances the detectability and robustness of LLM provenance verification.", "Experimental results on OPT-1.3B and LLaMA-7B demonstrate Bileve's effectiveness in tracing text origins and mitigating spoofing attacks with high accuracy and minimal impact on generation quality"], "tldr": "Current watermarking methods for Large Language Models (LLMs) primarily focus on robustness against removal attacks but are vulnerable to spoofing attacks, where malicious actors subtly alter the meaning of LLM-generated content or even forge harmful content and falsely attribute it to the LLM.  This leads to wrongful attribution of blame and undermines the reliability of LLMs. \nTo tackle this, the researchers propose a new bi-level signature scheme called Bileve. **Bileve embeds fine-grained signature bits for integrity checks and a coarse-grained signal to trace the source of the text even when the signature is invalid.** This approach enables Bileve to reliably trace text provenance and regulate LLMs, while enhancing the detectability of malicious activity.  The evaluation on OPT-1.3B and LLaMA-7B shows Bileve's high accuracy and minimal impact on text quality.", "affiliation": "Northeastern University", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "vjCFnYTg67/podcast.wav"}