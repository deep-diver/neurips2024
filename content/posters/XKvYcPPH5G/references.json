{"references": [{"fullname_first_author": "Sergey Levine", "paper_title": "Reinforcement learning and control as probabilistic inference: Tutorial and review", "publication_date": "2018-05-01", "reason": "This paper provides a comprehensive overview of the control as inference framework, which is foundational to the SPO algorithm's theoretical underpinnings."}, {"fullname_first_author": "Arthur P Dempster", "paper_title": "Maximum likelihood from incomplete data via the EM algorithm", "publication_date": "1977-01-01", "reason": "The Expectation-Maximization algorithm is central to SPO's iterative optimization approach, making this paper a fundamental reference for the algorithm's core methodology."}, {"fullname_first_author": "Richard S Sutton", "paper_title": "Reinforcement learning: An introduction", "publication_date": "2018-01-01", "reason": "This book provides a foundational understanding of reinforcement learning, which is the field of study to which the SPO algorithm belongs, providing essential background knowledge."}, {"fullname_first_author": "David Silver", "paper_title": "Mastering the game of Go without human knowledge", "publication_date": "2017-01-01", "reason": "AlphaGo's success in mastering Go demonstrated the power of combining tree-based search with deep learning, providing inspiration for SPO's model-based reinforcement learning approach."}, {"fullname_first_author": "Thomas Anthony", "paper_title": "Thinking fast and slow with deep learning and tree search", "publication_date": "2017-01-01", "reason": "This paper explores the integration of tree-based search and deep learning for planning, which is a core component of SPO's approach to policy improvement."}]}