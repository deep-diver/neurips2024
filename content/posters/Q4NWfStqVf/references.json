{"references": [{"fullname_first_author": "Shipra Agrawal", "paper_title": "Thompson sampling for contextual bandits with linear payoffs", "publication_date": "2013-01-01", "reason": "This paper is foundational for contextual bandits and introduces Thompson Sampling, a key algorithm used in the current work."}, {"fullname_first_author": "Shipra Agrawal", "paper_title": "Mnl-bandit: A dynamic learning approach to assortment selection", "publication_date": "2019-01-01", "reason": "This paper extends Thompson Sampling to the multinomial logit (MNL) bandit setting, which is the core problem investigated in the current work."}, {"fullname_first_author": "Xi Chen", "paper_title": "Dynamic assortment optimization with changing contextual information", "publication_date": "2020-01-01", "reason": "This paper provides a comprehensive study of contextual MNL bandits, establishing regret bounds and proposing algorithms that the current work builds upon and improves."}, {"fullname_first_author": "Min-hwan Oh", "paper_title": "Thompson sampling for multinomial logit contextual bandits", "publication_date": "2019-01-01", "reason": "This paper introduces a computationally efficient algorithm for contextual MNL bandits, which is a key aspect considered in the current work."}, {"fullname_first_author": "Noemie Perivier", "paper_title": "Dynamic pricing and assortment under a contextual mnl demand", "publication_date": "2022-01-01", "reason": "This paper improves upon previous results on contextual MNL bandits and provides tighter regret bounds in the adversarial setting, which is relevant to the current paper's goal of establishing minimax optimality."}]}