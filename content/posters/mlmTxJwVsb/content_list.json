[{"type": "text", "text": "DMNet: Self-comparison Driven Model for Subject-independent Seizure Detection ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Shihao Tu Zhejiang University shihao.tu@zju.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Linfeng Cao The Ohio State University cao.1378@osu.edu ", "page_idx": 0}, {"type": "text", "text": "Daoze Zhang Zhejiang University zhangdz@zju.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Junru Chen ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zhejiang University jrchen_cali@zju.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Lvbin Ma Zhejiang Huayun Information Technology Co. Ltd gmmmfly@163.com ", "page_idx": 0}, {"type": "text", "text": "Yin Zhang Zhejiang University yinzh@zju.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Yang Yang\u2020 Zhejiang University yangya@zju.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Automated seizure detection (ASD) using intracranial electroencephalography (iEEG) is critical for effective epilepsy treatment. However, the significant domain shift of iEEG signals across subjects poses a major challenge, limiting their applicability in real-world clinical scenarios. In this paper, we address this issue by analyzing the primary cause behind the failure of existing iEEG models for subject-independent seizure detection, and identify a critical universal seizure pattern: seizure events consistently exhibit higher average amplitude compared to adjacent normal events. To mitigate the domain shifts and preserve the universal seizure patterns, we propose a novel self-comparison mechanism. This mechanism effectively aligns iEEG signals across subjects and time intervals. Based on these findings, we propose Difference Matrix-based Neural Network (DMNet), a subjectindependent seizure detection model, which leverages self-comparison based on two constructed (contextual, channel-level) references to mitigate shifts of iEEG, and utilize a simple yet effective difference matrix to encode the universal seizure patterns. Extensive experiments show that DMNet significantly outperforms previous SOTAs while maintaining high efficiency on a real-world clinical dataset that we collected, as well as two public datasets for subject-independent seizure detection. Moreover, the visualization results demonstrate that the generated difference matrix can effectively capture the seizure activity changes throughout the seizure evolution process. Additionally, we deploy our method in an online diagnosis system to illustrate its effectiveness in real clinical applications. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Epilepsy, a chronic neurological disorder, affects more than 65 million people around the world. Up to $70\\%$ of people with epilepsy can be free from seizure only if the seizure onset zone (SOZ) can be located and surgically removed [26]. To diagnose epilepsy, doctors rely on the assessment of electrical activities that reflect the state and function of the subject\u2019s brain. Electroencephalography (EEG) is a widely employed and cost-effective method to record these electrical activities by placing sensors on the scalp. However, as a non-invasive method, it is unable to accurately locate SOZ in the deep structures of the brain. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Nowadays, iEEG is widely employed to identify and locate SOZ. Stereo-EEG, one representative iEEG technique, involves the deep implantation of electrodes within the brain to record electrical activities. These electrodes contain multiple recording contacts, called channels, and are placed across different regions of the brain, which provide stereoscopic recordings of the brain from both cortical and subcortical structures simultaneously [30]. This fully developed technique has been proven to be both effective and safe [5]. ", "page_idx": 1}, {"type": "text", "text": "Given a substantial volume of iEEG data, we present a pipeline tailored to real-world application scenarios for automated seizure detection (ASD), as depicted in Fig. 1 (g). Firstly, the ASD model is trained using data from accessible subjects. Subsequently, the trained model is applied to identify seizures in iEEG recordings from previously unseen subjects. Doctors can refer to the prediction results, allowing for a more accurate diagnosis and facilitating more effective treatment decisions. ", "page_idx": 1}, {"type": "text", "text": "However, most existing ASD methods are built on non-invasive EEG with a subject-specific setting [38, 31] and subject-independent setting [2, 44, 11]. However, these EEG-based methods are prone to failure when applied to iEEG data. This is primarily due to the significantly higher complexity of iEEG signals compared to EEG signals. iEEG signals exhibit a greater level of intricacy as a result of the structural and functional disparities in brain neural activities. Furthermore, there are variations in the number and placement of invasive electrodes (Fig. 1 (a,b)), leading to significant domain shifts across different subjects. However, Existing methods that employ domain adversarial training for subject-independent seizure detection on iEEG signals may encounter negative transfer effects [23, 27]. Although [41] proposed a method that utilizes a series of intricate pre-training strategies to learn the general pattern across subjects, it lacks efficiency. Consequently, developing an effective and efficient subject-independent ASD method using iEEG is crucial for clinical diagnosis. Here, we discuss the primary challenges associated with iEEG in ASD. ", "page_idx": 1}, {"type": "text", "text": "Challenges. The factors mentioned above cause a significant domain shift between subjects, posing an open question regarding the generalization of subject-independent epilepsy seizure detection using iEEG. This issue gives rise to challenges at both the subject level and the channel level: ", "page_idx": 1}, {"type": "text", "text": "(1) How to capture the general distinguishable representation for normal and seizures between different subjects and time intervals? Due to individual differences that exist among subjects, the inherent properties of iEEG recordings, such as amplitude, frequency, and others, are personalized to each subject. Even within the same individual, brain activities vary over time. ", "page_idx": 1}, {"type": "text", "text": "(2) How to reduce the inconsistency of the seizure patterns of different channels? The channels exhibit diverse patterns due to the iEEG records of various regions of the brain, potentially leading to conflicting patterns between subjects. For example, normal and seizure waves are indistinguishable between subjects or channels. As shown in Fig. 1, the normal wave in (e) is difficult to distinguish from the seizure waves in (c) and (d), while the seizure ", "page_idx": 1}, {"type": "image", "img_path": "mlmTxJwVsb/tmp/25e930f0d8914bfec40765c76560230cee0b83f26503f8e90e14fcf0f01388fb.jpg", "img_caption": ["Figure 1: (a, b) Locations of iEEG depth electrode contacts (red circle) for subjects $P2$ and $P4$ . (c, d, e, f) Examples of seizure and normal iEEG recording activities of subjects $P2$ and $P4$ . (g) Application of our proposed method in real-world clinical scenarios. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "event in (f) is often mistaken for the normal one. Therefore, the second challenge is to personalize the representations of brain activity independent of channels, allowing the model to adapt to different subjects. ", "page_idx": 1}, {"type": "text", "text": "Solution. To address these challenges, we first propose the mechanism of self-comparison: comparing the target segment with adjacent normal segments. Subsequently, we conduct a comprehensive observation study (Sec. 3) to demonstrate the effectiveness of self-comparison. Our findings indicate that self-comparison can obtain a general distinguishable representation of normal ones and seizures. ", "page_idx": 2}, {"type": "text", "text": "Drawing on these inspirations, we argue that the self-comparison mechanism is the key to easily and effectively capture subject-invariant patterns between subjects. To this end, we propose a novel model, namely Difference Matrix based neural Network (DMNet), for subject-independent seizure detection. Specifically, considering that different seizure events would present different neural activities (local bias) within different recording channels (global bias), we therefore introduce two reference objects (i.e., contextual reference and channel-level reference). These references ensure that we can capture both local and global dependencies within data, which are the primary contributors of distribution shift and can be effectively mitigated through the self-comparison mechanism. Subsequently, we utilize a simple yet effective fully differencing operation to generate the difference matrix, which compares the target segment with its reference objects for self-comparison implementation. To effectively extract semantics from the difference matrix, we design a difference matrix encoder based on convolutional neural network (CNN) blocks to obtain the final representation of the detection segment. Our primary contributions are listed as follows: ", "page_idx": 2}, {"type": "text", "text": "\u2022 We investigate the problem of subject-independent ASD based on the iEEG. Through comprehensive analysis, we identify the self-comparison mechanism as a simple yet effective way to capture the general representation.   \n\u2022 We propose a novel model named DMNet for subject-independent ASD. The fully differencing operation based on contextual reference and channel-level reference for self-comparison can mitigate the local and global biases among subjects and channels, improving the generalizability of learned representations.   \n\u2022 Extensive experiments on clinical and public iEEG datasets show DMNet outperforms existing SOTAs. Moreover, the generated difference matrix effectively captures seizure activity changes during the seizure evolution process. Furthermore, DMNet outperforms existing SOTAs while maintaining the high efficiency. Building on these strengths, we deploy our method in an online system, enhancing clinical applications by assisting medical professionals in the diagnosis of epilepsy and by facilitating the provision of more effective treatment options for patients. ", "page_idx": 2}, {"type": "text", "text": "2 Problem Formulation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this work, the iEEG recording is regarded as a set of time series $\\mathbf{X}=\\{\\pmb{x}^{(i)}\\}_{i=1}^{C}$ , where $C$ refers to the total number of channels. Each $\\pmb{x}^{(i)}\\in\\mathbb{R}^{T}$ corresponds to a channel, and $T$ refers to the total iEEG time series $\\bar{\\mathbf{x^{(i)}}}=\\{\\bar{x_{1}^{(i)}},\\cdots,x_{T}^{(i)}\\}$ x(Ti )} d from a subject, we first divi e the original recording data $i$ ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\left\\{s_{0},s_{1},...,s_{m-1}\\right\\}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $s_{k}\\,=\\,\\{x_{\\ell\\times k+1},\\cdot\\cdot\\cdot\\,,x_{\\ell\\times(k+1)}\\},0\\,\\le\\,k\\,\\le\\,m-1,\\,\\ell$ is the number of timestamp for each segment, $m$ is the total number of segments. Each segment $s_{k}$ has a corresponding label $y_{k}\\in\\{0,1\\}$ , indicating whether the segment contains a seizure event. In this work, our aim is to predict $y_{k}$ on each segment $s_{k}$ for different subjects. ", "page_idx": 2}, {"type": "text", "text": "We define our problem as an innovative study of Domain Generalization (DG) [45] in the context of epileptic diagnosis. In this study, we treat each subject\u2019s data as a domain, and our goal is to utilize the data of available labeled subjects (source domains) to train a model that can be directly adopted to the subjects with unseen data (target domains). ", "page_idx": 2}, {"type": "text", "text": "3 Empirical Analysis ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we first analyze the primary cause behind the failure of existing models for subjectindependent seizure detection of the iEEG and the reasons of occurrence. Then we explore the possibility of a domain-consistent seizure pattern existing within iEEG data, taking into account the domain shift issue. Finally, we validate whether self-comparison mechanism can mitigate distribution shifts in iEEG data and capture the potential domain consistent seizure patterns. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "image", "img_path": "mlmTxJwVsb/tmp/fd33b591ddfb478ffaf99e4ff137ce6e2659a3fa2f0796a0b1cfc751bab07fd3.jpg", "img_caption": [], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Figure 2: Observation results of the clinical iEEG dataset. (a) Overall distribution of raw iEEG signals (all subjects and channels), where normal and seizure events are indistinguishable. (b) Distribution of raw iEEG signals across different time intervals and subjects, where substantial domain shifts are evident in both distinct time intervals and among different subjects (red dashed line at 0 serves as reference line for domain shift). (c) Overall distribution of raw iEEG data after the self-comparison process. (d) Distribution of raw iEEG data across different time intervals and subjects after the self-comparison process. The self-comparison mechanism effectively mitigates distribution shifts across time intervals and subjects, thus enhancing the model\u2019s ability to distinguish between seizure and normal events. ", "page_idx": 3}, {"type": "text", "text": "3.1 iEEG Domain Shift Issue and Domain Consistent Seizure Pattern ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Most previous studies [10, 16] assert that vanilla detection models trained independently by each subject are prone to failure when applied to other subjects. To analyze the direct cause of failure, we merge raw iEEG signals from all subjects and channels in a clinical iEEG dataset (details in App. C), and analyze the distributions of seizure and normal events. As depicted in Fig. 2 (a), the results reveal nearly identical means and close variances for both seizure and normal signals in the merged data. This similarity leads to the indistinguishability between normal and seizure signals across subjects, which becomes a direct factor to the failure of subject-dependent models. ", "page_idx": 3}, {"type": "text", "text": "For a detailed analysis, we partition the iEEG signals into multiple intervals, each comprising 250 timestamps, for each subject. We then compute the distributions of seizure and normal events within each interval. Through empirical analysis, we observe significant domain shifts both across different subjects (inter-subject) and different time intervals for the same subject (intra-subject). Fig. 2 (b) presents the normal and seizure distributions within four intervals randomly sampled from subjects P1 and P2, where the distribution patterns of normal and seizure exhibit substantial variation across different time intervals and subjects. This observation aligns with findings from previous studies in neural science and medicine, which have consistently reported that brain signals exhibit high variability between subjects and sessions due to inherent background neural activities [33], seizure patterns [14], electrode locations [9], etc. ", "page_idx": 3}, {"type": "text", "text": "Despite the pronounced domain shift observed in iEEG signals across subjects and time intervals, there is a notable commonality among subjects. Specifically, seizure events consistently demonstrate a higher average amplitude in the frequency domain compared to their background signal (adjacent normal events), indicating more intense neural oscillatory activities. This finding is consistent with previous studies in the field [34, 21]. ", "page_idx": 3}, {"type": "text", "text": "3.2 Self-Comparison can Help ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Based on the commonality above, we propose a novel self-comparison mechanism, which compares the target segment with its adjacent normal segment, to mitigate domain shifts between subjects and time intervals. To verify the effectiveness of this mechanism, we conduct an empirical study. First, for each subject, we partition the contiguous iEEG data into small segments. Considering that the spectral signal of brain data can effectively track transient changes before and during seizures [6], we proceed to transform these segments into the frequency domain using Discrete Fourier Transform (DFT). Subsequently, we calculate the spectrum differences by subtracting the spectrum of the target segment from those of adjacent segments on both sides of the target segment. We then sum up the absolute values of these differences, generating a single value $D$ for each target segment. ", "page_idx": 3}, {"type": "image", "img_path": "mlmTxJwVsb/tmp/0ee7c267ca7b568a064af6df3f9a6a60b91b8de5344d21c8006ccfbd5091ca6e.jpg", "img_caption": ["Figure 3: Overview of the proposed DMNet. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "The overall distributions of $D$ values for all seizure and normal segments are depicted in Figure 3 (c). Notably, the distribution of the normal and seizure segments becomes distinctly separated after the adoption of the self-comparison mechanism. Additionally, we analyze the distribution of $D$ values for target segments within the same four intervals from P1 and P2, which is discussed in Section 3.1. The results are shown in Figure 3 (d). It is evident that the distribution of normal or seizures segments is well aligned across different subjects and time intervals, and the patterns of normal and seizure become more distinguishable. These results signify that our proposed self-comparison mechanism effectively mitigates the domain shift issue and preserves a domain consistent and distinguishable representation for normal and seizure segments. ", "page_idx": 4}, {"type": "text", "text": "4 Methodology ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Inspired by the above observations, we propose a subject-independent seizure detection framework called DMNet, which leverages self-comparison to alleviate the distribution shift and preserve the domain consistency while distinguishing seizure patterns. ", "page_idx": 4}, {"type": "text", "text": "Overview. The overall framework is illustrated in Fig. 3. First, for each detection segment $s_{k}\\prod$ , we construct two reference segments (contextual reference : $L_{c}(s_{k})\\,/\\,R_{c}(s_{k})$ , channel-level reference : $L_{c\\ell}(s_{k})\\mid R_{c\\ell}(s_{k}))$ to compare with the target segment (Fig. 3, left). Then we use a simple yet effective fully differencing operation with signed-min-max normalization for self-comparison implementation, and the compared information is encoded by a difference matrix (DM) (Fig. 3, middle). Then we employ a CNN-based difference matrix encoder to learn the latent representation of DM, and use a classifier for seizure detection (Fig. 3, right). ", "page_idx": 4}, {"type": "text", "text": "4.1 References for Self-Comparison ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Contextual Reference. The structural and functional differences in brain neural activity lead to distribution shifts between subjects, and even across different time intervals within the same subject. Based on the insights from observation studies in Section 3.2, we propose to compare the seizure wave with its adjacent contexts for the identification of seizure activities, as it significantly mitigates the domain shifts between subjects and preserves a domain-consistent and distinguishable pattern of seizure events. ", "page_idx": 4}, {"type": "text", "text": "However, capturing the long dependencies between seizure events and their contexts is challenging with a single contextual segment. This is because a typical epileptic seizure phase consists of preseizure aura, seizure onset, and post-seizure periods, with varying duration (ranging from seconds to minutes or longer in the case of status epilepticus) [12]. To this end, we first extract $2\\times N$ temporal segments $\\{s_{i}\\}_{k-N\\leq i\\leq k-1}$ and $\\{s_{i}\\}_{k+1\\leq i\\leq k+N}$ from both sides of $s_{k}$ (each contains $L=N\\times\\ell$ timestamps in total, with each segment consisting of $\\ell$ timestamps), ensuring that the context contain abundant normal information for comparison. Subsequently, we apply DFT to convert these segments into the frequency domain representation $\\in\\mathbb{R}^{d}$ . Finally, the frequency domain segments obtained from the left and right sides are referred as the contextual references of $s_{k}$ , denoted as $\\mathbf{\\breve{\\calL}}_{c}(s_{k})\\in\\mathbb{R}^{N\\times d}$ and $R_{c}(s_{k})\\in\\mathbb{R}^{N\\times d}\\,(\\!\\!\\!\\!\\prod_{i=1}^{}\\!\\!\\!\\!\\!\\!\\bigcirc_{s_{i}}\\!\\!\\!\\!\\!\\!N_{i})$ ) respectively. ", "page_idx": 4}, {"type": "text", "text": "Channel-level Reference. Different physiological brain regions have variations in neural activities [37], leading to distribution shifts between channels, even within the same subject. Although contextual reference can reduce local bias, it fails to address global bias. Moreover, for prolonged epileptic seizures, solely considering the adjacent contextual reference segments may not provide sufficient normal information as background for comparison. To address these issues, we introduce channel-level reference as representative features of channels. The aim is to personalize channels, alleviate global bias, and provide comprehensive global background information of normal events. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Specifically, we adopt the K-Means [24] algorithm to identify the most representative patterns within a channel. First, we divide the entire time series of each channel into segments with length $\\ell$ . Then, similar with contextual reference, we use DFT to obtain the frequency domain representation $\\in\\mathbb{R}^{d}$ of all segments. Next, the K-Means clustering algorithm is applied to group all frequency domain representations into $K$ clusters. Finally, we arrange the clusters in descending order according to the number of elements they contain (denoted as $C_{1},C_{2},\\cdots\\,,C_{K}$ , where $|C_{1}|\\stackrel{\\cdot}{\\geq}|C_{2}|\\geq\\cdots\\geq|C_{K}|)$ . The arrangement indicates that the higher the index of the cluster, the lower the frequency of occurrence of the corresponding general pattern in the respective channel. ", "page_idx": 5}, {"type": "text", "text": "To obtain the general patterns of the channel, we use the centroid of each cluster, resulting in the final representation denoted as $\\mu_{k}\\in\\mathbb{R}^{d},k=1,...,K$ . These $\\mu_{k}$ values are then concatenated to construct the left side channel-level reference $L_{c\\ell}(s_{k})\\in\\mathbb{R}^{K\\times d}$ . Empirically, the right side $R_{c\\ell}(s_{k})$ is formed by reversing the order of $L_{c\\ell}(s_{k})$ . ", "page_idx": 5}, {"type": "text", "text": "4.2 Difference Matrix ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this subsection, we present the self-comparison implementation based on the constructed references and target segments through a simple yet effective approach of fully differencing operation. The comparison information is encoded using a difference matrix (DM). ", "page_idx": 5}, {"type": "text", "text": "We first obtain the frequency domain representation $x_{k}^{f}\\,(\\boxed{\\begin{array}{l}{\\begin{array}{r l}\\end{array}})}$ of target segment $s_{k}$ via DFT, and then concatenate $\\v x_{k}^{f}$ with the constructed contextual $\\mathbb{(}\\overline{{\\;\\;\\mathbb{J}\\;}}$ and channel-level $\\mathbb{C}$ references to form the augmented segment $\\tilde{x}_{k}^{f}$ (as shown in Figure 3, bottom-left): ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\tilde{x}_{k}^{f}=L_{c\\ell}(s_{k})\\,||L_{c}(s_{k})||\\,x_{k}^{f}\\,||R_{c}(s_{k})||\\,R_{c\\ell}(s_{k}),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\bigstar\\bigstar||\\bigstar$ is a concatenate operation and $\\tilde{x}_{k}^{f}\\in\\mathbb{R}^{(2N+2K+1)\\times d}$ . ", "page_idx": 5}, {"type": "text", "text": "Fully Differencing Operation. To implement self-comparison of target segment and references, we introduce a fully differencing operation. Unlike traditional first-order differencing [13] that considers only adjacent points, the fully differencing operation makes a pairwise comparison across all segments in $\\tilde{x}_{k}^{f}$ (described in Equation 3 and Fig. 3, middle), which can more effectively capture the essential seizure patterns of brain activities. Moreover, since there are inherent scale differences in the vanilla difference matrix $\\mathbf{D}_{k}$ caused by varying magnitudes between seizure and normal iEEG signals across subjects, channels and time intervals, min-max normalization is adopted to address the scale difference issue. After these two operations, a synthetic difference matrix $\\hat{\\mathbf{D}}_{k}$ can be obtained: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\mathbf{D}_{k}[i,j]=\\tilde{x}_{k}^{f}[i]-\\tilde{x}_{k}^{f}[j],1\\le i,j\\le2N+2K+1,\\quad\\quad}\\\\ &{}&{\\hat{\\mathbf{D}}_{k}=\\mathrm{Min-Max-Norm}(\\mathbf D_{k})\\in\\mathbb{R}^{(2N+2K+1)\\times(2N+2K+1)\\times d}}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The generated difference matrix $\\hat{\\mathbf{D}}_{k}$ contains rich semantic information about the evolution of seizures. We provide a more detailed discussion on each component of the difference matrix $\\hat{\\mathbf{D}}_{k}$ and the corresponding semantic properties in App B. ", "page_idx": 5}, {"type": "text", "text": "Difference Matrix Encoder. To well capture and learn these essential differences, we adopt the CNNs as the DM encoder (Fig. 3,right), which have been proven to be powerful in learning representations from 2D matrices [35, 42]. The output of the CNNs will be concatenated as a representation $\\hat{\\textbf{Z}}$ of the DM. Finally, $\\hat{\\textbf{Z}}$ will be fed into a linear classifier to obtain the detection result. ", "page_idx": 5}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we conduct extensive experiments on public and clinical iEEG datasets to address three primary research questions: RQ1. How does the proposed DMNet model perform in subjectindependent seizure detection compared to other methods? RQ2. Do the proposed contextual ", "page_idx": 5}, {"type": "table", "img_path": "mlmTxJwVsb/tmp/68a890889bdb0b5bb4f6a5a22071f4c69aeba146fa7c10580f870d66558f39eb.jpg", "table_caption": ["Table 1: Average performance of subject-independent seizure detection tasks on clinical & public datasets. The v indicates the first rank in a column and v indicates the second. The performance with standard deviation is given in App. G. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "reference, channel-level reference and difference matrix contribute to seizure detection? RQ3. How does the difference matrix reflect seizure activity changes during seizure evolution process? ", "page_idx": 6}, {"type": "text", "text": "5.1 Experimental Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Datasets. To evaluate the performance of our DMNet model, we conduct experiments on both the public benchmark dataset, which includes MAYO and FNUSA [25], and the private clinical dataset (details refer to App. C). ", "page_idx": 6}, {"type": "text", "text": "Evaluation Metrics. For fair comparison, we use precision, recall, F1-score and F2-score as evaluation metrics. Typically, F2-score is particularly emphasized in practical clinical studies [15, 43] since overlooking any seizure can be costly in terms of diagnosis. Therefore, in our study, the F2-score serves as the primary metric for comparison. ", "page_idx": 6}, {"type": "text", "text": "Settings. To conduct the experiment under the domain generalization settings, we divide the subjects in the datasets into multiple groups and assign different groups as source and target domains for model training, validation and testing. A more detailed description of experimental setup that includes DMNet hyperparameters and setup on clinical and public datasets, can be found in App. D. ", "page_idx": 6}, {"type": "text", "text": "Baselines. We compare the proposed DMNet with state-of-the-art subject-independent seizure detection algorithms for both iEEG-based methods and EEG-based methods. For iEEG-based methods, we compared against SICR [17], SEEG-Net [39], and PPi [41]. For EEG-based methods, we compared against Abou-Abbas et al. [2], Zhao et al. [44], and Dissanayake et al. [11]. Additionally, we compare the performance with the domain generalization (DG) algorithms in other areas like SelfReg [18], GroupDRO [32], MTL [7], CORAL [36], CDANN [22], SD [28], IB-IRM [3], VREx [19], IB-ERM [4], TRM [40]. More details of the baselines are shown in App. A. ", "page_idx": 6}, {"type": "text", "text": "5.2 Overall Performance Comparison (RQ1) ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The overall performance of our proposed model DMNet and other baselines for subject-independent seizure detection are presented in Tab. 1. From the results, we can see that our proposed DMNet significantly outperforms other SOTA subject-independent seizure detection algorithms and the latest domain generalization methods, with an average improvement of $9.41\\%$ , $14.81\\%$ and $4.97\\%$ in terms of F2 score on clinical and public datasets (MAYO and FNUSA) respectively. These results highlight the superior generalization ability of DMNet. Compared to DG baselines, our model exhibits a substantial margin in all evaluation metrics, suggesting that general DG baselines fail to capture the diverse and evolving distribution patterns of iEEG over time. Furthermore, the EEG-based methods proposed by [2], [44] and [11] may not be adept at handling complex iEEG signals, which lead to subpar performance. Although the iEEG-based methods [41], SEEG-Net [39] and SICR [17] outperform most EEG-based methods and DG methods on F2-score, they still fall short of the performance compared to our model. This may be attributed to the fact that they do not explicitly capture the general pattern of difference between normal and seizure signals. In contrast, we utilize a difference matrix to achieve a distinguishable representation of normal and seizure. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "5.3 Ablation Study of DMNet (RQ2) ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "To validate the contribution of each component of our proposed DMNet, we conduct ablation studies on key components (w/o means without and w/ means with). The results of the ablation evaluation can be seen in Tab. 1, from which we can see full DMNet significantly outperforms other ablated models on F2-score. These results of the ablation experiment highlight the effectiveness of the following components: ", "page_idx": 7}, {"type": "text", "text": "Channel-level Reference. Removing channel-level reference causes poorer results compared to the full version. It indicates that utilizing the channel-level reference with representative characteristics of each channel for global dependencies modeling can improve the performance. ", "page_idx": 7}, {"type": "text", "text": "Contextual Reference. Removing contextual reference results in a noticeable performance drop. It illustrates that introducing the informative contextual reference for self-comparison to capture long-term dependencies and complete patterns of seizure improves the performances. ", "page_idx": 7}, {"type": "text", "text": "Difference Matrix. Removing DM leads to a significant drop in model performance, indicating the effectiveness of a fully differencing operation for the implementation of self-comparison. ", "page_idx": 7}, {"type": "text", "text": "5.4 Case Study (RQ3) ", "text_level": 1, "page_idx": 7}, {"type": "image", "img_path": "mlmTxJwVsb/tmp/3ce7accc9c0fcf394a91d8576f7970a9bda4a7bc39071066f80e6156a92f74fb.jpg", "img_caption": ["Figure 4: Case study. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "To provide a more intuitive demonstration of DMNet, we present the visualization results of difference matrix throughout the seizure process in Fig. 4 (A full visualization can be found in App. E). The upper figure shows the raw brain signal containing a full seizure process, with the gray wave representing the normal signal and the purple wave representing the seizure. The green masked blocks indicate the segments for detection. Notably, there are clear distinctions between seizure and normal difference matrices during the seizure evolution. Segments being closer to seizure events show rougher difference matrices (e.g., segments c, d, and e), while those further away appear smoother (e.g., segments a, b, f, and g). This case clearly illustrates how the difference matrix captures seizure activity changes and demonstrates the effectiveness of DMNet. ", "page_idx": 7}, {"type": "text", "text": "5.5 Hyperparameters Analysis of DMNet ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Number of Segments $N$ . As described in Sec. 4.1, we utilize $2\\times N$ segments to form the contextual reference. Increasing the value of $N$ results in a longer contextual reference, indicating the inclusion of a greater amount of contextual information. As depicted in Fig. 5(a), the evaluation scores generally increase as $N$ increases from 8 to 12. This trend is attributed to the fact that a longer contextual reference can provide more comprehensive information throughout the entire seizure phase. ", "page_idx": 7}, {"type": "text", "text": "Segment Length \u2113. We investigate the effects of segment length by varying the segment length $\\ell$ of contextual reference. The performance of DMNet with different segment lengths $(100,150,200,250,300)$ is shown in Fig. 5(b). As $\\ell$ increases, the model precision decreases. ", "page_idx": 7}, {"type": "image", "img_path": "mlmTxJwVsb/tmp/9698bd8d8dbf2274e25b1377a653b70f8cced8a70459c55c3705b713843eb75d.jpg", "img_caption": ["Figure 5: Hyperparameters Anslysis: (a, b, c) and Computational Efficiency Analysis (d). "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "In contrast, recall, F1 score and F2-score initially increase when $\\ell$ ranges from 100 to 200 but then decline. This suggests that shorter segment lengths $(\\ell)$ fail to provide representative semantic information, preventing the model from capturing long-term dependencies in the brain signal. Conversely, excessively long segment lengths can result in coarse-grained temporal representations, leading to the loss of fine-grained patterns and details. ", "page_idx": 8}, {"type": "text", "text": "Number of Clusters $K$ . We vary the number of clusters $K$ in channel-level reference, which controls the number of generated channel representative features of a specific channel. As we can see in Fig. 5(c), the evaluation metrics (recall, F1 score, and F2-score) demonstrate an initial increase followed by a decrease trend as $K$ varies from 6 to 12. However, precision shows an upward trend. This indicates that introducing global information can reduce false positive samples but it also affects recall. Therefore, it is necessary to consider trade-offs when selecting the value of $K$ . ", "page_idx": 8}, {"type": "text", "text": "5.6 Generalization Ability Analysis ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "To further assess the generalization capability of DMNet on a broader range of subjects with greater heterogeneity, we evaluated the model on data of 179 previously unseen subjects from the large TUSZ EEG dataset [1]. Additional details about this evaluation study are provided in App.F. ", "page_idx": 8}, {"type": "text", "text": "5.7 Application Scenario ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Model Efficiency. We compare the model efficiency of DMNet and several benchmark models in terms of parameter count and average inference time per patient file. As shown in Fig. 5 (d), the parameter count of DMNet is only $\\bar{1}9.4\\%$ of the model with the smallest parameter count, but its performance is $109.4\\%$ of the best-performing model. Additionally, DMNet has an average inference time of 45.5 seconds per subject file, which is also the fastest among all models. Overall, DMNet demonstrates significant advantages in both parameter count and inference time. Therefore, DMNet is an ideal choice, providing a reliable and high-performance solution for real application scenario. ", "page_idx": 8}, {"type": "text", "text": "Online Deployment. DMNet has been deployed on an online system (Fig.6), which illustrates the effectiveness of our method in a real clinical application. This system serves as an auxiliary tool for expert doctors, significantly enhancing the accuracy and efficiency of the diagnostic process. The system comprises two important pages: the overview page and the detail page. The overview page (Fig.6 (top)) offers a comprehensive view of the 12-hour patient file. Each square on the page represents a 1-minute iEEG signal segment and is color coded to indicate various states, including no epileptic waves (gray), correct predictions (green), incorrect predictions (blue), and missing predictions (red) made by our model. By clicking on a square, doctors can access the detail page (Fig.6 (bottom)), where they can change the presented time period using ", "page_idx": 8}, {"type": "image", "img_path": "mlmTxJwVsb/tmp/559512624e5c2e30c35154e252aff4c8adb0ab6fbf21d7a31c67a28ce0904494.jpg", "img_caption": ["Figure 6: Online auxiliary diagnosis system. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "the top toolbar. The page includes a data operation panel and seizure events displayed on the right side. In the center of the page, the purple section represents the true seizure annotations provided by doctors, while the yellow section showcases our model\u2019s predictions. As depicted in the figure, the predictions of our model align well with the actual seizures. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "6 Related Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Epileptic Seizure Detection for EEG. Data-driven methods for seizure detection have gained attention in clinical medicine. [38] combine CNN and SVM, [31] leverage frequency components and CNN. However, these methods are subject-specific and not suitable for real-world application. Several efforts have been made in the study of subject-independent methods in EEG. [2] proposed and investigates a subject-independent seizure detection model that uses stable EEG-based features obtained by comparing multiple feature selection methods. [44] proposed two subject independent deep learning architectures with different learning strategies that can learn a global function utilizing data from multiple subjects. [11] proposed IBA (Information Bottleneck Attribution), a subjectindependent seizure detection model that utilizes multi-view information. It employs adversarial deep learning to learn seizure-specific feature representations directly from raw EEG data. However, these methods are based on non-invasive EEG recordings. ", "page_idx": 9}, {"type": "text", "text": "Epileptic Seizure Detection for iEEG. iEEG, through the placement of electrodes inside or on the surface of the brain, offers higher temporal and spatial resolution, enabling more accurate capture and analysis of brain activity in specific regions, including subtle changes in electrophysiological signals. Consequently, this has spurred research into epilepsy detection based on iEEG [26]. There are several seizure detection methods being designed in subject-independent settings, which are more applicable to real-world scenarios. SEEG-Net [39] and SICR [17] proposed adversarial training to learn subject-invariant features on iEEG recordings. However, their experiments were carried out on small, manually denoised datasets with a balanced positive-negative sample ratio, resulting in a significant data bias that deviates from real clinical requirements. Moreover, [41] proposed a method that utilizes a series of intricate pre-training strategies to learn general pattern cross subjects, which is lack of efficiency. ", "page_idx": 9}, {"type": "text", "text": "General Domain Generalization. Our work focuses on detecting seizure events in unseen subjects, which can be framed as the domain generalization (DG) problem [45]. Existing DG studies can be categorized into two groups: Invariant representation based method [36, 22, 4, 18, 3, 7] and Learning strategy based method [20, 32, 19, 28]. Invariant representation methods aim to learn domain-invariant representations. CORAL [36] aligns covariance in feature layers, enhancing the extraction of domain-invariant features. CDANN [22] introduces adversarial training to encourage robust and domain-invariant feature learning. IB-ERM [4] minimizes empirical risk across domains to improve generalization. SelfReg [18] uses self-supervised learning and contrastive loss to capture invariant information across domains. Learning strategy methods aim to enhance generalization capability through various learning strategies. GroupDRO [32] achieves higher worst-group accuracy by coupling robust optimization models with increased regularization. VREx [19] penalizes the variance of training risks to improve domain extrapolation. Despite prior efforts, DG problems in time series, like iEEG signals, continue to be a relatively unexplored area and poses considerable challenges due to the diverse and evolving distribution patterns with time. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we present a novel seizure detection framework called DMNet. Our model addresses the challenge of generalization across different subjects by incorporating a self-comparison mechanism to capture the subject-invariant representation. Extensive experiments conducted on clinical intracranial EEG dataset and public dataset demonstrate the effectiveness of our model in subject-independent seizure detection tasks. Moreover, our generated difference matrix effectively captures seizure activity changes during the seizure evolution process, which is valuable for clinicians to better understand the seizure event and develop more effective treatment. Furthermore, DMNet outperforms existing SOTAs while maintaining the high efficiency. Based on these, we deploy our method in an online system, enhancing clinical applications by assisting physicians in the diagnosis of epilepsy and in offering optimal treatment strategies. We hope that this work will shed light on the development of a more robust subject-independent seizure detection system. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work was partially supported by National Natural Science Foundation of China (No. 62322606, No. 62441605). ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] The temple university hospital seizure detection corpus. Frontiers in Neuroinformatics, page 83, 2018.   \n[2] Lina Abou-Abbas, Khadidja Henni, Imene Jemal, Amar Mitiche, and Neila Mezghani. Patientindependent epileptic seizure detection by stable feature selection. Expert Systems with Applications, 232:120585, December 2023.   \n[3] Kartik Ahuja, Ethan Caballero, Dinghuai Zhang, Jean-Christophe Gagnon-Audet, Yoshua Bengio, Ioannis Mitliagkas, and Irina Rish. Invariance Principle Meets Information Bottleneck for Out-of-Distribution Generalization. In Advances in Neural Information Processing Systems, volume 34, pages 3438\u20133450, 2021.   \n[4] Kartik Ahuja, Ethan Caballero, Dinghuai Zhang, Jean-Christophe Gagnon-Audet, Yoshua Bengio, Ioannis Mitliagkas, and Irina Rish. Invariance principle meets information bottleneck for out-of-distribution generalization. Advances in Neural Information Processing Systems, 2021.   \n[5] Abdu Soha Alomar, Jaes Jones, Andres Maldonado, and Jorge Gonzalez-Martinez. The stereoelectroencephalography methodology. Neurosurgery Clinics of North America, pages 83\u201395, 2016.   \n[6] Mojtaba Bandarabadi, C\u00e9sar A Teixeira, Jalil Rasekhi, and Ant\u00f3nio Dourado. Epileptic seizure prediction using relative spectral power features. Clinical Neurophysiology, 126(2):237\u2013248, 2015.   \n[7] Gilles Blanchard and Aniket Anand Deshmukh. Domain Generalization by Marginal Transfer Learning.   \n[8] Gilles Blanchard, Aniket Anand Deshmukh, Urun Dogan, Gyemin Lee, and Clayton Scott. Domain generalization by marginal transfer learning. Journal of Machine Learning Research, pages 1\u201355, 2021.   \n[9] Stephan Chabardes, Taylor J Abel, Francesco Cardinale, and Philippe Kahane. Commentary: understanding stereoelectroencephalography: what\u2019s next? Neurosurgery, pages E15\u2013E16, 2018.   \n[10] Xin Chai, Qisong Wang, Yongping Zhao, Xin Liu, Ou Bai, and Yongqiang Li. Unsupervised domain adaptation techniques based on auto-encoder for non-stationary eeg-based emotion recognition. Computers in biology and medicine, 79:205\u2013214, 2016.   \n[11] Theekshana Dissanayake, Tharindu Fernando, Simon Denman, Sridha Sridharan, and Clinton Fookes. Deep Learning for Patient-Independent Epileptic Seizure Prediction Using Scalp EEG Signals. IEEE Sensors Journal, 21(7):9377\u20139388, April 2021.   \n[12] Arjan Hillebrand, Niall Holmes, Ndedi Sijsma, George C. O\u2019Neill, Tim M. Tierney, Niels Liberton, Anine H. Stam, Nicole van Klink, Cornelis J. Stam, Richard Bowtell, Matthew J. Brookes, and Gareth R. Barnes. Non-invasive measurements of ictal and interictal epileptiform activity using optically pumped magnetometers. Scientific Reports, 2023.   \n[13] S. L. Ho and M. Xie. The use of ARIMA models for reliability forecasting and analysis. Computers & Industrial Engineering, 1998.   \n[14] M Shamim Hossain, Syed Umar Amin, Mansour Alsulaiman, and Ghulam Muhammad. Applying deep learning for epilepsy seizure detection and brain mapping visualization. ACM Transactions on Multimedia Computing, Communications, and Applications, pages 1\u201317, 2019.   \n[15] Yingying Hu, Ruijia Chen, Haibing Gao, Haitao Lin, Jinye Wang, Xiaowei Wang, Jingfeng Liu, and Yongyi Zeng. Explainable machine learning model for predicting spontaneous bacterial peritonitis in cirrhotic patients with ascites. Scientific Reports, 2021.   \n[16] Eunjin Jeon, Wonjun Ko, and Heung-Il Suk. Domain adaptation with source selection for motor-imagery based bci. In 2019 7th International Winter Conference on Brain-Computer Interface (BCI), 2019.   \n[17] Eunjin Jeon, Wonjun Ko, Jee Seok Yoon, and Heung-Il Suk. Mutual information-driven subjectinvariant and class-relevant deep representation learning in bci. IEEE Transactions on Neural Networks and Learning Systems, 2021.   \n[18] Daehee Kim, Youngjun Yoo, Seunghyun Park, Jinkyu Kim, and Jaekoo Lee. Selfreg: Selfsupervised contrastive regularization for domain generalization. In Proceedings of the International Conference on Computer Vision, pages 9619\u20139628, 2021.   \n[19] David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapolation (rex). In International Conference on Machine Learning. PMLR, 2021.   \n[20] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy Hospedales. Learning to generalize: Metalearning for domain generalization. In Proceedings of the AAAI conference on artificial intelligence, 2018.   \n[21] Guangye Li, Shize Jiang, Sivylla E Paraskevopoulou, Meng Wang, Yang Xu, Zehan Wu, Liang Chen, Dingguo Zhang, and Gerwin Schalk. Optimal referencing for stereoelectroencephalographic (seeg) recordings. NeuroImage, pages 327\u2013335, 2018.   \n[22] Ya Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang, and Dacheng Tao. Deep domain generalization via conditional invariant adversarial networks. In Proceedings of the European Conference on Computer Vision, pages 624\u2013639, 2018.   \n[23] Hong Liu, Mingsheng Long, Jianmin Wang, and Michael Jordan. Transferable Adversarial Training: A General Approach to Adapting Deep Classifiers. In Proceedings of the 36th International Conference on Machine Learning. PMLR, 2019.   \n[24] S. Lloyd. Least squares quantization in pcm. IEEE Transactions on Information Theory, 28(2):129\u2013137, 1982.   \n[25] Petr Nejedly, Vaclav Kremen, Vladimir Sladky, Jan Cimbalnik, Petr Klimes, Filip Plesinger, Filip Mivalt, Vojtech Travnicek, Ivo Viscor, Martin Pail, Josef Halamek, Benjamin H. Brinkmann, Milan Brazdil, Pavel Jurak, and Gregory Worrell. Multicenter intracranial EEG dataset for classification of graphoelements and artifactual signals. Scientific Data, 7(1):179, June 2020.   \n[26] Min Ni, Bushra Afroze, Chao Xing, Chunxiao Pan, Yanqiu Shao, Ling Cai, Brandi L Cantarel, Jimin Pei, Nick V Grishin, Stacy Hewson, et al. A pathogenic ufsp2 variant in an autosomal recessive form of pediatric neurodevelopmental anomalies and epilepsy. Genetics in Medicine, pages 1\u20139, 2021.   \n[27] Xingchao Peng, Zijun Huang, Ximeng Sun, and Kate Saenko. Domain Agnostic Learning with Disentangled Representations. In Proceedings of the 36th International Conference on Machine Learning. PMLR, 2019.   \n[28] Mohammad Pezeshki, Oumar Kaba, Yoshua Bengio, Aaron C Courville, Doina Precup, and Guillaume Lajoie. Gradient Starvation: A Learning Proclivity in Neural Networks. In Advances in Neural Information Processing Systems, volume 34, pages 1256\u20131272, 2021.   \n[29] Mohammad Pezeshki, S\u00e9kou-Oumar Kaba, Yoshua Bengio, Aaron Courville, Doina Precup, and Guillaume Lajoie. Gradient starvation: A learning proclivity in neural networks. arXiv e-prints, pages arXiv\u20132011, 2020.   \n[30] Timoth\u00e9e Proix, Viktor K. Jirsa, Fabrice Bartolomei, Maxime Guye, and Wilson Truccolo. Predicting the spatiotemporal diversity of seizure propagation and termination in human focal epilepsy. Nature Communications, 9(1):1088, March 2018.   \n[31] Md Rashed-Al-Mahfuz, Mohammad Ali Moni, Shahadat Uddin, Salem A Alyami, Matthew A Summers, and Valsamma Eapen. A deep convolutional neural network method to detect seizures and characteristic frequencies using epileptic electroencephalogram (eeg) data. IEEE Journal of Translational Engineering in Health and Medicine, 2021.   \n[32] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. arXiv preprint arXiv:1911.08731, 2019.   \n[33] Wojciech Samek, Frank C Meinecke, and Klaus-Robert M\u00fcller. Transferring subspaces between subjects in brain\u2013computer interfacing. IEEE Transactions on Biomedical Engineering, pages 2289\u20132298, 2013.   \n[34] Catherine A Schevon, Shennan A Weiss, Guy McKhann Jr, Robert R Goodman, Rafael Yuste, Ronald G Emerson, and Andrew J Trevelyan. Evidence of an inhibitory restraint of seizure activity in humans. Nature communications, 2012.   \n[35] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps, 2014.   \n[36] Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In Computer Vision \u2013 ECCV 2016 Workshops. Springer, 2016.   \n[37] James X. Tao, Shasha Wu, Maureen Lacy, Sandra Rose, Naoum P. Issa, Carina W. Yang, Katherine E. Dorociak, Maria Bruzzone, Jisoon Kim, Ahmad Daif, Jason Choi, Vernon L. Towle, and Peter C. Warnke. Stereotactic EEG-guided laser interstitial thermal therapy for mesial temporal lobe epilepsy. Journal of Neurology, Neurosurgery, and Psychiatry, 2018.   \n[38] Syed Muhammad Usman, Shehzad Khalid, and Muhammad Haseeb Aslam. Epileptic seizures prediction using deep learning techniques. IEEE Access, pages 39998\u201340007, 2020.   \n[39] Yiping Wang, Yanfeng Yang, Gongpeng Cao, Jinjie Guo, Penghu Wei, Tao Feng, Yang Dai, Jinguo Huang, Guixia Kang, and Guoguang Zhao. Seeg-net: An explainable and deep learningbased cross-subject pathological activity detection method for drug-resistant epilepsy. Computers in Biology and Medicine, page 105703, 2022.   \n[40] Yilun Xu and Tommi Jaakkola. Learning representations that support robust transfer of predictors. arXiv e-prints, pages arXiv\u20132110, 2021.   \n[41] Zhizhang Yuan, Daoze Zhang, Yang Yang, Junru Chen, and Yafeng Li. PPi: Pretraining brain signal model for patient-independent seizure detection. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[42] Matthew D. Zeiler and Rob Fergus. Visualizing and Understanding Convolutional Networks. In Computer Vision \u2013 ECCV 2014. Springer International Publishing, 2014.   \n[43] Kevin Zhang and Dina Demner-Fushman. Automated classification of eligibility criteria in clinical trials to facilitate patient-trial matching for specific patient populations. Journal of the American Medical Informatics Association : JAMIA, 2017.   \n[44] Yanna Zhao, Gaobo Zhang, Yongfeng Zhang, Tiantian Xiao, Ziwei Wang, Fangzhou Xu, and Yuanjie Zheng. Multi-view cross-subject seizure detection with information bottleneck attribution. J. Neural Eng., 19(4):046011, August 2022.   \n[45] Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and Chen Change Loy. Domain Generalization: A Survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Baselines ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Firstly, we compare our model to other iEEG-based subject-independent epilepsy detection models. The Details of these baseline models are given here: ", "page_idx": 13}, {"type": "text", "text": "\u2022 SICR [17]: a framework that learns class-relevant and subject- invariant feature representations, which shows a promising performance in non-invasive brain-computer interface.   \n\u2022 SEEG-Net [39]: a model that can address the problems of sample imbalance, cross-subject domain shift, and poor interpretability and realizes high-sensitivity SEEG pathological activity detection. The source code of SEEG-Net is not released, so we implement it by ourselves to conduct the experiments.   \n\u2022 PPi [39]: proposed a method that utilizes a series of pre-training strategies to extract rich information from iEEG data while preserving the unique characteristics between brain signals recorded from different brain areas. ", "page_idx": 13}, {"type": "text", "text": "Secondly, we also compare our model to several EEG-based subject-independent epilepsy detection models. The Details of these baseline models are given here: ", "page_idx": 13}, {"type": "text", "text": "\u2022 [2]: they propose and investigates a patient-independent seizure detection model that uses stable EEG-based features obtained by comparing multiple feature selection methods. \u2022 [44]: they propose two subject independent deep learning architectures with different learning strategies that can learn a global function utilizing data from multiple subjects. \u2022 [11]: they propose a subject-independent seizure detection model, called IBA (Information Bottleneck Attribution), that utilizes multi-view information. By employing adversarial deep learning, the model learns seizure-specific feature representations directly from raw EEG data. ", "page_idx": 13}, {"type": "text", "text": "Moreover, we offer more details on comparisons to other latest domain generalization methods utilized in this paper: ", "page_idx": 13}, {"type": "text", "text": "\u2022 CDANN [22]: an end-to-end conditional invariant deep DG approach by leveraging deep neural networks for domain-invariant representation learning.   \n\u2022 CORAL [36]: an unsupervised domain adaptation method that aligns the second-order statistics of the source and target distributions with a linear transformation.   \n\u2022 GroupDRO [32]: a model coupling group DRO models with increased regularization, where DRO allows to learn models that instead minimize the worst-case training loss over a set of groups.   \n\u2022 MTL [8]: a representative framework for DG, which augments the original feature space with the marginal distribution of feature vectors.   \n\u2022 SD [29]: a regularization method aimed at decoupling feature learning dynamics, improving accuracy and robustness in cases hindered by gradient starvation.   \n\u2022 SelfReg [18]: a regularization method for DG based on contrastive learning, self-supervised contrastive regularization.   \n\u2022 TRM [40]: a robust estimation criterion that is specifically geared towards optimizing transfer to new environments.   \n\u2022 VREx [19]: a penalty on the variance of training risks as a simpler variant based on a form of robust optimization over a perturbation set of extrapolated domains.   \n\u2022 IB-ERM [4]: a DG method that improve generalization via minimizes the empirical risk over multiple domains.   \n\u2022 IB-IRM [4]: a DG method that improve generalization via minimizes the invariant risk over multiple domains. ", "page_idx": 13}, {"type": "image", "img_path": "mlmTxJwVsb/tmp/d0060e53043e222acfbf7694846c71eb1232652cb39678dcf54161953149fbba.jpg", "img_caption": ["Figure 7: Visualization of difference matrix. "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "B Indepth Visualization of Difference Matrix ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this section, we present visualizations of the difference matrix (DM) constructed in Section 4.2, for providing an in-depth analysis of the DM properties. Initially, the difference matrix is constructed separately for normal and seizure segments of all subjects using the method mentioned in Section 4. Next, we average all difference matrices of normal and seizure segments to obtain the averaged 2-dimensional matrices. These two averaged 2D matrices are shown in the second row of Fig. 7. The green square with dashed line represents the difference between the channel-level reference and target segment $\\v x_{k}^{f}$ . A zoom-in visualization is provided in the first row of the Fig. 7. The left (normal) shows little difference of $\\v x_{k}^{f}$ with most of the channel patterns (small cluster index), but significant difference with a small portion of channel patterns (large cluster index). Conversely, the right one (seizure) exhibits the opposite pattern, validating the effectiveness of channel-level reference. Furthermore, the red square with the dashed line represents the difference within $\\boldsymbol{x}_{k}^{f}$ (only containing contextual reference). The third row of the figure presents a zoom-in visualization, showing a smooth 2-dimensional matrix for normal event and a rough 2-dimensional matrix for seizure event. This demonstrates the effectiveness of introducing contextual reference. ", "page_idx": 14}, {"type": "text", "text": "C Datasets ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "To evaluate the performance of our model, we conduct extensive experiments on the following two datasets. ", "page_idx": 14}, {"type": "text", "text": "Clinical Dataset. The clinical dataset in our study is provided by a first-class hospital, and the intracranial EEG electrode implantation surgery and data collection are approved by the official ethics committee. For each subject, 4 to 10 invasive electrodes with 52 to 126 channels are implanted according to clinical needs to obtain brain signals. The dataset is quite massive due to the high frequency and multiple channels used to record intracranial EEG data, with more than 738 recording hours and 877.3GB total size. Data are labeled by professional neurologists at point level. Moreover, the positive sample (seizure event) ratio of a single subject in our dataset is around 0.003 on average, which is extremely imbalanced. More details can be found in Table 3. ", "page_idx": 14}, {"type": "text", "text": "Public Dataset. The public dataset MAYO and FNUSA [25] used in our paper, is collected from St. Anne\u2019s University Hospital (Brno, Czech Republic). This dataset is composed of intracranial EEG data collected in an awake resting state from 38 diagnosed subjects. Specifically, the dataset comprises a total of 348,300 segments. Each segment spans a duration of 3 seconds and consists of 15,000 data points, with a sampling frequency of $5000\\mathrm{Hz}$ . These segments are labeled into 4 categories, including physiological activity, pathological activity (seizure event), artifacts, and power line noise. We follow the setup in [39] of omitting invalid data from one subject while retaining the data from 30 subjects for analysis. More details can be found in Table 3. ", "page_idx": 15}, {"type": "table", "img_path": "mlmTxJwVsb/tmp/59e64e27df619b3474e3c0edcd2d0945bc9fd90963418a2bf17d43254f7332d1.jpg", "table_caption": ["Table 2: Basic hyperparameters of DMNet. "], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "mlmTxJwVsb/tmp/ddf9a42b732fdac1b5293450c93dd5f5e789e4e07ee847d65ff29299197e285d.jpg", "table_caption": ["Table 3: Details information of the clinical and public dataset. "], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "mlmTxJwVsb/tmp/0d4b9caebc4afcbc4a11a8537b1ba9bc1f66fe959253c132e409623e1d777244.jpg", "table_caption": ["Table 4: Group information of clinical and public datasets. "], "table_footnote": [], "page_idx": 16}, {"type": "table", "img_path": "mlmTxJwVsb/tmp/fe6ab7a8a9d7461a0a96562acf4513e7b5fdfb72bb624d2ed79fcf993c2b5405.jpg", "table_caption": ["Table 5: Detailed information of dataset setup in the experiment. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "D Experimental Setup ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "All experiments were run on a Linux system with 2 CPUs (AMD EPYC 7H12 64-Core Processor) and 4 GPUs (NVIDIA GeForce RTX 3090). ", "page_idx": 16}, {"type": "text", "text": "Setup on Clinical Dataset. To conduct the experiment under domain generalization setting, we divide these subjects in a clinical dataset into 4 groups, each group contains 2 subjects (detailed grouping information is listed in Table 4). For model training and testing, we adopt a $^{\\bullet\\bullet}2\\!-\\!1\\!-\\!1$ setting\u201d for the division of training, validation, and test sets. Specifically, we assign two groups to the training set and one group to the validation set, collectively forming the source domains. Additionally, we assign another group as the target domain for testing. For a comprehensive experiment, we conduct the experiments under 12 different grouping combinations (detailed settings in Table 5). To reduce computational load, we downsample the data to $250\\mathrm{Hz}$ . The length of the patch $\\ell$ is set to 1 second (250 data points). More experimental details, including model and optimization settings, are listed in Table 2. ", "page_idx": 16}, {"type": "text", "text": "Setup on Public Dataset. For the public dataset, we employ the grouping strategy mentioned in [39]. Specifically, we divide these subjects into 6 groups. We adopt a \u201c4-1-1 setting\u201d for model training, validation, and testing, respectively: randomly choose 5 groups (4 testing groups and 1 validation group) as the source domain, while the other one group as the target domain for testing. For the public dataset, we conduct the experiments under 6 different grouping combinations (detailed setups in Table 5). Moreover, because the public dataset is sampled data, there is no complete channel data, so for DMNet with public data, we remove the channel-level reference. More experimental details, including model and optimization settings are listed in Table 2. ", "page_idx": 16}, {"type": "text", "text": "E Full Visualization of Seizure Evolution Process ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "To additional illustrate the effectiveness of our proposed DMNet, we present the visualization results of the difference matrix throughout the entire seizure process in Fig. 8. The upper figure shows the raw iEEG signal that contains a complete seizure process, where the gray wave represents the normal signal and the purple wave represents the seizure. The green masked blocks indicate the segments for detection. Notably, distinctions between seizure and normal matrices are evident during the evolution of the seizure. For segments that are temporally closer to the seizure events, the difference matrices tend to be rougher (e.g., segments c, d, and e) and vice versa (e.g., segments a, b, f, and g). In summary, this case clearly illustrates how the difference matrix captures the seizure activity changes in different frequency bands, and indicates the effectiveness of our proposed method. ", "page_idx": 16}, {"type": "image", "img_path": "mlmTxJwVsb/tmp/130544a60aecb8d47a79549775695d4ca7163a4583227ca4e4b30a99e94f91f0.jpg", "img_caption": ["Figure 8: Illustration of how difference matrices reflect seizure activity changes during seizure evolution process. Purple line refers to seizure waves, gray line refers to normal waves. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "F Generalization Ability Analysis ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "To further evaluate the generalization capability of DMNet across a wider range of subjects with greater heterogeneity, we assessed the model using data from the extensive TUSZ EEG dataset [1] which encompasses numerous subjects. After data preprocessing, we retained data from 179 subjects, dividing them into training, validation, and testing sets in a 6:2:2 ratio, with distinct subjects in each split. Please refer to Tab. 6 for the results of the experiment. The results indicate that DMNet consistently outperforms existing SOTA models, demonstrating its effectiveness in seizure detection on EEG dataset with numerous subjects. ", "page_idx": 17}, {"type": "table", "img_path": "mlmTxJwVsb/tmp/77fdc1fd71a27bcc837e3ecff23a2d4ed566127a75a47152b047c0ae15e98006.jpg", "table_caption": ["Table 6: Performance of DMNet on TUSZ Dataset."], "table_footnote": [], "page_idx": 18}, {"type": "table", "img_path": "mlmTxJwVsb/tmp/9d39698f15d49737a67130679745872350cdbe2accab839de683f0f993d31af9.jpg", "table_caption": ["Table 7: Full average performance with standard deviation of of subject-independent seizure detection tasks on clinical dataset. The v indicates the first in a column and $\\underline{{\\mathbf{V}}}$ indicates the second. "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "G Full Result ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "H Limitations ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "There are two main limitations to my approach. Firstly, it lacks a theoretical foundation, which may call into question the effectiveness and reliability of the method. It becomes challenging to explain and justify the underlying principles behind the approach. Secondly, although the method is efficient, it suffers from a limited number of parameters. This limitation can potentially impact the generalizability of the method. Therefore, while the method may show promising results in specific contexts, caution should be exercised when applying it to broader or unfamiliar situations. ", "page_idx": 18}, {"type": "table", "img_path": "mlmTxJwVsb/tmp/ba4b2fd9b956dd1e08e6b75690b630cd4b2f6b359cd27a2ffb8f1a5ae08c5f88.jpg", "table_caption": ["Table 8: Full average performance with standard deviation of of subject-independent seizure detection tasks on MAYO. The v indicates the first in a column and v indicates the second. "], "table_footnote": [], "page_idx": 19}, {"type": "table", "img_path": "mlmTxJwVsb/tmp/6679b1123e04b142a443d35757e5c7932ff9150ddc1bcc4de2d053dbd4e1c062.jpg", "table_caption": ["Table 9: Average performance with standard deviation of of subject-independent seizure detection tasks on FNUSA. The v indicates the first in a column and v indicates the second. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: In this paper, abstract and introduction accurately reflect the paper\u2019s contributions and scope. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 20}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: The limitations of the work are discussed in Appendix H ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 20}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: The paper does not include theoretical results ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 21}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The private dataset so one may cannot reproduce the experiments on the private dataset. However, we also use another two public datasets, and the code of our work is fully provided too, which could help you understand our work. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 21}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: The private dataset so one may cannot reproduce the experiments on the private dataset. However, we also use another two public datasets, and the code of our work is fully provided too, which could help you understand our work. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 22}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We give a detailed description of our experiment setting in Appendix D. We also do a hyperparameter analysis in the Section 5. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 22}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: The standard derivation is shown in the Appendix G. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 22}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 23}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We provide information about Experiments Compute Resources such as CPU, GPU, etc. in the Appendix D. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 23}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: All authors reviewed and conducted the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 23}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 23}, {"type": "text", "text": "Answer: [No] ", "page_idx": 23}, {"type": "text", "text": "Justification: There is no social impact of the work performed. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 23}, {"type": "text", "text": "\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 24}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [No] ", "page_idx": 24}, {"type": "text", "text": "Justification: This paper poses no such risks. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 24}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: All the existing assets are properly referenced. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: Our code is provided as a supplement. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 25}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 25}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 25}, {"type": "text", "text": "Answer: [No] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}]