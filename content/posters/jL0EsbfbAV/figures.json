[{"figure_path": "jL0EsbfbAV/figures/figures_1_1.jpg", "caption": "Figure 1: Empirical study across multiple brain regions of dorsal cortex neural recordings of a mouse in a visual decision-making task. (A) The Brain Atlas map [Lein et al., 2007]. (B) Neural signals in various brain regions (SSp, MOs, and VIS) exhibit mixed selectivity in behavior of interest decoding. \u201cLevers\u201d, \u201cSpouts\u201d, \u201cPaw-(x)\u201d, and \u201cJaw\u201d are four behaviors of interest. cvR\u00b2 is short for cross-validation coefficient of determination. The higher, the better.", "description": "This figure shows the results of an empirical study on a mouse performing a visual decision-making task. Panel A displays a brain map highlighting three regions of interest: SSp, MOs, and VIS. Panel B presents bar graphs illustrating the mixed selectivity of neural signals in these brain regions for four different behaviors (Levers, Spouts, Paw-(x), and Jaw). The cross-validation coefficient of determination (cvR\u00b2) is used as a metric to quantify how well the neural signals predict each behavior, with higher cvR\u00b2 indicating better prediction accuracy.", "section": "1 Introduction"}, {"figure_path": "jL0EsbfbAV/figures/figures_2_1.jpg", "caption": "Figure 2: Schematic diagram of neural dynamics interpretation with BeNeDiff. We first employ a neural LVM to identify a disentangled neural latent subspace (the left part). Then, we train a linear neural encoder to map behavior video frames to neural trajectories. We use video diffusion models (VDMs) to generate behavior videos guided by the neural encoder, based on the objective of activating the variance of individual latent factors along the single-trial trajectory. This approach provides interpretable quantifications of neural dynamics in relation to the behaviors of interest.", "description": "This figure illustrates the BeNeDiff framework for interpreting neural dynamics.  It shows how a disentangled neural subspace is identified using a latent variable model (LVM). A linear neural encoder maps behavior videos to neural trajectories. Finally, video diffusion models (VDMs) generate behavior videos by activating individual latent factors, enabling interpretable quantification of neural dynamics related to specific behaviors.", "section": "2 Neural Dynamics Interpretation with BeNeDiff"}, {"figure_path": "jL0EsbfbAV/figures/figures_5_1.jpg", "caption": "Figure 3: Widefield Calcium Imaging Dataset. The head-fixed mouse is performing a visual decision-making task, with the behaviors of interest and the trial structure illustrated.", "description": "The figure shows a schematic of the experimental setup and the behavioral data collected.  The top panel shows images from two cameras, side and bottom views, capturing the mouse performing a task.  Colored dots on the images represent different body parts tracked, including the jaw, spout, right paw (x and y coordinates), chest, and lever. The bottom panel displays a timeline of the trial, indicating the timing of events like trial start, lever insertion, stimulus presentation, spout activation, and trial end. This illustrates the types of behavioral data collected along with the neural data for the study.", "section": "5.1 Dataset Description"}, {"figure_path": "jL0EsbfbAV/figures/figures_6_1.jpg", "caption": "Figure 4: Behavior decoding results of the disentangled neural latent variables of the VIS-Right region. We observe that the decoding capability of each latent factor is specified to the corresponding behavior of interest, exhibiting a single-mode shape. In contrast, the original neural signals exhibit mixed selectivity to the behaviors, shown in Figure 1(B). Each experiment condition is repeated 5 times, with the mean represented by the bar plot and the standard deviations shown as error bars.", "description": "This figure presents the behavior decoding results for each disentangled latent variable in the right visual region (VIS-Right) of the mouse brain.  Each bar represents the R-squared (R\u00b2) value, indicating the proportion of variance in each behavior explained by a specific latent factor. The error bars represent standard deviations across five repeated experiments.  The figure demonstrates that each latent factor is highly selective for a single behavior (e.g., one factor mainly explains 'Levers' movement while another explains 'Jaw' movement). This contrasts with the mixed selectivity observed in the original neural signals (Figure 1B), where individual neurons often responded to multiple behaviors.", "section": "5.2 Disentangled Neural Latent Subspace Investigation"}, {"figure_path": "jL0EsbfbAV/figures/figures_7_1.jpg", "caption": "Figure 5: Neural signal reconstruction performance evaluation of the VIS-Right region. We observe that the neural reconstruction quality from the latent subspace of BeNeDiff is maintained given the behavioral labels. \u201cSelf-Supervised\u201d denotes the VAE w/o behavior labels.", "description": "This figure displays the neural signal reconstruction performance of the VIS-Right region using different methods: ground truth, self-supervised learning (no behavioral labels), and BeNeDiff. It shows how well each method reconstructs the neural activity given the behavioral labels. The results demonstrate that BeNeDiff maintains good reconstruction quality even while incorporating behavioral information.", "section": "5.3 Neural Dynamics Exploration of Disentangled Latent Factors"}, {"figure_path": "jL0EsbfbAV/figures/figures_8_1.jpg", "caption": "Figure 6: Generated Single-trial Behavioral Videos with Latent Factor Guidance from the side view. Compared to baseline methods, we observe that the neural dynamics of latent factor in the results of BeNeDiff show specificity to the \u201cJaw\u201d movements.", "description": "This figure compares the results of three different methods for generating single-trial behavioral videos using latent factor guidance: Na\u00efve Latent Manipulation, Classifier-Free Guidance, and BeNeDiff (the authors' proposed method).  The top row shows the generated video frames for each method. The second row displays the inter-frame difference, highlighting the changes in the video frames over time.  The figure demonstrates that BeNeDiff produces videos with neural dynamics that are more specific to the \"Jaw\" movements compared to the other methods.  The inter-frame difference for BeNeDiff shows a more focused and consistent pattern of changes related to the jaw movement than the other two methods.", "section": "5.3 Neural Dynamics Exploration of Disentangled Latent Factors"}, {"figure_path": "jL0EsbfbAV/figures/figures_9_1.jpg", "caption": "Figure 7: Learnt Neural Latent Trajectories of BeNeDiff across various brain regions. It is difficult to clearly visualize the specific motion encoded by each region and to distinguish how different the motions are encoded across brain regions.", "description": "This figure displays the neural latent trajectories generated by the BeNeDiff model across multiple brain regions (VIS, SSp, MOs) in both left and right hemispheres.  The trajectories show the neural activity changes over time for a single trial, focusing on the period around the \"Lever In\" event.  The plot visually represents the latent space dynamics in each brain region and highlights the complexity of neural activity patterns across multiple brain areas during a decision-making task. It emphasizes the challenge of interpreting neural dynamics without a generative method for visualization, as the trajectories alone are difficult to interpret in terms of specific motor behaviors.", "section": "5.4 Neural Dynamics Exploration of Disentangled Latent Factors Across Brain Regions"}, {"figure_path": "jL0EsbfbAV/figures/figures_9_2.jpg", "caption": "Figure 8: Generated video frame differences across the right hemisphere regions. The red dots in the figure indicate paw appearances.", "description": "This figure visualizes the frame differences across three brain regions (VIS-Right, SSp-Right, and MOs-Right) of the right hemisphere when the \"Levers\" are coming into the point. The red dots highlight paw movements.  The inter-frame differences (bottom row of each section) show the changes in the video frames over time, allowing for a more detailed analysis of the temporal dynamics of paw movements across different brain areas. It demonstrates how the model captures the behavioral dynamics of paw movements and reflects it in the generated videos.  The differences are most prominent in the VIS region, highlighting the visual cortex's role in processing paw movement information, followed by the SSp and then the MOs, reflecting a sequential activation across regions.", "section": "5.4 Neural Dynamics Exploration of Disentangled Latent Factors Across Brain Regions"}, {"figure_path": "jL0EsbfbAV/figures/figures_15_1.jpg", "caption": "Figure 9: Generated Single-trial Behavioral Videos with Latent Factor Guidance from the bottom view. Compared to baseline methods, we observe that the neural dynamics of a latent factor in the results of BeNeDiff show specificity to the \u201cPaw-(y)\u201d movements.", "description": "This figure compares the results of three different methods for generating single-trial behavioral videos using latent factor guidance. The three methods are Na\u00efve Latent Manipulation, Classifier-Free Guidance, and BeNeDiff (the proposed method). For each method, the figure shows a series of video frames and their corresponding inter-frame differences. The results demonstrate that BeNeDiff produces more accurate and specific videos compared to the other two methods.", "section": "5.3 Neural Dynamics Exploration of Disentangled Latent Factors"}, {"figure_path": "jL0EsbfbAV/figures/figures_16_1.jpg", "caption": "Figure 6: Generated Single-trial Behavioral Videos with Latent Factor Guidance from the side view. Compared to baseline methods, we observe that the neural dynamics of latent factor in the results of BeNeDiff show specificity to the \u201cJaw\u201d movements.", "description": "This figure compares the results of three different methods for generating single-trial behavioral videos, focusing on the 'Jaw' movements. The methods compared are Na\u00efve Latent Manipulation, Classifier-Free Guidance, and BeNeDiff (the proposed method).  The top row shows the generated video frames for each method. The bottom row shows the inter-frame differences.  BeNeDiff is highlighted as producing more specific and consistent results reflecting 'Jaw' movements, demonstrating better interpretation of neural dynamics.", "section": "5.3 Neural Dynamics Exploration of Disentangled Latent Factors"}, {"figure_path": "jL0EsbfbAV/figures/figures_16_2.jpg", "caption": "Figure 6: Generated Single-trial Behavioral Videos with Latent Factor Guidance from the side view. Compared to baseline methods, we observe that the neural dynamics of latent factor in the results of BeNeDiff show specificity to the \u201cJaw\u201d movements.", "description": "This figure compares the results of three different methods for generating single-trial behavioral videos using latent factor guidance: Na\u00efve Latent Manipulation, Classifier-Free Guidance, and BeNeDiff (the authors' method). The top row shows the generated videos for each method, while the bottom row displays the inter-frame differences. BeNeDiff's results demonstrate a higher specificity to the \"Jaw\" movements compared to the other two methods, as indicated by the clearer and more focused changes in the inter-frame differences.", "section": "5.3 Neural Dynamics Exploration of Disentangled Latent Factors"}, {"figure_path": "jL0EsbfbAV/figures/figures_17_1.jpg", "caption": "Figure 12: Learnt Neural Latent Trajectories of BeNeDiff across various brain regions. It is difficult to clearly visualize the specific motion encoded by each region and to distinguish how different the motions are encoded across brain regions.", "description": "This figure shows the neural latent trajectories generated by BeNeDiff across different brain regions.  The plots illustrate the trajectories in two dimensions (X and Y axis) for left and right hemisphere regions. It highlights the challenge of visually interpreting the specific motion encoded by each brain region and how these motions might differ between regions solely based on the trajectory plots. This motivates the use of video generation to visualize and better understand the neural dynamics.", "section": "Neural Dynamics Exploration of Disentangled Latent Factors Across Brain Regions"}, {"figure_path": "jL0EsbfbAV/figures/figures_17_2.jpg", "caption": "Figure 13: Generated video frame differences across the left hemisphere regions. The red dots in the figure indicate paw appearances.", "description": "This figure shows the generated video frame differences across three brain regions in the left hemisphere (VIS-Left, SSp-Left, and MOs-Left) during a \"Levers Coming In Point\" event.  The video frames are generated using BeNeDiff (the proposed model), highlighting differences in the temporal dynamics of paw movements across the different cortical areas. Red dots indicate the paw appearances in the frames.  The inter-frame differences help to visualize the changes in the behavior video over time more clearly, showcasing the temporal resolution of the model's output.", "section": "5.4 Neural Dynamics Exploration of Disentangled Latent Factors Across Brain Regions"}]