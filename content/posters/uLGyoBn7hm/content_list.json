[{"type": "text", "text": "Disentangled Representation Learning in Non-Markovian Causal Systems ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Adam Li\u2217and Yushu Pan\u2217and Elias Bareinboim ", "page_idx": 0}, {"type": "text", "text": "Causal Artificial Intelligence Lab Columbia University {adam.li, yushupan, eb}@cs.columbia.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Considering various data modalities, such as images, videos, and text, humans perform causal reasoning using high-level causal variables, as opposed to operating at the low, pixel level from which the data comes. In practice, most causal reasoning methods assume that the data is described as granular as the underlying causal generative factors, which is often violated in various AI tasks. This mismatch translates into a lack of guarantees in various tasks such as generative modeling, decision-making, fairness, and generalizability, to cite a few. In this paper, we acknowledge this issue and study the problem of causal disentangled representation learning from a combination of data gathered from various heterogeneous domains and assumptions in the form of a latent causal graph. To the best of our knowledge, the proposed work is the first to consider i) non-Markovian causal settings, where there may be unobserved confounding, ii) arbitrary distributions that arise from multiple domains, and iii) a relaxed version of disentanglement. Specifically, we introduce graphical criteria that allow for disentanglement under various conditions. Building on these results, we develop an algorithm that returns a causal disentanglement map, highlighting which latent variables can be disentangled given the combination of data and assumptions. The theory is corroborated by experiments. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Causality is fundamental throughout various aspects of human cognition, including understanding, planning, decision-making. The ability to perform causal reasoning is considered one of the hallmarks of human intelligence [1\u20133]. In the context of AI, the capability of reasoning with cause-and-effect relationships plays a critical role in challenges of explainability, fairness, decision-making, robustness, and generalizability. One key assumption of most methods currently available in the causal literature is that the set of (endogenous) variables is at the right level of granularity. However, this is not the case in many AI applications, where various modalities, such as images, and text, come into play [4]. For example, images of a park scene capture objects as causal variables, not the pixels themselves. AI must disentangle these latent causal variables to represent the true relationships in the image. Faithfully representing this latent structure impacts downstream AI tasks like image generation and few-shot learning. ", "page_idx": 0}, {"type": "text", "text": "In machine learning, the representation learning literature is concerned with finding useful representations from data [5]. One important line of work traces back to linear ICA (independent component analysis) [6], where one attempts to disentangle latent variables assuming a linear mixing function. The literature has also considered settings where the mixing function is nonlinear [7, 8]. It has been understood that nonlinear-ICA is, in general, not identifiable (ID) given only observational data [9]. ", "page_idx": 0}, {"type": "table", "img_path": "uLGyoBn7hm/tmp/adb401f87c623f29d6592df65864f5cae041e1dde430cf629be625b7b1b46e7e.jpg", "table_caption": ["Table 1: A non-exhaustive list of identifiability results given knowledge of the latent graph. "], "table_footnote": [], "page_idx": 1}, {"type": "text", "text": "Different routes have been taken to circumvent such impossibilities. For instance, one might assume parametric families (e.g., exponential), and auxiliary variables as input, which can be thought of as non-stationary times-series that may lead to certain invariances that can be exploited [7, 8, 10]. ", "page_idx": 1}, {"type": "text", "text": "Interestingly, the machinery developed in this context can be applied to causal settings with multimodal data, where there is a mismatch between the causal variables and the granularity at which they are represented in the data. The key observation that links these two worlds is that an underlying causal system generates the data at such granularity (images, texts). Acknowledging this connection leads to various possibilities regarding learning, or disentangling the causal variables from data, similar to the initial ICA-like literature. First, the assumption that the features underlying a signal are independent needs to be relaxed since it is arguably too stringent, a priori ruling out almost any interesting causal system. So, we should consider different assumptions regarding the structure of the underlying generative model. One initial relaxation is that this model is Markovian, where the features need not be independent, and causal relationships are allowed across features. In the context of computer vision, for example, one might assume a specific structure on the latent variables where the style and content of the images are separated and augmented data is leveraged to disentangle these two components [18]. Generalizing this idea to more relaxed causal settings, one can show ID up to certain indeterminancies given observational across multiple domains, or interventional data [21, 22]. Another approach allows for certain parametric mixing functions, which could lead to new ID results [11, 14]. These results have been applied and advanced across various downstream tasks [25\u201331]. ", "page_idx": 1}, {"type": "image", "img_path": "uLGyoBn7hm/tmp/ac20dfd2d44b5aa5f82a0ca7e96df4f688b5c41d4bfcafd5f014f56a8007466e.jpg", "img_caption": ["Figure 1: Dimensions of identifiability in causal disentanglement representation learning. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Considering this background, we study three axes within the different types of input and expected outputs of the causal disentanglement representation learning task, which is summarized in Table 1 and Fig. 1. The input can be partitioned into qualitative and quantitative components. Qualitatively, we consider different assumptions about the underlying generative processes, including non-parametric models, as well as linear or Gaussian ones. We also account for systems with richer causal topologies than ICA (independent features) and generalize the Markovian setting. Notably, we do not rule out a priori the existence of unobserved confounding among features, a pervasive challenge in causal inference in empirical sciences. Quantitatively, we consider data gathered from arbitrary combinations of interventions and domains. Recent literature on this distinction acknowledges key differences [32\u201337], whereas prior literature often assumes data comes from different interventions in the same domain or from various (observational) distributions from different domains. In fact, it is feasible that data spawns various interventions and domains in a less well-structured manner (App. A.3). In terms of the expected output, similar to [24], we will consider both full disentanglements as well as a more relaxed type of disentanglement, known as the causal disentanglement map. ", "page_idx": 1}, {"type": "text", "text": "For concreteness, consider a hypothetical latent graph depicted in Fig. 2 in the context of epilepsy research [38\u201346]. In terms of assumptions, hospitals in different countries $\\Pi^{i}$ and $\\Pi^{j}$ will differ in the amount of sleep $(V_{1})$ patients get (represented by the S-node $S^{i,j}\\rightarrow V_{1}$ ). Now suppose sleep $(V_{1})$ affects the efficacy of the drug treatment $(V_{2})$ , and the drug helps epilepsy patients control their seizures $\\left(V_{3}\\right)$ . The quality of sleep and the type of drug treatment are confounded by socioeconomic factors $(V_{1}\\ \\kleftarrow\\mathrm{--}\\ \\kleftarrow V_{2})$ . Clinicians are then given electroencephalogram (EEG) data from each hospital where they know different drug treatments were administered. The EEG $\\mathbf{X}$ is a nonlinear (nonparametric) transformation of latent $\\mathbf{V}=\\{V_{1},V_{2},V_{3}\\}$ via $f_{X}$ . Their goal is to generate realistic EEG data to understand how different drugs affect EEG patterns. This requires a general output representation that disentangles sleep from drug as it is understood that sleep affects EEG [47]. One could leverage state-of-the-art generative modeling techniques and train a self-supervised learning model to learn a representation of the EEG that they then perturb to generate new instances of EEG [48\u201350]. However, there are no guarantees that the representation, or interventions in the latent space will generate realistic EEG. In this case, drug and sleep might remain entangled in the learned representation, which is potentially harmful, since it may lead to unrealistic EEG data that contains visual differences due to sleep rather than drug. More formally, given an input set of distributions and knowledge of the latent variable causal structure, the goal is to learn the inverse of the mixing function ${\\widehat{f}}_{X}^{-1}$ and a representation $\\widehat{\\mathbf{V}}=\\{\\widehat{V_{1}},\\widehat{V_{2}},\\widehat{V_{3}}\\}$ , where $V_{2}$ is disentangled from $V_{1}$ 2. ", "page_idx": 1}, {"type": "image", "img_path": "uLGyoBn7hm/tmp/f9631fb3b97f428c356fd7481a9835dfad451800f8fb6aecb69b159d0e46fe0d.jpg", "img_caption": ["Figure 2: Data generating model and the goal of learning disentangled causal latent representations. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "In this paper, we develop graphical and algorithmic machinery to determine whether (and how) causal representations can be disentangled from heterogeneous data and assumptions about the underlying causal system, which might help improve various downstream tasks. Our contributions are: 3: ", "page_idx": 2}, {"type": "text", "text": "1. Graphical criteria for determining the disentangleability of causal factors. We formalize a general version of the causal representation learning problem and develop methods to determine if a pair of (user-chosen) variables are disentangled in a non-Markovian setting with arbitrary distributions from multiple heterogeneous domains (Props. 3,4, and 5)4. 2. An algorithm to learn the causal disentanglement map. Leveraging these new conditions, we develop an algorithmic called CRID, which systematically determines whether two sets of latent variables are disentangleable given their selection diagram and a collection of intervention targets (Thm. 1). The theoretical findings are corroborated with simulations. ", "page_idx": 2}, {"type": "text", "text": "All supplementary material (including proofs) is provided in the full technical report. ", "page_idx": 2}, {"type": "text", "text": "Preliminaries. We introduce basic definitions used throughout the paper. Uppercase letters $(X)$ represent random variables, lowercase letters $(x)$ signify assignments, and bold letters $({\\mathbf X})$ indicate sets. For a set $\\mathbf{X}$ , $|\\mathbf{X}|$ denotes its dimension. Denote $P(\\mathbf{X})$ as a probability distribution over $\\mathbf{X}$ and $p(\\mathbf{x})$ as its density function. The basic semantic framework of our analysis rests on structural causal models (SCMs) [1, Ch. 7]. An SCM is a 4-tuple $\\langle\\mathbf{U},\\mathbf{V},\\mathcal{F},P(\\mathbf{U})\\rangle$ , where (1) U is a set of background variables, also called exogenous variables, that are determined by factors outside the model; (2) $\\mathbf{V}=\\{V_{1},V_{2},\\ldots,V_{d}\\}$ is the set of endogenous variables that are determined by other variables in the model; (3) $\\mathcal{F}$ is the set of functions $\\left\\{{\\bar{f}}_{V_{1}},f_{V_{2}}\\ldots,f_{V_{d}}\\right\\}$ mapping $\\mathbf{U}_{V_{j}}\\cup\\mathbf{Pa}_{V_{j}}$ to $V_{j}$ , where ${\\mathbf{U}}_{V_{j}}\\subseteq{\\mathbf{U}}$ and $\\mathbf{Pa}_{V_{j}}\\subseteq\\mathbf{V}\\backslash V_{j}$ ; (4) $P({\\bf U})$ is a probability function over the domain of $\\mathbf{U}$ . ", "page_idx": 2}, {"type": "text", "text": "Each SCM induces a causal diagram $G$ , which is a directed acyclic graph where every $V_{j}$ is a vertex. There is a directed arrow from $V_{j}$ to $V_{k}$ if $V_{j}\\,\\in\\,{\\bf P a}_{V_{k}}$ . There is a bidirected arrow between $V_{j}$ and $V_{k}$ if $\\mathbf{{U}}_{V_{j}}$ and ${\\bf U}_{V_{k}}$ are not independent [3]. Variables $\\mathbf{V}$ can be partitioned into subsets called $c$ -components [57]. The c-component of $X$ , denoted as $\\mathbf{C}(X)$ , is a set of variables connected to $X$ by bidirected paths. The c-component of a set $\\mathbf{X}$ , denoted as $\\mathbf{C}(\\mathbf{X})$ , is defined as the union of the c-component of every $X\\in\\mathbf{X}$ . We will use $\\mathbf{Pa}(X)$ or $\\mathbf{Pa}_{X}$ to denote parents of $X$ in $G$ . Let ${\\overline{{\\mathbf{Pa}}}}(X)=\\mathbf{Pa}(X)\\cup X$ , which includes $X$ itself. A subgraph over $\\mathbf{X}\\subseteq\\mathbf{V}$ in $G$ is denoted as $G(\\mathbf{X})$ and $G_{\\overline{{\\mathbf{X}}}}$ denotes the subgraph by removing arrows coming into nodes in $\\mathbf{X}$ . ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "A soft intervention on a variable $X$ , denoted $\\sigma_{X}$ , replaces $f_{X}$ with a new function $f_{X}^{\\prime}$ of $\\mathbf{Pa^{\\prime}}\\subset\\mathbf{V}$ and variables $\\mathbf{U}_{X}^{\\prime}$ [58, 59]. For interventions on a set of variables $\\mathbf{X}\\subseteq\\mathbf{V}$ , let $\\sigma_{\\mathbf{X}}=\\{\\sigma_{\\mathbf{X}}\\}_{X\\in\\mathbf{X}}$ , that is, the result of applying one intervention after the other. Given an SCM $\\mathcal{M}$ , let $\\mathcal{M}_{\\sigma\\mathbf{x}}$ be a submodel of $\\mathcal{M}$ induced by intervention $\\mathcal{M}_{\\sigma\\mathbf{x}}$ . A special class of soft interventions, resulting in observational distributions, called idle intervention, leaves the function as it is, which means $\\sigma_{\\mathbf{X}}=\\{\\}$ . Another special class of stochastic soft interventions, called perfect interventions [21, 51] and denoted as $\\operatorname{perf}(\\mathbf{X})$ , such that $\\mathbf{Pa}(\\mathbf{X})=\\emptyset$ and $\\mathbf{U}_{X}^{\\prime}\\cap\\mathbf{U}=\\emptyset$ . This implies that the modified diagram induced by $\\mathcal{M}_{\\sigma\\mathbf{x}}$ is $G_{\\mathbf{\\overline{{X}}}}$ . We assume soft interventions that are not hard do not change the structure of the graph 5. Namely, the diagram induced by $\\mathcal{M}_{\\sigma\\mathbf{x}}$ is the same with $G$ . ", "page_idx": 3}, {"type": "text", "text": "2 Modeling Disentangled Representation Learning (General Case) ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we formalize the disentangled representation learning task in causal language. We leverage an Augmented SCMs, to model the generative process over latent causal variables $\\mathbf{V}$ . ", "page_idx": 3}, {"type": "text", "text": "Definition 2.1 (Augmented Structure Causal Model). An Augmented Structure Causal Model (for short, ASCM) over a generative level SCM $\\mathcal{M}_{0}\\;=\\;\\left\\langle\\{\\mathbf{U}_{0},\\mathbf{\\bar{V}}_{0},\\mathcal{F}_{0},P^{0}(\\mathbf{U}_{0})\\}\\right\\rangle$ is a tuple $\\mathcal{M}\\,=$ $\\langle\\mathbf{U},\\{\\mathbf{V},\\mathbf{X}\\},\\mathcal{F},P(\\mathbf{U})\\rangle$ such that (1) exogenous variables $\\mathbf{U}=\\mathbf{U}_{0}$ ; (2) $\\mathbf{V}=\\mathbf{\\ddot{V}}_{0}=\\left\\{V_{1},\\ldots,V_{d}\\right\\}$ are $d$ latent endogenous variables; $\\mathbf{X}$ is an $m$ dimensional mixture variable; (3) ${\\mathcal F}=\\{{\\mathcal F}_{0},f_{\\mathbf{X}}\\}$ , where $f_{\\mathbf{X}}:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{m}$ is a diffeomorphic 6 function that maps from (the respective domains of) $\\mathbf{V}$ to $\\mathbf{X}$ . \u2203 $h=f_{\\mathbf{X}}^{-1}$ such that $\\mathbf{V}=h(\\mathbf{X})$ ; and (4) $P(\\mathbf{U}_{0})=P^{0}(\\mathbf{U}_{0})$ . \u53e3 ", "page_idx": 3}, {"type": "text", "text": "In words, an ASCM $\\mathcal{M}$ describes a two-stage generative process involving latent generative factors $\\mathbf{V}$ and high-dimensional mixture $\\mathbf{X}$ (e.g., images, or text). First, latent generative factors $\\mathbf{V}\\in\\mathbb{R}^{d}$ are generated by an underlying SCM. The causal diagram induced by $\\mathcal{M}_{\\mathrm{0}}$ over $\\mathbf{V}$ is called $a$ latent causal graph (LCG); denoted as $G$ here. Next, a nonparametric diffeomorphism $f_{\\mathbf{X}}$ mixes $\\mathbf{V}$ to get the high-dimensional mixture $\\mathbf{X}\\in\\mathbb{R}^{m}$ . An important aspect of $f_{\\mathbf{X}}$ is that it is invertible regarding $\\mathbf{V}$ which implies that the generative factors $\\mathbf{V}$ are recognized in a given $\\mathbf{X}=\\mathbf{x_{\\alpha}}^{7}$ . ", "page_idx": 3}, {"type": "text", "text": "The initial disentangled representation learning setting can be traced back at least to linear/nonlinear ICA [7\u20139], where $G$ is assumed to have no edges $\\mathbf{V}$ are independent of each other) and Markovian (no bidirected edges in the LCG). More recently, allowing latent variables to have edges in the LCG was studied, albeit still under the Markovian assumption [11, 13, 14, 21, 22, 51, 55]. We relax this assumption and allow confounding to exist between $\\mathbf{V}$ , which we call non-Markovianity8. ", "page_idx": 3}, {"type": "text", "text": "Domains. We address the general setting of distributions that arise from multiple domains. Following [32\u201335, 62, 63], we define the so-called latent selection diagram that represents a collection of ASCMs to model the multi-domain setting. Selection diagrams enable us to compactly represent causal structure and cross-domain invariances 9. ", "page_idx": 3}, {"type": "text", "text": "Definition 2.2 (Latent Selection Diagrams). Let $\\pmb{\\mathcal{M}}\\,=\\,\\langle\\mathcal{M}_{1},\\mathcal{M}_{2},...,\\mathcal{M}_{N}\\rangle$ be a collection of ASCMs relative to $N$ domains $\\Pi=\\left\\langle\\Pi_{1},\\Pi_{2},...,\\Pi_{N}\\right\\rangle$ , sharing mixing function $f_{\\mathbf{X}}$ and LCG, $G.\\ M$ defines a latent selection diagram (LSD. for short) $G^{S}$ , constructed as follows: (1) every edge in $G$ is also an edge in $G^{S}$ ; (2) $\\mathit{\\check{G}}^{S}$ contains an extra node $S^{i,j}$ and corresponding edge $S^{\\bar{i},j}\\ {\\bar{\\rightarrow}}\\ V_{k}$ whenever there exists a discrepancy $f_{V_{k}}^{i}\\neq f_{V_{k}}^{j}$ , or $P^{i}(U_{k})\\neq P^{j}(U_{k})$ between $\\mathcal{M}_{i}$ and $\\mathcal{M}_{j}$ \uff1a\u53e3 ", "page_idx": 3}, {"type": "text", "text": "S-nodes indicate possible differences over $\\mathbf{V}$ due to changes in the underlying mechanism or exogenous distributions across domains. For example, consider the LSD in Fig. 2. The S-node $S^{i,j}$ implies that $V_{1}$ possibly changes from domain $\\Pi^{i}$ to $\\Pi^{j}$ , while the other variable\u2019s mechanisms are assumed to be invariant. Note no S-node points to $\\mathbf{X}$ since $f_{\\mathbf{X}}$ is shared across $\\mathbf{\\mathcal{M}}$ . ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Interventions. A set of interventions $\\Sigma~=~\\{\\sigma^{(k)}\\}_{k=1}^{K}$ are applied across domains $\\mathbf{\\delta}\\pi$ , where $k$ is an index from 1 to $K$ . The corresponding domains that $\\Sigma$ are intervened in is denoted as $\\Pi^{\\Sigma}=\\{\\Pi^{(k)}\\}_{k=1}^{K}$ (the domains associated with each $\\sigma^{(k)}\\in\\Sigma_{.}^{\\cdot}$ ). We study a general setting where each intervention can be applied to any subset of nodes and in any domain, which can be seen as a generalization of the more restricted settings in prior work (see Appendix F). ", "page_idx": 4}, {"type": "text", "text": "The intervention targets collection of these $K$ interventions $\\{\\sigma^{(k)}\\}_{k=1}^{K}$ is denoted as $\\Psi=\\{\\mathbf{I}^{(k)}\\}_{k=1}^{K}$ . Each intervention target $\\mathbf{I}^{(k)}$ is given in the form of $\\{V_{i}^{\\Pi^{(k)},\\{b\\},t},V_{j}^{\\Pi^{(k)},\\{b^{\\prime}\\},t^{\\prime}},\\cdot\\cdot\\cdot\\}$ , which indicates the intervention $\\sigma^{(k)}$ changes the mechanism of $\\{V_{i},V_{j},\\ldots\\}$ in domain $\\Pi^{(k)}$ . $\\{b\\}$ indicates the mechanism of the intervention on the same node. The mechanisms of $V_{i}^{1}$ and $V_{i}^{2}$ are different while the mechanism on different nodes ( $\\mathbf{}V_{i}^{1}$ and $V_{j}^{1}$ ) is default different. $t=\\mathrm{perf}$ indicates the intervention is perfect. When I(k) = {V i\u03a0 ,t , where $\\{b\\}$ is omitted, then the intervention is assumed to have a different mechanism. When $\\mathbf{I}^{(k)}=\\{V_{i}^{\\Pi^{(k)},\\{b\\}}\\}$ V i\u03a0(k),{b}}, where t is omitted, then the intervention is assumed to be a general soft intervention. When I(k) is an idle intervention in \u03a0(n), it is denoted as {}\u03a0(n). The set $\\operatorname{Perf}[\\mathbf{I}^{(k)}]$ is a set of variables with perfect interventions in $\\sigma^{(k)}$ . Thus when $\\mathrm{Perf}[{\\bf{I}}^{(k)}]=\\{\\}$ , it implies there are no variables with perfect interventions in $\\sigma^{(k)}$ . $\\Psi_{\\mathrm{{T}}}^{\\mathrm{{perf}}}$ is a subset of $\\Psi$ such that $\\mathbf{T}\\subseteq\\operatorname{Perf}[\\mathbf{I}^{(j)}]$ for every $\\mathbf{I}^{(j)}\\in\\Psi_{\\mathbf{T}}^{\\mathrm{perf}}$ , which implies $\\mathbf{I}^{(j)}$ contains perfect interventions on $\\mathbf{T}$ ; see Fig. S1 and Ex. 7 illustrating the notation. ", "page_idx": 4}, {"type": "text", "text": "Given Distributions. The interventions $\\Sigma=\\{\\sigma^{(k)}\\}_{k=1}^{K}$ , induce distributions $\\mathcal{P}=\\{P^{(k)}\\}_{k=1}^{K}$ }k=1 in multi-domains, where $P^{(k)}=P^{\\Pi^{(k)}}(\\mathbf{X};\\sigma^{(k)})$ . ", "page_idx": 4}, {"type": "text", "text": "Problem Statement Suppose the underlying true model $\\mathbf{\\mathcal{M}}$ induces the LSD $G^{S}$ and a collection of distributions $\\mathcal{P}$ over $\\mathbf{X}$ is given according to a corresponding collection of interventions $\\Sigma$ . The goal of this paper is to learn a disentangled representation $\\widehat{\\mathbf{V}}$ of the latent generative factors $\\mathbf{V}$ in $\\mathbf{\\mathcal{M}}$ . In the literatur e, it is common to require every variable $V_{i}\\in\\mathbf{V}$ to be disentangled from all other variables [7, 21] or some special subset (e.g. non-ancestors of $V_{i}$ ) [21, 22]. However, as illustrated in Fig. 2, sometimes only the target variables $\\mathbf{\\cal{V}}^{t a r}\\subseteq\\mathbf{\\cal{V}})$ is needed to be disentangled from some user-chosen entangled variables $({\\bf V}^{e n})$ ", "page_idx": 4}, {"type": "image", "img_path": "uLGyoBn7hm/tmp/2361010d7abb1f4d343dcdea1478c838ddd9a91ad4d1fae2d124c155149a38e3.jpg", "img_caption": [], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": ". Figure 3: General ID/disentangleability. Recent work has also considered a similar goal of general", "page_idx": 4}, {"type": "text", "text": "ized disentanglement [24]. Our work still differs from theirs in the following ways: i) [assumptions] we model a completely nonparametric non-Markovian ASCM, whereas [24] assumes sparsity and a Markovian ASCM, and ii) [input] we consider arbitrary combinations of distributions from multiple domains, whereas [24] considers only interventions within a single domain (see Appendix F for a detailed comparison). We formally define this type of general indeterminacy next as well as the formal version of our ID task. ", "page_idx": 4}, {"type": "text", "text": "Definition 2.3 (General Identifiability/Disentangleability (ID)). Let $\\mathbf{\\mathcal{M}}$ be the underlying true ASCMs inducing LSD $G^{S}$ , and $\\mathcal{P}=\\dot{\\{}P^{(k)}\\}_{k=1}^{K}$ a set of distributions resulting from $K$ intervention sets $\\Sigma$ . Consider target variables $\\mathbf{V}^{t a r}\\,\\in\\,\\mathbf{V}$ , and ${\\bf V}^{e n}\\,\\subseteq\\,{\\bf V}\\backslash{\\bf V}^{t a r}$ . The set ${\\bf V}^{t a r}$ is identifiable (disentangled) with respect to (from) ${\\bf V}^{e n}$ if there exists a function $\\tau$ such that $\\widehat{{\\bf V}}^{t a r}=\\tau({\\bf V}\\backslash{\\bf V}^{e n})$ for any $\\widehat{\\pmb{M}}$ that is compatible with $G^{S}$ and $\\mathcal{P}^{\\widehat{\\mathcal{M}}}=\\mathcal{P}$ . For short, ${\\bf V}^{t a r}$ is said to be ID w.r.t. ${\\bf V}^{e n}$ . ", "page_idx": 4}, {"type": "text", "text": "To illustrate, consider a target variable ${\\bf V}^{t a r}$ such that one wants its representation to be disentangled from another subset variables ${\\bf V}^{e n}$ . The above definition states that $\\bar{\\mathbf{V}}^{t a r}$ is disentangled from ${\\bf V}^{e n}$ (or is $\\mathrm{ID}$ w.r.t. ${\\bf V}^{e n}$ ) if the learned representations $\\widehat{\\mathbf{V}}^{t a r}$ in $\\widehat{\\pmb{M}}$ is only a function of $\\mathbf{V}\\backslash\\mathbf{V}^{e n}$ for any $\\widehat{\\pmb{M}}$ that matches with the LSD $G^{S}$ and distribution $\\mathcal{P}^{10}$ . Def 2.3 is illustrated in Fig. 3. Following the example illustrated in Fig. 2, suppose the user wants $V_{3}$ to be disentangled from $V_{1}$ while considering the entanglement between $V_{2}$ and $V_{3}$ acceptable. If ${\\widehat{V}}^{3}=\\tau(V^{2},V^{3})$ for any ASCM $\\widehat{\\pmb{M}}$ matches the distributions and LSD, $V_{3}$ is $\\mathrm{ID}$ w.r.t. $V_{1}$ . Def. 2.3 is more relaxed since one is free to choose any target ${\\bf V}^{t a r}$ and ${\\bf V}^{e n}$ . It can be reduced to existing identifiability definitions (Appendix F.2). ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Example 1 (Example of an ID task). Suppose the pair of underlying ASCMs $\\langle\\mathcal{M}_{1},\\mathcal{M}_{2}\\rangle$ induces the LSG $G^{S}$ in Fig. 2 and distributions $\\begin{array}{r l r}{\\mathcal{P}}&{{}=}&{\\{P^{(1)},P^{(2)},P^{(3)},P^{(4)}\\}\\;\\;=}\\end{array}$ $\\{P^{\\Pi_{1}}({\\bf X}),P^{\\Pi_{2}}({\\bf X}),P^{\\Pi_{2}}({\\bf X};\\sigma_{V_{3}}),P^{\\Pi_{1}}({\\bf X};\\sigma_{V_{4}})\\}$ from interventions $\\Sigma=\\{\\sigma^{(1)},\\sigma^{(2)},\\sigma^{(3)},\\sigma^{(4)}\\}=$ $\\{\\{\\},\\{\\},\\sigma_{V_{3}},\\mathrm{perf}(V_{2})\\}$ . Given intervention targets $\\Psi\\;=\\;\\{{\\bf I}^{(1)},{\\bf I}^{(2)},{\\bf I}^{(3)},{\\bf I}^{(4)}\\}\\;=\\;\\{\\{\\}^{\\Pi_{1}},\\{\\}^{\\Pi_{2}}$ , $V_{3}^{\\Pi_{2}},V_{2}^{\\Pi_{1},\\mathrm{perf}}\\}$ and $G^{S}$ , the task is to determine whether (and how) $\\{V_{2},V_{3}\\}$ is $I D\\ w.r t.\\ V_{1}$ , and $V_{1}$ is ID w.r.t $\\{V_{2},V_{3}\\}$ . The answer to this is provided in Ex. 6. \u53e3 ", "page_idx": 5}, {"type": "text", "text": "Assumptions (Informal) and Modeling Concepts Before discussing the main theoretical contributions, we restate important assumptions and remarks (discussed in this section) here to ground the ASCM model 11. ", "page_idx": 5}, {"type": "text", "text": "Assumption 1 (Soft interventions without altering the causal structure). Interventions do not change the causal diagram. Hard interventions cut all incoming parent edges, and soft interventions preserve them [59]. However, more general interventions may arbitrarily change the parent set for any given node [59]. We do not consider such interventions and leave this general case for future work. ", "page_idx": 5}, {"type": "text", "text": "Assumption 2 (Known-target interventions). All interventions occur with known targets, reducing permutation indeterminacy for intervened variables. ", "page_idx": 5}, {"type": "text", "text": "Assumption 3 (Sufficiently different distributions). Each pair of distributions $P^{(j)}$ and $P^{(k)}\\in\\mathcal{P}$ are sufficiently different, unless stated otherwise. This is naturally satisfied if ASCMs and interventions are randomly chosen [51]. Similar assumptions include the \"genericity\" [51], \"interventional discrepancy\" [21], and \"sufficient changes\" assumptions [10, 22]. ", "page_idx": 5}, {"type": "text", "text": "Remark 1 (Mixing is invertible). As a consequence of Def. 2.1, the mixing function $f_{\\mathbf{X}}$ is invertible, ensuring that latent variables are uniquely learnable [9, 10, 17, 64]. ", "page_idx": 5}, {"type": "text", "text": "Remark 2 (Confounders are not part of the mixing function). According to Def. 2.1, latent exogenous variables U influence the high-dimensional mixture X only through latent causal variables $\\mathbf{V}$ , so unobserved confounding U does not directly affect the mixing function. ", "page_idx": 5}, {"type": "text", "text": "Remark 3 (Shared causal structure). As a consequence of Def. 2.2, each environment\u2019s ASCM shares the same latent causal graph, with no structural changes among latent variables 12. ", "page_idx": 5}, {"type": "text", "text": "3 Graphical Criterion for Causal Disentanglement ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we study a general form of identifiability given general assumptions and input distributions. More specifically, we build the connection from $\\mathbf{V}$ and representation $\\widehat{\\mathbf{V}}$ through comparing distributions and then introduce three graphical criteria (Prop. 3, 4 and 5) to check ID. ", "page_idx": 5}, {"type": "text", "text": "First, we introduce a factorization of distributions induced by non-Markovian models [3, Def. 15]. Specifically, consider $P_{\\mathbf{T}}(\\mathbf{V})$ induced by an ASCM $\\mathcal{M}$ after a perfect intervention on $\\mathbf{T}$ . Then, given a topological order $<$ of $G$ , $P_{\\mathbf{T}}(\\mathbf{V})$ can be factorized as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\nP_{\\mathbf{T}}(\\mathbf{V})=\\prod_{V_{i}\\in\\mathbf{V}}{P_{\\mathbf{T}}(V_{i}|\\mathbf{P}\\mathbf{a}_{i}^{\\mathbf{T}+})}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\mathbf{P}\\mathbf{a}_{i}^{\\mathrm{T}+}=\\overline{{\\mathbf{P}\\mathbf{a}}}(\\{V\\in\\mathbf{C}(V_{i}):V\\le V_{i}\\})\\setminus\\{V_{i}\\}$ is the extended parents set of $V_{i}$ in $G_{\\overline{{\\mathbf{T}}}}$ . The factorization form for $P_{\\mathbf{T}}(\\mathbf{V})$ will be different according to the choice given order. ", "page_idx": 5}, {"type": "text", "text": "Example 2. Consider a collection of $\\mathbf{\\mathcal{M}}$ inducing the LSD shown in Fig. $4(c)$ . Given order $A$ : $V_{1}\\,<\\,V_{2}\\,<\\,V_{3}\\,<\\,V_{4}$ , $P({\\bf V})$ can be factorized as: $P(V_{1})P(V_{2}\\mid V_{1})P(\\bar{V}_{3}\\mid V_{2},V_{1})P(V_{4}\\mid V_{3})$ Notice that the conditioning part of $V_{3}$ includes $\\{V_{2},V_{1}\\}$ , which are not parents of $V_{3}$ . Choosing order $B$ : $V_{1}<V_{3}<V_{2}<V_{4}$ , $P({\\bf V})$ can be factorized as $P(V_{1})P(V_{3})P(V_{2}\\mid V_{1},V_{3})P(V_{4}\\mid V_{3})$ . The conditioning part of $V_{2}$ and $V_{3}$ are different given different orders. \u53e3 ", "page_idx": 5}, {"type": "image", "img_path": "uLGyoBn7hm/tmp/8fdcfc13f8405885ab8d4b82eb3dd329e9f019d9642361892467728493b0e10d.jpg", "img_caption": ["Figure 4: LSDs in Ex. and Exps. (a) chain, (b) collider and (c) non-markovian graphs. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Armed with this factorization, the representation $\\widehat V$ in $\\widehat{\\pmb{M}}$ and the true underlying variables $\\mathbf{V}$ in $\\mathbf{\\mathcal{M}}$ can be related by comparing distributions as follows. ", "page_idx": 6}, {"type": "text", "text": "Proposition 1 (Distribution Comparison). Consider a pair of collections ASCMs $\\mathbf{\\mathcal{M}}$ andM that matches with the distribution $\\mathcal{P}$ resulting from interventions $\\Sigma$ and $L S D\\;G^{S}$ . Consider  two distributions $P^{\\Pi^{(j)}}(\\mathbf{X};\\sigma^{(j)})$ and $P^{\\Pi^{(k)}}(\\mathbf{X};\\sigma^{(k)})$ . Suppose perf $\\mathbf{\\rho}(\\mathbf{T})$ is in both intervention sets, then, ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\sum_{i}^{d}\\log p_{\\mathbf{T}}^{(j)}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})-p_{\\mathbf{T}}^{(k)}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})=\\sum_{i}^{d}\\log p_{\\mathbf{T}}^{(j)}(\\widehat{v}_{i}\\mid\\widehat{\\mathbf{pa}}_{i}^{\\mathbf{T}+})-\\log p_{\\mathbf{T}}^{(k)}(\\widehat{v}_{i}\\mid\\widehat{\\mathbf{pa}}_{i}^{\\mathbf{T}+}),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $p_{\\mathbf{T}}^{(j)}(\\cdot)$ and $p_{\\mathbf{T}}^{(k)}(\\cdot)$ are density functions. ", "page_idx": 6}, {"type": "text", "text": "To illustrate, Prop.1 shows when the intervention and domain changes from $\\sigma^{(k)}$ to $\\sigma^{(j)}$ and $\\Pi^{(k)}$ to $\\Pi^{(j)}$ , the change comes from factors $p_{\\mathbf{T}}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})$ both in $\\mathbf{\\mathcal{M}}$ and $\\widehat{\\pmb{M}}$ . ", "page_idx": 6}, {"type": "text", "text": "However, not all factors necessarily contribute to Eq (2). For example, in the Markovian setting, only one factor $p_{\\mathbf{T}}(v_{i}\\mid\\,\\mathbf{pa}_{i})$ possibly changes when comparing the observational to a singleton interventional distribution in the same domain. Other invariant factors will be canceled out in Eq. (2). The following result generalizes finding invariant factors when comparing distributions from different domains and interventions in non-Markovian settings. ", "page_idx": 6}, {"type": "text", "text": "Proposition 2 (Invariant Factors). Consider two distributions $P^{(j)},P^{(k)}\\in\\mathcal P$ with intervention targets $\\sigma^{(j)}$ and $\\sigma^{(k)}$ containing perf $\\mathbf{\\rho}(\\mathbf{T})$ . Construct the changed variable set $\\Delta\\mathbf{V}[\\mathbf{I}^{(j)},\\mathbf{I}^{(k)},G^{S}]$ (for short $\\Delta{\\bf V}_{\\perp}$ ) with target sets ${\\bf\\cal I}^{(j)},{\\bf\\cal I}^{(k)}$ as follows: $(I)\\,V_{l}\\in\\Delta{\\bf V}\\,i f V_{l}^{\\pi_{l},\\{b_{l}\\},t_{l}}\\in{\\bf I}^{(j)}$ but $V_{l}^{\\pi_{l}^{\\prime},\\{b_{l}\\},t_{l}^{\\prime}}\\notin$ $\\mathbf{I}^{(k)}$ , or vice versa; (2) $V_{l}\\,\\in\\,\\Delta\\mathbf{V}$ if i) $S^{\\Pi^{(j)},\\Pi^{(k)}}$ point to $V_{l}$ and ii) $V_{l}^{\\pi_{l},\\{b_{l}\\},t_{l}}\\,\\notin\\,{\\bf I}^{(j)}\\cup{\\bf I}^{(k)}$ . If $V_{i}\\in\\mathbf{V}\\backslash\\mathbf{C}(\\Delta\\mathbf{V})$ , then $p_{\\mathbf{T}}^{(j)}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})=p_{\\mathbf{T}}^{(k)}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})$ (denoted invariant factors). \u53e3 ", "page_idx": 6}, {"type": "text", "text": "Prop. 2 states that factors $p\\mathbf{_{T}}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})$ are guaranteed to be invariant if $V_{i}$ is not in the C-component of the changed variable set $\\Delta{\\bf V}$ . $\\Delta\\dot{\\mathbf{V}}[\\mathbf{I}^{(j)},\\mathbf{I}^{(k)},G^{S}]$ contains variables that are intervened differently in $\\mathbf{I}^{(j)},\\mathbf{I}^{(k)}$ and the variables pointed by S-node, $S^{j,k}$ 13. ", "page_idx": 6}, {"type": "text", "text": "Example 3. Consider the diagram in Fig. $4(c)$ and two distributions $P^{(1)},P^{(2)}\\in\\mathcal{P}$ with intervention targets ${\\bf I}^{(1)}\\,=\\,\\{\\}^{\\Pi_{1}}$ and $\\mathbf{I}^{(2)}\\,=\\,\\{V_{2}^{\\Pi_{1}}\\}$ . The changed variable set $\\Delta\\mathbf{V}^{(2),(1)}\\,=\\,\\{V_{2},V_{3}\\}$ since $V_{2}\\in\\mathbf{I}^{(2)}$ , $V_{2}\\notin{\\bf I}^{(1)}$ , and $\\mathbf{C}(V_{2})=\\{V_{2},V_{3}\\}$ . Thus, comparing $P^{(2)}$ with $P^{(1)}$ (order A in Ex. 2), factors $p(v_{1}),p(v_{4}\\mid v_{2},v_{1})$ are invariant, whereas $p(v_{2}\\mid v_{1}),p(v_{3}\\mid v_{2},v_{1})$ can change. \u53e3 ", "page_idx": 6}, {"type": "text", "text": "With Prop. 2, Eq. (2) naturally keeps factors only in the C-component of $\\Delta{\\bf V}$ , i.e., ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\sum_{V_{i}\\in\\bar{\\mathbb{V}}}\\log p_{\\mathbf{T}}^{(j)}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})-p_{\\mathbf{T}}^{(k)}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})=\\sum_{V_{i}\\in\\bar{\\mathbb{V}}}\\log p_{\\mathbf{T}}^{(j)}(\\widehat{v}_{i}\\mid\\widehat{\\mathbf{pa}}_{i}^{\\mathbf{T}+})-\\log p_{\\mathbf{T}}^{(k)}(\\widehat{v}_{i}\\mid\\widehat{\\mathbf{pa}}_{i}^{\\mathbf{T}+})\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\tilde{\\mathbf{V}}=\\mathbf{C}(\\Delta\\mathbf{V}[\\mathbf{I}^{(j)},\\mathbf{I}^{(k)},G^{S}])$ . This factorization hints that $\\widehat{\\mathbf{V}}$ (RHS of Eq. (3)) is only related to variables that appear on the LHS. ", "page_idx": 6}, {"type": "text", "text": "Definition 3.1 $\\left\\langle{\\Delta\\mathbf{Q}\\,S\\mathrm{et}}\\right\\rangle$ . Given two distributions $P^{(j)},P^{(k)}$ with interventions targets $\\sigma^{(j)}$ and $\\sigma^{(k)}$ containing perfect interventions on $\\mathbf{T}$ , the $\\Delta\\mathbf{Q}[\\mathbf{I}^{(j)},\\mathbf{I}^{(k)},\\mathbf{T},G^{S}]$ set (for short: $\\Delta\\bar{\\mathbf{Q}}^{(j),(k)}$ , or $\\Delta\\mathbf{Q}$ if index not needed) of the target sets ${\\bf\\cal I}^{(j)},{\\bf\\cal I}^{(k)}$ is the remaining variables after comparison (i.e. Eq. 3), $\\Delta\\mathbf{Q}[\\mathbf{I}^{(j)},\\mathbf{I}^{(k)},\\mathbf{T},G^{S}]=\\tilde{\\mathbf{V}}\\overset{\\cdot}{\\cup}\\mathbf{P}\\mathbf{a}^{\\mathbf{T}+}(\\tilde{\\mathbf{V}}).$ , where $\\tilde{\\mathbf{V}}=\\mathbf{C}(\\Delta\\mathbf{V}[\\mathbf{I}^{(j)},\\mathbf{I}^{(k)},G^{S}])$ . \u53e3 ", "page_idx": 6}, {"type": "text", "text": "To illustrate, the $\\Delta\\mathbf{Q}$ set involves all variables in LHS of Eq. (3), including $\\tilde{\\textbf{V}}$ and its extended parents. These variables come from factors that possibly change and are kept in Eq. (3). We call $\\mathbf{\\bar{V}}\\backslash\\Delta\\mathbf{Q}$ canceled variables since invariant factors are canceled out from the comparison. Continuing Ex. 3, $\\Delta\\mathbf{Q}=\\left\\{V_{1},V_{2},V_{3}\\right\\}$ given either topological order. ", "page_idx": 7}, {"type": "text", "text": "Leveraging the comparisons among distributions in $\\mathcal{P}$ (Eq. 3), we next develop three criterions for disentanglement. First, we can disentangle canceled variables from $\\Delta\\mathbf{Q}$ set since the difference of density over representationsV  in the $\\Delta\\mathbf{Q}$ set (RHS of Eq. (3)) is irrelevant to canceled variables (LHS of Eq. (3)). ", "page_idx": 7}, {"type": "text", "text": "Proposition 3 $\\mathbf{D}$ the $\\Delta\\mathbf Q$ set w.r.t Canceled Variables). Consider variables $\\mathbf{V}^{t a r}\\subseteq\\mathbf{V}$ . Let $\\mathcal{P}_{\\mathbf{T}}\\,\\dot{=}\\,\\{P^{(a_{0})},P^{(a_{1})},\\dots,\\dot{P}^{(a_{L})}\\}\\,\\subseteq\\,\\mathcal{P}$ be a collection of distributions such that $(I)\\ \\forall\\ l\\in\\ [L]$ , $\\mathbf{T}\\;=\\;\\mathrm{Perf}[\\mathbf{I}^{(a_{0})}]\\;\\subseteq\\;\\mathrm{Perf}[\\mathbf{I}^{(a_{l})}]\\;^{\\;14};$ (2) $\\begin{array}{r}{\\bigcup_{l\\in[L]}\\Delta\\mathbf{Q}[\\mathbf{I}^{(a_{l})},\\mathbf{I}^{(a_{0})},\\mathbf{T},G^{S}]\\,=\\,\\mathbf{V}^{t a r}}\\end{array}$ ; (3) there exists $\\{a_{1}^{\\prime},\\ldots,a_{d^{\\prime}}^{\\prime}\\}\\ \\subseteq\\ \\{a_{1},\\ldots,a_{L}\\}$ such that for all $V_{i}^{t a r}\\;\\in\\;{\\bf V}^{t a r},V_{i}^{t a r}\\;\\in\\;\\Delta{\\bf Q}[{\\bf I}^{(a_{i}^{\\prime})},{\\bf I}^{(a_{0})},{\\bf T},G^{S}],$ , where $d^{\\prime}=|\\mathbf{V}^{t a r}|$ . Then, ${\\bf V}^{t a r}$ is $I D\\;w.r.t\\;\\mathbf{V}\\backslash\\mathbf{V}^{t a r}$ . \u53e3 ", "page_idx": 7}, {"type": "text", "text": "Prop. 3 disentangles target variables ${\\bf V}^{t a r}$ (as a union of $\\Delta\\mathbf{Q}$ sets) from canceled variables according to Eq. (3). To illustrate, it considers to find a collection of $L$ distribution $\\{P^{(a_{1})},\\ldots,P^{(a_{L})}\\}$ to compare with the baseline $P^{(a_{0})}$ such that (1) the perfect intervention variables sets of $\\{\\mathbf{I}^{(a_{1})},\\dots,\\mathbf{I}^{(a_{L})}\\}$ contain the perfect intervention set of the baseline $\\mathbf{I}^{(a_{0})}$ , (2) the union of $\\Delta\\mathbf{Q}$ is equivalent to ${\\bf V}^{t a r}$ , and (3) each $V_{i}^{t a r}$ changes at least once. Then, ${\\bf V}^{t a r}$ can be ID wrt $\\mathbf{V}\\backslash\\mathbf{V}^{t a r}$ . ", "page_idx": 7}, {"type": "text", "text": "Example 4. $\\chi_{x}$ . 3 continued.) Suppose $\\mathcal{P}=\\{P^{(1)},P^{(2)},P^{(3)},P^{(4)}\\}$ with intervention targets $\\mathbf{I}^{(1)}=\\left\\{\\right\\}^{\\Pi_{1}}$ , ${\\bf I}^{(2)}=\\{V_{2}\\}^{\\Pi_{1}}$ , ${\\bf I}^{(3)}=\\{V_{3}\\}^{\\Pi_{1}}$ , $\\mathbf{I}^{(4)}=\\{V_{1}\\}^{\\Pi_{1}}$ . Consider ${\\bf V}^{t a r}=\\{V_{1},V_{2},V_{3}\\}$ and ${\\bf V}^{e n}\\,=\\,{\\bf V}\\backslash\\{V_{1},V_{2},V_{3}\\}\\,=\\,\\{V_{4}\\}$ . Comparing $\\{\\mathbf{I}^{(2)},\\mathbf{I}^{(3)},\\mathbf{I}^{(4)}\\}$ with the baseline $\\mathbf{I}^{(1)}$ , the perfect intervention variables are $\\begin{array}{r}{\\mathbf{T}=\\mathrm{Perf}[\\mathbf{I}^{(1)}]=\\{\\}}\\end{array}$ . Then we have $\\Delta\\mathbf{Q}$ sets: $\\{V_{1},V_{2},V_{3}\\},\\{V_{1},V_{2},V_{3}\\}$ and $V_{1}$ . Thus, these three comparisons satisfy the three conditions in Prop. 3. Then ${\\bf V}^{t a r}$ is $I D\\,w.r.t$ ${\\bf V}^{e n}$ by Prop. 3. See Appendix Ex. 17 for a derivation. \u53e3 ", "page_idx": 7}, {"type": "text", "text": "According to Prop. 3, a disentanglement corollary leveraging the comparison of interventions and observational distributions can be derived. ", "page_idx": 7}, {"type": "text", "text": "Corollary 1 (ID intervened variables). Given an observational distribution and $L$ distributions resulting from interventions on the same target W but with different mechanisms (in the same domain), $i f\\,L\\geq|\\mathbf{\\dot{P}}\\mathbf{a}_{\\mathbf{W}}^{+}\\cup\\mathbf{W}|$ , $\\mathbf{Pa}_{\\mathbf{W}}^{+}\\cup\\mathbf{W}$ is ID w.r.t $\\mathbf{V}\\backslash\\{\\mathbf{Pa}_{\\mathbf{W}}^{+}\\cup\\hat{\\mathbf{W}}\\}$ , where $\\mathbf{P}\\mathbf{a}_{\\mathbf{W}}^{+}=\\cup_{W_{i}\\in\\mathbf{W}}\\mathbf{P}\\mathbf{a}_{W_{i}}^{+}$ . \u53e3 ", "page_idx": 7}, {"type": "text", "text": "The second result disentangles variables within $\\Delta\\mathbf{Q}$ sets. ", "page_idx": 7}, {"type": "text", "text": "Proposition 4 $\\mathbf{D}$ of variables within $\\Delta\\mathbf Q$ sets). Consider the variables $\\mathbf{V}^{t a r}\\subseteq\\mathbf{V}$ , $\\mathcal{P}_{\\mathbf{T}}$ that satisfies conditions $(I)$ in Prop. 3 and $\\Delta\\mathbf{Q}^{(a_{l}),(a_{0})}=\\mathbf{V}^{t a r}$ , for $l\\in[L]$ . For any pair of $V_{i}$ , $V_{j}\\in\\mathbf{V}^{t a r}$ such that $V_{i}$ \u22a5\u22a5 $V_{j}|\\mathbf{V}^{t a r}\\backslash\\{V_{i},V_{j}\\}$ in $G_{\\overline{{\\mathbf{T}}}}(\\mathbf{V}^{t a r})$ , $V_{i}$ is $I D$ w.r.t. $V_{j}$ if $L\\,\\geq\\,2|\\mathbf{V}^{t a r}|+^{\\underbar{\\mathbf{\\alpha}}}\\delta_{\\substack{\\nmid\\mathbf{\\alpha}}}$ , where $\\delta_{\\mathcal{L}}$ is the number of pair $V_{k},V_{r}\\,\\in\\,\\mathbf{V}^{t a r}$ such that $V_{k}$ and $V_{r}$ are connected given $\\mathbf{V}^{t a r}\\backslash\\{V_{k},V_{r}\\}$ in $G_{\\overline{{\\mathbf{T}}}}(\\mathbf{V}^{t a r})$ . \u53e3 ", "page_idx": 7}, {"type": "text", "text": "Prop. 4 disentangles target variables $V_{i}$ and $V_{j}$ both in $\\Delta\\mathbf Q$ sets. To illustrate, consider a set of distributions that satisfies conditions (1) as Prop. 3. This proposition suggests that if (1) $V_{i}$ , $V_{j}\\in\\mathbf{V}^{t a r}$ are conditionally independent given all other variables in $\\mathbf{\\bar{V}}^{t a r}$ , $\\left(2\\right)L$ is not smaller than $2|\\mathbf{V}^{t a r}|+\\delta_{\\mathcal{L}}$ , then $V_{i}$ can be disentangled from $V_{j}$ . ", "page_idx": 7}, {"type": "text", "text": "Example 5. Suppose LSD $G^{S}$ is a collider graph shown in Fig. 4(b). Suppose the intervention targets are $\\bar{\\Psi}\\ \\stackrel{...}{=}\\{\\{\\}^{\\Pi_{1}},\\{\\}^{\\Pi_{2}},\\{\\}^{\\Pi_{3}},\\{\\}^{\\Pi_{4}},\\{\\}^{\\overleftarrow{}^{\\Pi_{5}}\\},$ , which means that observational distributions are available in each domain. Consider $\\mathbf{T}=\\{\\}$ . Let $\\mathbf{V}^{t a r}\\,=\\,\\{V_{1},V_{3}\\}$ . We have $V_{1}\\perp\\!\\!\\!\\perp V_{3}$ in $G(V_{1},V_{3})$ . Based on Def. $3.I,\\Delta\\mathbf{Q}[\\mathbf{I}^{(j)},\\mathbf{I}^{(1)},\\mathbf{T},G^{S}]=\\{V_{1},V_{3}\\}$ for $j=2,3,4,5$ . Then the number of distributions used for comparing (i.e., four) is not smaller than the required $(2\\times2+0)$ , which means $V_{1}$ is $I D\\,w.r t$ . $V_{3}$ and $V_{3}$ is $I D$ w.r.t. $V_{1}$ by Prop. 4. See App. Ex. 18 for a derivation. \u53e3 ", "page_idx": 7}, {"type": "text", "text": "With these existing disentanglements from Props. 3 and 4, the following Proposition considers an inverse direction, which identifies canceled variables w.r.t. $\\Delta\\mathbf Q$ sets 15. ", "page_idx": 7}, {"type": "text", "text": "Proposition 5 ( $\\mathbf{D}$ of canceled variables w.r.t. $\\Delta\\mathbf{Q}$ sets). Suppose $\\Psi$ contains perf $\\mathbf{\\rho}(\\mathbf{T})$ . Given $\\mathbf{V}\\backslash\\bar{V}^{t a r}$ is $I D$ w.r.t. a single variable $V^{t a r}$ , $V^{t a r}$ is $I D$ w.r.t. $\\mathbf{V}\\backslash\\bar{V}^{t a r}\\,i f V^{t a r}\\perp\\!\\!\\!\\perp\\,\\mathbf{V}\\backslash\\bar{V}^{t a r}$ in $G_{\\overline{{\\mathbf{T}}}}$ . ", "page_idx": 7}, {"type": "text", "text": "Algorithm 1 CRID: Algorithm for determining causal representation identifiability - $G^{S}$ is the LSD; $\\Psi$ is the intervention target sets; $G_{\\mathbf{V},\\widehat{\\mathbf{v}}}$ is the output bipartite graph (i.e. CDM). ", "page_idx": 8}, {"type": "text", "text": "Input: $G_{\\mathbf{V}}$ , and intervention target sets $\\Psi$ .   \nOutput: CDM $G_{\\mathbf{V},\\widehat{\\mathbf{V}}}$   \n1: $G_{\\mathbf{V},\\widehat{\\mathbf{V}}}\\gets$ FullyConnectedBipartiteGraph $(\\mathbf{V},{\\widehat{\\mathbf{V}}})$ \u25b7Initialize $G_{\\mathbf{V},\\widehat{\\mathbf{v}}}$ with Alg. F.2   \n2: whil e $G_{\\mathbf{V},\\widehat{\\mathbf{V}}}$ is updated in the last epoch do   \n3: $\\mathbf{Perf}=\\{\\mathbf{T}_{1},\\mathbf{T}_{2},\\dots,\\mathbf{T}_{s}\\}\\leftarrow\\Psi$ $\\triangleright$ Get perfect intervention variables sets.   \n4: for all $\\mathbf{T}\\in\\mathbf{Perf}$ do   \n5: $\\Psi_{\\mathbf{T}}^{\\mathrm{perf}}\\leftarrow\\Psi\\qquad\\mathsf{D}\\,^{\\prime}$ Collect intervention targets that contain hard intervention variables $\\mathbf{T}$   \n6: for all I \u2208\u03a8pTerf such that $\\mathrm{Perf}[\\mathbf{I}]=\\mathbf{T}$ do $\\triangleright$ Iterate intervention targets as the baseline   \n7: $\\mathcal{Q}=\\left\\{\\mathbf{Q}_{1},\\ldots,\\mathbf{Q}_{|\\Psi_{\\mathbf{T}}\\backslash\\mathbf{I}|}\\right\\}$ , where $Q_{k}\\gets\\Delta\\mathbf{Q}[\\mathbf{J}^{(k)},\\mathbf{I},\\mathbf{T},G^{S}]$ $\\triangleright$ Construct $\\Delta\\mathbf{Q}$ sets.   \n8: for all $\\mathbf{Q}$ such that $\\begin{array}{r}{\\mathbf{Q}=\\bigcup_{\\mathbf{Q}_{l}\\in\\mathcal{Q}}\\mathbf{Q}_{l}\\subset\\mathbf{V}}\\end{array}$ do $\\triangleright$ Iterate the union of $\\Delta\\mathbf{Q}$ factors   \n9: $\\begin{array}{r l}&{G_{\\mathbf{V},\\widehat{\\mathbf{V}}}\\leftarrow\\mathbf{Dis}\\Delta\\mathbf{QFromCancel}(\\mathbf{Q},G_{\\mathbf{V},\\widehat{\\mathbf{V}}},G_{\\mathbf{\\overline{{T}}}},\\Psi_{\\mathbf{T}}^{\\mathrm{perf}},\\mathbf{I},\\mathcal{Q})}\\\\ &{G_{\\mathbf{V},\\widehat{\\mathbf{V}}}\\leftarrow\\mathbf{DisWithin}\\Delta\\mathbf{Q}(\\mathbf{Q},G_{\\mathbf{V},\\widehat{\\mathbf{V}}},G_{\\mathbf{\\overline{{T}}}},\\Psi_{\\mathbf{T}}^{\\mathrm{perf}},\\mathbf{I},\\mathcal{Q})}\\end{array}$ \u25b7Alg. F.3, Prop. 3   \n10: \u25b7 Alg. F.6, Prop. 4   \n11: for all T \u2208Perf do   \n12: $G_{\\mathbf{V},\\widehat{\\mathbf{V}}}\\leftarrow\\mathbf{DisCancelFrom}\\Delta\\mathbf{Q}(G_{\\mathbf{V},\\widehat{\\mathbf{V}}},G_{\\overline{{\\mathbf{T}}}})$ \u25b7 Alg. F.8, Prop. 5   \n13: return GV,V V1 V V1 V V1 V1 V1 V1 V2 V V2 V2 V2 V2 V2 V V3 V V3 V3 V3 V3 V3 V (a) Initialization. (b) 1st epoch, Step 11. (c) 1st epoch, Step 14. (d) 2nd epoch, Step 11. ", "page_idx": 8}, {"type": "text", "text": "To illustrate, Prop. 5 states: if $\\mathbf{V}\\backslash\\{V^{t a r}\\}$ is already disentangled from $V^{t a r}$ , then $V^{t a r}$ is ID wrt $\\mathbf{V}\\backslash\\{V^{t a r}\\}$ if a perfect intervention on $\\mathbf{T}$ exists to separate $V^{t a r}$ and $\\mathbf{V}\\backslash\\{V^{t a r}\\}$ in $G_{\\overline{{\\mathbf{T}}}}$ . Prop. 5 does not compare distributions but relies on existing disentanglements. See Ex. 19 for details. ", "page_idx": 8}, {"type": "text", "text": "4 Algorithmic Disentanglement of Causal Representations ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we develop an algorithmic procedure for determining whether ${\\bf V}^{t a r}$ and ${\\bf V}^{e n}$ are disentangleable given the LSD $G^{\\widetilde{S}}$ and interventions sets $\\Psi$ . The whole algorithm CausalRepresentationID (CRID, for short) is described in Alg. 1. We start by introducing a bipartite graph $G_{\\mathbf{V},\\widehat{\\mathbf{v}}}$ , called Causal Disentanglement Map $(C D M)$ (which was informally shown in Fig 2 (right)). In wor ds, the absence of the edge $V_{i}\\neq\\widehat{V}_{j}$ implies $V_{j}$ is ID w.r.t $V_{i}$ . If each $\\widehat{V}_{i}$ is only pointed by $V_{i}$ , then we have full disentanglement of $\\mathbf{V}$ . If $\\mathbf{V}\\subset V_{i}$ points to $\\widehat{V}_{i}$ , then we have partial disentanglement of $V_{i}$ . ", "page_idx": 8}, {"type": "text", "text": "CRID proceeds by first constructing the fully connected CDM in Step 1. In each iteration, the hard intervention set $\\mathbf{T}$ and the baseline intervention target set I (Steps 4 and 6) are enumerated. For each $\\mathbf{T}$ and baseline, all $\\Delta\\mathbf{Q}$ sets are constructed based on Def. 3.1 and put into a collection $\\mathcal{Q}$ (Steps 7). After the union of $\\Delta\\mathbf{Q}$ sets (denoted as $\\mathbf{Q}$ ) is chosen (Step 8) iteratively, Props. 3 and 4 are leveraged in two procedures (Step 9 and 10) to check the identification of $\\mathbf{Q}$ w.r.t. $\\mathbf{V}\\backslash\\mathbf{Q}$ and the identification within $\\mathbf{Q}$ . The disentanglements in CDM at the current stage are leveraged to reduce the required number of distributions (see details in Alg. F.3 and F.6). At the end of the iteration, Prop. 5 is used for identifying $\\mathbf{V}\\backslash\\mathbf{Q}$ from $\\mathbf{Q}$ leveraging current disentanglement in CDM (Step 11-12). ", "page_idx": 8}, {"type": "text", "text": "Example 6. (Ex. 1 continued.) Consider the selection diagram (Fig. 2) and the set up in Ex. 1 The perfect intervention variable sets are the empty set $\\{\\}$ and $\\{V_{2}\\}$ . First, $\\mathbf{T}$ is chosen as $\\{\\}$ and then $\\Psi_{\\mathbf{T}}^{\\mathrm{perf}}\\,=\\,\\Psi$ . Choosing the baseline ${\\bf I}\\,=\\,{\\bf I}^{(1)}$ , the $\\Delta\\mathbf Q$ collection: $\\mathcal{Q}\\,=\\,\\left\\{\\mathbf{Q}_{1},\\mathbf{Q}_{2},\\mathbf{Q}_{3}\\right\\}\\,=$ $\\{\\{V_{2},\\bar{V_{3}}\\},\\{V_{2},V_{3}\\},\\{V_{1},V_{2}\\}\\}$ . We consider the $\\mathbf{Q}$ as $\\{V_{2},V_{3}\\}$ and $\\{V_{1},V_{2}\\}$ . For ${\\bf Q}=\\{V_{2},V_{3}\\}$ , leveraging Step 9 (Prop. 3), the edges from $V_{1}$ to $\\{\\widehat{V}_{2},\\widehat{V}_{3}\\}$ are removed (See Ex. 15 for details) and Step 10 (Prop. 4) does not remove further edges. H owever, for $\\mathbf{Q}\\,=\\,\\{V_{1},V_{2}\\}$ , no edge can be removed, since it at least needs two comparisons for claiming disentanglement. ", "page_idx": 8}, {"type": "image", "img_path": "uLGyoBn7hm/tmp/d125836109e518bb7715d1df57e36554625f4a99966772eb4600f9c2a704abb7.jpg", "img_caption": ["Figure 6: Correlation of learned latent representations with true latent variables from Fig. 4. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Choosing $\\{\\}^{\\Pi_{2}}$ or $V_{3}^{\\Pi_{2}}$ or $V_{2}^{\\Pi_{1},\\mathrm{do}}$ as the baseline, no new $\\mathbf{Q}$ can be constructed, so no further edges are removed. When $\\mathbf{T}$ is chosen as $\\{V_{2}\\}$ , the comparison does not work since no other distribution is available. At the end of this iteration, with the fact that $\\{V_{2},V_{3}\\}$ is $I D$ wrt $V_{1}$ and $V_{1}$ \u22a5\u22a5 $\\{V_{2},V_{3}\\}$ in $G_{\\overline{{V_{2}}}}$ , Step 12 (Prop. 5) removes edges from $V_{2}$ to $\\widehat{V}_{1}$ and $V_{3}$ to $\\widehat{V}_{1}$ . In the second iteration, the algorithm repeats the choice of $\\mathbf{T}$ and the baseline. At this iteration, for $\\mathbf{Q}=\\{V_{1},V_{2}\\}$ , the edge from $V_{3}$ to $\\widehat{V}_{2}$ is removed since $V_{3}$ to $\\widehat{V}_{1}$ has already been removed in CDM and only $^{\\,l}$ comparison is needed no w.  At the end of this epoch  n o further can be removed by Alg. F.8. In the third epoch, $G_{\\mathbf{V},\\widehat{\\mathbf{V}}}$ is not updated and the process of CDM returned is shown in Fig. 5. ", "page_idx": 9}, {"type": "text", "text": "The following theorem indicates the soundness of CRID. ", "page_idx": 9}, {"type": "text", "text": "Theorem 1 (Soundness of CRID). Consider a LSD $G^{S}$ and intervention targets $\\Psi$ . Consider the target variables ${\\bf V}^{t a r}$ and ${\\bf V}^{e n}\\subseteq{\\bf V}\\backslash{\\bf V}^{t a r}$ . If no edges from ${\\bf V}^{t a r}$ points to $\\widehat{\\mathbf{V}}^{e n}$ in the output causal disentanglement map $(C D M)$ from CRID, $G_{V,\\widehat{V}}$ , then $\\dot{\\mathbf V}^{t a r}$ is $I D\\;w.r{t}\\;{\\bf V}^{e n}$ . \u53e3 ", "page_idx": 9}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We corroborate the theoretical findings through simulations and MNIST dataset. For full details, see Appendix Section G. In simulations, we consider LSDs shown in Fig. 4 with different collection of distributions P = {P (k)(X; \u03c3(k))}kK=1 and the results are presented in Fig. 6. For the evaluation, we follow a standard evaluation protocol in prior work [18], where we take the latent representations $\\widehat{\\bf V}$ and compute their mean correlation coefficient (MCC) wrt the latent $\\mathbf{V}$ . We compare MCC with what is expected from CRID. Fig. S9 shows the full MCC comparisons of $\\mathbf{V}$ and $\\widehat{\\bf V}$ . ", "page_idx": 9}, {"type": "text", "text": "Chain Graph Fig. 4(a). Fig. 6(a) shows ID of $V_{3}$ wrt $\\{V_{1}\\}$ using input distributions $\\mathcal{P}$ with interventions $\\Sigma=\\{\\sigma_{\\{\\}},\\sigma_{3}^{\\{1\\}},\\sigma_{3}^{\\{2\\}}\\}$ because $M C C(\\widehat{V}_{3},V_{1})$ is relatively low compared to $M C C(\\widehat{V}_{3},V_{3})$ , which is consistent with CRID. The ID results of [21] states $V_{3}$ would still be entangled with $V_{1}$ because $V_{1}\\in\\overline{{A n c}}(V_{3})$ . Fig. 6(b) shows ID of $V_{1}$ wrt $\\{V_{2},V_{3}\\}$ . Interestingly, we do not even have to intervene on $V_{1}$ to obtain full disentanglement. ", "page_idx": 9}, {"type": "text", "text": "Collider Graph Fig. 4(b). Fig. 6(c) shows $V_{1}$ and $V_{3}$ are ID wrt $V_{2}$ and each other because $M C C(\\widehat{V}_{3},V_{3})\\;>\\;M C C(\\widehat{V}_{3},V_{i})$ and $M C C(\\widehat{V}_{2},V_{2})\\;>\\;M C C(\\widehat{V}_{2},V_{i})$ , which is consistent with CRID. There are distributions from four domains that have a change-in-mechanism on $\\{V_{1},V_{3}\\}$ (represented by the S-node). According to [22], since $V_{1}$ and $V_{3}$ are adjacent in the Markov Network, $V_{1}$ and $V_{3}$ are not disentangleable. ", "page_idx": 9}, {"type": "text", "text": "Non-Markovian Graph Fig. 4(c). Fig. 6(d) shows $V_{3}$ is $\\mathrm{ID}$ wrt $\\{V_{1},V_{2},V_{4}\\}$ with interventions $\\Sigma=$ $\\{d o^{\\{1\\}}(V_{3}),d o^{\\{2\\}}(V_{3}\\bar{)\\}$ , which is consistent with CRID. No prior results achieve disentanglement with confounding among $\\mathbf{V}$ . ", "page_idx": 9}, {"type": "text", "text": "6 Conclusions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work introduces theory and a practical ID algorithm for determining which latent variables are disentangleable from a given set of assumptions in the form of a LSD, and input distributions from heterogenous domains. This brings us one step closer to building robust AI that can reason causally over high-level concepts when only given low-level data. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "AL was supported by the NSF Computing Innovation Fellowship (#2127309). YP and EB were supported in part by the NSF, ONR, AFOSR, DoE, Amazon, JP Morgan, and The Alfred P. Sloan Foundation. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Judea Pearl. Causality: Models, reasoning, and inference. 2nd. Cambridge University Press, 2009.   \n[2] J. Pearl and D. Mackenzie. The book of why : the new science of cause and effect. Pages: 418. 2019.   \n[3] E. Bareinboim, J. D. Correa, D. Ibeling, and T. Icard. \u201cOn Pearl\u2019s Hierarchy and the Foundations of Causal Inference.\u201d In: Probabilistic and Causal Inference: The Works of Judea Pearl. 1st ed. Vol. 36. New York, NY, USA: Association for Computing Machinery, 2022, pp. 507\u2013556.   \n[4] B. Sch\u00f6lkopf, F. Locatello, S. Bauer, N. R. Ke, N. Kalchbrenner, A. Goyal, and Y. Bengio. Towards Causal Representation Learning. arXiv:2102.11107 [cs]. 2021.   \n[5] Y. Bengio, A. Courville, and P. Vincent. \u201cRepresentation Learning: A Review and New Perspectives.\u201d In: Arxiv (2012).   \n[6] A. Hyv\u00e4rinen and E. Oja. \u201cIndependent component analysis: algorithms and applications.\u201d In: Neural networks 13.4-5 (2000), pp. 411\u2013430.   \n[7] A. Hyvarinen, H. Sasaki, and R. E. Turner. Nonlinear ICA Using Auxiliary Variables and Generalized Contrastive Learning. arXiv:1805.08651 [cs, stat]. 2019.   \n[8] A. Hyv\u00e4rinen, I. Khemakhem, and H. Morioka. \u201cNonlinear independent component analysis for principled disentanglement in unsupervised deep learning.\u201d In: Patterns 4.10 (2023), p. 100844.   \n[9] A. Hyv\u00e4rinen and P. Pajunen. \u201cNonlinear independent component analysis: Existence and uniqueness results.\u201d In: Neural networks 12.3 (1999), pp. 429\u2013439.   \n[10] I. Khemakhem, D. Kingma, R. Monti, and A. Hyvarinen. \u201cVariational autoencoders and nonlinear ica: A unifying framework.\u201d In: International Conference on Artificial Intelligence and Statistics. PMLR. 2020, pp. 2207\u20132217.   \n[11] C. Squires, A. Seigal, S. S. Bhate, and C. Uhler. \u201cLinear Causal Disentanglement via Interventions.\u201d en. In: Proceedings of the 40th International Conference on Machine Learning. ISSN: 2640-3498. PMLR, 2023, pp. 32540\u201332560.   \n[12] K. Ahuja, J. S. Hartford, and Y. Bengio. \u201cWeakly supervised representation learning with sparse perturbations.\u201d In: Advances in Neural Information Processing Systems 35 (2022), pp. 15516\u201315528.   \n[13] B. Varici, E. Acarturk, K. Shanmugam, A. Kumar, and A. Tajer. \u201cScore-based causal representation learning with interventions.\u201d In: arXiv preprint arXiv:2301.08230 (2023).   \n[14] K. Ahuja, D. Mahajan, Y. Wang, and Y. Bengio. Interventional Causal Representation Learning. 2024.   \n[15] L. Gresele, P. K. Rubenstein, A. Mehrjou, F. Locatello, and B. Sch\u00f6lkopf. \u201cThe incomplete rosetta stone problem: Identifiability results for multi-view nonlinear ica.\u201d In: Uncertainty in Artificial Intelligence. PMLR. 2020, pp. 217\u2013227.   \n[16] L. Gresele, J. Von K\u00fcgelgen, V. Stimper, B. Sch\u00f6lkopf, and M. Besserve. \u201cIndependent mechanism analysis, a new concept?\u201d In: Advances in neural information processing systems 34 (2021), pp. 28233\u201328248.   \n[17] S. Lachapelle, P. Rodriguez, Y. Sharma, K. E. Everett, R. Le Priol, A. Lacoste, and S. LacosteJulien. \u201cDisentanglement via Mechanism Sparsity Regularization: A New Principle for Nonlinear ICA.\u201d In: First Conference on Causal Learning and Reasoning. 2021.   \n[18] J. von K\u00fcgelgen, Y. Sharma, L. Gresele, W. Brendel, B. Sch\u00f6lkopf, M. Besserve, and F. Locatello. Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style. 2022.   \n[19] F. Locatello, B. Poole, G. R\u00e4tsch, B. Sch\u00f6lkopf, O. Bachem, and M. Tschannen. \u201cWeaklysupervised disentanglement without compromises.\u201d In: International conference on machine learning. PMLR. 2020, pp. 6348\u20136359.   \n[20] J. Brehmer, P. De Haan, P. Lippe, and T. S. Cohen. \u201cWeakly supervised causal representation learning.\u201d In: Advances in Neural Information Processing Systems 35 (2022), pp. 38319\u2013 38331.   \n[21] L. Wendong, A. Keki\u00b4c, J. von K\u00fcgelgen, S. Buchholz, M. Besserve, L. Gresele, and B. Sch\u00f6lkopf. Causal Component Analysis. arXiv:2305.17225 [cs, stat]. 2023.   \n[22] K. Zhang, S. Xie, I. Ng, and Y. Zheng. Causal Representation Learning from Multiple Distributions: A General Setting. arXiv:2402.05052 [cs, stat]. 2024.   \n[23] B. Varici, E. Acart\u00fcrk, K. Shanmugam, and A. Tajer. \u201cGeneral identifiability and achievability for causal representation learning.\u201d In: International Conference on Artificial Intelligence and Statistics. PMLR. 2024, pp. 2314\u20132322.   \n[24] S. Lachapelle, P. R. L\u00f3pez, Y. Sharma, K. Everett, R. L. Priol, A. Lacoste, and S. Lacoste-Julien. \u201cNonparametric partial disentanglement via mechanism sparsity: Sparse actions, interventions and sparse temporal dependencies.\u201d In: arXiv preprint arXiv:2401.04890 (2024).   \n[25] Z. Jin, J. Liu, Z. Lyu, S. Poff, M. Sachan, R. Mihalcea, M. Diab, and B. Sch\u00f6lkopf. Can Large Language Models Infer Causation from Correlation? arXiv:2306.05836 [cs]. 2023.   \n[26] M. Zec\u02c7evic\u00b4, M. Willig, D. S. Dhami, and K. Kersting. \u201cCausal Parrots: Large Language Models May Talk Causality But Are Not Causal.\u201d en. In: Transactions on Machine Learning Research (2023).   \n[27] Y. Pan and E. Bareinboim. \u201cCounterfactual Image Editing.\u201d In: arXiv preprint arXiv:2403.09683 (2024).   \n[28] P. C. Austin. \u201cAn introduction to propensity score methods for reducing the effects of confounding in observational studies.\u201d In: Multivariate Behavioral Research 46.3 (2011), pp. 399\u2013 424.   \n[29] M. Brookhart, T. St\u00fcrmer, R. Glynn, J. Rassen, and S. Schneeweiss. \u201cConfounding control in healthcare database research: challenges and potential approaches.\u201d In: Medical care 48.6 0 (2010), S114\u2013S120.   \n[30] C. Wachinger, B. G. Becker, A. Rieckmann, and S. P\u00f6lsterl. \u201cQuantifying Confounding Bias in Neuroimaging Datasets with Causal Inference.\u201d en. In: Medical Image Computing and Computer Assisted Intervention \u2013 MICCAI 2019. Ed. by D. Shen, T. Liu, T. M. Peters, L. H. Staib, C. Essert, S. Zhou, P.-T. Yap, and A. Khan. Cham: Springer International Publishing, 2019, pp. 484\u2013492.   \n[31] F. Mahmood, R. Chen, and N. J. Durr. \u201cUnsupervised Reverse Domain Adaptation for Synthetic Medical Images via Adversarial Training.\u201d In: IEEE Transactions on Medical Imaging 37.12 (2018), pp. 2572\u20132581.   \n[32] A. Li, A. Jaber, and E. Bareinboim. \u201cCausal discovery from observational and interventional data across multiple environments.\u201d In: Thirty-seventh Conference on Neural Information Processing Systems. 2023.   \n[33] E. Bareinboim and J. Pearl. \u201cTransportability of Causal Effects: Completeness Results.\u201d In: Proceedings of the AAAI Conference on Artificial Intelligence 26.1 (2012), pp. 698\u2013704.   \n[34] J. Pearl and E. Bareinboim. \u201cTransportability across studies: A formal approach.\u201d In: (2018).   \n[35] E. Bareinboim and J. Pearl. \u201cMeta-Transportability of Causal Effects: A Formal Approach.\u201d en. In: Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics. ISSN: 1938-7228. PMLR, 2013, pp. 135\u2013143.   \n[36] E. Bareinboim and J. Pearl. \u201cCausal inference and the data-fusion problem.\u201d In: Proceedings of the National Academy of Sciences 113.27 (2016). Publisher: National Academy of Sciences, pp. 7345\u20137352.   \n[37] P. H\u00fcnermund and E. Bareinboim. Causal Inference and Data Fusion in Econometrics. arXiv:1912.09104 [econ]. 2023.   \n[38] A. Li, C. Huynh, Z. Fitzgerald, I. Cajigas, D. Brusko, J. Jagid, A. O. Claudio, A. M. Kanner, J. Hopp, S. Chen, J. Haagensen, E. Johnson, W. Anderson, N. Crone, S. Inati, K. A. Zaghloul, J. Bulacio, J. Gonzalez-Martinez, and S. V. Sarma. \u201cNeural fragility as an EEG marker of the seizure onset zone.\u201d en. In: Nature Neuroscience 24.10 (2021). Number: 10 Publisher: Nature Publishing Group, pp. 1465\u20131474.   \n[39] A. Li, P. Myers, N. Warsi, K. M. Gunnarsdottir, S. Kim, V. Jirsa, A. Ochi, H. Otusbo, G. M. Ibrahim, and S. V. Sarma. Neural Fragility of the Intracranial EEG Network Decreases after Surgical Resection of the Epileptogenic Zone. en. Pages: 2021.07.07.21259385. 2022.   \n[40] A. Li, B. Chennuri, S. Subramanian, R. Yaffe, S. Gliske, W. Stacey, R. Norton, A. Jordan, K. Zaghloul, S. Inati, S. Agrawal, J. Haagensen, J. Hopp, C. Atallah, E. Johnson, N. Crone, W. Anderson, Z. Fitzgerald, J. Bulacio, J. Gale, S. Sarma, and J. Gonzalez-Martinez. \u201cUsing network analysis to localize the epileptogenic zone from invasive EEG recordings in intractable focal epilepsy.\u201d In: Network Neuroscience 2.2 (2017).   \n[41] J. M. Bernabei, A. Li, A. Y. Revell, R. J. Smith, K. M. Gunnarsdottir, I. Z. Ong, K. A. Davis, N. Sinha, S. Sarma, and B. Litt. \u201cQuantitative approaches to guide epilepsy surgery from intracranial EEG.\u201d In: Brain (2023), awad007.   \n[42] K. M. Gunnarsdottir, A. Li, R. J. Smith, J.-Y. Kang, A. Korzeniewska, N. E. Crone, A. G. Rouse, J. J. Cheng, M. J. Kinsman, P. Landazuri, U. Uysal, C. M. Ulloa, N. Cameron, I. Cajigas, J. Jagid, A. Kanner, T. Elarjani, M. M. Bicchi, S. Inati, K. A. Zaghloul, V. L. Boerwinkle, S. Wyckoff, N. Barot, J. Gonzalez-Martinez, and S. V. Sarma. \u201cSource-sink connectivity: a novel interictal EEG marker for seizure localization.\u201d In: Brain 145.11 (2022), pp. 3901\u20133915.   \n[43] L. Nobili, B. Frauscher, S. Eriksson, S. Gibbs, H. Peter, I. Lambert, R. Manni, L. Peter-Derex, P. Proserpio, F. Provini, A. Weerd, and L. Parrino. \u201cSleep and epilepsy: A snapshot of knowledge and future research lines.\u201d In: Journal of Sleep Research 31 (2022).   \n[44] A. Bagshaw, J. Jacobs, P. LeVan, F. Dubeau, and J. Gotman. \u201cEffect of sleep stage on interictal high-frequency oscillations recorded from depth macroelectrodes in patients with focal epilepsy.\u201d In: Epilepsia 50 (2008), pp. 617\u201328.   \n[45] S. Gibbs, P. Proserpio, M. Terzaghi, A. Pigorini, S. Sarasso, G. Russo, L. Tassi, and L. Nobili. \u201cSleep-related epileptic behaviors and non-REM-related parasomnias: Insights from stereoEEG.\u201d In: Sleep Medicine Reviews 63 (2015).   \n[46] P. Greene, A. Li, J. Gonzalez-Martinez, and S. Sarma. \u201cClassification of Stereo-EEG Contacts in White Matter vs. Gray Matter Using Recorded Activity.\u201d In: Frontiers in Neurology 11 (2021).   \n[47] A. A. Borb\u00e9ly, F. Baumann, D. Brandeis, I. Strauch, and D. Lehmann. \u201cSleep deprivation: Effect on sleep stages and EEG power density in man.\u201d In: Electroencephalography and Clinical Neurophysiology 51.5 (1981), pp. 483\u2013493.   \n[48] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, \u0141. Kaiser, and I. Polosukhin. \u201cAttention is All you Need.\u201d In: Advances in Neural Information Processing Systems. Ed. by I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett. Vol. 30. Curran Associates, Inc., 2017.   \n[49] R. Bommasani et al. On the Opportunities and Risks of Foundation Models. 2022.   \n[50] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei. Language Models are Few-Shot Learners. 2020.   \n[51] J. von K\u00fcgelgen, M. Besserve, L. Wendong, L. Gresele, A. Kekic\u00b4, E. Bareinboim, D. M. Blei, and B. Sch\u00f6lkopf. Nonparametric Identifiability of Causal Representations from Unknown Interventions. arXiv:2306.00542 [cs, stat]. 2023.   \n[52] K. Ahuja, D. Mahajan, Y. Wang, and Y. Bengio. \u201cInterventional causal representation learning.\u201d In: International conference on machine learning. PMLR. 2023, pp. 372\u2013407.   \n[53] D. Yao, D. Xu, S. Lachapelle, S. Magliacane, P. Taslakian, G. Martius, J. von K\u00fcgelgen, and F. Locatello. Multi-View Causal Representation Learning with Partial Observability. 2024.   \n[54] M. Yang, F. Liu, Z. Chen, X. Shen, J. Hao, and J. Wang. \u201cCausalVAE: Disentangled Representation Learning via Neural Structural Causal Models.\u201d In: 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). ISSN: 2575-7075. 2021, pp. 9588\u20139597.   \n[55] J. Zhang, K. Greenewald, C. Squires, A. Srivastava, K. Shanmugam, and C. Uhler. \u201cIdentifiability guarantees for causal disentanglement from soft interventions.\u201d In: Advances in Neural Information Processing Systems 36 (2024).   \n[56] A. Li, J. Feitelberg, A. P. Saini, R. H\u00f6chenberger, and M. Scheltienne. \u201cMNE-ICALabel: Automatically annotating ICA components with ICLabel in Python.\u201d In: Journal of Open Source Software 7.76 (2022), p. 4484.   \n[57] J. Tian and J. Pearl. \u201cOn the testable implications of causal models with hidden variables.\u201d In: arXiv preprint arXiv:1301.0608 (2012).   \n[58] J. Correa and E. Bareinboim. \u201cA Calculus for Stochastic Interventions:Causal Effect Identification and Surrogate Experiments.\u201d en. In: Proceedings of the AAAI Conference on Artificial Intelligence 34.06 (2020). Number: 06, pp. 10093\u201310100.   \n[59] J. Correa and E. Bareinboim. \u201cGeneral Transportability of Soft Interventions: Completeness Results.\u201d In: Advances in Neural Information Processing Systems. Vol. 33. Curran Associates, Inc., 2020, pp. 10902\u201310912.   \n[60] P. R. Rosenbaum and D. B. Rubin. \u201cThe Central Role of the Propensity Score in Observational Studies for Causal Effects.\u201d In: Biometrika 70.1 (1983), pp. 41\u201355.   \n[61] J. Pearl. \u201cCausal Diagrams for Empirical Research.\u201d In: Biometrika 82.4 (1995). Publisher: [Oxford University Press, Biometrika Trust], pp. 669\u2013688.   \n[62] J. Pearl and E. Bareinboim. \u201cTransportability of Causal and Statistical Relations: A Formal Approach.\u201d en. In: Proceedings of the AAAI Conference on Artificial Intelligence 25.1 (2011). Number: 1, pp. 247\u2013254.   \n[63] S. Lee, J. D. Correa, and E. Bareinboim. \u201cGeneral identifiability with arbitrary surrogate experiments.\u201d In: 2019.   \n[64] F. Locatello, S. Bauer, M. Lucic, G. Raetsch, S. Gelly, B. Sch\u00f6lkopf, and O. Bachem. \u201cChallenging common assumptions in the unsupervised learning of disentangled representations.\u201d In: international conference on machine learning. PMLR. 2019, pp. 4114\u20134124.   \n[65] R. Perry, J. von K\u00fcgelgen, and B. Sch\u00f6lkopf. Causal Discovery in Heterogeneous Environments Under the Sparse Mechanism Shift Hypothesis. arXiv:2206.02013 [cs, stat]. 2022.   \n[66] B. Huang, K. Zhang, M. Gong, and C. Glymour. \u201cCausal Discovery and Forecasting in Nonstationary Environments with State-Space Models.\u201d en. In: Proceedings of the 36th International Conference on Machine Learning. ISSN: 2640-3498. PMLR, 2019, pp. 2901\u20132910.   \n[67] B. Huang, C. J. H. Low, F. Xie, C. Glymour, and K. Zhang. \u201cLatent hierarchical causal structure discovery with rank constraints.\u201d In: arXiv preprint arXiv:2210.01798 (2022).   \n[68] J. Peters, P. B\u00fchlmann, and N. Meinshausen. Causal inference using invariant prediction: identification and confidence intervals. arXiv:1501.01332 [stat]. 2015.   \n[69] J. M. Mooij, S. Magliacane, and T. Claassen. \u201cJoint causal inference from multiple contexts.\u201d In: The Journal of Machine Learning Research 21.1 (2020), 99:3919\u201399:4026.   \n[70] M. Okamoto. \u201cDistinctness of the eigenvalues of a quadratic form in a multivariate sample.\u201d In: The Annals of Statistics (1973), pp. 763\u2013765.   \n[71] D. Koller and N. Friedman. Probabilistic graphical models: principles and techniques. MIT press, 2009.   \n[72] J. Pearl. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. en. Google-Books-ID: AvNID7LyMusC. Morgan Kaufmann, 1988.   \n[73] S. L. Lauritzen, A. P. Dawid, B. N. Larsen, and H.-G. Leimer. \u201cIndependence properties of directed markov fields.\u201d en. In: Networks 20.5 (1990). _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/net.3230200503, pp. 491\u2013505.   \n[74] K. Rajamanickam. \u201cA Mini Review on Different Methods of Functional-MRI Data Analysis Citation: Karunanithi Rajamanickam. A Mini Review on Different Methods of Functional-MRI Data Analysis.\u201d In: Archives of Internal Medicine Research 03 (2020), pp. 44\u2013060.   \n[75] Nuzillard, D. and Bijaoui, A. \u201cBlind source separation and analysis of multispectral astronomical images.\u201d In: Astron. Astrophys. Suppl. Ser. 147.1 (2000), pp. 129\u2013138.   \n[76] E. Bingham and A. Hyvarinen. \u201cICA of complex valued signals: a fast and robust deflationary algorithm.\u201d In: Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium. Vol. 3. 2000, 357\u2013362 vol.3.   \n[77] A. D. Back and A. S. Weigend. \u201cA First Application of Independent Component Analysis to Extracting Structure from Stock Returns.\u201d In: Econometrics: Applied Econometrics & Modeling eJournal (1997).   \n[78] E. Bingham, J. Kuusisto, and K. Lagus. \u201cICA and SOM in text document analysis.\u201d In: Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval. 2002, pp. 361\u2013362.   \n[79] B. Var\u0131c\u0131, E. Acart\u00fcrk, K. Shanmugam, and A. Tajer. \u201cLinear Causal Representation Learning from Unknown Multi-node Interventions.\u201d In: arXiv preprint arXiv:2406.05937 (2024).   \n[80] S. Bing, U. Ninad, J. Wahl, and J. Runge. \u201cIdentifying linearly-mixed causal representations from multi-node interventions.\u201d In: arXiv preprint arXiv:2311.02695 (2023).   \n[81] L. Gresele, G. Fissore, A. Javaloy, B. Sch\u00f6lkopf, and A. Hyv\u00e4rinen. Relative gradient optimization of the Jacobian term in unsupervised deep learning. 2020.   \n[82] G. Papamakarios, E. Nalisnick, D. J. Rezende, S. Mohamed, and B. Lakshminarayanan. Normalizing Flows for Probabilistic Modeling and Inference. 2021.   \n[83] C. Durkan, A. Bekasov, I. Murray, and G. Papamakarios. Neural Spline Flows. 2019.   \n[84] D. P. Kingma and J. Ba. Adam: A Method for Stochastic Optimization. 2017.   \n[85] K. Sachs, O. Perez, D. Pe\u2019er, D. A. Lauffenburger, and G. P. Nolan. \u201cCausal protein-signaling networks derived from multiparameter single-cell data.\u201d eng. In: Science (New York, N.Y.) 308.5721 (2005), pp. 523\u2013529.   \n[86] J. M. Robins, M. A. Hern\u00e1n, and B. Brumback. \u201cMarginal structural models and causal inference in epidemiology.\u201d eng. In: Epidemiology (Cambridge, Mass.) 11.5 (2000), pp. 550\u2013 560.   \n[87] J. Tian and J. Pearl. \u201cA General Identification Condition for Causal Effects.\u201d In: AAAI (2002).   \n[88] I. Shpitser and J. Pearl. \u201cIdentification of Joint Interventional Distributions in Recursive Semi-Markovian Causal Models.\u201d In: AAAI-Proceedings (2006), pp. 1219\u20131226.   \n[89] M. Kocaoglu, K. Shanmugam, and E. Bareinboim. \u201cExperimental Design for Learning Causal Graphs with Latent Variables.\u201d In: Advances in Neural Information Processing Systems 30 (2017).   \n[90] M. Kocaoglu, A. Jaber, K. Shanmugam, and E. Bareinboim. \u201cCharacterization and Learning of Causal Graphs with Latent Variables from Soft Interventions.\u201d In: Advances in Neural Information Processing Systems 32 (2019).   \n[91] A. Jaber, M. Kocaoglu, K. Shanmugam, and E. Bareinboim. \u201cCausal Discovery from Soft Interventions with Unknown Targets: Characterization and Learning.\u201d In: Advances in Neural Information Processing Systems. Vol. 33. Curran Associates, Inc., 2020, pp. 9551\u20139561.   \n[92] X. Shen, F. Liu, H. Dong, Q. Lian, Z. Chen, and T. Zhang. \u201cWeakly Supervised Disentangled Generative Causal Representation Learning.\u201d In: Journal of Machine Learning Research 23 (2022), pp. 1\u201355.   \n[93] K. Xia, K.-Z. L. Lee Bloomberg, Y. Bengio, and E. Bareinboim. \u201cThe Causal-Neural Connection: Expressiveness, Learnability, and Inference.\u201d In: (2021).   \n[94] K. Xia, Y. Pan, and E. Bareinboim. \u201cNeural Causal Models for Counterfactual Identification and Estimation.\u201d In: International Conference on Learning Representations. 2022.   \n[95] A. Jaber, A. H. Ribeiro, J. Zhang, and E. Bareinboim. \u201cCausal Identification under Markov equivalence: Calculus, Algorithm, and Completeness.\u201d In: Advances in Neural Information Processing Systems. 2022.   \n[96] A. Jaber, J. Zhang, and E. Bareinboim. \u201cCausal Identification under Markov Equivalence: Completeness Results.\u201d In: (2019). Publisher: PMLR, pp. 2981\u20132989.   \n[97] T. V. Anand, A. H. Ribeiro, J. Tian, and E. Bareinboim. \u201cCausal effect identification in cluster dags.\u201d In: Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 37. 10. 2023, pp. 12172\u201312179.   \n[98] I. Shpitser and J. Pearl. \u201cComplete Identification Methods for the Causal Hierarchy.\u201d In: Journal of Machine Learning Research 9 (2008), pp. 1941\u20131979.   \n[99] J. Zhang, J. Tian, and E. Bareinboim. \u201cPartial Counterfactual Identification from Observational and Experimental Data.\u201d In: (2021). ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Contents ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A Background and Assumptions 17   \nA.1 Notations 17   \nA.2 Assumptions and Remarks 18   \nA.3 Domains vs Interventions 21   \nA.4 Permutation Indeterminancy 22   \nB CRID Algorithm Details 23   \nC Proofs 27   \nC.1 \"Distribution Change Sufficiently\" - Proof of Lemma 1 27   \nC.2 Distribution comparison - Proof of Proposition 1 28   \nC.3 Invariant factors - Proof of Proposition 2 29   \nC.4 ID \u2206Q w.r.t Canceled Factors - Proof of Proposition 3 and Lemma 2 29   \nC.5 ID within $\\Delta\\mathbf{Q}$ set - Proof of Proposition 4 and Lemma 3 30   \nC.6 ID-reverse of existing disentangled variables - Proof of Proposition 5 33   \nC.7 Soundness of LatentID Algorithm - Proof of Thm. 1 34   \nD Examples and Discussion . 35   \nD.1 Additional Example Illustrating Motivation of Causal Disentangled Learning 35   \nD.2 Examples for non-Markovian Factorization 35   \nE Examples for Proposition 2 . 37   \nE.1 The detailed examples of Proposition 3 and 4 37   \nF Related Work Discussion 39   \nF.1 Causal representation learning with unknown latent causal structure 39   \nF.2 Comparisons with other identifiability criterion 39   \nF.3 Case study on challenges when disentangling variables in a non-Markovian   \nsetting . . 40   \nF.4 ID within c-components 41   \nF.5 Case study on disentangling variables in a Markovian setting 41   \nF.6 Comparing different identifiability results 42   \nG Experimental Results 46   \nG.1 Synthetic data-generating process 46   \nG.2 Image Editing Using Disentangled Representations 47   \nG.3 Model 48   \nG.4 Training details 49   \nG.5 Evaluation metrics 49   \nG.6 Limitations 49   \nG.7 Discussion of Results 50   \nH Broader Impact and Forward-Looking Statements 52   \nI Frequently Asked Questions 52 ", "page_idx": 15}, {"type": "table", "img_path": "uLGyoBn7hm/tmp/b7d657c35be43fc5444ee2285a3b4b433624aca015e3d3a9809a78e8d75eeb29.jpg", "table_caption": ["A.1 Notations "], "table_footnote": ["Figure S1: Table of Notations "], "page_idx": 16}, {"type": "text", "text": "We gave an example to illustrate the notation of a collection of intervention target sets $\\Psi$ and each intervention target set $\\mathbf{I}^{(k)}$ . ", "page_idx": 17}, {"type": "text", "text": "Example 7. Let an intervention target collection be ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\Psi=\\{\\mathbf{I}^{(1)}=\\{\\{\\}^{\\Pi_{1}}\\},\\mathbf{I}^{(2)}=\\{V_{1}^{\\Pi_{1},\\{1\\}}\\},\\mathbf{I}^{(3)}=\\{V_{1}^{\\Pi_{2},\\{2\\}},V_{2}^{\\Pi_{2},\\{1\\},\\mathrm{perf}\\},\\mathbf{I}^{(4)}=\\{V_{1}^{\\Pi_{2},\\{1\\}},V_{2}^{\\Pi_{2},\\mathrm{perf}\\},\\mathbf{I}^{(5)}=\\{V_{1}^{\\Pi_{3},\\{1\\}},V_{2}^{\\Pi_{2},\\mathrm{perf}\\},\\mathbf{I}^{(6)}=V_{2}^{\\Pi_{3},\\{1\\},\\mathrm{perf}\\}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "In words, $\\Psi$ indicates $^{4}$ different interventions $\\Sigma=\\{\\sigma^{(k)}\\}_{k=1}^{4}$ :   \n$\\sigma^{(1)}$ ; an idle intervention is applied resulting in an observational distribution in the domain $\\Pi^{1}$ . $\\sigma^{(2)}$ ; a soft intervention with mechanism $\\{1\\}$ is applied to $V_{1}$ in domain $\\Pi^{1}$ .   \n$\\sigma^{(3)}$ ; an intervention is applied to $V_{1}$ and $V_{2}$ in domain $\\Pi^{2}$ where the mechanism of $V_{1}$ is different from $\\sigma^{(2)}$ and the intervention on $V_{2}$ is perfect.   \n$\\bar{\\sigma}^{(4)}$ ; an intervention is applied to $V_{1}$ and $V_{2}$ in domain $\\Pi^{2}$ where the mechanism of $V_{1}$ is the same with $\\sigma^{(2)}$ and the mechanism of $V_{2}$ is different from $\\sigma^{(3)}$ .   \n$\\mathrm{Perf}[\\mathbf{I}^{(3)}]=\\{V_{2}\\}$ means that $\\sigma^{(3)}$ perfectly intervenes on $\\{V_{2}\\}$ .   \n$\\Psi_{V_{2}}^{\\mathrm{perf}}=\\{\\mathbf{I}^{(3)},\\mathbf{I}^{(4)}\\}$ means that the interventions targets that contain perfect interventions on $V_{2}$ $\\Psi_{\\{\\}}=\\Psi$ . Also, the mechanism of $V_{1}^{\\Pi_{1},\\{1\\}}$ is different from the mechanism of $V_{2}^{\\Pi_{2},\\{1\\}}$ since variables are different. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "A.2 Assumptions and Remarks ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this paper, we make a few key assumptions about interventions and the differences in domains. We leverage many similar assumptions to the setting proposed in the literature related to causal representation learning, and handling of multiple domains and interventions [21, 22, 32, 51]. We discuss those assumptions and their implications here. ", "page_idx": 17}, {"type": "text", "text": "Remark 1 (Mixing is invertible). As a consequence of Def. 2.1, the mixing function $f_{\\mathbf{X}}$ is invertible, ensuring that latent variables are uniquely learnable [9, 10, 17, 64]. ", "page_idx": 17}, {"type": "text", "text": "The mapping from generative factors $\\mathbf{V}$ to high dimensional mixture $\\mathbf{X}$ is a one-to-one mapping. Consider images. In one direction, V constructs the image through a mixing tool $f_{\\mathbf{X}}$ (such as a camera lens). In the reverse direction, these generative factors $\\mathbf{V}$ can be uniquely labeled through $f_{\\mathbf{X}}^{-1}$ . We take images example in Sec. D.1 as an example. The generative factors Gender, $A g e$ and Haircolor are directly expressed through pixels in images. Given an image, the values of these generative factors are uniquely determined. This assumption is commonly used in non-linear ICA and representation learning literature [9, 10, 17, 64]. ", "page_idx": 17}, {"type": "text", "text": "Remark 2 (Confounders are not part of the mixing function). According to Def. 2.1, latent exogenous variables U influence the high-dimensional mixture $\\mathbf{X}$ only through latent causal variables $\\mathbf{V}$ , so unobserved confounding $\\mathbf{U}$ does not directly affect the mixing function. ", "page_idx": 17}, {"type": "text", "text": "An example of when this can occur in the real world is when modeling high-dimensional T1 MRI scans. Let the LCG comprise of Drug Treatment $\\rightarrow$ Outcome, but they are confounded by socioeconomic status (Drug Treatment $\\leftrightarrow$ Outcome). The drug treatment and outcome are assumed to be visually discernable on the MRI. However, socioeconomic status does not directly impact how the MRI appears, except through how it impacts the drug treatment efficacy or outcome. In addition, in EEG data, sleep quality and drug treatment may influence EEG appearance, while socioeconomic status may confound sleep and drug treatment but not directly affect EEG. This idea is also present in prior work, such as nonlinear ICA, where independent exogenous variables $U_{i}$ each point to a single $V_{i}$ . [7]. ", "page_idx": 17}, {"type": "text", "text": "Remark 3 (Shared causal structure). As a consequence of Def. 2.2, each environment\u2019s ASCM shares the same latent causal graph, with no structural changes among latent variables 16. ", "page_idx": 17}, {"type": "text", "text": "This means that the S-nodes will not represent structural changes such as when $V_{i}$ has a different parent set across domains 17. ", "page_idx": 17}, {"type": "text", "text": "Remark 4 (Mixing function is shared across all domains). By Def. 2.1, the mixing function $f_{\\mathbf{X}}$ is the same for all ASCMs $\\mathcal{M}^{i}\\in\\mathcal{M}$ , enabling cross-domain analysis. If the mixing function varied across distributions, the latent representations would not be identifiable from iid data alone [9, 51]. \u518f\u53e3 ", "page_idx": 18}, {"type": "text", "text": "Sharing of the mixing function is needed for the multi-domain setting because if everything may change across environments, the domains can only be analysed in isolation, and thus unable to leverage the changes (and similarities) across domains. ", "page_idx": 18}, {"type": "text", "text": "Assumptions for Interventions We discuss assumptions related to interventions here. ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Assumption 1 (Soft interventions without altering the causal structure). Interventions do not change the causal diagram. Hard interventions cut all incoming parent edges, and soft interventions preserve them [59]. However, more general interventions may arbitrarily change the parent set for any given node [59]. We do not consider such interventions and leave this general case for future work. ", "page_idx": 18}, {"type": "text", "text": "This assumption precludes any soft interventions that modify the graphical structure of the causal diagram. This work does allow both perfect interventions that cut all incoming parent edges, and soft interventions that preserve all parent edges. However, more general interventions may arbitrarily change the parent set for any given node [59]. We do not consider such interventions and leave this general case for future work. Note Assumption 1 does not mean that interventions cannot occur with the same mechanism across domains. For example, consider two hospitals $\\Pi^{1}$ and $\\Pi^{2}$ . Treating epilepsy in each of these hospitals can have outcomes that differ vastly due to the differences in domains [38, 39, 41]. This is represented graphically in $G^{S}$ with $S^{1,2}\\stackrel{\\cdot}{\\rightarrow}$ outcome. However, if a neurologist who controls every aspect of his treatment procedure treats patients in both hospitals herself for the purposes of an experiment, then the outcomes will not differ in distribution. This is represented graphically as $S^{1,2}\\ {\\widehat{\\phi}}$ outcome with the S-node being removed from the \"outcome\" variable. Thus if a pair of interventions occurring in different domains are deemed to have the same mechanism, then the S-node (if one is pointing to the intervened variable) is removed when comparing these two distributions. ", "page_idx": 18}, {"type": "text", "text": "Another assumption we make is that all interventions have known targets. ", "page_idx": 18}, {"type": "text", "text": "Assumption 2 (Known-target interventions). All interventions occur with known targets, reducing permutation indeterminacy for intervened variables. ", "page_idx": 18}, {"type": "text", "text": "That is, for each interventional distribution we have, we know the interventions that occurred and at which node(s) they occurred. This assumption allows us to reduce the permutation indeterminacy that would arise if we did not know the intervention targets. In this work, we also are not concerned with permutation indeterminacy for variables we do not necessarily intervene on because we will mostly be concerned with disentanglement wrt the intervened variables (see Appendix Section A.4). It would be interesting for future work to consider unknown intervention targets. ", "page_idx": 18}, {"type": "text", "text": "Assumptions for Distributions In Sec. 2, we discuss that each distribution resulting from an intervention is sufficiently distinct from another distribution Assumption 4. Here we formally define and illustrate what is \"change sufficiently\". ", "page_idx": 18}, {"type": "text", "text": "Assumption 4 (Changing Sufficiently). Consider a collection of ASCMs M and a set of distribution $\\mathcal{P}$ induced by $\\mathbf{\\mathcal{M}}$ from a collection of interventions $\\Sigma$ . Let the LSD induced by $\\mathbf{\\mathcal{M}}$ be $G^{S}$ . Let $\\mathcal{P}_{\\mathbf{T}}=\\{P^{(a_{0})},P^{(a_{1}^{*})},\\dots,P^{(a_{L})}\\}\\subseteq\\mathcal{P}$ be any collection of distributions such that ${\\bf T}=d o[{\\bf I}^{(a_{0})}]\\subseteq$ $d o[\\mathbf{I}^{(a_{l})}]\\,f o r\\,l\\in[L]$ , meaning for the baseline distribution all perfect interventions must be exactly on $\\mathbf{T}$ , and all other distributions must at least contain $\\mathbf{T}$ in their perfect interventions. Let $\\mathbf{Q}=$ $\\bigcup_{l\\in[L]}\\Delta\\mathbf{Q}[\\mathbf{I}^{(a_{l})},\\mathbf{I}^{(0)},\\mathbf{T},G^{S}]$ (Def. 3.1). It is assumed: ", "page_idx": 18}, {"type": "text", "text": "1. The probability density function of $\\mathbf{V}$ is smooth and positive, i.e. $p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})$ is smooth and $p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})>0$ almost everywhere.   \n2. First-order discrepancy. If there exists $\\{a_{1}^{\\prime},\\ldots,a_{|\\mathbf{Q}|}^{\\prime}\\}\\subseteq\\{a_{1},\\ldots,a_{L}\\}$ such that $\\forall~~V_{q}\\in$ $\\mathbf{Q},V_{q}\\in\\Delta\\mathbf{Q}[\\mathbf{I}^{(a_{q}^{\\prime})},\\mathbf{I}^{(a_{0})},\\mathbf{T},G^{S}],$ , then $\\{\\omega_{1}(\\mathbf{v},a_{1}),\\omega_{1}(\\mathbf{v},a_{2}),\\dots,\\omega_{1}(\\mathbf{v},a_{L})\\}$ are linearly independent, where ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\omega_{1}(\\mathbf{v},a_{l})=\\left(\\oplus(\\frac{\\partial\\log p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\mathbf{v})}{\\partial v_{q}})_{V_{q}\\in\\mathbf{Q}}\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "3. Second-order discrepancy. Let a set $\\varepsilon$ consist of pairs of $(V_{p},V_{q})$ such that $(V_{p},V_{q})$ appears at least in one $\\Delta\\mathbf Q$ and $V_{p}$ is connected with $V_{q}$ conditioning on $\\mathbf{V}\\backslash\\{V_{p},\\dot{V}_{q}\\}$ in $G_{\\overline{{T}}}(\\mathbf{Q})$ . Namely, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{\\mathcal{E}}=\\{\\epsilon_{j}=\\{V_{k},V_{r}\\}\\mid}\\\\ {(i)\\ \\exists a_{l},\\{V_{p},V_{q}\\}\\in\\Delta\\mathbf{Q}^{(a_{l}),(a_{0})};}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\omega_{2}(\\mathbf{v},a_{l})=\\Bigg(\\oplus(\\frac{\\partial\\log p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\mathbf{v})}{\\partial v_{q}})_{V_{q}\\in\\mathbf{Q}},\\ \\ \\ \\ \\ \\ \\ }\\\\ {\\oplus(\\frac{\\partial^{2}\\log p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\mathbf{v})}{\\partial v_{q}^{2}})_{V_{q}\\in\\mathbf{Q}},\\ \\ \\ \\ \\ \\ \\ }\\\\ {\\oplus(\\frac{\\partial^{2}\\log p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\mathbf{v})}{\\partial v_{p}v_{q}})_{(V_{p},V_{q})\\in\\mathcal{E}(G_{T}(\\mathbf{Q}))}\\Bigg)}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "At a high level, this assumption will be naturally satisfied if the ASCMs and interventions are randomly chosen and only will be violated if the probability density of $P^{(j)}$ and $P^{(k)}$ are fine-tuned to each other [51]. This kind of assumption is generally included in the causal representation learning literature, such as the \"genericity\" assumption [51], the \"interventional discrepancy\" assumption [21], and the \"sufficient changes\" assumption [10, 22]. ", "page_idx": 19}, {"type": "text", "text": "To illustrate, the assumptions contain two linear independence constraints. Specifically, the first-order and second-order partial derivatives of the log discrepancy from $P^{(a_{l})}$ to $P^{(a_{0})}$ should be independent of each other. Specifically, The two conditions are made because of necessity, since the linear independence constraints can hold only if these conditions hold. The following example illustrates the necessity of the first-order condition: ", "page_idx": 19}, {"type": "text", "text": "Example 8 (Distributions do not change sufficiently). Consider $\\Delta\\mathbf Q$ obtained after comparisons as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\Delta\\mathbf{Q}^{(1),(0)}=\\{V_{1}\\},\\Delta\\mathbf{Q}^{(2),(0)}=\\{V_{1}\\},\\Delta\\mathbf{Q}^{(1),(0)}=\\{V_{1},V_{2},V_{3}\\},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Let $\\mathbf{Q}=\\{V_{1},V_{2},V_{3}\\}$ . We have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\frac{\\log p_{\\mathbf{T}}^{(1)}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(0)}(\\mathbf{v})}{\\partial v_{2}}=0\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Since $V_{2}\\not\\in\\Delta\\mathbf{Q}^{(1),(0)}$ . Similarly, we know ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\mathcal s}_{1}(v_{1},v_{2},v_{3},1)=(\\frac{\\partial\\log p_{\\mathbf{T}}^{(1)}({\\mathbf v})-\\log p_{\\mathbf{T}}^{(0)}({\\mathbf v})}{\\partial v_{1}},0,0)}}\\\\ {{\\displaystyle{\\mathcal s}_{1}(v_{1},v_{2},v_{3},2)=(\\frac{\\partial\\log p_{\\mathbf{T}}^{(2)}({\\mathbf v})-\\log p_{\\mathbf{T}}^{(0)}({\\mathbf v})}{\\partial v_{1}},0,0)}}\\\\ {{\\displaystyle{\\mathcal s}_{1}(v_{1},v_{2},v_{3},3)=(\\frac{\\partial\\log p_{\\mathbf{T}}^{(3)}({\\mathbf v})-\\log p_{\\mathbf{T}}^{(0)}({\\mathbf v})}{\\partial v_{1}},\\frac{\\partial\\log p_{\\mathbf{T}}^{(3)}({\\mathbf v})-\\log p_{\\mathbf{T}}^{(0)}({\\mathbf v})}{\\partial v_{2}},\\frac{\\partial\\log p_{\\mathbf{T}}^{(3)}({\\mathbf v})-\\log p_{\\mathbf{T}}^{(0)}({\\mathbf v})}{\\partial v_{3}},\\frac{\\partial\\log p_{\\mathbf{T}}^{(0)}({\\mathbf v})-\\log p_{\\mathbf{T}}^{(0)}({\\mathbf v})}{\\partial v_{1}},}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "And this implies $\\omega_{1}(v_{1},v_{2},v_{3},1),\\omega_{1}(v_{1},v_{2},v_{3},2),\\omega_{1}(v_{1},v_{2},v_{3},3)$ are for sure not linearly independent. \u53e3 ", "page_idx": 19}, {"type": "text", "text": "On the other perspective, violating these assumptions is like stating the probability densities are fine-tuned to each other [51]. Here we give an example of how this assumption can be violated. ", "page_idx": 19}, {"type": "table", "img_path": "uLGyoBn7hm/tmp/4d4a79f6938452bf1d119782667a81dd41ba82edbc5c45d394d568301c717173.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "Example 9 (Distributions do not change sufficiently). Consider intervention targets ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\Psi=\\{\\mathbf{I}^{(1)}=\\{\\{\\}^{\\Pi_{1}}\\},\\mathbf{I}^{(2)}=\\{V_{1}^{\\Pi_{1},\\{1\\}}\\},\\mathbf{I}^{(3)}=\\{V_{2}^{\\Pi_{1},\\{2\\}}\\},\\mathbf{I}^{(4)}=\\{V_{1}^{\\Pi_{1},\\{1\\}},V_{2}^{\\Pi_{1},\\{2\\}}\\}\\}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Choosing ${\\bf\\cal I}^{(1)}$ as the baseline, $\\mathbf{T}=\\{\\}$ . The corresponding $\\Delta\\mathbf{Q}$ sets are $\\{\\{V_{1}\\},\\{V_{2}\\},\\{V_{1},V_{2}\\}\\}$ . Let $\\mathbf{Q}$ be the union of $\\Delta\\mathbf{Q}$ sets, which is $\\{V_{1},V_{2}\\}$ . One can verify ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\omega_{1}(\\mathbf{v},2)+\\omega_{1}(\\mathbf{v},3)=\\omega_{1}(\\mathbf{v},4)\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "since $\\mathbf{I}^{(4)}$ is designed as a combination of $\\mathbf{I}^{(2)}$ and $\\mathbf{I}^{(3)}$ . ", "page_idx": 20}, {"type": "text", "text": "We provide the following Lemma to justify Assumption 4 formally. ", "page_idx": 20}, {"type": "text", "text": "Lemma 1. Assumption 4 almost surely holds. ", "page_idx": 20}, {"type": "text", "text": "A.3 Domains vs Interventions ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In previous studies, there has been a tendency to conflate the notions of interventions and domain shifts [65\u201369]. However, it is essential to recognize their distinctiveness, particularly when considering various real-world examples spanning different scientific domains that utilize observational and interventional data. The differentiation between interventions and domains is not only conceptually significant but also holds implications for causal inference and the characterization of corresponding causal structures as noted by [32]. Moreover, it is crucial to avoid conflating these qualitatively distinct concepts of interventions and domains, as highlighted in transportability analysis [62]. Pearl and Bareinboim have introduced clear semantics for (S) nodes (environments), presenting a unified representation in the form of selection diagrams [33, 35, 36]. ", "page_idx": 20}, {"type": "text", "text": "By recognizing these differences, this work leverages any combination of observational and/or interventional data arising from multiple domains to present a general approach to disentanglement learning compared to prior work (see Table S1). Prior work generally considered either interventions in a single domain (top row in $\\Pi^{1}$ ), where there must be an intervention per latent variable [14, 21], or observational distributions from many domains $\\Pi^{1},\\Pi^{2},...,\\Pi^{N}$ (first column under \"Observational\"). However, this paper considers a general setting where we may have an arbitrary collection of interventions, or observations from any combination of domains (green section). ", "page_idx": 20}, {"type": "text", "text": "Here, we illustrate some examples of the CRID algorithm using distributions from multiple domains. ", "page_idx": 20}, {"type": "text", "text": "Example 10 (Example illustrating CRID with domains). Consider the LSD shown in Fig. 4(a). We have the following distributions $\\mathcal{P}\\,=\\,\\{P^{(1)},P^{(2)}\\}\\,=\\,\\{P^{\\Pi_{1}}(\\mathbf{X}),P^{\\Pi_{2}}(\\mathbf{X})$ from interventions $\\Sigma=\\{\\sigma^{(1)},\\sigma^{(2)}\\}=\\{\\{\\},\\{\\}\\}$ . Applying CRID algorithm, we can determine that $V_{1}$ is $I D$ wrt $V_{2}$ and $V_{3}$ . \u53e3 ", "page_idx": 20}, {"type": "text", "text": "This example illustrates that observational data in two domains can help disentangle a root variable $(V_{1})$ from all its descendants. ", "page_idx": 20}, {"type": "text", "text": "Example 11 (Example illustrating CRID with interventions across domains with different mechanisms). Consider the LSD shown in Fig. $4(a)$ . We have the following distributions $\\mathcal{P}\\;=$ $\\{P^{(1)},\\stackrel{\\cdot\\,}{\\underline{{P}}}^{(2)}\\}_{\\underline{{\\imath}}}=\\;\\;\\{P^{\\Pi_{1}}({\\bf X}),P^{\\Pi_{2}}({\\bf X})$ from interventions $\\Sigma~=~\\{\\bar{\\sigma}^{(1)},\\sigma^{(2)}\\}$ with targets $\\boldsymbol{\\Psi}=$ $\\left\\{\\left\\{V_{2}\\right\\}^{\\Pi_{1}},\\left\\{\\right\\}^{\\Pi_{2}}$ . Applying CRID algorithm, we can determine that $V_{2}$ and $V_{1}$ is $I D\\,w r t\\,V_{3}$ . \u53e3 ", "page_idx": 21}, {"type": "text", "text": "This example demonstrates that when comparing observational data from domain $\\Pi_{1}$ with interventional data from a different domain $\\Pi_{2}$ , the only invariant factor is $P(V_{3}|V_{2})$ , with $\\Delta V[\\{\\{V_{2}\\}^{\\Pi_{1}},\\{\\}^{\\Pi_{2}},G^{S}]=\\{V_{1},V_{2}\\}$ . The canceled variable is $V_{3}$ , and thus we achieve our identifiability result. ", "page_idx": 21}, {"type": "text", "text": "Example 12 (Example illustrating CRID with interventions across domains with the same mechanisms). Consider the LSD shown in Fig. 4(a). We have the following distributions $\\begin{array}{r l r}{\\mathcal{P}}&{{}=}&{\\{P^{(1)},P^{(2)},P^{(3)}\\}}\\end{array}$ from interventions $\\begin{array}{r l r}{\\sum}&{{}=}&{\\{\\sigma^{(1)},\\sigma^{(2)},\\sigma^{(3)}\\}}\\end{array}$ with targets $\\begin{array}{r l}{\\Psi}&{{}=}\\end{array}$ $\\{\\{V_{1}^{[i]},V_{2}\\}^{\\Pi_{1}},\\{\\}^{\\Pi_{2}},\\{V_{1}^{[i]}\\}^{\\Pi_{2}}$ . Applying CRID algorithm, we can determine that $V_{1}$ is $I D\\ w r t$ $\\{V_{2},V_{3}\\}$ , and $V_{2}$ is $I D$ wrt $\\{V_{3}\\}$ . \u53e3 ", "page_idx": 21}, {"type": "text", "text": "Even with an intervention that changes both $V_{1},V_{2}$ . When comparing the distributions $P^{(1)}$ and $P^{(3)}$ , the $P(V_{1})$ term becomes an invariant factor because the intervention has the same mechanism. This removes the possible difference encoded by the S-node on $V_{1}$ between domains $\\Pi^{1},\\Pi^{2}$ . ", "page_idx": 21}, {"type": "text", "text": "These examples further demonstrates the importance of distinguishing domains and interventions because a difference in mechanism is present when comparing all distributions between a pair of domains, $\\Pi_{i}\\ \\neq\\ \\Pi_{j}$ . This in principle, results in additional variables in the $\\Delta\\mathbf Q$ set. However, interventions may allow us to remove variables from this set by increasing the number of invariant factors. ", "page_idx": 21}, {"type": "text", "text": "A.4 Permutation Indeterminancy ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In the context of causal representation learning, permutation indeterminacy is a significant challenge that arises when attempting to identify latent variables from observed data. This phenomenon occurs when the ordering of latent variables is not uniquely determined, leading to multiple equivalent representations (i.e. permutations of the latent variables) that can explain the observed data equally well. ", "page_idx": 21}, {"type": "text", "text": "In the earliest results of disentangled representation learning, linear ICA was known to be identifiable only up to permutation and scaling indeterminacies [6]. Permutation indeterminacy is still present in nonlinear ICA [7], since the independent components may be permuted arbitrarily. ", "page_idx": 21}, {"type": "text", "text": "Interestingly, when generalizing the problem to the Markovian setting where latent variables have causal structure (i.e. edges in a causal graph), permutation indeterminacy can be reduced to a graph isomorphism in certain cases. That is, latent variables are exchangeable with other latent variables that preserve the topological ordering of the latent causal graph (rather than permuted with any arbitrary latent variable) [13, 22, 51]. When the interventions occur with known targets on the latent space, and intervention occurs uniquely on every latent variable, then there is no permutation indeterminacy [21]. ", "page_idx": 21}, {"type": "text", "text": "In this work, we assume intervention targets are known, but do not necessarily occur on all latent variables, and they may occur on multiple variables at once. For variables that are intervened on uniquely (i.e. one intervention applied on only that variable), there is no permutation ambiguity. For variables that are intervened on in groups, or not intervened on at all, there still exists permutation ambiguity: ", "page_idx": 21}, {"type": "text", "text": "1. (Grouped variables) These variables are all intervened on in the same group. In the context of our paper, these variables are consistently in the same $\\Delta\\mathbf Q$ set. For example, consider the following LCG $V_{1}\\to V_{2}\\leftarrow V_{3}$ . If we have distributions arising only from interventions on $\\{V_{1},\\bar{V}_{3}\\}$ and the observational distribution, and assume the learned representation is fully disentangled, then the learned representation still has a permutation indeterminacy wrt $\\{V_{1},V_{3}\\}$ . That is, $\\hat{V}_{1}$ could be the representation for $V_{1}$ , or $V_{3}$ and similarly for $\\hat{V}_{3}$ (See why permutation can hold for details in Example 18).   \n2. (Non-intervened variables) These variables do not contain any interventions. Then there is still permutation ambiguity among these variables. However, instead of a graph isomorphism ambiguity, these variables form a subgraph isomorphism problem because there may be other ", "page_idx": 21}, {"type": "text", "text": "variables that change across distributions (i.e. via interventions, or changes in domains), which are not permutable with respect to these invariant variables. ", "page_idx": 22}, {"type": "text", "text": "Specifically, the identifiability we talk about (Def. 2.3) is considered after a subgraph isomorphism permutation. For example, in the collider example setting where permutation can happen between $V_{1}$ and $V_{3}$ . The $\"V_{1}$ is ID w.r.t $\\{V_{2},V_{3}\\}^{\\prime\\prime}$ should implies there exists a function $\\tau$ such that $\\pi({\\bf V})[V_{1}]\\,=\\,\\tau(\\pi({\\bf V})[V_{1}])$ , where $\\pi(\\mathbf{V})[V_{i}]$ means variable $V_{i}$ after the permutation on $\\mathbf{V}$ and $\\pi$ denotes a permutation only in this text. In our paper, we are primarily concerned with disentanglement and determining if the learned representation is disentangled in some general sense, and the permutation part is out of our scope. ", "page_idx": 22}, {"type": "text", "text": "B CRID Algorithm Details ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Here, we provide additional pseudocode for the CRID Alg. 1. ", "page_idx": 22}, {"type": "text", "text": "First, the following algorithm illustrates how to initialize a fully connected bipartite graph $G_{\\mathbf{V},\\widehat{\\mathbf{v}}}$ . In the initial $G_{\\mathbf{V},\\widehat{\\mathbf{v}}}$ , the true underlying factors $\\mathbf{V}$ points to representations each $\\widehat V_{i}\\in\\widehat{\\mathbf V}$ , which means each variable $V_{i}\\in\\mathbf{V}$ is entangled with all other variables. ", "page_idx": 22}, {"type": "table", "img_path": "uLGyoBn7hm/tmp/9762769652129e7d624665453fc684df8e31adf9f8638cf1f66ce7c71f029b46.jpg", "table_caption": [], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "Then, after constructing $Q$ from comparisons of distributions, the Alg. F.3 illustrates the details to check whether $\\mathbf{V}\\backslash\\mathbf{Q}$ can be disentangled from $\\mathbf{Q}$ according to Proposition 3. To illustrate, each variable $Z\\,\\in\\,{\\mathbf V}\\backslash{\\mathbf Q}$ is checked one by one. The variables that have already been disentangled from $Z$ are collected in the list Mem through procedure CheckMemoize. Next, check if there is a sub-collection of $\\mathcal{Q}$ that satisfy the [1-3] conditions in Proposition 3. The checking procedure is shown in Alg.F.5. If conditions are satisfied the edges from $Z$ to $\\widehat{\\mathbf{Q}}$ are removed to demonstrate disentanglement. Based on the Lemma 2, the condition [3] in Prop. 3 can be reduced to a weaker condition [4] leveraging existing disentanglements in CDM. ", "page_idx": 22}, {"type": "text", "text": "Lemma 2. Consider variables $\\mathbf{V}^{t a r}\\subseteq\\mathbf{V}$ and $Z\\,\\in\\,\\mathbf{V}\\backslash\\mathbf{V}^{t a r}$ . Suppose $\\mathbf{Mem}\\,=\\,\\{V_{j}\\,\\in\\,\\mathbf{V}^{t a r}\\,\\mid$ $V_{j}$ is $I D\\ w.r.t.\\ Z\\}$ . Consider, $\\mathcal{P}_{\\mathbf{T}}$ and its corresponding intervention targets that hold conditions $[I\\cdot2J$ in Prop. 3. If the new version of the condition $[3J$ is also satisfied: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{[4]\\ t h e r e\\quad e x i s t s\\quad\\{a_{1}^{\\prime},\\ldots,a_{|\\mathbf{V}^{t a r}|}^{\\prime}\\}\\quad\\subseteq\\quad\\{a_{1},\\ldots,a_{L}\\}}\\\\ &{\\quad\\quad\\mathbf{V}^{t a r}\\backslash\\mathbf{Mem},V_{i}^{t a r}\\in\\Delta\\mathbf{Q}[\\mathbf{I}^{(a_{i}^{\\prime})},\\mathbf{I}^{(a_{0})},\\mathbf{T},G^{S}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "then ${\\bf V}^{t a r}$ is $I D\\,w.r.t\\,Z$ . ", "page_idx": 22}, {"type": "text", "text": "To illustrate, the above lemma indicates not all variables in ${\\bf V}^{t a r}$ needed to be covered uniquely.   \nVariables that have been already disentangled (in Mem) do not need to be considered. ", "page_idx": 22}, {"type": "text", "text": "Example 13. Consider the $L S D~G^{S}$ and intervention targets ${\\bf\\cal I}^{(1)}\\,=\\,\\{\\}$ and $\\mathbf{I}^{(4)}~=~\\{V_{2}^{\\Pi_{1},d o}\\}$ . Comparing $\\mathbf{I}^{(4)}$ and $\\mathbf{I}^{(1)}$ taking $\\mathbf{T}=\\{\\},\\,\\Delta\\mathbf{Q}=\\{V_{1},V_{2}\\}$ . Based on Prop. 3, we cannot get $V_{2}$ is $I D$ $w.r.t\\;V_{3}$ since to cover $V_{1}$ and $V_{2}$ separately, at least two $\\Delta\\mathbf{Q}$ sets are needed. ", "page_idx": 22}, {"type": "text", "text": "Now assume it is known that $V_{1}$ is $I D$ w.r.t. $V_{3}$ , namely $\\mathbf{Mem}=\\{V_{1}\\}$ . $\\Delta\\mathbf Q$ sets only need to cover $V_{2}$ and does not need to cover $V_{1}$ from condition $[4]$ in Lemma 2. Then $V_{2}$ is $I D$ w.r.t. $V_{3}$ . \u53e3 ", "page_idx": 22}, {"type": "text", "text": "Algorithm F.3 Dis\u2206QfromCancel - Check whether canceled variables $\\mathbf{V}\\backslash\\mathbf{Q}$ can be disentangled from the LQ factors $\\mathbf{Q}$ . $G_{\\mathbf{V},\\widehat{\\mathbf{v}}}$ is the current bipartite graph; $G_{\\overline{{\\mathbf{T}}}}$ is the LCG after the perfect intervention on $\\mathbf{T}$ ; $\\Psi_{\\bf X}^{\\mathrm{perf}}$ is the  intervened sets that contains perfect interventions on $\\mathbf{X};\\mathbf{I}\\in\\Psi_{\\mathbf{T}}^{\\mathrm{perf}}$ is the chosen baseline distribution; $\\mathcal{Q}$ is the collection of $\\Delta\\mathbf{Q}$ sets after comparing intervention targets $\\mathbf{J}\\in\\Psi_{\\mathbf{X}}^{\\mathrm{perf}}\\backslash\\mathbf{I}$ with the baseline. ", "page_idx": 23}, {"type": "text", "text": "Input: $\\mathbf{Q},G_{\\mathbf{V},\\widehat{\\mathbf{V}}},G_{\\overline{{\\mathbf{X}}}},\\boldsymbol{\\Psi}_{\\mathbf{X}}^{\\mathrm{perf}},\\mathbf{I},\\boldsymbol{\\mathcal{Q}}$   \nOutput: GV,V   \n1: for all $Z\\in\\mathbf{V}\\backslash\\mathbf{Q}$ do   \n2: $\\mathbf{Mem}\\gets C h e c k M e m o i z e(G_{\\mathbf{V},\\hat{\\mathbf{V}}},Z,\\mathbf{Q})$ $\\triangleright$ Variables in $\\mathbf{Q}$ has been already ID w.r.t. $Z$ . 3: if CheckConsition3 $(\\mathcal{Q},\\mathbf{Q},\\mathbf{Mem})$ then $\\triangleright$ Check conditions in Prop. 3 and Lem. 3 4: remove edge Z \u2192Q  in GV,V   \n5: return GV,V ", "page_idx": 23}, {"type": "text", "text": "Algorithm F.4 CheckMemoize: Memoization step - The variables in Q is ID w.r.t $Z$ already. ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Input: $G_{V,\\hat{V}},Z,\\mathbf{Q}$   \nOutput: Mem   \n1: $\\mathbf{\\bar{Mem}}\\gets\\{\\}$   \n2: for all $\\widehat V\\in{\\bf Q}$ do   \n3: if $Z\\rightarrow{\\widehat{V}}\\not\\in G_{\\mathbf{v},{\\widehat{\\mathbf{v}}}}$ then   \n4: Mem.appen d(V )   \n5: return Mem ", "page_idx": 23}, {"type": "text", "text": "Algorithm F.6 DisWithin $\\Delta\\mathbf{Q}$ - Check the disentanglement of variables within $\\mathbf{Q}$ . $G_{\\mathbf{V},\\widehat{\\mathbf{V}}}$ is the current bipartite graph; $G_{\\overline{{\\mathbf{T}}}}$ is the LCG after the perfect intervention on $\\mathbf{T}$ ; $\\Psi_{\\bf T}^{\\mathrm{perf}}$ is the intervened sets that contains perfect interventions on X; I \u2208\u03a8pTerfis the chosen baseline distribution; Q is the collection of $\\Delta\\mathbf{Q}$ sets after comparing intervention targets $\\mathbf{J}\\in\\Psi_{\\mathbf{X}}^{\\mathrm{perf}}\\backslash\\mathbf{I}$ with the baseline. ", "page_idx": 24}, {"type": "text", "text": "Input: $\\mathbf{Q},G_{\\mathbf{V},\\widehat{\\mathbf{V}}},G_{\\overline{{\\mathbf{T}}}},\\Psi_{\\mathbf{T}}^{\\mathrm{perf}},\\mathbf{I},\\mathcal{Q}$   \nOutput: GV,V   \n1: for for all  pair $V_{i},V_{j}\\in\\mathbf{Q}$ do   \n2: if $V_{i}\\perp V_{j}\\mid\\mathbf{Q}\\backslash\\bar{\\{V_{i},V_{j}\\}}$ then   \n3: $\\mathbf{Mem}_{i}\\leftarrow C h e c k M e m o i z e(G_{\\mathbf{V},\\widehat{\\mathbf{V}}},V_{i},\\mathbf{Q})$ $\\triangleright$ Variables in $\\mathbf{Q}$ is ID w.r.t $V_{i}$ already. 4: $\\mathbf{Mem}_{j}\\leftarrow C h e c k M e m o i z e(G_{\\mathbf{V},\\widehat{\\mathbf{V}}},V_{j},\\mathbf{Q})$ $\\triangleright$ Variables in $\\mathbf{Q}$ is ID w.r.t $V_{j}$ already. 5: if CheckConsition4 $\\mathbf{\\:\\left\\langle{Q,Q,Mem}_{\\mathrm{}i},M e m_{j},G_{\\overline{{\\mathbf{T}}}}\\right\\rangle}$ then $\\triangleright$ Check conditions in Prop. 4 and Lem. 3   \n6: remove edge $Z\\to{\\widehat{\\mathbf{Q}}}$ in $G_{\\mathbf{V},\\widehat{\\mathbf{v}}}$   \n7: return GV,V ", "page_idx": 24}, {"type": "text", "text": "Next, the Alg. F.6 illustrates the details to check whether $V_{i},V_{j}\\,\\in\\,{\\bf Q}$ such that $V_{i}$ and $V_{j}$ are independent of each other conditioning on other variables in $\\mathbf{Q}$ can be disentangled according to Proposition 4. To illustrate, two lists of variables that have already been disentangled from $V_{i}$ and $V_{j}$ are constructed as $\\mathbf{Mem}_{i}$ and $\\mathbf{Mem}_{j}$ respectively through CheckMemoize. Next, check if there is a sub-collection of $\\mathcal{Q}$ that satisfy the [1-3] conditions in Proposition 3. The checking procedure is shown in Alg.F.7. If conditions are satisfied the edges from $Z$ to $\\widehat{\\mathbf{Q}}$ are removed to demonstrate disentanglement. Based on the Lem. 3, the condition $[3^{\\circ}]$ in Prop. 4 can be reduced to a weaker condition [4\u2019] leveraging existing disentanglements in CDM. ", "page_idx": 24}, {"type": "text", "text": "Lemma 3 (ID of variables within $\\Delta\\mathbf Q$ sets). Consider variables $\\mathbf{V}^{t a r}\\subseteq\\mathbf{V}$ . For any pair of $V_{i},V_{j}\\in\\mathbf{V}^{t a r}$ such that $V_{i}\\perp\\!\\!\\!\\perp V_{j}|{\\bf V}^{t a r}\\backslash\\{V_{i},V_{j}\\}$ in $G_{\\overline{{\\mathbf{T}}}}(\\mathbf{V}^{t a r})$ , let $\\mathbf{Mem}_{i}$ be a list of variables in $\\mathbf{Q}$ that have been $I D$ w.r.t. $V_{i}$ and let $\\mathbf{Mem}_{j}$ be a list of qvariables in $\\mathbf{Q}$ that have been ID w.r.t. $V_{j}$ . If there exists $\\mathcal{P}_{\\mathbf{T}}$ that satisfies conditions $I I$ -2] in Prop. 3 and the following condition $[4\\,]$ . ", "page_idx": 24}, {"type": "text", "text": "$[4\\,]$ (Enough changes occur across distributions) Let $\\mathbf{Q}^{r e}\\,=\\,\\mathbf{V}^{t a r}\\backslash(\\mathbf{Mem}_{i}\\bigcup\\mathbf{Mem}_{j})$ ) and $d^{\\prime}=|\\mathbf{Q}^{r e}|$ . And ", "page_idx": 24}, {"type": "equation", "text": "$$\n{\\pmb\\mathscr{E}}_{i j}=\\{{\\pmb{\\epsilon}}_{j}=\\{V_{k},V_{r}\\}\\mid i)\\ \\exists a_{l},\\{V_{k},V_{r}\\}\\in\\Delta{\\bf Q}^{(a_{l}),(a_{0})};\n$$", "text_format": "latex", "page_idx": 24}, {"type": "equation", "text": "$$\n;)\\ V_{k},V_{r}\\notin\\mathbf{Mem}_{i}\\cup\\mathbf{Mem}_{j}\\}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Algorithm F.7 CheckCondition4: Check conditions in Proposition 4 and 3. $\\mathcal{Q}$ is the collection of $\\Delta\\mathbf{Q}$ sets; $\\mathbf{Q}$ are target variables; $\\mathbf{Mem}_{i}$ are variables in $\\mathbf{Q}$ have already been disentangled with $V_{i};\\mathbf{Mem}_{j}$ are variables in $\\mathbf{Q}$ have already been disentangled with $V_{j}$ ; $G_{\\overline{{\\mathbf{T}}}}$ is the diagram after removing incoming edge to $\\mathbf{T}$ . ", "page_idx": 25}, {"type": "text", "text": "Input: $\\mathcal{Q}.$ , Q, $\\mathbf{Mem}_{i}$ , $\\mathbf{Mem}_{j}$ , $G_{\\overline{{\\mathbf{T}}}}$   \nOutput: True or False   \n1: $\\bar{\\bf L}\\gets\\{\\}$   \n2: for $\\mathbf{Q}_{k}\\in\\mathcal{Q}$ do   \n3: if $\\mathbf{Q}_{k}\\subseteq\\mathbf{Q}$ then   \n4: L.append $\\mathbf{\\nabla}[\\mathbf{Q}_{k})$   \n5: $\\pmb{\\mathcal{E}}\\gets\\{\\}$   \n6: for $\\left\\{V_{k},V_{r}\\right\\}\\subseteq\\mathbf{Q}$ do   \n7: if (i) $\\exists L\\in\\mathbf{L}$ such that $\\{V_{k},V_{r}\\}\\subseteq L$ (ii) $V_{k}$ is conditionally connected to $V_{l}$ (iii) $\\{V_{k},V_{r}\\}$ \u0338\u2286   \n$\\mathbf{Mem}_{i}\\cup\\mathbf{Mem}_{j}$ then   \n8: $\\pmb{\\mathcal{E}}.a p p e n\\bar{d}((V_{k},V_{r}))$ \u25b7Construct $\\varepsilon$ according to Lem. 3   \n9: $\\mathbf{Q}^{r e+}=\\{Q_{1},\\ldots,Q_{d^{\\prime}}\\}\\gets(\\mathbf{Q}\\backslash(\\mathbf{Mem}_{i}\\cup\\mathbf{Mem}_{j}))\\cup\\mathcal{E},d^{+}$ $d^{+}\\gets|\\mathbf{Q}^{r e}|$   \n10: if Q1 $\\in\\mathbf{L}_{1},Q_{2}\\in\\mathbf{L}_{2},\\ldots,Q_{d^{\\prime}}\\in\\mathbf{L}_{d^{\\prime}}$ after a permutation of $\\mathbf{L}$ then   \n11: return True   \n12: return False ", "page_idx": 25}, {"type": "text", "text": "Lastly, we leverage the independence and current disentangled results stored in $G_{\\mathbf{V},\\widehat{\\mathbf{v}}}$ . Canceled variables with $\\mathbf{V}\\backslash\\mathbf{Q}$ can be disentangled with each other according to Proposition 5. The following algorithm illustrates this step. ", "page_idx": 25}, {"type": "table", "img_path": "uLGyoBn7hm/tmp/6326d2fbf90b1023ad48533cc3639b40d96402187a779d53f62ec7d7c7ddb2d2.jpg", "table_caption": [], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "C Proofs ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Here, we provide detailed proofs of theoretical results in the main paper. ", "page_idx": 26}, {"type": "text", "text": "C.1 \"Distribution Change Sufficiently\" - Proof of Lemma 1 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "We assume \"distributions changes sufficiently\" in Sec. 2. This assumption is formally defined in Assumption 4 and will be used as a technique assumption in the proof of propositions in this work. Lemma 1 provides the justification of this assumption. It suggests Assumption 4 almost surely holds. We first provide proof here. ", "page_idx": 26}, {"type": "text", "text": "Assumption 4 (Changing Sufficiently). Consider a collection of ASCMs M and a set of distribution $\\mathcal{P}$ induced by $\\mathbf{\\mathcal{M}}$ from a collection of interventions $\\Sigma$ . Let the LSD induced by $\\mathbf{\\mathcal{M}}$ be $G^{S}$ . Let $\\mathcal{P}_{\\mathbf{T}}=\\{P^{(a_{0})},P^{(a_{1})},\\dots,P^{(a_{L})}\\}\\subseteq\\mathcal{P}$ be any collection of distributions such that ${\\bf T}=d o[{\\bf I}^{(a_{0})}]\\subseteq$ $d o[\\mathbf{I}^{(a_{l})}]\\,f o r\\,l\\in[L]$ , meaning for the baseline distribution all perfect interventions must be exactly on $\\mathbf{T}$ , and all other distributions must at least contain $\\mathbf{T}$ in their perfect interventions. Let $\\mathbf{Q}=$ $\\bigcup_{l\\in[L]}\\Delta\\mathbf{Q}[\\mathbf{I}^{(a_{l})},\\mathbf{I}^{(0)},\\mathbf{T},G^{S}]$ (Def. 3.1). It is assumed: ", "page_idx": 26}, {"type": "text", "text": "1. The probability density function of $\\mathbf{V}$ is smooth and positive, i.e. $p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})$ is smooth and $p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})>0$ almost everywhere.   \n2. First-order discrepancy. If there exists $\\{a_{1}^{\\prime},\\ldots,a_{|\\mathbf{Q}|}^{\\prime}\\}\\subseteq\\{a_{1},\\ldots,a_{L}\\}$ such that \u2200 $V_{q}\\in$ $\\mathbf{Q},V_{q}\\in\\Delta\\mathbf{Q}[\\mathbf{I}^{(a_{q}^{\\prime})},\\mathbf{I}^{(a_{0})},\\mathbf{T},G^{S}],$ , then $\\{\\omega_{1}(\\mathbf{v},a_{1}),\\omega_{1}(\\mathbf{v},a_{2}),\\dots,\\omega_{1}(\\mathbf{v},a_{L})\\}$ are linearly independent, where ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\omega_{1}(\\mathbf{v},a_{l})=\\left(\\oplus(\\frac{\\partial\\log p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\mathbf{v})}{\\partial v_{q}})_{V_{q}\\in\\mathbf{Q}}\\right)\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "3. Second-order discrepancy. Let a set $\\varepsilon$ consist of pairs of $(V_{p},V_{q})$ such that $(V_{p},V_{q})$ appears at least in one $\\Delta\\mathbf Q$ and $V_{p}$ is connected with $V_{q}$ conditioning on $\\mathbf{V}\\backslash\\{V_{p},\\dot{V}_{q}\\}$ in $G_{\\overline{{T}}}(\\mathbf{Q})$ Namely, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{\\mathcal{E}}=\\{\\epsilon_{j}=\\{V_{k},V_{r}\\}\\mid}\\\\ {(i)\\ \\exists a_{l},\\{V_{p},V_{q}\\}\\in\\Delta\\mathbf{Q}^{(a_{l}),(a_{0})};}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\omega_{2}(\\mathbf{v},a_{l})=\\Bigg(\\oplus(\\frac{\\partial\\log p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\mathbf{v})}{\\partial v_{q}})_{V_{q}\\in\\mathbf{Q}},\\ \\ \\ \\ \\ \\ }\\\\ {\\oplus(\\frac{\\partial^{2}\\log p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\mathbf{v})}{\\partial v_{q}^{2}})_{V_{q}\\in\\mathbf{Q}},\\ \\ \\ \\ \\ \\ \\ }\\\\ {\\oplus(\\frac{\\partial^{2}\\log p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\mathbf{v})}{\\partial v_{p}v_{q}})_{(V_{p},V_{q})\\in\\mathcal{E}(G_{T}(\\mathbf{Q}))}\\Bigg)}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Lemma 1. Assumption 4 almost surely holds. ", "page_idx": 26}, {"type": "text", "text": "Proof. We will prove the first-order discrepancy and second-order discrepancy almost surely hold, which means the situations where first-order discrepancy and second-order discrepancy do not hold have Lebesgue measure 0. ", "page_idx": 26}, {"type": "text", "text": "We first consider the first-order discrepancy. Denote $\\{\\omega_{1}(\\mathbf{v},a_{1}),\\omega_{1}(\\mathbf{v},a_{2}),\\dots,\\omega_{1}(\\mathbf{v},a_{L})\\}$ as $\\mathbf{A}$ . And every entry in $\\mathbf{A}$ is ", "page_idx": 26}, {"type": "equation", "text": "$$\na_{l q}=\\frac{\\partial\\log p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\mathbf{v})}{\\partial v_{q}}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "According to Eq. (3), we know $\\log p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\mathbf{v})$ is a function of only variables in $\\Delta\\mathbf{Q}$ Thus, if $V_{q}\\,\\not\\in\\,\\Delta\\mathbf{Q}[\\mathbf{I}^{(a_{l}^{\\prime})},\\mathbf{I}^{(a_{0})},\\mathbf{T},G^{S}]$ , $a_{l q}\\,=\\,0$ ; if $V_{q}\\,\\in\\,\\Delta{\\bf Q}[{\\bf I}^{(a_{l}^{\\prime})},{\\bf I}^{(a_{0})},{\\bf T},G^{S}]$ , we assume $a_{l q}$ follows a standard normal distribution, which means the non-zero entries in matrix A are randomly sampled and are not fine-tuned. Thus, to prove this lemma, it is equivalent to prove if there exists $\\{a_{1}^{\\prime},\\ldots,a_{|\\mathbf{Q}|}^{\\prime}\\}\\subseteq\\{a_{1},\\ldots,a_{L}\\}$ such that $\\mid\\;V_{q}\\;\\in{\\bf Q},V_{q}\\;\\in\\;\\Delta{\\bf Q}[{\\bar{\\bf I}}^{(a_{q}^{\\prime})},{\\bf I}^{(a_{0})},{\\bar{\\bf T}},{\\cal G}^{S}]$ , the row of A are almost surely linear independent. W.O.L.G, we let $\\{a_{1}^{\\prime}=a_{1},\\ldots,a_{\\mathbf{Q}}^{\\prime}=a_{L}$ . Then, it is equivalent to prove that $\\mathbf{A}$ is a full rank matrix. ", "page_idx": 27}, {"type": "text", "text": "In order to prove that A is a full-rank matrix, we prove that the determinant of $\\mathbf{A}$ is almost surely non-zero. Since $\\forall\\;\\;V_{q}\\;\\in\\;{\\bf Q},V_{q}\\;\\in\\;\\Delta{\\bf Q}[{\\bf I}^{(a_{q})},{\\bf I}^{(a_{0})},{\\bf T},G^{S}]$ , there exists $\\mathbf{A}$ such that $\\operatorname*{det}(\\mathbf{A})$ is non-zero, and then $\\operatorname*{det}(\\mathbf{A})$ is non-trivial. Based on a simple algebraic lemma in [70], the subset of $\\{\\mathbf{A}\\mid\\operatorname*{det}(\\mathbf{A})=0\\}$ of the real space has Lebesgue measure 0. Then $\\operatorname*{det}(\\mathbf{A})=0$ almost surely holds. ", "page_idx": 27}, {"type": "text", "text": "The second-order discrepancy proof is similar. Denote $\\{\\omega_{2}(\\mathbf{v},a_{1}),\\omega_{2}(\\mathbf{v},a_{2}),\\dots,\\omega_{2}(\\mathbf{v},a_{L})\\}$ as $\\mathbf{B}$ . And every entry of $\\mathbf{B}$ is ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{a_{l q}=\\frac{\\displaystyle\\partial\\log p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\mathbf{v})}{\\displaystyle\\partial v_{q}},q\\leq|\\mathbf{Q}|}\\\\ &{a_{l q}=\\frac{\\displaystyle\\partial^{2}\\log p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\mathbf{v})}{\\displaystyle\\partial v_{q}^{2}},|\\mathbf{Q}|+1\\leq q\\leq2|\\mathbf{Q}|}\\\\ &{a_{l\\epsilon}=\\frac{\\displaystyle\\partial^{2}\\log p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\mathbf{v})}{\\displaystyle\\partial v_{p}\\partial v_{q}},2|\\mathbf{Q}|+1\\leq\\epsilon\\leq2|\\mathbf{Q}|+|\\mathcal{E}|,\\left\\{V_{p},V_{q}\\right\\}\\in\\mathcal{E}}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "According to Eq. (3), we know $\\log p_{\\mathbf{T}}^{(a_{l})}(\\mathbf{v})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\mathbf{v})$ is a function of only variables in $\\Delta\\mathbf{Q}$ Thus, if $V_{q}\\;\\;\\notin\\;\\Delta{\\bf Q}[{\\bf I}^{(a_{l}^{\\prime})},{\\bf I}^{(a_{0})},{\\bf T},G^{S}]$ , $a_{l q}~=~0$ ; if $V_{q}\\;\\in\\;\\Delta{\\bf Q}[{\\bf I}^{(a_{l}^{\\prime})},{\\bf I}^{(a_{0})},{\\bf T},G^{S}]$ , we assume $a_{l q}$ follows a standard normal distribution, which means the non-zero entries in matrix $\\mathbf{B}$ are randomly sampled and are not fine-tuned. If $\\{V_{p},V_{q}\\}\\;\\;\\mathcal{Q}\\;\\;\\Delta\\mathbf{Q}[\\mathbf{I}^{(a_{l}^{\\prime})},\\mathbf{I}^{(a_{0})},\\mathbf{T},G^{S}]$ , $a_{l\\epsilon}\\;=\\;0$ ; if $\\{V_{p},V_{q}\\}\\subseteq\\Delta\\mathbf{Q}[\\mathbf{I}^{(a_{l}^{\\prime})},\\mathbf{I}^{(a_{0})},\\mathbf{T},G^{S}]$ , we assume $a_{l\\epsilon}$ follows a standard normal distribution, which means the non-zero entries in matrix $\\mathbf{B}$ are randomly sampled and are not fine-tuned. Following the same discussion above, the subset of $\\{\\mathbf{B}\\mid\\operatorname*{det}(\\mathbf{B})=0\\}$ of the real space has Lebesgue measure 0. Then $\\operatorname*{det}(\\mathbf{B})=0$ almost surely holds. \u53e3 ", "page_idx": 27}, {"type": "text", "text": "C.2 Distribution comparison - Proof of Proposition ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Proposition 1 (Distribution Comparison). Consider a pair of collections ASCMs $\\mathbf{\\mathcal{M}}$ andM that matches with the distribution $\\mathcal{P}$ resulting from interventions $\\Sigma$ and $L S D\\;G^{S}$ . Consider  two distributions $P^{\\Pi^{(j)}}(\\mathbf{X};\\sigma^{(j)})$ and $P^{\\Pi^{(k)}}(\\mathbf{X};\\sigma^{(k)})$ . Suppose perf $\\mathbf{\\rho}(\\mathbf{T})$ is in both intervention sets, then, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sum_{i}^{d}\\log p_{\\mathbf{T}}^{(j)}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})-p_{\\mathbf{T}}^{(k)}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})=\\sum_{i}^{d}\\log p_{\\mathbf{T}}^{(j)}(\\widehat{v}_{i}\\mid\\widehat{\\mathbf{pa}}_{i}^{\\mathbf{T}+})-\\log p_{\\mathbf{T}}^{(k)}(\\widehat{v}_{i}\\mid\\widehat{\\mathbf{pa}}_{i}^{\\mathbf{T}+}),\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $p_{\\mathbf{T}}^{(j)}(\\cdot)$ and $p_{\\mathbf{T}}^{(k)}(\\cdot)$ are density functions. ", "page_idx": 27}, {"type": "text", "text": "Proof. According to the ASCM definition Def .2.1, the mapping from $\\mathbf{V}$ to $\\mathbf{X}$ , and the mapping $\\mathbf{X}$ to $\\widehat{\\mathbf{V}}$ can be expressed as: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\widehat{\\mathbf{V}}=\\widehat{f}_{\\mathbf{X}}^{-1}(\\mathbf{X})=\\widehat{f}_{\\mathbf{X}}^{-1}(f_{\\mathbf{X}}(\\mathbf{V}))\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Then based on the change variable formula, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\np(\\mathbf{v})=p(\\widehat{\\mathbf{v}})|\\mathbf{J}_{\\phi}|\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $\\phi=\\hat{f}_{\\mathbf{X}}^{-1}\\circ f_{\\mathbf{X}}$ and $\\mathbf{J}_{\\phi}$ is the Jacobian matrix of $\\phi$ . Leveraging the factorization in Eq. 1 and taking log o f the above equation, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{d}\\log p_{\\mathbf{T}}(v_{i}\\mid\\mathbf{pa}^{\\mathbf{T}+})=\\sum_{i=1}^{d}\\log p_{\\mathbf{T}}(\\widehat{v}_{i}\\mid\\widehat{\\mathbf{pa}}^{\\mathbf{T}+})+\\log|\\mathbf{J}_{\\phi}|\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Subtract the above factorization of density function induced by ${\\bf\\cal I}^{(j)}$ and $\\mathbf{I}^{(k)}$ , and we have Eq.( 2). ", "page_idx": 27}, {"type": "text", "text": "Eq 2 naturally gives a connection from $\\mathbf{V}$ to $\\widehat{\\bf V}$ . Comparing two factorization for Fig. 4(c), the connection connections are made from $P(v_{1}),p(v_{2}\\phantom{\\frac{1}{3}}|\\phantom{\\frac{1}{3}}v_{1}),p(v_{3}\\phantom{\\frac{1}{3}}|\\phantom{\\frac{1}{3}}v_{2},v_{1}),P(v_{4}\\phantom{\\frac{1}{3}}|\\phantom{\\frac{1}{3}}v_{3})$ or $P(v_{1}),p(v_{3}),p(v_{2}\\mid v_{1},v_{3}),P(v_{4}\\mid v_{3})$ . ", "page_idx": 28}, {"type": "text", "text": "C.3 Invariant factors - Proof of Proposition 2 ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Proposition 2 (Invariant Factors). Consider two distributions $P^{(j)},P^{(k)}\\in\\mathcal P$ with intervention targets $\\sigma^{(j)}$ and $\\sigma^{(k)}$ containing perf $\\mathbf{\\rho}(\\mathbf{T})$ . Construct the changed variable set $\\Delta\\mathbf{V}[\\mathbf{I}^{(j)},\\mathbf{I}^{(k)},G^{S}]$ (for short $\\Delta{\\bf V}_{\\perp}$ ) with target sets ${\\bf\\cal I}^{(j)},{\\bf\\cal I}^{(k)}$ as follows: $(I)\\,V_{l}\\in\\Delta{\\bf V}\\,i f V_{l}^{\\pi_{l},\\{b_{l}\\},t_{l}}\\in{\\bf I}^{(j)}$ but $V_{l}^{\\pi_{l}^{\\prime},\\{b_{l}\\},t_{l}^{\\prime}}\\notin$ $\\mathbf{I}^{(k)}$ , or vice versa; (2) $V_{l}\\,\\in\\,\\Delta\\mathbf{V}$ if i) $S^{\\Pi^{(j)},\\Pi^{(k)}}$ point to $V_{l}$ and ii) $V_{l}^{\\pi_{l},\\{b_{l}\\},t_{l}}\\,\\notin\\,{\\bf I}^{(j)}\\cup{\\bf I}^{(k)}$ . If $V_{i}\\in\\mathbf{V}\\backslash\\mathbf{C}(\\Delta\\mathbf{V})$ , then $p_{\\mathbf{T}}^{(j)}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})=p_{\\mathbf{T}}^{(k)}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})$ (denoted invariant factors). \u53e3 ", "page_idx": 28}, {"type": "text", "text": "Proof. Consider an arbitrary order. Based on the proposition, $\\Delta\\mathbf{V}[\\mathbf{I}^{(j)},\\mathbf{I}^{(k)},G^{S}]$ includes all variables that the mechanism $f_{V}$ or exogenous $U$ possibly change when the intervention changes from $\\mathbf{I}^{(k)}$ to $\\mathbf{I}^{(j)}$ . In other words, for any $V_{l}\\in{\\mathbf V}\\backslash\\Delta{\\mathbf V}[{\\mathbf I}^{(j)},{\\mathbf I}^{(k)},G^{S}],\\,f$ $f_{V_{l}}$ and exogenous $U_{l}$ are invariant. Let $V_{i}\\in\\mathbf{V}\\backslash\\mathbf{C}(\\Delta\\mathbf{V})$ . $\\mathbf{Z}=\\mathbf{C}(V_{i})\\cup\\mathbf{P}\\mathbf{a}^{\\mathbf{T}+}$ . We have $\\mathbf{Z}\\subseteq\\mathbf{V}\\backslash\\mathbf{C}(\\Delta\\mathbf{V})$ according to the definition of C-component. ", "page_idx": 28}, {"type": "text", "text": "According to the definition of $\\mathbf{Pa}_{i}^{\\mathbf{T}^{+}}$ , we know $\\mathbf{P}\\mathbf{a}_{i}^{\\mathbf{T}^{+}}\\backslash\\mathbf{Z}=\\mathbf{P}\\mathbf{a}(\\{V_{i}\\}\\cup\\mathbf{Z})$ . Now reconsider the distribution $P^{\\Pi^{(}j)}(V_{i}\\mid\\mathbf{Pa}_{i}^{\\mathbf{T}+};\\sigma^{(j)})$ and $P^{\\Pi^{(}k)}(V_{i}\\mid\\mathbf{Pa}_{i}^{\\mathbf{T}+};\\sigma^{(k)})$ , ", "page_idx": 28}, {"type": "equation", "text": "$$\nP_{\\mathbf{T}}^{\\Pi^{(j)}}(V_{i}\\mid\\mathbf{P}\\mathbf{a}_{i}^{\\mathrm{T+}};\\sigma^{(j)})=P_{\\mathbf{T}}^{\\Pi^{j}}(V_{i},\\mathbf{Z}\\mid\\mathbf{P}\\mathbf{a}_{i}(\\{V_{i}\\}\\cup\\mathbf{Z});\\sigma^{(j)})/P_{\\mathbf{T}}^{\\Pi^{(j)}}(\\mathbf{Z}\\mid\\mathbf{P}\\mathbf{a}_{i}(\\{V_{i}\\}\\cup\\mathbf{Z});\\sigma^{(j)})\n$$", "text_format": "latex", "page_idx": 28}, {"type": "equation", "text": "$$\nP_{\\mathbf{T}}^{\\Pi^{(k)}}(V_{i}\\mid\\mathbf{P}_{a}^{\\mathbf{T}+};\\sigma^{(k)})=P_{\\mathbf{T}}^{\\Pi^{(k)}}(V_{i},\\mathbf{Z}\\mid\\mathbf{P}\\mathbf{a}_{i}(\\{V_{i}\\}\\cup\\mathbf{Z});\\sigma^{(k)})/P_{\\mathbf{T}}^{\\Pi^{(k)}}(\\mathbf{Z}\\mid\\mathbf{P}\\mathbf{a}_{i}(\\{V_{i}\\}\\cup\\mathbf{Z});\\sigma^{(k)})~,\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Since the mechanism and exogenous variables of $V_{i}$ and $\\mathbf{Z}$ are invariant, both the nominators and denominators are the same. Namely, ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P_{\\mathbf{T}}^{\\Pi^{j}}(V_{i},\\mathbf{Z}\\mid\\mathbf{Pa}_{i}(\\{V_{i}\\}\\cup\\mathbf{Z});\\sigma^{(j)})=P_{\\mathbf{T}}^{\\Pi^{k}}(V_{i},\\mathbf{Z}\\mid\\mathbf{Pa}_{i}(\\{V_{i}\\}\\cup\\mathbf{Z});\\sigma^{(k)})}\\\\ &{\\quad P_{\\mathbf{T}}^{\\Pi^{(j)}}(\\mathbf{Z}\\mid\\mathbf{Pa}_{i}(\\{V_{i}\\}\\cup\\mathbf{Z});\\sigma^{(j)})=P_{\\mathbf{T}}^{\\Pi^{(k)}}(\\mathbf{Z}\\mid\\mathbf{Pa}_{i}(\\{V_{i}\\}\\cup\\mathbf{Z});\\sigma^{(k)})}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "which implies the density functions are invariant, ", "page_idx": 28}, {"type": "equation", "text": "$$\np_{\\mathbf{T}}^{(j)}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})=p_{\\mathbf{T}}^{(k)}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "C.4 ID $\\Delta\\mathbf{Q}$ w.r.t Canceled Factors - Proof of Proposition 3 and Lemma 2 ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Proposition 3 $\\mathbf{\\delta}^{\\mathrm{TD}}$ the $\\Delta\\mathbf Q$ set w.r.t Canceled Variables). Consider variables $\\mathbf{V}^{t a r}\\subseteq\\mathbf{V}$ . Let $\\mathcal{P}_{\\mathbf{T}}\\,\\dot{=}\\,\\{P^{(a_{0})},P^{(a_{1})},\\dots,\\dot{P}^{(a_{L})}\\}\\,\\subseteq\\,\\mathcal{P}$ be a collection of distributions such that $(I)\\ \\forall\\ l\\in\\ [L]$ , ${\\bf T}\\;=\\;\\mathrm{Perf}[{\\bf{I}}^{(a_{0})}]\\;\\subseteq\\;\\mathrm{Perf}[{\\bf{I}}^{(a_{l})}]\\;^{18}$ ; (2) $\\begin{array}{r}{\\bigcup_{l\\in[L]}\\Delta\\mathbf{Q}[\\mathbf{I}^{(a_{l})},\\mathbf{I}^{(a_{0})},\\mathbf{T},G^{S}]\\,=\\,\\mathbf{V}^{t a r}}\\end{array}$ ; (3) there exists $\\{a_{1}^{\\prime},\\ldots,a_{d^{\\prime}}^{\\prime}\\}\\ \\subseteq\\ \\{a_{1},\\ldots,a_{L}\\}$ such that for all $V_{i}^{t a r}\\;\\in\\;{\\bf V}^{t a r},V_{i}^{t a r}\\;\\in\\;\\Delta{\\bf Q}[{\\bf I}^{(a_{i}^{\\prime})},{\\bf I}^{(a_{0})},{\\bf T},G^{S}],$ , where $d^{\\prime}=|\\mathbf{V}^{t a r}|$ . Then, ${\\bf V}^{t a r}$ is ID w.r.t $\\mathbf{V}\\backslash\\mathbf{V}^{t a r}$ . \u53e3 ", "page_idx": 28}, {"type": "text", "text": "Proof. We denote ${\\bf V}^{t a r}$ as $\\mathbf{Q}$ for convenience. Notice that the Assumption 4 will be used in the proof. ", "page_idx": 28}, {"type": "text", "text": "Comparing ${\\cal P}^{\\Pi^{(a_{l})}}({\\bf V};\\sigma^{(a_{l})})$ with ${\\cal P}^{\\Pi^{(a_{0})}}({\\bf V};\\sigma^{(a_{0})})$ , we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{i\\in\\bar{\\Psi}}\\log p_{\\mathbf{T}}^{(a_{i})}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})-p_{\\mathbf{T}}^{a_{0}}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})=\\sum_{V_{i}\\in\\bar{\\Psi}}\\log p_{\\mathbf{T}}^{(a_{i})}(\\widehat{v_{i}}\\mid\\widehat{\\mathbf{pa}}_{i}^{\\mathbf{T}+})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\widehat{v_{i}}\\mid\\widehat{\\mathbf{pa}}_{i}^{\\mathbf{T}+})}}\\\\ &{}&{=\\log p_{\\mathbf{T}}^{(a_{i})}(\\widehat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\widehat{\\mathbf{v}})}\\\\ &{}&{=\\log p_{\\mathbf{T}}^{(a_{i})}(\\widehat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\widehat{\\mathbf{v}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "from Eq. (3). ", "page_idx": 29}, {"type": "text", "text": "Notice that the left side only involves variables in $\\begin{array}{r}{\\mathbf{Q}=\\bigcup_{l\\in[L]}\\Delta\\mathbf{Q}[\\mathbf{I}^{(a_{l})},\\mathbf{I}^{(a_{0})},\\mathbf{T},G^{S}]}\\end{array}$ based on the Def. 3.1. Thus, for any $Z\\in\\mathbf{V}\\backslash\\mathbf{Q}$ , ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\forall l\\in[L],\\frac{\\partial\\log p_{\\mathbf{T}}^{(a_{l})}(\\widehat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\widehat{\\mathbf{v}})}{\\partial\\widehat{z}}=0\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Take partial of the above equation w.r.t. $Z$ , we have: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\forall l\\in[L],0=\\displaystyle\\sum_{v_{i}\\in\\mathbf{V}}\\frac{\\partial\\log p_{\\mathbf{T}}^{(a_{l})}(\\widehat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\widehat{\\mathbf{v}})}{\\partial\\widehat{v}_{i}}\\frac{\\partial\\widehat{v}_{i}}{\\partial z}}\\\\ {=\\displaystyle\\sum_{v_{q}\\in\\mathbf{Q}}\\frac{\\partial\\log p_{\\mathbf{T}}^{(a_{l})}(\\widehat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\widehat{\\mathbf{v}})}{\\partial\\widehat{v}_{q}}\\frac{\\partial\\widehat{v}_{q}}{\\partial z}}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Eq. (27) is a linear system for unknowns $\\{\\partial\\widehat{V}_{q}/\\partial Z\\}_{V_{q}\\in{\\bf Q}}$ . When distribution changes sufficiently, namely under Assumption 4, the row factor of the coefficient matrix of the linear system is linearly independent. When $L\\geq|\\mathbf{Q}|$ (implied by condition [3]), the matrix is full rank, thus, ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\forall\\,V_{q}\\in\\mathbf{Q},\\frac{\\partial\\widehat{v}_{q}}{\\partial z}=0\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Recall that $V_{q}=\\phi_{V_{q}}(\\mathbf{V})$ . For any $Z\\in\\mathbf{V}\\backslash\\mathbf{Q}$ , Eq.( 28) holds. Thus, $\\mathbf{Q}$ is enough to be the input of $\\phi_{V_{q}}$ , which means there exists $V_{q}=\\phi_{V_{q}}(\\mathbf{Q})$ . ", "page_idx": 29}, {"type": "text", "text": "Lemma 2. Consider variables $\\mathbf{V}^{t a r}\\subseteq\\mathbf{V}$ and $Z\\,\\in\\,\\mathbf{V}\\backslash\\mathbf{V}^{t a r}$ . Suppose $\\mathbf{Mem}\\,=\\,\\{V_{j}\\,\\in\\,\\mathbf{V}^{t a r}\\,\\mid$ $V_{j}$ is $I D\\ w.r.t.\\ Z\\}$ . Consider, $\\mathcal{P}_{\\mathbf{T}}$ and its corresponding intervention targets that hold conditions $[I\\cdot2J$ in Prop. 3. If the new version of the condition $[3J$ is also satisfied: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\mathbf{V}^{t a r}\\backslash\\mathbf{Mem},V_{i}^{t a r}\\in\\Delta\\mathbf{Q}[\\mathbf{I}^{\\tau a_{i}},\\mathbf{I}^{(a_{0})},\\mathbf{T},G^{S}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "then ${\\bf V}^{t a r}$ is ID w.r.t Z. ", "page_idx": 29}, {"type": "text", "text": "Proof. For all $V_{m}\\,\\in\\,\\mathbf{Mem}$ , $\\partial V_{m}/\\partial Z=0$ . Thus, the unknown in Eq.( 27) exclude $\\frac{\\partial v_{m}}{\\partial z}$ . Then, when [3\u2019] holds, the system will have zero solutions and Eq.( 28) will hold. ", "page_idx": 29}, {"type": "text", "text": "C.5 ID within $\\Delta\\mathbf{Q}$ set - Proof of Proposition 4 and Lemma ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "The next result provides us with an additional way of disentangling latent variables within the same $\\Delta\\mathbf{Q}$ -factor leveraging second-order conditions and conditional independence. We will first prove the following stronger result. ", "page_idx": 29}, {"type": "text", "text": "Definition 6.1 (Markov Network). Let $M_{V}$ be the Markov network over variables $\\mathbf{V}$ with vertices $\\{V_{i}\\}_{i=1}^{n}$ and ${\\mathcal{E}}(M_{V})$ denote the set of edges. An edge $(V_{i},V_{j})$ is added to ${\\mathcal{E}}(M_{V})$ if $V_{i}\\underline{{\\sf{\\sigma}}}\\underline{{\\sf{1}}}\\underline{{\\sf{\\sigma}}}V_{j}|{\\bf{V}}\\backslash\\{V_{i},V_{j}\\}$ . \u53e3 ", "page_idx": 29}, {"type": "text", "text": "Proposition 6 $\\mathbf{D}$ of variables within $\\Delta\\mathbf{Q}$ sets). Consider the variables $\\mathbf{V}^{t a r}\\subseteq\\mathbf{V}$ . Define $\\varepsilon$ as the set of edges within the Markov Network of $G_{\\overline{{\\mathbf{T}}}}(\\mathbf{V}^{t a r})$ that are contained within a $\\Delta\\mathbf{Q}$ set. ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{\\mathcal{E}}=\\lbrace\\epsilon_{j}=\\lbrace V_{k},V_{r}\\rbrace\\bigg|\\qquad\\qquad}\\\\ {(i)\\ \\exists a_{l},\\lbrace V_{k},V_{r}\\rbrace\\subseteq\\Delta\\mathbf{Q}^{(a_{l}),(a_{0})};}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "For any pair of $V_{i},V_{j}\\,\\in\\,{\\bf V}^{t a r}$ such that $V_{i}\\;\\bot\\;V_{j}\\;\\mid\\;{\\bf V}^{t a r}\\backslash\\{V_{i},V_{j}\\}$ in $G_{\\overline{{\\mathbf{T}}}}(\\mathbf{V}^{t a r})$ , if there exists $\\mathcal{P}_{\\mathbf{T}}=\\{P^{(a_{0})},P^{(a_{1})},\\dots,P^{(a_{L})}\\}\\subseteq\\mathcal{P}$ that satisfies conditions (1-2) in Prop. 3 and the following condition $(3^{\\,\\cdot})$ . ", "page_idx": 30}, {"type": "text", "text": "$(3^{\\,\\cdot})$ Enough changes occur across distributions, i.e., Formally, there exists $\\{a_{1}^{\\prime},\\ldots,a_{2d^{\\prime}+|\\pmb{\\varepsilon}|}^{\\prime}\\}\\in$ $\\{a_{1},\\ldots,a_{L}\\}$ such that for all $V_{i}^{t a r}~\\in~{\\bf V}^{t a r},$ , i) $V_{i}^{t a r}~~\\in~{\\Delta\\bf Q}^{(a_{i}^{\\prime}),(a_{0})}$ , ii) $V_{i}^{t a r}\\:\\:\\in\\:\\:$ $\\Delta\\mathbf{Q}^{\\left(a_{d^{\\prime}+i}^{\\prime}\\right),\\left(a_{0}\\right)}$ , and iii) for all $\\pmb{\\epsilon}_{j}\\in\\pmb{\\mathcal{E}},\\pmb{\\epsilon}_{j}\\subseteq\\Delta\\mathbf{Q}^{(a_{2d^{\\prime}+j}^{\\prime}),(a_{0})}$ , where $d^{\\prime}=|\\mathbf{V}^{t a r}|$ ", "page_idx": 30}, {"type": "text", "text": "then, $V_{i}$ is $I D$ w.r.t. $V_{j}$ . ", "page_idx": 30}, {"type": "text", "text": "Proof. We denote ${\\bf V}^{t a r}$ as $\\mathbf{Q}$ for convenience. Notice that Assumption 4 will be used in the proof. From Eq. 3, we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i\\in\\bar{\\Psi}}\\log p_{\\mathbf{T}}^{(a_{l})}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})-p_{\\mathbf{T}}^{a_{0}}(v_{i}\\mid\\mathbf{pa}_{i}^{\\mathbf{T}+})=\\displaystyle\\sum_{V_{i}\\in\\bar{\\Psi}}\\log p_{\\mathbf{T}}^{(a_{l})}(\\widehat{v_{i}}\\mid\\widehat{\\mathbf{pa}}_{i}^{\\mathbf{T}+})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\widehat{v_{i}}\\mid\\widehat{\\mathbf{pa}}_{i}^{\\mathbf{T}+})}\\\\ &{\\quad\\llangle v}\\\\ &{\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\log p_{\\mathbf{T}}^{(a_{l})}(\\widehat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\widehat{\\mathbf{v}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Notice that the left side only involves variables in $\\begin{array}{r}{\\mathbf{Q}=\\bigcup_{l\\in[L]}\\Delta\\mathbf{Q}[\\mathbf{I}^{(a_{l})},\\mathbf{I}^{(a_{0})},\\mathbf{T},G^{S}]}\\end{array}$ based on the Def. 3.1. ", "page_idx": 30}, {"type": "text", "text": "We first argue that if $V_{i}\\perp\\!\\!\\!\\perp V_{j}|\\mathbf{Q}\\backslash\\{V_{i},V_{j}\\}$ in $G_{\\overline{{\\mathbf{T}}}}$ then $V_{i}\\not\\in{\\bf P}a_{j}^{{\\bf T}+},V_{j}\\not\\in{\\bf P}a_{i}^{{\\bf T}+}$ and $V_{i},V_{j}\\not\\in{\\bf P}a_{m}^{{\\bf T}+}$ for any . ", "page_idx": 30}, {"type": "text", "text": "First, since $V_{i}\\perp\\perp V_{j}|\\mathbf{Q}\\backslash\\{V_{i},V_{j}\\}$ , $V_{i}$ and $V_{j}$ cannot be directly connected by edges in $G_{\\overline{{\\mathbf{T}}}}$ , which implies $V_{i}\\not\\in{\\bf C}(V_{j})$ and $V_{i}\\not\\in{\\bf P a}^{{\\bf T}+}(V_{j})$ . Also, the outgoing edge from $V_{i}$ and $V_{j}$ cannot point to the same C-component. Otherwise, the path is active from $V_{i}$ and $V_{j}$ is active when conditioning on other variables (collider structure). Thus, $V_{i}\\notin\\mathbf{P}a_{j}^{\\mathbf{T}+},V_{j}\\notin\\mathbf{P}a_{i}^{\\mathbf{T}+}$ and $V_{i},V_{j}\\notin{\\bf P}a_{k}^{{\\bf T}+}$ where $V_{k}\\in\\mathbf{Q}$ This implies $V_{i}$ and $V_{j}$ will not appear to the same factor $p_{\\mathbf{T}}^{(a_{l})}(v_{m}\\mid\\mathbf{pa}_{m}^{\\mathbf{T}+})$ for any $V_{m}\\in\\tilde{\\mathbf{V}}$ . Thus, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\frac{\\partial^{2}\\log p_{\\mathbf{T}}^{(a_{l})}(v_{m}\\mid\\mathbf{pa}_{m}^{\\mathbf{T}+})}{\\partial v_{i}v_{j}}=0\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Thus, for any pair of $V_{k},V_{r}$ such that $V_{k}\\perp\\!\\!\\!\\perp V_{r}|\\mathbf{Q}\\backslash\\{V_{k},V_{r}\\}$ , ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\forall l\\in[L],\\displaystyle\\sum_{V_{m}\\in\\Tilde{V}}\\frac{\\partial^{2}\\log p_{\\mathbf{T}}^{(a_{l})}(\\widehat{v}_{m}\\mid\\mathbf{p}\\mathbf{a}_{m}^{\\mathrm{T+}})}{\\partial\\widehat{v}_{k}\\widehat{v}_{r}}}\\\\ &{\\qquad\\qquad=\\frac{\\partial^{2}\\log p_{\\mathbf{T}}^{(a_{l})}(\\widehat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\widehat{\\mathbf{v}})}{\\partial\\widehat{v}_{k}\\widehat{v}_{r}}=0}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "On the other hand, when either $V_{k}$ or $V_{r}$ is in $\\mathbf{Q}\\backslash\\Delta\\mathbf{Q}^{(a_{l}),(a_{0})}$ for $l\\in[L]$ , ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\forall l\\in[L],=\\frac{\\partial^{2}\\log p_{\\mathbf{T}}^{(a_{l})}(\\widehat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\widehat{\\mathbf{v}})}{\\partial\\widehat{v}_{k}\\widehat{v}_{r}}=0\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "since ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\frac{\\partial p_{\\mathbf{T}}^{(a_{l})}(\\widehat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\widehat{\\mathbf{v}})}{\\partial\\widehat{v}_{k}}=0\\;\\;\\;\\;\\;\\mathrm{or}\\;\\;\\;\\;\\;\\;\\frac{\\partial p_{\\mathbf{T}}^{(a_{l})}(\\widehat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\widehat{\\mathbf{v}})}{\\partial\\widehat{v}_{r}}=0\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Upon Eq. (31), taking the second partial derivative on both sides of Eq. (30), the left side will be 0, and then $\\forall\\,l\\in[L]$ , we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n0=\\sum_{V_{k},V_{r}\\in\\mathbf{Q}}\\frac{\\partial\\log p_{\\mathbf{T}}^{(a_{l})}(\\widehat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\widehat{\\mathbf{v}})}{\\partial\\widehat{v}_{k}\\widehat{v}_{r}}\\frac{\\partial\\widehat{v}_{k}}{\\partial v_{i}}\\frac{\\widehat{v}_{r}}{\\partial v_{j}}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\frac{\\partial^{2}\\log p_{\\mathbf{T}}^{(a)}(\\hat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a)}(\\hat{\\mathbf{v}})}{\\partial\\hat{v}_{i}^{2}}\\frac{\\partial\\hat{v_{i}}}{\\partial v_{i}}\\frac{\\partial\\hat{v_{i}}}{\\partial v_{j}}+\\frac{\\partial^{2}\\log p_{\\mathbf{T}}^{(a)}(\\hat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a)}(\\hat{\\mathbf{v}})}{\\partial\\hat{v}_{j}^{2}}\\frac{\\partial\\hat{v_{j}}}{\\partial v_{i}}\\frac{\\partial\\hat{v_{j}}}{\\partial v_{j}}}\\\\ &{+\\displaystyle\\sum_{V_{q}\\in\\mathbf{Q}}\\frac{\\partial^{2}\\log p_{\\mathbf{T}}^{(a)}(\\hat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\hat{\\mathbf{v}})}{\\partial\\hat{v_{q}}}\\frac{\\partial\\hat{v_{q}}}{\\partial v_{i}}\\frac{\\partial\\hat{v_{q}}}{\\partial v_{j}}}\\\\ &{+\\displaystyle\\sum_{V_{q}\\in\\mathbf{Q}}\\frac{\\partial\\log p_{\\mathbf{T}}^{(a_{1})}(\\hat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\hat{\\mathbf{v}})}{\\partial\\hat{v}_{q}}\\frac{\\partial^{2}\\hat{v_{q}}}{\\partial v_{i}}}\\\\ &{+\\displaystyle\\sum_{(V_{k},V_{r})\\in\\mathcal{E}}\\frac{\\partial\\log p_{\\mathbf{T}}^{(a_{1})}(\\hat{\\mathbf{v}})-\\log p_{\\mathbf{T}}^{(a_{0})}(\\hat{\\mathbf{v}})}{\\partial\\hat{v}_{k}\\hat{v}_{r}}\\frac{\\hat{v}_{r}}{\\partial v_{i}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Eq.( 36) is also a linear system. When distribution changes sufficiently, namely under Assumption 4, the row factor of the coefficient matrix of the linear system is linearly independent. When $L\\geq2|\\mathbf{Q}|+\\delta_{\\mathcal{L}}$ (implied by condition 4), the matrix is full rank, thus, ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\frac{\\partial\\widehat{v_{i}}}{\\partial v_{i}}\\frac{\\partial\\widehat{v_{i}}}{\\partial v_{j}}=0,\\frac{\\partial\\widehat{v_{j}}}{\\partial v_{i}}\\frac{\\partial\\widehat{v_{j}}}{\\partial v_{j}}=0\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Then we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\frac{\\partial\\widehat{v}_{i}}{\\partial v_{j}}=0,\\frac{\\partial\\widehat{v}_{i}}{\\partial v_{j}}=0\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "up to a permutation of $V_{i}$ and $V_{j}$ . This implies that $V_{i}$ is $\\mathrm{ID}$ w.r.t $V_{j}$ and $V_{j}$ is $\\mathrm{ID}$ w.r.t $V_{i}$ . ", "page_idx": 31}, {"type": "equation", "text": "$\\Delta\\mathbf{Q}^{(a_{1}),(a_{0})}=\\cdot\\cdot\\cdot=\\Delta\\mathbf{Q}^{(a_{L}),(a_{0})}\\mathbf{V}^{t a r}$ ", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Then we can get Prop. 4 directly from the above result. ", "page_idx": 31}, {"type": "text", "text": "Proposition 4 (ID of variables within $\\Delta\\mathbf Q$ sets). Consider the variables $\\mathbf{V}^{t a r}\\subseteq\\mathbf{V}$ , $\\mathcal{P}_{\\mathbf{T}}$ that satisfies conditions $(I)$ in Prop. 3 and $\\Delta\\mathbf{Q}^{(a_{l}),(a_{0})}=\\dot{\\mathbf{V}}^{t a r}$ , for $l\\in[L]$ . For any pair of $V_{i}$ $\\mathbf{\\Delta},V_{j}\\in\\mathbf{V}^{t a r}$ such that $V_{i}$ \u22a5\u22a5 $V_{j}|\\mathbf{V}^{t a r}\\backslash\\{V_{i},V_{j}\\}$ in $G_{\\overline{{\\mathbf{T}}}}(\\mathbf{V}^{t a r})$ , $V_{i}$ is $I D$ w.r.t. $V_{j}$ if $L\\,\\geq\\,2|\\mathbf{V}^{t a r}|+^{\\underbar{\\mathbf{\\alpha}}}\\delta_{\\substack{\\nmid\\mathbf{\\alpha}}}$ , where $\\delta_{\\mathcal{L}}$ is the number of pair $V_{k},V_{r}\\in\\mathbf{V}^{t a r}$ such that $V_{k}$ and $V_{r}$ are connected given $\\mathbf{V}^{t a r}\\backslash\\{V_{k},V_{r}\\}$ in $G_{\\overline{{\\mathbf{T}}}}(\\mathbf{V}^{t a r})$ . \u53e3 ", "page_idx": 31}, {"type": "text", "text": "Proof. Taking $\\Delta\\mathbf{Q}^{(a_{1}),(a_{0})}=\\cdots=\\Delta\\mathbf{Q}^{(a_{L}),(a_{0})}\\mathbf{V}^{t a r}$ , the condition (2) is satisfied. When $L\\geq$ $2|\\mathbf{V}^{i a r}|+\\delta_{\\mathcal{L}}$ , condition (3) is satisfied. Thus, Prop. 4 holds. ", "page_idx": 31}, {"type": "text", "text": "Lemma 3 (ID of variables within $\\Delta\\mathbf Q$ sets). Consider variables $\\mathbf{V}^{t a r}\\subseteq\\mathbf{V}$ . For any pair of $V_{i},V_{j}\\in\\mathbf{V}^{t a r}$ such that $V_{i}\\perp\\perp V_{j}|\\mathbf{V}^{t a r}\\backslash\\{V_{i},V_{j}\\}$ in $G_{\\overline{{\\mathbf{T}}}}(\\mathbf{V}^{t a r})$ , let $\\mathbf{Mem}_{i}$ be a list of variables in $\\mathbf{Q}$ that have been $I D$ w.r.t. $V_{i}$ and let $\\mathbf{Mem}_{j}$ be a list of qvariables in $\\mathbf{Q}$ that have been $I D$ w.r.t. $V_{j}$ . If there exists $\\mathcal{P}_{\\mathbf{T}}$ that satisfies conditions $[I\\cdot2J$ in Prop. 3 and the following condition $[4\\,]$ . ", "page_idx": 31}, {"type": "text", "text": "$[4\\,]$ (Enough changes occur across distributions) Let $\\mathbf{Q}^{r e}\\,=\\,\\mathbf{V}^{t a r}\\backslash(\\mathbf{Mem}_{i}\\cup\\mathbf{Mem}_{j})$ ) and $d^{\\prime}=|\\mathbf{Q}^{r e}|$ . And ", "page_idx": 31}, {"type": "equation", "text": "$$\n{\\pmb\\mathscr{E}}_{i j}=\\{{\\pmb{\\epsilon}}_{j}=\\{V_{k},V_{r}\\}\\mid i)\\ \\exists a_{l},\\{V_{k},V_{r}\\}\\in\\Delta{\\bf Q}^{(a_{l}),(a_{0})};\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\nV_{k},V_{r}\\notin\\mathbf{Mem}_{i}\\cup\\mathbf{Mem}_{j}\\}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. The unknown in the linear system ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\frac{\\partial\\widehat{v}_{q}}{\\partial v_{i}}\\frac{\\partial\\widehat{v}_{q}}{\\partial v_{j}}=0,\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "if $V_{p}$ is ID w.r.t $V_{i}$ or $V_{q}$ is $\\mathrm{ID}$ w.r.t $V_{j}$ . ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\frac{\\partial^{2}\\widehat{v}_{q}}{\\partial v_{i}v_{j}}=0\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "If $V_{q}$ is $\\mathrm{ID}$ w.r.t $V_{i}$ or $V_{j}$ . Even these terms are excluded in [4\u2019], the system still has the zero solutions. ", "page_idx": 32}, {"type": "text", "text": "C.6 ID-reverse of existing disentangled variables - Proof of Proposition 5 ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "The next Proposition provides an additional tool to achieve identifiability and leverages the fact that other variables may have previously been disentangled and independence relationships in the factorization. ", "page_idx": 32}, {"type": "text", "text": "Proposition 5 (ID of canceled variables w.r.t. $\\Delta\\mathbf{Q}$ sets). Suppose $\\Psi$ contains perf $\\mathbf{\\rho}(\\mathbf{T})$ . Given $\\mathbf{V}\\backslash\\bar{V}^{t a r}$ is $I D$ w.r.t. a single variable $V^{t a r}$ , $V^{t a r}$ is $I D$ w.r.t. $\\mathbf{V}\\backslash{\\bar{V}}^{t a r}\\,i f V^{t a r}\\perp\\!\\!\\!\\perp\\,\\mathbf{V}\\backslash{\\bar{V}}^{t a r}\\,i r$ $G_{\\overline{{\\mathbf{T}}}}$ . \u53e3 ", "page_idx": 32}, {"type": "text", "text": "Proof. We first introduce a lemma for distribution preserving from [20]. ", "page_idx": 32}, {"type": "text", "text": "Lemma 4 (Lemma 2 of [20]). Let $A=C=R$ and $B=\\mathbb{R}^{n}$ . Let $f:A\\times B\\to C$ be differentiable. Define differentiable measures $P_{A}$ on $A$ and $P_{C}$ on $C$ . Let $\\forall b\\in B$ , $f(\\cdot,b):A\\rightarrow C$ be measurepreserving. Then $f$ is constant in $b$ . ", "page_idx": 32}, {"type": "text", "text": "Denote $\\mathbf{V}\\backslash\\mathbf{V}^{t a r}$ as $\\mathbf{Z}.~V^{t a r}\\perp\\!\\!\\!\\perp\\mathbf{Z}$ in $G_{\\overline{{\\mathbf{T}}}}$ implies that ", "page_idx": 32}, {"type": "equation", "text": "$$\nP_{\\mathbf{T}}(\\mathbf{V})=P_{\\mathbf{T}}(V^{t a r})P_{\\mathbf{T}}(\\mathbf{Z})\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "With the change of variable formulation and taking log: ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\log p_{\\mathbf{T}}(\\mathbf{v}^{t a r})+\\log p_{\\mathbf{T}}(\\mathbf{z})=\\log p_{\\mathbf{T}}(\\widehat{\\mathbf{v}}^{t a r})+\\log p_{\\mathbf{T}}(\\widehat{\\mathbf{z}})+\\log|\\mathbf{J}_{\\phi}|\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Since $\\mathbf{Z}$ is ID w.r.t $V^{t a r}$ , $\\partial\\widehat{\\mathbf{Z}}/\\partial\\mathbf{V}^{t a r}=0$ . In other words, the elements $\\partial\\phi_{Z}/\\partial\\mathbf{V}^{t a r}=0$ for every $Z\\in\\mathbf{Z}$ in Jacobian matrix are 0, where $\\phi_{Z}$ is a function mapping from $\\mathbf{V}$ to $\\widehat{Z}$ . Then ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\log|\\mathbf{J}_{\\phi}|=\\log|\\mathbf{J}_{\\mathbf{Z}}|+\\log|\\mathbf{J}_{\\mathbf{V}^{t a r}}|\n$$", "text_format": "latex", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{where}\\quad|\\mathbf{J}_{\\mathbf{Z}}|}&{=\\begin{array}{c c c c c}{\\left[\\begin{array}{c c c c c}{\\partial\\phi_{Z_{1}}/\\partial z_{1}}&{\\partial\\phi_{Z_{1}}/\\partial z_{2}}&{\\ldots}&{\\partial\\phi_{Z_{1}}/\\partial z_{d-1}}\\\\ {\\partial\\phi_{Z_{2}}/\\partial z_{1}}&{\\partial\\phi_{Z_{2}}/\\partial z_{2}}&{\\ldots}&{\\partial\\phi_{Z_{2}}/\\partial z_{d-1}}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {\\partial\\phi_{Z_{d-1}}/\\partial z_{1}}&{\\partial\\phi_{Z_{d-1}}/\\partial z_{2}}&{\\ldots}&{\\partial\\phi_{Z_{d-1}}/\\partial z_{d-1}}\\end{array}\\right]}&{\\mathrm{and}\\quad\\mathrm{log}\\ |\\mathbf{J}_{\\mathbf{V}^{t a r}}|}\\end{array}}&{=\\begin{array}{c}{\\hat{F}_{\\mathbf{X}}}\\\\ {\\hat{F}_{\\mathbf{X}}}\\end{array}}\\\\ {\\mid\\partial\\phi_{V^{t a r}}/\\partial v^{t a r}\\rvert.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "Again, since $\\mathbf{Z}$ is $\\mathrm{ID}$ w.r.t ${\\bf V}^{t a r}$ , $\\widehat{\\mathbf{Z}}=\\phi_{\\mathbf{Z}}(\\mathbf{Z})$ . Thus, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\log p_{\\mathbf{T}}(\\mathbf{z})=\\log p_{\\mathbf{T}}(\\widehat{\\mathbf{z}})+\\log\\left|\\mathbf{J}_{\\mathbf{Z}}\\right|\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Subtracting this to Eq. (42) ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\log p_{\\mathbf{T}}(v^{t a r})=\\log p_{\\mathbf{T}}(\\widehat{v}^{t a r})+\\log|\\mathbf{J}_{\\mathbf{V}^{t a r}}|\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Denote $\\phi_{\\mathbf{V}^{t a r}}(\\mathbf{z},\\cdot)$ as $\\phi_{\\mathbf{V}^{t a r}}^{\\mathbf{z}}(\\cdot)$ , which is the function $\\phi_{\\mathbf{V}^{t a r}}$ fixing value $\\mathbf{Z}=\\mathbf{z}$ mapping from ${\\bf V}^{t a r}$ to $\\widehat{\\bf V}$ . This suggests for every $\\mathbf{z}$ , ", "page_idx": 32}, {"type": "equation", "text": "$$\nP_{\\mathbf{T}}(\\widehat{V}^{t a r})=P_{\\mathbf{T}}(\\phi_{V^{t a r}}^{\\mathbf{z}}(V^{t a r}))\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Apply Lemma 2 of [20], $\\phi_{V^{t a r}}$ should be a constant regarding $\\mathbf{Z}$ . Thus, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\forall\\,Z\\in{\\mathbf{Z}},\\frac{\\partial V^{t a r}}{\\partial Z}=0\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "C.7 Soundness of LatentID Algorithm - Proof of Thm. 1 ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "The following provides the proof of the soundness of our proposed graphical algorithm for determining whether or not two variables are disentangleable given a collection of distributions from multiple domains and interventions. ", "page_idx": 33}, {"type": "text", "text": "Theorem 1 (Soundness of CRID). Consider a LSD $G^{S}$ and intervention targets $\\Psi$ . Consider the target variables ${\\bf V}^{t a r}$ and ${\\bf V}^{e n}\\subseteq{\\bf V}\\backslash{\\bf V}^{t a r}$ . If no edges from ${\\bf V}^{t a r}$ points to $\\widehat{\\mathbf{V}}^{e n}$ in the output causal disentanglement map (CDM) from CRID, $G_{V,\\widehat{V}}$ , then ${\\bf V}^{t a r}$ is $I D\\;w.r{t}\\;{\\bf V}^{e n}$ . \u53e3 ", "page_idx": 33}, {"type": "text", "text": "Proof. In LatentID, for each epoch, we iterate to choose $\\mathbf{T}$ and the baseline distribution to execute procedure Alg. F.3 and Alg. F.6. Any time an edge is removed, Proposition 3 and/or 4 are applied. At the end of epoch, Alg. F.8 is executed and edges will be removed only if Proposition 5 is applied. Thus the edge removals are all sound. The algorithm will stop when no edge will be removed, and terminate giving the causal disentanglement map $G_{V,\\hat{V}}$ , which is a valid summary of what is disentangleable. \u53e3 ", "page_idx": 33}, {"type": "image", "img_path": "uLGyoBn7hm/tmp/9ad17fc212bc5e24c205cfe3ac0d7d9d13c1742f49f545fee15b9f1d4f5dc380.jpg", "img_caption": ["Figure S3: Latent causal graph and the desired causal disentanglement map. "], "img_footnote": [], "page_idx": 34}, {"type": "text", "text": "D Examples and Discussion ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "D.1 Additional Example Illustrating Motivation of Causal Disentangled Learning ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "In the introduction, we illustrated a medical example for why it is important to learn disentangled representations. ", "page_idx": 34}, {"type": "text", "text": "An additional motivating example can be seen through the lens of generating realistic face images [27]. Consider an image dataset of human faces. Based on our understanding of anatomy and facial expressions, we know that both Gender and Age are not causally related, while age does directly affect HairColor. There is a strong spurious correlation between age and gender, where there are many old males and young females in the dataset. In addition, let there be face images from both a senior and teen center building. The change in domain (i.e. population center) impacts the age distribution, as senior center faces are older than teen center faces. Given these images and knowledge of the latent causal graph, one would ultimately like to generate realistic face images given perturbations of $A g e$ . If the variable representations are entangled, then it is possible for changes in age to also spuriously change gender. This is undesirable, and thus our goal is to achieve disentanglement of age and gender. Note that we do not require $A g e$ to be disentangled from HairColor necessarily since changing Age and also simultaneously changing Haircolor would be a realistic image generation. Here, we would seek a causal disentanglement map shown in Fig. S3. ", "page_idx": 34}, {"type": "image", "img_path": "uLGyoBn7hm/tmp/b4e771bba573144d6b4f24fbb64a3790969bc21c50a793d3822be8472340e614.jpg", "img_caption": ["Figure S2: The disentanglement requirements in face examples "], "img_footnote": [], "page_idx": 34}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "If we could get the causal disentanglement map, then we know that when the representations are fully learned, we can intervene on $A g e,a n$ without changing the Gender of the face. This motivates the need for a general approach to identifiability, compared to the scaling indeterminacy in Def. 6.5, which requires all variables to be disentangled from each other. ", "page_idx": 34}, {"type": "text", "text": "As another motivating example, consider a marketing company creating faces for a female product. The relevant latent factors are Gender $\\leftrightarrow\\mathrm{Age}\\to\\mathrm{Hair}$ Color (see Appendix D.1 for details). If Gender and Age are entangled, changing Age might also alter Gender, which is undesirable. The company needs a model where Age is disentangled from Gender, while correlation with Hair Color is allowed. Our paper addresses the problem of determining whether a given set of input data and assumptions in the form of a LSD is sufficient to learn such a disentangled representation. ", "page_idx": 34}, {"type": "text", "text": "D.2 Examples for non-Markovian Factorization ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "In this section, we centralize theoretical results in relation to the theory presented in this paper. ", "page_idx": 34}, {"type": "text", "text": "Unless specified, we denote the natural log as log. ", "page_idx": 34}, {"type": "text", "text": "We first provide more discussion about non-Markovian factorization Eq. (1). First, the concept C-component is formally defined as follows: ", "page_idx": 34}, {"type": "image", "img_path": "uLGyoBn7hm/tmp/4ca3d64129f74e59508d5b9c34fd2007c5827fbf45502a6bbf6c1829c0baf5a6.jpg", "img_caption": ["Figure S4: Causal graph with four C-components. "], "img_footnote": [], "page_idx": 35}, {"type": "text", "text": "Definition 6.2 (Confounded Component). Let $\\{\\mathbf{C_{1}},\\mathbf{C_{2}},\\dotsc,\\mathbf{C_{k}}\\}$ be a partition over the set of variables $\\mathbf{V}$ , where $\\mathbf{C_{i}}$ is said to be a confounded component (for short, $C$ -component) of the selection diagram $G_{V}$ if for every $V_{i},V_{j}\\in\\mathbf{C_{i}}$ there exists a path made entirely of bidirected edges between $V_{i}$ and $V_{j}$ in $G_{V}$ , and $\\mathbf{C_{i}}$ is maximal. \u53e3 ", "page_idx": 35}, {"type": "text", "text": "This construct represents clusters of variables that share the same exogenous variations regardless of their directed connections. The selection diagram in Figure 2 has a bidirected edge indicating the presence of unobserved confounders affecting the pairs $\\left(V_{1},V_{2}\\right)$ and contains two C-components, namely, $\\mathbf{C_{1}}=\\{V_{1},V_{2}\\}$ , ${\\bf C_{2}}=\\{V_{3}\\}$ . ", "page_idx": 35}, {"type": "text", "text": "Akin to parents within a Markovian SCM, the c-components play a fundamental role in factorizing the joint distribution of the observed variables $\\mathbf{V}$ . ", "page_idx": 35}, {"type": "text", "text": "Let $<$ be a topological order $V_{1},\\ldots,V_{n}$ of the variables $\\mathbf{V}$ in $G^{S}$ . Then define the $\\mathbf{Pa}_{i}^{\\mathbf{T}+}=$ $\\mathbf{Pa}(\\{V\\in\\mathbf{C}(V_{i}):V\\le V_{i}\\})\\setminus\\{V_{i}\\}.$ The $\\mathbf{Pa}^{+}(V_{i})$ set consists of the nodes in the same c-component that are $\"\\leq\"$ in topological order as $V_{i}$ , their corresponding parents, minus the node $V_{i}$ itself. For instance, in Fig. S4, $P a^{+}(E)=\\{D,C,A\\}$ and $P a^{\\bar{+}}(D)=\\bar{\\{}B,C,A\\}$ . ", "page_idx": 35}, {"type": "text", "text": "The general factorization formula Eq. (1) factorizes not only the joint observational distribution related to a causal graph, but also interventional distributions. With a perfect intervention on $\\mathbf{T}$ , the factorization follows the corresponding graph is $G_{\\overline{{\\mathbf{T}}}}$ , where the incoming arrows towards $\\mathbf{T}$ are cut. This factorization encompasses both Markovian and non-Markovian SCM models. When there are no bidirected edges in the diagram, $\\mathbf{Pa}_{i}^{\\mathbf{T}+}$ reduce to Pa in $F_{\\mathbf{T}}$ . ", "page_idx": 35}, {"type": "text", "text": "Next, we introduce the Markov blanket, a fundamental idea in characterizing certain conditional independences in a causal graph [71, 72]. ", "page_idx": 35}, {"type": "text", "text": "Definition 6.3 (Markov Blanket). Let $G$ be a causal graph over variables $\\mathbf{V}$ . A Markov blanket of a random variable $Y\\in\\mathbf{V}$ is any subset $V_{1}\\subseteq\\mathbf{V}$ such that conditioned on $V_{1}$ , Y is independent of all other variables. ", "page_idx": 35}, {"type": "equation", "text": "$$\nY\\perp\\!\\!\\!\\perp\\mathbf{V}\\!\\!\\!\\backslash V_{1}|V_{1}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "The Markov blanket is an important object that captures conditional independences between variables when conditioned on all other variables in the graph. ", "page_idx": 35}, {"type": "text", "text": "Definition 6.4 (\"Global\" Markov property of DAGs [73]). Consider a joint probability distribution, $P$ over a set of variables $\\mathbf{V}$ satisfies the Markov property with respect to a graph $G=\\stackrel{\\cdot}{(}V\\cup L,E)$ if the following holds for, $(\\mathbf{X},\\mathbf{Y},\\mathbf{Z})$ disjoint subsets of $\\mathrm{v}$ : ", "page_idx": 35}, {"type": "text", "text": "The global Markov property maps graphical structure in causal directed acyclic graphs (DAGs) to conditional independence (CI) statements in the relevant probability distributions from data. The distributions we consider $\\mathcal{P}$ are considered Markov wrt the graph, thus mapping d-separations in the graph to conditional independences in the distributions. This allows us to leverage factorizations, such as the one presented in Section 2. ", "page_idx": 35}, {"type": "text", "text": "E Examples for Proposition 2 ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "The following example illustrates more about the invariant factors. ", "page_idx": 36}, {"type": "text", "text": "Example 14. (Example $^{\\,l}$ continued.) Choose $P^{(1)}$ as the baseline and $\\mathbf{T}=\\{\\}$ . The factorization of $P({\\bf V})$ is $P(V_{1})P(V_{2}\\mid V_{1})P(V_{3}\\mid V_{2})$ . The changed variable set $\\Delta\\mathbf{V}[\\mathbf{I}^{(2)},\\mathbf{I}^{(1)},G^{S}]=\\{V_{3}\\}$ since the $S$ -node points to $V_{3}$ in $G^{S}$ and $\\Delta\\Dot{\\mathbf{V}}[\\mathbf{I}^{(3)},\\mathbf{I}^{(1)},G^{S}]=\\{V_{3}\\}$ since $V_{3}\\in\\mathbf{I}^{(3)}$ while $V_{3}\\not\\in{\\bf I}^{(1)}$ . Thus, comparing $P^{(2)}$ and $P^{(3)}$ with the baseline $P^{(1)}$ , $p(v_{2}\\mid v_{1})$ and $p(v_{1})$ are invariant factors while $p(v_{3}\\mid v_{2})$ possibly changes. \u53e3 ", "page_idx": 36}, {"type": "text", "text": "E.1 The detailed examples of Proposition 3 and 4 ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "We show another example of using Proposition 3 to solve an ID task in Example 1. ", "page_idx": 36}, {"type": "text", "text": "Example 15. (Example $^{l4}$ continued.) Consider ${\\bf V}^{t a r}=\\{V_{2},V_{3}\\}.$ , ${\\bf V}^{e n}={\\bf V}\\backslash\\{V_{2},V_{3}\\}=\\{V_{1}\\}$ . When comparing $\\{P^{(2)},P^{(3)}\\}$ with the baseline $P^{(1)}$ , $\\mathbf{T}=\\sigma_{M}[\\mathbf{I}^{(1)}]=\\{\\}$ , and then ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\Delta\\mathbf{Q}[\\mathbf{I}^{(2)},\\mathbf{I}^{(1)},\\mathbf{T},G^{S}]=\\Delta\\mathbf{Q}[\\mathbf{I}^{(3)},\\mathbf{I}^{(1)},\\mathbf{T},G^{S}]=\\mathbf{V}^{t a r}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Thus, these two comparisons satisfy the three conditions in Prop.3. Because the number of compared distribution $\\{P^{(2)},\\dot{P}^{(3)}\\}$ is 2, which is equal to $\\left|\\mathbf{V}^{t a r}\\right|$ , then we know ${\\bf V}^{t a r}$ is $I D\\ w.r{t}\\ {\\bf V}^{e n}$ by Prop. 3. This demonstrates that a variable $V_{2}$ can be disentangled from another variable that is in the $C$ -component $(V_{1})$ . See Appendix $E x.$ . 16 for a detailed derivation. \u53e3 ", "page_idx": 36}, {"type": "text", "text": "Proposition 3 and 4 disentangle variables through comparing distributions. With enough distributions, one can build a linear system (illustrated in Appendix C.4 and C.5). ", "page_idx": 36}, {"type": "text", "text": "Example 16. (details for Example $15$ ). By comparing distribution resulting from $\\sigma^{(2)}$ and $\\sigma^{(3)}$ with the baseline $\\sigma^{(1)}$ , ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\log p^{(2)}(v_{3}\\mid v_{2})-\\log p^{(1)}(v_{3}\\mid v_{2})=\\log p^{(2)}(\\widehat{v}_{3}\\mid\\widehat{v}_{2})-\\log p^{(1)}(\\widehat{v}_{3}\\mid\\widehat{v}_{2})}\\\\ {\\log p^{(3)}(v_{3}\\mid v_{2})-\\log p^{(1)}(v_{3}\\mid v_{2})=\\log p^{(3)}(\\widehat{v}_{3}\\mid\\widehat{v}_{2})-\\log p^{(1)}(\\widehat{v}_{3}\\mid\\widehat{v}_{2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Taking the first order partial derivative w.r.t. $V_{1}$ : ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r}{0=\\cfrac{\\partial\\log p^{(2)}(\\widehat{v}_{3}\\mid\\widehat{v}_{2})-\\log p^{(1)}(\\widehat{v}_{3}\\mid\\widehat{v}_{2})}{\\partial\\widehat{v}_{2}}\\cfrac{\\partial\\widehat{v}_{2}}{\\partial v_{1}}+\\cfrac{\\partial\\log p^{(2)}(\\widehat{v}_{3}\\mid\\widehat{v}_{2})-\\log p^{(1)}(\\widehat{v}_{3}\\mid\\widehat{v}_{2})}{\\partial\\widehat{v}_{3}}\\cfrac{\\partial\\widehat{v}_{3}}{\\partial v_{1}}}\\\\ {0=\\cfrac{\\partial\\log p^{(3)}(\\widehat{v}_{3}\\mid\\widehat{v}_{2})-\\log p^{(1)}(\\widehat{v}_{3}\\mid\\widehat{v}_{2})}{\\partial\\widehat{v}_{2}}\\cfrac{\\partial\\widehat{v}_{2}}{\\partial v_{1}}+\\cfrac{\\partial\\log p^{(3)}(\\widehat{v}_{3}\\mid\\widehat{v}_{2})-\\log p^{(1)}(\\widehat{v}_{3}\\mid\\widehat{v}_{2})}{\\partial\\widehat{v}_{3}}\\cfrac{\\partial\\widehat{v}_{3}}{\\partial v_{1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "In this system, notice that ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\log p^{(2)}(\\widehat{v}_{3}\\mid\\widehat{v}_{2})-\\log p^{(1)}(\\widehat{v}_{3}\\mid\\widehat{v}_{2})=\\log p^{(2)}(\\widehat{v}_{1},\\widehat{v}_{2},\\widehat{v}_{3})-\\log p^{(1)}(\\widehat{v}_{1},\\widehat{v}_{2},\\widehat{v}_{3})\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Then since the coefficient is linear independent assumed in Assumption 4, we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\frac{\\partial\\widehat{v}_{2}}{\\partial v_{1}}=0,\\frac{\\partial\\widehat{v}_{3}}{\\partial v_{1}}=0\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Then $V_{2}=\\tau_{2}(V_{2},V_{3})$ , and $V_{3}=\\tau_{3}(V_{2},V_{3})$ . ", "page_idx": 36}, {"type": "text", "text": "First, this example shows we can disentangle two variables in the same $C$ -component $(V_{!},V_{2})$ . Second, Compared with the baseline, one can disentangle variable $V$ with its descendants when soft interventions are given per node, and $V$ is considered to be still entangled with its ancestral (see Sec. F.6). The above result shows that it is possible to disentangle variables from their ancestors using only soft interventions. More interestingly, no intervention is performed on $V_{2}$ while we disentangle $V_{2}$ from $V_{1}$ . Compared with [22], one can disentangle $V_{1}$ and $V_{3}$ using $I O$ distributions and we demonstrate 3 distributions are enough. \u53e3 ", "page_idx": 36}, {"type": "text", "text": "Example 17. (details for Example 4). Choosing order $V_{1}<V_{3}<V_{2}<V_{4}$ . ", "page_idx": 36}, {"type": "equation", "text": "$$\nP(\\mathbf{V})=P(V_{1})P(V_{3})P(V_{2}\\mid V_{1},V_{3})P(V_{4}\\mid V_{3})\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "as the factorization. By comparing distribution resulting from $\\sigma^{(2)}$ and $\\sigma^{(3)}$ with the baseline $\\sigma^{(1)}$ , ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log p^{(2)}(v_{2}\\mid v_{1},v_{3})-\\log p^{(1)}(v_{2}\\mid v_{1},v_{3})=\\log p^{(2)}(\\widehat{v}_{2}\\mid\\widehat{v}_{1},\\widehat{v}_{3})-\\log p^{(1)}(\\widehat{v}_{2}\\mid\\widehat{v}_{1},\\widehat{v}_{3})}\\\\ &{\\log p^{(3)}(v_{3})-\\log p^{(1)}(\\widehat{v}_{3})+\\log p^{(3)}(v_{2}\\mid v_{1},v_{3})-\\log p^{(1)}(v_{2}\\mid v_{1},v_{3})=}\\\\ &{\\log p^{(3)}(\\widehat{v}_{1})(\\widehat{v}_{3})-\\log p^{(3)}(\\widehat{v}_{3})+\\log p^{(2)}(\\widehat{v}_{2}\\mid\\widehat{v}_{1},\\widehat{v}_{3})-\\log p^{(1)}(\\widehat{v}_{2}\\mid\\widehat{v}_{1},\\widehat{v}_{3})}\\\\ &{\\log p^{(4)}(v_{1})-\\log p^{(1)}(v_{1})=\\log p^{(4)}(\\widehat{v}_{1})-\\log p^{(1)}(\\widehat{v}_{1})}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Taking the first order partial derivative w.r.t. $V_{4}$ : ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{0=h_{2,1}\\displaystyle\\frac{\\partial\\widehat{v}_{1}}{\\partial v_{4}}+h_{2,2}\\displaystyle\\frac{\\partial\\widehat{v}_{2}}{\\partial v_{4}}+h_{2,3}\\displaystyle\\frac{\\partial\\widehat{v}_{3}}{\\partial v_{4}}}\\\\ &{0=h_{3,1}\\displaystyle\\frac{\\partial\\widehat{v}_{1}}{\\partial v_{4}}+h_{3,2}\\displaystyle\\frac{\\partial\\widehat{v}_{2}}{\\partial v_{4}}+h_{3,3}\\displaystyle\\frac{\\partial\\widehat{v}_{3}}{\\partial v_{4}}}\\\\ &{0=h_{4,1}\\displaystyle\\frac{\\partial\\widehat{v}_{1}}{\\partial v_{4}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{h_{2,i}=\\cfrac{\\partial\\log p^{(2)}(\\widehat{v}_{2}\\mid\\widehat{v}_{1},\\widehat{v}_{3})-\\log p^{(1)}(\\widehat{v}_{2}\\mid\\widehat{v}_{1},\\widehat{v}_{3})}{\\partial\\widehat{v}_{4}}\\;\\;f o r\\,i=1,2,3}\\\\ &{h_{3,i}=\\cfrac{\\partial\\log p^{(3)}(\\widehat{v}_{3})-\\log p^{(1)}(\\widehat{v}_{3})+\\log p^{(3)}(\\widehat{v}_{2}\\mid\\widehat{v}_{1},\\widehat{v}_{3})-\\log p^{(1)}(\\widehat{v}_{2}\\mid\\widehat{v}_{1},\\widehat{v}_{3})}{\\partial\\widehat{v}_{4}}\\;\\;f o r\\,i=1,2,3}\\\\ &{h_{4,1}=\\cfrac{\\partial p^{(4)}(\\widehat{v}_{1})-\\log p^{(1)}(\\widehat{v}_{1})}{\\partial\\widehat{v}_{4}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Then since the coefficient is linear independent assumed in Assumption $^{4}$ , we have ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\frac{\\partial\\widehat{v}_{1}}{\\partial v_{4}}=0,\\frac{\\partial\\widehat{v}_{2}}{\\partial v_{4}}=0,\\frac{\\partial\\widehat{v}_{3}}{\\partial v_{4}}=0\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Then $V_{1}=\\tau_{1}(V_{1},V_{2},V_{3}).$ , and $V_{2}=\\tau_{2}(V_{1},V_{2},V_{3})$ and $V_{3}=\\tau_{3}(V_{1},V_{2},V_{3})$ . ", "page_idx": 37}, {"type": "text", "text": "Example 18. The factorization based on $G^{S}$ choosing $\\mathbf{T}=\\{\\}$ is ", "page_idx": 37}, {"type": "equation", "text": "$$\nP(\\mathbf{V})=P(V_{1})P(V_{3})P(V_{3}\\mid V_{1},V_{2})\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "By comparing distribution resulting from $\\sigma^{(2)}$ and $\\sigma^{(3)}$ with the baseline $\\sigma^{(1)}$ , for $j=2,3,4,5$ ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\log p^{(j)}(v_{1})+\\log p^{(j)}(v_{3})-\\log p^{(1)}(v_{1})-\\log p^{(1)}(v_{3})}\\\\ {=\\log p^{(j)}(\\widehat{v}\\cdot)+\\log p^{(j)}(\\widehat{v}_{3})-\\log p^{(1)}(\\widehat{v}_{1})-\\log p^{(1)}(\\widehat{v}_{3})}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Taking the second order partial derivative w.r.t. $V_{1},V_{3}$ : ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{0=\\displaystyle\\frac{\\partial^{2}\\log p^{(j)}(\\widehat{v}_{1})p^{(j)}-\\log p^{(1)}(\\widehat{v}_{1})}{\\partial\\widehat{v}_{1}^{2}}\\frac{\\partial\\widehat{v}_{1}}{\\partial v_{1}}\\frac{\\partial\\widehat{v}_{1}}{\\partial v_{3}}+\\frac{\\partial^{2}\\log p^{(j)}(\\widehat{v}_{3})p^{(j)}-\\log p^{(1)}(\\widehat{v}_{3})}{\\partial\\widehat{v}_{3}^{2}}\\frac{\\partial\\widehat{v}_{3}}{\\partial v_{1}}\\frac{\\partial\\widehat{v}_{3}}{\\partial v_{3}}}\\\\ &{\\phantom{=}+\\frac{\\partial\\log p^{(j)}(\\widehat{v}_{1})p^{(j)}-\\log p^{(1)}(\\widehat{v}_{1})}{\\partial\\widehat{v}_{1}}\\frac{\\partial^{2}\\widehat{v}_{1}}{\\partial v_{1}\\partial V_{3}}+\\frac{\\partial\\log p^{(j)}(\\widehat{v}_{3})p^{(j)}-\\log p^{(1)}(\\widehat{v}_{3})}{\\partial\\widehat{v}_{3}}\\frac{\\partial^{2}\\widehat{v}_{3}}{\\partial v_{1}\\partial v_{3}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Then since the coefficient is linear independent assumed in Assumption 4, we have ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\frac{\\partial\\widehat{v}_{1}}{\\partial v_{1}}\\frac{\\partial\\widehat{v}_{1}}{\\partial v_{3}}=0,\\frac{\\partial\\widehat{v}_{3}}{\\partial v_{1}}\\frac{\\partial\\widehat{v}_{3}}{\\partial v_{3}}=0\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Then after permutation, ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\frac{\\partial\\widehat{v}_{1}}{\\partial v_{3}}=0,\\frac{\\partial\\widehat{v}_{3}}{\\partial v_{1}}=0\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "which implies that $V_{3}$ is $I D\\,w.r.t\\,V_{1}$ and $V_{1}$ is $I D\\ w.r.t\\ V_{3}$ . ", "page_idx": 37}, {"type": "text", "text": "The following example shows how Proposition 5 achieves disentanglement for the ID task in Example 1. ", "page_idx": 37}, {"type": "text", "text": "Example 19. (Example 15 (continued).) Let $P^{(4)}$ with intervention target $\\mathbf{I}^{(4)}=\\{V_{2}^{1,\\{1\\},\\mathrm{do}}\\}$ be another distribution added to the original setting. Consider $\\mathbf{V}^{t a r}=\\{V_{1}\\}$ . From Ex. 14, $\\{V_{2},V_{3}\\}$ is ID w.r.t. $V_{1}$ . Consider ${\\bf T}=\\{V_{2}\\}$ (from $\\mathbf{I}^{(4)}$ ). Since $V_{1}\\perp\\perp V_{2},V_{3}\\}$ , then $V_{1}$ is $I D\\,w.r.t\\left\\{V_{2},V_{3}\\right\\}$ . ", "page_idx": 37}, {"type": "text", "text": "Disentangled representation learning aims to obtain approximations $\\widehat{\\mathbf{V}}=\\{\\widehat{V}_{1},\\ldots,\\widehat{V}_{d}\\}$ that separate the distinct, informative generative factors of variations [5] from the observations of $\\mathbf{X}$ and inductive bias of $\\mathcal{M}$ . In other words, the learning goal is an unmixing function ${\\widehat{f}}_{X}^{-1}$ that maps from $\\mathbf{X}$ to $\\widehat{\\mathbf{V}}$ (namely ${\\widehat{\\mathbf{V}}}\\,=\\,{\\widehat{f}}_{X}^{-1}(\\mathbf{X}))$ , where $\\widehat{V}_{i}$ is some transformation of $\\mathbf{W}\\subseteq\\mathbf{V}$ . The goal of disentangled representation learning is to have $\\widehat{V}_{i}$ be a function only of $V_{i}$ , i.e. ${\\bf W}=\\{V_{i}\\}$ . This is not always possible, and different assumption s, data and relaxed versions of disentanglement may be studied to theoretically ground representation learning. The disentangled representation learning tasks are studied with various assumptions and input. In the following, we discuss related tasks and identifiability results in context of this paper. We also present a few case studies on the nuances between Markovian and non-Markovian ASCM setting. ", "page_idx": 38}, {"type": "text", "text": "First, we review the main goal of identifiability in all prior works. It is what is known as scaling identifiability. A special case of our ID definition in Def. 2.3. ", "page_idx": 38}, {"type": "text", "text": "Definition 6.5 (Scaling indeterminancy). Consider a collection of ASCM $\\mathbf{\\mathcal{M}}$ that induces an LSD $G^{S}$ and a collection of distribution $\\mathcal{P}$ . We say $\\mathbf{V}$ is identifiable up to scaling indeterminacy if for every $\\widehat{\\pmb{M}}$ matches with the $G^{S}$ and $\\mathcal{P}$ , there exists functions $\\{h_{1},\\ldots,h_{d}\\}$ such that $\\widehat{V}_{i}=\\mathbf{h}_{i}(V_{i}),i\\in[d]$ , where $h_{i}$ is a diffeomorphism in $\\mathbb{R}$ . \u53e3 ", "page_idx": 38}, {"type": "text", "text": "F.1 Causal representation learning with unknown latent causal structure ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "In many prior works, the goal has been not only identifiability of the underlying latent variables, but also the discovery of the causal relationships among the latent variables [4, 22, 51]. That is, the latent causal graph is unknown. The work proposed in this paper is a foundation for the first step of causal representation learning, i.e. identifying the distributions of the latent causal variables. It would be interesting future work to explore how the results proposed in this paper extend to the case when the latent causal graph is unknown. ", "page_idx": 38}, {"type": "text", "text": "F.2 Comparisons with other identifiability criterion ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "We also consolidate other definitions of identifiability from the literature using the notion of an ASCM. We have already defined identifiability up to scaling ambiguity in Def. 6.5. ", "page_idx": 38}, {"type": "text", "text": "Corollary 2 (Scaling ID is a case in general ID). Let $\\mathbf{\\mathcal{M}}$ be a collection of ASCM with $G^{S}$ the LSD over the latent causal variables $\\mathbf{V}$ . If $\\tilde{V}\\subseteq\\mathbf{V}$ is identifiable up to scaling indeterminacy, then it is identifiable wrt $\\mathbf{V}\\backslash\\tilde{V}$ . ", "page_idx": 38}, {"type": "text", "text": "Proof. The proof follows from the application of Def. 2.3 and Def. 6.5. ", "page_idx": 38}, {"type": "text", "text": "Definition 6.6 (Identifiability up to ancestral mixtures [21]). Let $\\mathbf{\\mathcal{M}}$ be a collection of ASCM with $G^{S}$ the LSD over the latent causal variables $\\mathbf{V}$ . We say a variable $\\tilde{V}\\in\\mathbf{V}$ is identifiable up to ancestral mixtures if for every $\\widehat{\\pmb{M}}$ matches with the $G^{S}$ and $\\mathcal{P}$ , there exists functions $\\{h_{1},\\ldots,h_{d}\\}$ such that $\\widehat{V}_{i}=\\mathbf{h}_{i}(\\overline{{\\mathbf{A}\\mathbf{nc}}}(V_{i})),i\\in[d]$ . \u53e3 ", "page_idx": 38}, {"type": "text", "text": "Corollary 3 (Ancestral ID is a case in general ID). Let $M$ be a collection of ASCM with $G$ the LSD over the latent causal variables $\\mathbf{V}$ . If $\\tilde{V}\\subseteq\\mathbf{V}$ is identifiable up to ancestral mixtures, then it is identifiable wrt $\\mathbf{V}\\backslash\\mathbf{Anc}(\\Tilde{V})$ . ", "page_idx": 38}, {"type": "text", "text": "Proof. The proof follows from the application of Def. 2.3 and Def. 6.6. ", "page_idx": 38}, {"type": "text", "text": "The following definitions are inspired by the identifiability results from [22]. ", "page_idx": 38}, {"type": "text", "text": "Definition 6.7 (Intimate Neighbor Set). We say $\\varepsilon_{M_{G},V_{i}}:=\\{V_{j}\\mid j\\neq i$ , but $V_{j}$ is adjacent to $V_{i}$ and all other neighbors of $V_{i}$ in $M_{G}$ . \u53e3 ", "page_idx": 38}, {"type": "text", "text": "The intimate neighbor set for a variable dictates a set of neighbors that are adjacent to all of that variable\u2019s neighbors. It is used in the following definition from [22]. ", "page_idx": 38}, {"type": "text", "text": "Definition 6.8 (Identfiability up to intimate neighbor set of Markov Network [22]). Let $\\mathbf{\\mathcal{M}}$ be a collection of ASCM with $G^{S}$ the LSD over the latent causal variables $\\mathbf{V}$ . We say a variable $\\tilde{V}\\in\\mathbf{V}$ is identifiable up to intimate neighbors in the Markov Network if for every $\\widehat{\\pmb{M}}$ matches with the $G^{S}$ and $\\mathcal{P}$ , there exists functions $\\{h_{1},\\ldots,h_{d}\\}$ such that $\\widehat{V}_{i}\\,=\\,{\\bf h}_{i}\\bigl(\\varepsilon(M_{G},V_{i})\\bigr),i\\,\\in\\,[d]$ , and $M_{G}$ is the Markov network of $G$ and $\\varepsilon(M_{G},V_{i})$ is the intimate n eighbor set of $V_{i}$ in $M_{G}$ . \u53e3 ", "page_idx": 39}, {"type": "text", "text": "Corollary 4 (Intimate Neighbor Markov Network ID is a case in general ID). Let $M$ be a collection of ASCM with $G$ the LSD over the latent causal variables $\\mathbf{V}$ . If $\\tilde{V}\\subseteq\\mathbf{V}$ is identifiable up to intimate neighbor set of the Markov Network, then it is identifiable wrt ${\\bf V}\\backslash\\phi(M N(G);\\tilde{V})$ . ", "page_idx": 39}, {"type": "text", "text": "Proof. The result follows from the application of Def. 2.3 and Def. 6.8. ", "page_idx": 39}, {"type": "text", "text": "Thus, we showed that each of these identifiability definitions imply a general ID for a non-trivial subset of latent variables $\\tilde{\\mathbf{V}}\\subseteq\\mathbf{V}$ with respect to ${\\bf V}^{e n}\\subset{\\bf V}$ . ", "page_idx": 39}, {"type": "text", "text": "F.3 Case study on challenges when disentangling variables in a non-Markovian setting ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Prior results suggest that in a Markovian setting, given a perfect intervention on every node, the latent variables $\\mathbf{V}$ are ID up to scaling indeterminancies according to Def. 6.5 [14, 21]. ", "page_idx": 39}, {"type": "text", "text": "One would suspect that ID may still hold in non-Markovian ASCMs, but the following result states that even with one perfect intervention per node, it is not possible to disentangle latent variables within the same c-component. ", "page_idx": 39}, {"type": "text", "text": "Lemma 5 (Challenges of identifability in non-Markovian causal models). Consider the ASCM $M$ that induces the diagram $V_{1}\\leftrightarrow V_{2}$ . Suppose the intervention set includes an observational distribution, and perfect interventions on both $V_{1}$ and $V_{2}$ : $\\Psi=\\langle\\sigma_{\\{\\}},\\sigma_{M}(\\{V_{1}\\}),\\sigma_{M}(\\{V_{2}\\})\\rangle$ . Then $V_{1}$ is not $I D\\ w.r.t\\ V_{2}$ and vice versa. \u53e3 ", "page_idx": 39}, {"type": "text", "text": "Proof. We prove this by construction of a counter-example. ", "page_idx": 39}, {"type": "text", "text": "Consider an ASCM $M^{*}$ that is constructed as follows: ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{F}^{*}=\\left\\{\\begin{array}{l l}{V_{1}\\gets U_{1,2}}\\\\ {V_{2}\\gets U_{1,2}+U_{V_{2}}}\\\\ {X_{1}\\gets V_{1},X_{2}\\gets V_{2}}\\end{array}\\right.}\\\\ {U_{1,2}\\sim\\mathcal{N}(0,1),U_{Y}\\sim\\mathcal{N}(0,3)}\\\\ {\\sigma_{V_{1}}=P(\\tilde{U_{V_{1}}}),\\tilde{U}_{V_{1}}\\sim\\mathcal{N}(0,2)}\\\\ {\\sigma_{V_{2}}=P(\\tilde{U_{V_{2}}}),\\tilde{U}_{V_{1}}\\sim\\mathcal{N}(0,7)}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Consider a separate ASCM $M^{(1)}$ that is constructed as follows: ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{F}^{(1)}=\\left\\{V_{2}^{(1)}-0.5U_{1,2}^{(1)}\\right.+1.5U_{Y}}\\\\ {\\left.V^{(1)}=0.5U_{1,2}^{(1)}+1.5U_{Y}\\right.}\\\\ {\\left.X_{1}-1/3V_{1}^{(1)}+2/3V_{2}^{(1)},\\right.}\\\\ {\\left.X_{2}<2/3V_{1}^{(1)}-2/3V_{2}^{(1)}\\right.}\\\\ {\\left.U_{1,2}^{(1)}\\sim\\mathcal{N}(0.3)U_{1}^{(1)}\\sim\\mathcal{N}(0,1)\\right.}\\\\ {\\sigma_{V_{1}}=P(\\tilde{U_{1}}^{(1)}),\\tilde{U_{1}}^{(1)}\\sim\\mathcal{N}(0,6)}\\\\ {\\sigma_{V_{2}}=P(\\tilde{U_{1}}^{(1)}),\\tilde{U_{1}}^{(1)}\\sim\\mathcal{N}(0,7)}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "$M^{*}$ and $M^{(1)}$ induce the same observational distribution $P(\\mathbf{X})\\sim\\mathcal{N}(0,\\left[\\!\\!1\\!\\!\\!1\\!\\!\\!\\!1\\!\\!\\!\\!\\right])$ , and interventional distributions $P(\\mathbf{X};\\sigma_{V_{1}})\\sim\\mathcal{N}(0,\\left[\\!\\!\\begin{array}{c c}{2}&{0}\\\\ {0}&{4}\\end{array}\\!\\!\\right]),P(\\mathbf{X};\\sigma_{V_{2}})\\sim\\mathcal{N}(0,\\left[\\!\\!\\begin{array}{c c}{1}&{0}\\\\ {0}&{7}\\end{array}\\!\\!\\right])}\\end{array}$ ", "page_idx": 39}, {"type": "text", "text": "However, $V_{1}^{(1)}=V_{1}-V_{2}$ , which implies $V_{1}^{(1)}$ is not ancestral mixture or rescaling of the original $V_{1}$ . Therefore, $V_{1}$ is not identifiable up to ancestral mixtures, or rescaling. ", "page_idx": 40}, {"type": "text", "text": "F.4 ID within c-components ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Lemma 5 shows that even with one perfect intervention on each node, it is not possible to disentangle variables within the same c-component. The next lemma provides a means of doing so using two perfect interventions on the same node. This provides some intuition for the usefulness of perfect interventions in the CRID setting. ", "page_idx": 40}, {"type": "text", "text": "Lemma 6 (Two perfect interventions can disentangle within a c-component). Let $G^{S}$ be the $L S D$ induced from a collection of ASCM $\\mathbf{\\mathcal{M}}$ . Suppose $V_{i},V_{j}\\in\\mathbf{V}$ are in the same $c$ -component, and there are $L+1$ perfect interventions distributions $\\mathcal{P}_{V_{i}}\\;=\\;\\{P^{(a_{0})},P^{(a_{1})},\\ldots,P^{(a_{L})}\\}$ such that $V_{i}\\in d o[\\mathbf{I}^{(a_{l})}]$ and $\\Delta\\mathbf{Q}[\\mathbf{I}^{(a_{l})},\\mathbf{I}^{(a_{0})},V_{i},G^{S}]$ are equivalent (denoted as $\\mathbf{Q},$ ) for $l\\in[L]$ . When $V_{j}\\notin\\mathbf{Q}$ and if $L\\geq|\\mathbf{Q}|$ , $V_{i}$ is identifiable wrt $V_{j}$ . When $V_{j}\\in\\mathbf{Q}$ and $i f L\\ge2|\\mathbf{Q}|+\\delta_{\\mathcal{J}}$ , $V_{i}$ is identifiable wrt Vj. ", "page_idx": 40}, {"type": "text", "text": "Proof. The result follows from the application of Proposition 3 and Proposition 4. ", "page_idx": 40}, {"type": "text", "text": "Example 20. In most simple case. Let\u2019s have $d o[{\\bf{I}}^{(j)}]\\;=\\;d o[{\\bf{I}}^{(k)}]\\;=\\;V_{i}$ and $\\Delta\\mathbf{Q}\\;=\\;V_{i}$ . Let $V_{i},V_{j}\\in\\mathbf{C}_{k}$ be two arbitrary latent variables in the same $c$ -component. By comparing distributions, we have ", "page_idx": 40}, {"type": "equation", "text": "$$\np_{V_{i}}^{(2)}(v_{i})-p_{V_{i}}^{(1)}(v_{i})=p_{V_{i}}^{(2)}(\\widehat{v}_{i})-p_{V_{i}}^{(1)}(\\widehat{v}_{i})\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Taking partial w.r.t. $V_{j}$ , we have ", "page_idx": 40}, {"type": "equation", "text": "$$\n0=\\frac{p_{V_{i}}^{(2)}(\\widehat{v}_{i})-p_{V_{i}}^{(1)}(\\widehat{v}_{i})}{\\widehat{v}_{i}}\\frac{\\widehat{v}_{i}}{v_{j}}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "which implies $\\begin{array}{r}{\\frac{\\widehat{v}_{i}}{v_{j}}=0}\\end{array}$ . ", "page_idx": 40}, {"type": "text", "text": "Notice that this is not the only way to disentangle to variables in the C-Component. In Example 6, $V_{1}$ and $V_{2}$ are disentangled from each other without leveraging two perfect interventions. ", "page_idx": 40}, {"type": "text", "text": "F.5 Case study on disentangling variables in a Markovian setting ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "This next example works out the algebraic derivations for analyzing Fig. 4(a). This derivation is provided to provide additional intuition on the theory presented in Section 3, and how these concepts apply in a simple 3-dimensional latent causal graph. ", "page_idx": 40}, {"type": "text", "text": "Example 21 (Algebraic derivation of disentanglement in a simple 3-node chain graph). Given the graph shown in Figure $^{4}(a)$ , we can factorize the joint observational distribution of the latent variables ", "page_idx": 40}, {"type": "equation", "text": "$$\nP(\\mathbf{V})=P(V_{3}|V_{2})P(V_{1}|V_{2})P(V_{2})\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "By the probability transformation formula, we can similarly write the distribution in terms of its estimated sources via function $\\phi=\\hat{f}_{\\mathbf{X}}^{-1}\\circ f_{\\mathbf{X}}$ for its distribution $Q$ . ", "page_idx": 40}, {"type": "equation", "text": "$$\nP(\\mathbf{V})=P(\\phi_{V_{3}}(\\mathbf{V})|\\phi_{V_{2}}(\\mathbf{V}))P(\\phi_{V_{1}}(\\mathbf{V})|\\phi_{V_{2}}(\\mathbf{V})P(\\phi_{V_{2}}(\\mathbf{V}))|d e t J_{\\phi}|\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Now, consider the interventional distributions: $P(\\mathbf{V};\\sigma_{V_{3}^{(1)}})$ and $P(\\mathbf{V};\\sigma_{V_{3}^{(2)}})$ . Here, we will use shorthand $\\phi_{i}$ to indicate $\\phi_{V_{i}}(\\mathbf{V})$ . Similarly, we can factorize the distribution $P(\\mathbf{V};\\sigma_{V_{3}^{(1)}})$ : ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P({\\mathbf{V}};\\sigma_{V_{3}^{(1)}})}\\\\ &{\\ =P(V_{3}|V_{2};\\sigma_{V_{3}^{(1)}})P(V_{1}|V_{2};\\sigma_{V_{3}^{(1)}})P(V_{2};\\sigma_{V_{3}^{(1)}})\\ \\ \\ (C o n d i t i o n a l\\,i n d e p e n d e n c e)}\\\\ &{\\ =P(\\phi_{3}|\\phi_{2};\\sigma_{3^{(1)}})P(\\phi_{1}|\\phi_{2};\\sigma_{V_{3}^{(1)}})P(\\phi_{2};\\sigma_{V_{3}^{(1)}})|d e t J_{\\phi}\\ \\ \\ (P r o b a b i l i t y\\,t r a n s f o r m a t i o n\\,f o r m u l a)}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Similarly, we can decompose the interventional distribution $P(\\mathbf{V};\\sigma_{V_{3}^{(2)}})$ . Now, comparing the log observational distribution with the log intervention $\\sigma_{V_{3}^{(i)}}$ , we get: ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log p(\\mathbf{V};\\sigma_{V_{3}^{(i)}})-\\log p(\\mathbf{V})}\\\\ &{=\\log p(V_{3}|V_{2};\\sigma_{V_{3}^{(i)}})+\\log p(V_{1}|V_{2};\\sigma_{V_{3}^{(i)}})+\\log p(V_{2};\\sigma_{V_{3}^{(i)}})}\\\\ &{\\phantom{=}-\\log p(V_{3}|V_{2})-\\log p(V_{1}|V_{2})-\\log p(V_{2})}\\\\ &{=\\log p(V_{3}|V_{2};\\sigma_{V_{3}^{(i)}})-\\log p(V_{3}|V_{2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Where the last line applies the invariance of $P(V_{i}|V_{j};\\sigma_{V_{k}})=P(V_{i}|V_{j})\\;i f\\,(V_{i}\\perp\\perp V_{k}|V_{j})_{G_{V_{\\overline{{{\\nu_{3}}}}}}}$ . In the space mapped by $\\phi$ , we similarly get: ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log p(\\phi;\\sigma_{{V_{3}^{(i)}}})-\\log p(\\phi)}\\\\ &{=\\log p(\\phi_{3}|\\phi_{2};\\sigma_{3^{(i)}})+\\log p(\\phi_{1}|\\phi_{2};\\sigma_{{V_{3}^{(i)}}})+\\log p(\\phi_{2};\\sigma_{{V_{3}^{(i)}}})}\\\\ &{\\quad-\\log p(\\phi_{3}|\\phi_{2})-\\log p(\\phi_{1}|\\phi_{2})-\\log p(\\phi_{2})}\\\\ &{=\\log p(\\phi_{3}|\\phi_{2};\\sigma_{3^{(i)}})-\\log p(\\phi_{3}|\\phi_{2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "When comparing the distributions of $\\widehat{\\mathbf{V}}$ , interestingly the log of the determinant of the Jacobian cancels out. Combining the two, we ge t: ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\log p(V_{3}|V_{2};\\sigma_{V_{3}^{(u)}})-\\log p(V_{3}|V_{2})=\\log p(\\phi_{3}|\\phi_{2};\\sigma_{3^{(u)}})-\\log p(\\phi_{3}|\\phi_{2})\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Taking the partial derivative now with respect to $V_{1}$ , we get that the LHS equals $\\boldsymbol{O}$ and the RHS becomes: ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle0=\\frac{\\partial}{\\partial V_{1}}\\log p(\\phi_{3}|\\phi_{2};\\sigma_{3^{(i)}})-\\log p(\\phi_{3}|\\phi_{2})}&{}\\\\ {\\displaystyle}&{\\displaystyle=\\frac{\\partial\\log p(\\phi_{3}|\\phi_{2};\\sigma_{3^{(i)}})}{\\partial\\phi_{3}}\\frac{\\partial\\phi_{3}}{\\partial V_{1}}+\\frac{\\partial\\log p(\\phi_{3}|\\phi_{2};\\sigma_{3^{(i)}})}{\\partial\\phi_{2}}\\frac{\\partial\\phi_{2}}{\\partial V_{1}}}\\\\ {\\displaystyle}&{\\displaystyle~~-\\frac{\\partial\\log p(\\phi_{3}|\\phi_{2})}{\\partial\\phi_{3}}\\frac{\\partial\\phi_{3}}{\\partial V_{1}}-\\frac{\\partial\\log p(\\phi_{3}|\\phi_{2})}{\\partial\\phi_{2}}\\frac{\\partial\\phi_{2}}{\\partial V_{1}}}\\\\ {\\displaystyle}&{\\displaystyle=\\frac{\\partial\\phi_{3}}{\\partial V_{1}}\\left(\\frac{\\partial\\log p(\\phi_{3}|\\phi_{2};\\sigma_{3^{(i)}})}{\\partial\\phi_{3}}-\\frac{\\partial\\log p(\\phi_{3}|\\phi_{2})}{\\partial\\phi_{3}}\\right)}\\\\ &{\\displaystyle~~~+\\frac{\\partial\\phi_{2}}{\\partial V_{1}}\\left(\\frac{\\partial\\log p(\\phi_{3}|\\phi_{2};\\sigma_{3^{(i)}})}{\\partial\\phi_{2}}-\\frac{\\partial\\log p(\\phi_{3}|\\phi_{2})}{\\partial\\phi_{2}}\\right)}&{(C o l l e c t\\,t e r m s)}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Thus, we have two unknowns $\\frac{\\partial\\phi_{2}}{\\partial V_{1}}$ and $\\frac{\\partial\\phi_{3}}{\\partial V_{1}}$ . Given the two interventions with different mechanisms on compared to the observational distribution, we have two equations that result in a 2-dimensional linear system. We are able to determine that = \u2202\u2202\u03d5V3 = 0 thus demonstrating that our approach disentangles $\\hat{V}_{3}=\\phi_{3}(\\mathbf{V})$ and $\\hat{V}_{2}=\\phi_{2}(\\mathbf{V})$ from $V_{1}$ . \u53e3 ", "page_idx": 41}, {"type": "text", "text": "F.6 Comparing different identifiability results ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "In this section, we explicitly compare and discuss our work compared to a non-exhaustive list of related disentangled learning in the setting of causally related latent components. Different from previous literature, we do not make common assumptions such as (1) each intervention is applied to a single node [55]; (2) idle interventions (observational distribution) are present within each domain [21, 22]; (3) exactly one intervention is applied per node [13]; (4) at least one intervention is applied per node [21, 55]. ", "page_idx": 41}, {"type": "image", "img_path": "uLGyoBn7hm/tmp/0b3892126891e944e7951cc063527525960921eab4cbb0304fcb6c07796a6978.jpg", "img_caption": ["Figure S5: Reproduced Fig. 4 for convenience. "], "img_footnote": [], "page_idx": 42}, {"type": "text", "text": "Causal component analysis [21] The closest work to ours is [21], which also presupposes knowledge of the latent causal graph and focuses solely on learning the unmixing function and the distributions of the causal variables. In [21], the results emphasized the need for interventions that occur only on a single node in the latent causal graph. However, Lemma 5 demonstrates challenges that are not addressed in the prior work. In addition, in our work, we propose a more general concept of identifiability in Def. 2.3. As a result, Thm. 1 makes significantly weaker assumptions to still achieve identifiability. Exs.2-6 illustrate also the nuances addressed by our work, but not in [21]. ", "page_idx": 42}, {"type": "text", "text": "Another interesting concept introduced by [21] is the \"fat-hand\" interventions, which intervene on groups of variables within different groups, and the concept of \"block-identifiability\". ", "page_idx": 42}, {"type": "text", "text": "Here, we illustrate some examples and discussion on how our work compares with that of [21] that also provides sufficient conditions for identifiability given a causal graph over the latent variables. One key difference between our work is that we do not assume Markovianity in the underlying SCM, whereas they do. ", "page_idx": 42}, {"type": "text", "text": "Example (Ex. 6 cont.). This example continues off of Ex. 6. Consider the motivating example in healthcare depicted in Fig. 2. In hospitals from different countries $\\Pi^{i}$ and $\\Pi^{j}$ , drug treatment $(V_{1})$ affect length of ICU stay $(V_{2})$ , and ultimately whether or not the patient lives or dies $\\left(V_{3}\\right)$ . Our task is to learn representations of the high-level latent variables $(V_{1},V_{2},V_{3})$ that are not collected given $a$ collection of low-level input such as EMRs, imaging and bloodwork data (high-dimensional data $\\mathbf{X}$ ). In existing work [21], there are no guarantees that variables $\\{V_{2},V_{3}\\}$ are disentangled from their ancestor $V_{1}$ from soft interventions per nodes. However, Proposition $3$ demonstrates two comparisons are enough to disentangle both $V_{2}$ and $V_{3}$ from their ancestor $V_{1}$ . \u53e3 ", "page_idx": 42}, {"type": "text", "text": "Even in the Markovian setting, where the LSG does not contain bidirected edges, our results can also guarantee identifiability in this setting. ", "page_idx": 42}, {"type": "text", "text": "Example 22 ([21] approach). Given the graph shown in Figure 4(a), [21] requires an observational, and tuple of intervention sets $\\Psi=\\langle\\{\\},\\{V_{1}\\},\\{V_{2}\\},\\{V_{3}\\}\\rangle$ . Provided these four distributions, there is still no disentanglement of $\\hat{V}_{3}$ with respect to any variables, $V_{i}\\in\\mathbf{V}$ . \u53e3 ", "page_idx": 42}, {"type": "text", "text": "Causal Representation Learning from Multiple Distributions: A General Setting [22] Another approach to achieving disentanglement among the latent variables is similar to nonlinear-ICA, but leverages the conditional independence properties within a Markov Network of the causal graph. Then the proof strategy of [22] considers the second order derivative, which leverages the conditional independence constraints. ", "page_idx": 42}, {"type": "text", "text": "However, this results in a required $2d+|\\mathcal{E}(M_{G})|+1$ number of distributions that satisfy Assump. 4. In addition, this strategy states that in a collider graph $V_{1}\\to V_{2}\\leftarrow V_{3}$ , that $V_{1}$ is not ID wrt $V_{2}$ , and $V_{3}$ is not ID wrt $V_{2}$ . ", "page_idx": 42}, {"type": "text", "text": "Another example, continues off of Ex. 6. ", "page_idx": 42}, {"type": "text", "text": "Example (Ex. 6 cont.). This example continues off of Ex. 6. Consider the motivating example in healthcare depicted in Fig. 2. In hospitals from different countries $\\Pi^{i}$ and $\\Pi^{j}$ , drug treatment $(V_{1})$ affect length of ICU stay $(V_{2})$ , and ultimately whether or not the patient lives or dies $\\left(V_{3}\\right)$ . Our task is to learn representations of the high-level latent variables $(V_{1},V_{2},V_{3})$ that are not collected given $a$ collection of low-level input such as EMRs, imaging and bloodwork data (high-dimensional data X). According to [22], 10 distributions can disentangle $V_{3}$ from $V_{1}$ when $V_{3}$ \u22a5\u22a5 $V_{1}\\mid V_{2}$ . However, Proposition 3 demonstrates two comparisons are enough to disentangle both $V_{2}$ and $V_{3}$ from their ancestor $V_{1}$ . ", "page_idx": 42}, {"type": "text", "text": "Linear ICA Linear ICA has been extensively studied over decades, and is applied in magnetic resonance imaging (MRI) [74], astronomy [75], image processing [76], finance [77] and document analysis [78]. In linear ICA settings, the generative factors are assumed to be independent of each other and the mixture function $f_{\\mathbf{X})}$ is considered to be an invertible matrix $\\mathbf{A}\\in\\mathbb{R}^{d\\times d}$ . Formally, the mechanism $\\mathcal{F}$ and the distribution $P({\\bf U})$ of the true ASCM $\\mathcal{M}^{\\ast}$ are written as: ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{V_{j}\\leftarrow f_{j}(U_{j}),\\forall j\\in[d]}\\\\ {\\mathbf{X}\\leftarrow\\mathbf{A}\\mathbf{V}}\\\\ {U_{i}\\perp U_{j},\\forall i,j\\in[d]}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Notice that $\\mathbf{X}$ is $d$ dimensional variable here and $\\begin{array}{r}{X_{i}\\gets\\sum_{j=1}^{d}a_{i j}V_{j}=\\mathbf{a}_{i}\\mathbf{V},\\forall i\\in[d]}\\end{array}$ . Given the observational distribution $P(\\mathbf{X})$ , the goal of linear tasks is to learn $\\widehat{\\bf A}$ such that $\\widehat{V}_{j}$ is a scaling of a true underlying generative factors $V_{i}$ , where $\\widehat{\\mathbf{V}}=\\widehat{\\mathbf{A}}^{-1}\\mathbf{X}$ . The scaling and permutation identifiability is defined as follows to denote the achievab ility o f linear ICA tasks. ", "page_idx": 43}, {"type": "text", "text": "Definition 6.9 (Scaling and Permutation Identifiability). The representation $\\widehat V$ is said to be identifiable up to scaling and permutation $\\mathbf{V}^{(2)}=\\mathbf{CPV}^{(1)}$ if for every pair of ASCM $\\mathcal{M}^{(1)}$ and $\\mathcal{M}^{(2)}$ such that (1) $P^{\\mathcal{M}^{(1)}}(\\mathbf{X})=P^{\\mathcal{M}^{(2)}}(\\mathbf{X}),P^{\\mathcal{M}^{(1)}}(\\mathbf{X};\\sigma_{v_{k}})=P^{\\mathcal{M}^{(2)}}(\\mathbf{X};\\sigma_{v_{k}})$ ;   \n(2) $\\mathcal{M}^{(1)}$ and $\\mathcal{M}^{(2)}$ are constrained by the modeling process in Eq. 68,   \nwhere $\\mathbf{C}=\\mathrm{diag}(c_{1},\\ldots,c_{d})$ is a scaling diagonal matrix and $\\mathbf{P}$ is a permutation matrix. ", "page_idx": 43}, {"type": "text", "text": "Def. 6.9 says that if every pair model $\\mathcal{M}^{(1)}$ and $\\mathcal{M}^{(2)}$ in linear ICA settings match the observational distributions, the generative variables can be transformed by permutation and scaling. This implies once one finds a proxy ASCM $\\mathcal{M}$ that matches $P(\\mathbf{X})$ ,V is guaranteed to be a scale and permutation representation of the true generative variable if the identifiability is achieved. The next example illustrates ASCMs in linear ICA settings and Def. 6.9. ", "page_idx": 43}, {"type": "text", "text": "Example 23 (ICA Identifiability Is Not Achieved). We consider the three augmented generative processes $\\mathcal{M}^{\\ast}$ , $\\mathcal{M}^{(1)}$ and $\\mathcal{M}^{(2)}$ with linear ICA constraints. ", "page_idx": 43}, {"type": "image", "img_path": "uLGyoBn7hm/tmp/908438414a2e972a29311dd2a3a77cb1a8265a7b9ba9ae8af44ed8e0b1f6e890.jpg", "img_caption": [], "img_footnote": [], "page_idx": 43}, {"type": "text", "text": "It is verifiable that $X_{1},X_{2}\\,\\sim\\mathcal{N}(1,0;0,1)$ induced by all three models. The latent generative variables in $\\mathcal{M}^{(1)}$ are scaled and permuted representations of the true factors $\\mathcal{M}^{\\ast}$ , namely $V_{1}^{(1)}=$ 2V (2) and $V_{2}^{(1)}=0.5V_{2}^{(1)}$ . In ot(h2e)r words(, $V^{(1)}$ and $V^{(2)}$ distinctly represents $V_{2}$ and $V_{1}$ respectively. However, the representations and $V_{2}^{(2)}$ in $\\mathcal{M}^{(2)}$ are mixture of true generative factors and V2, i.e., ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{V_{1}^{(2)}=\\displaystyle\\frac{2}{2}V_{1}+\\displaystyle\\frac{2}{2}V_{2}}}\\\\ {{V_{2}^{(2)}=\\displaystyle\\frac{2}{2}V_{1}-\\displaystyle\\frac{2}{2}V_{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "which implies this is not a scaling and permutation transformation. Thus, $\\mathcal{M}^{(2)}$ demonstrates that the scaling and permutation identifiability is not achieved in this setting. \u53e3 ", "page_idx": 43}, {"type": "text", "text": "The above example shows a famous result of linear ICA: the representations are not identifiable if generative factors follow a multi-gaussian distribution. This result comes from the symmetricity of gaussian distributions: any white gaussian variables are still white gaussian after an orthogonal transformation. However, orthogonal transformations are not guaranteed to be a scaling or permutation thus a proxy model may have generative factors that are mixtures of the true $\\mathbf{V}$ ( $\\mathbf{V}^{(2)}$ in Example 23). Further, the identifiability result can be concluded as follows with the non-Gaussian assumption. ", "page_idx": 43}, {"type": "text", "text": "Nonlinear ICA [7, 10] Compared to linear ICA, nonlinear ICA assumes the mixing function is a nonlinear bijective function (i.e. invertible and differentiable). ", "page_idx": 44}, {"type": "text", "text": "In linear ICA settings, the generative factors are assumed to be independent of each other and the mixture function $f_{\\mathbf{X})}$ is considered to be an invertible matrix $\\mathbf{A}\\in\\mathbb{R}^{\\hat{d}\\times d}$ . Formally, the mechanism $\\mathcal{F}$ and the distribution $P({\\bf U})$ of the true ASCM $\\mathcal{M}^{\\ast}$ are written as: ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{V_{j}\\leftarrow f_{j}(U_{j}),\\forall j\\in[d]}\\\\ {\\mathbf{X}\\leftarrow\\mathbf{f}_{X}(\\mathbf{V})}\\\\ {U_{i}\\perp U_{j},\\forall i,j\\in[d]}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "The traditional approaches for proving identifiability from [7, 8, 10] has the following settings: ", "page_idx": 44}, {"type": "text", "text": "\u2022 (Assumptions) A parametric exponential family is assumed in [7]. In addition, the causal assumptions of the latent variables is fully disconnected graph, where all variables are mutually independent. Our work assumes a nonparametric mixing model, and only requires the mixing function to be a bijection. In addition, we allow a non-Markovian causal model among the latent variables, which is the first to our knowledge to analyze identifiability in this general setting.   \n\u2022 (Data) Nonlinear ICA assumes that $2d+1$ number of distributions with mechanism changes of the latent variables such that a version of the Assump. 4 holds. One instantiation of this in real-world data is time-series with non-stationary changes. Our work leverages arbitrary combinations of interventional data arising from multiple domains, and also does not necessarily require observational data.   \n\u2022 (Output) The focus of nonlinear ICA was typically on achieving disentanglement of latent variables up to scaling indeterminancy (Def. 6.5). Our work approaches the goal of identifiability from a more general setting according to Def. 2.3. ", "page_idx": 44}, {"type": "text", "text": "Interventional causal representation learning [52] Another potentially promising approach to improving identifiability results lies in assuming a parametric form to the mixing function. [52] considers the setting of having a mixing function that is a composition of polynomial functions (i.e. a polynomial decoder). ", "page_idx": 44}, {"type": "text", "text": "Thus, [52] is able to achieve identifiability of latent variables up to an affine transformation: ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\hat{V}=\\mathbf{A}\\mathbf{V}+c\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where $\\mathbf{A}\\in\\mathbb{R}^{d\\times d}$ and $c\\in\\mathbb{R}^{d}$ make up an invertible affine transformation of the true latent variables $\\mathbf{V}$ In our work, we consider a nonparametric form of the mixing function. However, future work could consider relaxing this assumption in the direction of a parametric mixing function with polynomial functions. ", "page_idx": 44}, {"type": "text", "text": "Learning Causal Representations from General Environments: Identifiability and Intrinsic Ambiguity [25] In this paper, identifiability results for a linear ASCM with a linear mixing function is provided, with access to multi-distributional data arising from different environments. ", "page_idx": 44}, {"type": "text", "text": "In addition, they prove identifiability up to \"surrounded-nodes\" in [25, Thm. 3]. Specifically, any linear proxy model that is compatible with the observed distributions $\\mathcal{P}$ , the causal graph, and satisfies a few technical assumptions will achieve identifiability for each variable with respect to variables not in the surrounded-set. Similar to ancestral identifiability (Def. 6.6), surrounded-set disentanglement is a special case of our proposed identifiability definition (Def. 2.3). Our work proposes a graphical criterion and an algorithm for determining a causal disentanglement map, which may contain different disentanglements compared to a surrounded-set. Besides our notion of identifiability (goal), our paper also allows arbitrary distributions from multiple domains (input), and non-parametric non-Markovian ASCMs (assumptions). ", "page_idx": 44}, {"type": "text", "text": "Definition 6.10 (Surrounded set from [79]). For two nodes, $V_{i},V_{j}\\in\\mathbf{V}$ in graph G, we say that $V_{i}\\in s u r(V_{j})$ if $V_{i}\\in P a_{j}$ and $C h_{j}\\subseteq C h_{i}$ . ", "page_idx": 44}, {"type": "text", "text": "Identifying Linearly-Mixed Causal Representations from Multi-Node Interventions [80] In this paper, the authors explore identifiability results in an ASCM with a linear mixing function, where interventions occur on multiple latent variables at the same time (i.e. multi-node interventions). Further, they assume that interventions are perfect interventions and sufficiently diverse, and have a sparse effect on the set of latent variables. Finally, their goal of identifiability is a full disentanglement, which is a special case of the general disentanglement we provide in Def. 2.3, where any variable may be ID w.r.t. a subset of latent variables. ", "page_idx": 45}, {"type": "text", "text": "Our paper also allows multi-node interventions within our graphical criterion (Props. 3, 4, and 5). In terms of the identifiability goal (output), ASCM model (assumptions), and distributions (input), our paper is more general notion of identifiability in the form of a causal disentanglement map (goal); our paper also allows arbitrary distributions (soft, and/or perfect interventions with same/different mechanisms) from multiple domains compared to only perfect interventions in a single domain that meet a sparsity constraint (input), and non-parametric non-Markovian ASCMs vs linear Markovian ASCMs (assumptions). ", "page_idx": 45}, {"type": "text", "text": "Linear Causal Representation Learning from Unknown Multi-node Interventions [79] In this paper, identifiability results are provided in a linear ASCM with a linear mixing function, where soft, or perfect interventions occur on multiple nodes. The authors establish full disentanglement results, or disentanglement up to ancestors, which is similar to the results demonstrated in \"Causal Component Analysis\" [21]. ", "page_idx": 45}, {"type": "text", "text": "Our paper also allows multi-node interventions within our graphical criterion (Props. 3, 4, and 5). In terms of the identifiability goal (output), ASCM model (assumptions), and distributions (input), our paper is more general notion of identifiability in the form of a causal disentanglement map (goal); our paper also allows arbitrary distributions (soft, and/or perfect interventions with same/different mechanisms) from multiple domains (input), and non-parametric non-Markovian ASCMs vs linear Markovian ASCMs (assumptions). ", "page_idx": 45}, {"type": "text", "text": "Learning Causal Representations from General Environments: Identifiability and Intrinsic Ambiguity [24] In this paper, the authors propose a partial disentanglement goal in a linear, or non-parametric Markovian ASCM with a sparse causal structure. ", "page_idx": 45}, {"type": "text", "text": "Their notion of the disentanglement goal introduces so-called entanglement graphs (output), which is interestingly exactly what we call the causal disentanglement map. Though the proposed output is the same, the identifiability results are not the same even in the Markovian case. ", "page_idx": 45}, {"type": "text", "text": "In addition, in terms of the distributions leveraged (input), our work differs in considering arbitrary combinations of distributions (soft, or perfect, or observational) from heterogenous domains. In terms of modeling the ASCM (assumptions), our work considers completely non-parametric non-Markovian ASCMs instead of non-parametric Markovian ASCMs with sparse connectivity. In future work, we believe it will be interesting to explore the assumption of sparsity in the context of our work. ", "page_idx": 45}, {"type": "text", "text": "G Experimental Results ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "G.1 Synthetic data-generating process ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "We generate data according to latent causal diagrams shown in Fig. 4. Specifically, we analyze the chain graph $V_{1}\\rightarrow V_{2}\\rightarrow V_{3}$ , and collider graph $V_{1}\\to V_{2}\\leftarrow V_{3}$ with different input distributions. ", "page_idx": 45}, {"type": "text", "text": "Each graph is constructed according to an ASCM, where the latent variables are related linearly: ", "page_idx": 45}, {"type": "equation", "text": "$$\nV_{i}:=\\sum_{j\\in P a_{i}}\\alpha_{i,j}V_{j}+\\epsilon_{i}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "where linear parameters are drawn from a uniform distribution $\\alpha_{i,j}\\sim U(-a,a)$ , and the noise is distributed according to the standard normal distribution $\\epsilon_{i}\\sim\\mathcal{N}(0,1)$ . ", "page_idx": 45}, {"type": "text", "text": "Generating Multiple Domains To generate a new domain, where $S^{i,j}\\rightarrow V_{i}$ indicates a change in mechanism for $V_{i}$ due to the change in ASCMs between $M^{i}$ and $M^{j}$ , we start from the first ASCM generated, and then we modify the distribution of the noise variable with a mean-shift. ", "page_idx": 45}, {"type": "text", "text": "Generating Interventions Within Each Domain To generate interventional datasets within each domain $\\Pi^{i}\\in\\Pi$ , we modify the $\\mathbf{M}^{i}\\in M$ by additionally modifying the SCM, and shifting its mean for a variable. Therefore for distribution $k$ in $\\Pi^{i}$ , with perfect intervention $\\mathbf{I}$ , we will have: ", "page_idx": 46}, {"type": "equation", "text": "$$\nV_{k}:=\\epsilon_{k}^{\\prime},\\quad\\mathrm{with~}\\epsilon_{k}^{\\prime}\\sim\\mathcal{N}(\\mu_{k},\\sigma_{k}),\\ \\forall V_{k}\\in\\mathbf{I}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "such that $\\mu_{k}$ is not within $+/-1$ of any other distribution for variable $V_{k}\\in\\mathbf{V}$ . This ensures the Assumption of Generalized Distribution Change (Assump. 4). With a soft intervention $\\mathbf{J}$ that is not perfect: ", "page_idx": 46}, {"type": "equation", "text": "$$\nV_{k}:=\\sum_{j\\in P a_{k}}\\alpha_{i,j}V_{k}+\\epsilon_{k}^{\\prime},\\quad\\mathrm{with~}\\epsilon_{k}^{\\prime}\\sim\\mathcal{N}(\\mu_{k},\\sigma_{k}),\\,\\forall V_{k}\\in\\mathbf{J}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "For each distribution over $\\mathbf{V}\\in\\mathbb{R}^{d}$ , we generate 200,000 data points resulting in $d\\times200,000$ data points in total for $N$ total distributions. ", "page_idx": 46}, {"type": "text", "text": "We modify the mean and the variance to ensure that the Assumption of distribution change is met (Assump. 4). ", "page_idx": 46}, {"type": "text", "text": "Mixing function In order to generate the low-level data $\\mathbf{X}$ , we will apply a mixing function $f_{\\mathbf{X}}$ to the generated latent variables $\\mathbf{V}$ . Following [21, 51], to generate an invertible mixing function, we will use a multilayer perceptron $\\mathbf{f}_{\\mathbf{X}}=\\sigma\\circ\\mathbf{A}_{M}\\circ...\\circ\\sigma\\mathbf{A}_{1}$ , where $\\mathbf{A}_{M}\\in\\mathbb{R}^{d\\times d}$ for $m\\in[1,M]$ denotes invertible linear matrices and $\\sigma$ is an element-wise invertible nonlinear function. In our case, we will use the tanh functio as done in [81]: ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\sigma(x)=t a n h(x)+0.1x\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "In addition, each sampled matrix ${\\bf A}_{i}$ is re-drawn if $|\\operatorname*{det}\\mathbf{A}_{i}|<0.1$ . This ensures that the linear maps are not ill-conditioned and close to being singular. Once the mixing function is drawn for a given simulation, it is fixed across all domains and interventions according to Assump. 4, and then $\\mathcal{P}$ is drawn according to all ASCMs instantiated. ", "page_idx": 46}, {"type": "text", "text": "G.2 Image Editing Using Disentangled Representations ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "We demonstrate qualitatively that the generalized disentanglement proposed in this work is valuable for downstream tasks, such as counterfactual image editing [27]. Consider the graph shown in Fig. S8. Specifically, we use our learned proxy model to generate initial images and perform interventions on learned representations $\\widehat{\\bf V}$ to edit images. We generate initial image samples from observational distribution of $\\Pi_{1}$ , and then perturb the relevant representations with random Gaussian noise to edit the image. This is done for the color of the bar, color of the digit, and the digit representations. If the learned $\\widehat{\\mathbf{V}}$ satisfy the CRID output disentanglement, ", "page_idx": 46}, {"type": "text", "text": "1. editing the color of the digit $(\\sigma_{\\widehat{V}_{2}})$ should keep the original digit and writing style but may change the color of the bar since $V_{2}$ has a causal effect on $V_{3}$ .   \n2. editing the color of the bar $(\\sigma_{\\widehat{V}_{3}})$ should keep the original digit and writing style but may change the color of the digit since $V_{3}$ is not disentangled with $V_{2}$ .   \n3. editing digit $(\\sigma_{\\widehat{V}_{1}})$ may change all variables since no disentanglement of $V_{1}$ is claimed by CRID. ", "page_idx": 46}, {"type": "text", "text": "The editing results are shown in Fig. S7. All editing results are aligned with the CDM output as expected, which are illustrated above. Specifically, Fig. S7(a) shows the learned VAE-NF model can change the color of the bar without arbitrarily changing the digit, or writing style. Fig. S7(b) shows the learned VAE-NF model can change the color of the digit without arbitrarily changing the digit, or writing style. Finally, Fig. S7(c) shows the learned VAE-NF model did not learn a disentangled representation for \"digit\". When perturbing the representation for digit, sometimes the digit does not change, while the color of the bar, color of the digit, or the writing style changes. This experiment also demonstrates one usage of CRID. Before training a model that is potentially computationally and time-intensive, one can leverage CRID to determine if their input data and input assumptions are sufficient for learning a relevant disentangled representation for their downstream task. ", "page_idx": 46}, {"type": "image", "img_path": "uLGyoBn7hm/tmp/3e81d04c323de22acab4976491c97c78af0d9e37deb8e1a79ca4df31b482d01b.jpg", "img_caption": ["Figure S7: Editing the image using the learned representations - The representation of the color of the digit (a), color of the bar (b), and the digit (c) is perturbed. Only (a) and (b) show robust editing due to the learned representation being relatively disentangled as predicted by CRID. "], "img_footnote": [], "page_idx": 47}, {"type": "image", "img_path": "uLGyoBn7hm/tmp/b4d1c6d605af5c6fea794acd8315eda0a7d2a40cfbbec52430c914f9a65105a2.jpg", "img_caption": ["Figure S8: Color MNIST with bar data generation. The ground-truth LSD is shown in (a). Four distributions are generated with observations in domain $\\Pi_{1}$ (b), observations in domain $\\Pi_{2}$ (c), soft intervention on the color-bar $\\left(V_{3}\\right)$ in $\\Pi_{1}$ (d), and a perfect intervention on the color-digit $(V_{2})$ in $\\Pi_{1}$ . "], "img_footnote": [], "page_idx": 47}, {"type": "text", "text": "G.3 Model ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "We train invertible MLPs with normalizing flows. The parameters of the causal mechanisms are learned while the causal graph is assumed to be known. We leverage the implementation in [21], and extend it for our experiments. ", "page_idx": 47}, {"type": "text", "text": "The encoder is trained with the following objective that estimates the inverse function $f^{-1}$ , and the latent densities $P({\\bf V})$ reproducing the ground-truth up to certain mixture ambiguities (c.f. Lemmas 3, 6). The encoder parameters is estimated by maximizing the likelihood.. ", "page_idx": 47}, {"type": "text", "text": "Normalizing flows We use a normalizing flows architecture [82] to learn an encoder $\\mathbf{g}_{\\theta}:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{d}$ . Therefore, the observations $\\mathbf{X}$ will be the result of an invertible and differentiable transformation: ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\mathbf{X}=\\mathbf{g}_{\\theta}(\\mathbf{V})\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "Specifically, $g_{\\boldsymbol{\\theta}}$ will comprise of Neural Spline Flows [83] with a 3-layer feedforward neural network with hidden dimension 128 and a permutation in each flow layer. ", "page_idx": 48}, {"type": "text", "text": "Base distributions Normalizing flows require a base distribution. We leverage one baseline distribution per sampled dataset, $\\bar{(\\hat{p}_{\\theta}^{k})}_{k\\in[d]}$ over the base noise variables $\\mathbf{V}$ . The conditional density of any variable is given by: ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\hat{p}_{\\theta}^{k}(v_{i}|\\mathbf{Pa_{i}})=\\mathcal{N}\\bigg(\\sum_{j\\in P a_{i}}\\hat{\\alpha}_{i,j}v_{j},\\hat{\\sigma}_{i}\\bigg)\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "where the parameters are replaced by their corresponding counterparts if there is a change-in-domain, or an intervention applied. When a perfect intervention is applied, we have that: ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\hat{p}_{\\theta}^{k}(v_{i})=\\mathcal N(\\hat{\\mu}_{i},\\hat{\\sigma}_{i}\\Big)\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "G.4 Training details ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "We use the ADAM optimizer [84].We start with a learning rate of 1e-4. We train the model for 200 epochs with a batch size of 4096. ", "page_idx": 48}, {"type": "text", "text": "The learning objective is expressed as: ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\theta^{*}=\\arg\\operatorname*{max}_{\\theta}\\sum_{k=0}^{N}\\big(\\frac{1}{n_{k}}\\sum_{n=1}^{n_{k}}\\log p_{\\theta}^{k}(\\mathbf{X}^{(k)})\\big)\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "where $n_{k}$ represents the size of the dataset $P^{k}$ , which is 200,000 in our simulations. We perform 10 training runs over different seeds for each experiment, and show the distributions of the meancorrelation coefficient (MCC). Using the output of Alg. 1, we compare variables that are expected to be entangled and disentangled. We use NVIDIA H100 GPUs to train the neural network models. ", "page_idx": 48}, {"type": "text", "text": "G.5 Evaluation metrics ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "The output of our trained model is $\\hat{\\mathbf{V}}=g_{\\theta}(\\mathbf{X})$ , which is a d-dimensional representation. We will compare this representation with our ground-truth latent variable distributions $\\mathbf{V}$ by computing the mean correlation coefficients (MCC) between the learned and ground-truth latents. We expect there to be an overall lower MCC for variables that are predicted to be disentangleable by Alg. 1 relative to variables that are not deemed disentangleable. ", "page_idx": 48}, {"type": "text", "text": "Note that our algorithm is not shown to be complete, so there may be variables that are disentangled at the end of our training process that are not captured by the output of Alg. 1. Characterizing when this occurs and coming up with a complete theoretical characterization of disentanglement is a line for future work. ", "page_idx": 48}, {"type": "text", "text": "For the evaluation, we follow a standard evaluation protocol taken in prior work [18]. We expect low MCC values when predicting variables that are disentangled, and higher MCC values when predicting variables that are still entangled. ", "page_idx": 48}, {"type": "text", "text": "G.6 Limitations ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "A major limitation of normalizing flows is that the input and output dimensions of the encoder must be the same. This is due to the fact that we wish to constrain the layers to be invertible transformations. It is easy to define invertible transformations for the same input/output dimensions, but it is non-trivial to do so when input/output dimensions vary widely. ", "page_idx": 48}, {"type": "text", "text": "Besides the technical limitations of the implementation, it is important to note that our theoretical results are asymptotic results. The theory claims we can achieve ID when the neural network is trained to zero error. However, in practice, this is not always simple to do and may require hyperparameter tuning and a very large sample size. ", "page_idx": 49}, {"type": "text", "text": "For example, when we consider Fig. 6, we observe that the disentanglement of (b,c) is significantly better than (a,d). In the experiment involving the collider graph from Fig. 4(b), we sample four distributions each with 200,000 samples, and thus we have almost $2\\mathbf{x}$ the data points compared to the settings in Fig. 6(a,c). We illustrate this point to emphasize that there is no correct way to set the sample sizes, hyperparameters, or model architecture as each simulation will be different. We chose a sample size, model architecture, and default hyperparameters based on prior literature [21] instead of biasing our experimental results by tuning significantly for each simulation. ", "page_idx": 49}, {"type": "text", "text": "G.7 Discussion of Results ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "In Fig. S9, we show the MCC values for each learned latent representation $\\hat{\\textbf{V}}$ and the corresponding ground-truth latents $\\mathbf{V}$ for the three different LSDs shown in Fig. 4. Based on the causal disentanglement map (CDM) output from the CRID algorithm, the disentangled variables are shown in red, while the entangled variables are shown in gray. ", "page_idx": 49}, {"type": "text", "text": "In Fig. S9(a), the $M C C(\\hat{V}_{3},V_{1})$ is low relative to the $M C C(\\hat{V}_{3},V_{3})$ , which is predicted by the CRID algorithm\u2019s CDM output (right plot). This suggests that $V_{1}$ is disentangled from $V_{3}$ . In addition, we observe that all MCC values wrt $\\hat{V_{1}}$ are relatively similar, which makes sense as we do not obtain any disentanglement wrt $V_{1}$ (left plot). CRID also predicts that $V_{2}$ is ID wrt $V_{1}$ (middle plot). However, we observe quite a large range of MCC values, possibly due to variance, default hyperparameter settings, or insufficient sample size. Importantly, this experiment verifies that two soft interventions on $V_{3}$ in the chain graph of Fig. 4(a) can ID $V_{3}$ wrt $V_{1}$ , whereas previous literature suggested that $V_{3}$ is not ID wrt $V_{1}$ because $V_{1}\\in\\mathbf{A}\\mathbf{n}\\mathbf{c}(V_{3})$ [21]. ", "page_idx": 49}, {"type": "text", "text": "In Fig. S9(b), we now have an observational, two soft interventions on $V_{3}$ , and a perfect intervention on $V_{2}$ . In addition to ID $V_{2}$ wrt $V_{3}$ (middle plot), we are also able to obtain full disentanglement of $V_{1}$ from $\\{V_{2},V_{3}\\}$ (left plot). Interestingly, we are able to fully disentangle the representation for $V_{1}$ without intervening on it. This is the first theoretical (and empirical) result to our knowledge that shows this in a causal representation learning setting. ", "page_idx": 49}, {"type": "text", "text": "In Fig. S9(c), we have an observational and four interventional distributions applied on $\\{V_{1},V_{3}\\}$ all with different mechanisms. We observe that $V_{1}$ and $V_{3}$ are fully disentangled. $M C C(\\hat{V}_{3},V_{3})>$ $M C C(\\hat{V}_{3},\\{V_{1},V_{2}\\})$ , and $M C C(\\hat{V_{1}},V_{1})>M C C(\\hat{V_{1}},\\{V_{2},V_{3}\\})$ . CRID does not predict disentanglement for the $V_{2}$ representation (middle plot), yet interestingly we still see some disentanglement. [21] analyzes a similar setup using \"fat-hand interventions\", and the corresponding theory does predict $V_{1}$ and $V_{3}$ is ID wrt $V_{2}$ . However, we also disentangle $V_{1}$ and $V_{3}$ from each other using many interventions. [22] presents a similar approach by leveraging $2d+|\\mathcal{E}(M_{G})|+1$ distributions that \"sufficiently change\" (i.e. Assumption 4) to disentangle variables. However, the corresponding theory suggests that $V_{1}$ and $V_{3}$ are still entangled because they are adjacent in the Markov Network of G $(M_{G})$ . These results demonstrate theoretically (and empirically) that $V_{1}$ and $V_{3}$ are in fact disentangled from each other in a fundamentally important causal graph (i.e. the collider). ", "page_idx": 49}, {"type": "text", "text": "In Fig. S9(d), we consider disentanglement in a non-Markovian LSD. We leverage two perfect interventions on $V_{3}$ (c.f. Lemma 6), and verify that even without observational distributions and the challenging setting of confounding among the latent variables, we can achieve disentanglement of $V_{3}$ wrt all other variables. $M C C(\\hat{V_{3}},V_{3})>^{\\prime}M C C(\\hat{V_{3}},\\{V_{1},V_{2},V_{4}\\})$ , which is predicted by the CRID algorithm\u2019s CDM output (3rd plot from left). As expected, $V_{1}$ and $V_{2}$ are still fully entangled with all other variables (1st and 2nd plot from left). ", "page_idx": 49}, {"type": "image", "img_path": "uLGyoBn7hm/tmp/456b1366a7472a7534416d5ffd006eeb5ecaf8e9d5534e4705ba26edb3103240.jpg", "img_caption": ["Figure S9: Mean correlation coefficient (MCC) of latent ground truth variables with the learned representation $\\hat{\\textbf{V}}$ , and expected disentanglement (red) according to the CRID algorithm. Each plot corresponds to an experimental setting using the graphs shown in Fig. 4: chain graph with two interventions on $V_{3}$ (a). chain graph with two interventions on $V_{3}$ and a perfect intervention on $V_{2}$ (b), collider graph with four interventions on $\\{V_{1},V_{3}\\}$ (c) and the non-markovian graph with two perfect interventions on $V_{3}$ (d). "], "img_footnote": [], "page_idx": 50}, {"type": "text", "text": "H Broader Impact and Forward-Looking Statements ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "The development of learning disentangled causal representations has the potential to improve our understanding of complex systems, and to help identify the generative factors for many important problems. By improving our ability to leverage observational and interventional data across multiple domains, this work could ultimately lead to more realistic generative AI. Beyond the machine learning and causal inference community, we expect that our results will enable fundamental contributions in various fields, including biology [85], epidemiology [86], economics [37] and neuroscience [38]. ", "page_idx": 51}, {"type": "text", "text": "I Frequently Asked Questions ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Q1. What\u2019s the learning goal of the paper? This work claims to be causal representation learning, but why do we not learn the structure over the latent variables while assuming it as given? ", "page_idx": 51}, {"type": "text", "text": "Answer. ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Causal representation learning may comprise of two parts: i) learning the distributions of the latent variables and ii) learning the causal structure among these latent variables. Learning the distribution over latent variables is a non-trivial problem, especially in the context of non-Markovian ASCMs and the general multi-domain context. For example, consider nonlinear ICA, where the structure of the latent variables is the fully disconnected graph. It was shown to be non-ID with only iid data [9]. Although ID results eventually came about for nonlinear ICA, it was nontrivial to derive. In the same spirit, we seek to analyze the most general setting possible when assuming knowledge of the causal structure. This is analogous to the causal inference task of identification [87, 88], where the goal is to determine if a causal effect over observed variables is estimable given infinite data from some given distributions on the observed variables. Put similarly, our work\u2019s goal is to determine if a latent variable $V_{i}\\in\\mathbf{V}$ is disentangleable given infinite data from some given distributions over the observed variables $\\mathbf{X}$ . In traditional causal inference, when the causal graph is unknown, then one is typically interested in causal discovery, or structure learning of the graph over the observed variables given distributions over the observed variables. Future work may assume that even the latent causal structure is unknown, and pursue the structure learning of the LCG given distributions over the observed variables. ", "page_idx": 51}, {"type": "text", "text": "Q2. Is it reasonable to expect that the causal diagram is available? How do you get the graph? ", "page_idx": 51}, {"type": "text", "text": "Answer. ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "The assumption of the causal diagram is made out of necessity. Even existing methods is able to learn the casual diagram at the same time, however, the setting is more restricted. For example, the SCM should be Markovian and the intervention data per node should be given. In our setting, the underlying SCM can be non-Markovian and the given data can be any observational and interventional data from an arbitrary domain. In the general setting, even when the generative factors are all observed, learning the causal diagram task (structural learning task) is still difficult. Interestingly, recovering the full true diagram is even impossible, and existing works aim to recover an equivalence class of diagrams [32, 89\u201391]. Thus, in this general setting for causal representation learning, we first provide identification results given a causal diagram and leave structure learning for future work. ", "page_idx": 51}, {"type": "text", "text": "We follow closely to the disentangled representation learning works that assume the causal diagram is given. ICA/Nonlinear ICA assumes the diagram $G$ is given and restricts the setting where no edges are in $G$ . Later, [18] assumes focus on disentangling the content variable from the style variable and assumes the knowledge of the diagram is given (Content is the ancestral of Style). Recently, [21] focuses on the setting that the given diagram is Markovian. We extend the setting to non-Markovain settings. Notice that our generalization is not only related to diagram assumption but involves more general assumption, data, and output (please see Sec. 1, Tab. 1 and Tab. S1 for details.) ", "page_idx": 51}, {"type": "text", "text": "In practice, knowledge of the latent causal graph is typically provided by domain experts, or a modeling assumption. As an example of a realistic setting where the latent causal graph can be assumed, consider generating realistic face images [27]. Here, the latent causal structure comprises of Gender, Age, and Hair Color. Knowledge of the graph is provided due to our understanding of what comprises realistic changes in a face. For a detailed discussion on this, see Appendix Section D.1. ", "page_idx": 51}, {"type": "text", "text": "Q3. Why CRID (Alg. 1) only takes intervention targets $\\Psi$ and LSG $G^{S}$ as input? Do you need distributions $\\mathcal{P}?$ If not, how do you learn representations? ", "page_idx": 52}, {"type": "text", "text": "Answer. CRID leverages the intervention targets $\\Psi$ and the LSG $G^{S}$ to determine the invariant and changing factors when considering the generalized factorization of probability distributions Markov relative to the provided graph. These invariant and changing factors are what give rise to the theory we develop in Section 3. The CRID algorithm leverages this theory to provide an identifiability algorithm, which answers the question: If we fully learn a representation $\\hat{\\textbf{V}}$ (given the diagram and the distributions), which variables are expected to be disentangled with which variables? This is an asymptotic question and assumes the representation is fully learned. ", "page_idx": 52}, {"type": "text", "text": "To fully learn the representations, one can search a proxy model that matches $\\mathcal{P}$ and $\\mathcal{G}^{S}$ and the $\\widehat{\\mathbf{V}}$ . Then the proxy model is the learned representation. We do this in the Experiments Section, but note we do not claim that this method of learning the representations is superior to any prior work. Specifically, we implement an approach to train a neural model that is compatible with the diagram to match the given distribution based on normalizing flows. Recently, many graphical constraints proxy neural models have been proposed, and they are trained to fit the given distribution for causal representation learning and downstream tasks [20, 27, 55, 92\u201394]. Without our work, one can still try to use these models to learn representations. However, there is no guarantee about how these learned representations is entangled with each other. Our work is the first one to provide general answers for this identification problem. This process can be compared with the identification and estimation problem in classic causal inference. The identification of a specific query given a causal diagram can be answered in symbolic ways [87, 95\u201399], and then if the query is identifiable, one can take the distribution (or data) as input and use estimation methods to obtain the estimated query. Without the identifiability result, there are no guarantees for the estimation. ", "page_idx": 52}, {"type": "text", "text": "Q4. Why not just use observational distributions in each domain as the baseline in the CRID algorithm described in Section 4? ", "page_idx": 52}, {"type": "text", "text": "Answer. One may surmise that this is not efficient and propose to choose the observational distribution in each domain alternatively. However, we argue that this enumeration is needed from two perspectives. First, the observational distributions, namely the idle interventions, are not always given. Second, comparing with observational distributions is not guaranteed to offer diverse $\\Delta\\mathbf{Q}$ sets. For example, consider intervention targets $\\mathbf{I}^{(1)}=\\big\\{\\bar{\\mathbf{\\big}}^{\\Pi_{1}},\\mathbf{I}^{(2)}=$ $\\{V_{1}^{\\Pi_{1},[1]},V_{2}^{\\Pi_{1},[1]}\\},\\mathbf{I}^{(3)}=\\{V_{1}^{\\Pi_{1},[1]},V_{2}^{\\Pi_{1},[2]}\\}$ all applied to the same domain $\\Pi_{1}$ . Choosing $\\mathbf{T}=\\{\\}$ and comparing $\\mathbf{I}^{(2)}$ and $\\mathbf{I}^{(3)}$ with the idle intervention $\\mathbf{I}^{(1)}$ , ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\Delta\\mathbf{Q}[\\mathbf{I}^{(2)},\\mathbf{I}^{(1)},\\mathbf{T}]=\\Delta\\mathbf{Q}[\\mathbf{I}^{(3)},\\mathbf{I}^{(1)},\\mathbf{T}]=\\{V_{1},V_{2}\\}.\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Comparing $\\mathbf{I}^{(1)}$ and $\\mathbf{I}^{(3)}$ with the idle intervention $\\mathbf{I}^{(2)}$ , ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\Delta\\mathbf{Q}[\\mathbf{I}^{(1)},\\mathbf{I}^{(2)},\\mathbf{T}]=\\Delta\\mathbf{Q}[\\mathbf{I}^{(3)},\\mathbf{I}^{(2)},\\mathbf{T}]=\\{V_{2}\\}.\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Then using Proposition 3, it is possible to disentangle $V_{2}$ from $V_{1}$ with the latter choice. This demonstrates that the observational distribution is not always necessarily the best baseline. Furthermore, consider the challenge of disentangling $V_{1}$ from $V_{2}$ in the LCG $V_{1}\\ \\gets\\mathrm{---\\}\\Sigma_{2}$ . As Lemma 6 demonstrates, one can compare two perfect intervention distributions on $V_{1}$ to achieve ID of $V_{1}$ wrt $V_{2}$ . In this case, one would not even need the observational distribution. ", "page_idx": 52}, {"type": "text", "text": "Q5. Why distinguish domains and interventions? Are they not the same thing? ", "page_idx": 52}, {"type": "text", "text": "Answer. The literature has typically conflated domains and interventions in the context of causal inference. ", "page_idx": 52}, {"type": "text", "text": "Many examples across scientific disciplines demonstrate that the notions of domain/environment and interventions are distinct. For example, when making inferences about humans based on data from bonobos, this distinction becomes clear. The difference between the two species is depicted as the environment/domain in this context. A scientist might perform an intervention on a bonobo\u2019s kidney (specifically, what we\u2019re representing as $Z$ ), and try to determine the effect of medication $(X)$ on fluid equilibrium in the body $(Y)$ . Although we could intervene on $Z$ in bonobos and observe its effect on $X$ and $Y$ , our ultimate goal might be to understand the effect of $X$ on $Y$ in humans. It\u2019s generally invalid to conflate these two qualitatively different indices, a point first noted by [62] in the context of transportability analysis. The distinct environments exist regardless of any intervention, such as medication. Also, an intervention on kidney function is different across the two species. [62] formalized this setting, introducing clear semantics for the S-nodes (environments) that essentially offer a combined representation for both environments. With this foundation, we can now address the more general problem of analyzing data generated from interventions across multiple domains in the latent space. ", "page_idx": 52}, {"type": "text", "text": "", "page_idx": 53}, {"type": "text", "text": "We point the reader to Appendix Section A.3 for a discussion and some examples of how CRID leverages this distinction. More recently, ", "page_idx": 53}, {"type": "text", "text": "In addition, we provide the following example that we hope further motivates the necessity of distinguishing interventions and domains. ", "page_idx": 53}, {"type": "text", "text": "Example 24 (Disentangled representation with interventions in different domains). Consider a ASCM, $\\mathcal{M}$ over domains bonobos $(\\Pi^{1})$ and humans $(\\Pi^{2})$ that induces the causal chain $V_{1}\\rightarrow V_{2}\\rightarrow V_{3}\\leftarrow S^{1,2}$ . The latent variables are sun exposure $(V_{1})$ , Age $(V_{2})$ , Hair Color $\\left(V_{3}\\right)$ . Sun exposure causes aging over time, and aging causes changes in hair color. Hair color looks different across species, which is represented by the $S_{}$ -node. We collect images of their faces, $\\mathbf{X}=f_{X}(V_{1},V_{2},V_{3})$ . Assume we are able to collect images in two interventional settings $\\{V_{1}\\}^{\\Pi_{1}}$ and $\\{V_{1}\\}^{\\Pi_{2}}$ , where we modify the level of sun exposure each participant is exposed to. ", "page_idx": 53}, {"type": "text", "text": "Now, assume we ignore the domain index, and simply treat these two distributions as interventional, since we are intervening on $V_{1}$ . Then prior results would state that a soft (or perfect) intervention on $V_{1}$ allows it to be disentangled from $V_{3}$ . However, this is incorrect. \u53e3 ", "page_idx": 53}, {"type": "text", "text": "Q6. Is the relaxation of Markovianity important? Since all $\\mathbf{V}$ are already latent, can one regard the confounding $\\mathbf{U}$ as $\\mathbf{V}$ to transfer the model in the non-Markovianity setting to a Markovanity model? ", "page_idx": 53}, {"type": "text", "text": "answer ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Yes the distinction between Markovianity and non-Markovianity is important both qualitatively and quantitatively. ", "page_idx": 53}, {"type": "text", "text": "Qualitatively, consider the following example in healthcare, where one has access to highdimensional T1 MRI scans. Let the LCG comprise of Drug Treatment $\\rightarrow$ Outcome, but they are confounded by socioeconomic status (Drug Treatment $\\leftarrow-\\rightarrow$ Outcome). The drug treatment and outcome are visually discernable on the MRI. However, socioeconomic status does not directly impact how the MRI appears, except through how it impacts the drug treatment efficacy or outcome. The socioeconomic status is therefore an unaccounted confounder in the LCG, and it is important to model this spurious association. If unaccounted for, one may assume that it is possible to disentangle Drug Treatment and Outcome leveraging existing ID results in the literature [11, 13, 14, 21, 22] even if the results do not apply in this setting. ", "page_idx": 53}, {"type": "text", "text": "Regarding modeling, an ASCM with confounding cannot be reduced to a Markovian ASCM. Although $\\mathbf{U}$ and $\\mathbf{V}$ are both latent, every U is not the direct parents of X, which means U cannot be uniquely determined by value of $\\mathbf{X}$ . Take the example where $V_{1}\\ \\gets\\mathrm{---\\}\\Sigma_{2}$ is the LCG $G$ . Since $U_{12}$ does not point to X, we cannot let $U_{12}$ be another latent generative factor $\\mathbf{V}$ . ", "page_idx": 53}, {"type": "text", "text": "Regarding results, we point the reader to Lemma 5, where it is shown that even with one perfect interventions per node, it is not possible to disentangle variables within the same c-component. This in contrast with results in the Markovian setting, where it is shown in [21] that one perfect intervention per latent variable allows us to achieve full identifiability of every latent variable up to scaling indeterminancies. ", "page_idx": 53}, {"type": "text", "text": "More broadly, it is noteworthy that transitioning causal reasoning from Markovian to nonMarkovian settings was not trivial. For example, it is known that interventional distributions, such as $P(y\\mid d o(x))$ , are always identifiable from the causal graph and observational distribution in Markovian settings in all models. Moving to non-Markovian settings, the celebrated do-calculus is developed primarily to address the decision problem of whether an interventional distribution can be uniquely computed from a combination of causal assumptions (in the form of a causal diagram) and the observational distribution [61]. ", "page_idx": 53}, {"type": "text", "text": "Naturally, the issue of non-identifiability is much more acute in this setting, due to the existence of unobserved confounding. ", "page_idx": 54}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 55}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 55}, {"type": "text", "text": "Justification: We claim that we introduce graphical criteria and an algorithm for determining whether latent variables are ID or not from our general definition of ID. We then provide our results in Section 3 and 4. ", "page_idx": 55}, {"type": "text", "text": "Guidelines: ", "page_idx": 55}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 55}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 55}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Justification: We discuss the assumptions made in this paper in Appendix Section A.2, and how future work can potentially improve upon our limitations. ", "page_idx": 55}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 55}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 56}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "Justification: For each proposition and Theorem stated in the main text: Propositions 1, 2, 3, 4, 5 and Theorem 1 are stated in the main text, and proved in Appendix Section C. Guidelines: ", "page_idx": 56}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 56}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 56}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 56}, {"type": "text", "text": "Justification: We provide details of our experiments in Appendix Section G. ", "page_idx": 56}, {"type": "text", "text": "Guidelines: ", "page_idx": 56}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 56}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 57}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 57}, {"type": "text", "text": "Justification: The code we used to run experiments is here: https://github.com/tree1111/CDRL. ", "page_idx": 57}, {"type": "text", "text": "Guidelines: ", "page_idx": 57}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 57}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 57}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Justification: We provide details of our experiments in Appendix Section G. ", "page_idx": 57}, {"type": "text", "text": "Guidelines: ", "page_idx": 57}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 57}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 57}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Justification: We show distribution plots, and do not compute any pvalues. ", "page_idx": 57}, {"type": "text", "text": "Guidelines: ", "page_idx": 57}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 57}, {"type": "text", "text": "", "page_idx": 58}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 58}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 58}, {"type": "text", "text": "Justification: We provide details of our experiments in Appendix Section G. ", "page_idx": 58}, {"type": "text", "text": "Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 58}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 58}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Justification: We have reviewed the code of ethics. ", "page_idx": 58}, {"type": "text", "text": "Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 58}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 58}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 58}, {"type": "text", "text": "Justification: We discuss broader impacts in Appendix Section H. ", "page_idx": 58}, {"type": "text", "text": "Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 58}, {"type": "text", "text": "", "page_idx": 59}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 59}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 59}, {"type": "text", "text": "Justification: Our paper poses no such risks. ", "page_idx": 59}, {"type": "text", "text": "Guidelines: ", "page_idx": 59}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 59}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 59}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 59}, {"type": "text", "text": "Justification: We cited [21], which we leveraged their code to produce experimental results shown in the paper. We do not repackage any datasets, or code. ", "page_idx": 59}, {"type": "text", "text": "Guidelines: ", "page_idx": 59}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 59}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 60}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 60}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 60}, {"type": "text", "text": "Justification: Our paper does not release new assets. ", "page_idx": 60}, {"type": "text", "text": "Guidelines: ", "page_idx": 60}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 60}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 60}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 60}, {"type": "text", "text": "Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 60}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 60}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 60}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 60}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 60}]