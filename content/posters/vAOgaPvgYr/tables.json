[{"figure_path": "vAOgaPvgYr/tables/tables_1_1.jpg", "caption": "Table 1: OccamLLM is the only approach to improving the arithmetic capabilities of a pretrained LLM which 1) enables single-pass arithmetic, 2) does not risk catastrophic forgetting from finetuning, 3) does not require arbitrary code execution, and 4) provides an interpretable process.", "description": "This table compares different methods for improving the arithmetic capabilities of pretrained LLMs along four key aspects: single-pass arithmetic, risk of catastrophic forgetting due to finetuning, need for arbitrary code execution, and interpretability of the process.  It highlights that OccamLLM uniquely excels in all four aspects.", "section": "1 Introduction"}, {"figure_path": "vAOgaPvgYr/tables/tables_6_1.jpg", "caption": "Table 2: Accuracy on arithmetic tasks, in percentages. The OccamLlama column corresponds to the results of both OccamLlama 8B and OccamLlama 70B. Higher is better. Bold indicates best performance for each row.", "description": "This table presents the accuracy of different language models on various arithmetic tasks.  The accuracy is shown as a percentage, with higher percentages indicating better performance.  The models compared are OccamLlama 8B, OccamLlama 70B, Llama 2 7B Chat, Llama 3 8b Instruct, GPT 3.5 Turbo, and GPT 40 (with and without code interpreter).  The arithmetic tasks include addition, subtraction, multiplication, division, square root, exponential, logarithm, sine, and cosine. OccamLlama consistently achieves 100% accuracy, significantly outperforming other models, especially on more complex operations.", "section": "4.1 Simple Arithmetic Problems"}, {"figure_path": "vAOgaPvgYr/tables/tables_9_1.jpg", "caption": "Table 3: Accuracy on multistep arithmetic.", "description": "This table compares the accuracy of OccamLlama and Llama 3 8B Instruct on multi-step arithmetic tasks (one-step, two-step, and three-step).  It demonstrates OccamLlama's ability to handle increasingly complex arithmetic operations with high accuracy, even outperforming Llama 3 8B significantly, especially as the number of steps increases.", "section": "4 Experiments"}, {"figure_path": "vAOgaPvgYr/tables/tables_14_1.jpg", "caption": "Table 2: Accuracy on arithmetic tasks, in percentages. The OccamLlama column corresponds to the results of both OccamLlama 8B and OccamLlama 70B. Higher is better. Bold indicates best performance for each row.", "description": "This table compares the accuracy of various language models on a series of arithmetic tasks, including addition, subtraction, multiplication, division, square root, exponential, logarithm, sine, and cosine.  The accuracy is presented as a percentage, with standard error included.  OccamLlama consistently achieves 100% accuracy, significantly outperforming other models, especially on more complex operations.", "section": "4.1 Simple Arithmetic Problems"}, {"figure_path": "vAOgaPvgYr/tables/tables_15_1.jpg", "caption": "Table 2: Accuracy on arithmetic tasks, in percentages. The OccamLlama column corresponds to the results of both OccamLlama 8B and OccamLlama 70B. Higher is better. Bold indicates best performance for each row.", "description": "This table presents the accuracy of different language models on various arithmetic tasks, including addition, subtraction, multiplication, division, square root, exponential, logarithm, sine, and cosine.  The accuracy is measured as a percentage and presented with error bars.  OccamLlama consistently achieves 100% accuracy, significantly outperforming other models, particularly on more complex operations.", "section": "4.1 Simple Arithmetic Problems"}, {"figure_path": "vAOgaPvgYr/tables/tables_17_1.jpg", "caption": "Table 2: Accuracy on arithmetic tasks, in percentages. The OccamLlama column corresponds to the results of both OccamLlama 8B and OccamLlama 70B. Higher is better. Bold indicates best performance for each row.", "description": "This table presents the accuracy of different language models on various arithmetic tasks, including addition, subtraction, multiplication, division, square root, exponential, logarithm, sine, and cosine.  The accuracy is measured as a percentage, with higher percentages indicating better performance. The results for OccamLlama represent the average performance of both the 8B and 70B versions of the model.  The table highlights the superior accuracy of OccamLlama compared to other models, especially on more complex arithmetic operations.", "section": "4 Simple Arithmetic Problems"}, {"figure_path": "vAOgaPvgYr/tables/tables_18_1.jpg", "caption": "Table 6: Percent accuracy on reasoning tasks. Higher is Better. Bold indicates best performance.", "description": "This table presents the accuracy of various LLMs on mathematical reasoning tasks.  The LLMs are compared across several benchmarks (AddSub, GSM8K, MultiArith, MultiArith Float, MATH401, Single Eq, SVAMP). The accuracy is expressed as a percentage with error bars. OccamLlama models (8B and 70B) show superior performance compared to baselines like Llama 3 and GPT models, especially on tasks with challenging arithmetic.", "section": "4.2 Mathematical Problem Solving"}, {"figure_path": "vAOgaPvgYr/tables/tables_19_1.jpg", "caption": "Table 2: Accuracy on arithmetic tasks, in percentages. The OccamLlama column corresponds to the results of both OccamLlama 8B and OccamLlama 70B. Higher is better. Bold indicates best performance for each row.", "description": "This table presents the accuracy of different language models on various arithmetic tasks (addition, subtraction, multiplication, division, square root, exponential, logarithm, sine, cosine).  The accuracy is expressed as a percentage, with the OccamLlama models (OccamLlama 8B and 70B) showing 100% accuracy on all tasks.  Other models, such as Llama 2, Llama 3, GPT 3.5 Turbo, and GPT 40 (with and without code interpreter), show significantly lower accuracy, highlighting the superior performance of OccamLlama on arithmetic tasks.", "section": "4.1 Simple Arithmetic Problems"}, {"figure_path": "vAOgaPvgYr/tables/tables_21_1.jpg", "caption": "Table 6: Percent accuracy on reasoning tasks. Higher is Better. Bold indicates best performance.", "description": "This table presents the accuracy of various language models on mathematical reasoning tasks.  The models are compared across six different benchmarks (AddSub, GSM8K, MultiArith, MultiArith Float, MATH401, Single Eq, SVAMP), each designed to test different aspects of mathematical reasoning ability. The table shows the percentage accuracy for each model on each benchmark, highlighting the best-performing model for each benchmark in bold.  The results show that OccamLlama consistently outperforms other models, especially on more challenging tasks.", "section": "4.2 Mathematical Problem Solving"}]