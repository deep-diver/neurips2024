[{"figure_path": "N0xNf9Qqmc/tables/tables_5_1.jpg", "caption": "Table 1: Unsupervised segmentation results. Best method in bold, second is underlined.", "description": "This table presents the mean Intersection over Union (mIoU) scores achieved by various unsupervised semantic segmentation methods on six benchmark datasets (Pascal VOC, Pascal Context, COCO-Object, COCO-Stuff-27, Cityscapes, and ADE20K).  The methods are categorized into those requiring extra training data (Extra-Training) and those that are training-free (Training-free).  The table highlights DiffCut's superior performance compared to existing state-of-the-art methods.  It also indicates whether a method relies on language dependency (LD), auxiliary images (AX), or unsupervised adaptation (UA).", "section": "4 Experiments"}, {"figure_path": "N0xNf9Qqmc/tables/tables_7_1.jpg", "caption": "Table 2: Ablation Study. The recursive partitioning of DiffCut yields superior results to both the self-attention merging process of DiffSeg and Automated Spectral Clustering. ", "description": "This ablation study compares the performance of DiffCut against two variations: DiffSeg (using a self-attention merging process) and AutoSC (using automated spectral clustering).  The table shows the mean Intersection over Union (mIoU) scores achieved by each method across six different datasets (VOC, Context, COCO-Object, COCO-Stuff-27, Cityscapes, ADE20K).  It demonstrates that DiffCut's recursive partitioning significantly outperforms both alternatives, highlighting the effectiveness of its approach.", "section": "4.3 Ablation study"}, {"figure_path": "N0xNf9Qqmc/tables/tables_8_1.jpg", "caption": "Table 3: Features Contribution. Hierarchical features in E32 provide optimal performance (Pascal VOC validation set).", "description": "This table presents ablation study results to show the contribution of different hierarchical features extracted from the UNet encoder to the overall performance of DiffCut.  It shows the mIoU scores achieved on the Pascal VOC validation set when using features from different encoder layers (32x32 and 64x64 resolution). The results indicate that the features from the 32x32 resolution layer provide the best performance, suggesting that lower resolution features are sufficient for optimal semantic segmentation in this context. Combining features from multiple layers does not improve performance, and instead increases computational overhead.", "section": "4.3 Ablation study"}, {"figure_path": "N0xNf9Qqmc/tables/tables_8_2.jpg", "caption": "Table 1: Unsupervised segmentation results. Best method in bold, second is underlined.", "description": "This table presents a comparison of unsupervised semantic segmentation methods on six benchmark datasets (Pascal VOC, Pascal Context, COCO-Object, COCO-Stuff-27, Cityscapes, and ADE20K).  The methods are categorized as either requiring extra training or being training-free.  The key metric is mean Intersection over Union (mIoU). DiffCut achieves the highest mIoU scores in most cases, highlighting its effectiveness compared to other state-of-the-art methods for zero-shot image segmentation.", "section": "4 Experiments"}, {"figure_path": "N0xNf9Qqmc/tables/tables_16_1.jpg", "caption": "Table 2: Ablation Study. The recursive partitioning of DiffCut yields superior results to both the self-attention merging process of DiffSeg and Automated Spectral Clustering.", "description": "This table presents the ablation study results, comparing the performance of DiffCut against two variations: DiffSeg (using self-attention merging) and Automated Spectral Clustering.  It shows that DiffCut's recursive partitioning approach significantly outperforms both alternatives across various datasets (VOC, Context, COCO-Object, COCO-Stuff, Cityscapes, ADE20K), demonstrating the effectiveness of its key design choices.", "section": "4.3 Ablation study"}, {"figure_path": "N0xNf9Qqmc/tables/tables_17_1.jpg", "caption": "Table 6: Comparison with MaskCut. DiffCut recursive partitioning algorithm yields superior results than MaskCut iterative partitioning.", "description": "This table compares the performance of DiffCut and MaskCut on six benchmark datasets (VOC, Context, COCO-Object, COCO-Stuff-27, Cityscapes, ADE20K). It demonstrates that DiffCut's recursive partitioning approach outperforms MaskCut's iterative approach.  The comparison is performed by varying the number of segments (k) detected by MaskCut (k = 3, 5, 20).  DiffCut consistently achieves better mIoU scores across all datasets and k values, highlighting its ability to dynamically adjust the number of segments based on visual content.", "section": "4.3 Ablation study"}, {"figure_path": "N0xNf9Qqmc/tables/tables_17_2.jpg", "caption": "Table 7: Performance of DiffCut with alternative diffusion backbones.", "description": "This table presents a comparison of DiffCut's performance using three different diffusion backbones: SD1.4, SSD-Vega, and SSD-1B.  It shows the mean Intersection over Union (mIoU) scores achieved on six different semantic segmentation benchmark datasets (VOC, Context, COCO-Object, COCO-Stuff-27, Cityscapes, and ADE20K). The results demonstrate DiffCut's robustness across various backbone choices, achieving competitive performance even with smaller models like SD1.4 and SSD-Vega compared to DiffSeg, a state-of-the-art baseline.", "section": "4.4 Model Analysis"}, {"figure_path": "N0xNf9Qqmc/tables/tables_17_3.jpg", "caption": "Table 8: Mask Upsampling", "description": "This ablation study compares two different upsampling strategies for generating high-resolution segmentation maps from low-resolution maps produced by the recursive normalized cut algorithm. The \"Concept Assignment\" strategy uses a concept assignment mechanism to assign pixel labels based on similarity to upsampled features of the segments, while the \"Nearest Upsampling\" strategy simply performs nearest-neighbor upsampling. The results show that the concept assignment strategy significantly outperforms the nearest upsampling approach, achieving a mIoU score of 62.0 compared to 61.2 for nearest upsampling.  This highlights the effectiveness of semantic information preservation in the concept assignment approach.", "section": "4.3 Ablation study"}, {"figure_path": "N0xNf9Qqmc/tables/tables_18_1.jpg", "caption": "Table 10: Threshold tuning. Tuned \u03c4 is denoted with \u03c4*.", "description": "This table presents the results of DiffCut where the threshold parameter \u03c4 is tuned using a small subset of annotated images from the target training split.  The tuning process aims to find an optimal \u03c4 value for each dataset (COCO-Object, COCO-Stuff-27, and Cityscapes) that balances the trade-off between segment granularity and segmentation accuracy.  The results demonstrate the impact of tuning \u03c4 on the performance of the method across different datasets.", "section": "4.1 Results on Zero-shot Segmentation"}, {"figure_path": "N0xNf9Qqmc/tables/tables_19_1.jpg", "caption": "Table 1: Unsupervised segmentation results. Best method in bold, second is underlined.", "description": "This table presents a comparison of unsupervised semantic segmentation methods on six benchmark datasets (Pascal VOC, Pascal Context, COCO-Object, COCO-Stuff-27, Cityscapes, and ADE20K).  The table shows the mean Intersection over Union (mIoU) achieved by each method.  The methods are categorized by whether they require language dependency (LD), auxiliary images (AX), or unsupervised training (UA).  The table highlights that DiffCut outperforms other state-of-the-art methods on this task.", "section": "4 Experiments"}]