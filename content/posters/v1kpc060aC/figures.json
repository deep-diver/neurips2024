[{"figure_path": "v1kpc060aC/figures/figures_3_1.jpg", "caption": "Figure 1: Illustration of the delay interval \u03c4(i) for worker i at iteration t, marking t (current iteration), t(i) (most recent update from worker i), and t \u2212 \u03c4(i) (previous update from worker i).", "description": "The figure shows a timeline illustrating delays in asynchronous distributed systems.  The timeline is divided into segments representing different update times from a worker (i).  The green circles represent previous updates from worker i at time t \u2212 \u03c4(i) and t(i). The blue circle represents the current time t. The thick black line at the bottom represents the delay \u03c4(i) between the current update and the previous update from worker i.", "section": "2 Setting"}, {"figure_path": "v1kpc060aC/figures/figures_9_1.jpg", "caption": "Figure 5: MNIST. Test Accuracy of Weighted vs. Non-Weighted Robust Aggregators. This scenario involves 17 workers, including 8 Byzantine workers, with workers' arrival probabilities proportional to the square of their IDs. We used the \u03bc\u00b2-SGD in this scenario. Left: label flipping, \u03bb = 0.3. Right: sign flipping, \u03bb = 0.4.", "description": "This figure compares the test accuracy of weighted and non-weighted robust aggregators on the MNIST dataset in an asynchronous Byzantine setting.  The experiment uses 17 workers, 8 of which are Byzantine, and simulates a scenario where faster workers send updates more frequently (arrival probability proportional to the square of their ID). The comparison is shown for two types of Byzantine attacks: label flipping (left) and sign flipping (right). The results illustrate that weighted robust aggregators generally perform better than their non-weighted counterparts.", "section": "Experiments"}, {"figure_path": "v1kpc060aC/figures/figures_9_2.jpg", "caption": "Figure 6: MNIST. Test Accuracy Comparison of Weighted Robust Aggregators With and Without w-CTMA. This scenario involves 9 workers, with a very fast Byzantine worker, and workers' arrival probabilities proportional to their IDs. On the left, we have a sign flipping attack with standard momentum (\u03b2 = 0.9, \u03bb = 0.4), and on the right, we have little (\u03bb = 0.2) and empire (\u03bb = 0.4) attacks with \u03bc\u00b2-SGD.", "description": "This figure compares the test accuracy of weighted robust aggregators (w-CWMed and w-RFA) with and without the w-CTMA meta-aggregator under different Byzantine attack scenarios in MNIST dataset.  The scenarios include sign flipping and attacks named \"little\" and \"empire\", which differ in their characteristics and aggressiveness. The results show that incorporating w-CTMA enhances the accuracy, especially in challenging scenarios like the 'empire' attack.  The x-axis represents the number of iterations, and the y-axis shows the test accuracy.", "section": "Experiments"}, {"figure_path": "v1kpc060aC/figures/figures_9_3.jpg", "caption": "Figure 4: CIFAR-10. Test Accuracy Comparison Among Different Optimizers. This scenario involves 9 workers (4 Byzantine) with \u03bb = 0.4 for the first three from left to right, and \u03bb = 0.3 for the label flipping attack on the left. Workers\u2019 arrival probabilities are proportional to their IDs.", "description": "This figure compares the performance of three different optimizers (\u03bc\u00b2-SGD, standard momentum, and SGD) on the CIFAR-10 dataset in an asynchronous Byzantine setting.  The results show that \u03bc\u00b2-SGD performs similarly to standard momentum, while SGD performs significantly worse.  The experiment simulates 9 workers, with 4 of them being Byzantine (malicious or faulty). The fraction of Byzantine updates is set at \u03bb = 0.4 for the first three scenarios, and \u03bb = 0.3 for the label flipping attack.  Worker arrival probabilities are proportional to their ID, leading to an imbalanced asynchronous setting. The results highlight the importance of using more advanced algorithms like \u03bc\u00b2-SGD, which leverage historical information, for robust performance in asynchronous Byzantine settings.", "section": "4 Asynchronous Robust Training"}, {"figure_path": "v1kpc060aC/figures/figures_28_1.jpg", "caption": "Figure 5: MNIST. Test Accuracy of Weighted vs. Non-Weighted Robust Aggregators. This scenario involves 17 workers, including 8 Byzantine workers, with workers\u2019 arrival probabilities proportional to the square of their IDs. We used the \u03bc\u00b2-SGD in this scenario. Left: label flipping, \u03bb = 0.3. Right: sign flipping, \u03bb = 0.4.", "description": "This figure compares the test accuracy of weighted and non-weighted robust aggregators on the MNIST dataset in an asynchronous Byzantine setting.  The experiment uses 17 workers (8 Byzantine), with faster workers having a higher chance of contributing updates.  Two attack types are shown: label flipping (left) and sign flipping (right), with different fractions of Byzantine updates (\u03bb).  The results demonstrate that weighted robust aggregators consistently outperform their non-weighted counterparts.", "section": "Experiments"}, {"figure_path": "v1kpc060aC/figures/figures_28_2.jpg", "caption": "Figure 6: MNIST. Test Accuracy Comparison of Weighted Robust Aggregators With and Without w-CTMA. This scenario involves 9 workers, with a very fast Byzantine worker, and workers' arrival probabilities proportional to their IDs. On the left, we have a sign flipping attack with standard momentum (\u03b2 = 0.9, \u03bb = 0.4), and on the right, we have little (\u03bb = 0.2) and empire (\u03bb = 0.4) attacks with \u03bc\u00b2-SGD.", "description": "This figure compares the performance of weighted robust aggregators (w-CWMed and w-RFA) with and without the addition of the w-CTMA meta-aggregator under different Byzantine attack scenarios in the MNIST dataset. The attacks simulated are sign flipping, little, and empire.  The results show that w-CTMA improves robustness, particularly in more challenging attack scenarios like the empire attack.", "section": "Experiments"}, {"figure_path": "v1kpc060aC/figures/figures_28_3.jpg", "caption": "Figure 7: MNIST. Test Accuracy Comparison Among Different Optimizers. This scenario involves 9 workers, with \u03bb = 0.4, 4 Byzantine workers, and workers\u2019 arrival probabilities proportional to their IDs. We also compared between momentum with the standard parameter \u03b2 = 0.9 suggested by Karimireddy et al. [2021] and a fine-tuned parameter \u03b2 = 0.8.", "description": "This figure compares the performance of three different optimizers: \u03bc\u00b2-SGD, standard momentum (with \u03b2=0.8 and \u03b2=0.9), and standard SGD in an asynchronous Byzantine setting on the MNIST dataset. The experiment setup includes 9 workers with 4 Byzantine workers (\u03bb=0.4), and workers' arrival probabilities are proportional to their IDs. The figure shows that \u03bc\u00b2-SGD achieves comparable performance to momentum while significantly outperforming standard SGD, highlighting the importance of incorporating historical information when addressing Byzantine scenarios.", "section": "Experiments"}]