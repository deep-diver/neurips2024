[{"figure_path": "1v4gKsyGfe/tables/tables_6_1.jpg", "caption": "Table 1: Changes in features (F) and classifier (C) norms on the CB and RTE datasets. CS, Diff, FDR, and Norm represent the cosine similarity between features, the difference in norms from the pre-trained model, Fisher's discriminant ratio, and the norm, respectively. After LP-FT, Diff(F) is smaller compared to FT, while preserving the high CS(F) and low FDR(F) of the pre-trained features. In contrast, Norm(C) is significantly larger after LP and LP-FT than both the pre-trained model and after FT. This trend is also observed when training with LoRA.", "description": "This table shows the changes in feature and classifier norms for different fine-tuning methods (LP, FT, LORA, LP-FT, LP-LORA) on two datasets (CB and RTE).  It compares cosine similarity (CS), norm difference (Diff), Fisher discriminant ratio (FDR), and norm (Norm) for both features and classifiers.  Key finding is LP-FT and LP-LORA show smaller feature changes and larger classifier norm increases compared to FT and LORA.", "section": "5 Numerical evaluation with transformer models"}, {"figure_path": "1v4gKsyGfe/tables/tables_7_1.jpg", "caption": "Table 2: Kernel statistics on the CB dataset. FN, Acc, and FT Ratio denote the Frobenius norm, kernel regression accuracy, and contribution of the FT-effective component, respectively. Pre-train E and FT E refer to the pre-train-effective and FT-effective components of the NTK matrix.", "description": "This table presents the results of kernel analysis performed on the CB dataset, focusing on the neural tangent kernel (NTK) matrix and its decomposition into pre-train and fine-tuning effective components. It shows the Frobenius norm (FN), kernel regression accuracy (Acc) on training and test sets, and the FT ratio (representing the contribution of the FT-effective component).  The table helps understand the relative contributions of pre-trained features and fine-tuning updates to the model's performance.", "section": "5.3 Kernel analysis"}, {"figure_path": "1v4gKsyGfe/tables/tables_8_1.jpg", "caption": "Table 3: ECE and MCE with temperature scaling on the test set of the RTE dataset. w/o TS and w/ TS denote without and with temperature scaling, respectively, and Imp. represents the improvement because of temperature scaling. We bold the best improvements. This table shows that poor calibration of LP-FT can be effectively mitigated through temperature scaling.", "description": "This table presents the Expected Calibration Error (ECE) and Maximum Calibration Error (MCE) for four different fine-tuning methods (FT, LP-FT, LoRA, LP-LoRA) on the RTE dataset, both with and without temperature scaling.  The improvement in calibration due to temperature scaling is shown.  The results highlight the potential of mitigating poor calibration in LP-FT through temperature scaling.", "section": "5.4 Analysis of classifier weight norms and temperature scaling"}, {"figure_path": "1v4gKsyGfe/tables/tables_13_1.jpg", "caption": "Table 1: Changes in features (F) and classifier (C) norms on the CB and RTE datasets. CS, Diff, FDR, and Norm represent the cosine similarity between features, the difference in norms from the pre-trained model, Fisher's discriminant ratio, and the norm, respectively. After LP-FT, Diff(F) is smaller compared to FT, while preserving the high CS(F) and low FDR(F) of the pre-trained features. In contrast, Norm(C) is significantly larger after LP and LP-FT than both the pre-trained model and after FT. This trend is also observed when training with LoRA.", "description": "This table presents a quantitative comparison of changes in feature and classifier norms after different fine-tuning methods (FT, LP-FT, LORA, LP-LORA) on two datasets: CB and RTE.  It shows that LP-FT, compared to standard fine-tuning (FT), leads to smaller changes in the features (as measured by CS, Diff, and FDR) while maintaining a significantly larger increase in the classifier norm.  This pattern is also observed when using the LoRA parameter-efficient fine-tuning method.", "section": "5.1 Setup"}, {"figure_path": "1v4gKsyGfe/tables/tables_14_1.jpg", "caption": "Table 1: Changes in features (F) and classifier (C) norms on the CB and RTE datasets. CS, Diff, FDR, and Norm represent the cosine similarity between features, the difference in norms from the pre-trained model, Fisher's discriminant ratio, and the norm, respectively. After LP-FT, Diff(F) is smaller compared to FT, while preserving the high CS(F) and low FDR(F) of the pre-trained features. In contrast, Norm(C) is significantly larger after LP and LP-FT than both the pre-trained model and after FT. This trend is also observed when training with LoRA.", "description": "This table shows a comparison of changes in feature and classifier norms for different fine-tuning methods (FT, LP-FT, LORA, LP-LORA) on two datasets (CB and RTE).  It demonstrates that linear probing then fine-tuning (LP-FT) and LoRA methods lead to smaller changes in pre-trained features while significantly increasing the classifier norm compared to standard fine-tuning.", "section": "5 Numerical evaluation with transformer models"}, {"figure_path": "1v4gKsyGfe/tables/tables_20_1.jpg", "caption": "Table 6: Hyperparameter configurations. The settings include batch size (bs), learning rate (lr), alpha (\u03b1), and rank (r).", "description": "This table shows the hyperparameter settings used in the experiments for different fine-tuning methods (FT, LoRA, LP-FT, and LP-LORA) and datasets.  For each dataset and method, it specifies the batch size (bs), learning rate (lr), alpha (\u03b1, for LoRA and LP-LORA), and rank (r, for LoRA and LP-LORA) used during training.  These settings were optimized to achieve good performance on the validation sets.", "section": "5.1 Setup"}, {"figure_path": "1v4gKsyGfe/tables/tables_20_2.jpg", "caption": "Table 1: Changes in features (F) and classifier (C) norms on the CB and RTE datasets. CS, Diff, FDR, and Norm represent the cosine similarity between features, the difference in norms from the pre-trained model, Fisher's discriminant ratio, and the norm, respectively. After LP-FT, Diff(F) is smaller compared to FT, while preserving the high CS(F) and low FDR(F) of the pre-trained features. In contrast, Norm(C) is significantly larger after LP and LP-FT than both the pre-trained model and after FT. This trend is also observed when training with LoRA.", "description": "This table shows the changes in features and classifier norms before and after different fine-tuning methods (LP, FT, LORA, LP-FT, LP-LORA) on the CB and RTE datasets.  It demonstrates that LP-FT effectively minimizes changes in pre-trained features while significantly increasing the classifier norm, which aligns with the paper's findings on feature preservation and the impact of classifier weight norms.", "section": "5.1 Setup"}, {"figure_path": "1v4gKsyGfe/tables/tables_20_3.jpg", "caption": "Table 1: Changes in features (F) and classifier (C) norms on the CB and RTE datasets. CS, Diff, FDR, and Norm represent the cosine similarity between features, the difference in norms from the pre-trained model, Fisher's discriminant ratio, and the norm, respectively. After LP-FT, Diff(F) is smaller compared to FT, while preserving the high CS(F) and low FDR(F) of the pre-trained features. In contrast, Norm(C) is significantly larger after LP and LP-FT than both the pre-trained model and after FT. This trend is also observed when training with LoRA.", "description": "This table presents a quantitative comparison of changes in features and classifier norms after different fine-tuning methods (LP, FT, LORA, LP-FT, LP-LORA) on two datasets (CB and RTE).  It shows that LP-FT successfully minimizes changes to pre-trained features while significantly increasing the norm of the classifier.  This supports the paper's claim that LP-FT preserves beneficial pre-trained features and benefits from a larger classifier norm.", "section": "5 Numerical evaluation with transformer models"}, {"figure_path": "1v4gKsyGfe/tables/tables_24_1.jpg", "caption": "Table 2: Kernel statistics on the CB dataset. FN, Acc, and FT Ratio denote the Frobenius norm, kernel regression accuracy, and contribution of the FT-effective component, respectively. Pre-train E and FT E refer to the pre-train-effective and FT-effective components of the NTK matrix.", "description": "This table presents the kernel statistics for the CB dataset, comparing different fine-tuning methods (FT, LoRA, LP-FT, LP-LORA).  It shows the Frobenius norm (FN), kernel regression accuracy (Acc), and the contribution of the FT-effective component (FT Ratio) to the overall kernel for each method.  Pre-train E and FT E columns represent the pre-train-effective and FT-effective components of the NTK matrix respectively, providing insights into the relative influence of pre-trained features and fine-tuning on prediction accuracy.", "section": "5.3 Kernel analysis"}, {"figure_path": "1v4gKsyGfe/tables/tables_25_1.jpg", "caption": "Table 10: Evaluation results on BOSS benchmark. We report the average accuracy and standard deviation over five seeds. The best results are highlighted in bold.", "description": "This table presents the results of experiments conducted on the BOSS benchmark to evaluate the performance of different fine-tuning methods.  The accuracy and standard deviation are reported for both in-distribution (ID) and out-of-distribution (OOD) data, across four different datasets: Amazon, Dynasent, SemEval, and SST-5. The best performing method for each dataset and setting is highlighted in bold, indicating the superior performance of LP-FT in many cases. The results showcase that the two-stage approach of linear probing followed by fine-tuning generally improves performance compared to other methods.", "section": "5.2 Small feature changes during LP-FT and significant norm increase during LP"}, {"figure_path": "1v4gKsyGfe/tables/tables_25_2.jpg", "caption": "Table 1: Changes in features (F) and classifier (C) norms on the CB and RTE datasets. CS, Diff, FDR, and Norm represent the cosine similarity between features, the difference in norms from the pre-trained model, Fisher's discriminant ratio, and the norm, respectively. After LP-FT, Diff(F) is smaller compared to FT, while preserving the high CS(F) and low FDR(F) of the pre-trained features. In contrast, Norm(C) is significantly larger after LP and LP-FT than both the pre-trained model and after FT. This trend is also observed when training with LoRA.", "description": "This table presents a quantitative comparison of changes in features and classifier norms after different fine-tuning methods (FT, LP-FT, LORA, LP-LORA) on two datasets (CB and RTE).  The results demonstrate that linear probing then fine-tuning (LP-FT) results in smaller changes to pre-trained features while significantly increasing the classifier norm compared to standard fine-tuning. The low-rank adaptation (LoRA) method shows a similar trend.", "section": "5.1 Setup"}, {"figure_path": "1v4gKsyGfe/tables/tables_25_3.jpg", "caption": "Table 1: Changes in features (F) and classifier (C) norms on the CB and RTE datasets. CS, Diff, FDR, and Norm represent the cosine similarity between features, the difference in norms from the pre-trained model, Fisher's discriminant ratio, and the norm, respectively. After LP-FT, Diff(F) is smaller compared to FT, while preserving the high CS(F) and low FDR(F) of the pre-trained features. In contrast, Norm(C) is significantly larger after LP and LP-FT than both the pre-trained model and after FT. This trend is also observed when training with LoRA.", "description": "This table shows a comparison of changes in features and classifier norms after different fine-tuning methods (LP, FT, LORA, LP-FT, LP-LORA) on two datasets (CB and RTE).  It highlights that LP-FT and LP-LORA result in smaller changes to pre-trained features while significantly increasing the classifier norm, suggesting a balance between preserving pre-trained information and adapting the linear classifier.", "section": "5 Numerical evaluation with transformer models"}, {"figure_path": "1v4gKsyGfe/tables/tables_25_4.jpg", "caption": "Table 1: Changes in features (F) and classifier (C) norms on the CB and RTE datasets. CS, Diff, FDR, and Norm represent the cosine similarity between features, the difference in norms from the pre-trained model, Fisher's discriminant ratio, and the norm, respectively. After LP-FT, Diff(F) is smaller compared to FT, while preserving the high CS(F) and low FDR(F) of the pre-trained features. In contrast, Norm(C) is significantly larger after LP and LP-FT than both the pre-trained model and after FT. This trend is also observed when training with LoRA.", "description": "This table presents a quantitative comparison of changes in features and classifier norms for different fine-tuning methods (FT, LP-FT, LORA, LP-LORA) on two datasets (CB and RTE).  It shows that LP-FT leads to smaller changes in features compared to standard FT while maintaining similarity to pre-trained features and achieving a larger increase in classifier norm.  The results also suggest that these trends hold when utilizing LoRA.", "section": "5 Numerical evaluation with transformer models"}, {"figure_path": "1v4gKsyGfe/tables/tables_26_1.jpg", "caption": "Table 1: Changes in features (F) and classifier (C) norms on the CB and RTE datasets. CS, Diff, FDR, and Norm represent the cosine similarity between features, the difference in norms from the pre-trained model, Fisher's discriminant ratio, and the norm, respectively. After LP-FT, Diff(F) is smaller compared to FT, while preserving the high CS(F) and low FDR(F) of the pre-trained features. In contrast, Norm(C) is significantly larger after LP and LP-FT than both the pre-trained model and after FT. This trend is also observed when training with LoRA.", "description": "This table presents a quantitative comparison of changes in feature and classifier norms between different fine-tuning methods (FT, LP-FT, LORA, LP-LORA) for two datasets (CB and RTE).  It shows that LP-FT effectively minimizes changes to pre-trained features while significantly increasing the classifier norm, which is also observed with LoRA.  The metrics used are cosine similarity (CS), norm difference (Diff), Fisher's discriminant ratio (FDR), and norm (Norm).", "section": "5 Numerical evaluation with transformer models"}, {"figure_path": "1v4gKsyGfe/tables/tables_28_1.jpg", "caption": "Table 1: Changes in features (F) and classifier (C) norms on the CB and RTE datasets. CS, Diff, FDR, and Norm represent the cosine similarity between features, the difference in norms from the pre-trained model, Fisher's discriminant ratio, and the norm, respectively. After LP-FT, Diff(F) is smaller compared to FT, while preserving the high CS(F) and low FDR(F) of the pre-trained features. In contrast, Norm(C) is significantly larger after LP and LP-FT than both the pre-trained model and after FT. This trend is also observed when training with LoRA.", "description": "This table presents a quantitative comparison of changes in feature and classifier norms for different fine-tuning methods (FT, LP-FT, LORA, LP-LORA) on two datasets (CB and RTE).  It shows that LP-FT effectively preserves pre-trained features while significantly increasing the classifier norm.  This observation supports the paper's argument about the role of the classifier norm in LP-FT's success.", "section": "5 Numerical evaluation with transformer models"}, {"figure_path": "1v4gKsyGfe/tables/tables_29_1.jpg", "caption": "Table 1: Changes in features (F) and classifier (C) norms on the CB and RTE datasets. CS, Diff, FDR, and Norm represent the cosine similarity between features, the difference in norms from the pre-trained model, Fisher's discriminant ratio, and the norm, respectively. After LP-FT, Diff(F) is smaller compared to FT, while preserving the high CS(F) and low FDR(F) of the pre-trained features. In contrast, Norm(C) is significantly larger after LP and LP-FT than both the pre-trained model and after FT. This trend is also observed when training with LoRA.", "description": "This table presents a quantitative comparison of changes in feature and classifier norms for different fine-tuning methods (FT, LP-FT, LORA, LP-LORA) on two datasets (CB and RTE).  It shows that LP-FT and LP-LORA result in smaller changes to the pre-trained features (indicated by lower Diff(F) and higher CS(F), demonstrating better feature preservation. However, these methods also show a significantly larger increase in the classifier norm (Norm(C)), highlighting a key trade-off observed in the study.", "section": "5 Numerical evaluation with transformer models"}, {"figure_path": "1v4gKsyGfe/tables/tables_29_2.jpg", "caption": "Table 1: Changes in features (F) and classifier (C) norms on the CB and RTE datasets. CS, Diff, FDR, and Norm represent the cosine similarity between features, the difference in norms from the pre-trained model, Fisher's discriminant ratio, and the norm, respectively. After LP-FT, Diff(F) is smaller compared to FT, while preserving the high CS(F) and low FDR(F) of the pre-trained features. In contrast, Norm(C) is significantly larger after LP and LP-FT than both the pre-trained model and after FT. This trend is also observed when training with LoRA.", "description": "This table shows a comparison of changes in features and classifier norms after different fine-tuning methods (FT, LP-FT, LORA, LP-LORA) on the CB and RTE datasets.  It demonstrates that LP-FT effectively minimizes feature changes while significantly increasing the classifier norm, supporting the paper's core argument.", "section": "5 Numerical evaluation with transformer models"}]