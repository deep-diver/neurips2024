[{"figure_path": "50nEnmVLRb/tables/tables_1_1.jpg", "caption": "Table 1: Compute and memory analysis for the proposed GP-TopK bandit algorithm. Rows represent different costs: total compute and memory of the GP-TopK algorithm for T rounds, time for matrix-vector multiplication (mvm) with the kernel matrix Kxt for tth round, and time to update Kx\u2081. Columns represent different approaches: the kernel approach, which uses full kernel matrices, and our novel feature approach, which performs the same operations through feature expansions and scales more efficiently with respect to T. The symbols c, k, and T denote the embedding size for contexts, the number of items, and the number of rounds, respectively.", "description": "This table compares the computational and memory costs of two different approaches (kernel and feature) for the GP-TopK algorithm. It breaks down the costs into four tasks: total computation time and memory usage for T rounds, matrix-vector multiplication time, and kernel matrix update time. The table highlights the efficiency gains of the feature approach, especially as the number of rounds (T) increases.", "section": "1 Introduction"}, {"figure_path": "50nEnmVLRb/tables/tables_3_1.jpg", "caption": "Table 1: Compute and memory analysis for the proposed GP-TopK bandit algorithm. Rows represent different costs: total compute and memory of the GP-TopK algorithm for T rounds, time for matrix-vector multiplication (mvm) with the kernel matrix Kxt for tth round, and time to update Kx\u2081. Columns represent different approaches: the kernel approach, which uses full kernel matrices, and our novel feature approach, which performs the same operations through feature expansions and scales more efficiently with respect to T. The symbols c, k, and T denote the embedding size for contexts, the number of items, and the number of rounds, respectively.", "description": "This table compares the computational and memory costs of two approaches (kernel and feature) for the GP-TopK algorithm across different tasks.  The kernel approach uses full kernel matrices, while the feature approach leverages feature expansions for increased efficiency as the number of rounds (T) increases. The table highlights that the feature approach significantly reduces both computational and memory requirements, especially as T grows larger.  The parameters c (context embedding size) and k (number of items) also influence these costs.", "section": "1 Introduction"}, {"figure_path": "50nEnmVLRb/tables/tables_5_1.jpg", "caption": "Table 1: Compute and memory analysis for the proposed GP-TopK bandit algorithm. Rows represent different costs: total compute and memory of the GP-TopK algorithm for T rounds, time for matrix-vector multiplication (mvm) with the kernel matrix Kxt for tth round, and time to update Kx\u2081. Columns represent different approaches: the kernel approach, which uses full kernel matrices, and our novel feature approach, which performs the same operations through feature expansions and scales more efficiently with respect to T. The symbols c, k, and T denote the embedding size for contexts, the number of items, and the number of rounds, respectively.", "description": "This table presents a comparison of computational and memory costs for two different approaches to the GP-TopK algorithm: the kernel approach and the feature approach.  The rows detail the costs for the overall algorithm across T rounds, matrix-vector multiplication, and kernel matrix updates. The columns show the results for both the kernel (full kernel matrices) and feature (feature expansions) approaches. It highlights the efficiency gains of the feature approach for large T values.", "section": "1 Introduction"}, {"figure_path": "50nEnmVLRb/tables/tables_7_1.jpg", "caption": "Table 1: Compute and memory analysis for the proposed GP-TopK bandit algorithm. Rows represent different costs: total compute and memory of the GP-TopK algorithm for T rounds, time for matrix-vector multiplication (mvm) with the kernel matrix Kxt for tth round, and time to update Kx\u2081. Columns represent different approaches: the kernel approach, which uses full kernel matrices, and our novel feature approach, which performs the same operations through feature expansions and scales more efficiently with respect to T. The symbols c, k, and T denote the embedding size for contexts, the number of items, and the number of rounds, respectively.", "description": "This table compares the computational and memory costs of two different approaches for the GP-TopK algorithm: the kernel approach (using full kernel matrices) and the feature approach (using feature expansions). The costs are broken down into three parts: total compute and memory, time for matrix-vector multiplication, and time to update the kernel matrix. The table shows that the feature approach scales more efficiently with respect to the number of rounds (T) and the number of items (k).", "section": "1 Introduction"}, {"figure_path": "50nEnmVLRb/tables/tables_16_1.jpg", "caption": "Table 1: Compute and memory analysis for the proposed GP-TopK bandit algorithm. Rows represent different costs: total compute and memory of the GP-TopK algorithm for T rounds, time for matrix-vector multiplication (mvm) with the kernel matrix Kxt for tth round, and time to update Kx\u2081. Columns represent different approaches: the kernel approach, which uses full kernel matrices, and our novel feature approach, which performs the same operations through feature expansions and scales more efficiently with respect to T. The symbols c, k, and T denote the embedding size for contexts, the number of items, and the number of rounds, respectively.", "description": "This table compares the computational and memory complexities of two approaches (kernel and feature) for the GP-TopK algorithm across various tasks.  It shows how these complexities scale with the number of rounds (T), the number of items (k), and the embedding size for contexts (c). The feature approach, a novel contribution of the paper, is shown to be significantly more efficient than the kernel approach, particularly for larger datasets and more rounds.", "section": "1 Introduction"}, {"figure_path": "50nEnmVLRb/tables/tables_19_1.jpg", "caption": "Table 1: Compute and memory analysis for the proposed GP-TopK bandit algorithm. Rows represent different costs: total compute and memory of the GP-TopK algorithm for T rounds, time for matrix-vector multiplication (mvm) with the kernel matrix Kxt for tth round, and time to update Kx\u2081. Columns represent different approaches: the kernel approach, which uses full kernel matrices, and our novel feature approach, which performs the same operations through feature expansions and scales more efficiently with respect to T. The symbols c, k, and T denote the embedding size for contexts, the number of items, and the number of rounds, respectively.", "description": "This table provides a detailed comparison of the computational and memory requirements for the proposed GP-TopK algorithm using two different approaches: a kernel approach and a novel feature approach. The analysis covers various aspects including total compute and memory, matrix-vector multiplication time, kernel matrix update time, and their dependence on different parameters like embedding size (c), number of items (k), and number of rounds (T).", "section": "1 Introduction"}]