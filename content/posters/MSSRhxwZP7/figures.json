[{"figure_path": "MSSRhxwZP7/figures/figures_1_1.jpg", "caption": "Figure 1: Statistics of SJTU-PCQA (part) [46] and predicted quality scores of NR-PCQA models (PQA-Net [21] and GPA-Net [32]). Quality scores of different distortion types are in lines of different colors. Red circles are to highlight the score span of different contents with the same distortion.", "description": "This figure compares the predicted quality scores from two no-reference point cloud quality assessment (NR-PCQA) models, PQA-Net and GPA-Net, with the ground truth scores from the SJTU-PCQA dataset.  The graphs show how the quality scores vary for different distortion types (color noise, downsampling, Gaussian noise) and intensities (1-4).  The red circles highlight the range of scores for different point cloud contents, even when the same distortion is applied. This visualization demonstrates the limitation of the existing NR-PCQA models in disentangling the effect of point cloud content and distortions on perceived quality.", "section": "1 Introduction"}, {"figure_path": "MSSRhxwZP7/figures/figures_4_1.jpg", "caption": "Figure 2: Architecture of proposed DisPA (a). Our DisPA consists of two encoders F and G for learning content-aware and distortion-aware representations, and an MI estimator M. The content-aware encoder F is pretrained using masked autoencoding (b). \"\" denotes concatenation.", "description": "This figure illustrates the architecture of the DisPA model proposed in the paper.  Panel (a) shows the overall architecture, which includes two encoders (F and G) for processing rendered images and mini-patch maps, respectively, an MI estimator (M) for disentangling the representations, and a quality score predictor (H). Panel (b) details the content-aware pretraining process, which uses a masked autoencoder to learn robust content representations.", "section": "4 Proposed Framework"}, {"figure_path": "MSSRhxwZP7/figures/figures_5_1.jpg", "caption": "Figure 3: Illustration of mini-patch map generation.", "description": "This figure illustrates the process of generating a mini-patch map from multi-view images. The left side shows multi-view images of a rendered point cloud, each divided into a grid of patches.  Selected patches (highlighted in green) are extracted from each view. The right side shows these selected patches assembled into a mini-patch map, which serves as input to the distortion-aware encoder. This process aims to create a representation focusing on local distortion patterns while blurring out global content information.", "section": "4.3 Distortion-Aware Mini-patch Map Generation"}, {"figure_path": "MSSRhxwZP7/figures/figures_8_1.jpg", "caption": "Figure 5: Qualitative Evaluation of NR-PCQA methods (PQA-Net [21], CoPA [33] and DisPA) on SJTU-PCQA [46] and WPC [20]. Figure (b)-(d) share the same distortion pattern (i.e., color noise), same for (f)-(h) (i.e., downsampling). \"GT\" denotes ground truth.", "description": "This figure shows a qualitative comparison of the predicted quality scores by three different NR-PCQA methods (PQA-Net, COPA, and the proposed DisPA) against the ground truth scores (GT) for eight different point cloud samples from the SJTU-PCQA and WPC datasets.  The examples are grouped to show the performance of each method under the same distortion type (color noise and downsampling), highlighting how well each method handles variations in point cloud content while maintaining consistent distortion.", "section": "5 Experiments"}, {"figure_path": "MSSRhxwZP7/figures/figures_8_2.jpg", "caption": "Figure 4: Statistical Analysis of SJTU-PCQA (part) and predicted quality scores of DisPA.", "description": "This figure compares the statistical analysis of predicted quality scores from the DisPA model against the ground truth scores from the SJTU-PCQA dataset (a subset). It focuses on the variation of scores across different distortion intensity levels and distortion types (color noise and downsampling). The key takeaway is that DisPA shows significantly less variation in its predictions compared to other methods (as shown in Figure 1), demonstrating its effectiveness and ability to handle variations in point cloud content more accurately.  The red circles highlight the score span across various content with the same distortion type.", "section": "5 Experiments"}]