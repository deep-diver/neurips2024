[{"figure_path": "Aj8RKCGwjE/tables/tables_5_1.jpg", "caption": "Table 1: Model Performance Comparison Test results. Metrics in Relative L2.", "description": "This table compares the performance of AROMA against various state-of-the-art baselines on three different datasets: Burgers, Navier-Stokes 1e-4, and Navier-Stokes 1e-5.  The performance is measured using the Relative L2 error metric.  The results highlight AROMA's superior performance in capturing the dynamics of turbulent phenomena, especially compared to global neural field methods like DINO and CORAL, which struggle with turbulent data.  AROMA also shows competitive results against other regular-grid methods like FNO and GNOT.", "section": "4.1 Dynamics on regular grids"}, {"figure_path": "Aj8RKCGwjE/tables/tables_6_1.jpg", "caption": "Table 2: Temporal Extrapolation - Test results. Metrics in MSE.", "description": "This table presents a comparison of the model's performance on two datasets (Navier-Stokes 1 \u00d7 10\u22123 and Shallow-Water) across various levels of observation sparsity (\u03c0 = 100%, 25%, 5%).  The metrics reported are Mean Squared Errors (MSE) for both the training horizon (In-t) and extrapolation horizon (Out-t).  The results highlight AROMA's consistent performance across different sparsity levels and time horizons.", "section": "4.2 Dynamics on irregular grids with shared geometries"}, {"figure_path": "Aj8RKCGwjE/tables/tables_7_1.jpg", "caption": "Table 3: Dynamics on different geometries - Test results. MSE on normalized data.", "description": "This table compares the performance of different models (CORAL, DINO, OFormer, and AROMA) on two fluid dynamics problems involving non-convex domains: CylinderFlow and AirfoilFlow.  The results are presented as Mean Squared Error (MSE) on normalized data, for both the in-training horizon (\"In-t\") and the extrapolation horizon (\"Out-t\"). The metrics evaluate the models' ability to predict flow dynamics on different geometries.", "section": "4.3 Dynamics on different geometries"}, {"figure_path": "Aj8RKCGwjE/tables/tables_15_1.jpg", "caption": "Table 4: Diffusion Transformer Hyperparameters for Different Datasets", "description": "This table shows the hyperparameters used for the diffusion transformer part of the AROMA model. The hyperparameters are the same for all datasets except for the minimum noise and epochs. The table includes the hidden size, depth, number of heads, MLP ratio, minimum noise, denoising steps, and epochs. ", "section": "4 Experiments"}, {"figure_path": "Aj8RKCGwjE/tables/tables_16_1.jpg", "caption": "Table 1: Model Performance Comparison Test results. Metrics in Relative L2.", "description": "This table compares the performance of AROMA against several baselines on three datasets: Burgers, Navier-Stokes 1e-4, and Navier-Stokes 1e-5.  The performance is measured using the Relative L2 error metric, which quantifies the relative difference between the model's predictions and the ground truth.  The results demonstrate AROMA's superior performance compared to other methods, particularly in handling turbulent phenomena.", "section": "4.1 Dynamics on regular grids"}, {"figure_path": "Aj8RKCGwjE/tables/tables_22_1.jpg", "caption": "Table 6: Influence of the number of latent tokens on the test reconstruction capabilities on Navier-Stokes 1 \u00d7 10\u207b\u2074. Performance in Relative L2 Error.", "description": "This table presents an ablation study on the impact of varying the number of latent tokens (M) used in the model's architecture.  The results show the test reconstruction error (Relative L2 Error) for three different values of M (64, 128, and 256) on the Navier-Stokes 1 \u00d7 10\u207b\u2074 dataset. The data indicates an improvement in reconstruction accuracy with an increase in the number of latent tokens.", "section": "C.6 Ablation studies"}, {"figure_path": "Aj8RKCGwjE/tables/tables_22_2.jpg", "caption": "Table 7: Ablation Study. Metrics in Relative L2 on the test set.", "description": "This table presents the ablation study results comparing different model variations of AROMA. The metrics used are Relative L2 errors on the test sets for Burgers, Navier-Stokes (1e-4), and Navier-Stokes (1e-5) datasets.  The variations compared include AROMA with auto-encoding, AROMA without diffusion, AROMA with MLP instead of the transformer, and the full AROMA model.  The results show the impact of each component on the overall performance.", "section": "C.6 Ablation studies"}, {"figure_path": "Aj8RKCGwjE/tables/tables_23_1.jpg", "caption": "Table 8: Test results on the KS equation. The evaluated metrics include: 1-step prediction MSE, MSE over the entire rollout (160 timestamps), and the duration for which the correlation between the generated samples and the ground truth remains above 0.8.", "description": "This table presents a comparison of the performance of AROMA with and without diffusion on the Kuramoto-Sivashinsky (KS) equation. The metrics used for comparison are the 1-step prediction MSE, the rollout MSE (over the entire 160 timestamps), and the duration for which the correlation between generated samples and the ground truth remains above 0.8.  The results show that while the diffusion improves the rollout MSE slightly and increases the correlation duration, it does not significantly impact the overall performance on this chaotic system.", "section": "C.7 Kuramoto-Sivashinsky: a failure case"}]