[{"figure_path": "ouoBW2PXFQ/figures/figures_1_1.jpg", "caption": "Figure 1: Analysis of representations in our experiments on KU-HAR dataset [47]. In a conventional CNN, the classifier predicts activities only using the feature representations at the last layer. Features at the early layer include the detailed information of original signals that may confound the classifier. In comparison, features at the later layer are more semantic, but the features (with more compact and short waveforms) make it challenging to classify activities that share similar semantics. Our goal is to design a CALANet that allows the classifier to use features for all layers while maintaining the inference time of conventional CNNS.", "description": "This figure analyzes feature representations at different layers of a conventional CNN and proposes the design goal of CALANet.  It shows that early layers capture detailed signal information, which can be noisy and unhelpful for classification, while later layers provide more semantic but less detailed features, making it difficult to distinguish between similar activities. CALANet aims to leverage features from all layers for improved accuracy without increasing computational cost.", "section": "1 Introduction"}, {"figure_path": "ouoBW2PXFQ/figures/figures_4_1.jpg", "caption": "Figure 2: Network architecture of CALANet. Convolution and pooling layers extract the sampled features by reducing the temporal resolution. CALANet aggregates the features for all layers based on the linear transformation and combination.", "description": "The figure illustrates the architecture of CALANet, a novel network designed for human activity recognition (HAR). It starts with input signals that go through a series of convolutional and pooling layers, reducing the temporal resolution. This part is standard in convolutional neural networks (CNNs). The novel aspect is the \"cheap all-layer aggregation\" module. In this module, features from all layers are aggregated before going to the classifier.  This aggregation is achieved by using learnable channel-wise transformation matrices (LCTMs) and a scalable layer aggregation pool (SLAP). LCTMs reduce the computational cost, while SLAP allows for stacking layers without dramatically increasing the cost. The classifier then predicts the activity based on these aggregated features. The diagram shows the flow of data through the network and highlights the key components of CALANet.", "section": "3 Cheap All-Layer Aggregation Network"}, {"figure_path": "ouoBW2PXFQ/figures/figures_7_1.jpg", "caption": "Figure 2: Network architecture of CALANet. Convolution and pooling layers extract the sampled features by reducing the temporal resolution. CALANet aggregates the features for all layers based on the linear transformation and combination.", "description": "This figure shows the architecture of CALANet, a novel network proposed in the paper for human activity recognition.  The input is sensor signals. These signals pass through a series of convolutional and pooling layers to extract features.  Crucially, unlike traditional CNNs which only use the final layer's features for classification, CALANet aggregates features from all layers.  This aggregation is done using learnable channel-wise transformation matrices (LCTMs) and a scalable layer aggregation pool (SLAP), designed to minimize the increase in computational cost associated with using all-layer features. The combined features are then fed into a classifier to predict the activity.", "section": "3 Cheap All-Layer Aggregation Network"}, {"figure_path": "ouoBW2PXFQ/figures/figures_8_1.jpg", "caption": "Figure 2: Network architecture of CALANet. Convolution and pooling layers extract the sampled features by reducing the temporal resolution. CALANet aggregates the features for all layers based on the linear transformation and combination.", "description": "The figure illustrates the architecture of CALANet, a novel network for human activity recognition.  It shows how convolutional and pooling layers initially extract features from input signals. A key innovation is the 'cheap all-layer aggregation' method, where learnable channel-wise transformation matrices (LCTMs) and a scalable layer aggregation pool (SLAP) efficiently combine features from all layers before feeding them into a final classifier. This contrasts with conventional CNNs, which only use the last layer's features.", "section": "3 Cheap All-Layer Aggregation Network"}, {"figure_path": "ouoBW2PXFQ/figures/figures_17_1.jpg", "caption": "Figure 2: Network architecture of CALANet. Convolution and pooling layers extract the sampled features by reducing the temporal resolution. CALANet aggregates the features for all layers based on the linear transformation and combination.", "description": "This figure illustrates the architecture of the CALANet model.  It shows how convolutional and pooling layers process the input signal, reducing temporal resolution and extracting high-level features.  The key innovation is the \"Cheap All-layer Aggregation\" module, which uses learnable channel-wise transformation matrices (LCTMs) to efficiently aggregate features from all layers before classification. This allows for more comprehensive feature utilization while controlling the computational cost.", "section": "3 Cheap All-Layer Aggregation Network"}, {"figure_path": "ouoBW2PXFQ/figures/figures_17_2.jpg", "caption": "Figure 2: Network architecture of CALANet. Convolution and pooling layers extract the sampled features by reducing the temporal resolution. CALANet aggregates the features for all layers based on the linear transformation and combination.", "description": "The figure shows the architecture of CALANet, a novel network for human activity recognition.  It highlights the use of learnable channel-wise transformation matrices (LCTMs) and a scalable layer aggregation pool (SLAP) for efficient all-layer feature aggregation.  Convolutional and pooling layers initially process input signals, reducing temporal resolution. Then, LCTMs transform features from each layer into a common representation, enabling their combination via SLAP for final classification. This architecture achieves improved accuracy without increasing computational cost compared to conventional CNNs.", "section": "3 Cheap All-Layer Aggregation Network"}, {"figure_path": "ouoBW2PXFQ/figures/figures_18_1.jpg", "caption": "Figure 2: Network architecture of CALANet. Convolution and pooling layers extract the sampled features by reducing the temporal resolution. CALANet aggregates the features for all layers based on the linear transformation and combination.", "description": "This figure shows the architecture of CALANet, a novel network for human activity recognition. It uses convolutional and pooling layers to extract features from input signals, reducing temporal resolution.  A key innovation is the \"cheap all-layer aggregation\" method. This involves using learnable channel-wise transformation matrices (LCTMs) and a scalable layer aggregation pool (SLAP) to efficiently combine features from all layers without significantly increasing computational cost.  The combined features are then fed into a classifier for activity prediction. This design allows CALANet to achieve better accuracy than methods using only the last layer's features.", "section": "3 Cheap All-Layer Aggregation Network"}]