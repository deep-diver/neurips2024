[{"figure_path": "CcNw4mVIxo/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative comparison on FE108. There are four challenging scenarios, including high dynamic range (HDR), low light (LL), fast motion with and without motion blur (FWB & FNB) and all testing datasets (ALL). [method]+SpikeSlicer represents the results based on our adaptive event slicing method and the results of [method] are tested on the original fixed-sliced event dataset from [3]. To ensure a fair comparison, fix event indicates that the model is tested on a dataset of fixed-sliced event frames, where the number of fixed event frames is the same as the number of dynamically sliced event frames by using SpikeSlicer. Best performances are denoted by deep green.", "description": "This table presents a quantitative comparison of different object tracking methods on the FE108 dataset.  It compares performance across various challenging scenarios (HDR, LL, FWB, FNB) and overall. The results are shown for models both with and without the proposed SpikeSlicer adaptive event slicing method.  \"Fix event\" indicates that a model uses fixed-length event slices for comparison.", "section": "4.2 Expert's Arena: Mastering Adaptive Event Slicing with SNN-ANN Collaboration"}, {"figure_path": "CcNw4mVIxo/tables/tables_7_2.jpg", "caption": "Table 2: Quantative comparison on DVS-Gesture, N-Caltech101, DVS-CIFAR10 and SL-Animals. Random and Fix denote that the input events are randomly sliced and fixed sliced, respectively. Instead, our method slices the event stream adaptively.", "description": "This table presents a quantitative comparison of the proposed SpikeSlicer method against traditional fixed-sliced and random-sliced methods on four different event-based datasets: DVS-Gesture, N-Caltech101, DVS-CIFAR10, and SL-Animals.  The results show the accuracy of ResNet-18, ResNet-34, and Swin-S models when using each slicing technique.  The \"Ours\" column indicates the performance using the proposed adaptive slicing method, highlighting its superior performance compared to both fixed and random slicing strategies.", "section": "4.2 Expert's Arena: Mastering Adaptive Event Slicing with SNN-ANN Collaboration"}, {"figure_path": "CcNw4mVIxo/tables/tables_8_1.jpg", "caption": "Table 3: Comparison of Efficiency and Speed. The comparison includes the number of operations (OPs) and tracking speed per image without image processing time.", "description": "This table compares the efficiency and speed of using an ANN with and without the SpikeSlicer method for event-based object tracking.  It shows the number of Giga-operations (OPs), energy consumption in millijoules (mJ), speed in seconds per image, and the performance (presumably a metric like success rate) for each approach. The results demonstrate that while adding SpikeSlicer increases the number of operations and energy consumption slightly, it significantly improves performance.", "section": "4.3 Analysis of the Adaptive Slicing Method"}, {"figure_path": "CcNw4mVIxo/tables/tables_8_2.jpg", "caption": "Table 8: Experiments on different event representations with fixed (including fixed time and fixed event count) or dynamic slicing methods. Our SpikeSlicer yields significant improvement when using different event representation methods.", "description": "This table presents the results of experiments comparing the performance of different event representation methods (Event Frame, Event Spike Tensor, Voxel Grid) under both fixed and dynamic slicing methods. The results are shown for the DVS-Gesture dataset, demonstrating the effectiveness of the proposed SpikeSlicer method in improving performance across various event representations.", "section": "4.2 Expert's Arena: Mastering Adaptive Event Slicing with SNN-ANN Collaboration"}, {"figure_path": "CcNw4mVIxo/tables/tables_8_3.jpg", "caption": "Table 5: Ablation studies for evaluating the proposed loss function on the SL-Animals dataset.", "description": "This table presents the ablation study results evaluating the effectiveness of different loss functions, specifically the proposed Mem-Loss and LA-Loss, on the SL-Animals dataset. The results are compared with the baseline using only a fixed slicing method.  The table shows that the combination of Mem-Loss and LA-Loss leads to better performance on object recognition tasks.", "section": "4.3 Analysis of the Adaptive Slicing Method"}, {"figure_path": "CcNw4mVIxo/tables/tables_8_4.jpg", "caption": "Table 6: Experiments with different event cell numbers N. The resulting sliced event group always has a similar time interval in various N conditions.", "description": "This table presents an ablation study on the impact of varying the number of event cells (N) on the adaptive event slicing process.  It demonstrates the robustness of the SpikeSlicer method by showing that even when the number of event cells changes, the duration of the resulting sliced event groups remains relatively consistent. This finding highlights the algorithm's ability to maintain consistent time intervals irrespective of input variations.  This stability is important for reliable downstream processing because it ensures that the sub-event streams maintain a consistent temporal structure despite changes in data density or the granularity of the time discretization.", "section": "4.3 Analysis of the Adaptive Slicing Method"}, {"figure_path": "CcNw4mVIxo/tables/tables_13_1.jpg", "caption": "Table 1: Quantitative comparison on FE108. There are four challenging scenarios, including high dynamic range (HDR), low light (LL), fast motion with and without motion blur (FWB & FNB) and all testing datasets (ALL). [method]+SpikeSlicer represents the results based on our adaptive event slicing method and the results of [method] are tested on the original fixed-sliced event dataset from [3]. To ensure a fair comparison, fix event indicates that the model is tested on a dataset of fixed-sliced event frames, where the number of fixed event frames is the same as the number of dynamically sliced event frames by using SpikeSlicer. Best performances are denoted by deep green.", "description": "This table presents a quantitative comparison of different object tracking methods on the FE108 dataset.  It compares performance across various challenging scenarios (high dynamic range, low light, fast motion with and without blur) and evaluates the impact of the proposed SpikeSlicer method. The table shows that SpikeSlicer improves the performance of several state-of-the-art trackers, achieving best results in many scenarios. A fixed event baseline is included for fair comparison.", "section": "4.2 Expert's Arena: Mastering Adaptive Event Slicing with SNN-ANN Collaboration"}, {"figure_path": "CcNw4mVIxo/tables/tables_14_1.jpg", "caption": "Table 8: Experiments on different event representations with fixed (including fixed time and fixed event count) or dynamic slicing methods. Our SpikeSlicer yields significant improvement when using different event representation methods.", "description": "This table presents the results of experiments comparing different event representation methods (Event Frame, Event Spike Tensor, Voxel Grid) under three slicing methods: fixed duration, fixed event count, and the proposed SpikeSlicer.  The goal was to demonstrate the effectiveness of SpikeSlicer across various event representation techniques. The results show that SpikeSlicer consistently outperforms the fixed slicing methods in terms of accuracy for the DVSGesture dataset.", "section": "4.2 Expert's Arena: Mastering Adaptive Event Slicing with SNN-ANN Collaboration"}, {"figure_path": "CcNw4mVIxo/tables/tables_19_1.jpg", "caption": "Table 9: Results on simple event slicing tasks with SPA-Loss.", "description": "This table presents the results of experiments on simple event slicing tasks using the Spiking Position-aware Loss (SPA-Loss). Two tasks are defined: Task (I) uses identical event cells and expects the Spiking Neural Network (SNN) to slice at a specific time step. Task (II) introduces randomized event cells and noise, making it more challenging. The table shows that the SPA-Loss effectively guides the SNN to converge faster to the desired slicing time, regardless of the complexity of the task.  The results are organized by input size (32x32 or 64x64), number of time steps (30 or 100), the model parameter count (0.52M or 2.02M), and the iterations needed to achieve convergence.", "section": "4.1 Beginner's Arena: Event Slicing in Simple Tasks"}, {"figure_path": "CcNw4mVIxo/tables/tables_20_1.jpg", "caption": "Table 10: Statistic results of dynamic slicing method (our SpikeSlicer) and fixed slicing method.", "description": "This table presents a statistical comparison of the results obtained using the proposed dynamic event slicing method (SpikeSlicer) and a fixed duration slicing method.  It shows the average, variance, minimum, 25th percentile, 75th percentile, and maximum durations of the sliced event streams generated by each method.  The data reveals that SpikeSlicer produces a wider range of sliced stream durations, whereas the fixed duration method consistently generates streams of a single, fixed duration.", "section": "4.2 Expert's Arena: Mastering Adaptive Event Slicing with SNN-ANN Collaboration"}, {"figure_path": "CcNw4mVIxo/tables/tables_20_2.jpg", "caption": "Table 10: Statistic results of dynamic slicing method (our SpikeSlicer) and fixed slicing method.", "description": "This table presents a statistical comparison of the dynamic event slicing method (SpikeSlicer) and a fixed-duration slicing method. It shows the average number of event cells used, the variance in the number of cells, and the average, minimum, 25th percentile, 75th percentile, and maximum durations of the sliced event segments for both methods.  The comparison highlights the variability in segment lengths produced by the dynamic method compared to the consistent lengths of the fixed-duration method.", "section": "4.2 Expert's Arena: Mastering Adaptive Event Slicing with SNN-ANN Collaboration"}, {"figure_path": "CcNw4mVIxo/tables/tables_21_1.jpg", "caption": "Table 12: Experiments of utilizing SpikeSlicer on latest recognition backbones.", "description": "This table presents the results of experiments evaluating the effectiveness of SpikeSlicer when used with different state-of-the-art recognition backbones, specifically SwinT and ViT.  It compares the performance (accuracy) achieved using SpikeSlicer with two baseline methods: random slicing and fixed slicing.  The improvement in accuracy obtained with SpikeSlicer is shown in parentheses for each backbone.", "section": "4.2 Expert's Arena: Mastering Adaptive Event Slicing with SNN-ANN Collaboration"}, {"figure_path": "CcNw4mVIxo/tables/tables_21_2.jpg", "caption": "Table 13: Experiments of utilizing SpikeSlicer on complex dataset N-ImageNet [47]", "description": "This table presents the quantitative comparison of using different slicing methods on the N-ImageNet dataset for object recognition.  The results show the accuracy achieved using ResNet-18 for three different approaches: random slicing, fixed slicing, and the authors' proposed adaptive slicing method (SpikeSlicer). SpikeSlicer demonstrates a significant performance improvement over the other two methods.", "section": "4.4 Ablation Study"}]