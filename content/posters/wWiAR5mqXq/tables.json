[{"figure_path": "wWiAR5mqXq/tables/tables_13_1.jpg", "caption": "Table 1: Statistics of training data generated by original LongChat. We show the total data volume on the left, the number of positive examples on the middle, and the number of negative examples on the right side.", "description": "This table shows the amount of training data generated by the original LongChat model, broken down by dataset (HotPotQA, GSM8K, Checkmate in One Move) and category (total, positive examples, negative examples).  It provides a quantitative overview of the data used in the supervised fine-tuning stage of the reflector model training within the COPPER framework.", "section": "B Details of Training Data"}, {"figure_path": "wWiAR5mqXq/tables/tables_14_1.jpg", "caption": "Table 2: Statistics of training data generated by LongChat fine-tuned with SFT. We show the total data volume on the left, the number of positive examples on the middle, and the number of negative examples on the right side.", "description": "This table shows the quantitative information of the training data used in the fine-tuning of the shared reflector with Supervised Fine-Tuning (SFT). It provides the total number of data samples, positive samples, and negative samples generated by LongChat for the HotPotQA, GSM8K, and Checkmate datasets.  The data is categorized by the reward type (Episode Difference Reward and Counterfactual Reward) and the agent involved (agent_0, agent_1, agent_2, or all).", "section": "5 Experiments"}]