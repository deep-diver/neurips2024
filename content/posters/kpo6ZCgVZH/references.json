{"references": [{"fullname_first_author": "Qiang Liu", "paper_title": "Stein variational gradient descent: A general purpose Bayesian inference algorithm", "publication_date": "2016-00-00", "reason": "This paper introduces Stein Variational Gradient Descent (SVGD), a foundational method for particle-based variational inference that the current paper builds upon and extends."}, {"fullname_first_author": "Lauro Langosco di Langosco", "paper_title": "Neural variational gradient descent", "publication_date": "2021-00-00", "reason": "This work is highly relevant as it proposes using neural networks to parameterize the gradient flow in particle-based variational inference, which is directly adopted by the current paper."}, {"fullname_first_author": "Hanze Dong", "paper_title": "Particle-based variational inference with preconditioned functional gradient flow", "publication_date": "2023-00-00", "reason": "This work is highly relevant as it also uses functional gradient approaches with neural networks for ParVIs and proposes novel numerical strategies, which are closely related to the methods developed in the current paper."}, {"fullname_first_author": "Changyou Chen", "paper_title": "A unified particle-optimization framework for scalable Bayesian sampling", "publication_date": "2018-00-00", "reason": "This paper provides a unified perspective on MCMC and VI, which inspired the development of particle-based variational inference methods, and is a crucial foundation for the current paper's approach."}, {"fullname_first_author": "Kwangjun Ahn", "paper_title": "Efficient constrained sampling via the mirror-langevin algorithm", "publication_date": "2021-00-00", "reason": "This paper addresses the challenge of constrained sampling, a problem directly tackled in the current work, and offers a relevant baseline method for comparison."}]}