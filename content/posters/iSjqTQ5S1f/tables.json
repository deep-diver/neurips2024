[{"figure_path": "iSjqTQ5S1f/tables/tables_6_1.jpg", "caption": "Table 1: Test-set concept and target accuracy (%) prior to interventions. Results are reported as averages and standard deviations of model performance across ten seeds. For each dataset and metric, the best-performing method is bolded and the runner-up is underlined.", "description": "This table presents the concept and target accuracy of different models on three datasets (Synthetic, CUB, and CIFAR-10) before any interventions are made.  The results are averaged over ten different random seeds, and the best-performing model for each dataset and metric is highlighted in bold, while the second-best is underlined.  The table provides a baseline comparison of the models before any user interaction.", "section": "5 Results"}, {"figure_path": "iSjqTQ5S1f/tables/tables_6_2.jpg", "caption": "Table 2: Relative time it takes for one epoch in the CUB dataset when training on the training set, or evaluating on the test set, respectively.", "description": "This table presents the relative training and inference times for different models on the CUB dataset. The training time is relative to the Hard CBM model, which is set as a baseline of 5x.  The inference time is also relative to the Hard CBM model, set to 1x. The table helps to understand and compare the computational efficiency of different methods, especially highlighting the significant increase in inference time for the Autoregressive CBM.", "section": "5 Results"}, {"figure_path": "iSjqTQ5S1f/tables/tables_8_1.jpg", "caption": "Table 3: Test-set calibration (%) of concept predictions. Results are reported as averages and standard deviations of model performance across ten seeds. For each dataset and metric, the best-performing method is bolded and the runner-up is underlined. Lower is better.", "description": "This table presents the calibration performance of different methods on three datasets (Synthetic, CUB, and CIFAR-10).  Calibration is evaluated using two metrics: Brier score and Expected Calibration Error (ECE). Lower values indicate better calibration.  The table shows that the proposed Amortized SCBM method generally achieves better calibration than the other methods across all three datasets, demonstrating its improved ability to accurately estimate the uncertainty of its concept predictions.", "section": "5 Results"}, {"figure_path": "iSjqTQ5S1f/tables/tables_17_1.jpg", "caption": "Table 1: Test-set concept and target accuracy (%) prior to interventions. Results are reported as averages and standard deviations of model performance across ten seeds. For each dataset and metric, the best-performing method is bolded and the runner-up is underlined.", "description": "This table presents the concept and target accuracy of different models before any interventions are performed.  The results are averaged over ten different random seeds to provide a reliable measure of performance. The best-performing model for each dataset and metric is highlighted in bold, with the second-best underlined, allowing for easy comparison of model performance across different datasets and metrics.", "section": "5 Results"}]