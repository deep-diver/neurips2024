{"references": [{"fullname_first_author": "Jason Wei", "paper_title": "Emergent abilities of large language models", "publication_date": "2022-MM-DD", "reason": "This paper is foundational to the concept of in-context learning, a key element of the study's focus on multi-modal in-context learning."}, {"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-MM-DD", "reason": "This paper introduces Flamingo, a significant visual language model that directly inspires the multi-modal aspect of the research."}, {"fullname_first_author": "Libo Qin", "paper_title": "Improving zero-shot chain-of-thought reasoning across languages", "publication_date": "2023-MM-DD", "reason": "This paper is by one of the authors and directly relates to the study's focus on improving the performance of multi-modal in-context learning."}, {"fullname_first_author": "Shukang Yin", "paper_title": "A survey on multimodal large language models", "publication_date": "2023-MM-DD", "reason": "This survey provides an overview of the state-of-the-art in multimodal large language models, which is essential context for the current research."}, {"fullname_first_author": "Takeshi Kojima", "paper_title": "Large language models are zero-shot reasoners", "publication_date": "2022-MM-DD", "reason": "This paper is highly relevant because it demonstrates the zero-shot reasoning capabilities of LLMs, a key aspect of the MM-ICL explored in the study."}]}