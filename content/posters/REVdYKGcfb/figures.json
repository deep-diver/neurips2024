[{"figure_path": "REVdYKGcfb/figures/figures_1_1.jpg", "caption": "Figure 1: The whole process of prompting creation for multi-modal in-context-learning.", "description": "This figure illustrates the three core steps involved in creating prompts for multi-modal in-context learning (MM-ICL): demonstration retrieval, demonstration ordering, and prompt construction.  The process starts with a multimodal validation set, from which relevant demonstrations are retrieved. These demonstrations are then ordered, and finally, a prompt is constructed which includes the ordered demonstrations along with instructions.  Each step is visually represented as a box, showing data flow from one step to the next.", "section": "Background"}, {"figure_path": "REVdYKGcfb/figures/figures_2_1.jpg", "caption": "Figure 2: The demonstration retrieval process for MM-ICL.", "description": "This figure illustrates the three key steps involved in the demonstration retrieval process for multi-modal in-context learning (MM-ICL).  These steps are:\n\n1. **Sample Representation**:  Each input sample and the query are mapped into a shared representation space using various encoder architectures (textual, visual, or multi-modal).\n2. **Sample Comparison**: The quality of each sample representation is evaluated relative to the query using metrics like cosine similarity, L2 distance, and semantic coverage.\n3. **Sample Selection**: A selection criterion is applied to choose the most advantageous samples for inclusion in the demonstration set. This selection is guided by factors such as domain information, image style, and modality distance. The figure visually depicts the flow of these processes using different components and arrows.", "section": "3.1 Exploration of MM-ICL Demonstration Retrieval"}, {"figure_path": "REVdYKGcfb/figures/figures_3_1.jpg", "caption": "Figure 3: The demonstration ordering process for MM-ICL.", "description": "This figure illustrates the demonstration ordering process in multi-modal in-context learning (MM-ICL).  It shows two key aspects: intra-demonstration ordering (the sequence within a demonstration, particularly the order of modalities like text and image), and inter-demonstration ordering (the sequence in which demonstrations are arranged within the dataset).", "section": "3.2 Exploration of MM-ICL Demonstration Ordering"}, {"figure_path": "REVdYKGcfb/figures/figures_6_1.jpg", "caption": "Figure 5: The impact of token pattern representation in Gemini-Pro.", "description": "This figure shows the impact of token pattern representation on the performance of different tasks using the Gemini-Pro model.  The x-axis represents the BLEU score (measuring token repetition in demonstration outputs), and the y-axis represents the model performance in terms of accuracy and other metrics like CIDER, RAS, and BERTScore.  Different colored lines represent different tasks: VQA, Classification, Caption, and Reasoning. The figure shows the performance of each task under various levels of token pattern repetition.", "section": "5.1 Empirical Analysis of MM-ICL Demonstration Retrieval"}, {"figure_path": "REVdYKGcfb/figures/figures_6_2.jpg", "caption": "Figure 6: The impact of different sample comparison methodologies in Gemini-Pro.", "description": "This figure shows the impact of different sample comparison methods on the performance of MM-ICL using the Gemini-Pro model.  Specifically, it compares two different similarity metrics (cosine similarity and L2 similarity) and two different diversity approaches (diversity retriever and similar retriever) across various downstream tasks (Image Caption, Visual Question Answering, Classification, and Reasoning). The results highlight the importance of cosine similarity over L2 similarity for MM-ICL, and show minimal effect of diversity on performance.", "section": "3.1 Exploration of MM-ICL Demonstration Retrieval"}, {"figure_path": "REVdYKGcfb/figures/figures_6_3.jpg", "caption": "Figure 7: The impact of sample selection on average score performance in Gemini-Pro.", "description": "This figure presents a comprehensive analysis of how sample selection strategies affect the performance of Multi-modal In-context Learning (MM-ICL) using the Gemini-Pro model. It systematically explores three key factors influencing sample selection: in-domain vs. out-of-domain samples, visual style consistency, and the token distance between modalities.  The results highlight the importance of selecting in-domain samples for optimal performance, the nuanced role of visual style consistency depending on the task, and the non-monotonic relationship between token distance and performance.  The figure provides a detailed breakdown of these effects across multiple tasks and metrics, offering valuable insights for optimizing MM-ICL strategies.", "section": "5.1 Exploration of MM-ICL Demonstration Retrieval"}, {"figure_path": "REVdYKGcfb/figures/figures_7_1.jpg", "caption": "Figure 3: The demonstration ordering process for MM-ICL.", "description": "This figure illustrates the demonstration ordering process in multi-modal in-context learning (MM-ICL).  It shows two key aspects: intra-demonstration ordering (the sequence within a single demonstration, such as the order of text and image) and inter-demonstration ordering (the sequence of multiple demonstrations). The intra-demonstration ordering is represented by a permutation of the modalities within a single sample, while the inter-demonstration ordering is represented by a permutation of the selected demonstrations.", "section": "3.2 Exploration of MM-ICL Demonstration Ordering"}, {"figure_path": "REVdYKGcfb/figures/figures_7_2.jpg", "caption": "Figure 9: The impact of injecting instruction into demonstrations on model average score performance.", "description": "This figure displays the impact of three different instruction injection methods on the average performance across five different large language models (LLMs) for four different tasks. The three methods are: Introductory Instruction (placing instruction before demonstrations), Summative Instruction (placing instruction after demonstrations), and Intra-demonstration Instruction (embedding instructions within demonstrations). The results indicate that Introductory Instruction consistently enhances performance, while the other two methods generally reduce performance, suggesting the importance of providing context before examples for better task comprehension.", "section": "5.3 Empirical Analysis of MM-ICL Prompt Construction"}, {"figure_path": "REVdYKGcfb/figures/figures_8_1.jpg", "caption": "Figure 10: The impact of the number of demonstrations on performance.", "description": "This figure shows the effect of varying the number of demonstrations on the performance of different large language models across various tasks. It demonstrates how the optimal number of demonstrations may vary across different tasks and models. In some cases, increasing the number of demonstrations leads to improved performance, while in other cases it can lead to a decrease in performance. This highlights that there is no universally optimal number of demonstrations for Multi-Modal In-Context Learning (MM-ICL), and that the optimal number may be dependent on various factors such as task complexity, model architecture, and dataset characteristics.", "section": "5 Empirical Analysis of Factors Affecting MM-ICL"}, {"figure_path": "REVdYKGcfb/figures/figures_8_2.jpg", "caption": "Figure 10: The impact of the number of demonstrations on performance.", "description": "This figure shows the impact of the number of demonstrations on the average performance across different tasks and models.  It reveals that increasing the number of demonstrations does not always lead to performance improvements in MM-ICL, and the optimal number of demonstrations varies across different tasks. For image captioning and VQA tasks, performance increases with the number of demonstrations to a point, but then starts to decline when the number of demonstrations exceeds 3. For more complex reasoning tasks, additional demonstrations do not improve performance.", "section": "5 Empirical Analysis of Factors Affecting MM-ICL"}, {"figure_path": "REVdYKGcfb/figures/figures_17_1.jpg", "caption": "Figure 1: The whole process of prompting creation for multi-modal in-context-learning.", "description": "This figure illustrates the three main steps involved in creating prompts for multi-modal in-context learning: demonstration retrieval (selecting relevant demonstrations), demonstration ordering (arranging demonstrations in an effective sequence), and prompt construction (combining demonstrations with instructions into a final prompt).  The process starts with a set of multimodal samples, followed by retrieval of relevant demonstrations based on a validation sample. Then, the retrieved demonstrations are ordered, and finally, a prompt is constructed incorporating the ordered demonstrations and instructions.", "section": "Background"}, {"figure_path": "REVdYKGcfb/figures/figures_19_1.jpg", "caption": "Figure 6: The impact of different sample comparison methodologies in Gemini-Pro.", "description": "This figure compares the performance of two different sample comparison metrics (cosine similarity and L2 similarity) and two different diversity strategies (diversity retriever and similar retriever) across five different large language models (LLMs).  The results indicate that cosine similarity is a better metric for MM-ICL than L2 similarity, and that diversity is not a significant factor in sample comparison for MM-ICL.  This suggests that semantic directional consistency is more important than complete semantic alignment for MM-ICL, and that diversity may not be directly correlated with better MM-ICL performance.", "section": "5.1 Empirical Analysis of MM-ICL Demonstration Retrieval"}, {"figure_path": "REVdYKGcfb/figures/figures_19_2.jpg", "caption": "Figure 2: The demonstration retrieval process for MM-ICL.", "description": "This figure details the demonstration retrieval process for Multi-Modal In-Context Learning (MM-ICL). It outlines three key steps: sample representation (using textual, visual, and multi-modal encoders), sample comparison (using cosine distance, L2 distance, and semantic coverage), and sample selection (employing domain selection, image style selection, and modality distance).  The diagram illustrates how these steps work together to retrieve the most relevant demonstrations for the MM-ICL task.", "section": "3.1 Exploration of MM-ICL Demonstration Retrieval"}, {"figure_path": "REVdYKGcfb/figures/figures_20_1.jpg", "caption": "Figure 14: The demonstration sampling process for MM-ICL prompt construction.", "description": "This figure illustrates the demonstration sampling process within the MM-ICL prompt construction.  The process starts with a validation dataset (V) containing multiple samples. A subset of these samples forms an ordered list (L).  Then, additional samples (Xj1, Xj2) are selected via demonstration sampling. This expanded list is then used to create the final prompt (P). This process is crucial for optimizing the MM-ICL method by carefully selecting relevant examples and additional samples for the prompt.", "section": "3.3 Exploration of MM-ICL Prompt Construction"}, {"figure_path": "REVdYKGcfb/figures/figures_20_2.jpg", "caption": "Figure 1: The whole process of prompting creation for multi-modal in-context-learning.", "description": "This figure illustrates the three core steps involved in creating prompts for multi-modal in-context learning: demonstration retrieval, demonstration ordering, and prompt construction.  Demonstration retrieval selects relevant examples from a dataset. Demonstration ordering arranges those examples in a sequence.  Prompt construction combines the ordered demonstrations and instructions to create the final prompt given to a language model.  Each step is crucial for effective multi-modal in-context learning.", "section": "Background"}, {"figure_path": "REVdYKGcfb/figures/figures_21_1.jpg", "caption": "Figure 1: The whole process of prompting creation for multi-modal in-context-learning.", "description": "This figure illustrates the three main steps involved in creating prompts for multi-modal in-context learning (MM-ICL): demonstration retrieval, demonstration ordering, and prompt construction.  Each step is represented visually, showing how the process flows from selecting relevant demonstrations to constructing the final prompt used to evaluate the model.  The validation set provides samples for retrieval. A demonstration set is created, ordered, and then used to construct the prompt, which contains instructions and the ordered demonstrations.", "section": "Background"}, {"figure_path": "REVdYKGcfb/figures/figures_22_1.jpg", "caption": "Figure 1: The whole process of prompting creation for multi-modal in-context-learning.", "description": "The figure illustrates the three main steps involved in creating prompts for multi-modal in-context learning (MM-ICL): demonstration retrieval, demonstration ordering, and prompt construction.  Each step is visually represented, showing how demonstrations are selected, ordered, and combined to form a prompt used with a multi-modal large language model.  The process helps to understand how each stage influences the effectiveness of the MM-ICL approach.", "section": "Background"}, {"figure_path": "REVdYKGcfb/figures/figures_22_2.jpg", "caption": "Figure 1: The whole process of prompting creation for multi-modal in-context-learning.", "description": "This figure illustrates the three main steps involved in creating prompts for multi-modal in-context learning.  First, relevant demonstrations are retrieved from a demonstration set. Second, these demonstrations are ordered, considering both intra-demonstration (order within a single demonstration) and inter-demonstration (order between demonstrations) sequencing.  Finally, a prompt is constructed using the ordered demonstrations, which may also include instructions.", "section": "Background"}, {"figure_path": "REVdYKGcfb/figures/figures_23_1.jpg", "caption": "Figure 1: The whole process of prompting creation for multi-modal in-context-learning.", "description": "The figure illustrates the three core steps involved in creating prompts for multi-modal in-context learning.  First, relevant demonstrations are retrieved. Second, these demonstrations are ordered.  Third, a final prompt is constructed, incorporating the ordered demonstrations.  This process aims to leverage examples to enable a model to perform a task without explicit parameter tuning.", "section": "Background"}]