[{"figure_path": "HXdAfK488A/tables/tables_5_1.jpg", "caption": "Table 1: Performance on Zendo and ActiveACRE. The results for Zendo are mean \u00b1 standard error of predictive posterior accuracy summed over the test scenes, averaged over the tasks and 5 seeds. ActiveACRE results are mean \u00b1 standard error of each metric averaged over 20 tasks. ActiveACRE is heavily class-inbalanced, so we compute a wider variety of accuracy metrics.", "description": "This table presents the results of two experiments, Zendo and ActiveACRE, comparing different methods for learning rules from data.  It shows predictive posterior accuracy (averaged over multiple trials), along with other metrics like F1 score and ROC AUC, to evaluate the performance.  Note that ActiveACRE is class-imbalanced; hence, additional metrics are used for a thorough evaluation.  The results demonstrate the effectiveness of online learning methods, and comparing different models (including human performance) illustrates the nuanced picture of which methods best fit human behavior.", "section": "3 Experimental Results"}, {"figure_path": "HXdAfK488A/tables/tables_5_2.jpg", "caption": "Table 1: Performance on Zendo and ActiveACRE. The results for Zendo are mean \u00b1 standard error of predictive posterior accuracy summed over the test scenes, averaged over the tasks and 5 seeds. ActiveACRE results are mean \u00b1 standard error of each metric averaged over 20 tasks. ActiveACRE is heavily class-inbalanced, so we compute a wider variety of accuracy metrics.", "description": "This table presents the performance comparison of different methods on two tasks: Zendo and ActiveACRE.  For Zendo, the average predictive posterior accuracy is reported, averaged across multiple runs and tasks. For ActiveACRE, because of class imbalance, multiple metrics (ROC AUC, F1, task solving) are presented.", "section": "Experimental Results"}, {"figure_path": "HXdAfK488A/tables/tables_7_1.jpg", "caption": "Table 1: Performance on Zendo and ActiveACRE. The results for Zendo are mean \u00b1 standard error of predictive posterior accuracy summed over the test scenes, averaged over the tasks and 5 seeds. ActiveACRE results are mean \u00b1 standard error of each metric averaged over 20 tasks. ActiveACRE is heavily class-inbalanced, so we compute a wider variety of accuracy metrics.", "description": "This table presents the performance of different models on two tasks: Zendo and ActiveACRE.  For Zendo, it shows the average predictive posterior accuracy (with standard error) across multiple test scenes.  For ActiveACRE, which has class imbalance, it presents more metrics (ROC AUC, F1, task solving) along with the average predictive posterior accuracy and standard error.", "section": "3 Experimental Results"}, {"figure_path": "HXdAfK488A/tables/tables_7_2.jpg", "caption": "Table 1: Performance on Zendo and ActiveACRE. The results for Zendo are mean \u00b1 standard error of predictive posterior accuracy summed over the test scenes, averaged over the tasks and 5 seeds. ActiveACRE results are mean \u00b1 standard error of each metric averaged over 20 tasks. ActiveACRE is heavily class-inbalanced, so we compute a wider variety of accuracy metrics.", "description": "This table presents the results of the proposed model on two different tasks: Zendo and ActiveACRE.  It compares the model's performance against human performance and several baselines, assessing metrics such as predictive posterior accuracy, ROC AUC, F1 score, and task solving success rate. The results reveal that the online inference model, particularly when using fuzzy rules, outperforms other models, including humans in overall performance on Zendo, and achieves higher accuracy in solving the ActiveACRE tasks.", "section": "3 Experimental Results"}, {"figure_path": "HXdAfK488A/tables/tables_17_1.jpg", "caption": "Table 1: Performance on Zendo and ActiveACRE. The results for Zendo are mean \u00b1 standard error of predictive posterior accuracy summed over the test scenes, averaged over the tasks and 5 seeds. ActiveACRE results are mean \u00b1 standard error of each metric averaged over 20 tasks. ActiveACRE is heavily class-inbalanced, so we compute a wider variety of accuracy metrics.", "description": "This table presents the performance of different methods on two tasks: Zendo and ActiveACRE.  For Zendo, the average predictive posterior accuracy is shown, considering the mean and standard error across multiple trials.  ActiveACRE results are presented with several metrics (ROC AUC, F1, Task Solving) because of the class imbalance in the data. The table allows comparison of the performance of human players, several baselines from previous work, and the authors' proposed methods with different rule configurations (hard vs. fuzzy, online vs. batch).", "section": "Experimental Results"}, {"figure_path": "HXdAfK488A/tables/tables_23_1.jpg", "caption": "Table 1: Performance on Zendo and ActiveACRE. The results for Zendo are mean \u00b1 standard error of predictive posterior accuracy summed over the test scenes, averaged over the tasks and 5 seeds. ActiveACRE results are mean \u00b1 standard error of each metric averaged over 20 tasks. ActiveACRE is heavily class-inbalanced, so we compute a wider variety of accuracy metrics.", "description": "This table presents the performance of different methods on two tasks: Zendo and ActiveACRE.  For Zendo, the results show average predictive posterior accuracy, with standard errors. For ActiveACRE, which is class imbalanced, ROC AUC, F1 score, and task solving are reported as well, showcasing a comparison of multiple models across different metrics.", "section": "3 Experimental Results"}, {"figure_path": "HXdAfK488A/tables/tables_24_1.jpg", "caption": "Table 1: Performance on Zendo and ActiveACRE. The results for Zendo are mean \u00b1 standard error of predictive posterior accuracy summed over the test scenes, averaged over the tasks and 5 seeds. ActiveACRE results are mean \u00b1 standard error of each metric averaged over 20 tasks. ActiveACRE is heavily class-inbalanced, so we compute a wider variety of accuracy metrics.", "description": "This table presents the performance comparison of different methods on two tasks: Zendo and ActiveACRE.  For Zendo, it shows the average predictive posterior accuracy, calculated as the mean across test scenes, tasks, and multiple runs. ActiveACRE results, due to class imbalance, include additional metrics beyond accuracy, like ROC AUC, F1 score, and task solving success rate. The table allows for comparison of human performance with the proposed model and existing baselines.", "section": "3 Experimental Results"}, {"figure_path": "HXdAfK488A/tables/tables_26_1.jpg", "caption": "Table 1: Performance on Zendo and ActiveACRE. The results for Zendo are mean \u00b1 standard error of predictive posterior accuracy summed over the test scenes, averaged over the tasks and 5 seeds. ActiveACRE results are mean \u00b1 standard error of each metric averaged over 20 tasks. ActiveACRE is heavily class-inbalanced, so we compute a wider variety of accuracy metrics.", "description": "This table presents the results of the proposed model on two tasks, Zendo and ActiveACRE.  For Zendo, it shows the average predictive posterior accuracy, calculated as the mean across multiple trials and averaged across different tasks.  For ActiveACRE, which has an imbalanced class distribution, it presents a broader set of evaluation metrics (ROC AUC, F1-score, task solving success rate) to provide a comprehensive assessment of the model's performance.  The standard error is provided to indicate the variability of the results.", "section": "3 Experimental Results"}, {"figure_path": "HXdAfK488A/tables/tables_28_1.jpg", "caption": "Table 1: Performance on Zendo and ActiveACRE. The results for Zendo are mean \u00b1 standard error of predictive posterior accuracy summed over the test scenes, averaged over the tasks and 5 seeds. ActiveACRE results are mean \u00b1 standard error of each metric averaged over 20 tasks. ActiveACRE is heavily class-inbalanced, so we compute a wider variety of accuracy metrics.", "description": "This table presents the performance comparison of different models on two tasks: Zendo and ActiveACRE.  For Zendo, it shows the average predictive posterior accuracy, while for ActiveACRE it provides a more comprehensive evaluation due to class imbalance, including ROC AUC, F1 score, and task solving rate.  The results highlight the superior performance of the proposed online inference model, especially in ActiveACRE.", "section": "3 Experimental Results"}, {"figure_path": "HXdAfK488A/tables/tables_29_1.jpg", "caption": "Table 1: Performance on Zendo and ActiveACRE. The results for Zendo are mean \u00b1 standard error of predictive posterior accuracy summed over the test scenes, averaged over the tasks and 5 seeds. ActiveACRE results are mean \u00b1 standard error of each metric averaged over 20 tasks. ActiveACRE is heavily class-inbalanced, so we compute a wider variety of accuracy metrics.", "description": "This table presents the performance comparison between different models on two tasks: Zendo and ActiveACRE.  For Zendo, it shows the average predictive posterior accuracy, with standard error, across multiple test scenes and trials.  ActiveACRE results are also averaged across multiple trials but include additional metrics (ROC AUC, F1 score, and Task Solving) due to class imbalance.", "section": "3 Experimental Results"}]