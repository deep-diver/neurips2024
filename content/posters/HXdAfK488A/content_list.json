[{"type": "text", "text": "Doing Experiments and Revising Rules with Natural Language and Probabilistic Reasoning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Wasu Top Piriyakulkij1\u2217 Cassidy Langenfeld1 Tuan Anh Le2 Kevin Ellis1 Cornell University1 Google2 ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We give a model of how to infer natural language rules by doing experiments. The model integrates Large Language Models (LLMs) with Monte Carlo algorithms for probabilistic inference, interleaving online belief updates with experiment design under information-theoretic criteria. We conduct a human-model comparison on a Zendo-style task, finding that a critical ingredient for modeling the human data is to assume that humans also consider fuzzy, probabilistic rules, in addition to assuming that humans perform approximately-Bayesian belief updates. We also compare with recent algorithms for using LLMs to generate and revise hypotheses, finding that our online inference method yields higher accuracy at recovering the true underlying rule, and provides better support for designing optimal experiments. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "An important way that humans grow their knowledge of the world is by experimentation and other forms of active learning. This process is most clearly present in the experimental sciences, but similar processes of active inference begin in infancy through early childhood [1, 2, 3, 4, 5]. Within everyday adult cognition, active experimentation helps us quickly learn to use new devices and tools. ", "page_idx": 0}, {"type": "text", "text": "A basic framework for modeling experimentation is to alternate between conducting a good experiment, and updating one\u2019s beliefs based on those experimental results [6]. These beliefs concern a latent hypothesis about the regularity or trend the experimenter is investigating. This leaves open at least two computational questions. First, we need to define a hypothesis space. Second, we need efficient algorithms for belief updates and experiment generation. Such algorithms should reason about probabilistic beliefs\u2014considering many hypotheses and their associated probabilities\u2014in order to find experiments that optimally resolve different competing hypothesis. ", "page_idx": 0}, {"type": "text", "text": "Here we will introduce a model that represents hypotheses in natural language\u2014even for problems that do not intrinsically involve human language. We do this for two reasons. First, natural language can index many human concepts, and can recursively combine them, giving an expressive hypothesis space. Second, it allows using Large Language Models (LLMs) to aid the inference task of updating beliefs after each experiment, giving tractable, approximate probabilistic inference when we view the LLM as a proposal distribution for a Monte Carlo estimator. ", "page_idx": 0}, {"type": "text", "text": "We are especially interested in comparing our model to human behavior, given the long legacy of probabilistic modeling within cognitive science [7, 8]. We find a nuanced picture: vanilla LLMs are not humanlike on our active learning tasks (and underperform humans); our full model outperforms humans; but a simple change\u2014switching from deterministic to probabilistic hypotheses\u2014allows matching humans in overall performance, and agreement with humans on more fine-grained metrics. ", "page_idx": 0}, {"type": "text", "text": "From a technical perspective, our work needs to infer natural-language hypotheses in an online setting, so that it can cycle between experimentation and hypothesis formation. This differs from recent batched approaches for hypothesis formation [9, 10, 11]. To allow online inference, we hybridize LLMs with Sequential Monte Carlo Samplers (SMC-S: [12]). In SMC-S, one tracks a modest number of hypotheses that serve as (approximate) samples from the posterior. Meanwhile, the LLM focuses the sampler on a small set of candidate hypotheses that it deems relevant, given the data. The resulting sampler facilitates active learning by choosing an experiment which optimally \u201csplits\u201d the candidate hypotheses. With strategies that do not use probabilistic framing, such as tracking a single best-guess hypothesis, the active learner would have little guidance on what experiment to do next. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "We will focus here on active inference of basic symbolic concepts expressible in natural language, as we believe these are tractable first targets of study. Concretely, we consider tasks in the spirit of the boardgame \u2018Zendo\u2019, a challenging but accessible game where human players actively learn binary rules combining logical and spatial relations [13, 14, 15], as well as \u2018Blicket test\u2019 style tasks, inspired by studies in developmental psychology [16, 2, 17] that investigate how children learn the causal mechanism behind the activation of a machine. See Figure 1. ", "page_idx": 1}, {"type": "text", "text": "We contribute the following: ", "page_idx": 1}, {"type": "text", "text": "1. An algorithm for probabilistic inference of latent natural language hypotheses. This derives from SMC-S, but uses an LLM proposal distribution to allow tractable inference over natural language strings, essentially using the LLM to suggest ways of revising the belief state. 2. Model-Human/Model-Baseline comparisons, finding that (1) we get a better fit to human data using natural language, instead of formal languages; (2) the model can be further made more humanlike by considering fuzzy (probabilistic) rules, and (3) that our online inference also yields better accuracy at the actual task relative to recent work [10, 9, 11]. 3. Empirical findings about the ability of LLMs to revise hypotheses and propose experiments. On the domains we consider, we find that LLMs are effective for proposing and revising hypotheses, but do not consistently outperform random guessing when proposing experiments. ", "page_idx": 1}, {"type": "text", "text": "2 Model ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "We start with standard Bayesian optimal experiment design, which gives a framework for describing both experimentation and hypothesis formation [18, 19]. Our model includes natural-language hypotheses $h\\in\\Sigma^{*}$ , experiments $x\\in\\mathscr{X}$ , and experiment outcomes $y\\in\\mathcal{V}$ . We consider equipping $h$ with real-valued parameters $\\theta$ : For example, if the hypothesized rule is fuzzy (noisy), then $\\theta$ would control the noise level. As new experiments are proposed sequentially, we index experiments and outcomes with subscripts, i.e. $x_{t}$ and $y_{t}$ for the $t^{\\mathrm{th}}$ experiment and outcome, respectively. The objective is to identify ground-truth $h^{*}$ , and to accurately predict the outcome of future experiments. ", "page_idx": 1}, {"type": "image", "img_path": "HXdAfK488A/tmp/c20595670809b92b4231798b233fb2743d0eca672d53d3ca4475a34b5f5b634b.jpg", "img_caption": ["Figure 1: Alternation of experimentation and hypothesis generation on a simplified version of our ActiveACRE domain. Hypotheses characterizes what causes the machine to activate (make noise). "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "The joint distribution over hypothesis $h,\\theta$ and outcomes $y_{1:T}$ , given experiments $x_{1:T}$ , is ", "page_idx": 2}, {"type": "equation", "text": "$$\np(h,y_{1:T},\\theta|x_{1:T})=p(h)p(\\theta)\\prod_{1\\leq t\\leq T}p(y_{t}|x_{t},h,\\theta)\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where the prior $p(h)$ favors shorter or simpler hypotheses. From eq. (1) the posterior is ", "page_idx": 2}, {"type": "equation", "text": "$$\np(h|x_{1:T},y_{1:T})\\propto p(h)\\int_{\\theta}p(\\theta)\\prod_{1\\leq t\\leq T}p(y_{t}|x_{t},h,\\theta)\\mathrm{d}\\theta\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where we assume the above integral is tractable, because $\\theta$ is low-dimensional. Ultimately, the purpose of the hypothesis is to make predictions on new experiments. Given a test experiment $x_{\\mathrm{{test}}}$ , an ideal learner predicts an outcome $y_{\\mathrm{{test}}}$ distributed as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\np(y_{\\mathrm{test}}|x_{\\mathrm{test}},x_{1:T},y_{1:T})=\\sum_{h}p(h|x_{1:T},y_{1:T})\\int_{\\theta}p(\\theta|h,x_{1:T},y_{1:T})p(y_{\\mathrm{test}}|x_{\\mathrm{test}},h,\\theta)\\mathrm{d}\\theta\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The optimal experiment for identifying $h$ maximizes the following information gain [20]: ", "page_idx": 2}, {"type": "equation", "text": "$$\nx^{*}=\\underset{x\\in\\mathcal{X}}{\\arg\\operatorname*{max}}\\ \\underset{p(y|x_{1:T},y_{1:T},x)}{\\mathbb{E}}[D_{\\mathrm{KL}}(p(h|x_{1:T},y_{1:T},x,y)||p(h|x_{1:T},y_{1:T}))]\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The above computations are intractable because they involve considering the infinitely large set of all hypotheses and experiments. We next describe our LLM-guided approximation methods. ", "page_idx": 2}, {"type": "text", "text": "2.1 Revising Rules: Online Inference ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We introduce a generalization of the Sequential Monte Carlo Sampler (SMC-S) [12], an online approximate inference algorithm which tracks a small pool of hypotheses\u2014called particles\u2014that evolve over time as new data is collected. Tracking representative high-posterior particles allows approximate inference (eq. (2)) and prediction (eq. (3)) by only considering the current particles. This makes the model \u201cboundedly rational\u201d [21]: as the bound on computation (# particles) grows large, the sampler better approximates optimal inference. To the extent that our work offers a cognitive model, we are claiming that humans only consider a small number of hypotheses, which evolve in ways that approximate probabilistic reasoning. This should be seen within the tradition of using approximate inference methods to give mechanistic accounts of human learning [22, 23, 24, 25]. ", "page_idx": 2}, {"type": "text", "text": "Standard SMC-S tracks $n$ particles at each time point $t$ , written $H_{t}\\ \\ =\\ \\ \\{h_{t}^{(i)}\\}_{i=1}^{n}$ . Each particle has a weight, $W_{t}~=~\\{w_{t}^{(i)}\\}_{i=1}^{n}$ , giving the approximate posterior $p(h|x_{1:t},y_{1:t})\\ \\approx$ $\\begin{array}{r}{\\sum_{i}w_{t}^{(i)}\\mathbb{1}\\left[h=h_{t}^{(i)}\\right]}\\end{array}$ . Upon observing a new data point, the particles $H_{t}$ are pushed through a forward kernel $\\bar{q}_{t+1}\\bar{(h_{t+1}|h_{t}^{(i)})}$ , which randomly perturbs the particles, to obtain new particles $H_{t+1}$ . Next, the particles are reweighed to obtain $W_{t+1}$ . Finally, a resampling step can be executed to prune low-weight particles and multiply high-weight particles. ", "page_idx": 2}, {"type": "image", "img_path": "HXdAfK488A/tmp/f98550985e9686dbc0a327d830ca15472692117892d193d6f6ca457d3ccddcd0.jpg", "img_caption": ["Figure 2: Sequential Monte Carlo method tracks a small number of hypotheses (called particles), each of which is a natural language rule, represented above by circles. After each experiment, the particles are revised in light of the new data by pushing the particles through the forward kernel. Then, the new particles are reweighed according to how well each explains the data we have seen so far. Resampling prunes low-probability hypotheses while multiplying high-probability ones. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "Here $h$ is a natural language string, suggesting an LLM should define $q_{t}(h_{t}|h_{t-1}^{(i)})$ . For example, an LLM can be prompted with a hypothesis, together with the latest experiment outcome, and asked to revise that hypothesis. But calling an LLM to perturb every single particle is expensive, and unnecessary for hypotheses that already explain the data well. ", "page_idx": 3}, {"type": "text", "text": "We therefore design a variant of SMC-S whose forward kernel looks globally at the current set of particles and prompts an LLM to revise the worst (lowest-likelihood) particles, while keeping unchanged the best (highest-likelihood) particles. This concentrates the computation on improving bad hypotheses, instead of wasting effort altering what already works. Within the context of LLMs, this can be seen as an online, probabilistic version of hypothesis refinement [9, 26, 10]. Within the context of SMC-S, this mathematically corresponds to defining a forward kernel that conditions on the entire set of previous particles and all seen data points, $\\bar{q}_{t}(h_{t}|H_{t-1},x_{1:t},y_{1:t})$ .2 Below we formalize our new SMC-S variant, which we call LLM-SMC-S, illustrated in Figure 2. ", "page_idx": 3}, {"type": "text", "text": "Procedure: LLM-SMC-S (A.4). Given $H_{t},W_{t}$ where $\\begin{array}{r}{p(h|x_{1:t},y_{1:t})\\approx\\sum_{i}w_{t}^{(i)}\\mathbb{1}\\left[h=h_{t}^{(i)}\\right]\\!;}\\end{array}$ 1. Define unnormalized target densities $\\gamma(h)=p(h,y_{1:t},x_{1:t})$ and $\\gamma^{\\prime}(h)=p(h,y_{1:t+1},x_{1:t+1})$ . 2. Sample $h^{\\prime}\\sim q_{t+1}(\\cdot|H_{t},x_{1:t+1},y_{1:t+1})$ (i.e., using LLM to revise hypotheses) 3. Compute the weight $w^{\\prime}$ for $h^{\\prime}$ following ", "page_idx": 3}, {"type": "equation", "text": "$$\nw^{\\prime}={\\frac{A(h^{\\prime},H_{t},W_{t})}{q_{t+1}(h^{\\prime}|H_{t},x_{1:t+1},y_{1:t+1})}}{\\mathrm{~where~}}A(h^{\\prime},H_{t},W_{t})={\\frac{1}{n}}\\sum_{i=1}^{n}w_{t}^{(i)}{\\frac{\\gamma^{\\prime}(h^{\\prime})r(h_{t}^{(i)}|h^{\\prime})}{\\gamma(h_{t}^{(i)})}}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "with the reverse kernel $r(h|h^{\\prime})$ defined as uniform up to strings of a maximum length. ", "page_idx": 3}, {"type": "text", "text": "4. Repeat steps 2-3 (sampling/weighing) a total of $n$ times, and normalize the weights. Optionally, resample to generate an unweighted posterior (we always resample).   \n5. Output: $H_{t+1}$ and $W_{t+1}$ , formed from $n$ samples of $h^{\\prime},w^{\\prime}$ with $w^{\\prime}$ normalized from step 4, which approximate $p(h|x_{1:t+1},y_{1:t+1})$ . ", "page_idx": 3}, {"type": "text", "text": "The correctness of the above procedure is most easily understood using the following definition: ", "page_idx": 3}, {"type": "text", "text": "Definition: Proper Weighting [27]. Let $\\gamma(h)$ be an unnormalized target density, which we can evaluate. Let the corresponding normalized target density be \u03c0(h) = \u03b3Z(h\u03c0) where $\\begin{array}{r}{Z_{\\pi}=\\int\\gamma(h)\\mathrm{d}h}\\end{array}$ is the normalization constant. A weighted particle $h,w$ is properly weighted with respect to $\\gamma$ if for any function $f$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\nE[w f(h)]=Z_{\\pi}E_{\\pi(h)}[f(h)]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Proposition 1. If $H,W$ input to Procedure LLM-SMC-S is properly weighted with respect to $\\gamma$ , then the output $h^{\\prime},w^{\\prime}$ is properly weighted with respect to $\\gamma^{\\prime}$ . (Proof in Appendix A.1.) ", "page_idx": 3}, {"type": "text", "text": "2.2 Doing Experiments: Active Learning ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Our active learning works by doing an experiment that maximizes information gain (eq. (4)). Experiments may be complex, such as involving putting objects or instruments in specific positions, and there might be combinatorially many possible experiments. For a rich space of experiments, a bounded learner\u2014human or AI\u2014cannot consider all possibilities. ", "page_idx": 3}, {"type": "text", "text": "We will propose experiments using an LLM, but then reassess those proposals under probabilistic criteria. Particularly, we provide an LLM with the hypotheses tracked by the SMC-S sampler at each iteration, and prompt it to generate experiments that support and falsify each hypothesis. Empirically, this process yields a diverse pool of experiments. We take the best experiment proposed by the LLM, as measured under the approximate posterior from SMC-S: ", "page_idx": 3}, {"type": "equation", "text": "$$\nx_{t+1}=\\operatorname*{arg\\,max}_{x\\in\\mathrm{PRoMPT}(H_{t})}\\ \\underset{\\hat{p}(y|x,x_{1:t},y_{1:t})}{\\mathbb{E}}\\big[D_{\\mathrm{KL}}\\big(\\hat{p}(h|x_{1:t},y_{1:t},x,y)\\big|\\vert\\hat{p}(h|x_{1:t},y_{1:t})\\big)\\big]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\hat{p}$ is approximated with the weighted particles from SMC-S.3 ", "page_idx": 3}, {"type": "text", "text": "2.3 Instantiating the model ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "All of our experiments have binary outcomes $(y\\in\\{0,1\\})$ , and all of our natural language hypotheses correspond to rules that predict whether an experiment succeeds or fails (1 or 0). Although the rules predict hard all-or-none judgments, a learner can relax that constraint by assuming that the underlying rule is fuzzy (noisy). Many natural language facts and rules actually only partly hold, such as birds fly (almost always true), or birds lay eggs (true half the time). To handle the possibility of fuzzy rules, we equipped each hypothesized rule with real-valued parameters $\\theta$ that control the noise level. The noise parameters decompose into a pair $\\theta=(\\epsilon,\\delta)$ controlling the rate of false-positives/false-negatives: ", "page_idx": 4}, {"type": "equation", "text": "$$\np(y=1|x,h,\\epsilon,\\delta)=\\ \\left[\\begin{array}{c c}{\\delta}&{\\mathrm{if}\\ h(x)=1}\\\\ {1-\\epsilon}&{\\mathrm{if}\\ h(x)=0}\\end{array}\\right]\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Under this formulation, hard rules corresponds to $p(\\epsilon)$ and $p(\\delta)$ having non-zero probability only at value 1. For probabilistic, fuzzy rules, we use Gaussian priors for $p(\\epsilon)$ and $p(\\delta)$ , truncated to [0.5,1], and with a bias toward larger $\\epsilon$ . The prior $p(h)$ is defined as inversely proportional to wordcount, giving a gentle bias toward parsimony. We investigate both hard and fuzzy rules in our experiments. ", "page_idx": 4}, {"type": "text", "text": "Evaluating $h(x)$ requires checking the natural language string $h$ against experiment $x$ , for which we use GPT-3.5 to translate the natural language $h$ to code which is run on $x$ . We use GPT-4 Turbo to propose hypotheses [30]. Recent studies find a similar breakdown of LLMs works well [9, 10, 11]. ", "page_idx": 4}, {"type": "text", "text": "3 Experimental Results ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Domains. Zendo is a game where a player seeks to infer a hidden binary rule about scenes of colored shapes. Our Zendo games begin with showing the player a positive example scene, followed by 7 rounds of experimentation, where the player builds a scene, and receives feedback on if the scene obeys the hidden rule. After the experimentation phase, players are tested on 8 test scenes, half of which follow the hidden rule. Our setup follows Bramley et al.[13], but modified for LLMs by presenting scenes as text describing each block by its color, size, orientation, groundedness, and what other blocks it touches and stacks (Figure 3). ", "page_idx": 4}, {"type": "text", "text": "Our second domain, ActiveACRE, derives from The Abstract Causal REasoning (ACRE) dataset [17], which in turn derives from \u2018blicket\u2019 tests in developmental cognitive psychology [16]. The original ACRE is a causal induction dataset where each task is to figure out what causes the \u2018blicket\u2019 machine to make sounds when multiple objects are put on the machine. We add active learning to ACRE: rather than passively observe examples, our ActiveACRE allows the player to try 7 experiments, after passively witnessing the outcome of one experiment involving eight objects. The player is then tested (without further feedback) on all possible combinations of the original eight objects. ", "page_idx": 4}, {"type": "text", "text": "Model-Baseline comparisons. Table 1 contrasts the performance of different models, showing that online inference with hard rules outperforms all other models on both datasets, including a ReActstyle baseline [31] (Direct LLM), and batched inference with refinement, an approach advocated for in recent work [10, 9]. To measure accuracy on Zendo, we compute the predictive posterior accuracy summed over the 8 test scenes and averaged over all tasks. Because the test set on ActiveACRE are highly imbalanced, we also report ROC AUC, F1, and task solving scores. The last metric, task solving, measures whether the models perfectly solves each task. The results, especially the large gap on average task solving between our online inference algorithm and batch inference, demonstrate that our online algorithm is more successful at inducing the correct causal law within ACRE, and more accurate at predicting what scenes obey the rule in Zendo. Interestingly, our most performant models\u2014which assume hard deterministic rules\u2014actually surpass human accuracy [13]. This raises the question of how humanlike the model is (or isn\u2019t), which we investigate next. ", "page_idx": 4}, {"type": "image", "img_path": "HXdAfK488A/tmp/f2f5a948e2adbee0ac82e74bf4f8ccc9f652833269eb28a70fc9e1889e583e27.jpg", "img_caption": ["Figure 3: (a) Example Zendo scene and its serialization into text. (b) Eight experiments, each of which is a scene, with a binary outcome (whether the scene makes stars come out of it). (c) Test scenes that evaluate whether a model or human has correctly inferred the hidden rule. "], "img_footnote": [], "page_idx": 4}, {"type": "table", "img_path": "HXdAfK488A/tmp/3974c0c5b7f1be59cdefe742b7ba6ce7aa6fea6dcb8fad608aeb8009bdbaa949.jpg", "table_caption": [], "table_footnote": ["Table 1: Performance on Zendo and ActiveACRE. The results for Zendo are mean $\\pm$ standard error of predictive posterior accuracy summed over the test scenes, averaged over the tasks and 5 seeds. ActiveACRE results are mean $\\pm$ standard error of each metric averaged over 20 tasks. ActiveACRE is heavily class-inbalanced, so we compute a wider variety of accuracy metrics. "], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Model-Human comparisons. We run the model on the same Zendo games that human participants did, taking human data from Bramley et al. [13]. Average human accuracy is $5.26/8$ , which surpasses a ReAct-style agent (4.60/8), falls short of our strongest model (6.55/8), and is close to the variant of our model which uses probabilistic fuzzy rules (5.35/8). For a more fine-grained understanding of how human and model accuracy compare, we split accuracy across each of the 10 rules on test scenes that either obey the hidden rule (Rule Following or $R F$ condition) or violate the rule (Not Rule Following or Not $R F$ condition) (Figure 4a). With fuzzy rules, the model explains $57\\%$ of the variation in this more fine-grained measurement of human accuracy $\\mathcal{R}^{2}=.5\\dot{7}\\$ ). Switching to hard rules drops this to $R^{2}=.\\dot{1}0$ , suggesting that hard all-or-none rules do not provide as good of an explanation of human behavior, even though hard rules outperform probabilistic ones in terms of accuracy. Doing batch inference instead of online inference degrades fit to $R^{2}=.05$ . Having the LLM play Zendo directly (ReAct [31]) is only loosely correlated with human accuracy patterns ( $R^{2}=.\\dot{2}5)$ ). We last consider predicting every single human judgment on every single test scene, for every single rule. The online, fuzzy rules model predicts these human judgments at the level of $R^{2}=.\\dot{3}5$ , and importantly, it is only with combination of online inference with fuzzy rules that gives a significant fraction of explained variance (Figure 5), and which assigns the highest likelihood to the raw human data (Table 2). ", "page_idx": 5}, {"type": "table", "img_path": "HXdAfK488A/tmp/f968b40ebed931b4d5660e451e8acb75ee36631e839d93fb3d8509d2f0189fa3.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "image", "img_path": "HXdAfK488A/tmp/1448f7ae4480a861cdbcdfdfe285a6e15571b1cc81a1ae7de7fa889e6e900fbe.jpg", "img_caption": ["Figure 6: Performance of human and model on \u2019the majority of blocks is red\u2019 "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "We noticed across many rules a significant difference in human accuracy on RF and Not RF test scenes. Whether people finds RF or Not RF test scenes easier depends on the underlying rule. Figure 4b illustrates this phenomenon and compares it against what each model thinks should be the easier condition. Online learning of fuzzy rules successfully predicts the direction of almost all of these trends, unlike the alternative models. ", "page_idx": 5}, {"type": "text", "text": "Hence, we hypothesize that although the hidden Zendo rules are deterministic, humans might nonetheless infer fuzzy rules. Real-world regularities are seldomly deterministic, so it may be rational for human learners to seek probabilistic explanations, especially when they are uncertain about the underlying rule. However, fuzzy rules on their own do not suffice to explain human judgments: Only by combining with online probabilistic inference do we begin to explain the data. ", "page_idx": 5}, {"type": "image", "img_path": "HXdAfK488A/tmp/9fd3347bbd85d5e40d2ce401399fb8db6a85ca4a4b4a7e440f2046afd5ded8c9.jpg", "img_caption": ["Figure 4: Human vs model accuracy binned by 4 rule-following (RF) and 4 not rule-following (Not RF) test scenes. (a) Each point is a RF or Not RF accuracy for the 10 rules. (b) Rows/columns are methods/rules. Online inference with fuzzy rules (last row) most closely matches humans. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Why reason in natural language instead of a formal language? Many Bayesian models account for human concept learning using probabilistic reasoning over formal languages such as logic [32, 33, 34, 35, 36]. Instead, our model operates over natural language. This helps address two liabilities of formal representations: expressivity and tractability. A handcrafted formal language is often insufficiently expressive, accidentally excluding many human concepts. This expressivity must be limited because, although there exist highly expressive formal languages, in practice, inference in such languages is generally intractable\u2014a tradeoff partly addressed by using LLM proposal distributions. ", "page_idx": 6}, {"type": "text", "text": "To illustrate these points, we study a new Zendo rule\u2014\u2018the majority of blocks is red\u2019\u2014which is not expressible in the formal language introduced by [13]. We collect new human data in an IRB-approved study. Figure 6 shows that both humans and our model correctly learn this rule $30\\%-40\\bar{\\%}$ of the time. This indicates both the model and humans are able to represent this rule in their hypothesis space, which is unrepresentable in a formal language designed specifically for Zendo. ", "page_idx": 6}, {"type": "image", "img_path": "HXdAfK488A/tmp/fbe441e3a9f9289286c8dc263493bd6119a99dfd4ae4593a4d9339cc711bc9cf.jpg", "img_caption": ["Figure 5: Comparing human and model prediction on each test scene after 7 rounds of experimentation; see also Table 2. Each point is a prediction on a test scene. We only present LLM, best batch model, and best online model here. Please see the figure for all methods at Figure 14. "], "img_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "HXdAfK488A/tmp/8a861ad42f05e406d9d221fc16ca4d87fe809b3e72a415bf02e90b16b56942a6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Table 3: Average predictive posterior (standard error computed over 5 seeds) of online inference models with different active learning methods on Zendo. ", "page_idx": 7}, {"type": "table", "img_path": "HXdAfK488A/tmp/0ee7d145cc0183f3ea1deb1d7fcd9e462c3b79291352daf35c84adbf5d6bab0a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Table 4: Average predictive posterior (standard error computed over 5 seeds) of online inference with hard rules model with different experiment proposers on different number of candidate experiments on Zendo. ", "page_idx": 7}, {"type": "text", "text": "Another reason to use natural language representations is that LLMs, trained on human-generated data, may to some extent capture human bias, judgement, and opinions [37, 38, 39]. Unlike approaches based on estimating probabilities on formal languages, incorporating LLMs into our models might therefore make them display more human-like behaviors\u2014as shown in earlier sections\u2014without access to additional human data. Indeed, Table 2 shows that our best-performing model surpasses [13]\u2019s model on human data log likelihood even though the latter fits their models on both human active queries and predictions, while our model does not perform such parameter fitting. ", "page_idx": 7}, {"type": "text", "text": "Bounded rationality. To understand the effect of computational cost on the results, we analyze performance and human-model fit while varying the computational budget, as measured by LLM calls. Figure 7 plots human-model fit as compute budget varies (see also Table 5). We observe an (inverted) U-shaped curve: Too little budget gives a bad fit, but overshooting also degrades fti. This result aligns with the theory of bounded rationality [21], which argues for considering human\u2019s limited cognitive resources, and with the rational analysis of human processing limitations [23, 40]. ", "page_idx": 7}, {"type": "image", "img_path": "HXdAfK488A/tmp/c5e64c6f567907541c65607371273694545a63b2115af6732181ea5b4d25be81.jpg", "img_caption": ["R\u00b2 Score between Model and Human Predictions ", "Figure 7: $R^{2}$ score of human vs model accuracy at different computational budgets. A LLM call batch-samples 15 hypotheses. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "What makes good experiments: LLMs, or Information Gain? We first study the importance of the information gain objective (Table 3), contrasting three different active learning methods: LLM (prompting with the hypotheses and asking for a good experiment); Random (handcoded random generator), and InfoGain (main method, with LLM proposing experiments). Substituting InfoGain with alternative methods significantly degrades model performance. Reranking LLM proposals with information gain is important, and an LLM\u2014on its own\u2014does not generate experiments that are as effective. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Is this explained by the strength of the LLM experiment proposer, or by the strength of the InfoGain objective? While earlier results support LLMs\u2019 effectiveness as hypothesis proposers, Table 4 demonstrates that a random proposer, hand-designed under reasonable assumptions, performs similarly to an LLM experiment proposer. This finding is in line with [41] which argues that LLMs may not always produce the most useful set of candidate questions. ", "page_idx": 7}, {"type": "text", "text": "4 Related Work ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Bayesian Concept Learning in Cognitive Science. Bayesian models of few-shot learning of concepts and categories has a long legacy [32, 34, 42, 43, 44, 13, 14, 15, 33, 35, 45, 46, 47, 36]. On Zendo, [13, 14, 15] also engineers a probabilistic context-free grammar to define the Bayesian model to explain Zendo human data; inference is intractable, and they study various approximate inference algorithms on the task. Our work opts for natural language as the hypothesis space for its expressiveness and leverages LLMs to help with approximate inference. ", "page_idx": 8}, {"type": "text", "text": "Inductive Reasoning with Large Language Models. There are a number of recent works on inductive reasoning with LLMs [10, 9, 56, 11, 57]. [10, 9] study the inductive reasoning ability of vanilla LLMs and propose a simple refinement algorithm to improve performance. [11] explicitly treats LLMs as importance samplers and shows that their model, with prior learned from human data and importance sampling as their inference algorithm, is human-like on some domains. Our work frames many of these works as batch inference\u2014in the spirit of importance sampling, from a probabilistic view\u2014which is compared in our results. Additionally, we model the full life-cycle of experimentation and hypothesis revision. ", "page_idx": 8}, {"type": "text", "text": "Active Learning with Large Language Models. The problem of performing active learning with the help of LLMs has been studied under the task of asking better questions with LLMs [58, 59, 60, 41, 61]. GATE [58] directly prompts LLMs to ask open-ended, informative questions. Other works [59, 60, 41] use LLMs to help propose several candidate questions, and then use expected information gain to select the question to be asked. Following these previous works, we investigate the relevance of classic criteria from active learning such as expected information gain. ", "page_idx": 8}, {"type": "text", "text": "Probabilistic Inference with Large Language Models. The framework of probabilistic inference has been applied to LLM-based algorithms. Language-model cascades [62] provides a unifying framework for seeing recent inference-time LLM algorithms [63, 64, 65] as reasoning with probabilistic programs. Other work [66] fine-tunes CoT models by formulating the problem as maximum marginal likelihood where the marginalization over the latent chain of thought is done via probabilistic inference. We use an LLM as an aid for SMC-S, but others have explored using SMC as an aid for LLM decoding [67, 68], which although technically very different, is conceptually complementary. ", "page_idx": 8}, {"type": "text", "text": "5 Limitations and Next Steps ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "The work presented is limited in important ways that suggest next steps. Most immediately, many of the the hypotheses we consider are simple and stereotyped in form, and much of the promise of using natural language is that it exposes a rich, expressive representation for combining and creating new ideas [70]. More ambitiously, hypothesis generation, both in science and in everyday thinking, often involves conjecturing the existence of unseen objects, not just unknown regularities, and incorporating this abductive thinking\u2014which is absent from our model\u2014could open many directions. ", "page_idx": 8}, {"type": "text", "text": "Although the work here is most directly an account of human behavior within the context of the game Zendo, our model is also more broadly inspired by the mental activities of experimental scientists as they build theories and models, weigh hypotheses, and design experiments. Two basic features of our approach reflect scientific experimentation and theory building. First, scientific theories apply only within a particular regime. For example, many equations in physics only apply when objects are moving slowly, and many thermodynamic equations only apply at equilibrium. Outside this regime, the theory is no longer predictive. Similarly, a variant of a model like ours could hypothesize fuzzy, probabilistic rules which either predict a category with high confidence, or outside the regime in which the rule applies, can fail to make a decisive prediction. ", "page_idx": 8}, {"type": "text", "text": "The second way in which this work reflects the practices of experimental science is that it builds its hypotheses via an incremental evolutionary process. In this way, our model is best thought of as performing what is sometimes called \u2018normal science\u2019 \u2014 where one works within an existing paradigm, and considers piecemeal evidence \u2014 and does not model paradigm shifts [71] (what a scientific theorist might pursue) or deeper conceptual changes [3] (what happens during child development), both of which require deep reanalysis of a broad batch of past data, rather than online incremental revision. ", "page_idx": 8}, {"type": "text", "text": "6 Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We are grateful to Neil Bramley and Jan-Philipp Fr\u00e4nken for providing the Zendo data, helpful discussions, and comments on the manuscript. We also thank Hao Tang, Simon Alford, Celine Lee, and the anonymous reviewers for valuable comments on the manuscript. This work was supported by an NSF CAREER grant. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Andres H Mendez, Chen Yu, and Linda B Smith. Controlling the input: How one-year-old infants sustain visual attention. Developmental Science, page e13445, 2023.   \n[2] Claire Cook, Noah D. Goodman, and Laura E. Schulz. Where science starts: Spontaneous experiments in preschoolers\u2019 exploratory play. Cognition, 120(3):341\u2013349, 2011. Probabilistic models of cognitive development.   \n[3] Susan Carey. Conceptual Change In Childhood. MIT Press, 1985.   \n[4] Laura Schulz. The origins of inquiry: Inductive inference and exploration in early childhood. Trends in cognitive sciences, 16(7):382\u2013389, 2012.   \n[5] Alison Gopnik, Andrew N Meltzoff, and Patricia K Kuhl. The scientist in the crib: Minds, brains, and how children learn. William Morrow & Co, 1999.   \n[6] David Klahr and Kevin Dunbar. Dual space search during scientific reasoning. Cognitive science, 12(1):1\u201348, 1988.   \n[7] Nick Chater and Mike Oaksford. The probabilistic mind: Prospects for Bayesian cognitive science. Oxford University Press, USA, 2008.   \n[8] Joshua B Tenenbaum, Charles Kemp, Thomas L Grifftihs, and Noah D Goodman. How to grow a mind: Statistics, structure, and abstraction. Science, 331(6022):1279\u20131285, 2011.   \n[9] Linlu Qiu, Liwei Jiang, Ximing Lu, Melanie Sclar, Valentina Pyatkin, Chandra Bhagavatula, Bailin Wang, Yoon Kim, Yejin Choi, Nouha Dziri, and Xiang Ren. Phenomenal yet puzzling: Testing inductive reasoning capabilities of language models with hypothesis refinement. arXiv preprint arXiv:2310.08559, 2023.   \n[10] Ruocheng Wang, Eric Zelikman, Gabriel Poesia, Yewen Pu, Nick Haber, and Noah D Goodman. Hypothesis search: Inductive reasoning with language models. arXiv preprint arXiv:2309.05660, 2023.   \n[11] Kevin Ellis. Human-like few-shot learning via bayesian reasoning over natural language. NeurIPS, 2023.   \n[12] Pierre Del Moral, Arnaud Doucet, and Ajay Jasra. Sequential monte carlo samplers. Journal of the Royal Statistical Society Series B: Statistical Methodology, 68(3):411\u2013436, 2006.   \n[13] Neil Bramley, Anselm Rothe, Josh Tenenbaum, Fei Xu, and Todd Gureckis. Grounding compositional hypothesis generation in specific instances. In Proceedings of the 40th annual conference of the cognitive science society, 2018.   \n[14] Jan-Philipp Fr\u00e4nken, Nikos C Theodoropoulos, and Neil R Bramley. Algorithms of adaptation in inductive inference. Cognitive Psychology, 137:101506, 2022.   \n[15] Neil R Bramley and Fei Xu. Active inductive inference in children and adults: A constructivist perspective. Cognition, 238:105471, 2023.   \n[16] Alison Gopnik and David M Sobel. Detecting blickets: How young children use information about novel causal powers in categorization and induction. Child development, 71(5):1205\u20131222, 2000.   \n[17] Chi Zhang, Baoxiong Jia, Mark Edmonds, Song-Chun Zhu, and Yixin Zhu. Acre: Abstract causal reasoning beyond covariation. In Proceedings of the ieee/cvf conference on computer vision and pattern recognition, pages 10643\u201310653, 2021.   \n[18] Dennis V Lindley. On a measure of the information provided by an experiment. The Annals of Mathematical Statistics, 27(4):986\u20131005, 1956.   \n[19] Tom Rainforth, Adam Foster, Desi R Ivanova, and Freddie Bickford Smith. Modern bayesian experimental design. Statistical Science, 39(1):100\u2013114, 2024.   \n[20] Burr Settles. Active learning literature survey. 2009.   \n[21] Herbert A Simon. A behavioral model of rational choice. The quarterly journal of economics, pages 99\u2013118, 1955.   \n[22] Adam N Sanborn, Thomas L Grifftihs, and Daniel J Navarro. Rational approximations to rational models: alternative algorithms for category learning. Psychological review, 117(4):1144, 2010.   \n[23] Thomas L. Griffiths, Falk Lieder, and Noah D. Goodman. Rational use of cognitive resources: Levels of analysis between the computational and the algorithmic. Topics in Cognitive Science, 7(2):217\u2013229, 2015.   \n[24] Roger Levy, Florencia Reali, and Thomas Griffiths. Modeling the effects of memory on human online sentence processing with particle filters. Advances in neural information processing systems, 21, 2008.   \n[25] Adam N Sanborn and Nick Chater. Bayesian brains without probabilities. Trends in cognitive sciences, 20(12):883\u2013893, 2016.   \n[26] Xinyun Chen, Maxwell Lin, Nathanael Sch\u00e4rli, and Denny Zhou. Teaching large language models to self-debug. arXiv preprint arXiv:2304.05128, 2023.   \n[27] Christian Naesseth, Fredrik Lindsten, and Thomas Schon. Nested sequential monte carlo methods. In International Conference on Machine Learning, pages 1292\u20131301. PMLR, 2015.   \n[28] Jun S Liu and Jun S Liu. Monte Carlo strategies in scientific computing, volume 10. Springer, 2001.   \n[29] Tuan Anh Le. A better proof of unbiasedness of the sequential monte carlo based normalizing constant estimator, 2023.   \n[30] OpenAI. Gpt-4 technical report, 2023.   \n[31] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022.   \n[32] Noah D Goodman, Joshua B Tenenbaum, Jacob Feldman, and Thomas L Grifftihs. A rational analysis of rule-based concept learning. Cognitive science, 32(1):108\u2013154, 2008.   \n[33] Steven Thomas Piantadosi. Learning and the language of thought. PhD thesis, MIT, 2011.   \n[34] Brenden M Lake, Ruslan Salakhutdinov, and Joshua B Tenenbaum. Human-level concept learning through probabilistic program induction. Science, 350(6266):1332\u20131338, 2015.   \n[35] Goker Erdogan, Ilker Yildirim, and Robert A Jacobs. From sensory signals to modality-independent conceptual representations: A probabilistic language of thought approach. PLoS computational biology, 11(11):e1004610, 2015.   \n[36] Mathias Sabl\u00e9-Meyer, Kevin Ellis, Josh Tenenbaum, and Stanislas Dehaene. A language of thought for the mental representation of geometric shapes. Cognitive Psychology, 139:101527, 2022.   \n[37] Gati V Aher, Rosa I Arriaga, and Adam Tauman Kalai. Using large language models to simulate multiple humans and replicate human subject studies. In International Conference on Machine Learning, pages 337\u2013371. PMLR, 2023.   \n[38] Danica Dillion, Niket Tandon, Yuling Gu, and Kurt Gray. Can ai language models replace human participants? Trends in Cognitive Sciences, 2023.   \n[39] Ishita Dasgupta, Andrew K Lampinen, Stephanie CY Chan, Antonia Creswell, Dharshan Kumaran, James L McClelland, and Felix Hill. Language models show human-like content effects on reasoning. arXiv preprint arXiv:2207.07051, 2022.   \n[40] John R. Anderson. The adaptive character of thought. 1990.   \n[41] Kunal Handa, Yarin Gal, Ellie Pavlick, Noah Goodman, Jacob Andreas, Alex Tamkin, and Belinda Z Li. Bayesian preference elicitation with language models. arXiv preprint arXiv:2403.05534, 2024.   \n[42] Marie Amalric, Liping Wang, Pierre Pica, Santiago Figueira, Mariano Sigman, and Stanislas Dehaene. The language of geometry: Fast comprehension of geometrical primitives and rules in human adults and preschoolers. PLoS computational biology, 13(1):e1005273, 2017.   \n[43] Kevin Ellis, Adam Albright, Armando Solar-Lezama, Joshua B Tenenbaum, and Timothy J O\u2019Donnell. Synthesizing theories of human language with bayesian program induction. Nature communications, 13(1):5024, 2022.   \n[44] Kevin Ellis, Catherine Wong, Maxwell Nye, Mathias Sabl\u00e9-Meyer, Lucas Morales, Luke Hewitt, Luc Cary, Armando Solar-Lezama, and Joshua B. Tenenbaum. Dreamcoder: Bootstrapping inductive program synthesis with wake-sleep library learning. In PLDI, 2021.   \n[45] Lucas Tian, Kevin Ellis, Marta Kryven, and Josh Tenenbaum. Learning abstract structure for drawing by efficient motor program induction. Advances in Neural Information Processing Systems, 33:2686\u20132697, 2020.   \n[46] Feras A Saad, Marco F Cusumano-Towner, Ulrich Schaechtle, Martin C Rinard, and Vikash K Mansinghka. Bayesian synthesis of probabilistic programs for automatic data modeling. Proceedings of the ACM on Programming Languages, 3(POPL):1\u201332, 2019.   \n[47] Percy Liang, Michael I. Jordan, and Dan Klein. Learning dependency-based compositional semantics. In ACL, pages 590\u2013599, 2011.   \n[48] Andrew G Wilson and Pavel Izmailov. Bayesian deep learning and a probabilistic perspective of generalization. Advances in neural information processing systems, 33:4697\u20134708, 2020.   \n[49] Sreejan Kumar, Carlos G Correa, Ishita Dasgupta, Raja Marjieh, Michael Hu, Robert D. Hawkins, Jonathan Cohen, Nathaniel Daw, Karthik R Narasimhan, and Thomas L. Griffiths. Using natural language and program abstractions to instill human inductive biases in machines. In NeurIPS, 2022.   \n[50] Fran\u00e7ois Chollet. On the measure of intelligence, 2019.   \n[51] Pedro A Tsividis, Joao Loula, Jake Burga, Nathan Foss, Andres Campero, Thomas Pouncy, Samuel J Gershman, and Joshua B Tenenbaum. Human-level reinforcement learning through theory-based modeling, exploration, and planning. arXiv preprint arXiv:2107.12544, 2021.   \n[52] Kevin P Murphy. Machine learning: a probabilistic perspective. MIT press, 2012.   \n[53] Joshua Brett Tenenbaum. A Bayesian framework for concept learning. PhD thesis, Massachusetts Institute of Technology, 1999.   \n[54] Steven T Piantadosi, Joshua B Tenenbaum, and Noah D Goodman. The logical primitives of thought: Empirical foundations for compositional cognitive models. Psychological review, 123(4):392, 2016.   \n[55] Jan-Philipp Fr\u00e4nken, Christopher G Lucas, Neil R Bramley, and Steven T Piantadosi. Modeling infant object perception as program induction. arXiv preprint arXiv:2309.07099, 2023.   \n[56] Yangqiaoyu Zhou, Haokun Liu, Tejes Srivastava, Hongyuan Mei, and Chenhao Tan. Hypothesis generation with large language models. arXiv preprint arXiv:2404.04326, 2024.   \n[57] Sarah Schwettmann, Tamar Shaham, Joanna Materzynska, Neil Chowdhury, Shuang Li, Jacob Andreas, David Bau, and Antonio Torralba. Find: A function description benchmark for evaluating interpretability methods. Advances in Neural Information Processing Systems, 36, 2023.   \n[58] Belinda Z Li, Alex Tamkin, Noah Goodman, and Jacob Andreas. Eliciting human preferences with language models. arXiv preprint arXiv:2310.11589, 2023.   \n[59] Wasu Top Piriyakulkij, Volodymyr Kuleshov, and Kevin Ellis. Active preference inference using language models and probabilistic reasoning. In NeurIPS FMDM Workshop, 2023.   \n[60] Gabriel Grand, Valerio Pepe, Jacob Andreas, and Joshua B Tenenbaum. Loose lips sink ships: Asking questions in battleship with language-informed program sampling. arXiv preprint arXiv:2402.19471, 2024.   \n[61] Chinmaya Andukuri, Jan-Philipp Fr\u00e4nken, Tobias Gerstenberg, and Noah D Goodman. Star-gate: Teaching language models to ask clarifying questions. arXiv preprint arXiv:2403.19154, 2024.   \n[62] David Dohan, Winnie Xu, Aitor Lewkowycz, Jacob Austin, David Bieber, Raphael Gontijo Lopes, Yuhuai Wu, Henryk Michalewski, Rif A Saurous, Jascha Sohl-Dickstein, et al. Language model cascades. arXiv preprint arXiv:2207.10342, 2022.   \n[63] Maxwell Nye, Anders Andreassen, Guy Gur-Ari, Henryk Witold Michalewski, Jacob Austin, David Bieber, David Martin Dohan, Aitor Lewkowycz, Maarten Paul Bosma, David Luan, Charles Sutton, and Augustus Odena. Show your work: Scratchpads for intermediate computation with language models, 2021. https://arxiv.org/abs/2112.00114.   \n[64] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824\u201324837, 2022.   \n[65] Antonia Creswell, Murray Shanahan, and Irina Higgins. Selection-inference: Exploiting large language models for interpretable logical reasoning. arXiv preprint arXiv:2205.09712, 2022.   \n[66] Matthew Douglas Hoffman, Du Phan, David Dohan, Sholto Douglas, Tuan Anh Le, Aaron Parisi, Pavel Sountsov, Charles Sutton, Sharad Vikram, and Rif A Saurous. Training chain-of-thought via latent-variable inference. Advances in Neural Information Processing Systems, 36, 2024.   \n[67] Alexander K Lew, Tan Zhi-Xuan, Gabriel Grand, and Vikash K Mansinghka. Sequential monte carlo steering of large language models using probabilistic programs. arXiv preprint arXiv:2306.03081, 2023.   \n[68] Stephen Zhao, Rob Brekelmans, Alireza Makhzani, and Roger Grosse. Probabilistic inference in language models via twisted sequential monte carlo. arXiv preprint arXiv:2404.17546, 2024.   \n[69] Zirui Zhao, Wee Sun Lee, and David Hsu. Large language models as commonsense knowledge for large-scale task planning. arXiv preprint arXiv:2305.14078, 2023.   \n[70] Elizabeth Spelke. What Makes Us Smart? Core Knowledge and Natural Language, pages 277\u2013312. 03 2003.   \n[71] Thomas Samuel Kuhn. The structure of scientific revolutions. 1962. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Appendix ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Contents ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A.1 Proof for the weight update of LLM-SMC-S . 14   \nA.2 Code and data availability . . . . . . . 14   \nA.3 Zendo and ACRE details . . 14   \nA.4 Algorithm details . . . 15   \nA.5 Example hypothesis traces from models 16   \nA.6 Baseline descriptions . . . . . 17   \nA.7 Priors . 18   \nA.8 Computational cost . . 18   \nA.9 Human study on \u2018majority is red\u2019 rule details 18   \nA.10 Prompts . . . . 23   \nA.11 Supplemental results . 23 ", "page_idx": 12}, {"type": "text", "text": "A.1 Proof for the weight update of LLM-SMC-S ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Proposition 1. If $H,W$ input to Procedure LLM-SMC-S is properly weighted with respect to $\\gamma$ , then the output $h^{\\prime},w^{\\prime}$ is properly weighted with respect to $\\gamma^{\\prime}$ . ", "page_idx": 13}, {"type": "text", "text": "Proof. Let $\\begin{array}{r}{Z_{\\pi^{\\prime}}=\\int\\gamma^{\\prime}(h^{\\prime})d h^{\\prime}}\\end{array}$ be the normalizing constant of $\\gamma^{\\prime}$ and $\\begin{array}{r}{\\pi^{\\prime}(h^{\\prime})=\\frac{\\gamma^{\\prime}(h^{\\prime})}{Z_{\\pi^{\\prime}}}}\\end{array}$ \u03b3\u2032Z(h\u2032)be the normalized target. We want to show ", "page_idx": 13}, {"type": "equation", "text": "$$\nE[w^{\\prime}f(h^{\\prime})]=Z_{\\pi^{\\prime}}E_{\\pi^{\\prime}(h^{\\prime})}[f(h^{\\prime})].\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Following arguments similar to [29], we have ", "page_idx": 13}, {"type": "text", "text": "(sub in the definition of $w$ ) (8) as an integral) (9) (sub in the definition of $A$ ) (10) $\\sum$ out of the $\\int)$ (11)   \n(denote the integral as $g(h^{(i)}))$ (12)   \nproper weighting   \nith test function $g$ ) (13) (sub in expression for $g$ ) (14) $Z_{\\pi}=\\gamma/\\pi_{.}^{}$ ) (15) $\\left.\\left(r(h^{\\prime}|h)\\right)$ is normalized) (16) $(Z_{\\pi^{\\prime}}=\\gamma^{\\prime}/\\pi^{\\prime})$ ", "page_idx": 13}, {"type": "text", "text": "$\\begin{array}{r l}{\\lefteqn{(||\\bar{\\mathbf{x}}||^{6}\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ }\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ }\\\\ {=\\ E_{0,m,n,\\delta,\\gamma,\\delta,\\ldots}\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\ \\left\\{\\frac{1}{m+1}|\\psi||^{2}\\hat{H}_{\\sigma;\\sigma;\\gamma+1;\\gamma+1;\\gamma+1;\\gamma+1;\\gamma}\\right\\}}\\\\ &{=E_{0,n}\\,\\Bigg[\\displaystyle\\int_{0}^{1}\\Big(||\\hat{H}_{\\sigma}||^{3}\\,\\psi_{0}^{*}\\Big)\\,\\mathrm{d}|\\psi_{0}^{*}\\Big\\rangle}\\\\ &{=E_{0,n}\\,\\Bigg[\\displaystyle\\sum_{s\\geq0}^{\\infty}\\displaystyle\\sum_{u=1}^{\\infty}\\sum_{\\gamma\\geq0}^{\\infty}\\Big(\\displaystyle\\sum_{\\gamma=1}^{\\infty}\\hat{\\psi}_{0}^{*}\\Big)\\Big(|\\hat{H}_{\\sigma}^{(0)}|\\Big)\\,\\chi_{0}^{\\prime}\\Big\\rangle\\,\\Bigg]}\\\\ &{=\\displaystyle\\frac1{m}\\sum_{s\\geq0}^{\\infty}E_{0,n}\\,,\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad}\\\\ &{=\\displaystyle\\frac1{m}\\sum_{s\\geq0}^{\\infty}E_{0,n}\\,,\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad}\\\\ &{=\\displaystyle\\sum_{s\\geq0}^{\\infty}\\displaystyle\\sum_{u=1}^{\\infty}\\sum_{\\gamma\\geq0}^{\\infty}\\Big(||\\hat{H}_{\\sigma}^{(0)}|\\hat{H}_{\\sigma}^{(0)}|\\Big)}\\\\ &{=2\\,,\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad}\\end{array}$ f(h\u2032) (write $E_{h^{\\prime}\\sim q_{t+1}}$ (pull the (parpoppleyrt yt hwe \u03b3\u2032(h\u2032)r(h|h\u2032)f(h\u2032)dh\u2032dh cancel terms using \u2032(h\u2032)f(h\u2032)dh\u2032 ( = Z\u03c0\u2032E\u03c0\u2032(h\u2032)[f(h\u2032)] = RHS. ", "page_idx": 13}, {"type": "text", "text": "A.2 Code and data availability ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Code and data available at ", "page_idx": 13}, {"type": "text", "text": "https://github.com/topwasu/doing-experiments-and-revising-rules/ ", "page_idx": 13}, {"type": "text", "text": "A.3 Zendo and ACRE details ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Zendo. Zendo is a game where a player seeks to infer a hidden binary rule about assemblies of colored blocks. The game starts by providing the player with a positive scene that follows the hidden rule. Then, the player queries an oracle as to a particular scene follows the rule or not, or makes a guess about the secret rule. The game ends when they guess correctly. ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "Bramley et al. (2018) [13] introduces a 2D version of the Zendo game shown in Figure 3. The scenes consist of blocks, each with its own color (red, blue, green) and size (small, medium, large). The blocks can have different orientations and positions in a 2D scene. They may and may not touch each other. The game starts with an initial phase where a rule-following scene is given, followed by 7 rounds of active learning phase where the player gets to query an oracle for ground truth prediction. At the end, the player enters a prediction phase where they are asked to give predictions for 8 test scenes (4 rule-following and 4 not rule-following). Bramley et al. (2018) study human gameplay on 10 rules, collecting data from 30 participants who each play Zendo 10 times (once per rule). They use a cover story of an alien planet where some arrangements of blocks emit radiation, and the task is to figure out a rule predicting radiation emission. ", "page_idx": 14}, {"type": "text", "text": "Zendo is most naturally framed as a visual-physical concept learning problem. For our model, however, we will work with discrete symbolic descriptions of scenes. This makes that problem more compatible with the language-of-thought paradigm, and also allows using LLMs to operationalize the language of thought. We therefore modify Bramley et al. (2018)\u2019s version of Zendo by associating each block in a scene with discrete attributes instead. The five attributes are color (red, blue, green), size (small, medium, large), orientation (upright, left, right, strange), groundedness (grounded, ungrounded, stacking), and touching (which blocks it touches / stacks). While this natural language version of the game removes continuous attributes, such as $x,y$ position and orientation in 2D space, from its scene representations, these five attributes still maintain the complexity of the game and are sufficient for all 10 Zendo rules.4 ", "page_idx": 14}, {"type": "text", "text": "The data is licensed under CC-BY 4.0. ", "page_idx": 14}, {"type": "text", "text": "ActiveACRE. We convert the originally visual tasks into symbolic version of the tasks, similar to [9]. While the ground truth rule always has the structure that the blicket machine produces noises when one or more \"blicket\" objects (each object is either a blicket or a non-blicket) is placed on the machine, in contrast to [9], we do not hint the learners that the ground truth rule is of this form, which means the learners are free to think that the rule may have to do with colors, number of objects, etc. We further modify the task to incorporate elements of active learning, making the logistics similar to Zendo: the game starts with 8 relevant objects, described with color (gray/red/blue/green/brown/cyan/purple/yellow), material (metal/rubber), and shape attributes (cube/sphere/cylinder), placed on the blicket machine which causes the machine makes sounds and follows by 7 rounds of query. The prediction phase tests the models on all possible combinations of the eight objects. We call this resulting domain, ActiveACRE. Figure 1 partially shows what a gameplay of simplified ActiveACRE looks like. ", "page_idx": 14}, {"type": "text", "text": "To obtain the 8 initial objects, we sample uniformly from the three attributes to get an object and keep doing this until we achieve 8 unique objects. This can be done with a simple code, without external data. ", "page_idx": 14}, {"type": "text", "text": "A.4 Algorithm details ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "For all methods, unless specified, the number of LLM calls used per each iteration is 5 with each call batch-sampling 15 natural language hypotheses. ", "page_idx": 14}, {"type": "text", "text": "Batch Inference. For batch, fuzzy model, we cap the number of unique hypotheses considered to 30, otherwise we would have too many hypotheses considered, since all fuzzy hypotheses have non-zero posterior probability, making inference very compute intensive. ", "page_idx": 14}, {"type": "text", "text": "Batch Inference with Refinement. We set the number of refinement to 2 (we have tried increasing the number of refinement to 4 but didn\u2019t see any improvement). Following [9], this method works as follows: (1) it first batch-samples many hypotheses with LLM, (2) select the best hypothesis (in ", "page_idx": 14}, {"type": "text", "text": "Algorithm 1 LLM-SMC-S algorithm ", "page_idx": 15}, {"type": "text", "text": "Let $(x_{1},y_{1})$ be the first data point we observe   \n$h_{1}^{(1)},...,h_{1}^{(n)}\\sim q(h|x_{1},y_{1})$   \n$\\begin{array}{r}{w_{1}^{(i)}\\leftarrow\\frac{p(x_{1},y_{1},h_{1}^{(i)})}{q(h|x_{1},y_{1})}}\\end{array}$ p(qx(1h,|yx1,,hy(1i) ))for 1 \u2264i \u2264n \u25b7Reweighting   \n$H_{1}\\leftarrow R e s a m p l i n g(H_{1},W_{1})$ \u25b7Resampling   \nfor $t=2,...,T$ do The active learning algorithm gives $\\left({{x}_{t}},{{y}_{t}}\\right)$ $\\begin{array}{r l}&{h_{t}^{(1)},...,h_{t}^{(n)}\\sim q(h|H_{t-1},x_{1:t},y_{1:t})}\\\\ &{A(h_{t}^{(i)},H_{t-1},W_{t-1})=\\frac{1}{n}\\sum_{j=1}^{n}w_{t-1}^{(j)}\\frac{p(h_{t}^{(i)}|x_{1:t},y_{1:t})r(h_{t-1}^{(j)}|h_{t}^{(i)},x_{1:t},y_{1:t})}{p(h_{t}^{(j)}|x_{1:t-1},y_{1:t-1})}}\\\\ &{w_{t}^{(i)}\\leftarrow\\frac{A(h_{t}^{(i)},H_{t-1},W_{t-1})}{q(h_{t}^{(i)}|H_{t-1},x_{1:t},y_{1:t})}\\;\\mathrm{for}\\;1\\leq i\\leq n}\\\\ &{\\underline{{H}}_{\\mathfrak{t}}\\leftarrow R e s a m p l i n g(H_{t},W_{t})}\\end{array}$ \u25b7Rejuvenating \u25b7Reweighting \u25b7Resampling   \nend for ", "page_idx": 15}, {"type": "text", "text": "Algorithm 2 B function pseudocode ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "function $\\mathbf{B}(x_{1:t},y_{1:t},H)$ $r e s u l t=\\emptyset$ $h_{1},...,h_{k}=\\mathfrak{t}$ p-k-lowest-likelihood $(H,x_{1:t},y_{1:t})\\ \\triangleright\\ g e t\\ k$ $k$ hypotheses with lowest likelihood for $i=1,...,k$ do $H_{n b}=L L M(x_{t},y_{t},h_{i})$ $\\triangleright$ get neighbors (nb) of $h_{i}$ Hnb = $\\{h_{n b}\\in H_{n b}\\mid p(h_{n b}|x_{1:t},y_{1:t})\\leq p(h_{i}|x_{1:t},y_{1:t})\\}$ $\\triangleright$ filter out bad neighbors if $|H_{n b}|>\\mathrm{m}$ then $\\triangleright$ we want to consider a maximum of $m$ neighbors $w_{n b}^{(i)}\\leftarrow p(h_{n b}^{(i)}|x_{1:t},y_{1:t})$ h(nib)|x1:t, y1:t) for 1 \u2264i \u2264n $\\Ddot{H_{n b}}\\gets D\\sigma\\overset{\\cdots}{w n}-S a m p l i n g(H_{n b},p=W_{n b},s i z e=m)$ end if $r e s u l t=r e s u l t\\cup H_{n b}$ end for return result   \nend function ", "page_idx": 15}, {"type": "text", "text": "numbers of data points accounted) to be refined, (3) use LLM to output a batch of refined hypotheses, and (4) repeat the (2)-(3) steps until at least one hypothesis fully accounts for all data points. ", "page_idx": 15}, {"type": "text", "text": "Online Inference (LLM-SMC-S) The algorithm for LLM-SMC-S is described in Algorithm 1. For the first iteration, the initial important proposer $q(h|x_{1},y_{1})$ is defined to be an LLM, similar to batch inference. We define the forward kernel $q$ in the algorithm as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\nq(h|H,x_{1:t},y_{1:t})\\propto\\mathbf{1}[h\\in(H\\cup B(x_{1:t},y_{1:t},H))]\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The pseudocode for $B$ can be founded at Algorithm 2. What $B$ is doing is basically look at low likelihood hypotheses, prompt LLM to come up with their neighbors, and filter out bad neighbors and limit the number of chosen neighbors to $m$ . We find that having the down-sampling step to keep the number of neighbors considered low is helpful in practice, but one can remove this step to make $B$ fully deterministic. The LLM function in the pseudocode means prompting an LLM with zero temperature. ", "page_idx": 15}, {"type": "text", "text": "A.5 Example hypothesis traces from models ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Batch. \u2019Blocks must touch at least one other block\u2019 is proposed but is immediately falsified by an existing experiment where a scene with no blocks touching is negative. ", "page_idx": 15}, {"type": "text", "text": "Batch with refinement. \u2018Blue blocks must not touch green blocks\u2019 is proposed and then refined into \u2018Blue blocks must not touch blocks of any color other than red\u2019. This hypothesis later gets falsified, without an opportunity to refine itself since the model is not online, when a scene with no blocks touching is negative. ", "page_idx": 15}, {"type": "image", "img_path": "HXdAfK488A/tmp/4e011d6b808b806b106a45e3a7283fd0966d09f5aed773a41771d0c789121cf4.jpg", "img_caption": ["Figure 8: Human vs online, fuzzy model accuracy binned by 4 rule-following (RF) and 4 not rulefollowing (Not RF) test scenes. This figure shows online, fuzzy model with same and different priors for $\\epsilon$ and $\\delta$ "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "Online. \u2018There must be a blue block\u2019 is proposed and added to the pool of particles. Since it has higher prior than other particles (has shorter length); it keeps surviving while others get killed, despite some conforming with the data. Upon seeing a scene with a blue touching a green being negative, the particle \u2018There must be a blue block\u2019 is perturbed into \u2018there must be a blue block touching a red block\u2019. ", "page_idx": 16}, {"type": "text", "text": "A.6 Baseline descriptions ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "sampling $\\begin{array}{r}{p(h|x_{1:t},y_{1:t})=E_{p(h^{\\prime}|x_{1:t},y_{1:t})}[1[h=h^{\\prime}]]=E_{q(h^{\\prime}|x_{1:t},y_{1:t})}[\\frac{p(h^{\\prime}|x_{1:t},y_{1:t})}{q(h^{\\prime}|x_{1:t},y_{1:t})}1[h=\\bar{h^{\\prime}}]].}\\end{array}$ ", "page_idx": 16}, {"type": "text", "text": "The difference in the two baselines lie in how $q(h^{\\prime}|x_{1:t},y_{1:t})$ is constructed. ", "page_idx": 16}, {"type": "text", "text": "Batch. $q(h|x_{1:t},y_{1:t})=U(L L M(x_{1:t},y_{1:t}))$ where $L L M(...)$ prompts an LLM to return a list of hypotheses ", "page_idx": 16}, {"type": "text", "text": "Batch with refinement. $\\begin{array}{r l r}{q(h|x_{1:t},y_{1:t})}&{=}&{U(R e f i n e d{-}L L M(x_{1:t},y_{1:t},N o n e,0))}\\end{array}$ where Refined-LLM is defined as follows: ", "page_idx": 16}, {"type": "text", "text": "First, let $\\begin{array}{r}{s(h,x_{1:t},y_{1:t})=\\frac{1}{t}\\sum_{i=1}^{t}\\mathbb{1}[h(x_{i})=y_{i}]}\\end{array}$ . This simply scores what percentage of data points in $x_{1:t},y_{1:t}$ that $h$ makes correct predictions. Then, ", "page_idx": 16}, {"type": "text", "text": "unction Refined- : $H=L L M$ -with- $h(x_{1:t},y_{1:t},h)$ # Prompts LLM to refine h if $k=K$ : return $\\varnothing$ else if $\\exists h^{\\prime}\\in H,s(h^{\\prime},x_{1:t},y_{1:t})=1$ : $\\mathrm{return}\\;h^{\\prime}\\in H|s(h^{\\prime},x_{1:t},y_{1:t})=1$ else: $\\begin{array}{r l}&{{h^{*}}=a r g m a x_{h^{\\prime}\\in H}\\big(s(h^{\\prime},{x_{1:t}},{y_{1:t}})\\big)}\\\\ &{\\mathrm{return~}R e f i n e d-L L M(x_{1:t},{y_{1:t}},{h^{*}},k+1)}\\end{array}$ ", "page_idx": 16}, {"type": "text", "text": "where $K$ is the number of refinements allowed. ", "page_idx": 16}, {"type": "table", "img_path": "HXdAfK488A/tmp/bf80bcadece707de115b5417ee6a410f9f423f7f8eb4909ebf84178477741092.jpg", "table_caption": [], "table_footnote": ["Table 5: Average predictive posterior (standard error computed over 5 seeds) of models with different number of LLM calls (each LLM batch-samples 15 hypotheses) on Zendo. "], "page_idx": 17}, {"type": "text", "text": "A.7 Priors ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Priors for $\\epsilon$ and $\\delta$ $p(\\delta)$ has a mean of 0.7 and a standard deviation of 0.1, and $p(\\epsilon)$ has a mean of 0.9 and a standard deviation of 0.01. Both distributions are truncated to remain within the range [0.5, 1]. We found that using different priors for $\\epsilon$ and $\\delta$ results in a more human-like behavior as shown in Figure 8. ", "page_idx": 17}, {"type": "text", "text": "Prior for $h$ We let $p(h)$ be inversely proportional to the word count of $h$ for Zendo and uniform for ActiveACRE. ", "page_idx": 17}, {"type": "text", "text": "For Zendo, we consider using a prior that would decay exponentially in length but find that letting $\\begin{array}{r}{p(h)\\propto(\\frac{1}{w o r d_{-}c o u n t(h)})^{2}}\\end{array}$ already makes the particles become mostly short strings. A prior decaying exponentially in string length would definitely be too harsh on the hypotheses. ", "page_idx": 17}, {"type": "text", "text": "A.8 Computational cost ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Computational Cost Analysis Table 5 shows the performance of models with different compute budgets (number of LLM calls per iteration) on Zendo. It turns out that the performance of batch inference models plateaus after just 15 hypotheses (1 LLM call), while the performance of online inference models benefits from being able to sample more hypotheses but also plateaus after 75 hypotheses (5 LLM calls). ", "page_idx": 17}, {"type": "text", "text": "Experiments Compute Resources We also describe here the compute resources required to reproduce the experiments. The main compute cost comes from OpenAI API which we call to prompt GPTs. The models with 1, 5, 10 LLM calls per each iteration uses up roughly $\\mathbb{S}0.5$ , $\\mathbb{S}1.5$ , $\\mathbb{S}3$ OpenAI API credit to run a Zendo task. For Zendo, one needs to run 50 tasks\u201410 Zendo tasks on 5 different seeds\u2014to get the performance numbers of a method like we reported. The actual cost, however, could be lower than calculated since one can cache LLM responses. ", "page_idx": 17}, {"type": "text", "text": "A.9 Human study on \u2018majority is red\u2019 rule details ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "20 participants from our academic department were recruited via Slack to attempt the rule \"the majority of blocks are red\". The participants are compensated $\\mathbb{S}10{-}\\mathbb{S}20$ depending on their performance (\\$10 base rate $+\\,\\mathbb{S}1.25$ bonus for each correct test scence prediction \u2013 there are 8 test scenes). Figure 9 shows the web interface displayed to participants. The full instructions given to human participants are displayed at Figures 12 and 13. ", "page_idx": 17}, {"type": "text", "text": "Special blocks 1 of 2 ", "text_level": 1, "page_idx": 18}, {"type": "image", "img_path": "HXdAfK488A/tmp/ee8ef336387275e4dd486a4bfa2bff98af07f3d3e3a60d3c518c76967cb17829.jpg", "img_caption": [], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Now you play with the bemmies. Press buttons at the bottom to add blocks. \u00b7 Move the blocks around by picking them up with the mouse (left clicking and holding) ", "page_idx": 18}, {"type": "text", "text": "\u00b7 Turn them using the $\"Z\"$ (counterclockwise) and \"x\" (clockwise) keys   \n\u00b7 Right click on them to remove them (command $^+$ click if you are using mac trackpad).   \nWhen you're done moving the special blocks, click \"Test\" to see if stars will come out ", "page_idx": 18}, {"type": "image", "img_path": "HXdAfK488A/tmp/93b3a4ccaabfd1e6630c73f03f2c05035e29021d2fe097470f2efd9a47d7e4d2.jpg", "img_caption": ["Figure 9: Example of the web interface shown to participants. ", "Figure 10: First figure for human participants instructions shown at Figure 12 "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "1. These special blocks are called Blickets. Stars come out of them if there is at least one small block ", "page_idx": 19}, {"type": "image", "img_path": "HXdAfK488A/tmp/1f6a9b25251f106f509cf0cbe7b3be6015b5f7ba3f1524263f11ac696bacbb5d.jpg", "img_caption": [], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "2. These special blocks are called Wozzles. Stars come out of them if the blocks are all the same color ", "page_idx": 19}, {"type": "image", "img_path": "HXdAfK488A/tmp/dbe70c10a6f59ce039c2eccfdf2af8fcb0b91e5fd54c4e9d78a3e4d4b3ff7400.jpg", "img_caption": [], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "3. These special blocks are called Daxes. Stars come out of them if none of the blocks are touching ", "page_idx": 19}, {"type": "image", "img_path": "HXdAfK488A/tmp/052d80e9de8cfc0278dfe2d119eb8e2a834fb6a9acf942ca0237bc83a14a7361.jpg", "img_caption": [], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "4. These special blocks are called Timas. Stars come out of them if all the blocks point in the same direction ", "page_idx": 19}, {"type": "image", "img_path": "HXdAfK488A/tmp/2f8b621efa49f8e191f308e65954bfc016609bc6295a0a6e4bf353f890aae69c.jpg", "img_caption": ["Figure 11: Second figure for human participants instructions shown at Figure 12 "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "Thank you for playing my game! ", "page_idx": 20}, {"type": "text", "text": "In this game you will be learning about an alien planet. This planet is called Zorb. ", "page_idx": 20}, {"type": "text", "text": "On Zorb, there are these special blocks that look like this: ", "page_idx": 20}, {"type": "text", "text": "{Figure 9} ", "page_idx": 20}, {"type": "text", "text": "These special blocks may look the same, but there are many different kinds of special blocks on the planet Zorb. They all have different names, and they all work differently. ", "page_idx": 20}, {"type": "text", "text": "Sometimes, when the blocks are set up in certain ways, stars will shoot out of them! Every kind of special block has a different rule for making stars shoot out of them. ", "page_idx": 20}, {"type": "text", "text": "Your job is to figure out each rule for how to make stars come out of all of the different kinds of special blocks! ", "page_idx": 20}, {"type": "text", "text": "{Figure 10} ", "page_idx": 20}, {"type": "text", "text": "So there are a lot of things that might make stars come out of certain special blocks! ", "page_idx": 20}, {"type": "text", "text": "You might get stars from blocks of different numbers, from blocks of different colors, from blocks of different sizes, from blocks facing different directions, and more! ", "page_idx": 20}, {"type": "text", "text": "We found out that there are 2 more kinds of special blocks on Zorb! Let\u2019s call them \u2019Bemmies\u2019 and \u2019Yoks\u2019. Again, you do not have to memorize the names -- we just want to emphasize that different kinds of blocks work under different rules ", "page_idx": 20}, {"type": "text", "text": "But we don\u2019t know the rule for setting up each kind of special blocks so stars will come out of them. Your job is to figure out the two different rules for how to set up each different kind of special blocks so stars come out! ", "page_idx": 20}, {"type": "text", "text": "Now we\u2019re going to watch a video. This video is going to show you how you can move the special blocks around yourself!   \nYou must watch the video to continue. ", "page_idx": 20}, {"type": "text", "text": "So, in the interface you can: ", "page_idx": 20}, {"type": "text", "text": "Press buttons at the bottom to add blocks ", "page_idx": 20}, {"type": "text", "text": "Move the blocks around by picking them up with the mouse (left clicking and holding) ", "page_idx": 20}, {"type": "text", "text": "Turn them using the \"Z\" (counterclockwise) and \"X\" (clockwise) keys Right click on them to remove them (command $^+$ click if you are using mac trackpad) ", "page_idx": 20}, {"type": "text", "text": "When you\u2019re done moving the special blocks, you\u2019re going to test them to see if stars will come out of them. If you set them up in the right way according to the rule, you\u2019ll see a bunch of stars appear! Otherwise, nothing will happen. ", "page_idx": 20}, {"type": "text", "text": "Figure 12: (Part 1) Instructions for participants. Please find instruction figure 1 and 2 at Figures 10   \nand 11 ", "page_idx": 20}, {"type": "text", "text": "After you move the special blocks around and test them, you\u2019re going to see if you can pick out which pictures of the blocks you think will shoot out stars. This video will show you how to do that: ", "page_idx": 21}, {"type": "text", "text": "{demo video} ", "page_idx": 21}, {"type": "text", "text": "In the video you can see that this participant thinks that four of the pictures show bemmies that stars will come out of (the ones marked in grey). The right answer could be anywhere between one and seven of the pictures. ", "page_idx": 21}, {"type": "text", "text": "Adults: You will earn a bonus of $\\Phi\\boldsymbol{1}\\cdot25$ for each of the pictures in the main task where you guess correctly whether it will shoot out stars (demo task performance does not count). That means, if you get all eight pictures correct in the main task, you will earn a bonus of $\\mathfrak{P}10!$ ! ", "page_idx": 21}, {"type": "text", "text": "You must watch the video to continue. ", "page_idx": 21}, {"type": "text", "text": "{demo video} ", "page_idx": 21}, {"type": "text", "text": "Finally, you may guess the rule for how this kind of special blocks works. ", "page_idx": 21}, {"type": "text", "text": "For example, if it looks like stars only shoot out of the blocks if all of them are green, you would write something like: \"all the blocks have to be green\"! ", "page_idx": 21}, {"type": "text", "text": "Warning: Your responses will be checked by a human before HIT approval. Nonsensical or copy-pasted answers will lead to your HIT being rejected. If you truly have no ideas about a rule, please just write \"I do not know\". ", "page_idx": 21}, {"type": "text", "text": "Instructions Summary: ", "page_idx": 21}, {"type": "text", "text": "You will look at 2 different kinds of special blocks (including one demo task for learning the game) that will shoot out stars if they are set up in certain ways. ", "page_idx": 21}, {"type": "text", "text": "You must figure out the rule for how each kind of special blocks works. ", "page_idx": 21}, {"type": "text", "text": "You will set up the special blocks and test them to see if stars will shoot out of them seven times for each type. ", "page_idx": 21}, {"type": "text", "text": "Your goal is to figure out which out of 8 new pictures of each kind of special blocks will shoot out stars $.\\Phi1.25$ bonus for each correct in the main task)... ", "page_idx": 21}, {"type": "text", "text": "...and to write down your best guess of the rule for that kind of special block! Figure 13: (Part 2) Instructions for participants. ", "page_idx": 21}, {"type": "text", "text": "A.10 Prompts ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The prompts used in all of our experiments can be found in Tables 7 to 12. ", "page_idx": 22}, {"type": "text", "text": "For Zendo, we engineer the prompts for initial importance sampler $q(h|x,y)$ for online inference so that they only output simple rules (see Table 7); this approach helps the proposer output hypotheses with higher priors, since our prior is defined by the number of words in the rule. We cannot apply this trick to batch inference because, unlike online inference, it does not evolve simpler rules into more complex ones. Additionally, we also design the importance sampler prompts to avoid proposing negative rules (\u2018there is no ...\u2019) (see Table 7). We found that this leads to a more human-like behavior and also better performance. ", "page_idx": 22}, {"type": "text", "text": "A.11 Supplemental results ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "See Table 6 and figs. 14 and 15 ", "page_idx": 22}, {"type": "table", "img_path": "HXdAfK488A/tmp/cee4bf8c9b21ebbc09feafc26b2e8a21d38982dbc57fa4400171d0ac6d125979.jpg", "table_caption": ["Table 6: BIC scores of models on human data. "], "table_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "HXdAfK488A/tmp/3216506eb1ecb28c8ec27d88f214476c8e93810802c01cd6d5082e8b2c78642b.jpg", "img_caption": ["Figure 14: Comparing human and model prediction on each test scene after 7 rounds of experimentation. Each point is a prediction on a test scene. "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "HXdAfK488A/tmp/44f44f3ce553a111065cef3819ac4cf1a0991ed7e99c55fce488b560e18b3771.jpg", "img_caption": ["Figure 15: Human vs online, fuzzy model accuracy binned by 4 rule-following (RF) and 4 not rulefollowing (Not RF) test scenes. This figure shows online, fuzzy model with three different active learning methods: LLM, Random, and InfoGain "], "img_footnote": [], "page_idx": 23}, {"type": "table", "img_path": "HXdAfK488A/tmp/032bc5bc99e9fc7054de2cb9f5876750236b8996190ab5ef768bb38eb9a2ada6.jpg", "table_caption": [], "table_footnote": ["Table 7: Prompts used for the importance sampler $q(h|x_{1},y_{1})$ of all methods "], "page_idx": 24}, {"type": "text", "text": "A structure has one or more blocks. Each block should contain the   \nfollowing attributes:   \n{att_par} Example of rule modifications:   \nQuantifier change: \u2019There must be a green block\u2019 -> \u2019There are two green blocks\u2019   \nAdditional attribute: \u2019There must be a green block\u2019 -> \u2019There must be a green block that is upright\u2019   \nAttribute change: \u2019There must be a green block\u2019 -> \u2019There must be a blue block\u2019   \nThese modifications are \"local\": only one attribute/quantifier is changed or added for each modification. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "Please modify the rule \u2019{h}\u2019. Generate {num} rules for each type of modification (Quantifier change, Additional attribute, Attribute change) so that the following structure is {text_y} a good structure: ", "page_idx": 25}, {"type": "text", "text": "Note that the number of the blocks do not matter. ", "page_idx": 25}, {"type": "text", "text": "Make the format a numbered list (1., 2., ..., 15.) Remember that the new rules should be a \"local\" modification from the rule \u2019{h}\u2019. Do not use attribute values that are not mentioned earlier. Do not say anything other than the modified rules. ", "page_idx": 25}, {"type": "text", "text": "An object contains the following attributes: color (gray/red/blue/green/\\ brown/cyan/purple/yellow) material (metal/rubber) shape(cube/sphere/cylinder) ", "page_idx": 25}, {"type": "text", "text": "Example of rule modifications:   \nAdditional conjunction: \u2019The light turns on when there is a cylinder   \npresent\u2019 -> \u2019The light turns on   \nwhen there is a cylinder and a cube present\u2019   \nAdditional disjunction: \u2019The light turns on when there is a cylinder   \npresent\u2019 -> \u2019The light turns on   \nwhen there is a cylinder or a cube present\u2019   \nAdditional attribute: \u2019The light   \nturns on when there is a cylinder   \npresent\u2019 -> \u2019The light turns on when there is a blue cylinder present\u2019   \nThese modifications are \"local\": only one disjunction/conjunction/attribute is changed or added for each   \nmodification. Please modify the rule \u2019{h}\u2019.   \nGenerate {num} rules for each type of modification (Additional conjunction, Additional disjunction, Additional attribute) so that the light does   \n{text_y} turn on when the following objects are present:   \n{x}   \nNote that the number of the blocks do not matter. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "Make the format a numbered list (1., 2., ..., 15.) Remember that the new rules should be a \"local\" modification from the rule \u2019{h}\u2019. Do not use attribute values that are not mentioned earlier. Do not say anything other than the modified rules. ", "page_idx": 25}, {"type": "text", "text": "Table 8: Prompts used for the forward kernel $q(h^{\\prime}|H_{t},x_{1:t},y_{1:t})$ of online inference methods ", "page_idx": 25}, {"type": "table", "img_path": "HXdAfK488A/tmp/c4d7a5451e8edb23ed100995acf24113d8422158bca502a55178620a4f5df560.jpg", "table_caption": [], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "Table 9: Prompts used for experiment proposers. ", "page_idx": 26}, {"type": "image", "img_path": "HXdAfK488A/tmp/cc1952fb45bcad4f5f1e41e0ab44ee9f132a80fd6938413d0a7871a17c86e649.jpg", "img_caption": [], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "Table 10: Prompts used to translate natural language $h$ to code. ", "page_idx": 27}, {"type": "table", "img_path": "HXdAfK488A/tmp/0ddebbfd90fda2bbc27964727a89f2ef57d3632aed9de2cc9530f7bcf74e9380.jpg", "table_caption": [], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "Table 11: Prompts used to perform refinement in batch inference with refinement ", "page_idx": 28}, {"type": "table", "img_path": "HXdAfK488A/tmp/9413a5a8a3fcaa31d9596ab92a308a482bb9eae3048709898105bc74751ba464.jpg", "table_caption": ["Table 12: Prompts used for vanilla, direct LLM method "], "table_footnote": [], "page_idx": 29}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: The claims we made in abstract and introduction accurately reflect the paper\u2019s contributions and scope. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 30}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: The last section discusses limitations. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 30}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We provide the formal proof of our proposition in the appendix. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 31}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Justification: We have fully described the algorithms used in the paper, with details included in the appendix. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 31}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: Code and data available at https://github.com/topwasu/ doing-experiments-and-revising-rules/ ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 32}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: Algorithm details are described in the appendix. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 32}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: The paper reports error bars \u2013 most of them computed over 5 seeds. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: We have provided estimated OpenAI API cost for our experiments. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 33}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: The research conducted in the paper conforms, in every aspect, with the NeurIPS Code of Ethics. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 33}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: Our work is foundational research and has no direct societal impact. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 34}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: The creators of original data are all properly credited, and the license and terms of use of the data are explicitly mentioned and properly respected. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 34}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 35}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: The code and data introduced in the paper is well documented. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 35}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: We have described our human study in details in the appendix ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 35}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Justification: We did not anticipate any risks from participating in our study. IRB approval was obtained. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 35}]