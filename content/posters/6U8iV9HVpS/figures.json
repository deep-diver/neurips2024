[{"figure_path": "6U8iV9HVpS/figures/figures_8_1.jpg", "caption": "Figure 1: Regret results on real data sets. (Left three figures: For MovieLens and Amazon, corrupt the chosen arm reward with 20% probability. For MNIST, consider C = 2000 and randomly sample 2000 rounds for attack); (Right three figures: For MovieLens and Amazon: we corrupt reward with 50% probability; For MNIST: C = 4000 and randomly sample 4000 corrupted rounds).", "description": "This figure displays the cumulative regret of different contextual bandit algorithms on three real-world datasets (MovieLens, Amazon, MNIST) under different adversarial corruption scenarios.  The left three subfigures show the results when 20% of chosen arm rewards are corrupted (with a specific corruption strategy for MNIST), while the right three subfigures show results when 50% of chosen arm rewards are corrupted.  The algorithms compared include linear baselines (LinUCB, CW-OFUL), traditional neural approaches (Neural-UCB, Neural-TS), and the authors' proposed methods (NeuralUCB-WGD, R-NeuralUCB). The figure demonstrates the performance of different algorithms against adversarial corruptions on various datasets and corruption levels.  Error bars might be shown indicating variability in the experiments.", "section": "Experiments"}, {"figure_path": "6U8iV9HVpS/figures/figures_19_1.jpg", "caption": "Figure 1: Regret results on real data sets. (Left three figures: For MovieLens and Amazon, corrupt the chosen arm reward with 20% probability. For MNIST, consider C = 2000 and randomly sample 2000 rounds for attack); (Right three figures: For MovieLens and Amazon: we corrupt reward with 50% probability; For MNIST: C = 4000 and randomly sample 4000 corrupted rounds).", "description": "This figure compares the cumulative regret of different contextual bandit algorithms on three real-world datasets (MovieLens, Amazon, MNIST) under two different levels of adversarial reward corruption (20% and 50%).  The left three subfigures show the results with 20% corruption, while the right three show the results with 50% corruption.  The MNIST experiments involve a different corruption approach where a certain number of randomly chosen rounds are corrupted.", "section": "Experiments"}]