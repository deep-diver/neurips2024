[{"figure_path": "yRRCH1OsGW/tables/tables_4_1.jpg", "caption": "Table 1: Conditional generation settings. g: roto-translations, \u03c4: torsions, A: residue identities M: upsampling factor. Superscripts indicate residue index and subscripts indicate frame (time) index. For inpainting, we find that excluding identities and torsions reduces overfitting.", "description": "This table details the different conditional generation settings used in the MDGEN model. It specifies the key frames used as conditioning input, the parts of the trajectory that the model generates, other conditioning information, and the dimensionality of the tokens used for each task (forward simulation, interpolation, upsampling, and inpainting).  Note that for inpainting, excluding residue identities and torsions improves performance, reducing overfitting.", "section": "3 Method"}, {"figure_path": "yRRCH1OsGW/tables/tables_5_1.jpg", "caption": "Table 2: JSD between sampled and ground-truth distributions, with replicate simulations as baselines. 100 ns represents oracle performance.", "description": "This table presents the Jensen-Shannon Divergence (JSD) values between the generated trajectories by the model and the ground truth MD trajectories.  It compares the JSD across various collective variables (torsion angles and TICA components) and different lengths of MD simulations (100 ps, 1 ns, 10 ns, and 100 ns), offering a benchmark against oracle performance (100 ns MD simulation). Lower JSD values indicate higher similarity between the generated and ground-truth trajectories.", "section": "4 Experiments"}, {"figure_path": "yRRCH1OsGW/tables/tables_7_1.jpg", "caption": "Table 1: Conditional generation settings. g: roto-translations, \u03c4: torsions, A: residue identities M: upsampling factor. Superscripts indicate residue index and subscripts indicate frame (time) index. For inpainting, we find that excluding identities and torsions reduces overfitting.", "description": "This table details the different conditional generation settings used in the paper's experiments.  It specifies the key frames used for conditioning (the initial frame, or both the initial and final frames), what parts of the trajectory are generated by the model, and what information is provided as input (roto-translations, torsions, amino acid identities).  The table also notes the dimensionality of the tokens used in each setting.  The inpainting setting is distinct, as it excludes residue identities and torsions to reduce overfitting.", "section": "3 Method"}, {"figure_path": "yRRCH1OsGW/tables/tables_8_1.jpg", "caption": "Table 4: Median results on test protein ensembles (n = 82); evaluations from Jing et al. (2024). Runtimes are reported per sample structure or frame.", "description": "This table compares the performance of MDGEN against two other methods, AlphaFlow and MSA subsampling, for protein structure prediction.  Several metrics are used to assess the quality of the generated protein structures, including pairwise and global RMSD (root mean square deviation), the distribution of distances between the generated and reference structures, and the similarity of the generated structures to those from molecular dynamics (MD) simulations.  The runtime per sample structure is also provided, highlighting the computational efficiency of MDGEN compared to AlphaFlow and MSA subsampling.", "section": "4 Experiments"}, {"figure_path": "yRRCH1OsGW/tables/tables_23_1.jpg", "caption": "Table 1: Conditional generation settings. g: roto-translations, \u03c4: torsions, A: residue identities M: upsampling factor. Superscripts indicate residue index and subscripts indicate frame (time) index. For inpainting, we find that excluding identities and torsions reduces overfitting.", "description": "This table details the different conditional generation settings used in the paper's experiments.  It specifies the key frames used for conditioning (the initial frame, or both the initial and final frames), what data is generated by the model, what data is provided as input to condition the model, and the resulting dimensionality of the input tokens.  The tasks covered are forward simulation, interpolation, upsampling, and inpainting.  For the inpainting task, it's noted that excluding residue identities and torsion angles from the conditioning improved model performance.", "section": "3 Method"}, {"figure_path": "yRRCH1OsGW/tables/tables_23_2.jpg", "caption": "Table 5: Comparison of MDGEN, Timewarp, and ITO in terms of the JSD between sampled and ground-truth distributions along various collective variables in the forward simulation setting.", "description": "This table compares the performance of MDGEN against two other methods, Timewarp and ITO, in terms of the Jensen-Shannon Divergence (JSD) between the sampled and ground truth distributions. The comparison is done along various collective variables in the forward simulation setting. The collective variables include backbone torsions, sidechain torsions, all torsions, TICA-0, TICA-0,1 joint, and MSM states. The runtime for each method is also provided.", "section": "C.6 Additional Comparisons"}]