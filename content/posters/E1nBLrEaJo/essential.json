{"importance": "This paper is crucial for researchers in private AI, particularly those working on federated learning and transfer learning.  It **directly addresses the limitations of prior work** that only considers in-distribution tasks, offering a novel theoretical model and empirical evidence for improving private training under realistic distribution shifts. This opens up **new avenues for building more robust and practical privacy-preserving AI systems** that can leverage publicly available data while safeguarding sensitive information.", "summary": "Public data boosts private AI accuracy even with extreme distribution shifts, improving private model training by up to 67% in three tasks.  This is due to shared low-dimensional representations between public and private data.", "takeaways": ["Public pre-training improves private AI model accuracy even under significant distribution shifts.", "Private linear probing consistently outperforms private finetuning when using public features.", "A theoretical model explains how shared low-dimensional representations enable public data to improve private learning's sample complexity."], "tldr": "Many studies show that using public data for pre-training improves differentially private model training. However, most of these studies focus on in-distribution tasks and do not address settings where there is distribution shift between pre-training and fine-tuning data. This is a major limitation because in real world scenarios private data is often fundamentally different from the public datasets. This paper addresses this limitation by conducting empirical studies on three tasks, and shows that public features can significantly improve the accuracy of private training even in the presence of large distribution shift. This improvement is not just observed empirically, but it is also theoretically explained in the paper through a stylized theoretical model.\nThe paper proposes a two-stage algorithm that first estimates the shared, low-dimensional representation from public data using a method of moments estimator, and then performs private linear regression within the learned subspace using the private data. By leveraging dimensionality reduction, the algorithm achieves better sample complexity. The paper also provides a novel lower bound that demonstrates the optimality of their approach among algorithms that estimate the transfer parameters within the same low-dimensional subspace. The findings show that pre-trained features can improve private learning, even under extreme distribution shift, and that linear probing consistently outperforms private finetuning.", "affiliation": "Carnegie Mellon University", "categories": {"main_category": "AI Theory", "sub_category": "Privacy"}, "podcast_path": "E1nBLrEaJo/podcast.wav"}