[{"figure_path": "7b2DrIBGZz/figures/figures_0_1.jpg", "caption": "Figure 1: High-resolution (1024px) samples from our LI-DiT-10B, showcasing its capabilities in complex prompt comprehension, precise prompt following, and high image quality across various styles and resolutions. Please refer to the appendix for the prompts.", "description": "This figure displays a selection of high-resolution images (1024 pixels) generated by the LI-DiT-10B model.  The images demonstrate the model's ability to understand and accurately follow complex and diverse prompts, producing high-quality results across a range of artistic styles and image resolutions. The specific prompts used to generate each image can be found in the appendix of the paper.", "section": "Abstract"}, {"figure_path": "7b2DrIBGZz/figures/figures_2_1.jpg", "caption": "Figure 2: Comparisons of our model, LLAMA series, and T5 series on image generation and text understanding benchmarks.", "description": "This figure compares the performance of the proposed LI-DiT model against several LLMs (LLaMA series) and encoder-decoder models (T5 series) across two benchmark datasets: image generation (T2I-CompBench) and text understanding (MMLU).  The results illustrate that while larger LLMs such as LLaMA3-8B show superior text understanding, they do not directly translate to better image generation performance.  The figure highlights the gap between raw LLM performance and effective prompt encoding within a diffusion model and motivates the need for a novel framework, such as the one proposed by the authors, to better leverage the power of LLMs in image generation. The performance of LI-DiT models (infused with different LLMs) is shown in relation to the base LLMs and T5 models, showcasing the improvement achieved by the proposed architecture.", "section": "1 Introduction"}, {"figure_path": "7b2DrIBGZz/figures/figures_2_2.jpg", "caption": "Figure 3: Performance discrepancy between former and latter adj-noun compositions in LLaMA3-8B and T5-XXL.", "description": "This figure shows the performance discrepancy between the former and latter adjective-noun compositions in the LLaMA3-8B and T5-XXL models.  It highlights the positional bias in decoder-only LLMs like LLaMA3-8B, where information in the latter part of a prompt is less effectively processed for image generation compared to encoder-decoder models such as T5-XXL. The x-axis represents the relative position of the adj-noun composition within the prompt, and the y-axis represents the performance score. The figure visually demonstrates that the LLaMA3-8B model struggles to capture information from the latter part of the prompt, whereas the T5-XXL model maintains consistent performance regardless of position.", "section": "2 Prompt Encoding with Language Models"}, {"figure_path": "7b2DrIBGZz/figures/figures_3_1.jpg", "caption": "Figure 4: The output of language models when feeding a prompt. We can observe that pre-trained LLaMA3-8B provides an unrelated expansion, and T5-XXL repeats the input prompt. LLaMA3-8B with multi-modal fine-tuning can provide detailed information based on human instruction.", "description": "This figure demonstrates the difference in prompt encoding between different language models.  When given a simple prompt (\"a blue backpack and a red orange\"), T5-XXL simply repeats the prompt, showing a lack of understanding or generation capabilities. LLaMA3-8B generates an unrelated response, highlighting its tendency to focus on predicting the next token rather than representing the input's meaning. However, when the same LLaMA3-8B model is fine-tuned with multimodal data and given an instruction to describe the image in detail, it produces a much more relevant and informative response.  This highlights the effectiveness of multimodal fine-tuning and explicit instruction guidance in improving the capabilities of LLMs for prompt encoding in image generation tasks.", "section": "2 Prompt Encoding with Language Models"}, {"figure_path": "7b2DrIBGZz/figures/figures_4_1.jpg", "caption": "Figure 5: The pipeline of LLM-infused diffuser. First, the LLM-infused diffuser inserts an instruction to encourage LLMs to focus on image-related concepts. The linguistic token refiner eliminates the positional bias of LLM representations. Then the collaborative refiner further refines and mixes these embeddings and provides a more robust text representation. We only show 2 LLMs for simplicity.", "description": "This figure illustrates the architecture of the LLM-infused diffuser, a novel framework proposed in the paper to leverage the capabilities of large language models (LLMs) for prompt encoding in diffusion models.  It shows a four-part pipeline:  1) Instruction insertion to guide LLMs toward image-relevant content; 2) Separate encoding of the prompt by multiple LLMs; 3) Linguistic token refiners to mitigate positional bias in LLM outputs; and 4) A collaborative refiner to merge and enhance representations from multiple LLMs, producing a robust text representation for the diffusion model.  The diagram visually depicts the flow of information and the interaction between the different components of the framework.", "section": "3 LLM-infused Diffuser"}, {"figure_path": "7b2DrIBGZz/figures/figures_6_1.jpg", "caption": "Figure 1: High-resolution (1024px) samples from our LI-DiT-10B, showcasing its capabilities in complex prompt comprehension, precise prompt following, and high image quality across various styles and resolutions. Please refer to the appendix for the prompts.", "description": "This figure displays several high-resolution images (1024 pixels) generated by the LI-DiT-10B model.  The images demonstrate the model's ability to understand and accurately follow complex and diverse text prompts, resulting in high-quality outputs across different artistic styles and resolutions.  The specific prompts used are listed in the appendix of the paper.", "section": "Abstract"}, {"figure_path": "7b2DrIBGZz/figures/figures_8_1.jpg", "caption": "Figure 1: High-resolution (1024px) samples from our LI-DiT-10B, showcasing its capabilities in complex prompt comprehension, precise prompt following, and high image quality across various styles and resolutions. Please refer to the appendix for the prompts.", "description": "This figure displays several high-resolution images (1024 pixels) generated by the LI-DiT-10B model.  The images demonstrate the model's ability to understand and accurately follow complex and diverse text prompts, producing high-quality results across different artistic styles and resolutions.  The specific text prompts used are listed in the appendix of the paper.", "section": "Abstract"}, {"figure_path": "7b2DrIBGZz/figures/figures_17_1.jpg", "caption": "Figure 8: LI-DiT-10B exhibits an astonishing ability to understand bilingual prompts, accurately generating images even with complex descriptions and combinations of objects.", "description": "This figure showcases the high-quality image generation capabilities of the LI-DiT-10B model. It presents nine example images generated from diverse and complex prompts, highlighting the model's proficiency in understanding and translating both simple and nuanced instructions, including those involving multiple objects and bilingual phrases. The results indicate LI-DiT-10B's strength in accurately capturing the essence of complex descriptions and producing detailed, visually appealing images.", "section": "A.5 High-quality Images Showcases"}, {"figure_path": "7b2DrIBGZz/figures/figures_18_1.jpg", "caption": "Figure 9: LI-DiT-10B exhibits an astonishing ability to understand prompts, accurately generating images even with complex descriptions and combinations of objects.", "description": "This figure showcases the model's ability to generate high-quality images from complex and creative prompts.  The four example prompts demonstrate the model's understanding of various artistic styles (anime, pixel art, realistic photography), scene descriptions, and object combinations. The generated images highlight LI-DiT-10B's ability to accurately interpret and synthesize these prompts into visually coherent and appealing results.", "section": "A.5 High-quality Images Showcases"}, {"figure_path": "7b2DrIBGZz/figures/figures_19_1.jpg", "caption": "Figure 1: High-resolution (1024px) samples from our LI-DiT-10B, showcasing its capabilities in complex prompt comprehension, precise prompt following, and high image quality across various styles and resolutions. Please refer to the appendix for the prompts.", "description": "This figure displays several high-resolution images (1024 pixels) generated by the LI-DiT-10B model.  The images demonstrate the model's ability to understand and accurately represent complex prompts, generating images that match the specified styles and resolutions. The prompts used to generate these images can be found in the appendix of the paper.", "section": "Abstract"}, {"figure_path": "7b2DrIBGZz/figures/figures_20_1.jpg", "caption": "Figure 1: High-resolution (1024px) samples from our LI-DiT-10B, showcasing its capabilities in complex prompt comprehension, precise prompt following, and high image quality across various styles and resolutions. Please refer to the appendix for the prompts.", "description": "This figure displays high-resolution images generated by the LI-DiT-10B model.  The images demonstrate the model's ability to understand and accurately represent a wide range of complex prompts, showcasing its capabilities in various artistic styles and resolutions.  The specific prompts used to generate each image can be found in the Appendix of the paper.", "section": "Abstract"}, {"figure_path": "7b2DrIBGZz/figures/figures_21_1.jpg", "caption": "Figure 1: High-resolution (1024px) samples from our LI-DiT-10B, showcasing its capabilities in complex prompt comprehension, precise prompt following, and high image quality across various styles and resolutions. Please refer to the appendix for the prompts.", "description": "This figure displays a diverse set of high-resolution images (1024 pixels) generated by the LI-DiT-10B model. The images demonstrate the model's ability to understand and accurately represent complex and diverse prompts, producing high-quality output across a wide range of styles and resolutions.  The prompts used to generate these images can be found in the paper's appendix.", "section": "Abstract"}, {"figure_path": "7b2DrIBGZz/figures/figures_22_1.jpg", "caption": "Figure 1: High-resolution (1024px) samples from our LI-DiT-10B, showcasing its capabilities in complex prompt comprehension, precise prompt following, and high image quality across various styles and resolutions. Please refer to the appendix for the prompts.", "description": "This figure displays several high-resolution images (1024 pixels) generated by the LI-DiT-10B model.  The images demonstrate the model's ability to understand and follow complex and diverse prompts, producing high-quality results across different artistic styles and image resolutions. The specific prompts used to generate each image are listed in the appendix of the paper.", "section": "Abstract"}]