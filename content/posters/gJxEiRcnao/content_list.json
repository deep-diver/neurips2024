[{"type": "text", "text": "Biologically-Inspired Learning Model for Instructed Vision ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Roy Abel Weizmann Institute of Science roy.abel@weizmann.ac.il ", "page_idx": 0}, {"type": "text", "text": "Shimon Ullman Weizmann Institute of Science shimon.ullman@weizmann.ac.il ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "As part of the effort to understand how the brain learns, ongoing research seeks to combine biological knowledge with current artificial intelligence (AI) modeling in an attempt to find an efficient biologically plausible learning scheme. Current models often use a cortical-like combination of bottom-up (BU) and top-down (TD) processing, where the TD part carries feedback signals for learning. However, in the visual cortex, the TD pathway plays a second major role in visual attention, by guiding the visual process toward locations and tasks of interest. A biological model should therefore integrate both learning and visual guidance. We introduce a model that uses a cortical-like combination of BU and TD processing that naturally integrates the two major functions of the TD stream. This integration is achieved through an appropriate connectivity pattern between the BU and TD streams, a novel processing cycle that uses the TD stream twice, and a \u2019Counter-Hebb\u2019 learning mechanism that operates across both streams. We show that the \u2019CounterHebb\u2019 mechanism can provide an exact backpropagation synaptic modification. Additionally, our model can effectively guide the visual stream to perform a task of interest, achieving competitive performance on standard multi-task learning benchmarks compared to AI models. The successful combination of learning and visual guidance could provide a new view on combining BU and TD processing in human vision and suggests possible directions for both biologically plausible models and artificial instructed models, such as vision-language models (VLMs). ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Understanding how the human brain learns has been a longstanding pursuit in both neuroscience and artificial intelligence (AI). An extensive research area at this intersection is the development of biologically plausible models of cortical learning, particularly in visual processes [Lee et al., 2015, Lillicrap et al., 2016, Scellier and Bengio, 2017, Whittington and Bogacz, 2017, Bozkurt et al., 2024]. While the ultimate goal is to develop a detailed biological model, current research primarily focuses on potential schemes for modifying synaptic weights during learning, including how these modifications are determined and how they propagate through the cortical network (the credit assignment problem) [Whittington and Bogacz, 2019]. ", "page_idx": 0}, {"type": "text", "text": "Biologically plausible learning models typically incorporate a combination of feedforward (bottomup) and feedback (top-down) pathways, with the top-down (TD) stream playing a central role in the learning process, similar to the structure of the human cortex [Lillicrap et al., 2020, Song et al., 2021]. However, a key distinction between these models and the cortex is that, while most biological models primarily use the TD stream to propagate feedback signals, in the cortex, the TD stream also plays a crucial role in perception by directing attention [Manita et al., 2015]. ", "page_idx": 0}, {"type": "text", "text": "Top-down attention is an essential part of human vision and has been extensively studied in human physiology, anatomy, and psychophysics [Treisman and Gelade, 1980, Itti and Koch, 2001, Carrasco, ", "page_idx": 0}, {"type": "text", "text": "2011]. Studies indicate that the TD stream directs visual processes toward selected locations and tasks, actively shaping the neural activity in the bottom-up (BU) stream and creating task-dependent representations in the cortex [Gilbert and Li, 2013, Harel et al., 2014]. Consequently, current biologically plausible models have been criticized for not involving the TD stream in ongoing visual processes [Lillicrap et al., 2020], and the challenge of incorporating the TD stream into feedforward BU processing remains an open research question [Zagha, 2020, Kreiman and Serre, 2020]. ", "page_idx": 1}, {"type": "text", "text": "Our work addresses this gap and, to our knowledge, introduces the first biologically plausible learning model where the TD stream not only carries feedback signals but also performs visual guidance. This model tackles two key challenges that must be addressed together: first, attention guidance, understanding how the TD stream guides BU neural processing, and second, learning, determining synaptic modifications and solving the credit assignment problem in this guided processing context. ", "page_idx": 1}, {"type": "text", "text": "The dual role of the TD component in our model, involving both attention guidance and learning, may offer a more accurate depiction of bi-directional cortical processing and learning compared to existing models. For learning, we suggest a \u2019Counter-Hebb\u2019 mechanism, a modification of classical Hebbian learning [Hebb, 2005]. We show that this model can approximate the backpropagation (BP) synaptic modification [Rumelhart et al., 1986], and can provide an exact equivalence to BP under a symmetry assumption. Regarding its biological plausibility, we address the weight symmetry problem between forward and backward paths and use local synaptic updates dependent only on neurons associated with the modified synapse. Moreover, our method offers a possible solution to the long-standing challenge of integrating the TD stream into ongoing visual processing [Zagha, 2020, Kreiman and Serre, 2020, Lillicrap et al., 2020]. In the context of guidance, we demonstrate that the TD stream can be used both for learning and for directing the BU stream to perform tasks of interest by selecting a sparse, task-specific sub-network within the full BU network. We further show that this model achieves competitive results on standard multi-task learning benchmarks. ", "page_idx": 1}, {"type": "text", "text": "Beyond brain-related aspects, it is noteworthy that the integration of guidance is becoming a central aspect in recent AI models, particularly in Large Language Models (LLMs) and Vision-Language Models (VLMs). A fundamental characteristic of VLMs, similar to the brain, is their ability to focus on specific tasks of interest [Huang et al., 2023, Liu et al., 2024]. In these models, guidance is achieved through instructions that propagate through a language stream, which interacts with a visual component, allowing the model to dynamically adjust its attention to focus on the particular visual elements relevant to the task. This represents a significant shift from earlier computer vision models, where outputs relied exclusively on visual input and task instructions were implicitly embedded in the model design, with each task handled by a separate model. The parallel between AI advancements and brain modeling may deepen our understanding of the human brain and inspire the development of more advanced, human-like AI systems. ", "page_idx": 1}, {"type": "text", "text": "The key contributions of our work include: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We propose the first biologically motivated learning model for instructed vision. \u2022 We present a unified feedback mechanism that combines error propagation for synaptic learning with Top-Down attention to guide visual processing based on instructions. \u2022 We suggest a Counter-Hebb learning procedure as a possible local synaptic modification that can perform exact backpropagation learning. ", "page_idx": 1}, {"type": "text", "text": "The code for reproducing the experiments and creating BU-TD models for guided models is available at https://github.com/royabel/Top-Down-Networks. ", "page_idx": 1}, {"type": "text", "text": "2 Related work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "The fields of brain modeling and AI have fruitful interactions going in both directions [Yamins and DiCarlo, 2016, Bowers, 2017, Yildirim et al., 2019]. Particularly, the study of biologically plausible learning models aims to deepen our understanding of the learning mechanisms in the human brain and enhance learning techniques for artificial neural network models. While artificial models primarily employ the backpropagation (BP) algorithm for learning [Rumelhart et al., 1986], a direct implementation of BP in biological models is generally considered biologically implausible [Whittington and Bogacz, 2019, Lillicrap et al., 2020]. Nevertheless, the integration of BP with biological principles, such as Hebb\u2019s plasticity rule [Hebb, 2005], has inspired the development of diverse biologically plausible learning approaches. ", "page_idx": 1}, {"type": "text", "text": "These learning methods are often compared to learning with BP, aiming to achieve similar performance in a more biologically plausible way. For instance, Equilibrium Propagation methods [Scellier and Bengio, 2017] suggest updating synaptic weights once the model reaches a stable equilibrium state under a given input. Equilibrium Propagation methods have been shown to produce weight updates equivalent to those in BP under specific conditions [Ernoult et al., 2019], and approximate BP in other cases [Millidge et al., 2020]. The Predictive Coding approach suggests that in visual processing, feedback connections carry predictions of neural activities, whereas feedforward streams carry the residual errors between these predictions and the actual neural activities [Rao and Ballard, 1999]. It has been demonstrated that when predictive coding is used to train a neural network in a supervised learning setting, it can produce parameter updates that approximate those computed by backpropagation [Whittington and Bogacz, 2017, Millidge et al., 2022a]. These results have been further developed under additional assumptions, leading to predictive coding variants that produce the exact same parameter updates as backpropagation [Song et al., 2020, Salvatori et al., 2022]. However, the modifications necessary for these methods to approximate or be equivalent to backpropagation are criticized for reducing their biological plausibility [Rosenbaum, 2022, Golkar et al., 2022]. ", "page_idx": 2}, {"type": "text", "text": "Among biologically plausible approaches, Feedback Alignment and Target Propagation approaches are the most similar to our method. Like backpropagation, these approaches involve a forward (BU) stream that generates predictions from an input signal, followed by a backward (TD) stream that propagates feedback. While BP propagates gradients backward using the same weights as the forward path, feedback alignment methods propose propagating gradient-like signals through the TD stream with a separate set of weights, removing the symmetric weight structure of BP [Lillicrap et al., 2016, N\u00f8kland, 2016, Song et al., 2021]. The target propagation methods suggest propagating backward targets for the forward path instead of gradients [Bengio, 2014, Lee et al., 2015, Meulemans et al., 2020]. Both feedback alignment and target propagation methods can approximate the BP update under specific conditions [Akrout et al., 2019, Ahmad et al., 2020, Ernoult et al., 2022]. Nevertheless, current models lack the extensive BU-TD interactions observed in the brain, which are essential for guiding attention in visual processes [Harel et al., 2014, Manita et al., 2015, Lillicrap et al., 2020]. ", "page_idx": 2}, {"type": "text", "text": "2.1 Guided visual processing ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Human cortical processing uses a combination of bottom-up (BU) and top-down (TD) processing streams. In the visual brain, the BU stream proceeds from low-level sensory regions to high-level, more cognitive areas, while in the TD stream processing flows in the opposite direction [Dehaene et al., 2021]. In human vision, the TD stream is involved in TD attention, guiding the visual process and directing it toward tasks of interest [Goddard et al., 2022, Shahdloo et al., 2022]. For example, at the physiological level, it has been shown, in behaving primate studies, that given the same image, but with different tasks, the activation along the BU stream changes, modulated by TD activation, to focus on the instructed task [Gilbert and Li, 2013]. ", "page_idx": 2}, {"type": "text", "text": "The ability to guide visual processing to extract specific aspects of the image is essential because a single image encompasses a wealth of information regarding objects, their parts and sub-parts, their properties, and inter-relations. Consequently, for complex images, it becomes difficult to extract and represent all the possibly meaningful information through a single visual representation [Huang et al., 2023]. There are two approaches to address this challenge: one is to employ specialized models, each tailored to specific visual tasks, and the other is to develop general-purpose vision models that can selectively focus on relevant visual information ", "page_idx": 2}, {"type": "text", "text": "Empirical studies in artificial models have demonstrated that guiding the model\u2019s attention to selected locations or tasks offers advantages over non-guided, pure BU models [Tsotsos, 2021, Pang et al., 2021, Ullman et al., 2023]. Furthermore, as opposed to earlier computer vision models, which relied solely on visual inputs without guidance, recent Vision Language Models (VLMs) have integrated instruction guidance mechanisms into their visual processing [Bai et al., 2023, Zhu et al., 2023, Liu et al., 2024, Dai et al., 2024]. The processing of visual information in VLMs integrates a language stream that interacts with a visual stream and guides it to perform selected tasks. As a result, these models have been shown to have high generalization and zero-shot capabilities. The importance of guidance mechanisms in both the human cortex and AI models highlights the need for biologically inspired learning models that incorporate these mechanisms to neuroscience implications and potential advancements of artificial models. While our focus in this paper centers on vision, it is worth noting that our method can be applied to guided processing in other domains as well. ", "page_idx": 2}, {"type": "text", "text": "3 The bottom-up top-down model ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "This section introduces the proposed structure of the Bottom-Up (BU) and Top-Down (TD) networks. A BU network with $L$ hidden layers is a function that maps an input vector $x:=h_{0}$ to an output vector $y$ , such that for each layer $0\\leq l<L$ : the hidden values are defined to be: ", "page_idx": 3}, {"type": "equation", "text": "$$\nh_{l+1}:=\\sigma\\left(f_{l+1}(h_{0},h_{1},...,h_{l})\\right)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The functions $f_{l}$ are linear, and the activation function $\\sigma$ is an element-wise function that may be non-linear. To predict an output, we use a prediction head $H_{p r e d}$ , which is a small network, typically one to two layers, that maps the last hidden layer $h_{L}$ to the predicted output: $y=H_{p r e d}(h_{L})$ . ", "page_idx": 3}, {"type": "text", "text": "For a given BU network, we define a symmetric TD network (denoted with upper bars) as the reversearchitecture network, that maps an input vector $\\bar{y}$ to an output vector $\\bar{x}:=h_{0}$ . The TD network is constructed based on the BU architecture as follows: The input (e.g. the prediction error) $\\bar{y}$ is mapped to the top-level hidden layer $\\bar{h}_{L}$ of the TD network via the TD prediction head: $\\bar{h}_{L}=\\bar{H}_{p r e d}(\\bar{y})$ , and then for every $0\\leq l<L$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\n{\\bar{h}}_{l}:={\\bar{\\sigma}}\\left({\\bar{f}}_{l+1}({\\bar{h}}_{L},{\\bar{h}}_{L-1},...,{\\bar{h}}_{l+1})\\right)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The TD network satisfies two conditions. First, we restrict $\\bar{h}_{l}$ for each $l$ so that $h_{l}$ and $\\bar{h}_{l}$ will have the same size (the same number of neurons). This allows us to define pairs of corresponding neurons, assigning each BU neuron $h_{l,i}$ in layer $l$ a \u2019counter neuron\u2019 ${\\bar{h}}_{l,i}$ in the TD network. We also use the following notation for simplicity: $\\bar{\\bar{h}}:={h}$ . Additionally, we restrict $\\bar{f}_{l}$ to have the same connectivity structure as $f_{l}$ , but with the opposite direction: each pair of TD neurons is linked if and only if a link exists between their corresponding BU counter neurons. For example, given a fully connected layer $h_{l}=f_{l}(h_{l-1})=W_{l}h_{l-1}$ , the corresponding TD layer $\\bar{f}_{l}$ is defined to be also a fully connected layer $\\bar{h}_{l-1}=\\bar{f}_{l}(\\bar{h}_{l})=\\bar{W}_{l}\\bar{h}_{l}$ such that the shape of the TD weights matrix $\\bar{W}_{l}$ is equal to the shape of the transposed BU weights matrix $\\boldsymbol{W_{l}}^{T}$ . ", "page_idx": 3}, {"type": "text", "text": "3.1 Activation functions and biases ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The activation functions $\\sigma,\\,\\bar{\\sigma}$ , may be any element-wise functions. In this work, we focus on two functions. The first is ReLU which is commonly used for neural networks $R e L U(x):=x\\cdot I_{\\{x>0\\}}$ . ", "page_idx": 3}, {"type": "text", "text": "The second is the Gated Linear Unit (GaLU) [Fiat et al., 2019], which, in our model, leverages lateral connectivity between the BU and TD streams by gating neurons\u2019 activity based on the activation of their counter neurons. ", "page_idx": 3}, {"type": "equation", "text": "$$\nG a L U(x):=G a L U(x,{\\bar{x}}):=x\\cdot I_{\\{{\\bar{x}}>0\\}}={\\binom{x}{0}}\\quad{\\bar{x}}>0\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Where $\\textstyle{\\bar{x}}$ is the counter neuron of $x$ (either a BU or a TD neuron), and $I$ is an indicator function. ", "page_idx": 3}, {"type": "text", "text": "GaLU introduces bidirectional lateral connectivity between the BU and TD networks by temporarily turning off neurons based on the values of their counter neurons. As a result, each network can effectively guide its counterpart to operate on a specific partial sub-network. ", "page_idx": 3}, {"type": "text", "text": "In this paper, we omit bias terms to simplify the model. Nevertheless, biases can be implicitly expressed using the above notations by having additional neurons and weights, as commonly practiced [Lee et al., 2015, Ahmad et al., 2020]. In addition, we allow two modes of biases. The first is the standard bias mechanism, in which biases contribute to the output. The second mode is \u2019bias-blocking [Akrout et al., 2019] in which all bias terms are zeroed. ", "page_idx": 3}, {"type": "text", "text": "4 Counter-Hebbian learning ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we formulate the Counter-Hebb learning. The Counter-Hebb (CH) rule updates each synapse based on the activities of its pre-synaptic neuron and its post-synaptic counter neuron. Consider a given weights matrix W such that b = Wa. The (i, j)-th entry in that matrix, W i(jt ), represents the strength of the synapse connecting the pre-synaptic neuron $a_{j}$ to the post-synaptic neuron $b_{i}$ at time $t$ . Then the update rule is: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\Delta W_{i j}^{(t+1)}:=W_{i j}^{(t+1)}-W_{i j}^{(t)}=\\eta\\cdot a_{j}\\cdot\\bar{b}_{i}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\eta$ is the learning rate, and $\\bar{b}_{i}$ is the counter neuron of $b_{i}$ . This rule applies to all weights including both up-streams and down-streams, updating both $W$ and $\\Bar{W}$ identically, see Figure 1. ", "page_idx": 4}, {"type": "text", "text": "There is a close connection between this rule and the classic Hebb rule. In both cases, the brain strengthens synapses (weights) between neurons that are co-activated, and the modifications of each synapse are determined entirely by the activation values of neurons in the network associated directly with the changing synapse. However, the difference lies in the neurons connected to that synapse. Classic Hebbian proposes that the forward-firing of a post-synaptic neuron also propagates backward to the synapse. Thereby, synapse strength increases when a pre-synaptic neuron\u2019s firing is often followed by the firing of the post-synaptic neuron within a defined time interval [Magee and Johnston, 1997, Hebb, 2005]. In contrast, the Counter-Hebb modification does not depend on the cell\u2019s firing propagating back to its dendrites but suggests a contribution from the counter post-synaptic neuron via a lateral connection. Similar to Hebb\u2019s rule, the resulting synaptic modification also depends on the coincidence of two firing neurons, but the post-synaptic cell is replaced by its counterpart. See Figure 1 for a visual illustration of the Counter-Hebb update compared with the classic Hebb. ", "page_idx": 4}, {"type": "text", "text": "Therefore, the CH rule modifies the classical Hebb rule by integrating feedback streams that can carry error information into the learning process. The feasibility of synaptic plasticity that depends on the coincidence of two signals from feedforward and feedback sources is supported by empirical findings, such as those from CA1 hippocampal cells [Markov et al., 2014, Cornford et al., 2019]. ", "page_idx": 4}, {"type": "image", "img_path": "gJxEiRcnao/tmp/7fe8a6f4ff814a67fb74a2c006f3e685a1340a5a8d0297f9f34af2fd31edc7e3.jpg", "img_caption": ["Figure 1: The Counter-Hebb update rule in comparison with the classical Hebb rule. The classical Hebbrule (on the left), with a focus on a single upstream synapse $W_{i j}$ (outlined by a circle), connecting a pre-synaptic neuron $a_{j}$ with a post-synaptic neuron $b_{i}$ . The synapse $W_{i j}$ is updated based on the activity of both associated neurons $a_{j}$ and $b_{i}$ . While neuron $a_{j}$ is directly associated with the synapse $W_{i j}$ , neuron $b_{i}$ is assumed to transmit its information through propagation down the dendritic tree to synapse $W_{i j}$ (orange arrow). In contrast, the Counter-Hebb update rule (on the right), relies on a contribution from the counterpart downstream (marked in orange), mediated via lateral connections. Compared with the Hebb rule, the signal from $a_{j}$ is combined with the signal from neuron ${\\bar{b}}_{i}$ rather than neuron $b_{i}$ . Notably, the resulting Counter-Hebb rule naturally applies an identical update to both $W_{i j}$ and its counter synapse $\\bar{W}_{j i}$ . "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "4.1 The Counter-Hebb learning algorithm and backpropagation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "This section presents the full Counter-Hebbian (CH) learning algorithm. The learning algorithm is described in Algorithm 1. Similar to the backpropagation algorithm, the CH algorithm involves a single forward pass performed by the BU network to compute predictions from an input signal. Subsequently, a single backward pass is conducted using the TD network to propagate error information, and the weights are updated according to the CH update rule. ", "page_idx": 4}, {"type": "text", "text": "A special case occurs when the BU and TD networks have symmetric weights, (identical values). While symmetric BU and TD weights might, at first, seem unrealistic in the brain, symmetry is actually implicitly encouraged by the CH update. The CH update naturally applies an identical update to both the BU and the TD weights, see Figure 1. Therefore, as training progresses, assuming close-to-zero initial weights (a common practice), the BU and TD weights gradually become more symmetric, as the value of the weights will be dominant by the values of the updates. Additionally, at any point during the training, if the BU and TD weights are symmetric, they will maintain this symmetry during the entire learning. ", "page_idx": 4}, {"type": "table", "img_path": "gJxEiRcnao/tmp/4a1151164b59b5df970ce6eb5a07065c89aeba56bb883ee6c2c4075d89de25f4.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Given symmetric BU and TD weights, under the following standard conditions: 1) The BU network uses ReLU non-linearity 2) The error function computes the negative gradients of a loss function $L$ with respect to the BU output, for example, error $(y,\\tilde{y})=\\tilde{y}-y$ for Mean Squared Error loss 3) The TD network uses GaLU non-linearity and bias-blocking mode (see Section 3.1). Then the TD backward step in Algorithm 1 is mathematically equivalent to the backward computation of the BP algorithm [Rumelhart et al., 1986]. As a result, in this configuration, Counter-Hebb learning effectively replicates the exact BP update, performing similarly to BP and preserving its mathematical properties. Moreover, relaxing the symmetry constraint under the above conditions results in a learning algorithm that approximates BP in the non-symmetric case. For a detailed explanation of this equivalence and approximation see Appendix A.1. Like some previous models, the CH has the desired property, as a biological model, of locality: the synaptic modifications are determined entirely by the activation values of neurons directly associated with the synapse. ", "page_idx": 5}, {"type": "text", "text": "5 Instruction-based learning ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In the previous section, we described how the TD network can be used for learning a pure BU model. In this section, we describe how the model performs visual guidance. The TD network in our model can guide the BU network to perform multiple tasks by selecting a sub-network for each learned task (where sub-networks can overlap). In this setting, the objective is to predict an output $y$ given an input $x$ and a task $t$ . To accommodate this, the model has one additional head, resulting in two heads: a prediction head, and an instruction head. Each head consists of two parts: one for the BU network and the other for the TD network, preserving the symmetrical structure and lateral connectivity of the BU-TD core, see Appendix A.2 for more details on the heads. ", "page_idx": 5}, {"type": "text", "text": "The prediction head $H_{p r e d}$ , of one linear layer, is responsible for generating predictions and providing feedback, as discussed in section 3. The instruction head, $H_{i n s t r u c t}$ , employs a 2-layer MLP for specifying the selected task, projecting instructional information to the visual space (and vice versa), similarly to instruction processing in VLMs. More specifically, the instruction head takes a task representation $t$ as input and maps it to the top-level TD layer $\\bar{h}_{L}$ . We use one-hot encoding for representing the tasks, however, more complex embedding could also be explored, such as a projection from an LLM. Note that in our experiments, we allow only one head to participate in each pass of the model (either the prediction or instruction head), refer to Fig 2 for an illustration of how the two heads are utilized in learning instruction-based models. ", "page_idx": 5}, {"type": "text", "text": "The instruction-based learning algorithm is shown in Algorithm 2. This algorithm consists of two passes for prediction (a TD followed by BU) followed by an additional TD pass for the learning, thereby extending Algorithm 1 by adding an instruction-processing step that selects a task-specific sub-network. Given a task $t$ , the TD instruction head is used to propagate the task representation along the TD network. Since each task activates different patterns, the activated neurons (i.e., with activation value larger than 0) define a task-dependent sub-network. By running the BU network with GaLU activation, the BU computation is gated to propagate the input $x$ along the corresponding BU sub-network. In this manner, the resulting algorithm learns for each task a different predictor which is conditioned on the task, resembling a modular architecture where different modules are dedicated to each task. See Fig 2 for a visualization of this guided process. ", "page_idx": 5}, {"type": "text", "text": "Extending upon the results of section 4.1, with the constraint of symmetric BU and TD weights, both BP and CH learning produce identical updates within this guided learning framework, despite using the TD stream twice, see Appendix A.1 for more details. This equivalence provides mathematical ", "page_idx": 5}, {"type": "text", "text": "1: Input: data $x$ , task $t$ , ground truth label $\\tilde{y}$   \n2: Top-Down: $\\bar{x}=T D(\\bar{t};\\ \\ \\bar{H}_{i n s t r u c t}$ ; $\\bar{\\sigma}=R e L U$ )   \n3: Bottom-Up: $y=B U(x;\\;\\;H_{p r e d};$ $\\sigma=G a L U\\circ R e L U)$   \n4: Compute error: $e=e r r o r(y,\\tilde{y})$   \n5: Backward: $\\bar{x}=T D(e;~~\\bar{H}_{p r e d};~~\\bar{\\sigma}=G a L U)$   \n6: Counter-Hebb Update: update $W$ and $\\bar{W}$ ", "page_idx": 6}, {"type": "image", "img_path": "gJxEiRcnao/tmp/7f8b3594790f8119deb44e2d78023abbee569bfe0f73db9a31ecadd571b3b155.jpg", "img_caption": [], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Figure 2: The instruction-based learning algorithm. The three columns represent three passes of our model (left to right): $T D\\rightarrow B U\\rightarrow T\\bar{D}$ , where the first two passes provide a prediction output given an image and a task, and the last TD pass (in green frame) is used for learning. In inference, The BU visual process is guided by the TD network according to the given task. More specifically, The TD network propagates instruction signals downward followed by a guided BU process of the input image to compute predictions. By applying ReLU non-linearity, the input task selectively activates a subset of neurons (i.e. non-zero values), composing a sub-network within the full network. The BU network then processes an input image using a composition of ReLU and GaLU. The GaLU function (dashed arrows) gates the BU computation to operate only on the selected sub-network that was activated by the task. For learning, the same TD network is then reused to propagate prediction error signals with GaLU exclusively (no ReLU). Finally, the \u2019Counter-Hebb\u2019 learning rule adjusts both networks\u2019 weights based on the activation values of their neurons. Therefore, in contrast with standard models, the entire computation, including the learning, is carried out by neurons in the network, and no additional computation is used for learning (e.g. backpropagation) ", "page_idx": 6}, {"type": "text", "text": "guarantees to learning guided vision using a single TD network for both guidance and learning. Furthermore, symmetric weights have computational advantages. It enables extending standard BU architectures to instruction-based models without any additional parameters. For a given BU network, a complementary symmetric TD network can be constructed, sharing the same BU parameters. This TD network can guide the BU process of the original network to perform a given instruction. ", "page_idx": 6}, {"type": "text", "text": "6 Empirical results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we evaluate our BU-TD model, learned via Counter-Hebbian learning, in two settings: 1) unguided visual processing, to show that CH learning is capable of learning vision models 2) guided visual processing, to evaluate the ability of our model to guide the visual process according to instructions. Our goal is not to improve upon state-of-the-art models, but to show that the model, with a single top-down pathway for both error and instruction propagation, is comparable with current AI models, and capable of performing well two different functions: learning and directing attention. ", "page_idx": 6}, {"type": "text", "text": "6.1 Unguided visual processing ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In the unguided experiments, we evaluate the performance of the Counter-Hebb learning on standard image classification benchmarks: MNIST [LeCun et al., 1998], Fashion-MNIST [Xiao et al., 2017], ", "page_idx": 6}, {"type": "text", "text": "Table 1: Unguided learning results: mean and standard deviation of the test accuracy (in percentages) across 10 runs. The proposed CH learning algorithm is compared with BP and other biological state-of-the-art methods. The baseline results were taken from Bozkurt et al. [2024]. ", "page_idx": 7}, {"type": "table", "img_path": "gJxEiRcnao/tmp/0fc9fc18adfef238963fec177634a93e2d53ac79e9abf309ca7facd690c0cf42.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "and CIFAR10 [Krizhevsky et al., 2009]. We followed the same experiments as Bozkurt et al. [2024] and used two-layer fully connected networks, with a hidden layer of size 500 for both MNIST and Fashion-MNIST datasets and size 1,000 for CIFAR10. Further details including the full set of hyperparameters can be found in Appendix A.4.2. We compare CH learning using the Cross-Entropy loss with backpropagation and other biological learning methods. ", "page_idx": 7}, {"type": "text", "text": "We examine two settings of CH learning, one where the BU and TD weights are initialized with symmetrical values, denoted as \u2019Sym Init\u2019, and the other where the weights are initialized differently, referred to as \u2019Asym Init\u2019. The results, shown in Table 1, empirically validate that CH learning is equivalent to BP in the symmetric case, and approximates BP in the asymmetric case. Moreover, CH learning achieves comparable or superior performance compared with other biological methods. We further show the robustness of CH on other architectures and settings, such as convolutional networks, loss functions, and regularization. The results and additional information regarding these experiments can be found in Appendix A.4.2. ", "page_idx": 7}, {"type": "text", "text": "6.2 Guided visual processing ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In the guided experiments, we evaluate our model on two common multi-task learning (MTL) benchmarks. Since current biological methods are not capable of guided processing, we compare CH with non-biological state-of-the-art optimization methods as reported by Kurin et al. [2022], replicating their setup and using their reported results. ", "page_idx": 7}, {"type": "text", "text": "The Multi-MNIST dataset contains images of two overlaid digits, where the task indicates whether to classify the left or the right digit. Similar to the baselines, our BU network employs a simple architecture composed of two convolutional layers followed by a single fully-connected layer, with ReLU non-linearity, along with an additional fully-connected linear layer as the decoder (prediction head). To adapt this architecture to the BU-TD structure, we replace all max-pool layers with strided convolution layers, that perform a similar function as proposed by [Ayachi et al., 2020]. Since the BU-TD model uses only sparse sub-networks within the full network, we increased the number of channels in each convolution layer, however, the actual network size is effectively smaller compared with the baselines, see Appendix A.6 for an analysis of the actual size of the sub-networks. ", "page_idx": 7}, {"type": "text", "text": "The CelebA dataset is a more challenging large-scale benchmark, comprising head shots of celebrities, along with the indication of the presence or absence of 40 different attributes. Each task is a binary classification problem for an attribute. As done in previous work [Kurin et al., 2022], we employ a ResNet-18 [He et al., 2016] architecture (without the final layer) with batch normalization layers [Ioffe and Szegedy, 2015], and a linear decoder. Additionally, we remove the last average pooling layer to support the symmetric BU-TD structure. ", "page_idx": 7}, {"type": "text", "text": "Unlike the baselines, we do not use any learning \u2019tricks\u2019 such as dropout layers, regularization, or early stopping. Additionally, while the baseline models require a separate decoder (prediction head) for each task, our BU-TD model can use a single shared decoder for all tasks. Further details, ", "page_idx": 7}, {"type": "text", "text": "Table 2: Guided processing results: mean and $95\\%$ confidence interval of the avg. task test accuracy (in percentages) across 10 runs for Multi-MNIST and 5 runs for CelebA. The proposed CH learning algorithm is compared with non-biological state-of-the-art methods, as reported in Kurin et al.. ", "page_idx": 8}, {"type": "table", "img_path": "gJxEiRcnao/tmp/9146918354843d9edaff1265b62c7acd95462d3531dfd533f3d3d9d8eacc9c75.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "including exact architectures, hyper-parameters, and additional experiments with a single decoder, and varied network sizes, are provided in Appendix A.4. ", "page_idx": 8}, {"type": "text", "text": "The results, presented in Table 2, show that the proposed model successfully incorporates the two different TD functions, directing attention, and learning. The BU-TD model can achieve competitive performance compared with leading non-biological state-of-the-art methods. The proposed method may offer additional useful computational properties, such as compactness, see Appendix A.6. ", "page_idx": 8}, {"type": "text", "text": "6.3 Weight symmetry ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Weight symmetry poses a significant challenge in biological learning models, as copying the same weights across different locations is unrealistic in the brain, referred to as the \u2019weight transport\u2019 problem Grossberg [1987]. Therefore, unlike backpropagation, biological models use different weights for feedforward and feedback streams. In this section, we further explore the effect of deviation from weight symmetry on the model performance, focusing on both symmetry in the initialization of the weights, and symmetry in the subsequent updates. We use below the terms \u2019symmetric model\u2019 for models with symmetric weight initialization, \u2019asymmetric models\u2019 for weights initialized far from symmetry, and \u2019weak symmetric\u2019 for models initialized symmetrically (or nearly symmetric), but are subject to noisy, asymmetric updates. See Appendix A.5 for more details and additional experiments. ", "page_idx": 8}, {"type": "text", "text": "The results, presented in Table 3 and Appendix A.5, demonstrate that initial weight symmetry is more critical for approximating backpropagation performance than gradually converging to symmetry later in the learning process. The experiments show that performance degradation in the asymmetric case becomes more pronounced as task complexity and model size increase, even with weight decay applied to ensure convergence to symmetry. The results also show that our model demonstrates better scalability with asymmetric weights compared with some alternative methods, such as feedback alignment. In contrast, in the weak symmetric case, where weights do not maintain symmetry due to noise in updates, performance consistently remains nearly identical to standard back-propagation across all experiments. These results indicate that exact weight symmetry is not mandatory for backpropagation approximation. We hypothesize that Counter-Hebb learning, like backpropagation, depends on proper weight initialization to achieve optimal results, in addition to weight symmetry. By the time that symmetry of the weights is obtained, the weights may drift from their optimal initialization. This case will be similar to starting the standard backpropagation from non-optimal initialization conditions, leading in both cases to suboptimal performance. For more details regarding the effects of asymmetry see Appendix A.5.1. ", "page_idx": 8}, {"type": "text", "text": "7 Limitations ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "There are two directions that should be improved in the current model, one regarding performance and the second concerning biological aspects. In the asymmetric case, similar to other biologically inspired methods [Ernoult et al., 2022], we observe increasing performance gaps as task and model complexity increase. However, the learning parameters, including the weight initialization scheme, have been carefully optimized for backpropagation (symmetric weights) over the years. Therefore, examining the effects of tuning parameters in the asymmetric case could improve performance. On the biological side, the plausibility of the model should be further explored. The main issue we identify (in ours and other models) is that propagating error signals along the TD stream requires the representation of both positive and negative values in neuronal activity [Lillicrap et al., 2020]. Following initial work, we suggest that this could be obtained by \u2018on\u2019 and \u2018off\u2019 channels [Ringach, 2004], where negative values in the \u2018on\u2019 channel are represented by positive values in the complementary \u2018off\u2019 channel. ", "page_idx": 8}, {"type": "table", "img_path": "gJxEiRcnao/tmp/34fb10070d548ed9d21daecfb8c3c4871cb6ee44ce8e4919a2106b1b0ca7c216.jpg", "table_caption": ["Table 3: Comparing different weight asymmetry settings: mean accuracy and $95\\%$ confidence interval (in percentages) across 5 runs evaluated on CIFAR10 using ResNet18. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "8 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we proposed the first biologically-motivated learning model for instructed visual processing. Similar to the visual cortex, it uses a bottom-up (BU) top-down (TD) structure, which, unlike previous learning models, uses the TD stream in ongoing visual processing by directing attention, e.g. to tasks and locations of interest. ", "page_idx": 9}, {"type": "text", "text": "Modeling guided visual learning is challenging since the prediction of the model depends on both the BU processing of the image and the task selected by a top-down instruction. The error signal needs, therefore, to propagate through both the BU and TD pathways, and at the same time the network is required to preserve the neural activations from the prediction phase since they determine the required changes in synaptic weights (Fig. 1). These requirements place significant constraints on the structure of the model network, however, our model meets the requirements and, as supported by mathematical foundations and empirical experiments, succeeds in learning guided vision for multiple tasks. Since the cortex performs similar guided vision, the proposed model may suggest a sketch model for the combination of the BU and TD streams in the visual cortex. Furthermore, the model shares a similar general structure with VLMs, in the sense of using two parallel streams, a visual one together with a more cognitive one. Since the human brain excels at combining visual and cognitive information in visual perception, the combination of instructed VLMs with principles from human BU-TD processing can offer a promising direction for future studies. ", "page_idx": 9}, {"type": "text", "text": "The model also suggests a Counter-Hebbian learning process in addition to the classical Hebb rule, where synapses are modified by combining a pre-synaptic signal with a signal coming from the appropriate counter stream. The existence of CH learning may be tested biologically by the controlled activation of selected layers. For example, cortical layer 3B receives feedforward connections from layer 4 while feedback connections arrive to layer 2/3A [Markov et al., 2014]. The counter-Hebbian model predicts that it may be possible to modify the forward synapses from layer 4 to layer 3B by simultaneous activation of the two inputs. ", "page_idx": 9}, {"type": "text", "text": "Counter-Hebb learning provides new directions for addressing the weight symmetry problem in biological learning models. Our findings indicate that exact weight symmetry is not crucial for achieving performance comparable to backpropagation and performance is more significantly influenced by the choice of weight initialization than by the precise symmetry in the weights. This suggests that discussions around biological feasibility in learning models should focus on obtaining nearly symmetric weights at initialization, rather than starting with asymmetric weights and relying on convergence to symmetry. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Dong-Hyun Lee, Saizheng Zhang, Asja Fischer, and Yoshua Bengio. Difference target propagation. In Joint european conference on machine learning and knowledge discovery in databases, pages 498\u2013515. Springer, 2015.   \nTimothy P Lillicrap, Daniel Cownden, Douglas B Tweed, and Colin J Akerman. Random synaptic feedback weights support error backpropagation for deep learning. Nature communications, 7(1): 1\u201310, 2016.   \nBenjamin Scellier and Yoshua Bengio. Equilibrium propagation: Bridging the gap between energybased models and backpropagation. Frontiers in computational neuroscience, 11:24, 2017.   \nJames CR Whittington and Rafal Bogacz. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural computation, 29(5): 1229\u20131262, 2017.   \nBariscan Bozkurt, Cengiz Pehlevan, and Alper Erdogan. Correlative information maximization: A biologically plausible approach to supervised deep neural networks without weight symmetry. Advances in Neural Information Processing Systems, 36, 2024.   \nJames CR Whittington and Rafal Bogacz. Theories of error back-propagation in the brain. Trends in cognitive sciences, 23(3):235\u2013250, 2019.   \nTimothy P Lillicrap, Adam Santoro, Luke Marris, Colin J Akerman, and Geoffrey Hinton. Backpropagation and the brain. Nature Reviews Neuroscience, 21(6):335\u2013346, 2020.   \nGanlin Song, Ruitu Xu, and John Lafferty. Convergence and alignment of gradient descent with random backpropagation weights. Advances in Neural Information Processing Systems, 34: 19888\u201319898, 2021.   \nSatoshi Manita, Takayuki Suzuki, Chihiro Homma, Takashi Matsumoto, Maya Odagawa, Kazuyuki Yamada, Keisuke Ota, Chie Matsubara, Ayumu Inutsuka, Masaaki Sato, et al. A top-down cortical circuit for accurate sensory perception. Neuron, 86(5):1304\u20131316, 2015.   \nAnne M Treisman and Garry Gelade. A feature-integration theory of attention. Cognitive psychology, 12(1):97\u2013136, 1980.   \nLaurent Itti and Christof Koch. Computational modelling of visual attention. Nature reviews neuroscience, 2(3):194\u2013203, 2001.   \nMarisa Carrasco. Visual attention: The past 25 years. Vision research, 51(13):1484\u20131525, 2011.   \nCharles D Gilbert and Wu Li. Top-down influences on visual processing. Nature Reviews Neuroscience, 14(5):350\u2013363, 2013.   \nAssaf Harel, Dwight J Kravitz, and Chris I Baker. Task context impacts visual object processing differentially across the cortex. Proceedings of the National Academy of Sciences, 111(10): E962\u2013E971, 2014.   \nEdward Zagha. Shaping the cortical landscape: Functions and mechanisms of top-down cortical feedback pathways. Frontiers in Systems Neuroscience, 14:33, 2020.   \nGabriel Kreiman and Thomas Serre. Beyond the feedforward sweep: feedback computations in the visual cortex. Annals of the New York Academy of Sciences, 1464(1):222\u2013241, 2020.   \nDonald Olding Hebb. The organization of behavior: A neuropsychological theory. Psychology Press, 2005.   \nDavid E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning representations by back-propagating errors. nature, 323(6088):533\u2013536, 1986.   \nJiaxing Huang, Jingyi Zhang, Kai Jiang, Han Qiu, and Shijian Lu. Visual instruction tuning towards general-purpose multimodal model: A survey. arXiv preprint arXiv:2312.16602, 2023.   \nHaotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. Advances in neural information processing systems, 36, 2024.   \nDaniel LK Yamins and James J DiCarlo. Using goal-driven deep learning models to understand sensory cortex. Nature neuroscience, 19(3):356\u2013365, 2016.   \nJeffrey S Bowers. Parallel distributed processing theory in the age of deep networks. Trends in cognitive sciences, 21(12):950\u2013961, 2017.   \nIlker Yildirim, Jiajun Wu, Nancy Kanwisher, and Joshua Tenenbaum. An integrative computational architecture for object-driven cortex. Current opinion in neurobiology, 55:73\u201381, 2019.   \nMaxence Ernoult, Julie Grollier, Damien Querlioz, Yoshua Bengio, and Benjamin Scellier. Updates of equilibrium prop match gradients of backprop through time in an rnn with static input. Advances in neural information processing systems, 32, 2019.   \nBeren Millidge, Alexander Tschantz, Christopher L Buckley, and Anil Seth. Activation relaxation: A local dynamical approximation to backpropagation in the brain. arXiv preprint arXiv:2009.05359, 2020.   \nRajesh PN Rao and Dana H Ballard. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nature neuroscience, 2(1):79\u201387, 1999.   \nBeren Millidge, Alexander Tschantz, and Christopher L Buckley. Predictive coding approximates backprop along arbitrary computation graphs. Neural Computation, 34(6):1329\u20131368, 2022a.   \nYuhang Song, Thomas Lukasiewicz, Zhenghua Xu, and Rafal Bogacz. Can the brain do backpropagation?\u2014exact implementation of backpropagation in predictive coding networks. Advances in neural information processing systems, 33:22566, 2020.   \nTommaso Salvatori, Yuhang Song, Zhenghua Xu, Thomas Lukasiewicz, and Rafal Bogacz. Reverse differentiation via predictive coding. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 8150\u20138158, 2022.   \nRobert Rosenbaum. On the relationship between predictive coding and backpropagation. Plos one, 17(3):e0266102, 2022.   \nSiavash Golkar, Tiberiu Tesileanu, Yanis Bahroun, Anirvan Sengupta, and Dmitri Chklovskii. Constrained predictive coding as a biologically plausible model of the cortical hierarchy. Advances in Neural Information Processing Systems, 35:14155\u201314169, 2022.   \nArild N\u00f8kland. Direct feedback alignment provides learning in deep neural networks. Advances in neural information processing systems, 29, 2016.   \nYoshua Bengio. How auto-encoders could provide credit assignment in deep networks via target propagation. arXiv preprint arXiv:1407.7906, 2014.   \nAlexander Meulemans, Francesco Carzaniga, Johan Suykens, Jo\u00e3o Sacramento, and Benjamin F Grewe. A theoretical framework for target propagation. Advances in Neural Information Processing Systems, 33:20024\u201320036, 2020.   \nMohamed Akrout, Collin Wilson, Peter C Humphreys, Timothy Lillicrap, and Douglas Tweed. Deep learning without weight transport. arXiv preprint arXiv:1904.05391, 2019.   \nNasir Ahmad, Marcel AJ van Gerven, and Luca Ambrogioni. Gait-prop: A biologically plausible learning rule derived from backpropagation of error. arXiv preprint arXiv:2006.06438, 2020.   \nMaxence M Ernoult, Fabrice Normandin, Abhinav Moudgil, Sean Spinney, Eugene Belilovsky, Irina Rish, Blake Richards, and Yoshua Bengio. Towards scaling difference target propagation by learning backprop targets. In International Conference on Machine Learning, pages 5968\u20135987. PMLR, 2022.   \nStanislas Dehaene, Hakwan Lau, and Sid Kouider. What is consciousness, and could machines have it? Robotics, AI, and Humanity: Science, Ethics, and Policy, pages 43\u201356, 2021.   \nErin Goddard, Thomas A Carlson, and Alexandra Woolgar. Spatial and feature-selective attention have distinct, interacting effects on population-level tuning. Journal of cognitive neuroscience, 34 (2):290\u2013312, 2022.   \nMo Shahdloo, Emin \u00c7elik, Burcu A Urgen, Jack L Gallant, and Tolga \u00c7ukur. Task-dependent warping of semantic representations during search for visual action categories. Journal of Neuroscience, 42 (35):6782\u20136799, 2022.   \nJohn K Tsotsos. A computational perspective on visual attention. MIT Press, 2021.   \nBo Pang, Yizhuo Li, Jiefeng Li, Muchen Li, Hanwen Cao, and Cewu Lu. Tdaf: Top-down attention framework for vision tasks. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 2384\u20132392, 2021.   \nShimon Ullman, Liav Assif, Alona Strugatski, Ben-Zion Vatashsky, Hila Levi, Aviv Netanyahu, and Adam Yaari. Human-like scene interpretation by a guided counterstream processing. Proceedings of the National Academy of Sciences, 120(40):e2211179120, 2023.   \nJinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, and Jingren Zhou. Qwen-vl: A frontier large vision-language model with versatile abilities. arXiv preprint arXiv:2308.12966, 2023.   \nDeyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. Minigpt-4: Enhancing vision-language understanding with advanced large language models. arXiv preprint arXiv:2304.10592, 2023.   \nWenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale N Fung, and Steven Hoi. Instructblip: Towards general-purpose visionlanguage models with instruction tuning. Advances in Neural Information Processing Systems, 36, 2024.   \nJonathan Fiat, Eran Malach, and Shai Shalev-Shwartz. Decoupling gating from linearity. arXiv preprint arXiv:1906.05032, 2019.   \nJeffrey C Magee and Daniel Johnston. A synaptically controlled, associative signal for hebbian plasticity in hippocampal neurons. Science, 275(5297):209\u2013213, 1997.   \nNikola T Markov, Julien Vezoli, Pascal Chameau, Arnaud Falchier, Ren\u00e9 Quilodran, Cyril Huissoud, Camille Lamy, Pierre Misery, Pascale Giroud, Shimon Ullman, et al. Anatomy of hierarchy: feedforward and feedback pathways in macaque visual cortex. Journal of Comparative Neurology, 522(1):225\u2013259, 2014.   \nJonathan H Cornford, Marion S Mercier, Marco Leite, Vincent Magloire, Michael H\u00e4usser, and Dimitri M Kullmann. Dendritic nmda receptors in parvalbumin neurons enable strong and stable neuronal assemblies. Elife, 8:e49872, 2019.   \nYann LeCun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.   \nHan Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.   \nAlex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.   \nShanshan Qin, Nayantara Mudur, and Cengiz Pehlevan. Contrastive similarity matching for supervised learning. Neural computation, 33(5):1300\u20131328, 2021.   \nBeren Millidge, Yuhang Song, Tommaso Salvatori, Thomas Lukasiewicz, and Rafal Bogacz. Backpropagation at the infinitesimal inference limit of energy-based models: Unifying predictive coding, equilibrium propagation, and contrastive hebbian learning. arXiv preprint arXiv:2206.02629, 2022b.   \nVitaly Kurin, Alessandro De Palma, Ilya Kostrikov, Shimon Whiteson, and Pawan K Mudigonda. In defense of the unitary scalarization for deep multi-task learning. Advances in Neural Information Processing Systems, 35:12169\u201312183, 2022.   \nRiadh Ayachi, Mouna Afif, Yahia Said, and Mohamed Atri. Strided convolution instead of max pooling for memory efficiency of convolutional neural networks. In Proceedings of the 8th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT\u201918), Vol. 1, pages 234\u2013243. Springer, 2020.   \nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.   \nSergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International conference on machine learning, pages 448\u2013456. PMLR, 2015.   \nLiyang Liu, Yi Li, Zhanghui Kuang, J Xue, Yimin Chen, Wenming Yang, Qingmin Liao, and Wayne Zhang. Towards impartial multi-task learning. iclr, 2021.   \nOzan Sener and Vladlen Koltun. Multi-task learning as multi-objective optimization. Advances in neural information processing systems, 31, 2018.   \nZhao Chen, Jiquan Ngiam, Yanping Huang, Thang Luong, Henrik Kretzschmar, Yuning Chai, and Dragomir Anguelov. Just pick a sign: Optimizing deep multitask models with gradient sign dropout. Advances in Neural Information Processing Systems, 33:2039\u20132050, 2020.   \nTianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, and Chelsea Finn. Gradient surgery for multi-task learning. Advances in Neural Information Processing Systems, 33: 5824\u20135836, 2020.   \nBaijiong Lin, Feiyang Ye, and Yu Zhang. A closer look at loss weighting in multi-task learning. arXiv preprint arXiv:2111.10603, 2021.   \nStephen Grossberg. Competitive learning: From interactive activation to adaptive resonance. Cognitive science, 11(1):23\u201363, 1987.   \nDario L Ringach. Mapping receptive fields in primary visual cortex. The Journal of Physiology, 558 (3):717\u2013728, 2004.   \nYann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436\u2013444, 2015.   \nJonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural networks. arXiv preprint arXiv:1803.03635, 2018.   \nSara Sabour, Nicholas Frosst, and Geoffrey E Hinton. Dynamic routing between capsules. Advances in neural information processing systems, 30, 2017.   \nZiwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of the IEEE international conference on computer vision, pages 3730\u20133738, 2015.   \nSebastian Ruder. An overview of gradient descent optimization algorithms. arXiv preprint arXiv:1609.04747, 2016.   \nEran Malach, Gilad Yehudai, Shai Shalev-Schwartz, and Ohad Shamir. Proving the lottery ticket hypothesis: Pruning is all you need. In International Conference on Machine Learning, pages 6682\u20136691. PMLR, 2020.   \nXiaohan Chen, Yu Cheng, Shuohang Wang, Zhe Gan, Jingjing Liu, and Zhangyang Wang. The elastic lottery ticket hypothesis. Advances in Neural Information Processing Systems, 34:26609\u201326621, 2021.   \nAri Morcos, Haonan Yu, Michela Paganini, and Yuandong Tian. One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers. Advances in neural information processing systems, 32, 2019.   \nVivek Ramanujan, Mitchell Wortsman, Aniruddha Kembhavi, Ali Farhadi, and Mohammad Rastegari. What\u2019s hidden in a randomly weighted neural network? In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11893\u201311902, 2020.   \nHidenori Tanaka, Daniel Kunin, Daniel L Yamins, and Surya Ganguli. Pruning neural networks without any data by iteratively conserving synaptic flow. Advances in Neural Information Processing Systems, 33:6377\u20136389, 2020.   \nXin Yu, Thiago Serra, Srikumar Ramalingam, and Shandian Zhe. The combinatorial brain surgeon: Pruning weights that cancel one another in neural networks. In International Conference on Machine Learning, pages 25668\u201325683. PMLR, 2022. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "A Appendix ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A.1 Equivalent to the backpropagation algorithm ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we give a detailed explanation for the equivalence between the proposed CounterHebbian (CH) learning and Back-Propagation (BP), discussed in section 4.1. BP is a key component of current learning algorithms for artificial neural networks, and modern deep learning models are typically optimized using end-to-end BP and a global loss function [LeCun et al., 2015]. BP is an efficient algorithm to compute gradients, designed especially for deep neural networks [Rumelhart et al., 1986]. The algorithm uses the chain rule to back-propagate error signals through the network, thus computing the gradients of a loss function $L$ with respect to all parameters through a single backward pass. ", "page_idx": 15}, {"type": "text", "text": "A.1.1 Symmetric weights ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Given a feedforward BU network architecture, as described in section 3, Then, the BP backward pass propagates error signals $\\delta$ through the network from the output layer according to: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\delta_{l-1}:=\\frac{\\partial f_{l}}{\\partial h_{l-1}}\\delta_{l}=\\sigma^{\\prime}(h_{l-1})W_{l}^{T}\\delta_{l}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Where the initial $\\delta$ values, that correspond to the output layer, are the derivative of the loss with respect to the output layer: $\\begin{array}{r}{\\delta_{L}=\\frac{\\partial\\mathrm{Loss}}{\\partial h_{L}}}\\end{array}$ \u2202\u2202LhoLss . This construction of \u03b4 enables an easy way to compute the gradients with respect to each parameter: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\nabla\\mathrm{Loss}(W_{l})=\\frac{\\partial L}{\\partial W_{l}}=\\delta_{l}h_{l-1}^{T}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Given the following conditions: ", "page_idx": 15}, {"type": "text", "text": "\u2022 Symmetric BU and TD weights, $W=\\bar{W}^{T}$   \n\u2022 The BU network uses ReLU non-linearity, $\\sigma=R e L U$   \n\u2022 The error function computes the negative gradients of a loss function $L$ with respect to the BU output, $\\begin{array}{r}{e=e r r o r(\\bar{y},\\tilde{y})=-\\frac{\\partial\\bar{L}(y,\\tilde{y})}{\\partial y}}\\end{array}$   \n\u2022 The TD network uses GaLU non-linearity, $\\bar{\\sigma}=G a L U$ , and bias-blocking mode (see Section 3.1) ", "page_idx": 15}, {"type": "text", "text": "The TD process done in the backward step in Algorithm 1 makes the exact same computation as BP at each layer: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\bar{h}_{l-1}:=\\mathrm{GaLU}(\\bar{W}_{l}\\bar{h}_{l})=\\sigma^{\\prime}(h_{l-1})W_{l}^{T}\\bar{h}_{l}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "This similarity is since the BU and TD weights are symmetric, i.e. $W_{l}^{T}=\\bar{W}_{l}$ , and the GaLU function effectively applies a product of $x$ with an indicator function which is exactly the gradient of the ReLU function, thus the GaLU operation is equivalent to multiplication with the derivatives of the BU ReLU function. ", "page_idx": 15}, {"type": "text", "text": "Therefore, since the input to the TD network is the negative derivative of the loss function with respect to the output, the TD neurons have the same values as the BP signals, up to a different sign: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\bar{h}_{l}=-\\delta_{l}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "As a result, the update derived from our CH learning is equivalent to BP in this symmetric case and also performs a Gradient Descent (GD) update: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\Delta W_{l}=\\eta\\bar{h}_{l}h_{l-1}^{T}=-\\eta\\delta_{l}h_{l-1}^{T}=-\\eta\\nabla\\mathrm{Loss}(W_{l})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Moreover, when exploring the non-symmetric case, which has the same conditions as above but the symmetric constraint, we get that CH learning approximates the BP update as the learning progresses. ", "page_idx": 15}, {"type": "text", "text": "A.1.2 Asymmetric weights ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In the asymmetric case, the BU and TD weights are initialized with different values. Consider a BU weight matrix $W$ and its counter TD weights $\\bar{W}$ , where both weights were initialized i.i.d from a uniform distribution $U[-a,a]$ , where $a$ is a small positive scalar (a common practice). At each time step $t$ during the learning, the Counter-Hebb update applies a symmetrical update (up to the transposed dimensions of the matrices): ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\Delta W^{(t)}=\\Delta\\bar{W}^{(t)}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Consequently, in each time step, the difference between the two weight matrices remains constant, and is determined by the initialization of the weight, thus is bounded: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left|W_{i j}^{(t)}-\\bar{W}_{j i}^{(t)}\\right|=\\left|\\left(W_{i j}^{(0)}+\\displaystyle\\sum_{k=1}^{t}\\Delta W_{i j}^{(k)}\\right)-\\left(\\bar{W}_{j i}^{(0)}+\\displaystyle\\sum_{k=1}^{t}\\Delta\\bar{W}_{j i}^{(k)}\\right)\\right|=}&{{}}\\\\ {=\\left|W_{i j}^{(0)}-\\bar{W}_{j i}^{(0)}\\right|<=2a}&{{}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Notably, the weight initialization scheme is controlled, therefore the value $a$ can be controlled. Furthermore, a common belief is that high-magnitude weights of a trained network, are the weights that are important for the learned task. Pruning techniques have shown that those weights alone are sufficient for achieving results as good a full model consisting of all the weights [Frankle and Carbin, 2018]. Hence, focusing on a specific important weight (that has a high magnitude) $\\left|W_{i j}^{(t)}\\right|\\gg0$ , then ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\left|\\frac{W_{i j}^{(t)}-\\bar{W}_{j i}^{(t)}}{W_{i j}^{(t)}}\\right|<=\\left|\\frac{2a}{W_{i j}^{(t)}}\\right|\\approx0\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Therefore, as the training progresses, assuming close to zero weight initialization, the difference between the BU and TD weights will be negligible for the dominant BU weights that are important for the task. Consequently, as the training proceeds, the Counter-Hebb learning gradually pushes the BU and TD weights towards symmetry, and the CH update rule approximates the BP update. ", "page_idx": 16}, {"type": "text", "text": "Moreover, we can make the weights converge to exact symmetry by adding a weight decay mechanism. Denoted the original update at time $t$ by $A(t)$ , the new updates at time $t$ will be $\\Delta W_{l}^{(t)}=A(t)\\;-$ \u03bbW (t) and \u2206W\u00af l(t)T $\\Delta\\bar{W}_{l}^{(t)T}=A(t)-\\lambda\\bar{W}_{l}^{(t)T}$ . Thus, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\left|W^{(t)}-\\bar{W}^{(t)T}\\right|=\\left|(1-\\lambda)^{t}W^{(0)}-(1-\\lambda)^{t}\\bar{W}^{(0)T}\\right|\\xrightarrow{t\\to\\infty}0\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Therefore, similarly to the results shown by Akrout et al. [2019], initializing the BU and TD weights with different values will converge to symmetric BU and TD weights, in which the CH learning is equivalent to backpropagation. Hence, in that non-symmetric case, the Counter-Hebb learning algorithm approximates the BP and approaches the exact BP. ", "page_idx": 16}, {"type": "text", "text": "A.1.3 Guided visual processing ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Extending upon the above results to the guided learning framework, under the same constraints of the symmetric case, both BP and CH learning yield identical updates. ", "page_idx": 16}, {"type": "text", "text": "The guided learning algorithm consists of two passes for prediction, a TD pass followed by a BU pass. Hence, updating this model via BP requires computing the gradients of the loss function with respect to both the TD and BU computations. ", "page_idx": 16}, {"type": "text", "text": "Notably, the first TD computation in the prediction phase, is connected to the final prediction only through the gating functions on the computation graph, see Figure 2. Moreover, the gradients of this function with respect to the gate $\\bar{x}$ are always zero. Therefore, this TD computation does not contribute any gradients to the prediction process: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\nabla\\mathrm{Loss}(\\bar{W}_{l})=\\frac{\\partial{\\cal L}}{\\partial\\bar{W}_{l}}=0\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Focusing on the BU computation, given the constraint of symmetric BU and TD weights, the results from the non-guided scenario indicate that the last TD pass in our algorithm, used for error propagation, computes the exact backpropagation signals relative to the BU computation. ", "page_idx": 17}, {"type": "text", "text": "Consequently, given the constraint of symmetric weights, for example, obtained by sharing the same weights across the two streams, the BP algorithm actually updates both the BU and TD weights according only to the gradients of the BU pass. Hence the backpropagation update is identical to the Counter-Hebb learning update, and we got an equivalence in the guided processing framework. ", "page_idx": 17}, {"type": "text", "text": "A.2 The model heads ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we describe the structure of the heads in our proposed BU-TD model. The BU-TD core network consists of two symmetric neural networks that are connected via lateral connections, as described in 3. This core network is extended by two heads: a prediction head, and an instruction head, each employing an additional small BU-TD neural network. The instruction head employs a 2-layer Multi-Layer Perceptron (MLP), while the prediction head utilizes a single linear layer. Similar to the core, the heads consist of two connected parts: one for the BU network and the other for the TD network, thus preserving the symmetrical structure and lateral connectivity of the BU-TD model. ", "page_idx": 17}, {"type": "text", "text": "This results in two pairs of symmetric heads. The first pair is for the predictions: $H_{p r e d}$ in the BU stream, and its symmetric counterpart in the TD stream $\\bar{H}_{p r e d}$ . The second pair is for the instructions: $H_{i n s t r u c t}$ in the BU stream, and its symmetric counterpart in the TD stream $\\bar{H}_{i n s t r u c t}$ The prediction head is responsible for model predictions. In the BU stream, it generates predictions based on input data, while in the TD stream, it delivers prediction error information. On the other hand, the instruction head bridges the instructional space with visual concepts. The TD stream maps task representations into the model\u2019s hidden space, while the BU stream maps the visual space into the instructional space. ", "page_idx": 17}, {"type": "text", "text": "Only one head can participate in each pass of the network (either BU pass or TD pass), where heads can be alternated, with a different head chosen in each pass. For instance in the Counter-Hebb guided learning algorithm, the first TD pass uses the instruction head, while the following two passes (BU followed by a TD) use the prediction head. ", "page_idx": 17}, {"type": "text", "text": "A.3 Datasets ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Similar to other biologically motivated learning methods, we compare CH learning with BP on standard image classification benchmarks: MNIST [LeCun et al., 1998], Fashion-MNIST [Xiao et al., 2017], and CIFAR10 [Krizhevsky et al., 2009]. In addition, we use two common multi-task learning (MTL) benchmarks, the Multi-MNIST [Sabour et al., 2017] dataset, and the CelebA [Liu et al., 2015] dataset, to evaluate the ability of our model to guide the visual process according to instruction signals. ", "page_idx": 17}, {"type": "text", "text": "Multi-MNIST, introduced by [Sabour et al., 2017] and modified by Sener and Koltun [2018], is a simple two-task supervised learning benchmark dataset constructed by uniformly sampling two overlayed MNIST [LeCun et al., 1998] digits. One digit is placed in the top-left corner, while the other is in the bottom-right corner. Each of the two overlaid images corresponds to a 10-class classification task. We generated the dataset using the code provided by Kurin et al. [2022], which samples the training set from the first 50,000 MNIST training images, and the test set from the original MNIST test set. We omitted the validation set, and the hyper-parameters were tuned based solely on the training set. ", "page_idx": 17}, {"type": "text", "text": "The CelebA dataset [Liu et al., 2015] (with standard training, and test splits) comprises more than 200,000 face images of celebrities along with annotations for 40 attributes, such as the presence of eyeglasses, gender, smiling, and more. Within the context of Multi-Task Learning research, it is frequently approached as a 40-task classification challenge, where each task involves binary classification for one of the attributes. ", "page_idx": 17}, {"type": "table", "img_path": "gJxEiRcnao/tmp/5210b6363f581c411194e88e0cccfa9b19bdcf219d6c612def292dae3c035305.jpg", "table_caption": ["Table 4: Unguided learning results: mean and standard deviation of the test accuracy (in percentages) across 10 runs. The proposed CH learning algorithm is compared with BP and other biological state-of-the-art methods. The baseline results were taken from Bozkurt et al. [2024]. "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "A.4 Experimental settings and results ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "A.4.1 Computational resources ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "All the experiments were conducted using either NVIDIA RTX 6000 GPU or NVIDIA RTX 8000 GPU. For all experiments but CelebA, a single NVIDIA RTX 6000 GPU was used, with the experiments utilizing only a fraction of its capacity. In the case of the CelebA dataset, either a single NVIDIA RTX 8000 GPU or two NVIDIA RTX 6000 GPUs were used. ", "page_idx": 18}, {"type": "text", "text": "A.4.2 Image classification ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In the unguided regime, we evaluated the Counter-Hebb learning on the task of image classification and compared it with backpropagation and other biologically plausible learning algorithms under the same settings. The following results extend the results shown in Table 1 by evaluating the results obtained when learning with the MSE loss, in addition to the Cross-entropy loss reported in the main text. Note that there are two variations of CIM [Bozkurt et al., 2024], we report here the highest score obtained among the CIM experiments. ", "page_idx": 18}, {"type": "text", "text": "We repeat the same experiments as conducted in Bozkurt et al. [2024], our BU network employs a two-layer fully connected network, with a hidden layer of size 500 for both MNIST and FashionMNIST datasets and size 1,000 for CIFAR10. The standard Adam optimizer [Ruder, 2016] was used to optimize both the Cross-Entropy loss and MSE loss without any regularization. We trained for 50 epochs with an exponential learning rate decay with $\\gamma=0.95$ . The initial learning rate was $10^{-4}$ , and the batch size 20. All hyper-parameters but the initial learning rate were taken from the baseline experiments and were not optimized. The initial lr was selected from $1\\cdot10^{-3},5\\cdot10^{-4},1\\cdot10^{-4}$ according to the best test results on the CIFAR dataset The results are presented in Table 4. ", "page_idx": 18}, {"type": "text", "text": "The results, shown in table 4, empirically validate that CH learning is equivalent to BP in the symmetric case, and approximates BP in the asymmetric case for both Cross-Entropy and MSE loss. Furthermore, the proposed asymmetric CH learning method shows a significantly smaller gap from BP compared with the other biological learning methods. ", "page_idx": 18}, {"type": "text", "text": "A.4.3 Image classification with convolutional networks ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "The above experiments show that asymmetric CH learning approximates backpropagation well for fully connected networks (Multi-Layer Perceptron). Since biologically plausible learning methods often struggle to scale to larger networks and other types of architectures such as convolutional networks [Ernoult et al., 2022], we conducted additional experiments to assess the robustness of CH in other settings. We examine the effects of varying the number of channels in each convolution layer and adding a weight decay regularization term on performance. All other settings remain the same, with only one parameter changed at a time. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "For these experiments, we used the exact architecture and most hyper-parameters that were chosen for the Multi-MNIST benchmark. We ran two-layer convolutional networks on the MNIST and CIFAR10 benchmarks. Unlike the guided experiments, conducted on the Multi-MNIST benchmark, in these experiments, we used 32 channels for the convolution layers and increased the batch size to 256 for both MNIST and CIFAR10. The models were trained for 100 epochs, although most converged much faster. ", "page_idx": 19}, {"type": "text", "text": "The results shown in Figures 3, 4, 5, 6, compare different weight decay values and show that CH learning in the asymmetric case approximates the symmetric case (which is equivalent to backpropagation). Furthermore, in the backpropagation case, we observed a significant degradation in performance when increasing the weight decay term, up to the level where the model is not learning and the performances are near chance. Surprisingly, the asymmetric case is much more robust to this effect. ", "page_idx": 19}, {"type": "image", "img_path": "gJxEiRcnao/tmp/cb09eecd54f43861a0ad2c10b22e3ca59f6e5faf273b33a7ae9b4ad8d9d95d6e.jpg", "img_caption": ["Figure 3: MNIST results: comparing different weight decay values and presenting the mean performance including std per training epoch averaged across 5 runs. "], "img_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "gJxEiRcnao/tmp/907c6b560fd33bf50d94af043184ddeefe453ad75cb623f65d8530f1113a8fb2.jpg", "img_caption": ["Figure 4: MNIST results: comparing different weight decay values and presenting the mean performance including std per training epoch averaged across 5 runs. Focusing on less weight decay factors, and starting from the 4th iteration for better visualization of the differences "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "gJxEiRcnao/tmp/98043307c41dd314bf921a92af42bded35441ab55692057b4fe2a7d576af5b1f.jpg", "img_caption": ["Figure 5: CIFAR10 results: comparing different weight decay values and presenting the mean performance including std per training epoch averaged across 5 runs. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "gJxEiRcnao/tmp/84a39c7a7c1271624c17df82d603d1c280f05d820949117069bc746277d8f15a.jpg", "img_caption": ["Figure 6: CIFAR10 results: comparing different weight decay values and presenting the mean performance including std per training epoch averaged across 5 runs. Focusing on less weight decay factors, and starting from the 4th iteration for better visualization of the differences "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "gJxEiRcnao/tmp/24416c1e6a94c94aa4a62abe0e43c3080008c0e7e1774ee7ef6d1fd018c80f3a.jpg", "img_caption": ["Figure 7: MNIST results: comparing different channels and presenting the mean performance including std per training epoch averaged across 5 runs. "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "gJxEiRcnao/tmp/70419f06c06fc13018b79c687528a6780df83914e329cfb9df5f31c849b03dcd.jpg", "img_caption": ["Figure 8: MNIST results: comparing different channels and presenting the mean performance including std per training epoch averaged across 5 runs. Starting from the 10th iteration for better visualization of the differences "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "gJxEiRcnao/tmp/8356d74cb019a605dd27ac0a0d77a8a36c5d23097670e5e66a805a5e93c8fee7.jpg", "img_caption": ["Figure 9: CIFAR results: comparing different channels and presenting the mean performance including std per training epoch across 5 runs. "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "A.4.4 Guided visual processing settings ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In the guided experiments, we evaluate our model on Multi-MNIST and CelebA, two common multi-task learning (MTL) benchmarks. Since current biological methods are not capable of guided processing, we compare CH with state-of-the-art non-biological optimization methods as reported by Kurin et al. [2022], replicating their setup and use their reported results. ", "page_idx": 25}, {"type": "text", "text": "However, in contrast to the baseline multi-task learning methods, we do not use any learning \u2019tricks\u2019 such as dropout layers, regularization, or special optimizers. Instead, our model is trained straightforwardly using the Adam optimizer [Ruder, 2016]. Another distinction from the baseline methods is that we do not use a validation set. As a result, we do not use an early stopping mechanism, and report the final results obtained from the last epoch which might introduce some noisiness. Furthermore, all hyper-parameters were only lightly tuned based solely on the training set. ", "page_idx": 25}, {"type": "text", "text": "A.4.5 Multi-MNIST ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Similar to the baseline experiments conducted in [Kurin et al., 2022], our BU network employs a simple architecture composed of 2 convolutional layers followed by a single fully-connected layer and ReLU non-linearity, along with an additional fully-connected layer as the decoder. Each convolution layer includes 100 channels, and a $5\\times5$ kernel (a single stride and no padding). Similar to the baseline, the last fully connected layer size is 50. Additionally, to support the BU-TD structure, we replace all max-pool layers with strided convolution layers. The strided convolution layers have $2\\times2$ kernel size with a stride of 2 (similarly to the max pool operation). ", "page_idx": 25}, {"type": "text", "text": "The standard Adam optimizer [Ruder, 2016] was used to optimize the Cross-Entropy loss without any regularization, as opposed to the baseline. Similar to the compared methods, we trained for 100 epochs with an exponential learning rate decay with $\\gamma=0.95$ . The initial learning rate was $5\\cdot10^{-4}$ , and the batch size was 64. We have chosen the learning rate from [0.005, 0.001, 0.0005, 0.0001] based on the convergence rate on the train set. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "In the experiments below, we keep all the settings above and evaluate the impact of using a single decoder as well as varying the number of channels in each convolution layer on the performance. The results shown in Figures 10, 11 demonstrate the robustness of the instruction-based method in a vanilla setting (as opposed to the baselines compared in the main text). ", "page_idx": 26}, {"type": "text", "text": "We observe that increasing the capacity of the model (number of channels) (Fig 10) increases the performance. Interestingly, in the asymmetric case, further increasing the capacity beyond a certain point reduces the performance. ", "page_idx": 26}, {"type": "text", "text": "Furthermore, when the model uses a single decoder (Fig 11) for both tasks, similar performances are maintained. This is a very important finding that highlights the ability of the TD stream to guide the BU stream. When employing a single decoder, the same network is used for both tasks (there are no task-specific parameters), thus the model cannot rely on task-specific parameters to handle multiple tasks. ", "page_idx": 26}, {"type": "image", "img_path": "gJxEiRcnao/tmp/253b65478185872b3e465451eede60d17cd4baa4c621984d8d55b6f7bafeff65.jpg", "img_caption": ["Figure 10: Multi-MNIST results: mean and std of the average task accuracy and loss per training epoch (starting from the 10th). Comparing different numbers of channels. On the left is the number of channels at the first convolution layer, while on the right is the number of channels at the second layer "], "img_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "gJxEiRcnao/tmp/c6e4bd26d48a03cd9ce739c8f7cc90e54cf84e83a431761f46a53d900b3b8ad7.jpg", "img_caption": ["Figure 11: Multi-MNIST (single decoder) results: mean and std of the average task accuracy and loss per training epoch (starting from the 10th). Comparing different number of channels when the model uses a single decoder. "], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "A.4.6 CelebA", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "As done in previous work [Kurin et al., 2022], we employ a ResNet-18 [He et al., 2016] (without the final layer) with batch normalization layers [Ioffe and Szegedy, 2015], and the decoder is a single linear fully-connected layer with a single neuron output for binary classification. Additionally, we remove the last average pooling layer to support the symmetric BU-TD structure. ", "page_idx": 27}, {"type": "text", "text": "Batch normalization operates without reliance on learnable parameters, instead utilizing aggregated statistics such as the mean activation value of neurons across multiple iterations. Consequently, we implement distinct batch normalization for the BU and TD networks, with each network gathering statistics relevant to its own operations. ", "page_idx": 27}, {"type": "text", "text": "The standard Adam optimizer [Ruder, 2016] was used to optimize the Binary-Cross-Entropy loss without any regularization. Similar to the compared methods, we trained for 50 epochs with an exponential learning rate decay with $\\gamma=0.95$ . The initial learning rate was $5\\cdot10^{-4}$ which is chosen from [0.005, 0.001, 0.0005, 0.0001] based on the convergence rate on the train set. The batch size is slightly smaller than the baselines in order to fti the GPU memory, and is set to 100 when the BU and TD networks share the same set of weights, and 64 otherwise. ", "page_idx": 27}, {"type": "text", "text": "Statistics of the average task test accuracy obtained from the last epoch (no early stopping) with 5 repetitions are reported in table 5. We compare the BU-TD model across multiple configurations, as described in Appendix A.4. In addition, we plot the test results during the training process, sampled every 5 epochs, in Figures 12, 13. ", "page_idx": 27}, {"type": "table", "img_path": "gJxEiRcnao/tmp/fd8576e32f1e93f8ee8c012bd072626adf9ee2b171bb95e81c588377ccd44ef3.jpg", "table_caption": [], "table_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "gJxEiRcnao/tmp/032f3dd097587cc2cae4cda6e9e88393d258cf9401ed711897c389764d1c0970.jpg", "img_caption": ["Table 5: CelebA results: mean and $\\overline{{95\\%}}$ confidence interval of the avg. task test accuracy (in percentages) across 5 runs. "], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "Figure 12: CelebA results: mean and std of the average task accuracy and loss on the test set per training epoch (sampled every 5 epochs). ", "page_idx": 28}, {"type": "image", "img_path": "gJxEiRcnao/tmp/074515c60c80e2f1e98aa158dfa7d9c53edab14e7e2ced4bfd03e65c04af42e5.jpg", "img_caption": ["Figure 13: CelebA results: mean and std of the average task accuracy and loss on the test set per training epoch (sampled every 5 epochs). Within this figure, we omit the results of the asymmetric model due to being far from the other models. This allows for clearer observation of the distinctions among the remaining models. Additionally, on the right, presented the results starting from the 10th epoch. "], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "The results on the CelebA dataset, which is more challenging are consistent with the Multi-MNIST results, demonstrating the BU-TD model\u2019s ability to scale and solve complex tasks through CounterHebb learning. ", "page_idx": 29}, {"type": "text", "text": "A.5 Asymmetric weights ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Weight symmetry poses a significant challenge in biological learning models, as copying weights across different locations is unrealistic in the brain, referred to as the \u2019weight transport\u2019 problem Grossberg [1987]. Therefore, unlike backpropagation, biological models use different weights for feedforward and feedback streams. ", "page_idx": 29}, {"type": "text", "text": "The experiments above showed increasing performance gaps with asymmetric weights compared to symmetric weights as task and model complexity increase. This phenomenon aligns with other biologically inspired methods. In this section, we further explore the effect of deviation weight symmetry on the model performance, focusing on both symmetry in the initialization of the weights, and symmetry in the subsequent updates. We use the terms \u2019symmetric model\u2019 for models with symmetric weight initialization and symmetric updates, \u2019asymmetric models\u2019 for weights initialized far from symmetry and symmetric updates. Additionally we introduced a new \u2019weak symmetric\u2019 scenario for models initialized symmetrically (or nearly symmetric), but are subject to noisy, asymmetric updates. For convenience, an overview of all scenarios is described in Table 6. ", "page_idx": 29}, {"type": "text", "text": "In the proposed weak symmetry scenario, the BU and TD weights are initialized symmetrically (or nearly symmetric), but we introduce noise to the Counter-Hebb update, simulating a more realistic case of noisy update where the BU and TD weight adjustments are not identical. Hence, the weights do not maintain symmetry during the learning. Specifically, at each update step, the update value of each weight is multiplied by a random (can be relatively large) noise from a $\\bar{\\mathcal{N}}(1,\\,\\bar{\\sigma})$ distribution, with a different random variable for each weight. It is worth noting that weak symmetry can also simulate a scenario in which weights are initialized asymmetrically with close to zero values, and by the time we start learning a task, the brain has already undergone some weight updates. ", "page_idx": 29}, {"type": "text", "text": "The results shown in Figures 14, 15 compare different magnitudes of noise applied to the CounterHebb update. It is shown that a weak symmetry is sufficient for achieving a similar performance as backpropagation (referred to as a 0 noise in the figures), even with a relatively large magnitude of noise. Since as the training progresses the results gradually become less symmetric, it demonstrates the ability of CH learning to converge to good solutions even when the BU and TD weights are not symmetric and have different values. ", "page_idx": 29}, {"type": "image", "img_path": "gJxEiRcnao/tmp/a68e941de408f231baba78fda089adceabaa54cd4f9fb3b6b3ae63cc21807ded.jpg", "img_caption": ["Figure 14: MNIST results: comparing different magnitudes of noise and presenting the mean performance including std per training epoch averaged across 5 runs. Starting from the 10th iteration for better visualization of the differences "], "img_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "gJxEiRcnao/tmp/3483af7aaed61ea9ce1e7a5b464605748da36a3b7f38ff1b219b618ef8c133c7.jpg", "img_caption": ["Figure 15: CIFAR results: comparing different magnitudes of noise and presenting the mean performance including std per training epoch averaged across 5 runs. Starting from the 10th iteration for better visualization of the differences "], "img_footnote": [], "page_idx": 31}, {"type": "text", "text": "In addition, we evaluate the weak symmetric scenario in the guided-vision settings on the MultiMNIST dataset. The results shown in Fig 16 demonstrate that an exact symmetry is not required by our model to perform similarly to backpropagation on a guided vision task, achieving similar performance despite using the TD network for both feedback propagation and guiding attention. The weak symmetry experiments achieve competitive (and even slightly higher) performances compared to exact symmetric weights. The dashed line indicates the final performance of the symmetric case. ", "page_idx": 31}, {"type": "image", "img_path": "gJxEiRcnao/tmp/37231f1e14bdea23d271991fe107d7e4d625fed2423780c8827c4c9c3d83dc9a.jpg", "img_caption": ["Figure 16: Multi-MNIST (weak symmetry) results: mean and std of the average task accuracy and loss per training epoch (starting from the 10th). Comparing different magnitudes of noise in the weak symmetry case. The dashed line indicates the final performance of the symmetric case. "], "img_footnote": [], "page_idx": 32}, {"type": "text", "text": "To investigate the effect of deviation from weight symmetry on a larger model, we further compare the different weight asymmetry settings using the same ResNet18-like architecture from the CelebA experiments. Specifically, we evaluate Counter-Hebb learning on the CIFAR10 dataset under the following scenarios: ", "page_idx": 32}, {"type": "text", "text": "\u2022 symmetric \u2022 asymmetric ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "\u2022 asymmetric with a weight decay term with magnitude of $10^{-2}$ and $10^{-3}$ \u2022 weak symmetric weights (noise std of 0.05) ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "\u2022 noisy symmetric scenario which is similar to the weak symmetry but with noise applied to the weight initialization as well to start with asymmetric weights. Here, weights were initially set symmetrically, then each weight is multiplied by random noise with an std of 0.05. ", "page_idx": 32}, {"type": "text", "text": "Additionally, we compare our model to the feedback alignment method [Lillicrap et al., 2016], as it achieved the highest performance among other biologically inspired methods in our non-guided experiments (Table 1). All models were trained for 50 epochs using the Cross Entropy loss, with a batch size was 128, learning rate of $10^{-4}$ , and an exponential learning rate decay with $\\gamma=0.95$ . ", "page_idx": 32}, {"type": "image", "img_path": "gJxEiRcnao/tmp/5e2adf3621476cc98d68540d87312b38d68fd8d628f7fe8e8943b1ea608fe9bf.jpg", "img_caption": ["Figure 17: Comparing different weight symmetry using ResNet18 on CIFAR10 and presenting the mean accuracy including std per training epoch averaged across 5 runs. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "gJxEiRcnao/tmp/9bd8672ab8a5085f1b2aa8312c9e6ab1106cb6ec52158859ab97a749794a926e.jpg", "img_caption": ["Figure 18: Comparing different weight symmetry using ResNet18 on CIFAR10 and presenting the mean accuracy including std per training epoch averaged across 5 runs. Excluding FA and starting from the 4th iteration for better visualization of the differences "], "img_footnote": [], "page_idx": 34}, {"type": "text", "text": "The results presented in Figures 17, 18 show that initial weight symmetry is more critical for approximating backpropagation performance than gradually converging to symmetry later in the learning process. The asymmetric case is worse than the symmetric case both in terms of convergence speed and final results. Applying a weight decay term, which guarantees convergence to symmetric weights, does not appear to have a significant effect or improve results. The results also show that our model demonstrates significantly better scalability compared to the feedback alignment. In contrast, both in the weak symmetric case and the noisy symmetric case, where weights do not maintain symmetry due to noise, performance remains nearly identical to the symmetric case. These results indicate that exact weight symmetry is not necessary for backpropagation approximation. ", "page_idx": 34}, {"type": "text", "text": "A.5.1 Asymmetric weights summary ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "The empirical experiments confirmed that symmetric Counter-Hebb learning is equivalent to learning with backpropagation. However, copying the same weights across different locations is unrealistic in the brain, referred to as the \u2019weight transport\u2019 problem Grossberg [1987]. Therefore, we explored the effect of deviation from weight symmetry on the model performance, focusing on both symmetry in the initialization of the weights, and symmetry in the subsequent updates. See Table 6 for an overview of these scenarios. In the asymmetric scenario, where weights are initialized far from symmetric but become more symmetric over training due to the symmetric updates, performance can approximate backpropagation on simple models and tasks. However, as task complexity and model size increase, performance begins to fall compared to backpropagation. ", "page_idx": 34}, {"type": "text", "text": "Table 6: Overview of the different weight symmetry settings used in our experiments. The columns indicate the name of the method, the weights initialization scheme, whether the updates are symmetric or noisy, the state of the weights at the end of the training, and whether the final performance is similar to learning with backpropagation in order, respectively ", "page_idx": 35}, {"type": "table", "img_path": "gJxEiRcnao/tmp/277560c6e694ec18bc98018c4bc48e13e56f6ff19cf07e52c55c6f833338dca1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 35}, {"type": "text", "text": "Adding a weight decay term guarantees convergence to weight symmetry, making the Counter-Hebb update approach the backpropagation update. Yet, the experiments show that late convergence to backpropagation alone does not ensure comparable performance. We hypothesize that, like backpropagation, Counter-Hebb and other biologically inspired learning models rely on proper weight initialization to achieve optimal results. By the time that symmetry of the weights is obtained, the weights may drift from their optimal initialization. This case will be similar to starting the standard backpropagation from non-optimal initialization conditions, leading in both cases to suboptimal performance. ", "page_idx": 35}, {"type": "text", "text": "In contrast, the weak symmetric and noisy symmetric scenarios, where weights remain close but do not converge to an exact symmetry, effectively approximate backpropagation and consistently maintain nearly identical performance. These findings suggest that exact weight symmetry is not essential for achieving performance comparable to backpropagation. Since Counter-Hebb naturally applies symmetric updates, performance appears more dependent on the initial weight configuration than on later symmetry convergence. Thus, discussions of biological feasibility in learning models may focus on achieving near-symmetric weight initialization, rather than starting with highly asymmetric weights and relying on convergence to symmetry. ", "page_idx": 35}, {"type": "text", "text": "A.6 Sub-networks analysis ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "In our experiments, the model has exhibited the capability to solve multiple tasks by assigning a distinct task-specific sub-network for each task. In this section, we analyze the resulting sub-networks focusing on the Multi-MNIST experiment, where two tasks: \"left\" and \"right\" are involved. For the purpose of this analysis, we have evaluated a BU-TD model with symmetric weights and a single decoder. Our analysis shows the characteristics of the different sub-networks learned by the model and how they evolved during the learning process. Specifically, we have extracted for each task its corresponding sub-network every 3 epochs. Then we evaluated the size of the sub-networks and examined the level of overlap between them. The analysis is presented in Fig 19. The findings collectively provide insights into the learning dynamics of the model and its ability to develop task-specific representations. ", "page_idx": 35}, {"type": "text", "text": "From the figure, several findings can be drawn: ", "page_idx": 35}, {"type": "text", "text": "\u2022 Dynamic Nature of Sub-Networks: The sub-networks exhibit changes throughout the learning process, indicating that the model adapts and refines its sub-networks representations. This adaptation occurs especially in the earlier epochs of the training. \u2022 Sparsity in Sub-Networks: A notable characteristic of the sub-networks is their sparsity (row 1)- a small percentage of active neurons. The percentage of active neurons drastically decreases at the early iterations until reaching a plateau. The level of sparsity is lower at the first layer as it represents the image signal and needs to capture a large number of pixels. \u2022 Fixed top-level hidden layer: The top-level hidden layer is obtained by passing the task via the task head function. Since we do not update the task head during the training, This layer remains fixed during the learning. \u2022 Similarity Between Sub-Networks: Despite the sparsity of the sub-networks, they demonstrate some degree of similarity (row 2). This outcome is likely due to the major correlation between the \"left\" and \"right\" tasks, as both tasks aim to identify one out of the same ten digits. The first hidden layer (layer 0) exhibits a degree of similarity, likely arising from the overlap between the two digits. The following hidden layer (layer 1) shows the least similarity. The similarity then increases as moving deeper into the network. A possible explanation could be that early layers focus on the low-level image features at different image locations (left/right), while deeper layers focus on the high-level features for the classification of the identified digit. ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 36}, {"type": "text", "text": "The results show that the sub-networks are adjusted during the process, their separation can change at different layers and can depend on the similarity of the tasks. ", "page_idx": 36}, {"type": "image", "img_path": "gJxEiRcnao/tmp/ff487aa2580089a9552cb7f9ede87d24d9aa5b640b985d0ed70edbbea49f6a1f.jpg", "img_caption": [], "img_footnote": [], "page_idx": 36}, {"type": "text", "text": "Figure 19: Analysis of the different sub-networks learned by the model and how they evolved during the learning process. We sampled the task-dependent sub-networks for each task Every 3 epochs during learning the Multi-MNIST data set. The columns in the figures represent the different hidden layers in the network, ordered from the first hidden layer on the left to the top hidden layer on the right. The X-axis of all figures represents the epochs during training. The first row shows the percentage of neurons that are being used in each sub-network for every layer. The second row shows the cosine similarity between the binary masking vectors of the two tasks, where 1 indicates an active neuron that is being used in the sub-network and 0 denotes an inactive one. ", "page_idx": 36}, {"type": "text", "text": "Therefore, the proposed method may offer some additional useful computational properties. In contrast to the compared baselines that require the full network for inference, our BU visual process is guided to operate only on a sparse sub-network, resulting in only a portion of the model that is used during inference. Consequently, after training, we can omit the unused parts of the model, resulting in a compact representation of the model, which is efficient both in terms of computation and memory. For example, we can drop approximately $80\\%$ of the network when running the model in inference on Multi-MNIST. Furthermore, the compactness indicates the capacity of the model to accommodate a larger number of tasks within the same network. ", "page_idx": 36}, {"type": "text", "text": "A.6.1 Functional sparse sub-networks ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "There has been a growing interest in the use of functional sparse sub-networks, following the LotteryTicket Hypothesis [Frankle and Carbin, 2018]. The hypothesis suggests that large dense networks contain smaller sub-networks that can be learned in isolation and match the performance of the full network on the learned task. This hypothesis has been supported by empirical evidence and was proven under certain conditions [Malach et al., 2020]. However, finding such sub-networks is challenging and is an active area of current research [Chen et al., 2021, Morcos et al., 2019, Ramanujan et al., 2020, Tanaka et al., 2020, Yu et al., 2022]. ", "page_idx": 36}, {"type": "text", "text": "In this paper, we propose to extend this hypothesis suggesting that a sufficiently large network contains multiple overlapping sub-networks, each dedicated to a different task, resembling a sparse modular architecture. Our work suggests that these sub-networks can be naturally revealed by the same top-down mechanism used for propagating feedback signals in conventional networks (backpropagation). These findings, which are inspired by the observation of a unified top-down mechanism for both learning and guiding attention, highlight the potential beneftis of the interactions between artificial intelligence and the human brain. ", "page_idx": 37}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: The abstract and introduction are clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 38}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Justification: There is a separated Limitations section dedicated to the limitations of the work. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 38}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: The paper does not include proofs. All mathematical results are provided with the proper assumptions, and a detailed explanation. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 39}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 39}, {"type": "text", "text": "Justification: We release a code for creating the proposed model and reproduce the experiments. In addition we provide detailed instructions for how to replicate the results ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 39}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 40}, {"type": "text", "text": "Justification: The code is provided in the supplemental material and will be uploaded to GitHub. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 40}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Justification: The experimental setting are presented in the core paper, and the full details are provided in the appendix. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 40}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Justification: the results are accompanied by confidence intervals achieved through multiple trials. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 40}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 41}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: The compute resources for each experiment are reported in the appendix. Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 41}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Justification: We followed the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 41}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 41}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 41}, {"type": "text", "text": "Justification: There is no societal impact of the work performed. Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 41}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 42}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 42}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 42}, {"type": "text", "text": "Justification: The paper poses no such risks ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 42}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Justification: The owners of assets used in the paper are properly credited Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 42}, {"type": "text", "text": "", "page_idx": 43}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: The code and model are well documented. The documentation is on the supplemental materials and will be upload to GitHub. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 43}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 43}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 43}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 43}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 43}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 43}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 43}]