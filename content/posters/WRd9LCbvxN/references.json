{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces the foundational denoising diffusion probabilistic models (DDPMs) which are the basis for many of the image generation and editing methods used in the current research."}, {"fullname_first_author": "Alex Nichol", "paper_title": "Glide: Towards photorealistic image generation and editing with text-guided diffusion models", "publication_date": "2021-12-01", "reason": "This work significantly advances text-guided image generation and editing using diffusion models, which is a direct precursor to the current research's approach to text-conditioned manipulation of articulated objects."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper provides a key improvement in the quality and resolution of images generated by diffusion models, which is directly relevant to the current research's focus on high-fidelity manipulation of objects in real images."}, {"fullname_first_author": "Bahjat Kawar", "paper_title": "Imagic: Text-based real image editing with diffusion models", "publication_date": "2023-06-01", "reason": "This is a closely related work that demonstrates text-based image editing using diffusion models, providing a benchmark for the current research to compare against and improve upon."}, {"fullname_first_author": "Chong Mou", "paper_title": "DragonDiffusion: Enabling drag-style manipulation on diffusion models", "publication_date": "2023-07-01", "reason": "This paper introduces drag-style manipulation on diffusion models, a technique directly relevant to and compared against the current research's method for manipulating articulated objects."}]}