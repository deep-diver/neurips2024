[{"figure_path": "D2VK206HaJ/figures/figures_1_1.jpg", "caption": "Figure 1: As shown in the figure, the ideal result of facial stylization aims to ensure the faithful restoration of facial information while also significantly deforming the facial image according to the given style image. To achieve high-quality results, it is essential to ensure that the production process not only meets the standards for good generation quality but also encompasses a compelling and evocative artistic atmosphere.", "description": "This figure shows several examples of ideal facial stylization results.  The goal is to faithfully maintain facial features while transforming the face to match the style of a given artistic image. The figure highlights the challenge of balancing the preservation of facial recognition with the artistic transformation of style.", "section": "1 Introduction"}, {"figure_path": "D2VK206HaJ/figures/figures_3_1.jpg", "caption": "Figure 2: The overall schematic diagram of ACFun consists of two parts: one is the AFun module for extracting abstract features, and the other is the CFun module for extracting concrete features. The entire training process is controlled by our carefully designed Face and Style Imagery Alignment loss. We utilized a facial description text prompt to enhance the fusion of style and facial images.", "description": "This figure shows the overall architecture of the ACFun model.  It's composed of two main modules: the Abstract Fusion Module (AFun) and the Concrete Fusion Module (CFun).  AFun extracts abstract features from the style image and facial description prompt (text), which are then used to guide the generation process within a pre-trained diffusion model. CFun extracts concrete features, refining the output and ensuring detail preservation. The entire process is optimized using a Face and Style Imagery Alignment Loss to ensure that the generated image faithfully represents both the style and the facial identity. ", "section": "3 Method"}, {"figure_path": "D2VK206HaJ/figures/figures_4_1.jpg", "caption": "Figure 3: Left: The specific insertion method and structure of our CFun. Right: Our proposed imagery latent space, where the red line represents the VQ visual space, the green line represents the imagery latent space, and the blue line represents the process of mapping the original image from the VQ space into the imagery latent space through the introduction of abstract features ea.", "description": "The left part of the figure shows the detailed architecture of the Concrete Fusion Module (CFun), illustrating how trainable parameters are inserted into the ResBlock to learn concrete visual features while avoiding drastic semantic changes.  The right part depicts the proposed imagery latent space, which integrates abstract and concrete features from both style and face images. It highlights the process of mapping original images from the VQ space to this integrated latent space using the abstract features (ea).", "section": "3.2 Face and Style Concrete Fusion Module (CFun)"}, {"figure_path": "D2VK206HaJ/figures/figures_6_1.jpg", "caption": "Figure 4: We experimented with different facial and stylistic images and compared our previous high-performance methods. It can be seen that our facial stylization results have a stronger style, while ensuring facial information while harmoniously and naturally integrating with the target style.", "description": "This figure shows a comparison of facial stylization results using the proposed ACFun method and several state-of-the-art methods.  Each row presents a style image, a face image, and the results from the ACFun model, InstantStyle, SDXL, DreamStyler, Inst, AesPA, and StyTr2. The comparison highlights that the ACFun model generates results with stronger style transfer while better preserving facial features and integrating the style naturally.", "section": "4 Experiments"}, {"figure_path": "D2VK206HaJ/figures/figures_7_1.jpg", "caption": "Figure 5: We have made more comparisons with the InstantStyle methods. Our method not only achieves good results in terms of generation quality but also has the ability to generate following text guidance.", "description": "This figure compares the results of the proposed ACFun model and the InstantStyle model on facial stylization with text prompts.  The top row shows the style image and five different face images used as input. The two rows below show the results generated by ACFun and InstantStyle respectively, for each combination of style and face image, demonstrating the effect of text prompts on style transfer.  ACFun produces results that closely match the given style while preserving facial features, whereas InstantStyle's results show more variation and less accurate style transfer. The caption highlights the ability of ACFun to generate images following text prompts, something InstantStyle struggles with.", "section": "4.3 Text-to-Image Generation"}, {"figure_path": "D2VK206HaJ/figures/figures_8_1.jpg", "caption": "Figure 6: The ablation experiment demonstrated the role of our proposed abstract and concrete features, demonstrating the effectiveness of our proposed separation of learning abstract and concrete features.", "description": "This figure shows the results of an ablation study performed to evaluate the impact of abstract and concrete features on the facial stylization process.  Four different versions of the model are compared:\n\n1. **With All Feature:** The complete model, incorporating both abstract and concrete features.\n2. **Abstract Feature:** Only the abstract features are used in the process.\n3. **Concrete Feature in Encoder:** Only concrete features are used within the encoder part of the model.\n4. **Concrete Feature in Decoder:** Only concrete features are used in the decoder part of the model.\n\nThe image pairs demonstrate that while abstract features alone generate a stylized yet blurry image, incorporating concrete features (either in the encoder or decoder, or both) significantly enhances the detail and realism of the stylized faces, especially the features related to facial expressions and identity.", "section": "4 Experiments"}, {"figure_path": "D2VK206HaJ/figures/figures_12_1.jpg", "caption": "Figure 7: Single pseudo-word Prompt vs Facial Description Prompt and Hyperparameter Analysis of Imagery Alignment Loss", "description": "This figure shows an ablation study comparing the results of using a single pseudo-word prompt versus a facial description text prompt for facial stylization, along with a hyperparameter analysis of the imagery alignment loss.  The results demonstrate the impact of these choices on the quality and stability of the generated stylized images.  The hyperparameter analysis shows how different settings for the imagery alignment loss affect the balance between style and facial features in the final output.", "section": "B Comparative Experimental Analysis"}, {"figure_path": "D2VK206HaJ/figures/figures_12_2.jpg", "caption": "Figure 7: Single pseudo-word Prompt vs Facial Description Prompt and Hyperparameter Analysis of Imagery Alignment Loss", "description": "This figure shows an ablation study comparing the results of using single pseudo-word prompts versus detailed facial description text prompts in the proposed ACFun model. It also illustrates the effect of varying hyperparameters (\u03b3 and \u03b2) in the Imagery Alignment Loss on the generated facial stylization results.  The results demonstrate that more descriptive prompts and carefully tuned hyperparameters lead to higher quality and more consistent stylization results.", "section": "B Comparative Experimental Analysis"}, {"figure_path": "D2VK206HaJ/figures/figures_12_3.jpg", "caption": "Figure 7: Single pseudo-word Prompt vs Facial Description Prompt and Hyperparameter Analysis of Imagery Alignment Loss", "description": "This figure shows the results of ablative studies on different prompt methods and hyperparameters used in the ACFun model.  The top row demonstrates the impact of using a single pseudo-word prompt versus a facial description text prompt for style transfer. The bottom row illustrates how different hyperparameter settings (\u03b3 and \u03b2) in the Imagery Alignment Loss affect the final stylized image.  Different ratios of \u03b2 and \u03b3 values are shown, showcasing the effect of balancing style information with maintaining facial features. It shows the trade off between retaining facial features and applying the style. ", "section": "3.3 Face and Style Concrete Fusion Module (CFun)"}, {"figure_path": "D2VK206HaJ/figures/figures_13_1.jpg", "caption": "Figure 1: As shown in the figure, the ideal result of facial stylization aims to ensure the faithful restoration of facial information while also significantly deforming the facial image according to the given style image. To achieve high-quality results, it is essential to ensure that the production process not only meets the standards for good generation quality but also encompasses a compelling and evocative artistic atmosphere.", "description": "This figure shows several examples of ideal facial stylization results.  The goal is to successfully transfer the style from a style image to a face image while preserving the key facial features and making the result look both artistic and realistic.  The examples highlight the challenge of balancing style transfer with faithful representation of the face.", "section": "1 Introduction"}, {"figure_path": "D2VK206HaJ/figures/figures_14_1.jpg", "caption": "Figure 9: Splicing Facial Stylization", "description": "This figure demonstrates the results of applying the proposed ACFun method to facial images that have been spliced together from different faces.  The goal is to show the ability of the model to handle unusual inputs and produce coherent stylized results. The figure shows several examples of spliced faces, the style images used, the results generated by the ACFun method, and comparisons to results obtained from the InstantStyle method.  The red boxes highlight the spliced regions in the mixed face images. The comparison with InstantStyle results highlight ACFun's ability to generate a more complete and coherent stylized result even with complex, unusual input images.", "section": "C More Stylization Results"}, {"figure_path": "D2VK206HaJ/figures/figures_15_1.jpg", "caption": "Figure 4: We experimented with different facial and stylistic images and compared our previous high-performance methods. It can be seen that our facial stylization results have a stronger style, while ensuring facial information while harmoniously and naturally integrating with the target style.", "description": "This figure shows a comparison of facial stylization results between the proposed ACFun method and other state-of-the-art methods.  Multiple pairs of style images and face images are presented, along with their corresponding stylization results from ACFun and other methods.  The caption highlights that ACFun produces results with stronger styles while maintaining facial fidelity and natural integration with the target style.", "section": "4 Experiments"}, {"figure_path": "D2VK206HaJ/figures/figures_16_1.jpg", "caption": "Figure 4: We experimented with different facial and stylistic images and compared our previous high-performance methods. It can be seen that our facial stylization results have a stronger style, while ensuring facial information while harmoniously and naturally integrating with the target style.", "description": "This figure shows a comparison of facial stylization results between the proposed ACFun method and several other state-of-the-art methods.  Multiple rows present different style images paired with corresponding face images. For each pair, the results generated by the ACFun method and other methods are shown.  The caption highlights the ACFun method's ability to generate results with stronger styles while preserving facial features and blending naturally with the target style.", "section": "4 Experiments"}]