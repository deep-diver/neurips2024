[{"figure_path": "9c3IiAWeiN/figures/figures_1_1.jpg", "caption": "Figure 1: An illustration of the IPM-LSTM approach.", "description": "This figure illustrates the IPM-LSTM approach, which integrates Long Short-Term Memory (LSTM) neural networks into an interior point method (IPM) to accelerate solving nonlinear programs (NLPs).  The IPM-LSTM approach uses LSTM networks to approximate solutions to the systems of linear equations that are computationally expensive within the standard IPM.  These approximate solutions then warm-start a standard interior point solver (like IPOPT) to further refine the solution and obtain the optimal solution.  The figure shows the LSTM networks approximating the solution of the linear system, and how that approximate solution is passed to the IPOPT solver as a warm start.", "section": "3 Approach"}, {"figure_path": "9c3IiAWeiN/figures/figures_4_1.jpg", "caption": "Figure 2: The LSTM architecture for solving min \u03a6(y).", "description": "This figure illustrates the LSTM network architecture used for approximating solutions to the linear systems within the IPM.  The architecture consists of multiple LSTM cells, each taking as input the previous estimate (y<sub>t-1</sub>) and the gradient of the loss function (\u2207\u03a6(y<sub>t-1</sub>)). The LSTM cell processes these inputs using its internal mechanisms (gates and activation functions) to produce a new estimate (y<sub>t</sub>).  This process is repeated across T LSTM cells, resulting in a final approximate solution y<sub>T</sub> to the least squares problem.  The figure also highlights the sharing of parameters across different LSTM cells and coordinates of y, which improves efficiency and generalizability.", "section": "3.3 The IPM-LSTM Approach"}, {"figure_path": "9c3IiAWeiN/figures/figures_9_1.jpg", "caption": "Figure 3: The performance analysis of IPM-LSTM on a convex QP (RHS).", "description": "This figure shows the performance analysis of IPM-LSTM on a convex QP (RHS) problem.  The four subfigures illustrate (a) Condition (5): the relation between the norm of Jkyk + Fk and \u03b7[(zk)Txk]/n; (b) Condition (6): the relation between ||yk|| and (1+\u03c3+\u03b7)||Fo(xk,\u03bbk,zk)||; (c) Residual: the value of ||Jkyk + Fk|| across different LSTM time steps; (d) Objective value: the objective value across IPM iterations. The plots show that IPM-LSTM satisfies Assumption 1 during most of the iterations and that the approximation quality of the solution to the linear systems improves with the number of LSTM time steps. Also, the objective value decreases monotonically toward the optimal value with the increasing number of iterations.", "section": "4.3 Performance Analysis of IPM-LSTM"}, {"figure_path": "9c3IiAWeiN/figures/figures_17_1.jpg", "caption": "Figure 3: The performance analysis of IPM-LSTM on a convex QP (RHS).", "description": "This figure presents four subplots that analyze the performance of the IPM-LSTM algorithm on a convex quadratic program (QP) with 100 variables, 50 inequality constraints, and 50 equality constraints.  Plot (a) shows the progress of ||Jkyk + Fk|| (the residual of the linear system at each iteration k) compared to \u03b7[(zk)Txk]/n (a condition for convergence of the algorithm) during IPM iterations.  Plot (b) shows the progress of ||yk|| (the norm of the approximate solution) versus a bound on it related to the optimality gap. Plot (c) shows how the residual of the linear system decreases as the number of LSTM time steps increases, illustrating that LSTM networks improve solution quality with more time steps. Finally, plot (d) illustrates the convergence of the IPM-LSTM algorithm, showing that the objective function value decreases monotonically and converges toward the optimal value.", "section": "4.3 Performance Analysis of IPM-LSTM"}, {"figure_path": "9c3IiAWeiN/figures/figures_18_1.jpg", "caption": "Figure 1: An illustration of the IPM-LSTM approach.", "description": "This figure illustrates the IPM-LSTM approach, showing how Long Short-Term Memory (LSTM) neural networks are integrated into an interior point method (IPM) to approximate solutions to linear systems. The approximated solutions are then used to warm-start an interior point solver (IPOPT), leading to a more efficient solution of the nonlinear program (NLP).  The figure shows the LSTM cells approximating the solution to the linear system, which is then passed to the IPOPT solver as a warm start. The IPM-LSTM approach combines machine learning techniques with a classic optimization algorithm for improved performance.", "section": "3 Approach"}, {"figure_path": "9c3IiAWeiN/figures/figures_18_2.jpg", "caption": "Figure 1: An illustration of the IPM-LSTM approach.", "description": "This figure illustrates the IPM-LSTM approach, showing how an LSTM neural network approximates solutions to linear systems within an Interior Point Method (IPM). The LSTM's output is then used to warm-start the IPOPT solver, accelerating the overall NLP solving process.  The diagram shows the IPM-LSTM architecture, highlighting the integration of LSTM cells into the main IPM algorithm to approximate solutions and improve efficiency.", "section": "3 Approach"}]