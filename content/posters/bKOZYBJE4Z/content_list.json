[{"type": "text", "text": "Causal Contrastive Learning for Counterfactual Regression Over Time ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Mouad El Bouchattaoui \u22171,2, Myriam Tami1, Benoit Lepetit2, and Paul-Henry Courn\u00e8de1 ", "page_idx": 0}, {"type": "text", "text": "1Paris-Saclay University, CentraleSup\u00e9lec, MICS Lab, Gif-sur-Yvette, France 2Saint-Gobain, Paris, France ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Estimating treatment effects over time holds significance in various domains, including precision medicine, epidemiology, economy, and marketing. This paper introduces a unique approach to counterfactual regression over time, emphasizing long-term predictions. Distinguishing itself from existing models like Causal Transformer, our approach highlights the efficacy of employing RNNs for long-term forecasting, complemented by Contrastive Predictive Coding (CPC) and Information Maximization (InfoMax). Emphasizing efficiency, we avoid the need for computationally expensive transformers. Leveraging CPC, our method captures long-term dependencies in the presence of time-varying confounders. Notably, recent models have disregarded the importance of invertible representation, compromising identification assumptions. To remedy this, we employ the InfoMax principle, maximizing a lower bound of mutual information between sequence data and its representation. Our method achieves state-of-the-art counterfactual estimation results using both synthetic and real-world data, marking the pioneering incorporation of Contrastive Predictive Encoding in causal inference. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "It\u2019s vital in real-world applications to estimate potential responses, i.e., responses under hypothetical treatment strategies. Individuals show diverse responses to the same treatment, emphasizing the need to quantify individual response trajectories. This enables personalized interventions, enhancing decision-making efficacy. In medical contexts, precise response estimation enables tailored treatments for patients [2, 70, 49]. This paper focuses on counterfactual regression over time, estimating responses under hypothetical treatment plans based on individual records, including past covariates, responses, and treatment sequences up to the current prediction time [64, 62]. In addressing the challenges of this time-varying setting, we tackle: (1) Time-dependent confounding [55]: confounders influenced by past treatment, impacting subsequent treatments and responses. (2) Selection bias: imbalanced covariate distributions across treatment regimes in observational data, requiring time-aware handling beyond methods in static settings [64, 67, 41]. (3) Long-term dependencies: enduring interdependencies among covariates, treatments, and responses, enabling long-range interactions [15, 54]. ", "page_idx": 0}, {"type": "text", "text": "Recent advancements in neural networks, such as Recurrent Marginal Structural Networks (RMSNs) [42], Counterfactual Recurrent Networks (CRN) [7], and G-Net [39], have tackled these causal inference challenges. However, their reliance on RNNs limits their ability to capture long-term dependencies. Recent studies [48] propose integrating transformers to better represent temporal dynamics. Rather than viewing this as a limitation of RNNs, we see it as an opportunity to emphasize their strengths. We design specific architectures for counterfactual regression over large horizons, avoiding complex, hard-to-interpret models like transformers. Our approach leverages the computational efficiency of RNNs, incorporating Contrastive Predictive Coding (CPC) [52, 29] for learning data history representations. This enhances model performance while maintaining efficiency, offering a compelling alternative to transformer-based approaches. Furthermore, we usually formulate identification assumptions of counterfactual responses over the original process history space (Appendix B.1). However, these assumptions may not hold in the representation space for arbitrary functions. Since identification often involves conditional independence, it applies when using an invertible representation function. Current models for time-varying settings [42, 7, 48] do not enforce representation invertibility. To address this, instead of adding complexity with a decoder, we implicitly push the history process to be \"reconstructable\" from the encoded representation by maximizing Mutual Information (MI) between representation and input, following the InfoMax principle [43], akin to Deep InfoMax [32]. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "2 Contributions ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Our approach is inspired by self-supervised learning using MI objectives [32]. We aim to maximize MI between different views of the same input, introducing counterfactual regression over time through CPC to capture long-term dependencies. Additionally, we propose a tractable lower bound to the original InfoMax objectives for more efficient representations. This is challenging due to the sequential nature and high dimensionality, marking a novelty. We demonstrate the importance of regularization terms via an ablation study. Previous work leveraging contrastive learning for causal inference applies only to the static setting with no theoretical grounding [16]. To our knowledge, we frame for the first time the representation balancing problem from an information-theoretic perspective and show that the suggested adversarial game (Theorem 5.4) yields theoretically balanced representations using the Contrastive Log-ratio Upper Bound (CLUB) of MI, computed efficiently. Key innovations of our Causal CPC model include: (1) We showcase the capability of leveraging CPC to capture long-term dependencies in the process history using InfoNCE [25, 26, 52], an unexplored area in counterfactual regression over time where its integration into process history modeling is not straightforward in causality. (2) We enforce input reconstruction from representation by contrasting the representation with its input. Such quality is generally overlooked in baselines, yet it ensures that confounding information is retained, preventing biased counterfactual estimation. (3) Applying InfoMax to process history while respecting its dynamic nature is challenging. We provide a tractable lower bound to the original InfoMax problem, also bringing theoretical insights on the bound\u2019s tightness. (4) We suggest minimizing an upper bound on MI between representation and treatment to make the representation non-predictive of the treatment, using the CLUB of MI [13]. This novel information-theoretic perspective results in a theoretically balanced representation across all treatment regimes. (5) By using a simple Gated Recurrent Unit (GRU) layer [14] as the model backbone, we demonstrate that well-designed regularizations can outperform more complex models like transformers. Finally, our experiments on synthetic data (cancer simulation [24]) and semi-synthetic data based on real-world datasets (MIMIC-III [35]) show the superiority of Causal CPC at accurately estimating counterfactual responses. ", "page_idx": 1}, {"type": "text", "text": "3 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Models for Counterfactual Regression Through Time Traditionally, causal inference addresses time-varying confounders using Marginal Structural Models (MSMs) [64], which rely on inverse probability of treatment weighting [62]. However, MSMs can yield high variance estimates, especially with extreme values, and are limited to pooled logistic regression, impractical for high-dimensional, dynamic data. RMSNs [41] enhance MSMs by integrating RNNs for propensity and outcome modeling. CRN [7] employs adversarial domain training with a gradient reversal layer [23] to establish a treatment-invariant representation space, reducing bias induced by time-varying confounders. Similarly, G-Net [39] combines $\\mathrm{g}$ -computation and RNNs to predict counterfactuals in dynamic treatment regimes. Causal Transformer (CT) [48] uses transformers to estimate counterfactuals over time and handles selection bias by learning a treatment-invariant representation via Counterfactual Domain Confusion loss (CDC) [78]. These models, like ours, assume sequential ignorability [62], in contrast to a body of work which does not fully verify our assumptions [45, 73, 68, 60, 80, 79, 8, 28, 12, 38, 58, 69, 19, 10, 31, 34, 6, 11, 82, 22], which we discuss in detail in Appendix C.1.2. In contrast, we introduce a contrastive learning approach to capture long-term dependencies while maintaining a simple model and ensuring high computational efficiency in both training and prediction. This demonstrates that simple models with well-designed regularization terms can still achieve high prediction quality. Additionally, previous works [62, 64, 41, 39, 48] did not consider the role of invertible representation in improving counterfactual regression. Here, we introduce an InfoMax regularization term to make our encoder easier to invert. Appendix C.1 provides a detailed overview of counterfactual regression models. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "InfoMax Principle The InfoMax principle aims to learn a representation that maximizes MI with its input [43, 5]. Estimating MI for high-dimensional data is challenging, often addressed by maximizing a simple and tractable lower bound on MI [32, 56, 40]. Another approach involves maximizing MI between two lower-dimensional representations of different views of the same input [3, 29, 75, 77], offering a more practical solution. We adopt this strategy by dividing our process history into two views, past and future, and maximizing a tractable lower bound on MI between them. This encourages a \"reconstructable\" representation of the process history. To our knowledge, the only work applying an InfoMax approach to counterfactual regression, albeit in static settings, is [16]. They propose maximizing MI between an individual\u2019s representation and a global representation, aggregating information from all individuals into a single vector. However, the global representation lacks clarity and interpretability, raising uncertainties about its theoretical underpinnings in capturing confounders. Furthermore, there\u2019s a lack of theoretical analysis on how minimizing MI between individual and treatment-predictive representations could yield a treatment-invariant representation. As a novelty, we extend the InfoMax principle to longitudinal data, providing a theoretical guarantee of learning balanced representations. Appendix C.2 discusses self-supervision and MI, with all proofs in Appendix G. ", "page_idx": 2}, {"type": "text", "text": "4 Problem Formulation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Setup In the framework of Potential Outcomes (PO) [65], and following [63], we track a cohort of individuals (units) $i\\,\\in\\,\\{1,2,\\dots\\},N\\}$ over $t_{m a x}$ time steps. At each time $t\\ \\in$ $\\{1,2,\\dots,t_{m a x}\\}$ , we observe the following: (1) Discrete treatment $W_{i t}\\in\\mathcal{W}=\\{0,1,\\ldots,K-1\\}$ , e.g., in medical contexts, $W_{i t}$ may represent treatments like radiotherapy or chemotherapy. (2) Outcome of interest $Y_{i t}\\in\\mathcal{Y}\\subset\\mathbb{R}$ , such as tumor volume. (3) Time-varying context $\\mathbf{X}_{i t}\\,\\in\\,\\mathcal{X}\\,\\subset\\,\\mathbb{R}^{d_{x}}$ , containing information about the individual that may influence treatment decisions and outcomes. $\\mathbf{X}_{i t}$ is a $d_{x}$ -dimensional vector of confounders, such as health records or clinical measurements. (4) Static confounders $\\mathbf{V}\\in\\mathcal{V}\\subset\\mathbb{R}^{d_{v}}$ , such as gender, which remain constant over time. (5) Partially observed potential outcomes $Y_{i t}(\\omega_{i,\\leq t})$ , representing the outcomes that would have been observed for individual $i$ at time $t$ under treatment sequence $\\omega_{i,\\le t}\\,=\\,(\\omega_{i,1},\\dots,\\omega_{i,t})\\,\\in\\,\\mathcal{W}^{t}$ . We define the history process up to time $t+1$ as $\\mathbf{H}_{t+1}=\\mathbf{\\bar{[V}},\\mathbf{X}_{\\leq t+1},W_{\\leq t},Y_{\\leq t}]$ , capturing all information prior to the assignment of treatment $W_{t+1}$ . This history is illustrated in the causal graph shown in Figure 1. ", "page_idx": 2}, {"type": "image", "img_path": "bKOZYBJE4Z/tmp/fcb95f3579e9e688b0951f16d915250d77b14e929c5b7b04ba05c893b7debfbd.jpg", "img_caption": ["Figure 1: Causal graph over $\\mathbf{H}_{t+1}$ "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Goal Given a training dataset $\\{\\mathbf{H}_{i,t+1},i=1,\\dots,N\\}$ sampled from the empirical distribution $\\mathbb{P}_{\\mathbf{H}_{t+1}}$ , we address the following causal inference problem: Given a history process $\\mathbf{H}_{t+1}$ , how can we efficiently estimate counterfactual responses up to time $t+\\tau$ (where $\\tau\\geq1$ is the prediction horizon) for a potential treatment sequence $\\omega_{t+1:t+\\tau}=(\\omega_{t+1},\\ldots,\\omega_{t+\\tau})$ ? The goal is to estimate the causal quantity: $\\mathbb{E}(Y_{t+\\tau}(\\omega_{t+1:t+\\tau})\\mid\\mathbf{H}_{t+1})$ , i.e., the expected outcome at time $t+\\tau$ , given the history $\\mathbf{H}_{t+1}$ and a sequence of treatments $\\omega_{t+1:t+\\tau}$ . We identify this causal quantity from observational data using the assumption of sequential ignorability [62, 42, 39, 48], which is implicitly assumed in Figure 1 and explicitly discussed in Appendix B.1. This allows us to express the counterfactual as: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{E}(Y_{t+\\tau}(\\omega_{t+1:t+\\tau})\\mid\\mathbf{H}_{t+1})=\\mathbb{E}\\left(Y_{t+\\tau}\\mid\\mathbf{H}_{t+1},W_{t+1:t+\\tau}=\\omega_{t+1:t+\\tau}\\right).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "5 Causal CPC ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "5.1 Representation Learning ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Contrastive Predictive Coding We employ contrastive learning to efficiently represent the process history $\\mathbf{H}_{t}$ . Causal forecasting over multiple time horizons requires representations that capture variability in $\\mathbf{H}_{t}$ . For short-term predictions, local features and smooth signal variations are critical, while long-term predictions rely on capturing global structures and long-term dependencies, as shared information between history and future points diminishes. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "To achieve this, we learn a representation of $\\mathbf{H}_{t}$ that predicts future components over multiple time steps. For each horizon $j~=~1,\\ldots,\\tau$ , future components are defined as $\\mathbf{U}_{t+j}\\;\\;=\\;\\;$ $[\\mathbf{V},\\mathbf{X}_{t+j},W_{t+j-1},Y_{t+j-1}]\\in\\mathcal{U}\\subset\\mathbb{R}^{(d_{v}+d_{x}+K+1)}$ . First, local features are extracted by encoding $[{\\bf V},{\\bf X}_{t},W_{t-1},Y_{t-1}]$ into $\\mathbf{Z}_{t}=\\Phi_{\\theta_{1}}([\\mathbf{V},\\mathbf{X}_{t},W_{t-1},Y_{t-1}])$ . Then, the full process history $\\mathbf{H}_{t}$ is summarized into a context representation $\\mathbf{C}_{t}$ , given by an autoregressive model: $\\Phi_{\\theta_{2}}^{a r}(\\mathbf{Z}_{\\le t})=\\mathbf{C}_{t}$ , where $\\Phi_{\\theta_{2}}^{a r}$ is implemented with a GRU [14]. This results in the representation function: $\\Phi_{\\theta_{1},\\theta_{2}}(\\mathbf{H}_{t})=\\mathbf{C}_{t}$ . To train the model, we use a contrastive loss that encourages the context $\\mathbf{C}_{t}$ to predict future local features $\\mathbf{Z}_{t+1},\\ldots,\\mathbf{Z}_{t+\\tau}$ while distinguishing them from the features of other individuals. This is done by minimizing the InfoNCE loss L(jInfoNCE)for each horizon j: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}_{j}^{(I n f o N C E)}(\\theta_{1},\\theta_{2},\\Gamma_{j}):=-\\mathbb{E}_{\\mathcal{B}}\\left[\\log\\frac{\\exp(T_{j}(\\mathbf{U}_{t+j},\\mathbf{C}_{t}))}{\\sum_{l=1}^{|\\mathcal{B}|}\\exp(T_{j}(\\mathbf{U}_{l,t+j},\\mathbf{C}_{t}))}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ is a batch containing individual histories, and $\\Gamma_{j}$ is a weight matrix. The discriminator $T_{j}(.,.)$ classifies the correct future feature among negative samples from other individuals: ", "page_idx": 3}, {"type": "equation", "text": "$$\nT_{j}(\\mathbf{U}_{t+j},\\Phi_{\\theta_{1},\\theta_{2}}(\\mathbf{H}_{t}))=\\Phi_{\\theta_{1}}(\\mathbf{U}_{t+j})^{T}\\Gamma_{j}\\mathbf{C}_{t}=\\mathbf{Z}_{t+j}^{T}\\Gamma_{j}\\mathbf{C}_{t}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In practice, $\\mathbf{C}_{t}$ predicts $\\hat{\\mathbf{Z}}_{t+j}$ , and prediction quality is measured by the dot product $\\mathbf{Z}_{t+j}^{\\top}\\hat{\\mathbf{Z}}_{t+j}$ . Minimizing the InfoNCE loss $\\mathcal{L}_{j}^{(I n f o N C E)}$ provides a lower bound on the MI between the context and future features $I(\\mathbf{U}_{t+j},\\mathbf{C}_{t})$ [52]: ", "page_idx": 3}, {"type": "equation", "text": "$$\nI(\\mathbf{U}_{t+j},\\mathbf{C}_{t})\\geq\\log(|\\mathcal{B}|)-\\mathcal{L}_{j}^{(I n f o N C E)}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "For multiple forecasting horizons $j=1,2,\\dots,\\tau$ , we learn long-term dependencies by minimizing the InfoNCE loss across all horizons: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}^{C P C}(\\theta_{1},\\theta_{2},\\{\\Gamma_{j}\\}_{j=1}^{\\tau}):=\\frac{1}{\\tau}\\sum_{j=1}^{\\tau}\\mathcal{L}_{j}^{(I n f o N C E)}(\\theta_{1},\\theta_{2},\\Gamma_{j}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Thus, minimizing $\\mathcal{L}^{C P C}$ maximizes the shared information between the context and future components as shown in Eq. (5), pushing the model to capture the global structure of the process over large horizons\u2014crucial for counterfactual regression across multiple time steps: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{1}{\\tau}\\sum_{j=1}^{\\tau}I(\\mathbf{U}_{t+j},\\mathbf{C}_{t})\\geq\\log(|\\mathcal{B}|)-\\mathcal{L}^{C P C}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "InfoMax Principle We introduce a regularization term to make the context representation of the process history $\\mathbf{H}_{t}$ \"reconstructable.\" We leverage the InfoMax principle to maximize the MI between $\\mathbf{H}_{t}$ and the context $\\mathbf{C}_{t}$ . However, we avoid computing the contrastive loss between $\\mathbf{C}_{t}$ and $\\mathbf{H}_{t}$ for two main reasons. First, $\\mathbf{H}_{t}$ is a high-dimensional sequence, making the loss computation very demanding. Secondly, we are still interested in incorporating inductive bias toward capturing global dependencies, this time by pushing any subsequence to be predictive of any future subsequence within $\\mathbf{H}_{t}$ . Hence, we divide the process history into two non-overlapping views, $\\mathbf{H}_{t}^{h}:=\\mathbf{\\dot{U}}_{1:t_{0}}$ , $\\mathbf{H}_{t}^{f}:=\\mathbf{U}_{t_{0}+1:t}$ representing a historical subsequence and a future subsequence within the process history $\\mathbf{H}_{t}$ , with $t_{0}$ randomly chosen per batch. We then maximize the MI between the representations of these views, $\\mathbf{C}_{t}^{h}$ and $\\mathbf{C}_{t}^{f}$ , resulting in a lower bound to the InfoMax objective as formulated below: ition 5.1. ", "page_idx": 3}, {"type": "text", "text": "We provide an intuitive discussion of the inequality by providing an exact writing of the gap in 5.1: Theorem 5.2. ", "page_idx": 3}, {"type": "equation", "text": "$$\nI(\\mathbf{H}_{t};(\\mathbf{C}_{t}^{f},\\mathbf{C}_{t}^{h}))-I(\\mathbf{C}_{t}^{f},\\mathbf{C}_{t}^{h})=I(\\mathbf{H}_{t};\\mathbf{C}_{t}^{f}\\mid\\mathbf{C}_{t}^{h})+\\mathbb{E}_{\\mathbf{h}_{t}\\sim\\mathbb{P}_{\\mathbf{H}_{t}}}\\mathbb{E}_{\\mathbf{c}_{t}^{f}\\sim\\mathbb{P}_{\\mathbf{C}_{t}^{f}\\mid\\mathbf{h}_{t}}}\\left[D_{K L}[\\mathbb{P}_{\\mathbf{C}_{t}^{h}\\mid\\mathbf{h}_{t}}||\\mathbb{P}_{\\mathbf{C}_{t}^{h}\\mid\\mathbf{c}_{t}^{f}}]\\right].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Both terms on the RHS of Eq. (6) are positive, providing an alternative proof to Proposition 5.1. When equality holds, it implies $I({\\bf H}_{t};{\\bf C}_{t}^{f}\\mid{\\bf C}_{t}^{h})=0$ , indicating that $\\mathbf{H}_{t}$ is independent of $\\mathbf{C}_{t}^{f}$ given $\\mathbf{C}_{t}^{h}$ . This suggests that $\\mathbf{C}_{t}^{h}$ retains sufficient information from $\\mathbf{H}_{t}$ that is predictive of $\\mathbf{C}_{t}^{f}$ . The symmetry of MI also leads to the occurrence of the second term on the RHS when conditioning on $\\mathbf{C}_{t}^{f}$ . The equality in Proposition 5.1 implies $\\mathbb{P}_{\\mathbf{C}_{t}^{h}|\\mathbf{h}_{t}}=\\mathbb{P}_{\\mathbf{C}_{t}^{h}|\\mathbf{c}_{t}^{f}}$ , suggesting that $\\mathbf{C}_{t}^{f}$ efficiently encodes its subsequence while sharing maximum information with $\\mathbf{C}_{t}^{h}$ . ", "page_idx": 3}, {"type": "text", "text": "By considering the proposed variant of the InfoMax principle, we can compute a contrastive bound to $I({\\bf C}_{t}^{h},{\\bf C}_{t}^{f})$ more efficiently, as the random vectors reside in a low-dimensional space thanks to the encoding. We define a contrastive loss using InfoNCE similar to Eq. (1): ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}^{(I n f o M a x)}(\\theta_{1},\\theta_{2},\\eta):=-\\mathbb{E}_{\\boldsymbol{B}}\\left[\\log\\frac{\\exp(T_{\\eta}(\\mathbf{C}_{t}^{f},\\mathbf{C}_{t}^{h}))}{\\sum_{l=1}^{|B|}\\exp(T_{\\eta}(\\mathbf{C}_{l,t}^{f},\\mathbf{C}_{t}^{h}))}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We use a non-linear discriminator $T_{\\eta}$ parametrized by $\\eta$ (detailed in Appendix I). The representation of the past subsequence $\\mathbf{C}_{t}^{h}$ is mapped to a prediction of the future subsequence $\\hat{\\mathbf{C}}_{t}^{f}:=F_{\\eta}({\\mathbf{C}}_{t}^{h})$ and $T_{\\eta}={\\bf C}_{t}^{f}\\hat{\\bf\\Delta}\\hat{\\bf C}_{t}^{f}$ . ", "page_idx": 4}, {"type": "text", "text": "Theorem 5.2 and Proposition 5.1 justify using the loss in Eq. (7) by showing that our InfoMax simplification provides a valid lower bound. Thus, the contrastive loss in Eq. (7) is valid, as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\log(|\\mathcal{B}|)-\\mathcal{L}^{(I n f o M a x)}\\leq I(\\mathbf{C}_{t}^{h},\\mathbf{C}_{t}^{f})\\leq I(\\mathbf{H}_{t},(\\mathbf{C}_{t}^{h},\\mathbf{C}_{t}^{f})).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The \"mental model\" behind our regularization term comes from the MI, $I(\\mathbf{H}_{t},(\\mathbf{C}_{t}^{h},\\mathbf{C}_{t}^{f}))=H(\\mathbf{H}_{t})-$ $H(\\mathbf{H}_{t}\\mid\\mathbf{\\Xi}(\\mathbf{C}_{t}^{h},\\mathbf{C}_{t}^{f}))$ , which can be written using entropy. Since the entropy term is constant and parameter-free, minimizing the conditional entropy $H(\\mathbf{H}_{t}\\ |\\ \\left(\\mathbf{C}_{t}^{h},\\mathbf{C}_{t}^{f}\\right))\\,\\geq\\,0$ ensures that $\\mathbf{H}_{t}$ is almost surely a function of $({\\bf C}_{t}^{h},{\\bf C}_{t}^{f})$ (Appendix G.4, Proposition G.2). When MI is maximized, the theoretical existence of such a function suggests that the learned context $\\mathbf{C}_{t}$ can decode and reconstruct $\\mathbf{H}_{t}$ . ", "page_idx": 4}, {"type": "text", "text": "Beyond the idea of reconstruction, it was shown that the InfoNCE objective implicitly learns to invert the data\u2019s generative model under mild assumptions [86]. Recent works [18, 44] extend this insight to multi-modal settings, which can reframe our InfoMax problem: $\\mathbf{H}_{t}^{h}$ and $\\mathbf{H}_{t}^{f}$ can be seen as two coupled modalities, allowing us to identify latent generative factors up to some mild indeterminacies (e.g rotations, affine mappings). We plan to extend multi-modal causal representation learning to the longitudinal setting, where we anticipate minimizing our InfoMax objective, in the limit of infinite data, will effectively invert the data generation process up to a class of indeterminacies that we conjecture to be broader and under weaker assumptions than those in current causal representation learning literature, given our focus is on causal inference rather than the identification of causal latent variables. We initiate a formal basis for this claim in Appendix G.5. ", "page_idx": 4}, {"type": "text", "text": "5.2 Balanced representation learning ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Motivation Our goal is counterfactual regression, specifically estimating $\\mathbb{E}(Y_{t+\\tau}(\\omega_{t+1:t+\\tau})$ | $\\mathbf{H}_{t+1})$ . For simplicity, with $\\tau\\,=\\,1$ , we estimate the potential outcome for a given treatment $W_{t+1}=\\omega_{t+1}$ , where $W_{t+1}\\in\\{0,1,\\ldots,K-1\\}$ , expressed as $\\mathbb{E}(Y_{t+1}(\\omega_{t+1})\\mid\\mathbf{H}_{t+1})$ , which under standard assumptions is identified as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}(Y_{t+1}(\\omega_{t+1})\\mid\\mathbf{H}_{t+1})=\\mathbb{E}(Y_{t+1}\\mid\\mathbf{H}_{t+1},W_{t+1}=\\omega_{t+1}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The RHS can be estimated from data as $\\mathbb{E}(Y_{t+1}\\mid\\mathbf{H}_{t+1},W_{t+1})\\,=\\,f(\\mathbf{H}_{t+1},W_{t+1})$ . Since only one treatment is observed per individual at each time step, $W_{i,t+1}=\\omega_{i,t+1}$ , our model $\\hat{f}$ generates counterfactual responses by switching treatments $\\hat{f}(\\mathbf{h}_{i,t+1},\\omega_{t+1}^{\\prime})$ , where $\\omega_{t+1}^{\\prime}\\neq\\omega_{t+1}$ (e.g., chemotherapy vs. radiotherapy). The challenge is that $\\mathbf{H}_{t+1}$ and $W_{t+1}$ are not independent, introducing potential bias in counterfactual estimation [61], leading to covariate shift or selection bias. To address this, we learn a representation $\\Phi(\\mathbf{H}_{t+1})$ that enforces distributional balance during decoding. ", "page_idx": 4}, {"type": "text", "text": "Setup To mitigate selection bias, we leverage the context representation $\\mathbf{C}_{t}$ of $\\mathbf{H}_{t}$ and introduce two sub-networks: one for response prediction and one for treatment prediction, both using a mapping of the context representation: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{\\Phi}_{t}=\\mathrm{SELU}(\\mathrm{Linear}(\\mathbf{C}_{t}))=\\Phi_{\\theta_{R}}(\\mathbf{H}_{t}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where SELU represents the Scaled Exponential Linear Unit [37], and $\\theta_{R}$ denotes all parameters of the representation learner, i.e., $\\theta_{R}=[\\theta_{1},\\theta_{2}]$ . Following [7, 48], our objective is to learn a representation that accurately predicts outcomes while remaining distributionally balanced across all possible treatment choices $W_{t}=0,1,\\ldots,K-1$ . To achieve this, we frame the problem as an adversarial game: one network learns to predict the next treatment from the representation, while a regularization term ensures that the representation is non-predictive of the treatment. ", "page_idx": 4}, {"type": "image", "img_path": "bKOZYBJE4Z/tmp/8cdeaa92d4541cf014542bed1c9a990e3de88bf07909c811ac8240d58f30f66d.jpg", "img_caption": ["Figure 2: Causal CPC architecture: The left shows the encoder, which learns context $\\mathbf{C}_{t}$ from process history $\\mathbf{H}_{t}$ , with CPC and InfoMax objectives used for pretraining. The right shows the decoder, which autoregressively predicts the future outcome sequence from $\\mathbf{C}_{t}$ . "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Factual response prediction Since we intend to predict counterfactual responses for $\\tau$ steps ahead in time, we train a decoder to predict the factual responses $Y_{t+1},\\ldots,Y_{t+\\tau}$ given the sequence of treatments $(W_{t+1},\\ldots,W_{t+\\tau})$ . We minimize the negative conditional likelihood ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathcal{L}_{Y}(\\theta_{R},\\theta_{Y})=-\\log p_{\\theta_{Y}}\\!\\left(y_{t+1:t+\\tau}\\mid\\Phi_{t},\\omega_{t+1:t+\\tau}\\right)}\\\\ {\\displaystyle=-\\sum_{j=1}^{\\tau}\\log p_{\\theta_{Y}}\\!\\left(y_{t+j}\\mid y_{t+1:t+j-1},\\Phi_{t},\\omega_{t+1:t+j}\\right)\\!.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We denote $\\mathcal{T}_{t}^{j}:=[Y_{t+1:t+j-1},\\Phi_{t},W_{t+1:t+j}]$ and assume a Gaussian distribution for the conditional responses $Y_{t+j}\\mid\\mathcal{T}_{t}^{j}\\sim\\mathcal{N}(G_{Y}(\\mathcal{T}_{t}^{j}),\\sigma^{2})$ , where $G_{Y}$ models the mean of the conditional response (see right side of Figure 2). We set $\\sigma=0.05$ throughout our experiments. The response sequence is estimated autoregressively using a GRU-based decoder without teacher forcing [81] to ensure model training\u2019s consistency with testing in real-world scenarios (Figure 2 and Algorithm 2 in Appendix H). ", "page_idx": 5}, {"type": "text", "text": "Treatment prediction We learn a treatment prediction sub-network parameterized by $\\theta_{W}$ that takes as input the representation $\\Phi_{t+1}$ and predicts a distribution $q_{\\theta_{W}}\\!\\left(\\stackrel{-}{\\omega_{t+1}}\\mid\\Phi_{t+1}\\right)$ over the treatment $W_{t+1}$ by minimizing the negative log-likelihood, ${\\mathcal{L}}_{W}\\,=\\,-\\log q_{\\theta_{W}}\\bigl(\\omega_{t+1}~\\vert~\\Phi_{t+1}\\bigr)$ . To assess the quality of the representation in predicting the treatment, the gradient from $\\mathcal{L}_{W}$ only updates the treatment network parameters $\\theta_{W}$ and is not backpropagated through the response of the parameters for the representation $\\Phi_{t+1}$ (Algorithm 2, Appendix H). ", "page_idx": 5}, {"type": "text", "text": "Adversarial learning To create an adversarial game, we update the representation learning parameters, and in the next step, the treatment network $q_{\\theta_{W}}(\\cdot\\mid\\Phi_{t+1})$ with adverse losses such that the representation $\\Phi_{t+1}$ becomes invariant with respect to the assignment of $W_{t+1}$ . Different from SOTA models (as highlighted in related work) and in line with our information guidelines principles, learning a balanced representation $\\Phi_{t+1}$ amounts to ensuring $\\Phi_{t+1}$ \u22a5\u22a5 $W_{t+1}$ , which is equivalent to $I(\\bar{\\Phi_{t+1}},W_{t+1})=\\bar{0}$ . Hence, we minimize the MI as a way to confuse the treatment classifier. Specifically, we minimize an upper bound on $I(\\Phi_{t+1},W_{t+1})$ , namely the CLUB of MI [13]. ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{\\mathrm{CLUB}}\\big(\\Phi\\big(\\mathbf{H}_{t}\\big),W_{t+1};q_{\\theta_{W}}\\big):=\\mathbb{E}_{\\mathbb{P}_{(\\Phi(\\mathbf{H}_{t}),w_{t+1})}}\\left[\\log q_{\\theta_{W}}\\big(W_{t+1}\\mid\\Phi\\big(\\mathbf{H}_{t+1}\\big)\\big)\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad-\\mathbb{E}_{\\mathbb{P}_{\\Phi(\\mathbf{H}_{t})}}\\mathbb{E}_{\\mathbb{P}_{W_{t+1}}}\\left[\\log q_{\\theta_{W}}\\big(W_{t+1}\\mid\\Phi\\big(\\mathbf{H}_{t+1}\\big)\\big)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We use the objective in Eq. (9) to update the representation learner $\\Phi(.)$ [9, 32]. This update aims to minimize the discrepancy between the conditional likelihood of treatments for units sampled from $\\mathbb{P}_{(\\mathbf{H}_{t_{i}},W_{t+1})}$ and the conditional likelihood of treatments under the assumption of independent sampling from the product of marginals $\\mathbb{P}_{\\mathbf{H}_{t+1}}\\otimes\\mathbb{P}_{W_{t+1}}$ . In practice, we generate samples from the product of marginals by shuffling the treatment $W_{t+1}$ across the batch dimension similar to [9, 32]. When minimizing $\\mathcal{L}_{W}$ , $q_{\\theta_{W}}(\\omega_{t+1}\\mid\\Phi_{t+1})$ gets closer to the true conditional distribution $p(\\omega_{t+1}\\mid$ $\\Phi_{t+1})$ , and, in this case, the objective in Eq. (9) provides an upper bound of the MI between representation and treatment. We formalize the intuition by adapting the result of [13]: ", "page_idx": 5}, {"type": "text", "text": "Theorem 5.3. [13] Let $q_{\\theta_{W}}(\\Phi_{t+1},\\omega_{t+1})\\;:=\\;q_{\\theta_{W}}\\bigl(\\omega_{t+1}\\vert\\Phi_{t+1}\\bigr)p(\\Phi_{t+1})$ be the joint distribution induced by $q_{\\theta_{W}}(\\omega_{t+1}|\\Phi_{t+1})$ over the representation space of $\\Phi_{t+1}$ . If: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad D_{K L}(p(\\Phi_{t+1},\\omega_{t+1})||q_{\\theta_{W}}(\\Phi_{t+1},\\omega_{t+1}))\\leq D_{K L}(p(\\Phi_{t+1})p(\\omega_{t+1})||q_{\\theta_{W}}(\\Phi_{t+1},\\omega_{t+1})),}\\\\ &{\\quad_{t+1},W_{t+1})\\leq I_{C L U B}(\\Phi_{t+1},W_{t+1};q).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Based on Theorem 5.3, our adversarial training is interpretable and can be explained as follows: the treatment classifier seeks to minimize $\\mathbb{E}_{\\mathbb{P}(\\mathbf{H}_{t},W_{t+1})}\\left[\\mathcal{L}_{W}\\right]$ , which is equivalent to minimizing Kullback-Leibler divergence $D_{K L}(p(\\Phi_{t+1},\\omega_{t+1})||q_{\\theta_{W}}(\\Phi_{t+1},\\omega_{t+1}))$ . Therefore, $q_{\\theta_{W}}(\\Phi_{t+1},\\omega_{t+1})$ could get closer to $p(\\Phi_{t+1},\\omega_{t+1})$ than, ultimately, to $p(\\Phi_{t+1})p(\\omega_{t+1})$ , as we train the network to predict $W_{t+1}$ from $\\Phi_{t+1}$ . In such a case and by Theorem 5.3, $I_{C L U B}$ provides an upper bound on the MI. Hence, in a subsequent step, we minimize $I_{C L U B}$ w.r.t the representation parameters, minimizing the MI $I(\\Phi_{t+1},W_{t+1})$ and achieving balance. We theoretically formulate such behavior by proving in the following theorem that, at the Nash equilibrium of this adversarial game, the representation is exactly balanced across the different treatment regimes provided by $W_{t+1}$ . ", "page_idx": 6}, {"type": "text", "text": "Theorem 5.4. Let $t\\in\\{1,2,\\dots,t_{m a x}\\},$ , $\\Phi=\\Phi_{\\theta_{R}}$ and $q=q_{\\theta_{W}}$ are, respectively, any representation and treatment network. Let $\\mathbb{P}_{\\Phi(\\mathbf{H}_{t})}$ be the probability distribution over the representation space and $\\mathbb{P}_{\\Phi(\\mathbf{H}_{t})|W_{t+1}}$ its conditional counterpart. Then, there exist $\\Phi^{*}$ and $q^{*}$ such that: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\Phi^{*}=\\arg\\displaystyle\\operatorname*{min}_{\\Phi}I_{C L U B}(\\Phi(\\mathbf{H}_{t}),W_{t+1};q^{*})}}\\\\ {{\\displaystyle q^{*}=\\arg\\operatorname*{max}_{q}\\mathbb{E}_{\\mathbb{P}_{\\Phi^{*}(\\mathbf{H}_{t})}}\\left[\\log q(W_{t+1}\\mid\\Phi^{*}(\\mathbf{H}_{t}))\\right].}}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Such an equilibrium holds if and only if $\\\"\\mathbb{P}_{\\Phi(\\mathbf{H}_{t})|W_{t+1}=0}=\\mathbb{P}_{\\Phi(\\mathbf{H}_{t})|W_{t+1}=1}=...=\\mathbb{P}_{\\Phi(\\mathbf{H}_{t})|W_{t+1}=k-1},$ almost surely. ", "page_idx": 6}, {"type": "text", "text": "Since we target multi-timestep forecasting, covariate balancing in the representation space extends beyond $t+1$ . For simplicity, we presented it for $t+1$ , but in practice, the adversarial game applies the balancing across all forecasting horizons (Algorithm 2). The theorem also holds for other horizons by replacing $\\Phi(\\mathbf{H}_{t})$ with $\\Phi(\\mathbf{H}_{t+j-1})$ and $W_{t+1}$ with $W_{t+j}$ , for $2\\le j\\le\\tau$ . ", "page_idx": 6}, {"type": "text", "text": "Causal CPC Training The Causal CPC model is trained in two stages: (1) Encoder pretraining: We first learn an efficient representation of the process history by minimizing loss: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}_{e n c}=\\mathcal{L}^{C P C}(\\theta_{1},\\theta_{2},\\{\\Gamma_{j}\\}_{j=1}^{\\tau})+\\mathcal{L}^{(I n f o M a x)}(\\theta_{1},\\theta_{2},\\gamma).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "(2) Decoder training: After pretraining, we fine-tune the encoder by optimizing the factual outcome and treatment networks in the adversarial game from Theorem 5.4. Formally: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\underset{\\theta_{R},\\theta_{Y}}{\\mathrm{min}}\\,\\mathcal{L}_{d e c}\\big(\\theta_{R},\\theta_{Y},\\theta_{W}\\big)=\\mathcal{L}_{Y}\\big(\\theta_{R},\\theta_{Y}\\big)+I_{\\mathrm{CLUB}}\\big(\\Phi_{\\theta_{R}}\\big(\\mathbf{H}_{t}\\big),W_{t+1};q_{\\theta_{W}}\\big),}\\\\ &{\\displaystyle\\underset{\\theta_{W}}{\\mathrm{min}}\\,\\mathcal{L}_{W}\\big(\\theta_{W},\\theta_{R}\\big)=-\\mathbb{E}_{\\Phi_{\\theta_{R}}(\\mathbf{H}_{t})}\\left[\\log q_{\\theta_{W}}\\big(W_{t+1}\\mid\\Phi_{\\theta_{R}}\\big(\\mathbf{H}_{t}\\big)\\big)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We compare Causal CPC with SOTA baselines: MSMs [64], RMSN [41], CRN [7], G-Net [39], and CT [48]. All models are fine-tuned via a grid search over hyperparameters, including architecture and optimizers. Model selection is based on mean squared error (MSE) on factual outcomes from a validation set, and the same criterion is used for early stopping. Further details on hyperparameters and training procedures are provided in Appendices J and D. ", "page_idx": 6}, {"type": "text", "text": "6.1 Experiments with Synthetic Data ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Tumor Growth We use the PharmacoKinetic-PharmacoDynamic (PK-PD) model [24] to simulate responses of non-small cell lung cancer patients, following previous works [41, 7, 48]. We evaluate our approach on simulated counterfactual trajectories, varying the confounding level via the parameter $\\gamma$ (Appendix E.1). Unlike [48], who used larger datasets (10,000 for training, 1,000 for testing), we use a smaller, more challenging dataset (1,000 for training, 500 for testing) to reflect real-world data limitations. For long-horizon forecasting, we set the prediction horizon to 10 and evaluate two training sequence lengths: 60 and 40, with covariates of dimension 4. ", "page_idx": 6}, {"type": "image", "img_path": "bKOZYBJE4Z/tmp/7b0516d3c189e16df92556d925cd29fe00cf2b275e1f7749290b08a81ea11c90.jpg", "img_caption": ["Figure 3: Evolution of error (NRMSE) in estimating counterfactual responses for cancer simulation data. Top: training sequence length 60. Bottom: training sequence length 40. In both cases, $\\tau=10$ . MSM is excluded due to high prediction errors. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Results We tested all models on the cancer simulation data across three confounding levels, $\\gamma\\ =\\ 1,2,3$ . Figures 3a, 3b and 3c show the evolution of Normalized Root Mean Squared Error (NRMSE) over counterfactual tumor volume as the prediction horizon increases. Causal CPC consistently outperforms all baselines at larger horizons, demonstrating its effectiveness in long-term predictions. This confirms the quality of $\\mathbf{C}_{t}$ in predicting future components across multiple time steps, capturing the global structure of the process as discussed in Eq. (5). Extended results are provided in Appendix E.2.1. ", "page_idx": 7}, {"type": "text", "text": "In the more challenging case where the maximum sequence length is 40 (Figures 3d, 3e and 3f), the error evolution remains similar to Figure 3a, 3b and 3c. Our model maintains its advantage, outperforming most baselines in long-term forecasting. However, Causal CPC does not outperform other models in short-term forecasting, a consistent limitation across experiments. Still, the model\u2019s superior long-term performance highlights its potential in applications requiring long-term accuracy. At higher levels of confounding, the model does not always outperform SOTA models at certain time steps. This may be due to the low dimensionality of the time-varying components and static covariates, $\\mathbf{U}_{t}=[\\mathbf{V},\\mathbf{X}_{t},W_{t-1},Y_{t-1}]$ , which have only four dimensions. Our model leverages contrastive learning-based regularization to excel on datasets with higher confounding dimensions, as demonstrated on MIMIC-III where $\\mathbf{U}_{t}$ has 72 dimensions. In this setting, our model consistently outperforms baselines at longer prediction horizons. The occasional underperformance of Causal CPC at the final horizon is due to $\\tau=10$ being the last contrasted horizon, not an issue specific to $\\tau=10$ . To support this, we reran all models with a sequence length of 60, $\\tau=15$ , and $\\gamma=2$ . As shown in Figure 4, Causal CPC still outperforms SOTA for horizons beyond $\\tau=10$ due to the encoder\u2019s retraining, where the InfoNCE loss is computed over all 15 time steps. The last prediction error remains close to SOTA, suggesting that training over larger horizons than initially intended may be beneficial. ", "page_idx": 7}, {"type": "image", "img_path": "bKOZYBJE4Z/tmp/b7eb9f09f9d1b49825817a778c8c77a478a18c594deac79062ced80e733de2d2.jpg", "img_caption": ["Figure 4: Models\u2019 performance for cancer simulation, $\\gamma=2$ , $\\tau=15$ . "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "6.2 Experiments with semi-synthetic and real data ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Semi-synthetic MIMIC-III We used a semi-synthetic dataset constructed by [48] based on the MIMIC-III dataset [35], incorporating both endogenous temporal dependencies and exogenous dependencies from observational patient trajectories, as detailed in Appendix F.1. The patient trajectories are high-dimensional and exhibit long-range dependencies. Similar to the cancer simulation, the training data consisted of relatively few sequences (500 for training, 100 for validation, and 400 for testing). Table 1 presents the mean and standard deviation of counterfactual predictions across multiple horizons $(\\tau\\ =\\ 10)$ ). We test two maximum sequence lengths, 100 and 60, to assess the models\u2019 robustness for long-horizon forecasting. ", "page_idx": 7}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/518da8af6f90b652ccba29d060e0b4a554a714f11ca16ed755bd1bf62dcd555d.jpg", "table_caption": ["Table 1: Evolution of RMSEs for the semi-synthetic MIMIC III, sequence length 100. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Results Causal CPC consistently outperformed the baselines, especially at larger horizons, both with a sequence length of 100 and a reduced length of 60 (Figures 1, 5). Its superior performance at longer horizons is likely due to the high number of covariates, making it well-suited to contrastive-based training. We also tested the models with 800/200/200 individuals for training/validation/testing, as in [48] (Appendix F.2.2), where Causal CPC achieved state-of-the-art (SOTA) results comparable to CT but with much shorter training and prediction times. ", "page_idx": 8}, {"type": "image", "img_path": "bKOZYBJE4Z/tmp/2d794eff3f05e849cd8c0af52f659a80e0b0e86c0f56a014706a836a7bc0cdb9.jpg", "img_caption": ["Figure 5: Performance for MIMIC III semi-synthetic, sequence length 60. "], "img_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/084d6069c8b6e20673b7d44b7c458c749580c6ab4d7fd98d9f028a35c367ba09.jpg", "table_caption": ["Table 2: Models complexity and the running time averaged over five seeds. Results are reported for tumor growth simulation $(\\gamma\\ =\\ 1)$ ). Hardware: GPU1xNVIDIA Tesla M60. "], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/cd0926a052e94979a9ed9e255eaa64ecf7960278c3474b5ecc9b05fc75c1d7a4.jpg", "table_caption": ["Table 3: Ablation study with NRMSE averaged across $(1\\leq\\tau\\leq10)$ ) for cancer simulation $(\\gamma=1)$ ) and MIMIC III. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Computational Efficiency and Model Complexity Efficient execution is crucial for practical deployment, especially with periodic retraining. Beyond training, challenges arise in evaluating multiple counterfactual trajectories per individual, which grow exponentially with the forecasting horizon as $K^{\\tau}$ , where $K$ is the number of possible treatments. This is particularly relevant when generating multiple treatment plans, such as minimizing tumor volume. Table 2 shows the models\u2019 complexity (number of parameters) and running time, split between model fitting and prediction. Causal CPC is highly efficient during prediction due to its simple 1-layer GRU, similar to CRN (1-layer LSTM), while providing better ITEs estimation. In contrast, CT is less efficient due to its transformer architecture and teacher forcing, which requires recursive data loading during inference. G-Net also has longer prediction times due to Monte Carlo sampling. Overall, Causal CPC strikes a strong balance between accuracy and efficiency, making it well-suited under constrained resources. ", "page_idx": 8}, {"type": "text", "text": "Real MIMIC-III Data We evaluated our model on real MIMIC-III data, where counterfactual trajectories cannot be assessed due to the absence of observed counterfactual responses. However, performance can still be measured by forecasting factual (observed) responses over time. Our model estimates responses for each individual based on their observed treatment trajectory. As shown in Figure 6, Causal CPC consistently outperforms all baselines, especially at larger horizons, demonstrating its robustness and effectiveness in real-world settings. ", "page_idx": 8}, {"type": "image", "img_path": "bKOZYBJE4Z/tmp/eee308aae6d7b25ec511893e9b9fd04588750d4fc8785627cac4befd6639835d.jpg", "img_caption": ["Figure 6: Evolution of RMSEs, Real MIMIC III, sequence length 100. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "7 Discussion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Why does Causal CPC outperform SOTA at large horizons? Our context $\\mathbf{C}_{t}$ is designed to capture shared information across future representations, particularly covariates, by minimizing the ", "page_idx": 8}, {"type": "text", "text": "InfoNCE loss over multiple time steps (Eq. 1). As shown in Eq. (5), minimizing $\\mathcal{L}^{C P C}$ maximizes shared information between the context and future components, helping capture the global structure of the process. This is especially beneficial for counterfactual regression over long horizons, explaining the model\u2019s superior performance. However, it may not always outperform SOTA in shorter-term predictions due to its focus on long-term dependencies. ", "page_idx": 9}, {"type": "text", "text": "Short-term Counterfactual Regression While our model is designed for long-term predictions, it may not consistently outperform SOTA for short-horizon tasks. However, the use of contrastive loss, particularly InfoNCE (Eq. 4), suggests potential adaptability to balance both short- and long-term predictions without retraining. A trade-off could be achieved by adjusting the contrastive term weights across time steps in Eq. (4), which we leave for future work. ", "page_idx": 9}, {"type": "text", "text": "Ablation study We examined the model\u2019s performance in various configurations\u2014full model, without CPC, and without InfoMax. Table 3 and Figure 7 show that removing either term reduces counterfactual accuracy across all horizons, underscoring their significance. Additionally, replacing our ICLUB objective with CDC loss [48] or removing balancing increases errors. We also tested different MI lower bounds like NWJ [50] and MINE [4] for both CPC and InfoMax (Appendix C.2), finding that InfoNCE yielded the best results (Table 10). Full ablation results are in Appendices E.2.2 and F.2.1. ", "page_idx": 9}, {"type": "image", "img_path": "bKOZYBJE4Z/tmp/6d481b12315db4c1dfd3507b0dd1d6d29f9c902b8d2c32eec689ebd795328613.jpg", "img_caption": ["Figure 7: Ablation study of Causal CPC on MIMIC III. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Falsifiability Test This study assumes sequential ignorability, common in causal inference [41, 7, 39, 48]. To assess robustness, we performed a falsifiability test by omitting certain confounders during training, while they remained in MIMIC-III data construction. As seen in Table 4, violating sequential ignorability increased prediction errors for Causal CPC, CT, and CRN, though RMSN was less affected but underperformed at $\\tau\\geq2$ . Despite this, Causal CPC maintained its lead at larger horizons, demonstrating strong encoding of long-term dependencies. ", "page_idx": 9}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/750084b847bf3757d1af4dc26b3d8f9065ebf0f4388c7833304827a5d169bd7c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Tightness of MI Upper Bounds Estimating MI bounds for high-dimensional variables is challenging and expensive [59, 57], often limited to low-dimensional inputs or Gaussian assumptions. In MI-constrained models, batch size is crucial. As shown in Eq. (3), increasing the batch size $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ tightens the lower bound via $\\log(|B|)$ , and to balance memory and performance, we chose batch sizes of 256 for the encoder and 128 for the decoder. While these bounds may not be perfectly tight, mutual information and self-supervision biases significantly enhance performance (Appendix C.2), as confirmed by ablation studies. Other MI estimators like NWJ and MINE [50, 4] did not improve performance; our initial setup consistently performed better (Appendix F.2.1). ", "page_idx": 9}, {"type": "text", "text": "Extending Causal CPC to Continuous Treatment Our approach could be extended to continuous treatments by replacing the treatment classifier with a regressor. Since the method maximizes likelihood, the equilibrium in Theorem 5.4 remains valid. However, in practice, continuous treatments will be represented by a single dimension, unlike discrete treatments with $K$ -dimensional one-hot encoding. This risks losing important treatment information in counterfactual predictions. A simpler adaptation to our model could involve discretizing continuous treatments. ", "page_idx": 9}, {"type": "text", "text": "Conclusion We introduced a novel approach to long-term counterfactual regression, combining RNNs with CPC to achieve SOTA results without relying on complex transformer models. Prioritizing computational efficiency, we incorporated contrastive loss-based regularization guided by mutual information (MI). Our method consistently outperforms existing models on both synthetic and realworld datasets, marking the first application of CPC in causal inference. Future work could focus on improving interpretability by integrating Shapley values into the causal framework [30]. Additionally, developing uncertainty-aware models tailored for longitudinal data is crucial for enhancing the reliability of predictions in our causal framework [19, 33, 84]. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] S. Arora, H. Khandeparkar, M. Khodak, O. Plevrakis, and N. Saunshi. A theoretical analysis of contrastive unsupervised representation learning. arXiv preprint arXiv:1902.09229, 2019.   \n[2] O. Atan, J. Jordon, and M. Van der Schaar. Deep-treat: Learning optimal personalized treatments from observational data using neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 32, 2018.   \n[3] P. Bachman, R. D. Hjelm, and W. Buchwalter. Learning representations by maximizing mutual information across views. Advances in neural information processing systems, 32, 2019.   \n[4] M. I. Belghazi, A. Baratin, S. Rajeshwar, S. Ozair, Y. Bengio, A. Courville, and D. Hjelm. Mutual information neural estimation. In International conference on machine learning, pages 531\u2013540. PMLR, 2018.   \n[5] A. J. Bell and T. J. Sejnowski. An information-maximization approach to blind separation and blind deconvolution. Neural computation, 7(6):1129\u20131159, 1995.   \n[6] J. Berrevoets, A. Curth, I. Bica, E. McKinney, and M. van der Schaar. Disentangled counterfactual recurrent networks for treatment effect inference over time. arXiv preprint arXiv:2112.03811, 2021.   \n[7] I. Bica, A. M. Alaa, J. Jordon, and M. van der Schaar. Estimating counterfactual treatment outcomes over time through adversarially balanced representations. arXiv preprint arXiv:2002.04083, 2020.   \n[8] I. Bica, A. M. Alaa, and M. van der Schaar. Time series deconfounder: Estimating treatment effects over time in the presence of hidden confounders. In International Conference on Machine Learning, 2020. [9] P. Brakel and Y. Bengio. Learning independent features with adversarial nets for non-linear ica. arXiv preprint arXiv:1710.05050, 2017.   \n[10] D. Cao, J. Enouen, and Y. Liu. Estimating treatment effects in continuous time with hidden confounders. arXiv e-prints, pages arXiv\u20132302, 2023.   \n[11] Y. Chen, A. Prati, J. Montgomery, and R. Garnett. A multi-task gaussian process model for inferring time-varying treatment effects in panel data. In International Conference on Artificial Intelligence and Statistics, pages 4068\u20134088. PMLR, 2023.   \n[12] L. Cheng, R. Guo, and H. Liu. Causal mediation analysis with hidden confounders. Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining, null:null, 2021.   \n[13] P. Cheng, W. Hao, S. Dai, J. Liu, Z. Gan, and L. Carin. Club: A contrastive log-ratio upper bound of mutual information. In International conference on machine learning, pages 1779\u20131788. PMLR, 2020.   \n[14] K. Cho, B. Van Merri\u00ebnboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and Y. Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.   \n[15] E. Choi, M. T. Bahadori, J. Sun, J. Kulas, A. Schuetz, and W. Stewart. Retain: An interpretable predictive model for healthcare using reverse time attention mechanism. Advances in neural information processing systems, 29, 2016.   \n[16] Z. Chu, S. L. Rathbun, and S. Li. Learning infomax and domain-independent representations for causal effect inference with real-world data. In Proceedings of the 2022 SIAM International Conference on Data Mining (SDM), pages 433\u2013441. SIAM, 2022.   \n[17] T. M. Cover. Elements of information theory. John Wiley & Sons, 1999.   \n[18] I. Daunhawer, A. Bizeul, E. Palumbo, A. Marx, and J. E. Vogt. Identifiability results for multimodal contrastive learning. arXiv preprint arXiv:2303.09166, 2023.   \n[19] E. De Brouwer, J. Gonzalez, and S. Hyland. Predicting the impact of treatments over time with uncertainty aware neural differential equations. In International Conference on Artificial Intelligence and Statistics, pages 4705\u20134722. PMLR, 2022.   \n[20] M. D. Donsker and S. S. Varadhan. Asymptotic evaluation of certain markov process expectations for large time. iv. Communications on pure and applied mathematics, 36(2):183\u2013212, 1983.   \n[21] W. Falcon and The PyTorch Lightning team. PyTorch Lightning, Mar. 2019.   \n[22] D. Frauen, T. Hatt, V. Melnychuk, and S. Feuerriegel. Estimating average causal effects from patient trajectories. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 7586\u20137594, 2023.   \n[23] Y. Ganin and V. Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180\u20131189. PMLR, 2015.   \n[24] C. Geng, H. Paganetti, and C. Grassberger. Prediction of treatment response for combined chemo-and radiation therapy for non-small cell lung cancer patients using a bio-mathematical model. Scientific reports, 7(1):1\u201312, 2017.   \n[25] M. Gutmann and A. Hyv\u00e4rinen. Noise-contrastive estimation: A new estimation principle for unnormalized statistical models. In Proceedings of the thirteenth international conference on artificial intelligence and statistics, pages 297\u2013304. JMLR Workshop and Conference Proceedings, 2010.   \n[26] M. U. Gutmann and A. Hyv\u00e4rinen. Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics. Journal of machine learning research, 13(2), 2012.   \n[27] J. Z. HaoChen, C. Wei, A. Gaidon, and T. Ma. Provable guarantees for self-supervised deep learning with spectral contrastive loss. Advances in Neural Information Processing Systems, 34:5000\u20135011, 2021.   \n[28] T. Hatt and S. Feuerriegel. Sequential deconfounding for causal inference with unobserved confounders. arXiv preprint arXiv:2104.09323, 2021.   \n[29] O. Henaff. Data-efficient image recognition with contrastive predictive coding. In International conference on machine learning, pages 4182\u20134192. PMLR, 2020.   \n[30] T. Heskes, E. Sijben, I. G. Bucur, and T. Claassen. Causal shapley values: Exploiting causal knowledge to explain individual predictions of complex models. Advances in neural information processing systems, 33:4778\u20134789, 2020.   \n[31] \u00c7. H\u0131zl\u0131, S. John, A. T. Juuti, T. T. Saarinen, K. H. Pietil\u00e4inen, and P. Marttinen. Causal modeling of policy interventions from treatment-outcome sequences. In International Conference on Machine Learning, pages 13050\u201313084. PMLR, 2023.   \n[32] R. D. Hjelm, A. Fedorov, S. Lavoie-Marchildon, K. Grewal, P. Bachman, A. Trischler, and Y. Bengio. Learning deep representations by mutual information estimation and maximization. In International Conference on Learning Representations, 2019.   \n[33] A. Jesson, S. Mindermann, U. Shalit, and Y. Gal. Identifying causal-effect inference failure with uncertainty-aware models. Advances in Neural Information Processing Systems, 33:11637\u2013 11649, 2020.   \n[34] S. Jiang, Z. Huang, X. Luo, and Y. Sun. Cf-gode: Continuous-time causal inference for multiagent dynamical systems. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD \u201923, page 997\u20131009, New York, NY, USA, 2023. Association for Computing Machinery.   \n[35] A. E. Johnson, T. J. Pollard, L. Shen, L.-w. H. Lehman, M. Feng, M. Ghassemi, B. Moody, P. Szolovits, L. Anthony Celi, and R. G. Mark. Mimic-iii, a freely accessible critical care database. Scientific data, 3(1):1\u20139, 2016.   \n[36] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.   \n[37] G. Klambauer, T. Unterthiner, A. Mayr, and S. Hochreiter. Self-normalizing neural networks. Advances in neural information processing systems, 30, 2017.   \n[38] M. Kuzmanovic, T. Hatt, and S. Feuerriegel. Deconfounding temporal autoencoder: estimating treatment effects over time using noisy proxies. In Machine Learning for Health, pages 143\u2013155. PMLR, 2021.   \n[39] R. Li, S. Hu, M. Lu, Y. Utsumi, P. Chakraborty, D. M. Sow, P. Madan, J. Li, M. F. Ghalwash, Z. Shahn, and L. wei H. Lehman. G-net: a recurrent network approach to g-computation for counterfactual prediction under a dynamic treatment regime. In ML4H@NeurIPS, 2021.   \n[40] P. P. Liang, Z. Deng, M. Ma, J. Zou, L.-P. Morency, and R. Salakhutdinov. Factorized contrastive learning: Going beyond multi-view redundancy. In Advances in Neural Information Processing Systems, 2023.   \n[41] B. Lim. Forecasting treatment responses over time using recurrent marginal structural networks. advances in neural information processing systems, 31, 2018.   \n[42] B. Lim. Forecasting treatment responses over time using recurrent marginal structural networks. advances in neural information processing systems, 31, 2018.   \n[43] R. Linsker. Self-organization in a perceptual network. Computer, 21(3):105\u2013117, 1988.   \n[44] Y. Liu, Z. Zhang, D. Gong, B. Huang, M. Gong, A. v. d. Hengel, K. Zhang, and J. Q. Shi. Revealing multimodal contrastive representation learning through latent partial causal models. arXiv preprint arXiv:2402.06223, 2024.   \n[45] M. J. Lopez and R. Gutman. Estimation of causal effects with multiple treatments: a review and new ideas. Statistical Science, pages 432\u2013454, 2017.   \n[46] I. Loshchilov and F. Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017.   \n[47] S. Matthes, Z. Han, and H. Shen. Towards a unified framework of contrastive learning for disentangled representations. Advances in Neural Information Processing Systems, 36:67459\u2013 67470, 2023.   \n[48] V. Melnychuk, D. Frauen, and S. Feuerriegel. Causal transformer for estimating counterfactual outcomes. ArXiv, abs/2204.07258, 2022.   \n[49] S. Mueller and J. Pearl. Personalized decision making\u2013a conceptual introduction. Journal of Causal Inference, 11(1):20220050, 2023.   \n[50] X. Nguyen, M. J. Wainwright, and M. I. Jordan. Estimating divergence functionals and the likelihood ratio by convex risk minimization. IEEE Transactions on Information Theory, 56(11):5847\u20135861, 2010.   \n[51] S. Nowozin, B. Cseke, and R. Tomioka. f-gan: Training generative neural samplers using variational divergence minimization. Advances in neural information processing systems, 29, 2016.   \n[52] A. v. d. Oord, Y. Li, and O. Vinyals. Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748, 2018.   \n[53] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. K\u00f6pf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chintala. Pytorch: An imperative style, high-performance deep learning library. In Neural Information Processing Systems, 2019.   \n[54] T. Pham, T. Tran, D. Phung, and S. Venkatesh. Predicting healthcare trajectories from medical records: A deep learning approach. Journal of biomedical informatics, 69:218\u2013229, 2017.   \n[55] R. W. Platt, E. F. Schisterman, and S. R. Cole. Time-modified confounding. American journal of epidemiology, 170(6):687\u2013694, 2009.   \n[56] B. Poole, S. Ozair, A. Van Den Oord, A. Alemi, and G. Tucker. On variational bounds of mutual information. In International Conference on Machine Learning, pages 5171\u20135180. PMLR, 2019.   \n[57] B. Poole, S. Ozair, A. Van Den Oord, A. Alemi, and G. Tucker. On variational bounds of mutual information. In International Conference on Machine Learning, pages 5171\u20135180. PMLR, 2019.   \n[58] Z. Qian, Y. Zhang, I. Bica, A. Wood, and M. van der Schaar. Synctwin: Treatment effect estimation with longitudinal outcomes. Advances in Neural Information Processing Systems, 34:3178\u20133190, 2021.   \n[59] T. Rainforth, A. Kosiorek, T. A. Le, C. Maddison, M. Igl, F. Wood, and Y. W. Teh. Tighter variational bounds are not necessarily better. In International Conference on Machine Learning, pages 4277\u20134285. PMLR, 2018.   \n[60] R. Ranganath and A. Perotte. Multiple causal inference with latent confounding. arXiv preprint arXiv:1805.08273, 2018.   \n[61] J. M. Robins. Association, causation, and marginal structural models. Synthese, 121(1/2):151\u2013 179, 1999.   \n[62] J. M. Robins and M. A. Hern\u00e1n. Estimation of the causal effects of time-varying exposures. Longitudinal data analysis, 553:599, 2009.   \n[63] J. M. Robins and M. A. Hern\u00e1n. Estimation of the causal effects of time-varying exposures. Longitudinal data analysis, 553:599, 2009.   \n[64] J. M. Robins, M. A. Hernan, and B. Brumback. Marginal structural models and causal inference in epidemiology, 2000.   \n[65] D. B. Rubin. Causal inference using potential outcomes: Design, modeling, decisions. Journal of the American Statistical Association, 100(469):322\u2013331, 2005.   \n[66] N. Saunshi, J. Ash, S. Goel, D. Misra, C. Zhang, S. Arora, S. Kakade, and A. Krishnamurthy. Understanding contrastive learning requires incorporating inductive biases. In International Conference on Machine Learning, pages 19250\u201319286. PMLR, 2022.   \n[67] E. F. Schisterman, S. R. Cole, and R. W. Platt. Overadjustment bias and unnecessary adjustment in epidemiologic studies. Epidemiology (Cambridge, Mass.), 20(4):488, 2009.   \n[68] P. Schulam and S. Saria. Reliable decision support using counterfactual models. Advances in neural information processing systems, 30, 2017.   \n[69] N. Seedat, F. Imrie, A. Bellot, Z. Qian, and M. van der Schaar. Continuous-time modeling of counterfactual outcomes using neural controlled differential equations. arXiv preprint arXiv:2206.08311, 2022.   \n[70] U. Shalit. Can we learn individual-level treatment policies from clinical data? Biostatistics, 21(2):359\u2013362, 2020.   \n[71] R. Shwartz Ziv and Y. LeCun. To compress or not to compress\u2014self-supervised learning and information theory: A review. Entropy, 26(3):252, 2024.   \n[72] H. Soleimani, J. Hensman, and S. Saria. Scalable joint models for reliable uncertainty-aware event prediction. IEEE transactions on pattern analysis and machine intelligence, 40(8):1948\u2013 1963, 2017.   \n[73] H. Soleimani, A. Subbaswamy, and S. Saria. Treatment-response models for counterfactual reasoning with continuous-time, continuous-valued interventions. ArXiv, abs/1704.02038, 2017.   \n[74] I. Sutskever, J. Martens, G. Dahl, and G. Hinton. On the importance of initialization and momentum in deep learning. In International conference on machine learning, pages 1139\u2013 1147. PMLR.   \n[75] Y. Tian, D. Krishnan, and P. Isola. Contrastive multiview coding. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XI 16, pages 776\u2013794. Springer, 2020.   \n[76] C. Tosh, A. Krishnamurthy, and D. Hsu. Contrastive learning, multi-view redundancy, and linear models. In Algorithmic Learning Theory, pages 1179\u20131206. PMLR, 2021.   \n[77] M. Tschannen, J. Djolonga, P. K. Rubenstein, S. Gelly, and M. Lucic. On mutual information maximization for representation learning. In International Conference on Learning Representations, 2020.   \n[78] E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko. Simultaneous deep transfer across domains and tasks. In Proceedings of the IEEE international conference on computer vision, pages 4068\u20134076, 2015.   \n[79] V. Veitch, D. Sridhar, and D. Blei. Adapting text embeddings for causal inference. In Conference on Uncertainty in Artificial Intelligence, pages 919\u2013928. PMLR, 2020.   \n[80] Y. Wang and D. M. Blei. The blessings of multiple causes. Journal of the American Statistical Association, 114(528):1574\u20131596, 2019.   \n[81] R. J. Williams and D. Zipser. A learning algorithm for continually running fully recurrent neural networks. Neural computation, 1(2):270\u2013280, 1989.   \n[82] S. Wu, W. Zhou, M. Chen, and S. Zhu. Counterfactual generative models for time-varying treatments. arXiv preprint arXiv:2305.15742, 2023.   \n[83] Y. Yaz\u0131c\u0131, C.-S. Foo, S. Winkler, K.-H. Yap, G. Piliouras, and V. Chandrasekhar. The unusual effectiveness of averaging in GAN training. In International Conference on Learning Representations, 2019.   \n[84] M. Yin, C. Shi, Y. Wang, and D. M. Blei. Conformal sensitivity analysis for individual treatment effects. Journal of the American Statistical Association, 119(545):122\u2013135, 2024.   \n[85] N. Zhao, Z. Wu, R. W. Lau, and S. Lin. What makes instance discrimination good for transfer learning? arXiv preprint arXiv:2006.06606, 2020.   \n[86] R. S. Zimmermann, Y. Sharma, S. Schneider, M. Bethge, and W. Brendel. Contrastive learning inverts the data generating process. In International Conference on Machine Learning, pages 12979\u201312990. PMLR, 2021. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "A Impact Statements ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Our paper seeks to advance the field of Trustworthy Machine Learning by focusing on the accurate estimation of counterfactual trajectories. This capability holds significant potential to enhance decision-making processes across various domains, particularly in healthcare, where clinicians can leverage models designed to mitigate bias and promote fairness. Additionally, by focusing on efficiency, our contributions extend beyond traditional machine learning considerations to address environmental concerns associated with energy consumption. By advocating for the prudent use of computational resources, especially in training complex models deployed in real-world scenarios, we aim to promote sustainability in developing and applying machine learning solutions. ", "page_idx": 15}, {"type": "text", "text": "B Causal assumptions ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "B.1 Identifiability Assumptions in Causal CPC ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we detail the assumptions used for the identifiability of the counterfactual responses $\\mathbb{E}(Y_{t+\\tau}(\\omega_{t+1:t+\\tau})\\textrm{\\textbf{\\scriptsize i}}\\mathbf{H}_{t+1})$ . As briefly stated in Section 3, we follows similar assumptions to [62, 64, 7, 48], namely ", "page_idx": 15}, {"type": "text", "text": "Assumption B.1 (Consistency). For every time step $t$ and given any manner by which a unit $i$ receives the sequence of treatment $\\omega_{i,\\leq t}$ , we always observe the potential outcome $Y_{i t}(\\omega_{i,\\leq t})$ . Formally: ", "page_idx": 15}, {"type": "equation", "text": "$$\nW_{i,\\leq t}=w_{i,\\leq t}\\implies Y_{i t}=Y_{i t}(w_{i,\\leq t}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Assumption B.2 (Sequential Ignorability). Given any time step t, we have the conditional independence: ", "page_idx": 15}, {"type": "equation", "text": "$$\nY_{i t}(\\omega_{i t})\\perp W_{i t}|\\mathbf{H}_{i t}=\\mathbf{h}_{i t}\\quad\\forall(\\omega_{i t},\\mathbf{h}_{i t})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Assumption B.3 (Overlap/positivity). Given any time step $t$ , and for any possible historical context $\\mathbf{h}_{t}$ , the probability of observing any of the possible treatment regimes is strictly positive but not deterministic: ", "page_idx": 15}, {"type": "equation", "text": "$$\np(\\mathbf{h}_{t})\\neq0\\implies0<p(W_{t}=\\omega_{t}|\\mathbf{h}_{t})<1\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The three assumptions are sufficient for the identification of the counterfactual responses from observational data, which we formulate in the following proposition. ", "page_idx": 15}, {"type": "text", "text": "Proposition B.4. Assuming consistency, overlap, and ignorability (assumptions B.1, B.2, B.3), the causal quantity $\\mathbb{E}(Y_{t+\\tau}(\\omega_{t+1:t+\\tau})\\mid\\mathbf{H}_{t+1})$ is identifiable from observational data following ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}(Y_{t+\\tau}(\\omega_{t+1:t+\\tau})\\mid\\mathbf{H}_{t+1})=\\mathbb{E}\\left(Y_{t+\\tau}\\mid\\mathbf{H}_{t+1},W_{t+1:t+\\tau}=\\omega_{t+1:t+\\tau}\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. See [62] ", "page_idx": 15}, {"type": "text", "text": "B.2 On the Causal Graph ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We repeat the causal graph introduced in Figure 1 to explain the data generation process. here, all of the past observed data encompassed in $\\mathbf{H}_{t+1}$ confounds future treatments and responses, $W_{t+1},W_{t+2},\\dots,W_{t_{m a x}}$ and $Y_{t+1},Y_{t+2},...\\,,Y_{t_{m a x}}$ , which create long-term dependencies. The fact that post-covariates are affected by past treatments creates time-dependent confounding. The static covariates are assumed to be affecting all of the time-varying variables. Since we suppose sequential ignorability, there are no possible exogenous noises affecting both treatments and responses. However, such noise may possibly affect responses, time-varying covariates, and response variables. ", "page_idx": 15}, {"type": "text", "text": "In the figure, for simplicity, we represent past treatments as $W_{\\leq t}$ such that each element in that sub-sequence confounds the next treatment and response $W_{t+1}$ and $Y_{t+1}$ . Idem for $Y_{\\leq t}$ and $\\mathbf{X}{_{\\leq}}t$ . The static covariates $\\mathbf{V}$ are assumed to be affecting all the time-varying variables. We omit the representation of exogenous noise for simplicity. Interactions between $W_{\\leq t}$ , $\\mathbf{X}{_{\\leq t}}$ , and $Y_{\\leq t}$ were also omitted for simplicity. ", "page_idx": 15}, {"type": "image", "img_path": "bKOZYBJE4Z/tmp/02818c74b2d76aa18ef1e719d7babc6c15a0f54780ca579b5900d1588ae09cad.jpg", "img_caption": [], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "C Extended related work ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "C.1 Counterfactual regression over time: Methods overview ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "C.1.1 Methods included in experiments ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section, we give a brief overview of models included in our experiments: MSMs [62], RMSN [41], CRN [7], G-Net [39], and CT [48]. To delineate the differences between these models and Causal CPC, we detail in Table 5 the main design differences between all these models. ", "page_idx": 16}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/d7fe2bfeaebfb0218c49497eca0cd898cde4bec654a164118e4055d150556957.jpg", "table_caption": ["Table 5: A summary of the methods included in our experiments "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "C.1.2 Methods Violating Our Assumptions ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Our work relies on the assumption of sequential ignorability, yet several alternative models operate under different assumptions, often addressing the presence of unobserved confounders. Some of these models are rooted in deconfounding theory [45, 60, 80], which has been extended to time-varying settings. Deconfounding involves imposing a factor model on treatment assignment, where each treatment becomes conditionally independent given latent variables that act as proxies for unobserved confounders. Examples of this approach include [8, 28, 10]. Other models assume the presence of proxy variables, inferring a representation of unobserved confounders through probabilistic models based on these proxies [79, 12, 38]. ", "page_idx": 16}, {"type": "text", "text": "In contrast to our setting, which is governed by the three causal assumptions in Appendix B.1, many models assume a data-generating process similar to [73, 72, 58]. These methods, often non- or semiparametric, tend to either ignore static covariates or handle them linearly, leading to computational inefficiencies and scalability issues. Nevertheless, some non- or semi-parametric approaches\u2014such as [68, 69, 19, 31]\u2014align with our causal assumptions but extend them to continuous time, treating sequential ignorability in a continuous setting. ", "page_idx": 16}, {"type": "text", "text": "Additionally, models like [34] incorporate continuous-time and assume interactions between units, where an individual\u2019s outcome depends on both their treatment and the treatments of others. [6], focusing on binary treatment sequences, requires a stronger version of sequential ignorability\u2014conditional on current covariates\u2014whereas our model assumes a weaker version, conditioning on the entire history of covariates to account for long-lasting confounding effects. ", "page_idx": 16}, {"type": "text", "text": "Furthermore, [11] focuses solely on binary treatments and targets the estimation of the average treatment effect on the treated (ATT). The authors assume a specific treatment regime, where individuals enter a post-treatment state after a defined point in time. This assumption is restrictive compared to our framework, which allows for complex, individualized treatment assignment mechanisms and non-binary treatments, where treatment values can fluctuate over time. As a result, [11] is incompatible with our causal assumptions. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "Other methods, like [82], address high-dimensional counterfactual generation based on time-varying treatment plans under the same sequential ignorability assumption. However, they are not designed for causal forecasting over multiple time steps, as required in our setting. Similarly, [22] focuses on estimating the average causal effect and is not suited for predicting individual treatment effects or conditional counterfactual responses, as it targets marginal counterfactual expectations via gcomputation. ", "page_idx": 17}, {"type": "text", "text": "C.2 Mutual Information and Self-Supervision ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Self-Supervised Learning and Mutual Information In self-supervised learning, Deep InfoMax [32] uses MI computation between input images and their representations, focusing on maximizing MI to improve reconstruction quality. Local MI between representations and image patches captures detailed patterns across regions, enhancing encoding. By maximizing average MI with local regions, Deep InfoMax significantly boosts downstream task performance, while global MI plays a key role in reconstructing the entire input from the representation. ", "page_idx": 17}, {"type": "text", "text": "CPC aligns with the MI-based approach seen in Deep InfoMax, emphasizing the maximization of MI between global and local representation pairs. Distinct from Deep InfoMax, CPC processes local features sequentially, constructing partial \"summary features\" to predict specific local features in the future. While classical self-supervised paradigms often focus on tasks like classification or reconstruction-based objectives\u2014favoring either local or global MI maximization\u2014integrating both approaches becomes essential for downstream tasks such as counterfactual regression over time, which justifies why Causal CPC is designed to support both local and global MI maximization to improve temporal predictions. ", "page_idx": 17}, {"type": "text", "text": "Several other methods share similarities with CPC, such as Contrastive Multiview Coding [75]. This method emphasizes maximizing mutual information between representations of different views of the same observation. Augmented Multiscale Deep InfoMax [3], akin to CPC, makes predictions across space but differs by predicting representations across layers in the model. While Instance Discrimination [85] encourages representations capable of discriminating between individual examples in the dataset, our preference for CPC arises from its adaptability in processing sequential features in an ordered and autoregressive manner, which aligns with the requirements of our specific context, especially when dealing with counterfactual regression over time. ", "page_idx": 17}, {"type": "text", "text": "Mutual Information and Inductive Bias. Mutual information (MI) estimation success relies not only on MI\u2019s properties but also on the inductive biases from feature representation choices and MI estimator parameterization [77]. Experimental evidence shows that, although MI remains invariant under homeomorphisms, maximization with an invertible encoder during random initialization enhances downstream performance. While higher-capacity critics yield tighter MI bounds, findings consistent with [59] suggest that simpler critics provide better representations, even with looser MI bounds. Accordingly, we selected a simple bilinear critic function for contrastive losses. In vision tasks, augmentations and contrastive loss properties are crucial for representation efficiency [1, 76, 27], and [66] highlights that inductive bias, via function class representation and optimizers, significantly affects downstream performance, offering theoretical, non-vacuous guarantees on representation quality. ", "page_idx": 17}, {"type": "text", "text": "Variational Approaches and MI Estimation Challenges The estimation of MI faces inherent challenges, particularly within variational lower bounds. These bounds often degrade as MI increases, creating a delicate trade-off between high bias and high variance. To address this, methods that utilize upper bounds on MI have been developed, attempting to mitigate challenges associated with variational bounds. One strategy for MI maximization involves computing gradients of a lower MI bound concerning the parameters of a stochastic encoder. This computational approach potentially eliminates the need for direct MI estimation, providing a more tractable solution. However, estimating MI from samples remains challenging, and traditional approaches encounter scalability issues in modern machine-learning problems. ", "page_idx": 17}, {"type": "text", "text": "It\u2019s crucial to note that higher estimated MI between observations and learned representations does not consistently translate to improved predictive performance in downstream supervised learning tasks. CPC is an example, exhibiting less variance but more bias, with estimates capped at $\\log\\left|B\\right|$ . Strategies to reduce bias, such as increasing the batch size, introduce higher computational complexity, requiring additional evaluations for estimating each batch with the encoding function. ", "page_idx": 17}, {"type": "text", "text": "In our empirical approach, we adopt a specific sampling strategy for sequences, considering a onetime step per batch. This facilitates computing the InfoNCE between local summary features at time t and the future prediction of local features, leading to a reduction in algorithmic complexity for contrastive loss computation. Empirical observations demonstrate non-decreased representation quality and improved prediction of factual and counterfactual outcomes. ", "page_idx": 18}, {"type": "text", "text": "Other MI lower bounds. The Mutual Information Neural Estimator (MINE) [4] leverages the relationship between MI and the Kullback-Leibler (KL) divergence. MI can be expressed as the KL divergence between the joint distribution and the product of marginals: ", "page_idx": 18}, {"type": "equation", "text": "$$\nI(X;Z):=D_{K L}(\\mathbb{P}_{(X,Z)}\\parallel\\mathbb{P}_{X}\\otimes\\mathbb{P}_{Z})\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "MINE employs the Donsker-Varadhan representation [20] of the KL divergence: ", "page_idx": 18}, {"type": "equation", "text": "$$\nD_{K L}(\\mathbb{P}\\,|\\,\\mathbb{Q})=\\operatorname*{sup}_{T:\\Omega\\to\\mathbb{R}}\\mathbb{E}_{\\mathbb{P}}[T]-\\log\\left(\\mathbb{E}_{\\mathbb{Q}}[e^{T}]\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Here, the supremum is taken over all functions $T$ where the expectations exist. For a specific class of functions $\\mathcal{F}$ , potentially represented by a class of neural networks, we obtain the lower bound: ", "page_idx": 18}, {"type": "equation", "text": "$$\nD_{K L}(\\mathbb{P}\\,\\|\\,\\mathbb{Q})\\geq\\operatorname*{sup}_{T\\in\\mathcal{F}}\\mathbb{E}_{\\mathbb{P}}[T]-\\log\\left(\\mathbb{E}_{\\mathbb{Q}}[e^{T}]\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "In practice, we maximize ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\hat{I}_{\\gamma}^{\\mathrm{MINE}}(\\mathbb{P}\\left\\|\\mathbb{Q})=\\mathbb{E}_{\\mathbb{P}}[T_{\\gamma}]-\\log\\left(\\mathbb{E}_{\\mathbb{Q}}[e^{T_{\\gamma}}]\\right),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $T_{\\gamma}$ is a discriminator parameterized by $\\gamma$ , representing neural network parameters. The MINE estimator is a strongly consistent estimator of the true MI (Theorem 2, [4]). ", "page_idx": 18}, {"type": "text", "text": "Alternatively, the f-divergence representation of $D_{K L}$ [51] allows us to derive another MI lower bound, known as the Nguyen, Wainwright, and Jordan (NWJ) estimator [50]: ", "page_idx": 18}, {"type": "equation", "text": "$$\nD_{K L}(\\mathbb{P}\\,|\\,\\mathbb{Q})\\ge\\operatorname*{sup}_{T\\in\\mathcal{F}}\\mathbb{E}_{\\mathbb{P}}[T]-\\log\\left(\\mathbb{E}_{\\mathbb{Q}}[e^{T-1}]\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "This results in the estimator: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\hat{I}_{\\gamma}^{\\mathrm{NWJ}}(\\mathbb{P},\\mathbb{Q})=\\mathbb{E}_{\\mathbb{P}}[T_{\\gamma}]-\\log\\left(\\mathbb{E}_{\\mathbb{Q}}[e^{T_{\\gamma}-1}]\\right).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Unlike the InfoNCE estimator, which exhibits high bias and low variance, the NWJ estimator has a low bias but high variance [57]. ", "page_idx": 18}, {"type": "text", "text": "D Experimental protocol ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "All models were implemented using PyTorch [53] and PyTorch Lightning [21]. In contrast to the approach in [48], we employed early stopping for all models. The stopping criterion was defined as the Mean Squared Error over factual outcomes for a dedicated validation dataset. Specifically, for the Causal CPC encoder, the stopping criterion was determined by the validation loss of the encoder. ", "page_idx": 18}, {"type": "text", "text": "While all models in the benchmark were trained using the Adam optimizer [36], we opted for training Causal CPC (encoder plus decoder without the treatment subnetwork) with AdamW [46] due to its observed stability during training. Similar to the common practice in training GAN discriminators, the treatment subnetwork was optimized using SGD with momentum [74]. ", "page_idx": 18}, {"type": "text", "text": "The CT employed the Exponential Moving Average (EMA) [83] of parameters to enhance training stability. However, this technique was not applied to Causal CPC, as experimental evidence suggested only marginal improvements. Weight decay was set to zero for all models. ", "page_idx": 18}, {"type": "text", "text": "For each experiment, the models were trained over five different seeds, and the reported performance metrics include the mean and standard deviation of the results. ", "page_idx": 18}, {"type": "text", "text": "The counterfactual trajectories are generated following two strategies: ", "page_idx": 18}, {"type": "text", "text": "\u2022 Single sliding treatment [7, 48]: Trajectories are generated with a single treatment per trajectory while the treatment slides over the forecasting range to generate multiple trajectories. Similar to [7], we apply such a generation scheme to cancer simulation data. \u2022 Random trajectories: Trajectories are generated such that at each time step, treatment is generated randomly. We apply random trajectories to semi-synthetic MIMIC data. ", "page_idx": 18}, {"type": "text", "text": "For the falsifiability test on MIMIC III datset, we mask two confounders from the inputs of the benchmark models, namely sodium and glucose measurements. ", "page_idx": 18}, {"type": "text", "text": "E Experiments on synthetic data: Details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "E.1 Description of the Simulation Model ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We present a tumor growth simulation model, focusing on the PharmacoKinetic-PharmacoDynamic (PK-PD) model as discussed in [24], a recent approach to predicting treatment responses in non-small cell lung cancer patients. This simulation models the evolution of tumor volume, denoted by $\\mathbf{}V(t)$ , in discrete time, where $t$ represents the number of days since diagnosis: ", "page_idx": 19}, {"type": "equation", "text": "$$\nV(t)=\\left(1+\\underbrace{\\Lambda\\log\\left(\\frac{K}{V(t-1)}\\right)}_{\\mathrm{Tumor~Growth}}-\\underbrace{\\kappa_{c}C(t)}_{\\mathrm{Chemotherapy}}-\\underbrace{\\left(\\kappa_{r d}R d(t)+v R d(t)^{2}\\right)}_{\\mathrm{Radiation}}+\\underbrace{e_{t}}_{\\mathrm{Noise}}\\right)V(t-1)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Here, the model parameters $\\Lambda,K,\\kappa_{c},\\kappa_{r d},\\upsilon$ are sampled for each patient based on prior distributions from [24]. Additionally, $R d(t)$ represents the radiation dose applied at time $t$ , and $C(t)$ denotes the drug concentration. ", "page_idx": 19}, {"type": "text", "text": "We introduce confounding into the assignment of radiotherapy/chemotherapy treatment by making it dependent on past tumor volume evolution. Treatment is simulated using a Bernoulli distribution with probability $\\sigma(\\pi_{t})$ , where: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\pi_{t}=\\frac{\\gamma}{D_{\\mathrm{max}}}\\left(\\bar{D}(t)-\\delta\\right)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "In this context: $\\bar{D}(t)$ represents the average tumor diameter over the last 15 days, $D_{\\mathrm{max}}=13\\,\\mathrm{cm}$ is the maximum tumor diameter, $\\delta$ is set to $\\bar{\\delta}=D_{\\mathrm{max}}/2$ . ", "page_idx": 19}, {"type": "text", "text": "The parameter $\\gamma$ controls the level of time-dependent confounding, with a higher $\\gamma$ value assigning more weight to the history of tumor diameter in treatment assignment. ", "page_idx": 19}, {"type": "text", "text": "E.2 Additional results ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "E.2.1 Comparison to benchmark models ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We report in this section detailed counterfactual errors for Causal CPC and baselines over the cancer simulation dataset, which are responsible for Figure 3. ", "page_idx": 19}, {"type": "text", "text": "Table 6: Results on the synthetic data set with sequence length 60: mean\u00b1standard deviation of NRMSEs. The best value for each metric is given in bold: smaller is better. ", "page_idx": 19}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/ab16ba2fc465beb5daf2901157854012c9fb39b05afdce1e56794beaa736a5ca.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "E.2.2 Ablation study ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We detail here the results of the ablation study conducted on the cancer simulation dataset (Table 3). The (full) Causal CPC model, as presented in the core paper, gives, in most cases, better results than any ablation configuration. ", "page_idx": 19}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/051030a73af6c7e2004d201479b577bdd3e7f78aa6e6c88339fcee94bffa0b51.jpg", "table_caption": ["Table 7: Results on the synthetic data set with sequence length 40: mean\u00b1standard deviation of NRMSEs. The best value for each metric is given in bold: smaller is better. "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "Table 8: Results of the ablation study on the synthetic data set: mean $\\pm$ standard deviation of Normalized Rooted Mean Squared Errors (NRMSEs). The best value for each metric is given in bold: smaller is better. ", "page_idx": 20}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/c5a50a323f621caf03e6992aea8a1be31edadaf11c51bf56c823cd65546fbdee.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "F Experiments on semi-synthetic data: Details ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "F.1 Description of the simulation model ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In this section, we provide a concise overview of the simulation model built upon the MIMIC III dataset, as introduced by [48]. Initially, a cohort of 1,000 patients is extracted from the MIMIC III data, and the simulation proposed by [48] extends the model of [68]. ", "page_idx": 20}, {"type": "text", "text": "Let $d_{y}$ be the dimension of the outcome variable. In the case of multiple outcomes, untreated outcomes, denoted as $\\mathbf{Z}_{t}^{j,(i)}$ for $j=1,\\dots,d_{y}$ , are generated for each patient $i$ within the cohort. The generation process is defined as follows: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbf{Z}_{t}^{j,(i)}=\\underbrace{\\alpha_{S}^{j}\\mathbf{B}\\mathbf{-}\\mathrm{spline}(t)+\\alpha_{g}^{j}g^{j,(i)}(t)}_{\\mathrm{endogenous}}+\\underbrace{\\alpha_{f}^{j}f_{Z}^{j}\\left(\\mathbf{X}_{t}^{(i)}\\right)}_{\\mathrm{exogenous}}+\\underbrace{\\varepsilon_{t}}_{\\mathrm{noise}}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where: the B-spline B-spline $(t)$ is an endogenous component, $g^{j,(i)}(\\cdot)$ is sampled independently for each patient from a Gaussian process with a Mat\u00e9rn kernel and $f_{Z}^{j}(\\cdot)$ is sampled from a Random Fourier Features (RFF) approximation of a Gaussian process. ", "page_idx": 20}, {"type": "text", "text": "To introduce confounding in the assignment mechanism, current time-varying covariates are incorporated via a random function $f_{Y}^{l}\\left({{\\bf{X}}_{t}}\\right)$ and the average of the subset of the previous $T_{l}$ treated outcomes, $\\bar{\\mathbf{\\,l}}_{T_{l}}\\left(\\overline{{\\mathbf{Y}}}_{t-1}\\right)$ . For $d_{a}$ binary treatments ${\\bf A}_{t}^{l}$ , where $l=1,\\ldots,d_{a}$ , the assignment mechanism is modeled as: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{p_{\\mathbf{A}_{t}^{l}}=\\sigma\\left(\\gamma_{A}^{l}\\bar{A}_{T_{l}}\\left(\\overline{{\\mathbf{Y}}}_{t-1}\\right)+\\gamma_{X}^{l}f_{Y}^{l}\\left(\\mathbf{X}_{t}\\right)+b_{l}\\right),}\\\\ &{\\mathbf{A}_{t}^{l}\\sim\\mathrm{Bernoulli}\\left(p_{\\mathbf{A}_{t}^{l}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Subsequently, treatments are applied to the untreated outcomes using the following expression: ", "page_idx": 20}, {"type": "equation", "text": "$$\nE^{j}(t)=\\sum_{i=t-w^{l}}^{t}\\frac{\\operatorname*{min}_{l=1,\\ldots,d_{a}}{\\ddot{W}}_{\\left[\\mathbf{A}_{i}^{l}=1\\right]}p_{\\mathbf{A}_{i}^{l}}\\beta_{l j}}{\\left(w^{l}-i\\right)^{2}}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The final outcome combines the treatment effect and the untreated simulated outcome: ", "page_idx": 20}, {"type": "equation", "text": "$$\nY_{t}^{j}=Z_{t}^{j}+E^{j}(t).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "F.2 Additional results ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "F.2.1 Ablation study ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We detail here the results of the ablation study conducted on the MIMIC III semi-synthetic dataset (Table 3). The (full) Causal CPC model, as presented in the core paper, gives consistently better results than any ablation configuration. ", "page_idx": 21}, {"type": "text", "text": "Table 9: Results on MIMIC III semi-synthetic data set: mean\u00b1standard deviation of Normalized Rooted Mean Squared Errors (NRMSEs). The best value for each metric is given in bold: smaller is better. ", "page_idx": 21}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/ee41815eff8d680c374388e1f7e969b14c022a174fb9a2eca1e4064db1c02b5a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "Furthermore, We replace the InfoNCE objective used to compute the CPC term and InfoMax terms with that of NWJ and MINE (Section C.2). We repeat the same MIMIC III experimentation while varying the objective used for CPC and InfoMax. Table 10 shows the counterfactual errors for each configuration compared to the original formulation of Causal CPC. In all cases, The InfoNCE objective performs better with notable error reduction at large horizons. ", "page_idx": 21}, {"type": "text", "text": "Table 10: Results of NWJ and MINE MI lower bounds when used for CPC and InfoMax for MIMIC III semi-synthetic data set: mean $\\pm$ standard deviation of Normalized Rooted Mean Squared Errors (NRMSEs). The best value for each metric is given in bold: smaller is better. ", "page_idx": 21}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/0621d29a981ac98d4aa58959ef67616408aa36ab95ffdfda8a6b7702584946f3.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "F.2.2 Comparison to benchmark models: standard train/test split ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "As mentioned in Section 6.2, We also tested Causal CPC on MIMIC III semi-synthetic data using the same experimental protocol as [48], namely by using the split of patients into train/validation/test as 800/200/200. As a result, baseline performances in Table 11 are exactly the same as in [48]. ", "page_idx": 21}, {"type": "text", "text": "Table 11: Results over the MIMIC III semi-synthetic data set (same experimental protocol as in [48]): mean\u00b1standard deviation of Rooted Mean Squared Errors (RMSEs). The best value for each metric is given in bold: smaller is better. ", "page_idx": 21}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/e9a36ead268ad420eace227e16ffd1dd0963e83cb261b8db86b19d1aacbe9b21.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "F.2.3 Running time and model complexity ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In this section, we complement the table about complexity and running time given for cancer simulation in the core paper by providing the exact same table but for MIMIC III semi-synthetic data. ", "page_idx": 21}, {"type": "text", "text": "G Proofs of theoretical results ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "G.1 Relation between InfoNCE loss and mutual information Proposition G.1. ", "page_idx": 21}, {"type": "equation", "text": "$$\nI(\\mathbf{U}_{t+j},\\mathbf{C}_{t})\\geq\\log(|\\mathcal{B}|)-\\mathcal{L}_{j}^{(I n f o N C E)}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Table 12: The number of parameters to train for each model after hyper-parameters fine-tuning and the corresponding running time averaged over five seeds. Results are reported for semi-synthetic MIMIC III data; the processing unit is GPU - 1 x NVIDIA Tesla M60 . ", "page_idx": 22}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/c028df1b1090ff669d7996dad1e54d15073043212a4b28e36e6123369e08ce71.jpg", "table_caption": [], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "Proof. In the following, we draw inspiration from the proof of [52]. The InfoNCE loss corresponds to the categorical cross-entropy of classifying the positive sample $\\mathbf{U}_{t+j}$ correctly, given the context $\\mathbf{C}_{t}$ , with a probability: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{\\exp(T_{j}(\\mathbf{U}_{t+j},\\mathbf{C}_{t}))}{\\sum_{l=1}^{|\\mathcal{B}|}\\exp(T_{j}(\\mathbf{U}_{l,t+j},\\mathbf{C}_{t}))}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The positive sample $\\mathbf{U}_{t+j}$ is one element in the batch $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ , where the remaining elements serve as negative samples. Let $\\mathtt{p o s}\\in\\{1,\\dots,|B|\\}$ be the indicator of the positive sample $\\mathbf{U}_{t+j}$ . The optimal probability is given by: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left(\\mathrm{Index}=\\mathrm{pos}\\mid\\mathcal{B},\\mathbf{C}_{t}\\right)=\\frac{p(\\mathbf{u}_{\\mathrm{pos},t+j}\\mid\\mathbf{C}_{t})\\prod_{l=1,\\ldots,\\mid B\\mid;l\\neq p\\circ s}p(\\mathbf{u}_{l,t+j})}{\\sum_{j=1}^{\\lfloor B\\rfloor}\\left[p(\\mathbf{u}_{j,t+j}\\mid\\mathbf{C}_{t})\\prod_{l=1,\\ldots,\\mid B\\mid;l\\neq j}p(\\mathbf{u}_{l,t+j})\\right]}=\\frac{\\frac{p(\\mathbf{u}_{\\mathrm{pos},t+j}\\mid\\mathbf{C}_{t})}{p(\\mathbf{u}_{\\mathrm{pos},t+j})}}{\\sum_{j=1}^{\\lfloor B\\rfloor}\\frac{p(\\mathbf{u}_{j,t+j}\\mid\\mathbf{C}_{t})}{p(\\mathbf{u}_{j,t+j})}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "For the score $\\exp(T_{j}(\\mathbf{U}_{t+j},\\mathbf{C}_{t}))$ to be optimal, it should be proportional to $\\frac{p(\\mathbf{u}_{\\mathtt{p o s},t+j}|\\mathbf{C}_{t})}{p(\\mathbf{u}_{\\mathtt{p o s},t+j})}$ . The mutual information (MI) lower bound arises from the fact that $\\exp(T_{j}(\\mathbf{U}_{t+j},\\dot{\\mathbf{C}_{t}}))$ estimates the density ratio p(upos,t+j|Ct). ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathcal{L}_{j}^{(I n f o N C E)}=-\\mathbb{E}_{\\mathcal{B}}\\log\\left[\\frac{\\frac{p(\\mathbf{u}_{t+j}|\\mathbf{x}_{t})}{p(\\mathbf{u}_{t+j})}}{\\frac{p(\\mathbf{u}_{t+j}|\\mathbf{x}_{t})}{p(\\mathbf{u}_{t+j})}+\\sum_{u_{t+i+j}}e^{\\frac{p(\\mathbf{u}_{t+i+j}|\\mathbf{x}_{t})}{p(\\mathbf{u}_{t+i+j})}}}\\right]}\\\\ {=\\mathbb{E}_{\\mathcal{B}}\\log\\left[1+\\frac{p\\left(\\mathbf{u}_{t+j}\\right)}{p\\left(\\mathbf{u}_{t+j}\\right)\\,\\mathrm{e}^{\\frac{p}{t}}\\mathrm{u}_{t+i,j}e^{\\theta_{N_{a}}}}\\frac{p\\left(\\mathbf{u}_{t+i,j}|\\mathbf{\\phi}_{\\mathrm{c}}\\right)}{p\\left(\\mathbf{u}_{t+j}\\right)}\\right]}\\\\ {\\approx\\mathbb{E}_{\\mathcal{B}}\\log\\left[1+\\frac{p\\left(\\mathbf{u}_{t+j}\\right)}{p\\left(\\mathbf{u}_{t+i+j}\\right)\\,\\mathrm{e}^{\\mathrm{i}\\left(\\left(\\mathcal{B}\\right)/\\mathbf{t}_{+i}\\right)}}\\frac{p\\left(\\mathbf{u}_{t+j+j}\\right)}{p\\left(\\mathbf{u}_{t+i+j}\\right)}\\right]}\\\\ {=\\mathbb{E}_{\\mathcal{B}}\\log\\left[1+\\frac{p\\left(\\mathbf{u}_{t+j}\\right)}{p\\left(\\mathbf{u}_{t+i+j}\\right)}\\left(\\left|\\mathcal{B}\\right|-1\\right)\\right]}\\\\ {\\geq\\mathbb{E}_{\\mathcal{B}}\\log\\left[\\frac{p\\left(\\mathbf{u}_{t+j}\\right)}{p\\left(\\mathbf{u}_{t+j}\\right)\\,\\mathrm{e}^{\\mathrm{i}\\left(\\mathcal{B}\\right)}}\\right]}\\\\ {=-I\\left(\\mathbf{u}_{t+j}\\right)\\mathrm{.e}\\right)+\\log(\\left|\\mathcal{B}\\right|),}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The approximation in the third equation, Eq. (19), becomes more precise as the batch size increases. ", "page_idx": 22}, {"type": "text", "text": "G.2 Relation between InfoMax and Input Reconstruction ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We now prove Proposition 5.1, which states that: ", "page_idx": 22}, {"type": "equation", "text": "$$\nI(\\mathbf{C}_{t}^{h},\\mathbf{C}_{t}^{f})\\leq I(\\mathbf{H}_{t},(\\mathbf{C}_{t}^{h},\\mathbf{C}_{t}^{f})).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. This follows from two applications of the data processing inequality [17], which states that for random variables $A,\\,B$ , and $C$ satisfying the Markov relation $A\\rightarrow B\\rightarrow C$ , the inequality $I(A;C)\\leq I(A;B)$ holds. ", "page_idx": 22}, {"type": "text", "text": "First, since ${\\bf C}_{t}^{h}\\;=\\;\\Phi_{\\theta_{1},\\theta_{2}}({\\bf H}_{t}^{h})$ and $\\mathbf{C}_{t}^{f}\\ =\\ \\Phi_{\\theta_{1},\\theta_{2}}(\\mathbf{H}_{t}^{f})$ , we can write $\\mathbf{H}_{t}^{h}\\ =\\ \\operatorname{trunc}_{f}(\\mathbf{H}_{t})$ and $\\mathbf{H}_{t}^{f}=\\operatorname{trunc}_{h}(\\mathbf{H}_{t})$ , where $\\operatorname{trunc}_{f}$ and $\\operatorname{trunc}_{h}$ truncate the future and history processes, respectively, given a splitting time $t_{0}$ . ", "page_idx": 22}, {"type": "text", "text": "Thus, we have the Markov relation: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbf{C}_{t}^{h}\\xleftarrow{\\frac{\\Phi_{\\theta_{1},\\theta_{2}}\\circ\\mathrm{trunc}_{f}}{\\mathbf{C}_{t}}}\\mathbf{H}_{t}\\xrightarrow{\\Phi_{\\theta_{1},\\theta_{2}}\\circ\\mathrm{trunc}_{h}}\\mathbf{C}_{t}^{f},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "which is Markov equivalent to: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbf{C}_{t}^{h}\\xrightarrow{\\Phi_{\\theta_{1},\\theta_{2}}\\mathrm{otrunc}_{f}}\\mathbf{H}_{t}\\xrightarrow{\\Phi_{\\theta_{1},\\theta_{2}}\\mathrm{otrunc}_{h}}\\mathbf{C}_{t}^{f}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "By the data processing inequality, this results in $I(\\mathbf{C}_{t}^{h},\\mathbf{C}_{t}^{f})\\leq I(\\mathbf{H}_{t},\\mathbf{C}_{t}^{h})$ . On the other hand, we have the trivial Markov relation $\\mathbf{H}_{t}\\to(\\mathbf{C}_{t}^{h},\\mathbf{C}_{t}^{f})\\to\\mathbf{C}_{t}^{h}$ , which implies $I(\\mathbf{H}_{t},\\mathbf{C}_{t}^{h})\\leq I(\\mathbf{H}_{t},(\\mathbf{C}_{t}^{h},\\mathbf{C}_{t}^{f}))$ . Combining these two inequalities proves the proposition. ", "page_idx": 23}, {"type": "text", "text": "G.3 Proof of Theorem 5.2 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "To begin, we split the process history into two non-overlapping views (Figure 2): $\\mathbf{H}_{t}^{h}:=\\mathbf{U}_{1:t_{0}}$ and $\\mathbf{H}_{t}^{f}:=\\mathbf{U}_{t_{0}+1:t}$ , representing a historical subsequence and a future subsequence within the process history $\\mathbf{H}_{t}$ , respectively. We then computed representations of these two views denoted $\\mathbf{C}_{t}^{h}$ and $\\mathbf{C}_{t}^{f}$ , respectively. This naturally gives rise to the Markov chain, as in showed in the proof of proposition 5.1: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbf{C}_{t}^{h}\\gets\\mathbf{H}_{t}\\to\\mathbf{C}_{t}^{f}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "which is Markov equivalent to: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbf{C}_{t}^{h}\\rightarrow\\mathbf{H}_{t}\\rightarrow\\mathbf{C}_{t}^{f}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Following this Markov chain, we can show that [71]: ", "page_idx": 23}, {"type": "equation", "text": "$$\nI(\\mathbf{C}_{t}^{f},\\mathbf{C}_{t}^{h})=I(\\mathbf{H}_{t},\\mathbf{C}_{t}^{h})-\\mathbb{E}_{\\mathbf{h}_{t}\\sim\\mathbb{P}_{\\mathbf{H}_{t}}}\\mathbb{E}_{\\mathbf{c}_{t}^{f}\\sim\\mathbb{P}_{\\mathbf{C}_{t}^{f}\\mid\\mathbf{h}_{t}}}\\left[D_{K L}[\\mathbb{P}_{\\mathbf{C}_{t}^{h}\\mid\\mathbf{h}_{t}}||\\mathbb{P}_{\\mathbf{C}_{t}^{h}\\mid\\mathbf{c}_{t}^{f}}]\\right]\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "On the other hand, by applying the chain rule of the mutual information to $I(\\mathbf{H}_{t};(\\mathbf{C}_{t}^{h},\\mathbf{C}_{t}^{f}))$ we get: ", "page_idx": 23}, {"type": "equation", "text": "$$\nI(\\mathbf{H}_{t};(\\mathbf{C}_{t}^{f},\\mathbf{C}_{t}^{h}))=I(\\mathbf{H}_{t},\\mathbf{C}_{t}^{h})+I(\\mathbf{H}_{t};\\mathbf{C}_{t}^{f}\\mid\\mathbf{C}_{t}^{h})\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Combining these equations, the tightness of our bounds can be written as: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\big(\\mathbf{H}_{t};\\big(\\mathbf{C}_{t}^{f},\\mathbf{C}_{t}^{h}\\big)\\big)-I\\big(\\mathbf{C}_{t}^{f},\\mathbf{C}_{t}^{h}\\big)=I\\big(\\mathbf{H}_{t};\\mathbf{C}_{t}^{f}\\mid\\mathbf{C}_{t}^{h}\\big)+\\mathbb{E}_{\\mathbf{h}_{t}\\sim\\mathbb{P}\\mathbf{H}_{t}}\\mathbb{E}_{\\mathbf{c}_{t}^{f}\\sim\\mathbb{P}\\mathbf{C}_{t}^{f}\\mid\\mathbf{h}_{t}}\\left[D_{K L}\\big[\\mathbb{P}_{\\mathbf{C}_{t}^{h}\\mid\\mathbf{h}_{t}}||\\mathbb{P}_{\\mathbf{C}_{t}^{h}\\mid\\mathbf{c}_{t}^{f}}\\big]\\right]\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "G.4 On the Relation Between Conditional Entropy and Reconstruction ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We now prove the statement in the core paper, which asserts that the conditional entropy $H(\\mathbf{H}_{t}\\mid$ $(\\mathbf{C}_{t}^{h},\\mathbf{C}_{t}^{f}))\\ge0$ is minimized if $\\mathbf{H}_{t}$ is almost surely a function of $({\\bf C}_{t}^{h},{\\bf C}_{t}^{f})$ . The proof is adapted from [17]. ", "page_idx": 23}, {"type": "text", "text": "Proposition G.2. If $H(\\mathbf{A}\\mid\\mathbf{B})=0,$ , then $\\mathbf{A}=f(\\mathbf{B})$ almost surely. ", "page_idx": 23}, {"type": "text", "text": "Proof. For simplicity, suppose A and $\\mathbf{B}$ are discrete random variables. Assume, by contradiction, that there exists ${\\bf b}_{0}$ and two distinct values ${\\bf a}_{1}$ and ${\\bf a}_{2}$ such that $p(\\mathbf{a}_{1}\\mid\\mathbf{b}_{0})>0$ and $p(\\mathbf{a}_{2}\\mid\\mathbf{b}_{0})>0$ . Then, the conditional entropy is given by: ", "page_idx": 23}, {"type": "equation", "text": "$$\nH(\\mathbf{A}\\mid\\mathbf{B})=-\\sum_{\\mathbf{b}}p(\\mathbf{b})\\sum_{\\mathbf{a}}p(\\mathbf{a}\\mid\\mathbf{b})\\log p(\\mathbf{a}\\mid\\mathbf{b}).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "In particular, we have: ", "page_idx": 23}, {"type": "equation", "text": "$$\nH(\\mathbf{A}\\mid\\mathbf{B})\\geq p(\\mathbf{b}_{0})\\left(-p(\\mathbf{a}_{1}\\mid\\mathbf{b}_{0})\\log p(\\mathbf{a}_{1}\\mid\\mathbf{b}_{0})-p(\\mathbf{a}_{2}\\mid\\mathbf{b}_{0})\\log p(\\mathbf{a}_{2}\\mid\\mathbf{b}_{0})\\right)>0.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Since $-t\\log t\\geq0$ for $0\\le t\\le1$ and is strictly positive for $t$ not equal to 0 or 1, the conditional entropy $H(\\mathbf{A}\\mid\\mathbf{B})=0$ if and only if $\\mathbf{A}$ is almost surely a function of $\\mathbf{B}$ . \u53e3 ", "page_idx": 23}, {"type": "text", "text": "G.5 On the benefit of the InfoMax loss on inverting the data generation process ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "To ensure identifiability in the latent space, we leverage recent advances in causal and disentangled representation learning. Suppose the true data-generating process is given by ${\\bf H}_{t}=g({\\bf z}_{t})$ , where $\\mathbf{z}_{t}$ represents the true latent factors. In the sequential context, we assume that the same function $g$ generates two historical subsequences: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbf{H}_{t}^{f}=g(\\mathbf{z}_{t}^{f}),\\quad\\mathbf{H}_{t}^{h}=g(\\mathbf{z}_{t}^{h}).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We assume a general dependency of the form: ", "page_idx": 24}, {"type": "equation", "text": "$$\np(\\mathbf{z}_{t}^{f}\\mid\\mathbf{z}_{t}^{h})=\\frac{Q(\\mathbf{z}_{t}^{f})}{Z(\\mathbf{z}_{t}^{h})}\\exp(-d(\\mathbf{z}_{t}^{f},\\mathbf{z}_{t}^{h})).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Here, $\\Phi$ is an encoder, and we use the InfoMax regularization term as follows: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathcal{L}^{(I n f o M a x)}(\\Phi,d,\\mathcal{B}):=-\\mathbb{E}_{\\mathcal{B}}\\left[\\log\\frac{\\exp(-d(\\Phi(\\mathbf{H}_{t}^{f}),\\Phi(\\mathbf{H}_{t}^{h})))}{\\sum_{l=1}^{|\\mathcal{B}|}\\exp(-d(\\Phi(\\mathbf{H}_{l,t}^{f}),\\Phi(\\mathbf{H}_{t}^{h})))}\\right]\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "According to [47], under certain conditions, if the encoder $f$ minimizes $\\mathcal{L}^{(I n f o M a x)}$ , then $h=g\\circ f$ is a scaled permutation matrix. This result suggests that when the encoder achieves a minimizer for $\\mathcal{L}^{(I n f o M a x)}$ , the encoder function $f$ closely approximates an invertible transformation of $g$ . ", "page_idx": 24}, {"type": "text", "text": "From a causal inference perspective, if $Y_{i t}(\\omega_{i t})\\perp\\!\\!\\!\\perp W_{i t}\\mid\\mathbf{H}_{i t}$ and $\\mathbf{H}_{i t}=g(\\mathbf{Z}_{i t})$ , then an invertible function $g\\circ f$ ensures that: ", "page_idx": 24}, {"type": "equation", "text": "$$\nY_{i t}(\\omega_{i t})\\perp W_{i t}\\mid g\\circ f(\\mathbf{H}_{i t}).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Thus, $Y_{i t}(\\omega_{i t})\\perp W_{i t}\\mid g(\\mathbf{C}_{i t})$ and since $g$ is invertible, we have: ", "page_idx": 24}, {"type": "equation", "text": "$$\nY_{i t}(\\omega_{i t})\\perp\\!\\!\\!\\perp W_{i t}\\mid\\mathbf{C}_{i t}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "This demonstrates that the representation $\\mathbf{C}_{i t}$ retains the essential independence structure, facilitating accurate counterfactual inference. ", "page_idx": 24}, {"type": "text", "text": "G.6 Proof of theorem 5.4 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "To prove the Theorem 5.4, we first prove the following lemma and proposition. ", "page_idx": 24}, {"type": "text", "text": "Lemma G.3. Let $\\Phi$ be a fixed representation function. Given that $q(W_{t+1}\\mid\\Phi({\\bf H}_{t}))$ is the conditional likelihood of observing the treatment $W_{t+1}$ , denote the probability of observing each treatment value as $q^{j}=q(\\Phi(\\mathbf{H}_{t})):=q(W_{t+1}=j\\mid\\Phi(\\dot{\\mathbf{H}}_{t}))$ for $j\\in\\{0,1,\\ldots,K-1\\}$ . Then, the optimal treatment prediction function is such that ", "page_idx": 24}, {"type": "equation", "text": "$$\nq^{j,\\ast}(\\Phi(\\mathbf{H}_{t}))={\\frac{p(\\Phi(\\mathbf{H}_{t})\\mid W_{t+1}=j)}{\\sum_{l=0}^{K-1}p(\\Phi(\\mathbf{H}_{t})\\mid W_{t+1}=l)p(W_{t+1}=l)}}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof. For a fixed representation $\\Phi$ , finding the optimal treatment probabilities amounts to solving the following optimization problem: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{q}\\mathbb{E}_{\\mathbb{P}(\\Phi(\\mathbf{H}_{t}),W_{t+1})}\\left[\\log q(W_{t+1}\\mid\\Phi(\\mathbf{H}_{t}))\\right]\\quad{\\mathrm{subject~to~}}\\quad\\sum_{l=0}^{K-1}q^{l}(\\Phi(\\mathbf{H}_{t}))=1\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "First, we write the likelihood $q(W_{t+1}\\mid\\Phi({\\bf H}_{t}))$ using the conditional probabilities $q^{j}(\\Phi(\\mathbf{H}_{t}))$ . ", "page_idx": 24}, {"type": "equation", "text": "$$\nq(W_{t+1}\\mid\\Phi(\\mathbf{H}_{t}))=\\prod_{j=0}^{K-1}q^{j}(\\Phi(\\mathbf{H}_{t}))^{\\mathbb{1}_{\\{W_{t+1}=j\\}}}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Then, the treatment likelihood can be written as ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbf{\\Phi}_{i}),W_{t+1})\\left[\\log q(W_{t+1}\\mid\\Phi(\\mathbf{H}_{t}))\\right]=\\mathbb{E}_{\\mathcal{F}(\\Phi(\\mathbf{H}_{t}),W_{t+1})}\\left[\\displaystyle\\sum_{l=0}^{K-1}\\log(q^{l}(\\Phi(\\mathbf{H}_{t})))\\mathbf{1}_{\\{W_{t+1}=j\\}}\\right]}\\\\ &{=\\displaystyle\\sum_{l=0}^{K-1}\\int\\log(q^{l}(\\Phi(\\mathbf{H}_{t}))\\mathbf{1}_{\\{W_{t+1}=j\\}}p(W_{t+1}\\mid\\Phi(\\mathbf{H}_{t}))p(\\Phi(\\mathbf{H}_{t}))d W_{t}}\\\\ &{=\\displaystyle\\sum_{l=0}^{K-1}\\int\\log(q^{l}(\\Phi(\\mathbf{H}_{t}))p(W_{t+1}=l\\mid\\Phi(\\mathbf{H}_{t}))p(\\Phi(\\mathbf{H}_{t}))d\\Phi(\\mathbf{H}_{t})}\\\\ &{=\\displaystyle\\sum_{l=0}^{K-1}\\int\\log(q^{l}(\\Phi(\\mathbf{H}_{t}))p(\\Phi(\\mathbf{H}_{t})\\mid W_{t+1}=l)p(W_{t+1}=l)d\\Phi(\\mathbf{H}_{t})}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Let\u2019s denote $\\alpha_{l}=p(W_{t+1}=l)$ , the marginal probability of observing the $l$ -th treatment regime, and $p_{l}^{\\Phi}(\\mathbf{H}_{t})=p(\\Phi(\\mathbf{H}_{t})\\mid W_{t+1}=l)$ with a corresponding probability distribution $\\mathbb{P}_{l}^{\\Phi}$ . We intend to maximize point-wise the objective in Eq. (21). Plugging the latter formulation of the conditional likelihood in Eq. (21) and writing the Lagrangian function, we get ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{q}\\sum_{i=0}^{K-1}\\log(q^{l}(\\Phi(\\mathbf{H}_{t}))p_{j}^{\\Phi}(\\mathbf{H}_{t})\\alpha_{l}+\\lambda(\\sum_{l=0}^{K-1}q^{l}(\\Phi(\\mathbf{H}_{t}))-1)\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Computing the gradient w.r.t $q^{l}(\\Phi(\\mathbf{H}_{t}))$ for $l\\in\\{0,1,\\ldots,K-1\\}$ and setting to zero, we have ", "page_idx": 25}, {"type": "equation", "text": "$$\nq^{l,*}(\\Phi(\\mathbf{H}_{t}))=-\\frac{\\alpha_{l}p_{j}^{\\Phi}(\\mathbf{H}_{t})}{\\lambda}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Then, by the equality constraint, we find that $\\begin{array}{r}{\\lambda=-\\sum_{l=0}^{K-1}\\alpha_{l}p_{j}^{\\Phi}(\\mathbf{H}_{t})}\\end{array}$ . ", "page_idx": 25}, {"type": "text", "text": "Proposition G.4. Let $\\Phi$ be a fixed representation function. The $I_{C L U B}$ objective when the treatment prediction function is optimal (i.e. $q=q^{*}$ ) has the following form: ", "page_idx": 25}, {"type": "equation", "text": "$$\nI_{C L U B}=\\sum_{j=0}^{K-1}\\alpha_{l}D_{K L}(\\mathbb{P}_{j}^{\\Phi}||\\sum_{l=0}^{K-1}\\alpha_{l}\\mathbb{P}_{l}^{\\Phi})+\\mathbb{E}_{\\mathbb{P}_{\\Phi(\\mathbf{H}_{t})}}\\left[D_{K L}(\\mathbb{P}_{W_{t+1}}||\\mathbb{P}_{W_{t+1}|\\Phi(\\mathbf{H}_{t})})\\right].\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof. First, recall that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{cLub}(\\Phi(\\mathbf{H}_{t}),W_{t+1};q^{*})=\\mathbb{E}_{\\mathbb{P}(\\Phi(\\mathbf{H}_{t+1}),w_{t+1})}\\left[\\log q^{*}(W_{t+1}\\mid\\Phi(\\mathbf{H}_{t+1}))\\right]-\\mathbb{E}_{\\mathbb{P}_{\\Phi(\\mathbf{H}_{t+1})}}\\mathbb{E}_{\\mathbb{P}_{W_{t+1}}}\\left(\\log q^{*}(W_{t+1})\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad I_{\\mathrm{CLUB}}(\\Phi(\\mathbf{H}_{t}),W_{t+1};q^{*})=A-B}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Let\u2019s detail $A$ and $B$ separately, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\cal A}=\\sum_{j=0}^{K-1}\\int\\alpha_{j}\\log(q^{l,*}({\\Phi}({\\bf H}_{t}))p_{j}^{\\Phi}({\\bf H}_{t})d\\Phi({\\bf H}_{t})}}\\\\ {~~}\\\\ {{\\displaystyle~~=\\sum_{j=0}^{K-1}\\int\\alpha_{j}\\log(\\frac{\\alpha_{j}p_{j}^{\\Phi}({\\bf H}_{t})}{\\sum_{l=0}^{K-1}p_{l}^{\\Phi}({\\bf H}_{t})\\alpha_{l}})p_{j}^{\\Phi}({\\bf H}_{t})d\\Phi({\\bf H}_{t})}}\\\\ {~~}\\\\ {{\\displaystyle~~=\\sum_{j=0}^{K-1}\\int\\alpha_{j}\\log(\\frac{p_{j}^{\\Phi}({\\bf H}_{t})}{\\sum_{l=0}^{K-1}p_{l}^{\\Phi}({\\bf H}_{t})\\alpha_{l}})p_{j}^{\\Phi}({\\bf H}_{t})d\\Phi({\\bf H}_{t})+\\log(\\alpha_{j})\\alpha_{j}}}\\\\ {~~}\\\\ {{\\displaystyle~~=\\sum_{j=0}^{K-1}\\alpha_{j}D_{K L}({\\mathbb P}_{j}^{\\Phi}||\\sum_{l=0}^{K-1}\\alpha_{l}{\\mathbb P}_{l}^{\\Phi})+\\sum_{j=0}^{K-1}\\log(\\alpha_{j})\\alpha_{j}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Finally, we can write ", "page_idx": 25}, {"type": "equation", "text": "$$\nA=\\sum_{j=0}^{K-1}\\alpha_{j}D_{K L}({\\mathbb{P}}_{j}^{\\Phi}||\\sum_{l=0}^{K-1}\\alpha_{l}{\\mathbb{P}}_{l}^{\\Phi})-H(W_{t+1})\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "For the remaining term $B$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{{\\mathbf f}=\\sum_{\\ell\\in\\mathcal{N}_{D},n_{0}}\\mathbb{E}_{\\mathbb{R}_{n}\\to\\infty}[\\log(\\ell\\left({\\mathbf K}_{\\ell+1}\\right)+[({\\mathbf K}_{\\ell+1})])]}\\\\ &{=\\sum_{\\ell=0}^{\\infty}\\mathbb{E}_{\\mathbb{R}_{n}\\to\\infty}[\\log(\\ell^{n}({\\mathbf K}_{\\ell}))]}\\\\ &{\\phantom{=}\\sum_{\\ell=0}^{\\infty}\\mathbb{E}_{\\mathbb{R}_{n}\\to\\infty}[\\log(\\sqrt{\\Phi}({\\mathbf K}_{\\ell}))]\\left(\\mu({\\mathbf K}_{\\ell+1})\\right)}\\\\ &{=\\sum_{\\ell=0}^{\\infty}\\mathbb{E}_{\\mathbb{R}_{n}\\to\\infty}[\\log(\\mu({\\mathbf K}_{\\ell}))]\\right)}\\\\ &{\\phantom{=}\\sum_{\\ell=0}^{\\infty}\\int_{{\\mathbb{R}_{n}}}\\biggl[\\exp\\biggl(\\frac{\\mu({\\mathbf K}_{\\ell})}{\\sqrt{\\mathbf K}_{\\ell}+\\ln\\mathcal{D}_{\\ell}}\\biggr)\\biggr]\\varphi({\\mathbf K}_{\\ell})\\phi({\\mathbf K}_{\\ell})}\\\\ &{=\\sum_{\\ell=0}^{\\infty}\\int_{{\\mathbb{R}_{n}}}\\biggl[\\frac{\\mathbb{E}_{\\ell}({\\mathbf K}_{\\ell})}{\\sqrt{\\mathbf K}_{\\ell}+\\ln\\mathcal{D}_{\\ell}}\\biggr\\{\\mathbb{E}_{\\ell}[\\log(\\frac{1}{n_{0}})]\\biggr\\}\\varphi({\\mathbf K}_{\\ell}))\\phi({\\mathbf K}_{\\ell})}\\\\ &{=\\sum_{\\ell=0}^{\\infty}\\int_{{\\mathbb{R}_{n}}}\\biggl[\\frac{\\mathbb{P}({\\mathbf K}_{\\ell})}{\\sum_{\\ell=0}^{\\infty}\\mathbb{P}_{\\ell}^{\\prime}[\\mathbf R_{\\ell}][\\mathbf R_{\\ell}][\\mathbf R_{\\ell}]}\\biggr\\{\\mathbb{E}_{\\ell}^{[\\ell]}[\\mathbf R_{\\ell+1}-j]\\left[\\Theta({\\mathbf K}_{\\ell})\\right]\\biggr\\}\\rho({\\mathbf K}_{\\ell}))\\rho({\\mathbf K}_{\\ell})}\\\\ &{=\\prod_{\\ell=1}^{\\infty}\\phi\\left(\\frac{1}{\\sqrt{\\mathbf K}_{\\ell}}\\right)\\left(\\frac{\\mathbb{P}({\\mathbf K}_{\\ell})}{\\sqrt{\\mathbf K}_{\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The final form of $B$ is therefore ", "page_idx": 26}, {"type": "equation", "text": "$$\nB=-\\int D_{K L}(\\mathbb{P}_{W_{t+1}}|\\mathbb{P}_{W_{t+1}|\\Phi(\\mathbf{H}_{t})})p(\\Phi(\\mathbf{H}_{t}))d\\Phi(\\mathbf{H}_{t})-H(W_{t+1})\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The proposition follows immediately from Equations (25) and (26). ", "page_idx": 26}, {"type": "text", "text": "Proof. (Theorem 5.4) Since by lemma G.3, the $I_{C L U B}$ formulation in proposition G.4 holds, then to prove that the representation is balanced, it is enough to see that by the positivity of $D_{K L}$ ", "page_idx": 26}, {"type": "equation", "text": "$$\nI_{C L U B}\\geq\\mathbb{E}_{\\mathbb{P}_{\\Phi(\\mathbf{H}_{t})}}\\left[D_{K L}\\big(\\mathbb{P}_{W_{t+1}}\\big|\\vert\\mathbb{P}_{W_{t+1}\\vert\\Phi(\\mathbf{H}_{t})}\\big)\\right]\\geq0\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "$I_{C L U B}$ is minimal when $I_{C L U B}\\,=\\,0$ , which happens if and only if for $j\\;\\in\\;\\{0,1,\\ldots,K-1\\}$ $p(W_{t+1}=j)=p(W_{t+1}=j\\mid\\Phi(\\mathbf{H}_{t}))$ almost surely which, by Bayes rule is equivalent to say $p(\\Phi(\\mathbf{H}_{t}))=p(\\Phi(\\mathbf{H}_{t})\\mid W_{t+1}=j)$ . ", "page_idx": 26}, {"type": "text", "text": "H Causal CPC Pseudo algorithm ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "In this section, we present a detailed overview of the training procedure for Causal CPC. Initially, we train the Encoder using only the contrastive terms, as outlined in Algorithm 1. Our primary objective is to ensure that, for each time step $t$ , the process history $\\mathbf{H}_{t}$ is predictive of future local features $\\mathbf{Z}_{t}$ . However, calculating the InfoNCE loss for a batch across all possible time steps $t=0,\\dots,t_{\\mathrm{max}}$ can be computationally demanding. ", "page_idx": 26}, {"type": "text", "text": "To address this, we adopt a more efficient approach by uniformly sampling a single time step $t$ per batch. Subsequently, the corresponding process history $\\mathbf{H}_{t}$ is contrasted. The sampled $\\mathbf{H}_{t}$ is then employed as input for the InfoMax objective and randomly partitioned into future $\\mathbf{H}_{t}^{f}$ and past $\\mathbf{H}_{t}^{h}$ sub-processes. ", "page_idx": 26}, {"type": "text", "text": "The decoder is trained while taking the encoder as input (Algorithm 2), utilizing a lower learning rate compared to the untrained part of the decoder. It is trained autoregressively and without teacher forcing. This implies that for each time step $t$ , our GRU-based decoder should predict the future sequence of treatments $\\hat{Y}_{t+1:t+\\tau}$ with its hidden state initialized to the representation $\\Phi_{t}$ of the historical process up to time $t$ . ", "page_idx": 26}, {"type": "text", "text": "Algorithm 1 Pretraining of the encoder ", "page_idx": 27}, {"type": "text", "text": "Require: Encoder parameters $\\theta_{1,2,3}$ , learning rate $\\mu$ Input: data $\\\\{\\mathbf{H}_{i,t_{m a x}},i=1,\\dots,N\\}$ for $p\\in\\{1,\\ldots,\\mathrm{epoch}_{\\mathrm{max}}\\}$ do for $\\mathbf{\\nabla}\\cdot\\mathbf{\\mathcal{B}}=\\{\\mathbf{H}_{i,t_{m a x}},i=1,\\ldots,|\\mathcal{B}|\\}\\;\\mathbf{d}$ o $\\mathbf{Z}_{t}=\\Phi_{\\theta_{1}}([\\mathbf{X}_{t},W_{t-1},Y_{t-1}])$ for $t=0,\\ldots,t_{m a x}$ . Choose $t\\sim\\mathcal{U}([1,t_{m a x}-1])$ . Compute $\\mathbf{C}_{t}=\\Phi_{\\theta_{1},\\theta_{2}}(\\mathbf{H}_{t})$ . Compute $\\mathcal{L}^{C P C}(\\theta_{1},\\theta_{2},\\{\\Gamma_{j}\\}_{j=1}^{\\tau})$ . Choose $t_{0}\\sim\\mathcal{U}([1,t])$ . Compute ${\\bf C}_{t}^{h}=\\bar{\\Phi}_{\\theta_{1},\\theta_{2}}({\\bf H}_{t}^{h}),{\\bf C}_{t}^{f}=\\Phi_{\\theta_{1},\\theta_{2}}({\\bf H}_{t}^{f})$ , Compute $\\mathcal{L}^{(I n f o M a x)}(\\theta_{1},\\theta_{2},\\gamma)$ . Update parameters $\\theta_{1,2,3}\\gets\\theta_{1,2,3}-\\mu\\left(\\frac{\\partial\\mathcal{L}^{C P C}(\\theta_{1},\\theta_{2},\\{\\Gamma_{j}\\}_{j=1}^{\\tau})}{\\partial\\theta_{1,2,3}}+\\frac{\\partial\\mathcal{L}^{(I n f o M a x)}(\\theta_{1},\\theta_{2},\\gamma)}{\\partial\\theta_{1,2,3}}\\right)$ end for end for Return: Trained encoder. ", "page_idx": 27}, {"type": "text", "text": "To enhance training efficiency, instead of predicting $\\hat{Y}_{i,t+1:t+\\tau}$ for all individuals $i$ in a batch and for all possible time steps $t$ , we randomly select $m$ time indices $t_{i,1},\\ldots,t_{i,m}$ for each individual $i$ . From these indices, we compute future treatment response sequences $\\hat{Y}_{i,t_{i,1}+1:t_{i,1}+\\tau},\\ldots,\\hat{Y}_{i,t_{i,m}+1:t_{i,m}+\\tau}.$ We found that is enough to train while selecting randomly $10\\%$ of the time steps. ", "page_idx": 27}, {"type": "text", "text": "Algorithm 2 Training of the decoder ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Require: Encoder parameters $\\theta_{1,2,3}$ , Decoder parameters $\\theta_{4},\\theta_{Y},\\theta_{W}$ .   \nRequire: Encoder learning rate $\\mu_{e n c}$ , Treatment learning rate $\\mu_{W}$ , Outcome learning rate $\\mu_{Y}$ .   \nRequire: Number of random time indices $m$ . Input: data $\\\\{\\mathbf{H}_{i,t_{m a x}},i=1,\\dots,N\\}$ for $p\\in\\{1,\\ldots,\\mathrm{epoch}_{\\mathrm{max}}\\}$ do for $\\mathcal{B}=\\left\\{\\mathbf{H}_{i,t_{m a x}},i=1,\\ldots,|\\mathcal{B}|\\right\\}$ do Compute $\\mathbf{C}_{i,t}=\\mathrm{encoder}(\\mathbf{H}_{i,t})$ for $t=0,\\ldots,t_{m a x}$ , $i=1,\\ldots,|B|$ . Compute $\\Phi_{t}=\\Phi_{\\theta_{R}}(\\mathbf{H}_{t})$ . for $i=1,\\ldots,|B|$ do Choose $t_{i,1},\\dotsc,t_{i,m}\\sim\\mathcal{U}([1,t_{m a x}-\\tau])$ . for $t\\in\\{t_{i,1},\\ldots,t_{i,m}\\}$ do Compute $\\hat{Y}_{i,t+1:t+\\tau},\\hat{W}_{i,t+1:t+\\tau},\\Phi_{i,t+1:t+\\tau-1}=\\operatorname{decoder}(\\Phi_{t},\\mathbf{V}_{i},W_{i,t},Y_{i,t},W_{i,t+1:t+\\tau})$ end for end for Compute $\\mathcal{L}_{d e c}(\\theta_{R},\\theta_{Y},\\theta_{W})$ and $\\mathcal{L}_{W}(\\theta_{W},\\theta_{R})$ . Update parameters in the order. $\\begin{array}{r}{\\begin{array}{c}{\\theta_{1,2,3}\\leftarrow\\theta_{1,2,3}-\\mu_{e n c}\\left(\\frac{\\partial\\mathcal{L}_{d e c}\\left(\\theta_{R},\\theta_{Y},\\theta_{W}\\right)}{\\partial\\theta_{1,2,3}}\\right)}\\\\ {\\theta_{4,Y}\\leftarrow\\theta_{4,Y}-\\mu_{Y}\\left(\\frac{\\partial\\mathcal{L}_{d e c}\\left(\\theta_{R},\\theta_{Y},\\theta_{W}\\right)}{\\partial\\theta_{4,Y}}\\right)}\\\\ {\\theta_{W}\\leftarrow\\theta_{W}-\\mu_{W}\\left(\\frac{\\partial\\mathcal{L}_{W}\\left(\\theta_{W},\\theta_{R}\\right)}{\\partial\\theta_{W}}\\right)}\\end{array}}\\end{array}$ end for ", "page_idx": 27}, {"type": "text", "text": "Return: Trained decoder. ", "page_idx": 27}, {"type": "text", "text": "I Causal CPC: Architecture details ", "text_level": 1, "page_idx": 28}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/94e2a9e91ad9780bca3f500a9358b9094871a4770b535fefef59536c48a53ab0.jpg", "table_caption": [], "table_footnote": ["Table 13: Architecture for learning local features $\\mathbf{Z}_{t}$ "], "page_idx": 28}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/9d8ba98e7d0260ed3726897fe304d6f327f2ccd0b87eb6170b33ed05d5357fea.jpg", "table_caption": [], "table_footnote": ["Table 14: Architecture for learning context representation $\\mathbf{C}_{t}$ "], "page_idx": 28}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/3eb22fa1c6b173d1bf880e2bcf20c61e19d06ee32b76436b8d5e0688972e3a31.jpg", "table_caption": [], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "Table 15: Architecture for outcome prediction ", "page_idx": 28}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/496c47eaac807bf774068503e97e6b51083511efd50b6e05676631bb9c058780.jpg", "table_caption": [], "table_footnote": ["Table 16: Architecture for treatment prediction "], "page_idx": 28}, {"type": "text", "text": "J Models hyperparameters ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "In this section, we report the range of all hyperparameters to be fine-tuned, as well as fixed hyperparameters for all models and across the different datasets used in experiments. Best hyperparameter values are reported in the configuration files in the code repository. ", "page_idx": 28}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/2f8fc7fc5399b7c58ffd1902a0d41a791cd620fd0a3fe67859a71a1f9f89ef10.jpg", "table_caption": ["Table 17: Hyper-parameters search range for RMSN "], "table_footnote": [], "page_idx": 29}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/30bade7d0f4de411c8a54bd8b9b42d6ede764341d214889d407fcb21a09a0920.jpg", "table_caption": ["Table 18: Hyper-parameters search range for CRN "], "table_footnote": [], "page_idx": 29}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/fabc630547805e483cb385cfd913bcee2fb7cd08c6eb132e80ac72b49d795b08.jpg", "table_caption": ["Table 19: Hyper-parameters search range for G-Net "], "table_footnote": [], "page_idx": 29}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/31655d230a2c34847f07ff1ac79ddf728c91c20d4cb73f353896642e3f0126e1.jpg", "table_caption": ["Table 20: Hyper-parameters search range for Causal Transfomer "], "table_footnote": [], "page_idx": 29}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/8f5c27084492adfb9af3599d0a5397cf1bcf034c3f3c71334e527fe9dca25656.jpg", "table_caption": ["Table 21: Hyper-parameters search range for Causal CPC "], "table_footnote": [], "page_idx": 30}, {"type": "table", "img_path": "bKOZYBJE4Z/tmp/5d35b366ee43f0442c50e0557b5596af37228b5a72dc8d5697dab5c4ebeaa191.jpg", "table_caption": ["Table 22: Hyper-parameters search range for Causal CPC "], "table_footnote": [], "page_idx": 30}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "1. Claims ", "page_idx": 30}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: The paper introduces a novel method combining RNNs with CPC for long-term counterfactual regression, leveraging MI objectives for efficient representation learning, and demonstrates state-of-the-art results on both synthetic and real-world data. These claims are substantiated by the detailed theoretical 5 and empirical analyses 6 provided in the paper. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 30}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: While Causal CPC excels at large horizon predictions, it does not outperform SOTA models on short-term predictions (Table 1). ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 31}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Justification: Detailed proofs are provided in Appendix G. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 31}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: All the experimental details related to the training and evaluation protocol (D), datasets descriptions (E.1 and F.1) are provided. A detailed description of the Causal CPC architecture is provided in I. Pseudo-algorithms for both the encoder and the decoder are also provided in H. Code is provided in the supplementary material. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 32}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: Code is provided in the supplementary material at submission. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. ", "page_idx": 32}, {"type": "text", "text": "\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). \u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 33}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: Models\u2019 hyperparameter search range is provided in Appendix J, the selection method is provided at the beginning of Section 6, and remaining details about training and testing are provided in the experimental protocol (Appendix D). ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 33}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 33}, {"type": "text", "text": "Answer: [No] ", "page_idx": 33}, {"type": "text", "text": "Justification: It is computationally demanding to compute errors bars for all neural network models in our benchmark. However, we reported the mean and standard deviation of metrics for each experiment, computed from multiple runs. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 33}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: We provided the computation resources used in the title of Table 2 as well as the time of execution in the same table for cancer simulation data. A similar table is provided in Appendix F.2 for MIMIC III data (Table 12). ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 34}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: Authors acknowledge conducting research in conformity with the NeurIPS Code of Ethics. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 34}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Justification: An impact statement is included in Appendix A ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 34}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 35}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: Authors of models and datasets are appropriately cited in the paper in the introduction (1) and experiment (6) sections. Original owners of some model implementations are properly credited in our code. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 35}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: Code for Causal CPC is provided in the supplementary material. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets. \u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. ", "page_idx": 35}, {"type": "text", "text": "\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 36}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 36}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 36}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 36}]