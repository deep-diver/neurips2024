[{"figure_path": "bKOZYBJE4Z/tables/tables_8_1.jpg", "caption": "Table 1: Evolution of RMSEs for the semi-synthetic MIMIC III, sequence length 100.", "description": "This table presents the RMSEs (Root Mean Squared Errors) for the semi-synthetic MIMIC III dataset with a sequence length of 100.  The results are shown for different prediction horizons (\u03c4 = 1 to \u03c4 = 10) and different models: Causal CPC (the proposed model), CT (Causal Transformer), G-Net, CRN (Counterfactual Recurrent Networks), and RMSN (Recurrent Marginal Structural Networks). Lower RMSE values indicate better performance. The table shows how the RMSE increases as the prediction horizon increases for all models, but Causal CPC consistently outperforms the other models across all horizons.", "section": "Experiments with Semi-synthetic Data"}, {"figure_path": "bKOZYBJE4Z/tables/tables_8_2.jpg", "caption": "Table 2: Models complexity and the running time averaged over five seeds. Results are reported for tumor growth simulation (\u03b3 = 1). Hardware: GPU - 1xNVIDIA Tesla M60.", "description": "This table presents a comparison of the model complexity (in terms of the number of trainable parameters) and computational efficiency (training and prediction times) across different models. The results are based on the tumor growth simulation dataset with a confounding level of \u03b3 = 1, using a single NVIDIA Tesla M60 GPU for training.  The table shows that Causal CPC demonstrates a good balance between accuracy and computational efficiency.", "section": "Computational Efficiency and Model Complexity"}, {"figure_path": "bKOZYBJE4Z/tables/tables_8_3.jpg", "caption": "Table 3: Ablation study with NRMSE averaged across (1 \u2264 \u03c4 \u2264 10) for cancer simulation (\u03b3 = 1) and MIMIC III.", "description": "This table presents the results of an ablation study conducted to evaluate the impact of different components of the proposed Causal CPC model.  The study measures the Normalized Root Mean Squared Error (NRMSE) for prediction horizons from 1 to 10, across two datasets: a cancer simulation dataset and a semi-synthetic MIMIC III dataset.  By removing different parts of the model, such as the InfoNCE loss, the InfoMax loss, the balancing mechanism, or replacing the ICLUB objective with the CDC loss, the study aims to understand the contributions of each component to the overall model performance. The results show that removing any of the key components reduces the model's accuracy.", "section": "6 Experiments"}, {"figure_path": "bKOZYBJE4Z/tables/tables_9_1.jpg", "caption": "Table 4: Results on the MIMIC III when sequential ignorability is violated reported by RMSES", "description": "This table presents the results of experiments conducted on the MIMIC III dataset when the assumption of sequential ignorability is violated.  The table shows the normalized root mean squared error (NRMSE) for different forecasting horizons (\u03c4 = 1 to \u03c4 = 10) and for four different models: Causal CPC, Causal Transformer, CRN, and RMSN.  The NRMSE values demonstrate the impact of violating the sequential ignorability assumption on the accuracy of counterfactual estimation by each model over different time horizons.", "section": "6.2 Experiments with semi-synthetic and real data"}, {"figure_path": "bKOZYBJE4Z/tables/tables_16_1.jpg", "caption": "Table 5: A summary of the methods included in our experiments", "description": "This table compares Causal CPC with other state-of-the-art (SOTA) methods for counterfactual regression over time.  It highlights key architectural differences, such as the model backbone (e.g., GRU, Transformer, LSTM), whether the model is explicitly designed for long-term forecasting, the use of contrastive learning, the method used to predict counterfactuals, how selection bias is handled, and whether the model ensures invertibility of the representation. This comparison helps to contextualize Causal CPC's novel contributions and its advantages over existing approaches.", "section": "C.1 Counterfactual regression over time: Methods overview"}, {"figure_path": "bKOZYBJE4Z/tables/tables_19_1.jpg", "caption": "Table 6: Results on the synthetic data set with sequence length 60: mean\u00b1standard deviation of NRMSEs. The best value for each metric is given in bold: smaller is better.", "description": "This table presents the results of the cancer simulation experiment for sequence length 60.  It compares the performance of Causal CPC against other state-of-the-art models across multiple prediction horizons (\u03c4 = 1 to 10) and three different confounding levels (\u03b3 = 1, 2, 3). The performance metric is Normalized Root Mean Squared Error (NRMSE), with lower values indicating better performance.  The best performing model for each scenario is highlighted in bold.", "section": "E.2.1 Comparison to benchmark models"}, {"figure_path": "bKOZYBJE4Z/tables/tables_20_1.jpg", "caption": "Table 1: Evolution of RMSEs for the semi-synthetic MIMIC III, sequence length 100.", "description": "This table presents the Root Mean Squared Errors (RMSEs) for the semi-synthetic MIMIC III dataset with a sequence length of 100.  It shows the RMSE values for different prediction horizons (T=1 to T=10) for the Causal CPC model and four other comparison models: CT, G-Net, CRN, and RMSN. Lower RMSE values indicate better model performance.  The results are averaged across multiple runs, with standard deviations reported as well, reflecting the variability in model performance across different runs.", "section": "Experiments with Semi-synthetic Data"}, {"figure_path": "bKOZYBJE4Z/tables/tables_20_2.jpg", "caption": "Table 7: Results on the synthetic data set with sequence length 40: mean\u00b1standard deviation of NRMSEs. The best value for each metric is given in bold: smaller is better.", "description": "This table presents the results of the ablation study performed on the synthetic dataset using a sequence length of 40. The table shows the mean and standard deviation of the Normalized Root Mean Squared Errors (NRMSEs) for different horizons (\u03c4 = 1 to 10) for various model configurations: Causal CPC (full), Causal CPC without InfoNCE loss, Causal CPC without InfoMax loss, Causal CPC with CDC loss, and Causal CPC without balancing.  The best NRMSE value for each horizon and each model is highlighted in bold.", "section": "E.2.2 Ablation study"}, {"figure_path": "bKOZYBJE4Z/tables/tables_21_1.jpg", "caption": "Table 1: Evolution of RMSEs for the semi-synthetic MIMIC III, sequence length 100.", "description": "This table presents the results of the semi-synthetic MIMIC III experiment, focusing on the evolution of Root Mean Squared Errors (RMSEs) across different prediction horizons (\u03c4 = 1 to 10).  The experiment uses a sequence length of 100.  The RMSEs are shown for Causal CPC and several other comparative models.", "section": "Experiments with semi-synthetic data: Details"}, {"figure_path": "bKOZYBJE4Z/tables/tables_21_2.jpg", "caption": "Table 10: Results of NWJ and MINE MI lower bounds when used for CPC and InfoMax for MIMIC III semi-synthetic data set: mean\u00b1standard deviation of Normalized Rooted Mean Squared Errors (NRMSEs). The best value for each metric is given in bold: smaller is better.", "description": "This table presents a comparison of the performance of the Causal CPC model using different mutual information (MI) lower bounds for contrastive predictive coding (CPC) and InfoMax.  It shows the Normalized Root Mean Squared Errors (NRMSEs) for different prediction horizons (\u03c4 = 1 to 10) on the MIMIC III semi-synthetic dataset.  The results demonstrate the impact of the choice of MI estimation method on model performance.", "section": "F.2.2 Comparison to benchmark models: standard train/test split"}, {"figure_path": "bKOZYBJE4Z/tables/tables_21_3.jpg", "caption": "Table 1: Evolution of RMSEs for the semi-synthetic MIMIC III, sequence length 100.", "description": "This table presents the mean and standard deviation of Root Mean Squared Errors (RMSEs) for the semi-synthetic MIMIC III dataset across different prediction horizons (\u03c4 = 1 to 10).  The results are broken down by model and show the performance of Causal CPC (ours), CT, G-Net, CRN, RMSN, and MSM.  A sequence length of 100 was used for this experiment.  Lower RMSE values indicate better model performance.", "section": "Experiments with semi-synthetic data: Details"}, {"figure_path": "bKOZYBJE4Z/tables/tables_22_1.jpg", "caption": "Table 2: Models complexity and the running time averaged over five seeds. Results are reported for tumor growth simulation (\u03b3 = 1). Hardware: GPU - 1xNVIDIA Tesla M60.", "description": "This table compares the model complexity (in terms of trainable parameters) and the running time (in minutes) for different models, namely Causal CPC and four baselines (CT, G-Net, CRN, RMSN).  The results are averaged over five runs, for a specific configuration of the tumor growth simulation (\u03b3=1). The hardware used is a single NVIDIA Tesla M60 GPU. The table highlights that Causal CPC offers a good balance between model complexity and computational efficiency.", "section": "Computational Efficiency and Model Complexity"}, {"figure_path": "bKOZYBJE4Z/tables/tables_28_1.jpg", "caption": "Table 5: A summary of the methods included in our experiments", "description": "This table summarizes the key differences between Causal CPC and other state-of-the-art methods for counterfactual regression over time used in the paper's experiments. It compares model backbones, ability to handle long-term forecasting, use of contrastive learning, mechanisms for handling selection bias and representation invertibility.", "section": "C.1 Counterfactual regression over time: Methods overview"}, {"figure_path": "bKOZYBJE4Z/tables/tables_28_2.jpg", "caption": "Table 5: A summary of the methods included in our experiments", "description": "This table summarizes the key characteristics of the counterfactual regression models used in the paper's experiments, including the model backbone, whether they are tailored for long-term forecasting, their handling of time-dependent confounding and selection bias, the use of contrastive learning, and whether the representation is invertible.  It highlights the differences between the proposed Causal CPC model and existing state-of-the-art methods.", "section": "C Extended related work"}, {"figure_path": "bKOZYBJE4Z/tables/tables_28_3.jpg", "caption": "Table 5: A summary of the methods included in our experiments", "description": "This table summarizes the key differences between Causal CPC and the baseline models used in the experiments.  It highlights the model backbone, ability to handle long-term forecasting, use of contrastive learning, and the methods used to learn long-term dependencies, handle selection bias, and ensure the invertibility of the representation.", "section": "C Extended related work"}, {"figure_path": "bKOZYBJE4Z/tables/tables_28_4.jpg", "caption": "Table 17: Hyper-parameters search range for RMSN", "description": "This table shows the hyperparameter search ranges used for training the Recurrent Marginal Structural Networks (RMSN) model.  It details the ranges explored for various hyperparameters related to the LSTM layers (recurrent neural network layers) within the propensity and treatment networks, including the number of layers, learning rate, batch size, hidden unit count, dropout rate, and early stopping criteria. Separate ranges are provided for cancer simulation data and semi-synthetic MIMIC-III data.", "section": "J Models hyperparameters"}, {"figure_path": "bKOZYBJE4Z/tables/tables_29_1.jpg", "caption": "Table 17: Hyper-parameters search range for RMSN", "description": "This table details the hyperparameter search ranges used for training the Recurrent Marginal Structural Networks (RMSNs) model.  It shows the range of values explored for various hyperparameters within the RMSN model, broken down by sub-model (Propensity Treatment Network, Propensity History Network, Encoder, Decoder) for both cancer simulation and semi-synthetic MIMIC-III datasets.  The hyperparameters covered include the number of LSTM layers, learning rate, batch size, LSTM hidden units, LSTM dropout rate, maximum gradient norm, early stopping minimum delta, and early stopping patience. Each sub-model has its own set of hyperparameter ranges, demonstrating the complexity of tuning the RMSN model for optimal performance.", "section": "J Models hyperparameters"}, {"figure_path": "bKOZYBJE4Z/tables/tables_29_2.jpg", "caption": "Table 18: Hyper-parameters search range for CRN", "description": "This table displays the hyperparameter search ranges used for the CRN model in the experiments.  It breaks down the hyperparameters for the encoder and decoder sub-models separately, specifying the ranges explored for parameters like the number of LSTM layers, learning rate, batch size, LSTM hidden units, LSTM dropout rate, BR size, and early stopping criteria for both cancer simulation and MIMIC III (semi-synthetic) datasets.", "section": "J Models hyperparameters"}, {"figure_path": "bKOZYBJE4Z/tables/tables_29_3.jpg", "caption": "Table 17: Hyper-parameters search range for RMSN", "description": "This table details the hyperparameter search ranges used for training the Recurrent Marginal Structural Networks (RMSN) model.  It breaks down the hyperparameters by sub-model (Propensity Treatment Network, Propensity History Network, Encoder, Decoder) and lists the range of values tested for cancer simulation and MIMIC III (SS) datasets.  Each sub-model shows various tunable parameters including the number of LSTM layers, learning rate, batch size, hidden units, dropout rate, max gradient norm, and early stopping criteria (min delta and patience).", "section": "J Models hyperparameters"}, {"figure_path": "bKOZYBJE4Z/tables/tables_29_4.jpg", "caption": "Table 20: Hyper-parameters search range for Causal Transfomer", "description": "This table presents the hyperparameter search ranges used for the Causal Transformer model in the experiments.  It shows the ranges explored for various parameters such as the number of transformer blocks, learning rate, batch size, number of attention heads,  transformer units, LSTM dropout rate, BR size, fully connected hidden units, sequential dropout rate, maximum positional encoding, and early stopping parameters (minimum delta and patience). Separate ranges are given for the experiments conducted on the cancer simulation dataset and the semi-synthetic MIMIC III dataset.", "section": "J Models hyperparameters"}, {"figure_path": "bKOZYBJE4Z/tables/tables_30_1.jpg", "caption": "Table 17: Hyper-parameters search range for RMSN", "description": "This table details the hyperparameter search ranges used for training the Recurrent Marginal Structural Networks (RMSNs) model.  It covers hyperparameters for various sub-models within RMSN, including the propensity treatment network, propensity history network, encoder, and decoder.  Each hyperparameter is listed along with the tested values for both the cancer simulation dataset and the semi-synthetic MIMIC-III dataset. Note that this is a search range, not all listed values were necessarily used in the final model.", "section": "J Models hyperparameters"}, {"figure_path": "bKOZYBJE4Z/tables/tables_30_2.jpg", "caption": "Table 17: Hyper-parameters search range for RMSN", "description": "This table presents the hyperparameter search ranges used for training the Recurrent Marginal Structural Networks (RMSNs) model. It includes the hyperparameters for the propensity treatment network, propensity history network, encoder, and decoder.  The search ranges are provided separately for the cancer simulation and MIMIC III semi-synthetic datasets. For each hyperparameter, the table specifies the possible values explored during the hyperparameter search.", "section": "J Models hyperparameters"}]