[{"figure_path": "cBY66CKEbq/figures/figures_13_1.jpg", "caption": "Figure 1: Frozen-Lake: TV Distance Defined Uncertainty Set", "description": "The figure shows the performance comparison of three algorithms under the total variation uncertainty model in the Frozen Lake environment. The x-axis represents the size of the dataset, and the y-axis represents the sub-optimality gap. The three algorithms compared are: value function based, distribution based, and DRVI-LCB. The shaded area around each line represents the standard deviation across multiple runs. The figure demonstrates that the value function based approach outperforms the other two in terms of both convergence speed and final sub-optimality gap.", "section": "A.1 Comparison under the total variation uncertainty set model"}, {"figure_path": "cBY66CKEbq/figures/figures_13_2.jpg", "caption": "Figure 1: Frozen-Lake: TV Distance Defined Uncertainty Set", "description": "The figure shows the comparison of three algorithms under the total variation uncertainty set model on the Frozen-Lake problem. The three algorithms are value function based, distribution based, and DRVI-LCB. The x-axis represents the size of the dataset, and the y-axis represents the sub-optimality gap. The shaded area represents the standard deviation of the 10 independent runs. The figure shows that the value function-based construction has a smaller sub-optimality gap and converges faster than the distribution-based construction and the DRVI-LCB.", "section": "A.1 Comparison under the total variation uncertainty set model"}, {"figure_path": "cBY66CKEbq/figures/figures_14_1.jpg", "caption": "Figure 1: Frozen-Lake: TV Distance Defined Uncertainty Set", "description": "This figure compares three algorithms (Robust DP, Non-robust DP, and DRVI-LCB) under the total variation uncertainty set model on the Frozen Lake problem. The x-axis represents the size of the dataset, and the y-axis represents the sub-optimality gap. The shaded areas around the lines represent the standard deviations of the results over multiple runs (10 runs in this case). The figure shows that the value function-based construction of our algorithm (Robust DP) has a smaller sub-optimality gap and converges faster than the distribution-based construction and the DRVI-LCB, demonstrating that our algorithm is less conservative and more effective.", "section": "A.1 Comparison under the total variation uncertainty set model"}, {"figure_path": "cBY66CKEbq/figures/figures_14_2.jpg", "caption": "Figure 3: Frozen-Lake: x\u00b2 Divergence Defined Uncertainty Set", "description": "This figure compares the performance of three algorithms (Robust DP, Non-robust DP, and DRVI-LCB) on the Frozen-Lake problem under the chi-squared divergence uncertainty model.  The x-axis represents the size of the dataset used to train the algorithms.  The y-axis represents the sub-optimality gap, a measure of how far the performance of each algorithm is from the optimal policy.  The shaded areas around the lines represent the standard deviation of the results across multiple runs of each algorithm. The figure shows that the Robust DP algorithm converges faster and achieves a lower sub-optimality gap compared to the other two algorithms.", "section": "A.2 Comparison under the x\u00b2 divergence uncertainty set model"}, {"figure_path": "cBY66CKEbq/figures/figures_14_3.jpg", "caption": "Figure 1: Frozen-Lake: TV Distance Defined Uncertainty Set", "description": "The figure shows the comparison of three algorithms under the total variation uncertainty set model for the FrozenLake problem. The x-axis represents the size of the dataset, while the y-axis represents the sub-optimality gap. The three algorithms are Robust Value Iteration (our algorithm using value function-based construction), Distribution-based Robust Value Iteration (our algorithm using distribution-based construction), and DRVI-LCB (baseline algorithm). The shaded area represents the standard deviation of 10 independent runs of each algorithm. The results demonstrate that our algorithm using the value function-based construction achieves better performance (smaller sub-optimality gap and faster convergence) compared to the baseline and the distribution-based construction.", "section": "A.1 Comparison under the total variation uncertainty set model"}, {"figure_path": "cBY66CKEbq/figures/figures_14_4.jpg", "caption": "Figure 4: Gambler: x\u00b2 Divergence Defined Uncertainty Set", "description": "The figure compares the performance of three algorithms (Robust DP, Non-robust DP, and DRVI-LCB) on the Gambler problem under x\u00b2 divergence uncertainty.  The x-axis represents the size of the dataset used to train the algorithms, and the y-axis represents the sub-optimality gap, which measures how far the performance of the learned policy is from the optimal policy.  The shaded area around each line shows the standard deviation across multiple runs.  The results illustrate how our robust approach significantly outperforms the non-robust approach, demonstrating the benefits of using robustness measures, especially when working with limited data.", "section": "A.2 Comparison under the x\u00b2 divergence uncertainty set model"}, {"figure_path": "cBY66CKEbq/figures/figures_15_1.jpg", "caption": "Figure 7: Execution time: DRO vs LCB [36]", "description": "This figure compares the execution time of the proposed DRO algorithm and the LCB algorithm from [36] across three different environments: Frozen Lake, Gambler's game, and N-Chain. The x-axis represents the dataset size, and the y-axis represents the execution time in seconds.  The results show that, regardless of the environment, the DRO algorithm consistently demonstrates faster execution times, particularly as the dataset size increases, highlighting its improved computational efficiency.", "section": "A Experiments"}]