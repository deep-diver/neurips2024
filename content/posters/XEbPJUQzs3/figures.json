[{"figure_path": "XEbPJUQzs3/figures/figures_3_1.jpg", "caption": "Figure 1: A schematic for prospective learning (left) and realizations of the examples for the four scenarios (top right); dots denote 1s and empty spaces denote Os for Yt \u2208 {0, 1} with Xt = 1 for all times t. Prospective risk of learners at different times is shown in the bottom panels and discussed in Section 2.1. Scenario 1: For Bernoulli probability p = 0.2, the maximum-likelihood estimator (MLE) in blue uses a time-agnostic hypothesis ht(Xt) = 1(pt > 0.5) where pt = t\u00af\u00b9 \u2211=1 Ys, ties at \u00eet = 0.5 are broken randomly. The risk of this learner converges to the Bayes risk. Scenario 2: For Bernoulli probability p = 0.2, the MLE estimator (blue) performs at chance levels. A prospective learner (orange) that alternates between two predictors at even and odd times converges to Bayes risk. Variants of this learner that use less information from the stochastic process (green does not know that the data distributions at even and odd times are tied, red does not know that the distribution shifts at every time-step) also converge to Bayes risk, but more slowly. Scenario 3: For 0 = 0.1 and y = 0.9 in the discounted prospective risk, the MLE estimator (blue) again performs at chance levels. A prospective learner that computes an estimate of the transition probability of the two-state Markov chain to estimate P(Yt | yt) for future times t' > t converges to Bayes risk. Scenario 4: For \u03b8\u03bf = 0\u2081 = 0.1, the MLE estimator (blue) performs at chance levels. A prospective learner that uses a variant of Q-learning (described in the text and Appendix B.3) converges to the prospective Bayes risk.", "description": "This figure illustrates four different prospective learning scenarios with examples.  It visually represents data generation processes (independent and identically distributed, independent but not identically distributed, two-state Markov chain, and two-state Markov decision process), and compares the performance of several learners (MLE, various prospective learners) in terms of their prospective risk over time.  The bottom panels show the prospective risk of different learners in each scenario.  The goal is to show how prospective learning adapts to changes in the underlying data generating process and its advantage over standard methods.", "section": "Different prospective learning scenarios with illustrative examples"}, {"figure_path": "XEbPJUQzs3/figures/figures_8_1.jpg", "caption": "Figure 2: Prospective ERM can achieve good instantaneous and prospective risk in Scenario 2. Left: Instantaneous and prospective risks for problems constructed using synthetic data (see text) across 5 random seeds (which govern the sequence of samples and the weight initializations of neural networks). Instantaneous risk spikes when the task switches for many online learning baseline algorithms. In contrast, prospective ERM has minimal spikes at later times and both instantaneous and prospective risks eventually converge to zero. Right: Prospective risk for different baseline algorithms and prospective ERM for tasks constructed using MNIST and CIFAR-10 for Scenario 2. In all three cases, the risk of prospective ERM approaches Bayes risk while online learning baselines considered here do not achieve a low prospective risk. For comparison, the chance prospective risk is 0.5 for synthetic data and 0.742 for MNIST and CIFAR-10 tasks.", "description": "This figure compares the performance of prospective ERM against several online learning baselines on tasks with independently but not identically distributed data (Scenario 2). The left panel shows that prospective ERM achieves consistently low instantaneous and prospective risk, even when the task switches, while online learning baselines exhibit spikes. The right panel further demonstrates the superiority of prospective ERM over baselines on MNIST and CIFAR-10 tasks, showing its convergence towards the Bayes risk.", "section": "Experimental Validation"}, {"figure_path": "XEbPJUQzs3/figures/figures_9_1.jpg", "caption": "Figure 1: A schematic for prospective learning (left) and realizations of the examples for the four scenarios (top right); dots denote 1s and empty spaces denote 0s for Yt \u2208 {0, 1} with Xt = 1 for all times t. Prospective risk of learners at different times is shown in the bottom panels and discussed in Section 2.1. Scenario 1: For Bernoulli probability p = 0.2, the maximum-likelihood estimator (MLE) in blue uses a time-agnostic hypothesis ht(Xt) = 1(pt > 0.5) where pt = t\u00af\u00b9 \u2211=1 Ys, ties at pt = 0.5 are broken randomly. The risk of this learner converges to the Bayes risk. Scenario 2: For Bernoulli probability p = 0.2, the MLE estimator (blue) performs at chance levels. A prospective learner (orange) that alternates between two predictors at even and odd times converges to Bayes risk. Variants of this learner that use less information from the stochastic process (green does not know that the data distributions at even and odd times are tied, red does not know that the distribution shifts at every time-step) also converge to Bayes risk, but more slowly. Scenario 3: For \u03b8\u03bf = 0.1 and \u03b8\u2081 = 0.9 in the discounted prospective risk, the MLE estimator (blue) again performs at chance levels. A prospective learner that computes an estimate of the transition probability of the two-state Markov chain to estimate P(Yt | yt) for future times t' > t converges to Bayes risk. Scenario 4: For \u03b8\u03bf = \u03b8\u2081 = 0.1, the MLE estimator (blue) performs at chance levels. A prospective learner that uses a variant of Q-learning (described in the text and Appendix B.3) converges to the prospective Bayes risk.", "description": "This figure illustrates four different scenarios of prospective learning, showing how the optimal hypothesis changes over time in each case and comparing the performance of different learning methods.  It shows examples of data generation processes, the performance of MLE and prospective learners, and the convergence of their risk towards the Bayes risk.", "section": "Different prospective learning scenarios with illustrative examples"}, {"figure_path": "XEbPJUQzs3/figures/figures_9_2.jpg", "caption": "Figure 2: Prospective ERM can achieve good instantaneous and prospective risk in Scenario 2. Left: Instantaneous and prospective risks for problems constructed using synthetic data (see text) across 5 random seeds (which govern the sequence of samples and the weight initializations of neural networks). Instantaneous risk spikes when the task switches for many online learning baseline algorithms. In contrast, prospective ERM has minimal spikes at later times and both instantaneous and prospective risks eventually converge to zero. Right: Prospective risk for different baseline algorithms and prospective ERM for tasks constructed using MNIST and CIFAR-10 for Scenario 2. In all three cases, the risk of prospective ERM approaches Bayes risk while online learning baselines considered here do not achieve a low prospective risk. For comparison, the chance prospective risk is 0.5 for synthetic data and 0.742 for MNIST and CIFAR-10 tasks.", "description": "This figure compares the performance of prospective ERM against several online learning baselines on tasks with independently but non-identically distributed data (Scenario 2).  The left panel shows instantaneous and prospective risk curves for a synthetic dataset, highlighting how prospective ERM maintains low risk even during task switches, unlike the baselines. The right panel extends this comparison to MNIST and CIFAR-10 datasets, demonstrating that prospective ERM consistently achieves lower prospective risk, approaching the Bayes risk in all three cases.", "section": "Experimental Validation"}, {"figure_path": "XEbPJUQzs3/figures/figures_18_1.jpg", "caption": "Figure A.1: Prospective risk of MLE (blue), MAP (purple), and prospective MAP (red) based learners with respect to time. Both MAP and prospective MAP estimators assume a prior distribution of Beta(12, 16) over p. We refer to this as the prospective MAP estimate. Based on it, we set the hypothesis to be ht' = threshold(pt' > 0.5) for all future times beyond t. In Figure A.1, we plot the prospective risk the MLE, MAP, and prospective MAP-based learners. Due to an unfavorable prior, the MAP-based learner converges slowly. However, prospective MAP-based learner manages to leverage its forecasting to achieve a faster convergence rate despite having the same prior as the MAP. This shows that we can indeed benefit from prospection even in the IID case.", "description": "This figure compares the prospective risks of three different learning methods (MLE, MAP, and prospective MAP) under an IID scenario (Scenario 1) with a Bernoulli distribution.  The prospective MAP method, which incorporates future predictions into its learning, demonstrates faster convergence to the Bayes risk compared to the traditional MLE and MAP approaches. This highlights the benefit of prospective learning even when data are IID.", "section": "B Calculations for scenarios in Section 2.1"}, {"figure_path": "XEbPJUQzs3/figures/figures_19_1.jpg", "caption": "Figure 1: A schematic for prospective learning (left) and realizations of the examples for the four scenarios (top right); dots denote 1s and empty spaces denote 0s for Yt \u2208 {0, 1} with Xt = 1 for all times t. Prospective risk of learners at different times is shown in the bottom panels and discussed in Section 2.1. Scenario 1: For Bernoulli probability p = 0.2, the maximum-likelihood estimator (MLE) in blue uses a time-agnostic hypothesis ht(Xt) = 1(pt > 0.5) where pt = t\u00af\u00b9 \u2211=1 Ys, ties at pt = 0.5 are broken randomly. The risk of this learner converges to the Bayes risk. Scenario 2: For Bernoulli probability p = 0.2, the MLE estimator (blue) performs at chance levels. A prospective learner (orange) that alternates between two predictors at even and odd times converges to Bayes risk. Variants of this learner that use less information from the stochastic process (green does not know that the data distributions at even and odd times are tied, red does not know that the distribution shifts at every time-step) also converge to Bayes risk, but more slowly. Scenario 3: For \u03b80 = 0.1 and \u03b81 = 0.9 in the discounted prospective risk, the MLE estimator (blue) again performs at chance levels. A prospective learner that computes an estimate of the transition probability of the two-state Markov chain to estimate P(Yt | yt) for future times t' > t converges to Bayes risk. Scenario 4: For \u03b80 = \u03b81 = 0.1, the MLE estimator (blue) performs at chance levels. A prospective learner that uses a variant of Q-learning (described in the text and Appendix B.3) converges to the prospective Bayes risk.", "description": "This figure presents a schematic of prospective learning, illustrating its key components: data, hypothesis class, learner, and risk. It also shows example realizations of data for four different scenarios, each with varying degrees of data dependency and distribution shifts, and illustrates the performance of different learners (MLE, prospective learner variants) in each scenario. The figure highlights how prospective learning handles dynamic data distributions and evolving optimal hypotheses.", "section": "Different prospective learning scenarios with illustrative examples"}, {"figure_path": "XEbPJUQzs3/figures/figures_22_1.jpg", "caption": "Figure 1: A schematic for prospective learning (left) and realizations of the examples for the four scenarios (top right); dots denote 1s and empty spaces denote 0s for Yt \u2208 {0, 1} with Xt = 1 for all times t. Prospective risk of learners at different times is shown in the bottom panels and discussed in Section 2.1. Scenario 1: For Bernoulli probability p = 0.2, the maximum-likelihood estimator (MLE) in blue uses a time-agnostic hypothesis ht(Xt) = 1(pt > 0.5) where pt = t\u00af\u00b9 \u2211=1 Ys, ties at \u00eet = 0.5 are broken randomly. The risk of this learner converges to the Bayes risk. Scenario 2: For Bernoulli probability p = 0.2, the MLE estimator (blue) performs at chance levels. A prospective learner (orange) that alternates between two predictors at even and odd times converges to Bayes risk. Variants of this learner that use less information from the stochastic process (green does not know that the data distributions at even and odd times are tied, red does not know that the distribution shifts at every time-step) also converge to Bayes risk, but more slowly. Scenario 3: For \u03b8\u03bf = 0.1 and \u03b8\u2081 = 0.9 in the discounted prospective risk, the MLE estimator (blue) again performs at chance levels. A prospective learner that computes an estimate of the transition probability of the two-state Markov chain to estimate P(Yt | yt) for future times t' > t converges to Bayes risk. Scenario 4: For \u03b8\u03bf = \u03b8\u2081 = 0.1, the MLE estimator (blue) performs at chance levels. A prospective learner that uses a variant of Q-learning (described in the text and Appendix B.3) converges to the prospective Bayes risk.", "description": "This figure presents a schematic of prospective learning and examples illustrating four different scenarios.  The scenarios highlight how different data distributions and learning approaches affect the learner's ability to minimize risk, particularly considering the time-dependent nature of optimal hypothesis in prospective learning.", "section": "2 A definition of prospective learning"}, {"figure_path": "XEbPJUQzs3/figures/figures_23_1.jpg", "caption": "Figure 1: A schematic for prospective learning (left) and realizations of the examples for the four scenarios (top right); dots denote 1s and empty spaces denote Os for Yt \u2208 {0, 1} with Xt = 1 for all times t. Prospective risk of learners at different times is shown in the bottom panels and discussed in Section 2.1. Scenario 1: For Bernoulli probability p = 0.2, the maximum-likelihood estimator (MLE) in blue uses a time-agnostic hypothesis ht(Xt) = 1(pt > 0.5) where pt = t\u00af\u00b9 \u2211=1 Ys, ties at pt = 0.5 are broken randomly. The risk of this learner converges to the Bayes risk. Scenario 2: For Bernoulli probability p = 0.2, the MLE estimator (blue) performs at chance levels. A prospective learner (orange) that alternates between two predictors at even and odd times converges to Bayes risk. Variants of this learner that use less information from the stochastic process (green does not know that the data distributions at even and odd times are tied, red does not know that the distribution shifts at every time-step) also converge to Bayes risk, but more slowly. Scenario 3: For \u03b8\u03bf = 0.1 and \u03b8\u2081 = 0.9 in the discounted prospective risk, the MLE estimator (blue) again performs at chance levels. A prospective learner that computes an estimate of the transition probability of the two-state Markov chain to estimate P(Yt | yt) for future times t' > t converges to Bayes risk. Scenario 4: For \u03b8\u03bf = \u03b8\u2081 = 0.1, the MLE estimator (blue) performs at chance levels. A prospective learner that uses a variant of Q-learning (described in the text and Appendix B.3) converges to the prospective Bayes risk.", "description": "This figure presents a schematic of prospective learning and four different scenarios to illustrate the concept. The scenarios highlight how different data distributions affect the performance of various learning methods, including prospective learning.  Each scenario shows example data, and the bottom panels graph the prospective risk of different learning approaches over time. The figure demonstrates how prospective learning can successfully minimize cumulative future risk in dynamic scenarios where standard methods might fail.", "section": "2 A definition of prospective learning"}, {"figure_path": "XEbPJUQzs3/figures/figures_28_1.jpg", "caption": "Figure 1: A schematic for prospective learning (left) and realizations of the examples for the four scenarios (top right); dots denote 1s and empty spaces denote 0s for Yt \u2208 {0, 1} with Xt = 1 for all times t. Prospective risk of learners at different times is shown in the bottom panels and discussed in Section 2.1. Scenario 1: For Bernoulli probability p = 0.2, the maximum-likelihood estimator (MLE) in blue uses a time-agnostic hypothesis ht(Xt) = 1(pt > 0.5) where pt = t\u00af\u00b9 \u2211=1 Ys, ties at pt = 0.5 are broken randomly. The risk of this learner converges to the Bayes risk. Scenario 2: For Bernoulli probability p = 0.2, the MLE estimator (blue) performs at chance levels. A prospective learner (orange) that alternates between two predictors at even and odd times converges to Bayes risk. Variants of this learner that use less information from the stochastic process (green does not know that the data distributions at even and odd times are tied, red does not know that the distribution shifts at every time-step) also converge to Bayes risk, but more slowly. Scenario 3: For \u03b8\u2080 = 0.1 and \u03b8\u2081 = 0.9 in the discounted prospective risk, the MLE estimator (blue) again performs at chance levels. A prospective learner that computes an estimate of the transition probability of the two-state Markov chain to estimate P(Yt | yt) for future times t' > t converges to Bayes risk. Scenario 4: For \u03b8\u2080 = \u03b8\u2081 = 0.1, the MLE estimator (blue) performs at chance levels. A prospective learner that uses a variant of Q-learning (described in the text and Appendix B.3) converges to the prospective Bayes risk.", "description": "This figure illustrates four different prospective learning scenarios.  The left panel shows a schematic of the prospective learning process. The top right panel shows example data for each scenario. The bottom panels show the prospective risk of different learners for each scenario.  These illustrate that prospective learning can outperform standard methods when dealing with dynamic data.", "section": "2 A definition of prospective learning"}, {"figure_path": "XEbPJUQzs3/figures/figures_29_1.jpg", "caption": "Figure 2: Prospective ERM can achieve good instantaneous and prospective risk in Scenario 2. Left: Instantaneous and prospective risks for problems constructed using synthetic data (see text) across 5 random seeds (which govern the sequence of samples and the weight initializations of neural networks). Instantaneous risk spikes when the task switches for many online learning baseline algorithms. In contrast, prospective ERM has minimal spikes at later times and both instantaneous and prospective risks eventually converge to zero. Right: Prospective risk for different baseline algorithms and prospective ERM for tasks constructed using MNIST and CIFAR-10 for Scenario 2. In all three cases, the risk of prospective ERM approaches Bayes risk while online learning baselines considered here do not achieve a low prospective risk. For comparison, the chance prospective risk is 0.5 for synthetic data and 0.742 for MNIST and CIFAR-10 tasks.", "description": "This figure compares the performance of prospective ERM with other online learning algorithms in Scenario 2 (data is independent but not identically distributed). The left panel shows that prospective ERM maintains low risk even when the task switches, unlike other algorithms which experience spikes. The right panel demonstrates that prospective ERM consistently achieves lower prospective risk than other methods across synthetic, MNIST, and CIFAR-10 datasets, approaching the Bayes risk.", "section": "Experimental Validation"}, {"figure_path": "XEbPJUQzs3/figures/figures_29_2.jpg", "caption": "Figure 1: A schematic for prospective learning (left) and realizations of the examples for the four scenarios (top right); dots denote 1s and empty spaces denote 0s for Yt \u2208 {0, 1} with Xt = 1 for all times t. Prospective risk of learners at different times is shown in the bottom panels and discussed in Section 2.1. Scenario 1: For Bernoulli probability p = 0.2, the maximum-likelihood estimator (MLE) in blue uses a time-agnostic hypothesis ht(Xt) = 1(pt > 0.5) where pt = t\u22121\u2211t=1 Ys, ties at pt = 0.5 are broken randomly. The risk of this learner converges to the Bayes risk. Scenario 2: For Bernoulli probability p = 0.2, the MLE estimator (blue) performs at chance levels. A prospective learner (orange) that alternates between two predictors at even and odd times converges to Bayes risk. Variants of this learner that use less information from the stochastic process (green does not know that the data distributions at even and odd times are tied, red does not know that the distribution shifts at every time-step) also converge to Bayes risk, but more slowly. Scenario 3: For \u03b80 = 0.1 and \u03b81 = 0.9 in the discounted prospective risk, the MLE estimator (blue) again performs at chance levels. A prospective learner that computes an estimate of the transition probability of the two-state Markov chain to estimate P(Yt | yt) for future times t' > t converges to Bayes risk. Scenario 4: For \u03b80 = \u03b81 = 0.1, the MLE estimator (blue) performs at chance levels. A prospective learner that uses a variant of Q-learning (described in the text and Appendix B.3) converges to the prospective Bayes risk.", "description": "This figure illustrates four scenarios of prospective learning with examples.  The left panel shows a schematic of prospective learning, while the top-right shows sample data for each scenario.  The bottom panels display the performance of different learning methods (MLE, prospective learners) for each scenario, demonstrating how prospective learning can outperform standard methods when the optimal hypothesis changes over time.", "section": "Different prospective learning scenarios with illustrative examples"}, {"figure_path": "XEbPJUQzs3/figures/figures_30_1.jpg", "caption": "Figure 1: A schematic for prospective learning (left) and realizations of the examples for the four scenarios (top right); dots denote 1s and empty spaces denote 0s for Yt \u2208 {0, 1} with Xt = 1 for all times t. Prospective risk of learners at different times is shown in the bottom panels and discussed in Section 2.1. Scenario 1: For Bernoulli probability p = 0.2, the maximum-likelihood estimator (MLE) in blue uses a time-agnostic hypothesis ht(Xt) = 1(pt > 0.5) where pt = t\u00af\u00b9 \u2211=1 Ys, ties at pt = 0.5 are broken randomly. The risk of this learner converges to the Bayes risk. Scenario 2: For Bernoulli probability p = 0.2, the MLE estimator (blue) performs at chance levels. A prospective learner (orange) that alternates between two predictors at even and odd times converges to Bayes risk. Variants of this learner that use less information from the stochastic process (green does not know that the data distributions at even and odd times are tied, red does not know that the distribution shifts at every time-step) also converge to Bayes risk, but more slowly. Scenario 3: For \u03b8\u03bf = 0.1 and \u03b8\u2081 = 0.9 in the discounted prospective risk, the MLE estimator (blue) again performs at chance levels. A prospective learner that computes an estimate of the transition probability of the two-state Markov chain to estimate P(Yt | yt) for future times t' > t converges to Bayes risk. Scenario 4: For \u03b8\u03bf = \u03b8\u2081 = 0.1, the MLE estimator (blue) performs at chance levels. A prospective learner that uses a variant of Q-learning (described in the text and Appendix B.3) converges to the prospective Bayes risk.", "description": "This figure illustrates four different prospective learning scenarios with examples.  It shows how the optimal hypothesis changes over time in each scenario, and how different learners (including a prospective learner) perform in terms of minimizing the prospective risk.  The scenarios range from simple IID data to more complex Markov decision processes.", "section": "Different prospective learning scenarios with illustrative examples"}, {"figure_path": "XEbPJUQzs3/figures/figures_30_2.jpg", "caption": "Figure 2: Prospective ERM can achieve good instantaneous and prospective risk in Scenario 2. Left: Instantaneous and prospective risks for problems constructed using synthetic data (see text) across 5 random seeds (which govern the sequence of samples and the weight initializations of neural networks). Instantaneous risk spikes when the task switches for many online learning baseline algorithms. In contrast, prospective ERM has minimal spikes at later times and both instantaneous and prospective risks eventually converge to zero. Right: Prospective risk for different baseline algorithms and prospective ERM for tasks constructed using MNIST and CIFAR-10 for Scenario 2. In all three cases, the risk of prospective ERM approaches Bayes risk while online learning baselines considered here do not achieve a low prospective risk. For comparison, the chance prospective risk is 0.5 for synthetic data and 0.742 for MNIST and CIFAR-10 tasks.", "description": "This figure compares the performance of prospective ERM against other online learning algorithms (Follow-the-leader, Online SGD, Bayesian Gradient Descent) in Scenario 2 (data is independent but not identically distributed). The left panel shows instantaneous and prospective risks for synthetic data, demonstrating that prospective ERM maintains low risk even during task switches, unlike other methods.  The right panel shows prospective risk for MNIST and CIFAR-10 datasets, illustrating that prospective ERM consistently achieves lower risk than other algorithms and approaches the Bayes risk.", "section": "Experimental Validation"}, {"figure_path": "XEbPJUQzs3/figures/figures_31_1.jpg", "caption": "Figure 2: Prospective ERM can achieve good instantaneous and prospective risk in Scenario 2. Left: Instantaneous and prospective risks for problems constructed using synthetic data (see text) across 5 random seeds (which govern the sequence of samples and the weight initializations of neural networks). Instantaneous risk spikes when the task switches for many online learning baseline algorithms. In contrast, prospective ERM has minimal spikes at later times and both instantaneous and prospective risks eventually converge to zero. Right: Prospective risk for different baseline algorithms and prospective ERM for tasks constructed using MNIST and CIFAR-10 for Scenario 2. In all three cases, the risk of prospective ERM approaches Bayes risk while online learning baselines considered here do not achieve a low prospective risk. For comparison, the chance prospective risk is 0.5 for synthetic data and 0.742 for MNIST and CIFAR-10 tasks.", "description": "The figure shows the comparison of prospective ERM and other online learning algorithms like Follow-the-Leader, online SGD, and Bayesian gradient descent in Scenario 2. The left panel shows that prospective ERM achieves better instantaneous and prospective risk than other algorithms when data distribution changes over time. The right panel shows that prospective ERM achieves significantly lower prospective risk compared to other algorithms on MNIST and CIFAR-10 datasets.", "section": "Experimental Validation"}, {"figure_path": "XEbPJUQzs3/figures/figures_31_2.jpg", "caption": "Figure 1: A schematic for prospective learning (left) and realizations of the examples for the four scenarios (top right); dots denote 1s and empty spaces denote 0s for Yt \u2208 {0, 1} with Xt = 1 for all times t. Prospective risk of learners at different times is shown in the bottom panels and discussed in Section 2.1. Scenario 1: For Bernoulli probability p = 0.2, the maximum-likelihood estimator (MLE) in blue uses a time-agnostic hypothesis ht(Xt) = 1(pt > 0.5) where pt = t\u00af\u00b9 \u2211=1 Ys, ties at \u00eet = 0.5 are broken randomly. The risk of this learner converges to the Bayes risk. Scenario 2: For Bernoulli probability p = 0.2, the MLE estimator (blue) performs at chance levels. A prospective learner (orange) that alternates between two predictors at even and odd times converges to Bayes risk. Variants of this learner that use less information from the stochastic process (green does not know that the data distributions at even and odd times are tied, red does not know that the distribution shifts at every time-step) also converge to Bayes risk, but more slowly. Scenario 3: For \u03b80 = 0.1 and \u03b81 = 0.9 in the discounted prospective risk, the MLE estimator (blue) again performs at chance levels. A prospective learner that computes an estimate of the transition probability of the two-state Markov chain to estimate P(Yt | yt) for future times t' > t converges to Bayes risk. Scenario 4: For \u03b80 = \u03b81 = 0.1, the MLE estimator (blue) performs at chance levels. A prospective learner that uses a variant of Q-learning (described in the text and Appendix B.3) converges to the prospective Bayes risk.", "description": "This figure illustrates four different scenarios of prospective learning with their corresponding data examples and learner performances.  It visually demonstrates how prospective learning handles different levels of data dependency and distribution shifts, contrasting it with standard MLE approaches which perform poorly in dynamic settings. The bottom panels show how the prospective risk of different learners (including variations on prospective ERM) change over time for each scenario.", "section": "Different prospective learning scenarios with illustrative examples"}, {"figure_path": "XEbPJUQzs3/figures/figures_31_3.jpg", "caption": "Figure 1: A schematic for prospective learning (left) and realizations of the examples for the four scenarios (top right); dots denote 1s and empty spaces denote Os for Yt \u2208 {0, 1} with Xt = 1 for all times t. Prospective risk of learners at different times is shown in the bottom panels and discussed in Section 2.1. Scenario 1: For Bernoulli probability p = 0.2, the maximum-likelihood estimator (MLE) in blue uses a time-agnostic hypothesis ht(Xt) = 1(pt > 0.5) where pt = t\u00af\u00b9 \u2211=1 Ys, ties at \u00eet = 0.5 are broken randomly. The risk of this learner converges to the Bayes risk. Scenario 2: For Bernoulli probability p = 0.2, the MLE estimator (blue) performs at chance levels. A prospective learner (orange) that alternates between two predictors at even and odd times converges to Bayes risk. Variants of this learner that use less information from the stochastic process (green does not know that the data distributions at even and odd times are tied, red does not know that the distribution shifts at every time-step) also converge to Bayes risk, but more slowly. Scenario 3: For 0 = 0.1 and y = 0.9 in the discounted prospective risk, the MLE estimator (blue) again performs at chance levels. A prospective learner that computes an estimate of the transition probability of the two-state Markov chain to estimate P(Yt | yt) for future times t' > t converges to Bayes risk. Scenario 4: For \u03b8\u03bf = 0\u2081 = 0.1, the MLE estimator (blue) performs at chance levels. A prospective learner that uses a variant of Q-learning (described in the text and Appendix B.3) converges to the prospective Bayes risk.", "description": "This figure presents four different scenarios of prospective learning: IID, independent but not identically distributed (INID), Markov Chain, and Markov Decision Process. It visually demonstrates the data distribution for each scenario and shows how different learners (MLE and prospective learners) perform in terms of risk convergence to the Bayes risk over time.", "section": "Different prospective learning scenarios with illustrative examples"}]