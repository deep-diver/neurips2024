[{"type": "text", "text": "Low Precision Local Training is Enough for Federated Learning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zhiwei $\\mathbf{Li^{1,*}}$ Yiqiu $\\mathbf{Li^{1,*}}$ Binbin $\\mathbf{Lin}^{2,4}$ Zhongming $\\mathbf{Jin^{3}}$ Weizhong Zhang1,\u2020   \n1Fudan University 2Zhejiang University 3Alibaba Cloud Computing 4Fullong Inc. {zwli23, yiqiuli22}@m.fudan.edu.cn binbinlin@zju.edu.cn zhongming.jinzm@alibaba-inc.com weizhongzhang@fudan.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Federated Learning (FL) is a prevalent machine learning paradigm designed to address challenges posed by heterogeneous client data while preserving data privacy. Unlike distributed training, it typically orchestrates resource-constrained edge devices to communicate via a low-bandwidth communication network with a central server. This urges the development of more computation and communication efficient training algorithms. In this paper, we propose an efficient FL paradigm, where the local models in the clients are trained with low-precision operations and communicated with the server in low precision format, while only the model aggregation in the server is performed with high-precision computation. We surprisingly find that high precision models can be recovered from the low precision local models with proper aggregation in the server. In this way, both the workload in the client-side and the communication cost can be significantly reduced. We theoretically show that our proposed paradigm can converge to the optimal solution as the training goes on, which demonstrates that low precision local training is enough for FL. Our paradigm can be integrated with existing FL algorithms flexibly. Experiments across extensive benchmarks are conducted to showcase the effectiveness of our proposed method. Notably, the models trained by our method with the precision as low as 8 bits are comparable to those from the full precision training. As a by-product, we show that low precision local training can relieve the over-fitting issue in local training, which under heterogeneous client data can cause the client models drift further away from each other and lead to the failure in model aggregation. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Federated learning (FL) [3, 15, 22, 36] is a popular privacy preserving machine learning paradigm to collaboratively learn a global model over the decentralized data. In FL paradigm, the clients are responsible for local training and only have access to their private datasets, while the server plays an essential role in aggregating the clients\u2019 updates into a global model. Unlike large-scaled distributed training, FL typically orchestrates resource-constrained edge devices to communicate via a low-bandwidth communication network with a central server. This urges the development of more computation and communication efficient optimization algorithms. The most prevalent approach in FL is developed based on local-SGD [26], which is referred to as FedAvg. In each communication round, the clients individually train their local models for multiple steps and then send them to the server for aggregation. It can be expected that if longer local training process one uses, the greater communication cost saving one can achieve. However, long time local training could cause the local models drift further away from each other and degrades the aggregated global model\u2019s performance or even make the training diverge, especially when the data on the clients are heterogeneous. Therefore, in order to prolong local training processes in FL, extensive efforts have been made in the recent years. For example, the studies [1, 16, 21, 22] modify the local training process by imposing regularization on the client models to enforce them not to drift away from the previous global model. Another line of research [5, 6, 24, 31, 35, 38] focuses on refining the global model in the server aggregation process. These methods typically require a large proxy dataset on the server. Some of them [5, 6, 24] use it to align the outputs of the global model with that of the client ensemble by knowledge distillation. Others develop handcrafted aggregation rules to reweight the updates based on the statistics of updates or performance on proxy data [31, 35, 38] or further tune the global model with proxy data in every communication round [5, 24]. Although promising experimental results have been reported in the literature, it is still unclear that whether there exists more concise and effective FL paradigm, which can reduce both the workload in the client-side and the communication cost. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In this paper, we propose a concise and efficient federated learning paradigm, where the local models in the clients are trained with low precision operations and communicated with the server in low precision format, while only the server-side information integration maintains high-precision computation to ensure the accuracy. Our basic idea is inspired from the Kolmogorov\u2019s law [10], that is, the sample average can converge almost surely to the expected value although the samples always contain noise. Therefore, in the server side, we perform the simple moving average on the received low precision models from the clients to recover a high precision global model. In this way, both the workload in the client-side and the communication cost can be significantly reduced. We theoretically proved that our proposed paradigm integrated with FedAVG can converge to the optimal solution as the training goes on, which indicates that low precision local training is enough for federated learning. We extend our method to various existing FL method to show its flexibility. Experiments across extensive benchmarks are conducted to showcase the effectiveness of our proposed method. Notably, the models trained by our method with the precision as low as 8 bits are comparable to those from the full precision federated learning. Compared with some efficient FL designs, our method can achieve significant savings in training memory overhead, and what is more attractive is that our accuracy performance is even better. Our method exhibits another appealing feature in relieving the over-ftiting issue in local training. To be precise, in the local training steps, the models can be easily trained to over-fit the local training data as the local dataset is always insufficient. Under heterogeneous client data, it would further cause the client models drift further away from each other and lead to the failure in model aggregation. The experimental results show that our approach can effectively relieve the over-fitting issue since the local training is performed with low precision computation and the expressiveness of the local model is restricted. ", "page_idx": 1}, {"type": "text", "text": "Our main contributions are as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We propose an efficient federated learning paradigm that performs low precision computation during local training, saving computational overhead and communication costs, while being able to restore accuracy through high-precision aggregation on the server side.   \n\u2022 We theoretically proved that the efficient federated learning algorithm we proposed can achieve convergence at a rated of $\\mathcal{O}(1/T)$ under certain assumptions for non-iid situations.   \n\u2022 Since the expressiveness of the local model is restricted due to the low precision local training, our approach can relieve the over-ftiting issue, which would cause the client models drift further away from each other and lead to the failure in model aggregation when the local dataset are heterogeneous.   \n\u2022 The extensive experimental results demonstrate the effectiveness of our approach. Notably, the models trained by our method with the precision as low as 8 bits are comparable to those from the full precision federated learning. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Federated Learning. Fedrated Learning is first proposed by [26] to realize model training without sharing client device data. Many works have continued to solve some challenges of FL such as heterogeneity [16, 22, 25], privacy [2], communication efficiency [11, 18]. Also, some works proposes new FL methods to alleviate data heterogeneity. The vanilla FL method was FedAvg [26]. ", "page_idx": 1}, {"type": "text", "text": "FedProx [22] utilizes a regularization term while Scaffold [16] sets a control variate to reduce the drift in local training. FedGen [42] and FedFTG [40] maintain a generator, the former is used for local data augmentation, while the latter is used for fine-tuning the server. ", "page_idx": 2}, {"type": "text", "text": "Efficient Federated Learning. One challenge of FL is the limitation of low bandwidth and computing resources of client devices. [4, 20] assign each client a block mask, resulting in sparse local models. [28] took the transmission speed into consideration and chose the same method as [12] for uploading, uploading compressed gradients. [13] adopts boost training to client-side training overhead. [7, 28] only transmit the trained head to reduce transmission cost. [33] adopts the idea of Network Architecture Searching, e.g., each client selects a sub-network. [14] maintains a series of streamlined models in the server, from which the client selects a tiny model for training. In [9], the client selects a sub-model of the global model for training. In this paper, we address this issue by using low precision local training. ", "page_idx": 2}, {"type": "text", "text": "3 Preliminary ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 Federated Learning ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Given $N$ clients with their private datasets $\\mathcal{D}_{k}=\\{(x_{k,j},y_{k,j})\\}_{j=1}^{|\\mathcal{D}_{k}|}$ , $k=1,\\ldots,N$ , the optimization objective of $\\mathrm{FL}$ is always defined as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{w}}F(\\mathbf{w})\\triangleq\\sum_{k=1}^{N}p_{k}F_{k}(\\mathbf{w}),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mathbf{w}\\in\\mathbb{R}^{d}$ represents the model parameters, $F_{k}$ is denoted to be the empirical risk function of client $k$ , i.e., $\\begin{array}{r}{F_{k}(\\mathbf{w})=\\sum_{\\xi\\in\\mathcal{D}_{k}}\\frac{1}{|\\mathcal{D}_{k}|}\\ell(\\mathbf{w};\\xi)}\\end{array}$ with $\\ell(\\cdot,\\cdot)$ being the loss function and $\\begin{array}{r}{p_{k}=\\frac{|\\mathcal{D}_{k}|}{\\sum_{k=1}^{N}|\\mathcal{D}_{k}|}}\\end{array}$ denotes the proportion of data contained in client $k$ . ", "page_idx": 2}, {"type": "text", "text": "FL emphasizes data privacy protection and thus the server is not allowed to access these datasets $\\mathcal{D}_{k}$ directly in model training. The standard method to solve the above training problem of FL is FedAvg [26], which is developed based on local SGD. It is comprised by two steps, i.e., local training on the clients and model aggregation in the server side. The details are presented below. ", "page_idx": 2}, {"type": "text", "text": "\u2022 In local training, the central server would first randomly select partial clients and broadcasts the latest global model ${\\bf w}_{t}$ to them. We denote the selected clients set as $\\mathcal{S}_{t}$ and let $K=|\\ensuremath{\\boldsymbol{S}}_{t}|$ be the number of selected clients. Then the client $k$ with $k\\in S_{t}$ would initialize its local model to be $\\mathbf{w}_{t}^{k}=\\mathbf{w}_{t}$ and then performs local training with $E(\\geq1)$ iterations as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbf{w}_{t+1}^{k}\\leftarrow\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k};\\xi_{t}^{k}),k\\in\\mathcal{S}_{t},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mathbf{w}_{t}^{k}$ is the weights of the $k$ -th client in step $t,\\xi_{t}^{k}$ is a mini-batch of samples uniformly chosen from $\\mathcal{D}_{k}$ , $\\eta_{t}$ is the step size. ", "page_idx": 2}, {"type": "text", "text": "\u2022 In model aggregation, FedAvg updates the global model to be the weighted average of the received local models, i.e., ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{w}_{t+E}\\leftarrow\\sum_{k\\in S_{t}}\\frac{p_{k}}{q_{t}}\\mathbf{w}_{t+E}^{k},}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\begin{array}{r}{q_{t}=\\sum_{k\\in S_{t}}p_{k}}\\end{array}$ normalize the coefficients. ", "page_idx": 2}, {"type": "text", "text": "3.2 Block Floating Point Quantization ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Fixed point quantization is a standard quantization technique. It uses stochastic rounding to round the numbers up or down at random such that $\\mathbb{E}[Q(x)]=\\bar{x}$ , where $Q:\\mathbb{R}\\rightarrow\\mathbb{R}$ is the quantization function defined as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{Q(x)=\\binom{\\mathrm{clip}(\\delta\\lfloor\\frac{x}{\\delta}\\rfloor,l,u)}{\\mathrm{clip}(\\delta\\lceil\\frac{x}{\\delta}\\rceil,l,u)}\\;\\;\\;\\mathrm{w.p.}\\;\\;\\lceil\\frac{x}{\\delta}\\rceil-\\frac{x}{\\delta},}\\\\ {\\mathrm{clip}(\\delta\\lceil\\frac{x}{\\delta}\\rceil,l,u)\\;\\;\\;\\mathrm{w.p.}\\;\\;1-\\bigl(\\lceil\\frac{x}{\\delta}\\rceil-\\frac{x}{\\delta}\\bigr),}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "here $\\operatorname{clip}(x,a,b)\\,=\\,\\operatorname*{max}(\\operatorname*{min}(x,b),a)$ , $\\delta\\,=\\,2^{-F}$ is the quantization gap represents the distance between successive representable fixed point numbers, $\\dot{u^{\\ast}}=2^{W-F-1}-\\dot{2}^{-\\dot{F}}$ and $l=-2^{W-F-1}$ represent the upper and lower limits of the representable numbers, respectively. $W$ is the bit width of quantized numbers, and $F$ is the bit width of quantized numbers\u2019 fractional part. In order to improve the utilization efficiency of the bit width and better maintain numerical accuracy when data is unevenly distributed, we choose block floating point quantization. Given a block of numbers $X$ , it replaces $\\delta=2^{-F}$ in fixed point quantization to be $\\delta=2^{-E(X)+W-2}$ , where ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\nE(X)=\\operatorname{clip}(\\lfloor\\log_{2}(\\operatorname*{max}_{i}|X_{i}|)\\rfloor,-2^{W-F-1},2^{W-F-1}-1).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The shared exponent $E(X)$ is usually set to be the largest exponent in $X$ to avoid overflow [37]. ", "page_idx": 3}, {"type": "text", "text": "4 Method ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we introduce our low precision federated learning paradigm. It is comprised of two modules,i.e., one is the low precision local training to reduce the computation and communication cost, the other is the high precision aggregation with moving average to maintain the model accuracy. ", "page_idx": 3}, {"type": "text", "text": "4.1 Low Precision Local Training ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In order to reduce the computation and communication cost, we apply block floating point quantization to all clients\u2019 device of local training. The simple version of low precision local training is to convert the local training step in Eqn.(2) into ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{w}_{t+1}^{k}=Q\\big(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k};\\xi_{t}^{k})\\big).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Note that in the above version, we only quantize the updated parameters. We give this version just for the convenience of the theoretical analysis in Section 5. In practice, we quantize the gradient, the activation of each layer, the back-propagation signals, and the momentum in SGD when SGD is adopted as the optimizer. The details are given in Algorithm 1. ", "page_idx": 3}, {"type": "text", "text": "Algorithm 1 Low Precision Local Training with All Numbers Quantized   \nInput: Quantization functions $Q_{A}$ , $Q_{E}$ , $Q_{G}$ , $Q_{M}$ , $Q_{W}$ ; Momentum coefficient $\\rho$ ; L layers DNN   \n$\\{f_{1},f_{2},\\ldots,f_{L}\\}$ ; Loss function $\\ell$ .   \n1: ClientUpdate $(\\bar{t},k,w_{t}^{k})$ :   \n2: Get batch $(x_{k,j_{t}},y_{k,j_{t}})$ from $\\mathcal{D}_{k}$   \n3: Forward Propagation:   \n4: 5: $\\begin{array}{r l}&{(a_{t}^{k})^{(0)}=x_{k,j_{t}}}\\\\ &{(a_{t}^{k})^{(l)}=Q_{A}\\big(f_{l}\\big((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)}\\big)\\big),\\forall l\\in[1,L]}\\\\ &{\\mathbf{rkward\\,Propagation:}}\\\\ &{(e_{t}^{k})^{(L)}=\\nabla_{(a_{t}^{k})^{(L)}}\\ell\\big((a_{t}^{k})^{(L)},y_{k,j_{t}}\\big)}\\\\ &{(e_{t}^{k})^{(l-1)}=Q_{E}\\big(\\frac{\\partial f_{l}\\big((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)}\\big)}{\\partial(a_{t}^{k})^{(l-1)}}\\big(e_{t}^{k}\\big)^{(l)}\\big),\\forall l\\in[1,L]}\\\\ &{(g_{\\underline{{r}}}^{k})^{(l)}=Q_{G}\\big(\\frac{\\partial f_{l}\\big((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)}\\big)}{\\partial(w_{t}^{k})^{(l)}}\\big(e_{t}^{k}\\big)^{(l)}\\big),\\forall l\\in[1,L]}\\end{array}$   \n6: B   \n7:   \n8:   \n9:   \n10: Low Precision SGD Update:   \n11: $(v_{t+1}^{k})^{(l)}\\gets Q_{M}(\\rho(\\hat{v}_{t}^{k})^{(l)}+(g_{t}^{k})^{(l)}),\\forall l\\in[1,L]$   \n12: $(w_{t+1}^{k})^{(l)}\\gets Q_{W}((w_{t}^{k})^{(l)}-\\eta_{t}\\cdot(v_{t+1}^{k})^{(l)}),\\forall l\\in[\\]$ 1, L]   \n13: Return: $w_{t+1}^{k}$ ", "page_idx": 3}, {"type": "text", "text": "4.2 High Precision Aggregation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Although low precision training can reduce communication and training overhead, it would lead to a degradation in training accuracy. Inspired from the Kolmogorov\u2019s law [10], that is, the sample average can converge almost surely to the expected value although the samples always contain noise, we try to recover high-precision solution from the low-precision local model with a full precision aggregation process. It is implemented with the following two steps: ", "page_idx": 3}, {"type": "text", "text": "\u2022 Calculate the weighted average of the local models to partially reconvert the precision, i.e., ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{w}_{t+E}\\leftarrow\\sum_{k\\in S_{t}}\\frac{p_{k}}{q_{t}}\\mathbf{w}_{t+E}^{k}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "\u2022 Since in most cases clients\u2019 data is non-iid and quantization causes error, federated learning is harder to converge, however maintaining a moving average in the server can significantly alleviate the problem. Formally, we denote $\\bar{\\bf w}_{t}$ as the moving average stored in the server, then after aggregation, we update $\\bar{\\bf w}_{t}$ as follow ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\bar{\\mathbf{w}}_{t}\\leftarrow Q(\\lambda\\bar{\\mathbf{w}}_{t-E}+(1-\\lambda)\\mathbf{w}_{t}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\lambda$ is a coefficient controlling the influence of current weight. This procedure can further compensate the accuracy degradation due to the low precision local training. ", "page_idx": 4}, {"type": "text", "text": "In the next round of local training, the quantized model $Q(\\bar{\\mathbf{w}}_{t})$ will be distributed to the clients to intilize the local models. Our pseudocode in Algorithm 2 depicts the process of low precision local training on the client device and high precision aggregation on the server. In Algorithm 2, $t^{\\prime}=t-E\\,\\bar{+}\\,1$ and $\\mathcal{T}_{E}=\\{n E|n=1,2,\\dot{\\cdot}\\dot{\\cdot}\\cdot\\}$ represents the set of global synchronization steps. ", "page_idx": 4}, {"type": "table", "img_path": "vvpewjtnvm/tmp/f3525fdbde3ab2482e96edbb1541ced3fe33f75ad56d4c7bf3c7109909f8bad8.jpg", "table_caption": [], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "5 Theoretical Analysis ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we give the detailed theoretical results for our low precision FL paradigm. We will first introduce the convergence analysis in the full participation case where all client devices participate (i.e., $K=N$ ) and then we generalize the results of the analysis to scenarios that are more in line with reality. (i.e., $K<N$ ). The results demonstrate that we will explore aggregation strategies represented by the FederatedAveraging Algorithm (or FedAvg) and demonstrate that our proposed low precision FL framework can converge to the global optimal solution at a rate of $\\mathcal{O}(1/\\bar{T})$ for non-iid datasets based on strong convexity and smoothness assumptions. ", "page_idx": 4}, {"type": "text", "text": "5.1 Assumptions and Notations ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We need to make necessary assumptions about the objective function on the clients $F_{k},k=1,\\ldots,N$ . Assumption 1 is about the smoothness and strong convexity of the loss function and Assumption 2 is about the boundness of the gradients. These assumptions are standard and widely adopted in the related studies [41, 29, 30, 39]. ", "page_idx": 4}, {"type": "text", "text": "Assumption 1. $F_{1},F_{2},...,F_{N}$ are $L$ -smooth and $\\mu$ -strongly functions, which means that for all v and w, the following inequalities hold: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{{\\displaystyle F_{k}({\\bf v})\\leq F_{k}({\\bf w})+\\left({\\bf v}-{\\bf w}\\right)^{T}\\nabla F_{k}({\\bf w})+\\frac{L}{2}{\\|{\\bf v}-{\\bf w}\\|_{2}^{2}},\\quad}&{{\\displaystyle(L-s m o o t h)}}\\\\ {{\\displaystyle F_{k}({\\bf v})\\geq F_{k}({\\bf w})+\\left({\\bf v}-{\\bf w}\\right)^{T}\\nabla F_{k}({\\bf w})+\\frac{\\mu}{2}{\\|{\\bf v}-{\\bf w}\\|_{2}^{2}},\\quad}&{{\\displaystyle(\\mu-s t r o n g)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\left\\Vert\\cdot\\right\\Vert^{2}$ represents the square of two norms and $k=1,\\ldots,N$ . ", "page_idx": 4}, {"type": "text", "text": "Assumption 2. Let $\\xi_{t}^{k}$ be sample that randomly and uniformly sampled from the local data of the $k$ -th client device. For $k=1,2,\\cdots,N$ and $t=0,1,\\cdot\\cdot\\cdot$ , the variance of stochastic gradients in each client device and the expectation of squared two norm of stochastic gradients is bounded: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big\\|\\nabla F_{k}(\\mathbf{w}_{t}^{k};\\xi_{t}^{k})-\\nabla F_{k}(\\mathbf{w}_{t}^{k})\\big\\|_{2}^{2}\\leq\\sigma_{k}^{2},}\\\\ &{\\mathbb{E}\\big\\|\\nabla F_{k}(\\mathbf{w}_{t}^{k};\\xi_{t}^{k})\\big\\|_{2}^{2}\\leq G^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Degree of Data Heterogeneity. Let $F^{*}$ denote the global minimum of the objective function $F$ , and let $F_{k}^{*}$ represent the minimum of the local objective function $F_{k}$ specific to the $k$ -th client. We use the metric $\\Gamma$ [23] taking the form of ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\Gamma=F^{*}-\\sum_{k=1}^{N}p_{k}F_{k}^{*},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "to measure the degree of heterogeneity of all clients\u2019 data distribution. When the data on each client device is iid, as the number of samples increase, $\\Gamma$ evidently tends towards zero. However, when faced with non-iid situation, $\\Gamma$ tends towards a positive constant and thus it can be used to measure the degree of heterogeneity in the data distribution of each client device. ", "page_idx": 5}, {"type": "text", "text": "5.2 Convergence Analysis: Full Client Device Participation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "First we analyze the convergence of the participation of all clients\u2019 device in this section. We integrate our low precision FL framework with FedAvg and train the model for $T$ iterations to obtain the $\\bar{\\bf w}_{T}$ , and we expect $T$ to be divided by $E$ so that $\\bar{\\bf w}_{T}$ is the weight after aggregation. ", "page_idx": 5}, {"type": "text", "text": "Theorem 1. Under the Assumptions 1 and 2, we set \u03ba = L\u00b5 , \u03b3 = max{8\u03ba, E} \u22121 and \u03b7t =2(t\u00b5+\u03b3). When t satisfying $\\delta^{2}\\leq\\eta_{t}^{2}G^{2}$ , low precision FedAvg with full device participation satisfies: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}[F(\\bar{\\mathbf{w}}_{T})]-F^{*}\\le\\frac{\\kappa}{T+\\gamma}\\left(\\frac{2B}{\\mu}+\\frac{\\mu(\\gamma+1)}2\\|\\mathbf{w}_{1}-\\mathbf{w}^{*}\\|_{2}^{2}\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where ", "page_idx": 5}, {"type": "equation", "text": "$$\nB=2(\\sqrt{d}\\delta+1+\\frac{d}{2})G^{2}+16E^{2}G^{2}(2\\sqrt{d}\\delta+3)+\\frac{1}{N^{2}}\\sum_{k=1}^{N}{\\sigma_{k}}^{2}+6L\\Gamma.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "5.3 Convergence Analysis: Partial Client Device Participation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Compared to full participation situation, the partial participation situation is more in line with the reality. We need to make more assumption on how to choose $\\mathcal{S}_{t}$ . ", "page_idx": 5}, {"type": "text", "text": "Assumption 3. Assume $\\mathcal{S}_{t}$ contains a subset of $K$ indices uniformly sampled from $[N]$ without replacement. In addition, the data is balanced in the sence that $\\begin{array}{r}{p_{1}\\;=\\;\\cdot\\cdot\\;=\\;p_{N}\\;\\stackrel{}{=}\\;\\frac{1}{N}}\\end{array}$ . The aggregation step of FedAvg performs $\\begin{array}{r}{\\mathbf{w}_{t+E}\\gets\\frac{1}{K}\\sum_{k\\in S_{t}}\\mathbf{w}_{t+E}^{k}}\\end{array}$ ", "page_idx": 5}, {"type": "text", "text": "Theorem\u221a 2. Under the Assumptions 1 t\u221ao 3, we choose $\\begin{array}{r}{\\kappa=\\frac{L}{\\mu}}\\end{array}$ , $\\begin{array}{r}{\\gamma=\\operatorname*{max}\\{8\\kappa,E\\}-1,\\eta_{t}=\\frac{\\mu}{2(t+\\gamma)}}\\end{array}$ and $\\begin{array}{r}{3=2(\\sqrt{d}\\delta+1+\\frac{d}{2})G^{2}+16E^{2}G^{2}(2\\sqrt{d}\\delta+3)+\\frac{1}{N^{2}}\\sum_{k=1}^{N}{\\sigma_{k}}^{2}+6L\\Gamma,C=\\frac{N-K}{N-1}\\frac{8}{K}E^{2}G^{2}(2\\sqrt{d}\\delta+\\frac{3}{2})+\\frac{1}{N}\\sum_{k=1}^{N}{\\sigma_{k}}^{2}}\\end{array}$ $3)+d G^{2}$ . When $t$ satisfying $\\delta^{2}\\leq\\eta_{t}^{2}G^{2}$ , low precision FedAvg with partial client device participation satisfies: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}[F(\\bar{\\mathbf{w}}_{T})]-F^{*}\\le\\frac{\\kappa}{T+\\gamma}\\left(\\frac{2(B+C)}{\\mu}+\\frac{\\mu(\\gamma+1)}{2}\\|\\mathbf{w}_{1}-\\mathbf{w}^{*}\\|_{2}^{2}\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we conduct extensive experiments to verify the effectiveness of our methods in the following five aspects: ", "page_idx": 5}, {"type": "text", "text": "\u2022 When integrated with FedAvg, the models trained by our method with the low precision are comparable to (if not better than) those from the full precision training. This would also verify our theoretical results (Section 6.1). \u2022 Our method can effectively relieve the over-fitting issue in FL. See Section (Section 6.2). ", "page_idx": 5}, {"type": "text", "text": "\u2022 Our paradigm can be integrated with existing FL methods flexibly and preserve the performance even with a low precision local training (Section 6.3).   \n\u2022 Ablation studies on the effectiveness of moving average in model aggregation and the transferability over various neural networks (Section 6.4).   \n\u2022 Comparison with other efficient FL techniques (Section 6.5). ", "page_idx": 6}, {"type": "text", "text": "Remark 1. Similar with the existing low precision training studies [32], We do not give the results on the running time to show the real acceleration. The reason is that to achieve real acceleration, we need to implement our method integrated with the professional hardware. Moreover, such implementation is standard for the professional hardware platforms. ", "page_idx": 6}, {"type": "text", "text": "Benchmark Datasets and Baseline. We conduct experiments over four commonly used datasets: FashionMnist [34], CIFAR10 [19], CIFAR100 [19] and CINIC10 [8]. Four commonly used FL methods: 1) FedAvg [26]; 2) regularization-based strategy FedProx [22]; 3) data-dependent knowledge distillation strategy ABAvg [35] 4) data-free knowledge distillation strategy FedFTG [40] and FedGen [42] are adopted as the baselines. ", "page_idx": 6}, {"type": "text", "text": "Configurations. We follow the configurations in the recent studies [26, 42, 27] for fair comparison. To be precise, for FashionMNIST, CIFAR10, CINIC10 and CIFAR100, we run 200 communication rounds with local epoch set to 1. There are 80 clients in total, and the participation ratio in each round is set to $40\\%$ . We use Dirichlet distribution to simulate non-iid data distribution and set $\\alpha$ to 0.01, 0.04, and 0.16. The smaller $\\alpha$ is, the more serious the data heterogeneity is. For the network choice, we use ConvNet following with 3 layers, and the hidden dimension is set to 128. The local learning rate is set to $10^{-3}$ with Adam optimizer [17]. We report the last 5 round global model\u2019s average performance evaluated using the test split of the datasets. For quantization method, we adopt the Block FLoating Point Quantization with the number of bits used set to 6, 8 and 32 (without quantization). Some of the other hyperparameter settings are included in the Appendix C. ", "page_idx": 6}, {"type": "text", "text": "6.1 Results on FedAvg ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We demonstrate the superior performance of our Low Precision FL method with FedAvg by conducting experiments over comprehensive datasets, various precision and heterogeneity values $\\alpha$ . ", "page_idx": 6}, {"type": "text", "text": "Heterogeneity. As shown in Table 1, it is as expected that when the heterogeneity goes higher, that is, when $\\alpha$ decreases, the server performance worsens. Nevertheless, our proposed method can always maintain or improve the performance of the original case (bits $=32$ , w/o. avg) when using 8 quantizaiton bits with moving average, which empirically validates the effectiveness of our proposed method. ", "page_idx": 6}, {"type": "text", "text": "Quantization Bits. We conduct experiments on 3 quantization bits: 32, 8, 6 (shown in Table 1, Figure 1), as we observe that in most cases 8 bits is enough to hold the performance of full-precision and when the used bits is 6, the server performance begins to decrease due to the low precision level. ", "page_idx": 6}, {"type": "text", "text": "Table 1: Results of our method integrated with FedAvg over various levels of heterogeneity and precision. The results with moving average demonstrate that our method can match the performance of full-precision federated learning even with all numbers quantized down to 8 bits. The results in the bottom three rows indicates the without moving average, training with low precision would lead to performance degradation. ", "page_idx": 6}, {"type": "table", "img_path": "vvpewjtnvm/tmp/9934976fb1c82a237827bd94aee3aa4e8ef854385693c717858aba97fd97881d.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "6.2 Quantization Relieves Overfitting ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We present the averaged local training loss and the global testing loss over training in Figure 2. It can be seen that our method can effectively reduce testing losses on the server. The commonality with the original method is that when each round of communication starts retraining, the training loss of the client will be greatly increased due to the heterogeneity of the data $\\mathcal{D}_{k}$ . Subsequently, due to the highly imbalanced local data categories, the model quickly reached an overfitting state. It can be seen that at the beginning of each training round, under our method, the customer\u2019s training loss will not exceed the original training loss. At the same time, with some training steps, our training loss remains above the original training loss, which means our method can alleviate the overfitting problem of local training. ", "page_idx": 6}, {"type": "image", "img_path": "vvpewjtnvm/tmp/1132ce4920a37d9df38d8697ae45cc3bb25aa22d32c51b3f9152d4a88de00537.jpg", "img_caption": ["Figure 1: Accuracy and loss of FedAvg with full precision (origin), our method with precsion levels of 8 bit and 6 bit. We set $\\alpha=0.01$ on all the four datasets. Our method exhibits an effective reduction in fluctuation variance and improves the stability of training. The reason is that compared with the full precision training, our low precision local training can prevent the client models to drift further away from each other and overfit the local datasets, making the aggregation stable. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "image", "img_path": "vvpewjtnvm/tmp/5181d1a02fb3a8256ee53ed1997070a4af25ab87ff3efc1fc80d0d2727c1ed9d.jpg", "img_caption": ["Figure 2: Effectiveness of our method in relieving the over-fitting issue. We present the averaged local training loss and the global test loss over training. We select a part of the training procedure (iteration 1000 to 1400) for display, and enlarge a part of the picture in the upper right corner to show more details. We can observe that the local training loss of FedAvg (full precision) is siginificantly lower than our method, however its global test loss is much higher than us and fluctuates dramatically. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "6.3 Results on Other FL Methods ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The four FL methods we used are each representative. ABAvg and FedFTG are similar to FedAvg in local training, but the former only performs weight adjustment on the server side, while the latter uses knowledge distillation to fine-tune the server. FedProx and FedGen are similar to FedAvg in the server side, but the former only has regularization constraints on local training, while the latter uses the generator for regularization adjustment in local training. As is demonstrated in Table 2, we can see that, regardless of the FL method chosen, our low precision FL algorithm has a significant improvement in prediction accuracy compared to the original FL method, especially in dataset CIFAR10, CINIC10 and CIFAR100. ", "page_idx": 7}, {"type": "text", "text": "Table 2: The results of our method when integrated with existing FL methods ABAvg, FedProx, FedGen and FedFTG. Our method can improve the effectiveness of FL with a certain training cost, and can be applied in both regularization and distillation. The complete result is given in Table 4. It shows that integrated with our low precision training technique, these existing methods with the precision of 8 bits can match (or even better than) the performance with full precision. ", "page_idx": 8}, {"type": "table", "img_path": "vvpewjtnvm/tmp/2946ddbb5e8cfa57bf5fc28a5a90ac86d822b6fb5c0bfc687d324b788da315b6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "6.4 Ablation Study ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Moving Average. We conduct ablation study to validate the effectiveness of the moving average for the server, from Table 1, the average operation has a significant effect on the server performance over various settings. It is consistent of our expectation that averaging can alleviate the error introduced by quantization and the error by heterogeneity. ", "page_idx": 8}, {"type": "text", "text": "Architecture Generalization. We use another network structure, MLP, to verify that our method can be applied to other networks. The MLP was set to 3 layers, with the hidden dimension of each layer being 128, and experiments were conducted on FashionMNIST with $\\alpha$ of 0.01 and 0.04. From Table 3, our method can still maintain the accuracy, which also demonstrates its generalization ability on other network structures. ", "page_idx": 8}, {"type": "table", "img_path": "vvpewjtnvm/tmp/eb850f00ba6c585a39e1053f9682f8aa0e5aed545f41031db1d91c819c939a63.jpg", "table_caption": ["Table 3: To display our method can generalize to other architectures, the same experiments were also performed on the MLP, using the FashionMNIST, setting $\\alpha=0.01$ and $\\alpha=0.04$ . Through comparison, it is found that the accuracy under MLP is slightly lower than that of ConvNet. However, our method can still maintain or improve the accuracy on MLP. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "6.5 Versus Efficient FL Method ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In order to demonstrate that our method can effectively reduce computational costs and memory consumption, we compared it with two personalized model compression FL algorithms. HeteroFL [9] and Split-Mix [14] can both achieve the purpose of reducing training overhead by using smaller models for local training. We use the ConvNet with the same hidden dimension to conduct experiments, using CIFAR10 in the process, $\\alpha=0.01$ . SplitMix uses a split ratio of 1/8 by default. We re-tested at a split ratio of 1/16 to achieve the same compression ratio as HeteroFL. In Figure 3a, the vertical dotted line indicates the compression ratio of HeteroFL, more details are in the Appendix E. Compared with methods that directly compress model parameters, our method can achieve higher accuracy with lower memory consumption. Because quantization does not bring about the deletion of model parameters, there will be no aggregation problems when the model compression rate is too high. ", "page_idx": 8}, {"type": "image", "img_path": "vvpewjtnvm/tmp/7ed1bad0059c4d059d88eeb180e97a3fd5c75c49194a3dd78aa499a48bd09088.jpg", "img_caption": ["(a) Training cost Versus Acc. ", "(b) Results on CIFAR10 with $\\alpha=0.01$ . "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Figure 3: Results on CIFAR10 with $\\alpha=0.01$ . ( ) denotes the percentage of models on the clients. We use the number of weights, activation, and gradients of local training to approximate the training cost (MB / client) and communication cost (MB / round). ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we propose an efficient FL paradigm, where the local models in the clients are trained with low-precision operations and communicated with the server in low precision format, while only the model aggregation in the server is performed with high-precision computation. We theoretically show that our proposed paradigm can converge to the optimal solution as the training goes on, which demonstrates that low precision local training is enough for FL. Our paradigm can be integrated with existing FL algorithms flexibly. Experiments across extensive benchmarks are conducted to showcase the effectiveness of our proposed method. As a by-product, we show that low precision local training can relieve the over-fitting issue in local training. ", "page_idx": 9}, {"type": "text", "text": "8 Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Authors acknowledge the support in part by The National Nature Science Foundation of China grant No: 62472097, The National Nature Science Foundation of China grant No: 62273303, Yongjiang Talent Introduction Programme grant No: 2022A-240-G. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Durmus Alp Emre Acar, Yue Zhao, Ramon Matas, Matthew Mattina, Paul Whatmough, and Venkatesh Saligrama. Federated learning based on dynamic regularization. In International Conference on Learning Representations (ICLR 2021), 2021.   \n[2] Naman Agarwal, Ananda Theertha Suresh, Felix Xinnan X Yu, Sanjiv Kumar, and Brendan McMahan. cpsgd: Communication-efficient and differentially-private distributed sgd. Advances in Neural Information Processing Systems, 31, 2018.   \n[3] Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chlo\u00e9 Kiddon, Jakub Kone\u02c7cn\u00fd, Stefano Mazzocchi, Brendan McMahan, Timon Van Overveldt, David Petrou, Daniel Ramage, and Jason Roselander. Towards federated learning at scale: System design. In A. Talwalkar, V. Smith, and M. Zaharia, editors, Proceedings of Machine Learning and Systems, volume 1, pages 374\u2013388, 2019.   \n[4] Daoyuan Chen, Liuyi Yao, Dawei Gao, Bolin Ding, and Yaliang Li. Efficient personalized federated learning via sparse model-adaptation. In International Conference on Machine Learning, pages 5234\u20135256. PMLR, 2023.   \n[5] Hong-You Chen and Wei-Lun Chao. Fedbe: Making bayesian model ensemble applicable to federated learning. In International Conference on Learning Representations (ICLR 2021), 2021.   \n[6] Yae Jee Cho, Andre Manoel, Gauri Joshi, Robert Sim, and Dimitrios Dimitriadis. Heterogeneous ensemble knowledge transfer for training large models in federated learning. In Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence (IJCAI) Main Track, 2022.   \n[7] Liam Collins, Hamed Hassani, Aryan Mokhtari, and Sanjay Shakkottai. Exploiting shared representations for personalized federated learning. In International conference on machine learning, pages 2089\u20132099. PMLR, 2021.   \n[8] Luke N Darlow, Elliot J Crowley, Antreas Antoniou, and Amos J Storkey. Cinic-10 is not imagenet or cifar-10. arXiv preprint arXiv:1810.03505, 2018.   \n[9] Enmao Diao, Jie Ding, and Vahid Tarokh. Heterofl: Computation and communication efficient federated learning for heterogeneous clients. In International Conference on Learning Representations (ICLR 2021), 2021.   \n[10] Rick Durrett. Probability: theory and examples, volume 49. Cambridge university press, 2019.   \n[11] Neel Guha, Ameet Talwalkar, and Virginia Smith. One-shot federated learning. arXiv: Learning,arXiv: Learning, Feb 2019.   \n[12] Farzin Haddadpour, Mohammad Mahdi Kamani, Aryan Mokhtari, and Mehrdad Mahdavi. Federated learning with compression: Unified analysis and sharp guarantees. In International Conference on Artificial Intelligence and Statistics, pages 2350\u20132358. PMLR, 2021.   \n[13] Jenny Hamer, Mehryar Mohri, and Ananda Theertha Suresh. Fedboost: A communicationefficient algorithm for federated learning. In International Conference on Machine Learning, pages 3973\u20133983. PMLR, 2020.   \n[14] Junyuan Hong, Haotao Wang, Zhangyang Wang, and Jiayu Zhou. Efficient split-mix federated learning for on-demand and in-situ customization. In International Conference on Learning Representations (ICLR 2022), 2022.   \n[15] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aur\u00e9lien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances and open problems in federated learning. Foundations and trends\u00ae in machine learning, 14(1\u20132):1\u2013210, 2021.   \n[16] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank J Reddi, Sebastian U Stich, and Ananda Theertha Suresh. Scaffold stochastic controlled averaging for federated learning. In International Conference On Machine Learning, Vol 119, volume 119. JMLR-JOURNAL MACHINE LEARNING RESEARCH, 2020.   \n[17] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR 2015), 2015.   \n[18] Jakub Kone\u02c7cn\u00fd, H.Brendan McMahan, FelixX. Yu, Peter Richt\u00e1rik, AnandaTheertha Suresh, and Dave Bacon. Federated learning: Strategies for improving communication efficiency. arXiv: Learning,arXiv: Learning, Oct 2016.   \n[19] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.   \n[20] Ang Li, Jingwei Sun, Xiao Zeng, Mi Zhang, Hai Li, and Yiran Chen. Fedmask: Joint computation and communication-efficient personalized federated learning via heterogeneous masking. In Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems, pages 42\u201355, 2021.   \n[21] Qinbin Li, Bingsheng He, and Dawn Song. Model-contrastive federated learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10713\u201310722, 2021.   \n[22] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated optimization in heterogeneous networks. Proceedings of Machine learning and systems, 2:429\u2013450, 2020.   \n[23] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of fedavg on non-iid data. In International Conference on Learning Representations (ICLR 2020), 2020.   \n[24] Tao Lin, Lingjing Kong, Sebastian U Stich, and Martin Jaggi. Ensemble distillation for robust model fusion in federated learning. Advances in Neural Information Processing Systems, 33:2351\u20132363, 2020.   \n[25] Yishay Mansour, Mehryar Mohri, Jae Ro, and AnandaTheertha Suresh. Three approaches for personalization with applications to federated learning. Cornell University - arXiv,Cornell University - arXiv, Feb 2020.   \n[26] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273\u20131282. PMLR, 2017.   \n[27] Renjie Pi, Weizhong Zhang, Yueqi Xie, Jiahui Gao, Xiaoyu Wang, Sunghun Kim, and Qifeng Chen. Dynafed: Tackling client data heterogeneity with global dynamics. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12177\u201312186, 2023.   \n[28] Daniel Rothchild, Ashwinee Panda, Enayat Ullah, Nikita Ivkin, Ion Stoica, Vladimir Braverman, Joseph Gonzalez, and Raman Arora. Fetchsgd: Communication-efficient federated learning with sketching. In International Conference on Machine Learning, pages 8253\u20138265. PMLR, 2020.   \n[29] Sebastian U Stich. Local sgd converges fast and communicates little. In International Conference on Learning Representations (ICLR 2019), 2019.   \n[30] Sebastian U Stich, Jean-Baptiste Cordonnier, and Martin Jaggi. Sparsified sgd with memory. Advances in neural information processing systems, 31, 2018.   \n[31] Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H Vincent Poor. Tackling the objective inconsistency problem in heterogeneous federated optimization. Advances in neural information processing systems, 33:7611\u20137623, 2020.   \n[32] Naigang Wang, Jungwook Choi, Daniel Brand, Chia-Yu Chen, and Kailash Gopalakrishnan. Training deep neural networks with 8-bit floating point numbers. Advances in neural information processing systems, 31, 2018.   \n[33] Tianchun Wang, Wei Cheng, Dongsheng Luo, Wenchao Yu, Jingchao Ni, Liang Tong, Haifeng Chen, and Xiang Zhang. Personalized federated learning via heterogeneous modular networks. In 2022 IEEE International Conference on Data Mining (ICDM), pages 1197\u20131202. IEEE, 2022.   \n[34] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.   \n[35] Jianhang Xiao, Chunhui Du, Zijing Duan, and Wei Guo. A novel server-side aggregation strategy for federated learning in non-iid situations. In 2021 20th international symposium on parallel and distributed computing (ISPDC), pages 17\u201324. IEEE, 2021.   \n[36] Yueqi Xie, Weizhong Zhang, Renjie Pi, Fangzhao Wu, Qifeng Chen, Xing Xie, and Sunghun Kim. Robust federated learning against both data heterogeneity and poisoning attack via aggregation optimization. arXiv preprint arXiv:2211.05554, 2022.   \n[37] Guandao Yang, Tianyi Zhang, Polina Kirichenko, Junwen Bai, Andrew Gordon Wilson, and Chris De Sa. Swalp: Stochastic weight averaging in low precision training. In International Conference on Machine Learning, pages 7015\u20137024. PMLR, 2019.   \n[38] Yousef Yeganeh, Azade Farshad, Nassir Navab, and Shadi Albarqouni. Inverse distance aggregation for federated learning with non-iid data. In Domain Adaptation and Representation Transfer, and Distributed and Collaborative Learning: Second MICCAI Workshop, DART 2020, and First MICCAI Workshop, DCL 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4\u20138, 2020, Proceedings 2, pages 150\u2013159. Springer, 2020.   \n[39] Hao Yu, Sen Yang, and Shenghuo Zhu. Parallel restarted sgd with faster convergence and less communication: Demystifying why model averaging works for deep learning. In Proceedings of the AAAI conference on artificial intelligence, volume 33, pages 5693\u20135700, 2019.   \n[40] Lin Zhang, Li Shen, Liang Ding, Dacheng Tao, and Ling-Yu Duan. Fine-tuning global model via data-free knowledge distillation for non-iid federated learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10174\u201310183, 2022.   \n[41] Yuchen Zhang, Martin J Wainwright, and John C Duchi. Communication-efficient algorithms for statistical optimization. Advances in neural information processing systems, 25, 2012.   \n[42] Zhuangdi Zhu, Junyuan Hong, and Jiayu Zhou. Data-free knowledge distillation for heterogeneous federated learning. In International conference on machine learning, pages 12878\u201312889. PMLR, 2021. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "This appendix can be divided into several parts. To be precise: ", "page_idx": 13}, {"type": "text", "text": "\u2022 Section A gives the detailed proof for Theorem 1.   \n\u2022 Section B gives the detailed proof for Theorem 2. Compared to Theorem 1, Theorem 2 assumes that only a subset of client devices participate in the training, which is more in line with real-world scenarios.   \n\u2022 Section C introduce four FL methods\u2019(ABAvg, FedProx, FedGen, FedFTG) hyperparameters setting in our experiments.   \n\u2022 Section D provides detailed experiment results of four FL methods(ABAvg, FedProx, FedGen, FedFTG).   \n\u2022 Section E presents the comparsion between our low precision FL method and two efficient FL method in training overhead.   \n\u2022 Section F gives Limitation of this paper.   \n\u2022 Section G gives Broader Impacts of this paper. ", "page_idx": 13}, {"type": "text", "text": "A Proofs of Theorem 1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We analyze our low-precision federated learning algorithm in the setting of full device participation in this section. For the sake of convenience in proving, let\u2019s take the value of $p_{k}$ to be $\\frac{1}{N}$ , disregard the moving average, assume that quantization is only applied to model parameters and quantization gap is always $\\delta$ . Let $\\mathcal{Z}_{E}$ be a set composed of the sequence number of global aggregation steps, i.e., ${\\mathcal{T}}_{E}=\\{n E|n=1,2,\\cdots\\}$ . Suppose the model weights are updated as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbf{v}_{t+1}^{k}=Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k};\\xi_{t}^{k})).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbf{w}_{t+1}^{k}=\\left\\{\\begin{array}{l l}{\\mathbf{v}_{t+1}^{k}}&{\\mathrm{if~}t+1\\notin\\mathcal{T}_{E},}\\\\ {Q(\\frac{\\sum_{k=1}^{N}\\mathbf{v}_{t+1}^{k}}{N})}&{\\mathrm{if~}t+1\\in\\mathcal{T}_{E}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\mathbf{w}_{t}^{k}$ is an $d$ -dimensional vector, which represents the weight of the $k$ -th client device in step $t$ . $F_{k}$ represents the objective function of the $k$ -th device. $N$ is the total number of clients device participating in the training, and $T$ is the total number of steps trained, $\\xi_{t}^{k}$ represents a batch of data randomly sampled from the $k$ -th client device\u2019s local dataset $\\mathcal{D}_{k}$ in step $t$ , $\\nabla F_{k}(\\mathbf{w}_{t}^{k};\\xi_{t}^{k})$ is stochastic gradient, $\\eta_{t}$ represents learning rate, $Q$ represents the quantization function, and its formula has already been given in (4). ", "page_idx": 13}, {"type": "text", "text": "Notations. To further simplify our proof process, we introduce the following additional definitions: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\bar{\\mathbf{w}}_{0}=\\mathbf{w}_{0},\\bar{\\mathbf{w}}_{t}=\\frac{1}{N}\\sum_{k=1}^{N}\\mathbf{w}_{t}^{k},\\bar{\\mathbf{v}}_{t}=\\frac{1}{N}\\sum_{k=1}^{N}\\mathbf{v}_{t}^{k},\\bar{\\mathbf{g}}_{t}=\\frac{1}{N}\\sum_{k=1}^{N}\\nabla F_{k}(\\mathbf{w}_{t}^{k}),\\mathbf{g}_{t}=\\frac{1}{N}\\sum_{k=1}^{N}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "${\\bf w}_{t}$ represents the weight of the global model in step $t$ . Obviously, we can deduce $\\mathbb{E}\\mathbf{g}_{t}=\\bar{\\mathbf{g}}_{t}$ and $\\bar{\\mathbf{v}}_{t+1}=\\bar{\\mathbf{w}}_{t}-\\eta_{t}\\mathbf{g}_{t}$ . ", "page_idx": 13}, {"type": "text", "text": "Lemma 1. If $w$ is a scalar and can be written as $w=\\tilde{w}+b\\delta$ , satisfying $-\\delta\\,<\\,\\tilde{w}\\,<\\,\\delta,$ , \u03b4 is the quantization gap, represents the distance between successive representable fixed-point numbers, then we have: ", "page_idx": 13}, {"type": "equation", "text": "$$\nQ(w)-w=\\left\\{\\overset{-\\tilde{w},}{\\operatorname{\\mathit{\\sigma}-\\tilde{w}}(\\tilde{w})\\delta-\\tilde{w},}\\right.\\,\\left.w.p.\\quad1-s i g n(\\tilde{w})\\frac{\\tilde{w}}{\\delta},\\right.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $Q(\\cdot)$ is quantization function. And we always can find a suitable $\\tilde{w}$ that satisfies $|\\tilde{w}|\\leq|w|$ . ", "page_idx": 13}, {"type": "text", "text": "Proof. The quantization function is: ", "page_idx": 13}, {"type": "equation", "text": "$$\nQ(w)=\\bigg\\{\\!\\!\\begin{array}{l l}{\\displaystyle c l i p(\\delta\\big\\lfloor\\frac{w}{\\delta}\\big\\rfloor,l,u),\\quad}&{w.p.\\quad\\,\\,\\big\\lceil\\frac{w}{\\delta}\\big\\rceil-\\frac{w}{\\delta},}\\\\ {\\displaystyle c l i p(\\delta\\big\\lceil\\frac{w}{\\delta}\\big\\rceil,l,u),\\quad}&{w.p.\\quad1-\\big\\lceil\\frac{w}{\\delta}\\big\\rceil+\\frac{w}{\\delta}.}\\end{array}\\!\\!\\bigg\\}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "When $\\tilde{w}>0$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\nQ(w)-w=\\left\\{-\\tilde{w},\\qquad w.p.\\ \\ 1-\\frac{\\tilde{w}}{\\delta},\\right.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "When $\\tilde{w}<0$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\nQ(w)-w=\\left\\{-\\delta-\\tilde{w},\\begin{array}{l l}{w.p.}&{-\\frac{\\tilde{w}}{\\delta},}\\\\ {-\\tilde{w},}&{w.p.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "So we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\nQ(w)-w=\\left\\{\\overset{-\\tilde{w},}{\\mathop{s i g n}}(\\tilde{w})\\delta-\\tilde{w},\\begin{array}{l}{w.p.}\\end{array}}1-s i g n(\\tilde{w})\\frac{\\tilde{w}}{\\delta},\\right.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Next we prove that we always can find a suitable $\\tilde{w}$ that satisfies $|\\tilde{w}|\\leq|w|$ . When $w\\ge\\delta$ ,we can choose a $\\tilde{w}$ satisfying $\\tilde{w}\\,\\geq\\,0$ , then we can have $|\\tilde{w}|\\leq|w|$ . When $w\\,\\leq\\,-\\delta$ , we can choose a $\\tilde{w}$ satisfying $\\tilde{w}\\leq0$ , then we also can have $|\\tilde{w}|\\leq|w|$ . When $-\\delta<w<\\delta$ , we can choose a $\\tilde{w}$ satisfying $\\tilde{w}=w$ , then we also can have $|\\tilde{w}|\\leq|w|$ . In summary, we always can find a suitable $\\tilde{w}$ that satisfies $|\\tilde{w}|\\leq|w|$ . \u53e3 ", "page_idx": 14}, {"type": "text", "text": "Discussion. In the lemma 2 below, we analyze the convergence of the algorithm under the condition that $\\delta^{2}\\leq\\eta_{t}^{2}G^{2}$ , where $G^{2}$ is given in assumption 2 and represents the constraint on the expected value of the squared two-norm of the stochastic gradient. The right side of the inequality indicates the change in the iterative parameters during the gradient descent process, that is, the size of the gradient multiplied by the size of the learning rate. If the magnitude of this value is already less than the quantization precision, it will cause the gradient descent to fail, and the model parameters will not continue to change. In this case, it makes no sense to continue optimization, so analyzing convergence under this condition is practical. ", "page_idx": 14}, {"type": "text", "text": "Lemma 2. We assume that $\\begin{array}{r}{\\eta_{t}\\leq\\frac{1}{4L}}\\end{array}$ , based on assumption 1 and 2, when t satisfying $\\delta^{2}\\leq\\eta_{t}^{2}G^{2}$ we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t+1}-\\mathbf{w}^{*}\\right\\|_{2}^{2}\\leq2(\\sqrt{d}\\delta+1+\\frac{d}{2})\\eta_{t}^{2}G^{2}+(1-\\eta_{t}\\mu)\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}^{*}\\right\\|_{2}^{2}+6L\\eta_{t}^{2}\\Gamma}\\\\ {\\displaystyle+\\frac{2}{N}\\sum_{K=1}^{N}\\left\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}_{t}^{k}\\right\\|_{2}^{2}+\\mathbb{E}\\eta_{t}^{2}\\left\\|\\mathbf{g}_{t}-\\bar{\\mathbf{g}}_{t}\\right\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Proof. When $t+1\\notin\\mathcal{T}_{E}$ , we can easily derive that $\\bar{\\bf w}_{t+1}=\\bar{\\bf v}_{t+1}$ . So we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\|\\bar{\\mathbf{v}}_{t+1}-\\mathbf{w}^{*}\\|_{2}^{2}}\\\\ &{=\\|\\bar{\\mathbf{v}}_{t+1}-\\mathbf{w}^{*}\\|_{2}^{2}}\\\\ &{=\\left\\|\\displaystyle\\frac{1}{N}\\sum_{k=1}^{N}Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))-\\mathbf{w}^{*}\\right\\|_{2}^{2}}\\\\ &{=\\left\\|\\displaystyle\\bar{\\mathbf{w}}_{t}-\\eta_{t}\\mathbf{g}_{t}-\\mathbf{w}^{*}+\\frac{1}{N}\\sum_{k=1}^{N}Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))-\\frac{1}{N}\\sum_{k=1}^{N}\\left(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})\\right)\\right\\|_{2}^{2}}\\\\ &{=\\left\\|\\displaystyle\\frac{|\\bar{\\mathbf{w}}_{t}-\\eta_{t}\\mathbf{g}_{t}-\\mathbf{w}^{*}|_{2}^{2}}{A_{1}}+\\left\\|\\frac{1}{N}\\sum_{k=1}^{N}\\left(Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))-(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))\\right)\\right\\|_{2}^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "equation", "text": "$$\n+\\left.2\\langle\\overline{{\\mathbf{w}}}_{t}-\\eta_{t}\\mathbf{g}_{t}-\\mathbf{w}^{*},\\frac{1}{N}\\sum_{k=1}^{N}\\left(Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))-(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))\\right)\\rangle\\right..\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "$\\langle\\cdot\\rangle$ represents inner product operation. Due to $\\mathbb{E}Q(x)=x$ , according to the Law of iterated expectations, $\\mathbb{E}A_{3}=0$ . Next we aim to bound $A_{2}$ . $\\mathbb{E}A_{2}$ is: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}\\bigg\\|\\displaystyle\\frac{1}{N}\\sum_{k=1}^{N}(Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))-(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})))\\bigg\\|_{2}^{2}}\\\\ &{=\\displaystyle\\frac{1}{N^{2}}\\sum_{k=1}^{N}\\mathbb{E}(\\|Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))-(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))\\|_{2}^{2}}\\\\ &{\\quad+\\displaystyle\\frac{1}{N^{2}}\\sum_{k\\neq k_{2}}\\mathbb{E}(Q(\\mathbf{w}_{t}^{k_{1}}-\\eta_{t}\\nabla F_{k_{1}}(\\mathbf{w}_{t}^{k_{1}},\\xi_{t}^{k_{1}}))-(\\mathbf{w}_{t}^{k_{1}}-\\eta_{t}\\nabla F_{k_{1}}(\\mathbf{w}_{t}^{k_{1}},\\xi_{t}^{k_{1}})),}\\\\ &{\\quad Q(\\mathbf{w}_{t}^{k_{2}}-\\eta_{t}\\nabla F_{k_{2}}(\\mathbf{w}_{t}^{k_{2}},\\xi_{t}^{k_{2}}))-(\\mathbf{w}_{t}^{k_{2}}-\\eta_{t}\\nabla F_{k_{2}}(\\mathbf{w}_{t}^{k_{2}},\\xi_{t}^{k_{2}})))}\\\\ &{=\\displaystyle\\frac{1}{N^{2}}\\sum_{k=1}^{N}\\mathbb{E}\\left\\|Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))-(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))\\right\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "In the above equation, we used the law of iterated expectations. ", "page_idx": 15}, {"type": "text", "text": "The quantization function is: ", "page_idx": 15}, {"type": "equation", "text": "$$\nQ(w)=\\bigg\\{\\!\\!\\begin{array}{l l}{\\displaystyle c l i p(\\delta\\big\\lfloor\\frac{w}{\\delta}\\big\\rfloor,l,u),\\quad}&{w.p.\\quad\\,\\,\\big\\lceil\\frac{w}{\\delta}\\big\\rceil-\\frac{w}{\\delta},}\\\\ {\\displaystyle c l i p(\\delta\\big\\lceil\\frac{w}{\\delta}\\big\\rceil,l,u),\\quad}&{w.p.\\quad1-\\big\\lceil\\frac{w}{\\delta}\\big\\rceil+\\frac{w}{\\delta}.}\\end{array}\\!\\!\\bigg\\}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "$\\mathbf{w}_{t}^{k}$ is a quantified vector, therefore, its $\\mathbf{p}$ -th component $(\\mathbf{w}_{t}^{k})_{p}\\,=\\,c\\,\\delta$ , $\\mathrm{^c}$ is an integer. We rewrite $\\left[\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})\\right]_{p}=b\\delta+\\tilde{w}$ . Where b is an integer and $|\\tilde{w}|\\leq|w|$ . So that we can have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad[Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))-(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))]_{p}}\\\\ &{=\\displaystyle\\left\\{-s i g n(\\tilde{w})\\delta+\\tilde{w}\\quad w.p.\\quad\\frac{s i g n(\\tilde{w})\\tilde{w}}{\\delta},\\right.}\\\\ &{\\qquad\\qquad\\tilde{w}\\quad\\qquad w.p.\\ \\left.1-\\frac{s i g n(\\tilde{w})\\tilde{w}}{\\delta}.\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The expectation after the square is: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}[Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))-\\left(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})\\right)]_{p}^{2}}\\\\ &{=\\tilde{w}^{2}\\left[1-\\frac{s i g n\\left(\\tilde{w}\\right)\\tilde{w}}{\\delta}\\right]+\\left[-s i g n(\\tilde{w})\\delta+\\tilde{w}\\right]^{2}\\frac{s i g n\\left(\\tilde{w}\\right)\\tilde{w}}{\\delta}}\\\\ &{\\leq2\\tilde{w}^{2}+2\\delta\\left|\\tilde{w}\\right|}\\\\ &{\\leq2\\left[\\eta_{t}\\nabla F_{k}\\big(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}\\big)\\right]_{p}^{2}+2\\delta\\left|\\left[\\eta_{t}\\nabla F_{k}\\big(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}\\big)\\right]_{p}\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The expectation of $\\big\\|Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))-\\big(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})\\big)\\big\\|_{2}^{2}$ is: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}\\big\\|Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))-\\big(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})\\big)\\big\\|_{2}^{2}}\\\\ &{=\\mathbb{E}(\\mathbb{E}\\big\\|Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))-\\big(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})\\big)\\big\\|_{2}^{2})}\\\\ &{\\leq2\\eta_{t}\\delta\\mathbb{E}\\left\\|\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})\\big)\\right\\|_{1}+2\\eta_{t}^{2}\\mathbb{E}\\big\\|\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})\\big)\\big\\|_{2}^{2}}\\\\ &{=2\\delta\\mathbb{E}\\left\\|\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})\\right\\|_{1}+2\\eta_{t}^{2}\\mathbb{E}\\big\\|\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})\\big)\\big\\|_{2}^{2}}\\\\ &{\\leq2\\sqrt{d}\\delta\\eta_{t}^{2}\\mathbb{E}\\big\\|\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})\\big)\\big\\|_{2}^{2}+2\\eta_{t}^{2}\\mathbb{E}\\big\\|\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})\\big)\\big\\|_{2}^{2}}\\\\ &{=2(\\sqrt{d}\\delta+1)\\eta_{t}^{2}\\mathbb{E}\\big\\|\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})\\big)\\big\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "In the above inequality, we use the inequality $\\left\\|\\cdot\\right\\|_{1}\\leq\\sqrt{d}\\left\\|\\cdot\\right\\|_{2}^{2}$ , $d$ is the dimension of the vector. According to assumption 2 we can get: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{{\\mathbb{E}}\\|\\bar{\\mathbf{w}}_{t+1}-\\mathbf{w}^{*}\\|_{2}^{2}\\leq2(\\sqrt{d}\\delta+1){\\eta_{t}}^{2}G^{2}+{\\mathbb{E}}\\|\\bar{\\mathbf{w}}_{t}-\\eta_{t}\\mathbf{g}_{t}-\\mathbf{w}^{*}\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "We next aim to bound $A_{1}$ : ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\left\\|\\bar{\\mathbf{w}}_{t}-\\eta_{t}\\mathbf{g}_{t}-\\mathbf{w}^{*}\\right\\|_{2}^{2}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\left\\|\\bar{\\mathbf{w}}_{t}-\\eta_{t}\\mathbf{g}_{t}-\\mathbf{w}^{*}-\\eta_{t}\\bar{\\mathbf{g}}_{t}+\\eta_{t}\\bar{\\mathbf{g}}_{t}\\right\\|_{2}^{2}}\\\\ &{=\\underbrace{\\left\\|\\bar{\\mathbf{w}}_{t}-\\eta_{t}\\bar{\\mathbf{g}}_{t}-\\mathbf{w}^{*}\\right\\|_{2}^{2}}_{B_{1}}+\\underbrace{\\eta_{t}^{2}\\left\\|\\mathbf{g}_{t}-\\bar{\\mathbf{g}}_{t}\\right\\|_{2}^{2}}_{B_{2}}+2\\underbrace{\\eta_{t}\\langle\\bar{\\mathbf{w}}_{t}-\\eta_{t}\\bar{\\mathbf{g}}_{t}-\\mathbf{w}^{*},\\mathbf{g}_{t}-\\bar{\\mathbf{g}}_{t}\\rangle}_{B_{3}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Obviously $\\mathbb{E}B_{3}=0$ , so we can get: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}\\|\\bar{\\mathbf{w}}_{t}-\\eta_{t}\\mathbf{g}_{t}-\\mathbf{w}^{*}\\|_{2}^{2}=\\mathbb{E}\\|\\bar{\\mathbf{w}}_{t}-\\eta_{t}\\bar{\\mathbf{g}}_{t}-\\mathbf{w}^{*}\\|_{2}^{2}+\\mathbb{E}\\eta_{t}{^2}\\|\\mathbf{g}_{t}-\\bar{\\mathbf{g}}_{t}\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We next aim to bound $B_{1}$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\|\\bar{\\mathbf{w}}_{t}-\\eta_{t}\\bar{\\mathbf{g}}_{t}-\\mathbf{w}^{*}\\|_{2}^{2}}\\\\ &{=\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}^{*}\\|_{2}^{2}+\\eta_{t}^{2}\\|\\bar{\\mathbf{g}}_{t}\\|_{2}^{2}-2\\eta_{t}\\langle\\bar{\\mathbf{w}}_{t}-\\mathbf{w}^{*},\\bar{\\mathbf{g}}_{t}\\rangle}\\\\ &{=\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}^{*}\\|_{2}^{2}+\\underbrace{\\eta_{t}^{2}\\|\\bar{\\mathbf{g}}_{t}\\|_{2}^{2}}_{C_{1}}\\underbrace{\\frac{-2\\eta_{t}}{N}\\frac{1}{k-1}\\langle\\bar{\\mathbf{w}}_{t}-\\mathbf{w}_{t}^{k},\\nabla F_{k}({\\mathbf{w}}_{t}^{k})\\rangle}_{C_{2}}}\\\\ &{\\quad-2\\eta_{t}\\frac{1}{N}\\displaystyle\\sum_{k=1}^{N}\\langle\\mathbf{w}_{t}^{k}-\\mathbf{w}^{*},\\nabla F_{k}({\\mathbf{w}}_{t}^{k})\\rangle}_{C_{3}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "To bound $C_{1},C_{2},C_{3}$ , we need to derive several inequalities using the properties of $F_{1},F_{2},\\cdots\\,,F_{N}$ . First of all, for $k=1,2,\\cdots\\,,N,F_{k}$ is a $L$ -smooth function, we can get: ", "page_idx": 16}, {"type": "equation", "text": "$$\nF_{k}^{\\;*}\\leq F_{k}(x)\\leq F_{k}(\\mathbf{w}_{t}^{k})+\\big\\langle\\nabla F_{k}(\\mathbf{w}_{t}^{k}),x-\\mathbf{w}_{t}^{k}\\big\\rangle+\\frac{L}{2}\\big\\|x-\\mathbf{w}_{t}^{k}\\big\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Specifically, when $x=\\mathbf{w}_{t}^{k}-a\\nabla F_{k}(\\mathbf{w}_{t}^{k})$ , we can get: ", "page_idx": 16}, {"type": "equation", "text": "$$\n{F_{k}}^{*}\\leq F_{k}(\\mathbf{w}_{t}^{k})+(\\frac{L}{2}{a}^{2}-a)\\big\\|\\nabla F_{k}(\\mathbf{w}_{t}^{k})-\\nabla F_{k}^{*}\\big\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "when $\\begin{array}{r}{a=\\frac{1}{L}}\\end{array}$ , we can get: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\nabla F_{k}(\\mathbf{w}_{t}^{k})-\\nabla F_{k}^{*}\\right\\|_{2}^{2}\\leq2L(F_{k}(\\mathbf{w}_{t}^{k})-F_{k}^{*}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "According to the above equation, we can get: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\eta^{2}\\|\\bar{\\mathbf{g}}_{t}\\|_{2}^{2}=\\eta_{t}^{2}\\Bigg\\|\\sum_{k=1}^{N}p_{k}\\nabla F_{k}(\\mathbf{w}_{t}^{k})\\Bigg\\|_{2}^{2}\\leq\\eta_{t}^{2}\\sum_{k=1}^{N}p_{k}\\big\\|\\nabla F_{k}(\\mathbf{w}_{t}^{k})\\big\\|_{2}^{2}\\leq2L\\eta_{t}^{2}\\sum_{k=1}^{N}p_{k}\\big(F_{k}(\\mathbf{w}_{t}^{k})-F_{k}^{\\;*}\\big).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "In the inequality above, we have utilized inequality (16) and the property that $\\left\\|\\cdot\\right\\|_{2}^{2}$ is a convex function. ", "page_idx": 16}, {"type": "text", "text": "For $k=1,2,\\cdots\\,,N,F_{k}$ is a $\\mu$ -strong function, so we can get: ", "page_idx": 16}, {"type": "equation", "text": "$$\n-\\langle\\mathbf{w}_{t}^{k}-\\mathbf{w}^{*},\\nabla F_{k}(\\mathbf{w}_{t}^{k})\\rangle\\leq-(F_{k}(\\mathbf{w}_{t}^{k})-F_{k}(\\mathbf{w}^{*}))-\\frac{\\mu}{2}\\|\\mathbf{w}_{t}^{k}-\\mathbf{w}^{*}\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "By the inequality: ", "page_idx": 16}, {"type": "equation", "text": "$$\n2\\left<a,b\\right>\\leq\\gamma\\|a\\|_{2}^{2}+\\gamma^{-1}\\|b\\|_{2}^{2},(\\gamma>0).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "we can get: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle-2\\left\\langle\\bar{\\mathbf{w}}_{t}-\\mathbf{w}_{t}^{k},\\nabla F_{k}(\\mathbf{w}_{t}^{k})\\right\\rangle\\leq\\frac{1}{\\eta_{t}}\\big\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}_{t}^{k}\\big\\|_{2}^{2}+\\eta_{t}\\big\\|\\nabla F_{k}(\\mathbf{w}_{t}^{k})\\big\\|_{2}^{2}}\\\\ &{\\displaystyle\\qquad\\qquad\\qquad\\leq\\frac{1}{\\eta_{t}}\\big\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}_{t}^{k}\\big\\|_{2}^{2}+2L\\big(F_{k}(\\mathbf{w}_{t}^{k})-F_{k}^{*}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "In the inequality above, we have utilized inequality (16) again. Now, we can use inequality (16), (17), (18), (20) to bound $C_{1},C_{2},C_{3}$ to bound $B_{1}$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\left|\\right|\\bar{\\mathbf{w}}_{t}-\\eta_{t}\\bar{\\mathbf{g}}_{t}-\\mathbf{w}^{*}\\right|\\right|_{2}^{2}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=[w_{1},\\cdots w_{1}^{\\prime\\prime}]_{2}+w_{2}^{\\prime\\prime}]_{1}[w_{1},\\cdots,w_{2},\\cdots,w_{3}]}\\\\ &{=[w_{1},\\cdots w_{1}^{\\prime\\prime}]_{2}+w_{3}^{\\prime}[\\alpha_{1},\\cdots,\\gamma_{1}(\\alpha_{1},\\cdots,w_{4}),}\\\\ &{\\qquad\\quad+[w_{1},\\cdots w_{1}^{\\prime\\prime}]_{2}+(2\\alpha_{1})\\sum_{i=1}^{N}\\sum_{\\ell=1}^{N}w_{i}\\,,}\\\\ &{\\qquad\\quad+[w_{1},\\cdots w_{1}^{\\prime\\prime}]_{2}+2[\\alpha_{1},\\sum_{i=1}^{N}(F_{i}(w_{1}^{\\prime})-F_{i}(w_{1}^{\\prime}))}\\\\ &{\\qquad\\quad-2\\mathfrak{h}_{1}\\sum_{i=1}^{N}\\sum_{\\ell=1}^{N}\\sum_{\\ell=1}^{N}\\alpha_{i}\\mathfrak{h}_{i}\\left(w_{1}^{\\prime}\\right)+2\\mathfrak{h}_{2}\\sum_{i=1}^{N}w_{i}\\,,\\cdots\\,\\mathfrak{h}_{N}(w_{1}^{\\prime})}\\\\ &{\\qquad\\quad-[w_{1},\\cdots w_{1}^{\\prime\\prime}]_{2}+4\\mathfrak{h}_{3}\\sum_{i=1}^{N}[\\alpha_{1}(w_{1}^{\\prime})-F_{i}(w_{1}^{\\prime})+\\sum_{i=1}^{N}\\sum_{i=1}^{N}|w_{i}-w_{1}^{\\prime}|_{2}^{2}}\\\\ &{\\qquad\\quad-2\\mathfrak{h}_{3}\\sum_{i=1}^{N}(F_{i}(w_{1}^{\\prime})-F_{i}(w_{1}^{\\prime}))-9w_{1}\\frac{\\sqrt{3}}{2}\\sum_{i=1}^{N}|w_{i}-w_{1}^{\\prime}|_{2}^{2}}\\\\ &{\\qquad\\quad+[w_{1},\\cdots w_{1}^{\\prime\\prime}]_{2}+4\\mathfrak{h}_{3}\\sum_{i=1}^{N}[\\alpha_{1}(w_{1}^{\\prime})-F_{i}(w_{1}^{\\prime})+\\frac{1}{2}\\sum_{i=1}^{\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We set $\\gamma_{t}=2\\eta_{t}\\big(1-2L\\eta_{t}\\big)$ , because $\\begin{array}{r}{\\eta_{t}\\leq\\frac{1}{4L}}\\end{array}$ , so $\\eta_{t}\\le\\gamma_{t}\\le2\\eta_{t}$ . Decompose $D$ we can get: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle{\\cal D}=4L\\eta_{t}^{2}\\displaystyle\\sum_{k=1}^{N}p_{k}(F_{k}({\\mathbf w}_{t}^{k})-F_{k}^{\\star})-2\\eta_{t}\\displaystyle\\frac{1}{N}\\displaystyle\\sum_{k=1}^{N}(F_{k}({\\mathbf w}_{t}^{k})-F_{k}({\\mathbf w}^{\\star}))}\\\\ {\\displaystyle}\\\\ {\\displaystyle~~=(4L\\eta^{2}-2\\eta_{t})\\displaystyle\\sum_{k=1}^{N}p_{k}F_{k}({\\mathbf w}_{t}^{k})+4L\\eta_{t}^{2}\\displaystyle\\sum_{k=1}^{N}p_{k}F_{k}^{\\star}+2\\eta_{t}\\displaystyle\\frac{1}{N}\\displaystyle\\sum_{k=1}^{N}F_{k}({\\mathbf w}^{\\star})}\\\\ {\\displaystyle}\\\\ {\\displaystyle~~=-\\gamma_{t}\\displaystyle\\sum_{k=1}^{N}p_{k}F_{k}({\\mathbf w}_{t}^{k})+4L\\eta_{t}^{2}\\displaystyle\\sum_{k=1}^{N}p_{k}F_{k}^{\\star}+2\\eta_{t}F^{\\star}}\\\\ {\\displaystyle}\\\\ {\\displaystyle~~=-\\gamma_{t}\\displaystyle\\sum_{k=1}^{N}p_{k}(F_{k}({\\mathbf w}_{t}^{k})-F^{\\star})+(2\\eta_{t}-\\gamma_{t})\\displaystyle\\sum_{k=1}^{N}p_{k}(F^{\\star}-F_{k}^{\\star})}\\\\ {\\displaystyle}\\\\ {\\displaystyle~~=-\\gamma_{t}\\displaystyle\\sum_{k=1}^{N}p_{k}(F_{k}({\\mathbf w}_{t}^{k})-F^{\\star})+4L\\eta_{t}^{2}\\Gamma.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "It should be noted that $\\Gamma=\\sum_{k=1}^{N}p_{k}(F^{*}-F_{k}{}^{*})=F^{*}-\\sum_{k=1}^{N}{\\frac{1}{N}}{F_{k}}^{*}$ , and it measures the degree of data heterogeneity between different client devices.We can bound the first term in $D$ : ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{k=1}^{N}p_{k}(F_{k}(\\mathbf{w}_{t}^{k})-F^{*})}\\\\ {\\displaystyle=\\sum_{k=1}^{N}p_{k}(F_{k}(\\mathbf{w}_{t}^{k})-F_{k}(\\bar{\\mathbf{w}}_{t}))+\\displaystyle\\sum_{k=1}^{N}p_{k}(F_{k}(\\bar{\\mathbf{w}}_{t})-F^{*})}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\geq\\sum_{k=1}^{N}p_{k}\\left<\\nabla F_{k}(\\bar{\\mathbf w}_{t}),\\mathbf w_{t}^{k}-\\bar{\\mathbf w}_{t}\\right>+F(\\bar{\\mathbf w}_{t})-F^{*}}\\\\ {\\displaystyle\\geq-\\frac{1}{2}\\sum_{k=1}^{N}p_{k}[\\eta_{t}\\|\\nabla F_{k}(\\bar{\\mathbf w}_{t})\\|_{2}^{2}+\\frac{1}{\\eta_{t}}\\|\\mathbf w_{t}^{k}-\\bar{\\mathbf w}_{t}\\|_{2}^{2}]+F(\\bar{\\mathbf w}_{t})-F^{*}}\\\\ {\\displaystyle\\geq-\\sum_{k=1}^{N}p_{k}[\\eta_{t}L(F_{k}(\\bar{\\mathbf w}_{t})-F_{k}^{*})+\\frac{1}{2\\eta_{t}}\\|\\mathbf w_{t}^{k}-\\bar{\\mathbf w}_{t}\\|_{2}^{2}]+F(\\bar{\\mathbf w}_{t})-F^{*}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "In the above inequation, we use the inequations (16),(19) and the convexity of $F_{k}(\\cdot)$ . So we can bound $D$ and get: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D=-\\underset{k=1}{\\overset{N}{\\sum}}\\int_{\\mathbb{R}^{n}}(F_{k}(\\hat{\\mathbf{e}}_{i}^{k})-F^{*})+4L\\mu_{1}^{2}\\Gamma}\\\\ &{\\quad\\le\\operatorname*{min}\\frac{\\sum_{k=1}^{N}m_{k}(\\hat{\\mathbf{e}}_{k}^{k})-F_{k}^{*})+\\frac{1}{20}\\sum_{k=1}^{N}\\left\\{\\mathbf{e}_{k}^{k}-\\mathbf{e}_{k}^{k}\\mathbf{\\Bigg|}\\frac{2}{2}-\\gamma_{k}(F_{k}(\\hat{\\mathbf{e}}_{i})-F^{*})+4L\\mu_{1}^{2}\\Gamma\\right.}\\\\ &{\\quad\\left.-\\gamma_{k}L\\sum_{n}(F_{k}(\\hat{\\mathbf{e}}_{i})-F_{k}^{*})+\\frac{\\gamma_{n}}{20}\\sum_{k=1}^{N}\\mathbf{\\Bigg|}\\mathbf{e}_{k}^{n_{l}}-\\mathbf{e}_{k}^{k}\\mathbf{\\Bigg|}\\frac{2}{2}-\\gamma_{k}(F_{k}(\\hat{\\mathbf{e}}_{i})-F^{*})+4L\\mu_{1}^{2}\\Gamma\\right.}\\\\ &{\\quad\\left.-\\gamma_{k}L\\sum_{n}(F_{k}(\\hat{\\mathbf{e}}_{i})-F_{k}^{*})+\\frac{\\gamma_{n}}{20}\\sum_{k=1}^{N}\\mathbf{\\Bigg|}\\mathbf{e}_{k}^{n_{l}}-\\mathbf{e}_{k}^{k}\\mathbf{\\Bigg|}\\right.}\\\\ &{\\quad\\left.-\\gamma_{k}L\\sum_{n}^{N}P_{k}(\\hat{\\mathbf{e}}_{i}^{k})-\\gamma+F^{*}-F_{k}^{*}\\right)+\\frac{\\gamma_{n}}{20}\\sum_{k=1}^{N}\\mathbf{\\Bigg|}\\mathbf{e}_{k}^{n_{l}}-\\mathbf{e}_{k}^{k}\\mathbf{\\Bigg|}\\frac{2}{2}}\\\\ &{\\quad\\quad-\\gamma_{k}\\frac{N}{L}\\mathbf{\\Bigg|}\\mathbf{\\Bigg|}\\mathbf{\\Bigg|}\\mathbf{e}_{k}^{n_{l}}-\\mathbf{e}_{k}^{k}+4L\\mathbf{g}^{2}\\Gamma}\\\\ &{\\quad\\quad=\\gamma_{k}(\\theta_{1}-1)\\sum_{n=1}^{N}P_{k}(F_{k}(\\hat\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "When $t+1\\notin\\mathcal{T}_{E}$ , we can conclude that: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t+1}-\\mathbf{w}^{*}\\right\\|_{2}^{2}\\leq2(\\sqrt{d}\\delta+1)\\eta_{t}^{2}G^{2}+(1-\\eta_{t}\\mu)\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}^{*}\\right\\|_{2}^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\displaystyle\\frac{2}{N}\\sum_{K=1}^{N}\\left\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}_{t}^{k}\\right\\|_{2}^{2}+6L\\eta_{t}^{2}\\Gamma+\\mathbb{E}\\eta_{t}^{2}\\left\\|\\mathbf{g}_{t}-\\bar{\\mathbf{g}}_{t}\\right\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "When t + 1 \u2208IE, we have wtk+1 $\\begin{array}{r}{\\mathbf{w}_{t+1}^{k}=Q\\big(\\frac{\\sum_{}^{i\\vee}\\mathbf{v}_{t+1}^{k}}{N}\\big)}\\end{array}$ : ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\|\\mathbf{w}_{t+1}-\\mathbf{w}\\|_{2}}\\\\ &{=\\mathbb{E}\\left\\|Q(\\frac{1}{N}\\displaystyle\\sum_{k=1}^{N}\\mathbf{v}_{t+1}^{k})-\\mathbf{w}^{*}\\right\\|_{2}^{2}}\\\\ &{=\\mathbb{E}\\left\\|Q(\\frac{1}{N}\\displaystyle\\sum_{k=1}^{N}\\mathbf{v}_{t+1}^{k})-\\frac{1}{N}\\displaystyle\\sum_{k=1}^{N}\\mathbf{v}_{t+1}^{k}+\\frac{1}{N}\\displaystyle\\sum_{k=1}^{N}\\mathbf{v}_{t+1}^{k}-\\mathbf{w}^{*}\\right\\|_{2}^{2}}\\\\ &{=\\mathbb{E}\\left\\|Q(\\frac{1}{N}\\displaystyle\\sum_{k=1}^{N}\\mathbf{v}_{t+1}^{k})-\\frac{1}{N}\\displaystyle\\sum_{k=1}^{N}\\mathbf{v}_{t+1}^{k}+\\frac{1}{N}\\displaystyle\\sum_{k=1}^{N}Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))-\\mathbf{w}^{*}\\right\\|_{2}^{2}}\\\\ &{\\leq\\mathbb{E}\\left\\|Q(\\frac{1}{N}\\displaystyle\\sum_{k=1}^{N}\\mathbf{v}_{t+1}^{k})-\\frac{1}{N}\\displaystyle\\sum_{k=1}^{N}\\mathbf{v}_{t+1}^{k}\\right\\|_{2}^{2}+\\mathbb{E}\\left\\|\\frac{1}{N}\\displaystyle\\sum_{k=1}^{N}Q(\\mathbf{w}_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k}))-\\mathbf{w}^{*}\\right\\|_{2}^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n+\\,2\\mathbb{E}\\langle Q(\\frac{1}{N}\\sum_{k=1}^{N}\\mathbf v_{t+1}^{k})-\\frac{1}{N}\\sum_{k=1}^{N}\\mathbf v_{t+1}^{k},\\frac{1}{N}\\sum_{k=1}^{N}Q(\\mathbf w_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf w_{t}^{k},\\xi_{t}^{k}))-\\mathbf w^{*}\\rangle\\Big)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "$E_{2}$ has been given constraints in the text above that: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{E}_{2}\\leq2(\\sqrt{d}\\delta+1)\\eta_{t}^{2}G^{2}+(1-\\eta_{t}\\mu)\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}^{*}\\right\\|_{2}^{2}}}\\\\ {~~~~~~+\\frac{2}{N}\\displaystyle\\sum_{K=1}^{N}\\left\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}_{t}^{k}\\right\\|_{2}^{2}+6L\\eta_{t}^{2}\\Gamma+\\mathbb{E}\\eta_{t}^{2}\\left\\|\\mathbf{g}_{t}-\\bar{\\mathbf{g}}_{t}\\right\\|_{2}^{2}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "According to the law of iterated expectations, $E_{3}$ is 0. We next constrain $E_{1}$ . According to our assumption before Lemma 2, we have: ", "page_idx": 19}, {"type": "equation", "text": "$$\nE_{1}=\\mathbb{E}E_{1}\\leq\\mathbb{E}d\\delta^{2}\\leq\\mathbb{E}d\\eta_{t}^{2}\\left\\|\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})\\right\\|_{2}^{2}=d\\eta_{t}^{2}G^{2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "So when $t+1\\in\\mathcal{T}_{E}$ we have: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t+1}-\\mathbf{w}^{*}\\right\\|_{2}^{2}\\leq2(\\sqrt{d}\\delta+1+\\frac{d}{2})\\eta_{t}^{2}G^{2}+(1-\\eta_{t}\\mu)\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}^{*}\\right\\|_{2}^{2}+6L\\eta_{t}^{2}\\Gamma}\\\\ {\\displaystyle+\\frac{2}{N}\\sum_{K=1}^{N}\\left\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}_{t}^{k}\\right\\|_{2}^{2}+\\mathbb{E}\\eta_{t}^{2}\\left\\|\\mathbf{g}_{t}-\\bar{\\mathbf{g}}_{t}\\right\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "In summary, whether $t+1\\in\\mathcal{T}_{E}$ or $t+1\\notin\\mathcal{T}_{E}$ , we have: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t+1}-\\mathbf{w}^{*}\\right\\|_{2}^{2}\\leq2(\\sqrt{d}\\delta+1+\\frac{d}{2})\\eta_{t}^{2}G^{2}+(1-\\eta_{t}\\mu)\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}^{*}\\right\\|_{2}^{2}+6L\\eta_{t}^{2}\\Gamma}\\\\ {\\displaystyle+\\frac{2}{N}\\sum_{K=1}^{N}\\left\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}_{t}^{k}\\right\\|_{2}^{2}+\\mathbb{E}\\eta_{t}^{2}\\left\\|\\mathbf{g}_{t}-\\bar{\\mathbf{g}}_{t}\\right\\|_{2}^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Lemma 3. Based on assumption 2, we can get: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}\\|\\mathbf{g}_{t}-\\bar{\\mathbf{g}}_{t}\\|_{2}^{2}\\leq\\frac{1}{N^{2}}\\sum_{k=1}^{N}{\\sigma_{k}}^{2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\|\\mathbf{g}_{t}-\\bar{\\mathbf{g}}_{t}\\|_{2}^{2}=\\mathbb{E}\\bigg\\|\\frac{1}{N}\\displaystyle\\sum_{k=1}^{N}\\big(\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})-\\nabla F_{k}(\\mathbf{w}_{t}^{k})\\big)\\bigg\\|_{2}^{2}}\\\\ &{\\qquad\\qquad\\qquad=\\displaystyle\\sum_{k=1}^{N}\\displaystyle\\frac{1}{N^{2}}\\mathbb{E}\\big\\|\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})-\\nabla F_{k}(\\mathbf{w}_{t}^{k})\\big\\|_{2}^{2}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\displaystyle\\frac{1}{N^{2}}\\displaystyle\\sum_{k=1}^{N}\\sigma_{k}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Lemma 4. If $\\eta_{t}$ is non-increasing and $\\eta_{t}\\leq2\\eta_{t+E},(t\\geq0)$ ,based on assumption 2, we can get: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\frac{1}{N}\\sum_{k=1}^{N}\\mathbb{E}\\big\\lVert\\bar{\\mathbf{w}}_{t}-\\mathbf{w}_{t}^{k}\\big\\rVert_{2}^{2}\\leq8E^{2}\\eta_{t}^{2}G^{2}(2\\sqrt{d}\\delta+3).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. Since FedAvg requires a communication each $E$ steps. Therefore, for any $t\\geq0$ , there exists a $t_{0}~\\leq~t$ , such that $t\\,-\\,t_{0}\\,\\le\\,E\\,{-}\\,1$ and $\\bar{\\mathbf{w}}_{t_{0}}\\,=\\,\\mathbf{w}_{t_{0}}^{k}$ wtk0 for all k. Also, we use the fact that \u03b7t is non-increasing and $\\eta_{t}\\le2\\eta_{t+E},(t\\ge0)$ , then: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad_{\\mathbf{X}_{i}=0}:=:=\\cdots}\\\\ &{=:={\\cfrac{1}{N}}\\sum_{i=1}^{N}\\|\\mathbf{u}_{i}^{k}-\\mathbf{u}_{i}-(\\mathbf{u}_{i}-\\mathbf{u}_{i})\\|_{2}^{2}}\\\\ &{\\leq:={\\cfrac{1}{N}}\\sum_{i=1}^{N}\\|\\mathbf{u}_{i}^{k}-\\mathbf{u}_{i}\\|_{2}^{2}}\\\\ &{\\leq:={\\cfrac{1}{N}}\\sum_{i=1}^{N}\\|\\mathbf{u}_{i}^{k}-\\mathbf{u}_{i}\\|_{2}^{2}}\\\\ &{=:{\\cfrac{1}{N}}\\sum_{i=1}^{N}\\|\\mathbf{u}_{i}^{k}-\\mathbf{u}_{i}\\|_{2}^{2}}\\\\ &{=:{\\cfrac{1}{N}}\\sum_{i=1}^{N}\\|\\mathbf{u}_{i}^{k}-\\mathbf{u}_{i}^{k}\\|_{2}^{2}}\\\\ &{=:{\\cfrac{1}{N}}\\sum_{i=1}^{N}\\|\\mathbf{u}_{i}^{k}-\\mathbf{u}_{i}^{k}-\\mathbf{u}_{i}^{k}-\\mathbf{u}_{i}^{k}-\\mathbf{u}_{i}^{k}\\|_{2}^{2}}\\\\ &{\\leq:{\\cfrac{1}{N}}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\|\\mathbf{u}_{i}^{k}-\\mathbf{u}_{j}^{k}\\|_{2}^{2}}\\\\ &{={\\cfrac{1}{N}}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\|\\mathbf{u}_{i}^{k}-\\mathbf{u}_{j}^{k}\\|_{2}^{2}}\\\\ &{\\leq:{\\cfrac{1}{N}}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\|(\\mathbf{u}_{i}^{k}-\\mathbf{u}_{j}^{k})(\\mathbf{u}_{i}^{k})(\\mathbf{u}_{i}^{k})-(\\mathbf{u}_{i}^{k}-\\mathbf{u}_{i}^{k})\\mathbb{T}_{A}(\\mathbf{u}_{j}^{k},\\mathbf{d})-\\mathbf{u}_{i}^{k}\\mathbb{T}_{A}(\\mathbf{u}_{j}^{k})\\|_{2}^{2}}\\\\ &{\\leq:{\\cfrac{1\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Inequalities $\\left\\|\\sum_{i=1}^{E}a_{i}\\right\\|_{2}^{2}\\leq E\\sum_{i=1}^{E}\\left\\|a_{i}\\right\\|_{2}^{2}$ and $\\mathbb{E}\\left\\|X-\\mathbb{E}X\\right\\|_{2}^{2}\\leq\\mathbb{E}\\left\\|X\\right\\|_{2}^{2}$ are used in the above proof. We have already proofed in lemma 2 that: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\big\\|Q(\\mathbf{w}_{h}^{k}-\\eta_{h}\\nabla F_{h}(\\mathbf{w}_{h}^{k},\\xi_{h}^{k}))-(\\mathbf{w}_{h}^{k}-\\eta_{h}\\nabla F_{h}(\\mathbf{w}_{h}^{k},\\xi_{h}^{k}))\\big\\|_{2}^{2}\\leq2(\\sqrt{d}\\delta+1)\\eta_{h}^{2}G^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "So we can have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\frac{1}{N}\\sum_{k=1}^{N}\\mathbb{E}\\big\\lVert\\bar{\\mathbf{w}}_{t}-\\mathbf{w}_{t}^{k}\\big\\rVert_{2}^{2}\\leq8E^{2}\\eta_{t}^{~2}G^{2}(2\\sqrt{d}\\delta+3).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Theorem 1. Under the condition that assumptions 1, 2, we choose $\\begin{array}{r}{\\kappa=\\frac{L}{\\mu}}\\end{array}$ , $\\gamma=\\operatorname*{max}\\{8\\kappa,E\\}-1$ and $\\begin{array}{r}{\\eta_{t}=\\frac{\\mu}{2(t+\\gamma)}}\\end{array}$ . When $t$ satisfying $\\delta^{2}\\leq\\eta_{t}^{2}G^{2}$ our low precision federated learning algorihm with full device participation satisfies: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{E}F(\\bar{\\mathbf{w}}_{t})-F^{*}\\le\\frac{L}{2}\\frac{v}{t+\\gamma}\\le\\frac{\\kappa}{t+\\gamma}(\\frac{2B}{\\mu}+\\frac{\\mu(\\gamma+1)}{2}\\|\\mathbf{w}_{1}-\\mathbf{w}^{*}\\|^{2}).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where ", "page_idx": 20}, {"type": "equation", "text": "$$\nB=2(\\sqrt{d}\\delta+1+\\frac{d}{2})G^{2}+16E^{2}G^{2}(2\\sqrt{d}\\delta+3)+\\frac{1}{N^{2}}\\sum_{k=1}^{N}\\sigma_{k}{}^{2}+6L\\Gamma.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. Set $\\Delta_{\\mathrm{t}}=\\mathbb{E}\\lVert\\bar{\\mathbf{w}}_{t}-\\mathbf{w}^{*}\\rVert_{2}^{2}$ , according to lemma 1, 2, 3, we can have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\Delta_{\\mathrm{t+1}}\\leq(1-\\mu\\eta_{t})\\Delta_{\\mathrm{t}}+{\\eta_{t}}^{2}B.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Set \u03b7t = $\\begin{array}{r}{\\eta_{t}=\\frac{\\beta}{t+\\gamma}}\\end{array}$ , we can choose appropriate $\\beta$ and $\\gamma$ so that $\\begin{array}{r}{\\eta_{t}\\leq\\operatorname*{min}\\lbrace\\frac{1}{\\mu},\\frac{1}{4L}\\rbrace}\\end{array}$ and $\\eta_{t}\\leq2\\eta_{t+E}$ . Set $\\begin{array}{r}{v=\\operatorname*{max}\\lbrace\\frac{\\beta^{2}B}{\\beta\\mu-1},(\\gamma+1)\\Delta_{1}\\rbrace}\\end{array}$ , we will prove $\\begin{array}{r}{\\Delta_{\\mathrm{t}}\\le\\frac{v}{t+\\gamma}}\\end{array}$ by mathematical induction. ", "page_idx": 21}, {"type": "text", "text": "When $t=1$ , obviously it holds. Assume the conclusion holds for some $t$ , it follows that: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta_{\\mathfrak{t}+1}\\leq(1-\\mu\\eta_{t})\\Delta_{\\mathfrak{t}}+\\eta_{t}{^2B}}\\\\ &{\\qquad\\leq(1-\\frac{\\beta\\mu}{t+\\gamma})\\frac{v}{t+\\gamma}+\\frac{\\beta^{2}B}{(t+\\gamma)^{2}}}\\\\ &{\\qquad=\\frac{t+\\gamma-1}{{(t+\\gamma)}^{2}}v+[\\frac{\\beta^{2}B}{{(t+\\gamma)}^{2}}-\\frac{\\beta\\mu-1}{{(t+\\gamma)}^{2}}v]}\\\\ &{\\qquad\\leq\\frac{v}{t+\\gamma+1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Then by the $\\mathrm{L}$ -smoothness of $F(\\cdot)$ ,we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}F(\\bar{\\mathbf{w}}_{t})-F^{*}\\leq\\frac{L}{2}\\Delta_{\\mathfrak{t}}\\leq\\frac{L}{2}\\frac{v}{t+\\gamma}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We choose $\\begin{array}{r}{\\beta=\\frac{2}{\\mu},\\gamma=\\operatorname*{max}\\{8\\kappa,E\\}-1}\\end{array}$ and denote $\\begin{array}{r}{\\kappa=\\frac{L}{\\mu}}\\end{array}$ , then we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\nv=\\operatorname*{max}\\{\\frac{\\beta^{2}B}{\\beta\\mu-1},(\\gamma+1)\\Delta_{1}\\}\\leq\\frac{\\beta^{2}B}{\\beta\\mu-1}+(\\gamma+1)\\Delta_{1}\\leq\\frac{4B}{\\mu^{2}}+(\\gamma+1)\\Delta_{1}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "and ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}F(\\bar{\\mathbf{w}}_{t})-F^{*}\\leq\\frac{L}{2}\\frac{v}{t+\\gamma}\\leq\\frac{\\kappa}{t+\\gamma}(\\frac{2B}{\\mu}+\\frac{\\mu(\\gamma+1)}{2}\\Delta_{1}).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "B Proofs of Theorem 2 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We analyze our low precision federated learning algorithm in the setting of partial device participation in this section. ", "page_idx": 21}, {"type": "text", "text": "Updating scheme In real world application scenarios, constrained by communication efficiency and low straggler effect, FedAvg initiates by selecting a random subset $\\mathcal{S}_{t}$ which length is set to $K$ , and subsequently carries out updates exclusively on this subset.The analysis becomes somewhat complex due to the variability of $\\mathcal{S}_{t}$ every $E$ steps. Nevertheless, we can employ a thought trick to address this challenge. We envision that FedAvg initiates each epoch by engaging all devices and then relies solely on the parameters updated on a subset of these devices to generate the parameters for the subsequent round. It is evident that this method of parameter update is equivalent to the original approach. Then the update of FedAvg with partial devices active can be described as: for all $k\\in[N]$ , ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbf{v}_{t+1}^{k}=Q(w_{t}^{k}-\\eta_{t}\\nabla F_{k}(\\mathbf{w}_{t}^{k},\\xi_{t}^{k})).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbf{w}_{t+1}^{k}=\\left\\{\\mathbf{v}_{t+1}^{k}\\qquad\\qquad\\qquad\\mathrm{if}\\ t+1\\notin S_{t},\\right.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We use $\\mathbb{E}_{S_{t}}(\\cdot)$ to eliminate the error caused by $\\mathcal{S}_{t}$ . Unless otherwise specified, the meanings and assumptions of the symbols used in this section are the same as in the previous section. ", "page_idx": 21}, {"type": "text", "text": "Lemma 5. If $t+1\\in\\mathcal{T}_{E}$ , we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}_{S_{t}}\\big(\\bar{\\mathbf{w}}_{t+1}\\big)=\\bar{\\mathbf{v}}_{t+1}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. According to the selection method of $\\mathcal{S}_{t}$ , there is a function: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{I}_{i}=\\left\\{\\begin{array}{l l}{1,}&{\\mathbb{P}(i\\in\\mathscr{S}_{t})=\\frac{K}{N}}\\\\ {0,}&{\\mathbb{P}(i\\notin\\mathscr{S}_{t})=\\frac{N-K}{N}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "According to the aggregation process, we have: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\bar{\\mathbf{w}}_{t+1}=Q(\\frac{1}{K}\\sum_{i=1}^{N}\\mathbb{I}_{i}\\mathbf{v}_{t+1}^{i}).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "So we have: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\mathbb{E}_{S_{t}}(\\bar{\\mathbf{w}}_{t+1})=\\mathbb{E}_{S_{t}}(\\frac{1}{K}\\sum_{i=1}^{N}\\mathbb{I}_{i}\\mathbf{v}_{t+1}^{i})}}\\\\ {{\\displaystyle=\\frac{1}{K}\\sum_{i=1}^{N}\\mathbb{P}_{i}{\\mathbf{v}}_{t+1}^{i}=\\frac{1}{K}\\sum_{i=1}^{N}\\frac{K}{N}{\\mathbf{v}}_{t+1}^{i}=\\displaystyle\\sum_{i=1}^{N}\\frac{1}{N}{\\mathbf{v}}_{t+1}^{i}=\\bar{\\mathbf{v}}_{t+1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Lemma 6. For $t+1\\in\\mathcal{T}_{E}$ we have: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}_{S_{t}}\\left\\lVert\\bar{\\mathbf{v}}_{t+1}-\\bar{\\mathbf{w}}_{t+1}\\right\\rVert_{2}^{2}\\leq\\frac{N-K}{N-1}\\frac{8}{K}E^{2}\\eta_{t}^{2}G^{2}(2\\sqrt{d}\\delta+3)+d G^{2}\\eta_{t}^{2}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. According to the aggregation process,we have $\\begin{array}{r}{\\bar{\\mathbf{w}}_{t+1}=Q(\\frac{1}{K}\\sum_{i\\in S_{t}}\\mathbf{v}_{t+1}^{i})}\\end{array}$ . ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}_{\\boldsymbol{\\mathcal{S}}_{t}}\\left\\|\\widetilde{\\mathbf{w}}_{t+1}-\\bar{\\mathbf{v}}_{t+1}\\right\\|_{2}^{2}}\\\\ &{=\\mathbb{E}_{\\boldsymbol{\\mathcal{S}}_{t}}\\left\\|Q(\\frac{1}{K}\\displaystyle\\sum_{i\\in\\mathcal{S}_{t}}\\mathbf{v}_{t+1}^{i})-\\frac{1}{K}\\displaystyle\\sum_{i\\in\\mathcal{S}_{t}}\\mathbf{v}_{t+1}^{i}+\\frac{1}{K}\\displaystyle\\sum_{i\\in\\mathcal{S}_{t}}\\mathbf{v}_{t+1}^{i}-\\bar{\\mathbf{v}}_{t+1}\\right\\|_{2}^{2}}\\\\ &{=\\underbrace{\\mathbb{E}_{\\boldsymbol{\\mathcal{S}}_{t}}\\left\\|Q(\\frac{1}{K}\\displaystyle\\sum_{i\\in\\mathcal{S}_{t}}\\mathbf{v}_{t+1}^{i})-\\frac{1}{K}\\displaystyle\\sum_{i\\in\\mathcal{S}_{t}}\\mathbf{v}_{t+1}^{i}\\right\\|_{2}^{2}}_{F_{1}}+\\underbrace{\\frac{1}{K^{2}}\\mathbb{E}_{\\boldsymbol{\\mathcal{S}}_{t}}\\left\\|\\displaystyle\\sum_{i=1}^{N}\\mathbb{I}(i\\in\\mathcal{S}_{t})(\\mathbf{v}_{t+1}^{i}-\\bar{\\mathbf{v}}_{t+1})\\right\\|_{2}^{2}}_{F_{2}}}\\\\ &{\\quad+\\underbrace{2\\langle Q(\\frac{1}{K}\\displaystyle\\sum_{i\\in\\mathcal{S}_{t}}\\mathbf{v}_{t+1}^{i})-\\frac{1}{K}\\displaystyle\\sum_{i\\in\\mathcal{S}_{t}}\\mathbf{v}_{t+1}^{i},\\frac{1}{K}\\displaystyle\\sum_{i\\in\\mathcal{S}_{t}}\\mathbf{v}_{t+1}^{i}-\\bar{\\mathbf{v}}_{t+1}\\rangle}_{F_{3}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "In the lemma 2, we have proven $F_{1}\\leq d G^{2}\\eta_{t}^{2}$ . And obviously we have $F_{3}=0$ , we next aim to bound $F_{2}$ . ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{K^{2}}\\mathbb{E}_{s}\\bigg\\|\\displaystyle\\sum_{i=1}^{N}\\mathbb{I}(i\\in S_{t})\\big(\\mathbf{v}_{t+1}^{i}-\\bar{\\mathbf{v}}_{t+1}\\big)\\bigg\\|_{2}^{2}}\\\\ &{=\\displaystyle\\frac{1}{K^{2}}\\sum_{i=1}^{N}\\mathbb{P}(i\\in S_{t})\\left\\|\\mathbf{v}_{t+1}^{i}-\\bar{\\mathbf{v}}_{t+1}\\right\\|_{2}^{2}}\\\\ &{\\displaystyle\\quad+\\frac{1}{K^{2}}\\sum_{i\\neq j}\\mathbb{P}\\left(i,j\\in S_{t}\\right)\\bigg\\langle\\mathbf{v}_{t+1}^{i}-\\bar{\\mathbf{v}}_{t+1},\\mathbf{v}_{t+1}^{j}-\\bar{\\mathbf{v}}_{t+1}\\bigg\\rangle}\\\\ &{=\\displaystyle\\frac{1}{K N}\\sum_{i=1}^{N}\\left\\|\\mathbf{v}_{t+1}^{i}-\\bar{\\mathbf{v}}_{t+1}\\right\\|_{2}^{2}+\\displaystyle\\sum_{i\\neq j}\\frac{K-1}{K N\\left(N-1\\right)}\\langle\\mathbf{v}_{t+1}^{i}-\\bar{\\mathbf{v}}_{t+1},\\mathbf{v}_{t+1}^{j}-\\bar{\\mathbf{v}}_{t+1}\\right\\rangle}\\\\ &{=\\displaystyle\\frac{1}{K(N-1)}\\left(1-\\frac{K}{N}\\right)\\sum_{i=1}^{N}\\left\\|\\mathbf{v}_{t+1}^{i}-\\bar{\\mathbf{v}}_{t+1}\\right\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The last step in the above equation uses: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{N}{\\left\\|\\mathbf{v}_{t+1}^{i}-\\bar{\\mathbf{v}}_{t+1}\\right\\|}_{2}^{2}+\\sum_{i\\neq j}\\langle\\mathbf{v}_{t+1}^{i}-\\bar{\\mathbf{v}}_{t+1},\\mathbf{v}_{t+1}^{j}-\\bar{\\mathbf{v}}_{t+1}\\rangle=0.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Therefore: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t+1}-\\bar{\\mathbf{v}}_{t+1}\\right\\|_{2}^{2}=\\frac{N}{K(N-1)}\\left(1-\\displaystyle\\frac{K}{N}\\right)\\mathbb{E}\\left[\\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}\\left\\|\\mathbf{v}_{t+1}^{i}-\\bar{\\mathbf{w}}_{t_{0}}+\\bar{\\mathbf{w}}_{t_{0}}-\\bar{\\mathbf{v}}_{t+1}\\right\\|_{2}^{2}\\right]+F_{1}}\\\\ {\\displaystyle\\leq\\frac{N}{K(N-1)}\\left(1-\\displaystyle\\frac{K}{N}\\right)\\mathbb{E}\\left[\\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}\\left\\|\\mathbf{v}_{t+1}^{i}-\\bar{\\mathbf{w}}_{t_{0}}\\right\\|_{2}^{2}\\right]+F_{1}}\\\\ {\\displaystyle\\leq\\frac{N}{K(N-1)}\\left(1-\\displaystyle\\frac{K}{N}\\right)8E^{2}\\eta_{t}^{2}G^{2}(2\\sqrt{d}\\delta+3)+d G^{2}\\eta_{t}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We used $\\mathbb{E}\\left\\|\\mathbf{X}-\\mathbb{E}\\mathbf{X}\\right\\|_{2}^{2}\\leq\\mathbb{E}\\left\\|\\mathbf{X}\\right\\|_{2}^{2}$ in the inequality above. ", "page_idx": 23}, {"type": "text", "text": "Theorem 2. Under the cond\u221aition that assumptions 1, 2, 3, w\u221ae choose $\\begin{array}{r}{\\kappa=\\frac{L}{\\mu}}\\end{array}$ , $\\gamma=\\operatorname*{max}\\{8\\kappa,E\\}-$ $\\begin{array}{r}{1,\\eta_{t}=\\frac{\\mu}{2(t+\\gamma)}}\\end{array}$ an\u221ad $\\begin{array}{r}{B=2(\\sqrt{d}\\delta+1+\\frac{d}{2})G^{2}+16E^{2}G^{2}(2\\sqrt{d}\\delta+3)+\\frac{1}{N^{2}}\\sum_{k=1}^{K}\\sigma_{k}^{2}+6L\\Gamma,C=}\\end{array}$ NN\u2212\u2212K1K8 E2G2(2 d\u03b4 + 3) + dG2. When t satisfying \u03b42 \u2264\u03b7t2 G2, FedAvg with quantization and partial device participation satisfies: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}[F(\\bar{\\mathbf{w}}_{t})]-F^{*}\\le\\frac{\\kappa}{\\gamma+t}\\left(\\frac{2(B+C)}{\\mu}+\\frac{\\mu(\\gamma+1)}{2}\\|\\mathbf{w}_{1}-\\mathbf{w}^{*}\\|^{2}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof. We have: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t+1}-\\mathbf{w}^{*}\\right\\|_{2}^{2}=\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t+1}-\\bar{\\mathbf{v}}_{t+1}+\\bar{\\mathbf{v}}_{t+1}-\\mathbf{w}^{*}\\right\\|_{2}^{2}}\\\\ &{\\qquad\\qquad\\qquad=\\underbrace{\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t+1}-\\bar{\\mathbf{v}}_{t+1}\\right\\|_{2}^{2}}_{G_{1}}+\\underbrace{\\mathbb{E}\\left\\|\\bar{\\mathbf{v}}_{t+1}-\\mathbf{w}^{*}\\right\\|_{2}^{2}}_{G_{2}}+\\underbrace{2\\mathbb{E}\\langle\\bar{\\mathbf{w}}_{t+1}-\\bar{\\mathbf{v}}_{t+1},\\bar{\\mathbf{v}}_{t+1}-\\mathbf{w}^{*}\\rangle}_{G_{3}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We take the expectation for the above formula, $G_{3}$ vanishes according to lemma 5. ", "page_idx": 23}, {"type": "text", "text": "If $t+1\\notin\\mathcal{T}_{E}$ , according to our parameter update settings, $G_{1}$ vanishes. We use lemma 1, 2, 3, 4 to bound $G_{2}$ : ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left\\|\\bar{\\mathbf{v}}_{t+1}-\\mathbf{w}^{*}\\right\\|_{2}^{2}=\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t+1}-\\mathbf{w}^{*}\\right\\|_{2}^{2}\\leq(1-\\eta_{t}\\mu)\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}^{\\star}\\right\\|_{2}^{2}+\\eta_{t}^{2}B.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "If $t+1\\in\\mathcal{T}_{E}$ , We use lemma 6 to bound $G_{1}$ , lemma 1, 2, 3, 4 to bound $G_{2}$ , then we have : ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t+1}-\\mathbf{w}^{*}\\right\\|_{2}^{2}=\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t+1}-\\bar{\\mathbf{v}}_{t+1}\\right\\|_{2}^{2}+\\mathbb{E}\\left\\|\\bar{\\mathbf{v}}_{t+1}-\\mathbf{w}^{*}\\right\\|_{2}^{2}}\\\\ {\\leq(1-\\eta_{t}\\mu)\\mathbb{E}\\left\\|\\bar{\\mathbf{w}}_{t}-\\mathbf{w}^{\\star}\\right\\|_{2}^{2}+\\eta_{t}^{2}(B+C).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We use exactly the same method as in Theorem 1 and then we have: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}[F(\\bar{\\mathbf{w}}_{t})]-F^{*}\\le\\frac{\\kappa}{\\gamma+t}\\left(\\frac{2(B+C)}{\\mu}+\\frac{\\mu(\\gamma+1)}{2}\\|w_{1}-w^{*}\\|^{2}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "C Hyperparameters Setting ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We will introduce the four FL methods, ABAvg, FedProx, FedGen, FedFTG, and their hyperparameters setting in our experiments to prove our method\u2019s effectiveness. ", "page_idx": 23}, {"type": "text", "text": "\u2022 ABAvg [35] is a data-dependent distillation FL method, which uses a validation dataset $\\mathcal{D}_{v}$ to reweight each collected devices. In our experiment, we set the test dataset as the validation dataset. For FashionMNIST, CIFAR10, CIFAR100, we use the whole test dataset, and for CINIC10, we choose the $20\\%$ data of each label.   \n\u2022 FedProx [22] is an FL method with regularization when training locally. We set the FedProx proximal term $\\mu=0.1$ in our experiment.   \n\u2022 FedGen [42] is a data-free distillation FL method, which maintain a generator in the server to generate hidden variables, and transfer the generator to the device side for data enhancement. We set the generator learning rate to $3e-4$ , hidden dimension to 32. The generator\u2019s training epoch is 5.   \n\u2022 FedFTG [40] is a data-free distillation FL method, which maintain a generator on the server for fine-tuning aggregated server parameters. We set the generator learning rate to $1e-2$ , the fine-tuning learning rate to $1e-4$ . The totally fine-tune epoch is set to 10, inner epoch for generator is 1, inner epoch for server parameter is 5. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "All of our models are trained on s GeForce RTX 4090. We found only very small differences when evaluating on these other hardware platforms. ", "page_idx": 24}, {"type": "text", "text": "D Low Precision Training with Other FL Methods ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We put the four algorithms used here together with Efficient FL. Judging from the Table 4, lowprecision local training is sufficient in FL system. We put more emphasis on showing the case of $\\alpha=0.01$ , because this case is more consistent with the actual situation of FL, that is, the data heterogeneity of edge devices. Combining four FL methods and four datasets, in the case of $\\alpha=0.01$ , Figure 4, we can find the fact that our algorithm can maintain or even surpass the accuracy of the original algorithm on 8 bit, and at the same time, it can do the same on 6 bit to maintain accuracy. ", "page_idx": 24}, {"type": "table", "img_path": "vvpewjtnvm/tmp/0d3d2fc00bb4e68603b47659d180b33909963df406e46a9f226bd6ad923b1ef3.jpg", "table_caption": ["Table 4: Low precision FL on ABAvg, FedProx, FedGen, FedFTG. Our method is universal, whether it is regularized locally to constrain updates or finetuned on the server. Our method can maintain the effectiveness of various FL methods with a certain training cost, and can be applied in both regularization and distillation. "], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "We also place the algorithms used here, and these pseudocodes are added to our methods. When we conduct experiments, we also follow the algorithm flow from Algorithm 3 to Algorithm 6. We found that although different FL methods will behave differently when the client updates or the server updates, our method can be easily applied to them. ", "page_idx": 24}, {"type": "text", "text": "E Efficient FL Detail ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We list the detailed results of the Efficient FL used in experiments. We use the same network structure ConvNet and the CIFAR10 split in $\\alpha=0.01$ to conduct experiments. In HeteroFL, a, b, c, d, and e respectively represent $100\\bar{\\%}$ , $50\\%$ , $25\\%$ , $12.5\\%$ , and $6.25\\%$ channel proportions. In Table 5, for example, a1-b1-c1 means that during local training, a, b, c, the three models account for 1:1:1. In SplitMix, a, b, c, d, e, have the same representation. 1/8 and 1/16 of SplitMix represent the minimum model channel ratio after segmentation. We conducted experiments on 1/8 and 1/16 respectively. ", "page_idx": 24}, {"type": "text", "text": "We calculated the average memory consumption of a single device during each communication round, for each compression method, and also for our method. For memory consumption statistics, we record model size, gradient storage, and intermediate activation storage. Table 5 to Table 8 contains all our experimental results comparing memory savings. ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "image", "img_path": "vvpewjtnvm/tmp/2954946d8cb2eb0e4ae17c33ce2207765739e4a00da6af0a1d58303470447a31.jpg", "img_caption": ["Figure 4: Visualization of the accuracy of ABAvg, FedProx, FedGen, FedFTG FL methods when $\\alpha=0.01$ on 4 datasets. The picture from top to bottom is ABAvg, FedProx, FedGen, FedFTG. "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "Table 5: HeteroFL. a1, b1, c1, d1, e1 represent the percentage of the number of model channels to the original number: 1, 0.5, 0.25, 0.125, 0.625. For example, a1-b1-c1 means that the a, b, and c models exist in a 1:1:1 ratio. ", "page_idx": 25}, {"type": "table", "img_path": "vvpewjtnvm/tmp/d1f4ab196fc65c8bf9c98096e0d350a0edba0b9a545ceb7bc7a4d1352513a014.jpg", "table_caption": [], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "Table 6: SplitMix 1/8. Set the smallest model to 1/8 of the original model, which is the d model. By setting the client\u2019s resource limit, for example, a1-b1-c1, the client\u2019s resource limit is 1, 1/2, 1/4, then 8, 4, and $2\\;\\mathrm{d}$ models can be trained in parallel respectively. ", "page_idx": 26}, {"type": "table", "img_path": "vvpewjtnvm/tmp/110bbd008338e8289acf167e4d9b9cf1e7fb212f8b6603d37933c5c4d786e3b7.jpg", "table_caption": [], "table_footnote": [], "page_idx": 26}, {"type": "table", "img_path": "vvpewjtnvm/tmp/9c2252a9687e34fff66f0fa96d781b6797ba9b4928694946e9931502b8dbf204.jpg", "table_caption": ["Table 7: SplitMix 1/16. Set the smallest model to 1/16 of the original model, which is the e model. By setting the client\u2019s resource limit, for example, a1-b1-c1, the client\u2019s resource limit is 1, 1/2, 1/4, then 16, 8, and 4 e models can be trained in parallel respectively. "], "table_footnote": [], "page_idx": 26}, {"type": "table", "img_path": "vvpewjtnvm/tmp/139d689907fc15854d16969964f802fcae1ba7f9619282758a3eb714a91723bd.jpg", "table_caption": ["Table 8: Low precision FL. We tested the accuracy at different precisions and calculated the memory usage during local training. "], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "F Limitations ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "In fact, what we performed in the experiment was fake quantization, that is, simulated quantization, which means we only focused on the impact of quantization on accuracy. The actual quantization operation requires the cooperation of hardware, and the hardware GPU we used was GeForce RTX 4090, which could not directly perform low precision training, and could not reflect the acceleration effect of our method. ", "page_idx": 26}, {"type": "text", "text": "G Broader Impacts ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "FL, while having a positive impact in areas such as data privacy protection and cross-domain collaboration, also faces some potential negative impacts and challenges. ", "page_idx": 27}, {"type": "text", "text": "First, in FL, attackers might attempt to implant backdoors during the model training process. By introducing specific triggers into the training data, attackers can activate the backdoor after the model is deployed, causing the model to output results that the attacker desires. This type of attack poses a serious threat to the model\u2019s security and needs to be guarded against with strict security measures and auditing processes. ", "page_idx": 27}, {"type": "text", "text": "Second, attackers could disrupt the performance of the model by injecting incorrect information into the training data. This data poisoning can occur at the client side or during the model aggregation process. Data poisoning attacks may lead to the model behaving abnormally under certain conditions, affecting the model\u2019s reliability and accuracy. ", "page_idx": 27}, {"type": "text", "text": "Last, although FL is designed to protect user privacy by training models locally and sharing only model updates rather than raw data, this method is not foolproof. Attackers might infer sensitive information about the training data by analyzing the model\u2019s update information, such as gradients or weight changes. This kind of privacy leakage can be mitigated with techniques like differential privacy, which may impact the model\u2019s performance. ", "page_idx": 27}, {"type": "text", "text": "Algorithm 3 Low Precision FL with ABAvg   \nInput: Quantization functions $Q_{A}$ , $Q_{E}$ , $Q_{G}$ , $Q_{M}$ , $Q_{W}$ ; Momentum coefficient $\\rho$ ; L layers DNN   \n$\\{f_{1},f_{2},\\ldots,f_{L}\\}$ ; Loss function $\\ell$ ; Validation dataset $\\mathcal{D}_{v}$ .   \n1: Initialize: w0, w\u00af0 \u2190w0   \n2: for $t=0,1,\\dots,T-1\\,\\mathrm{e}$ do   \n3: if $t\\equiv0$ (mod $E$ ) then   \n4: Select $K$ clients from $[N]$ to be $S_{t}$   \n5: $\\mathbf{w}_{t}^{k}\\leftarrow Q(\\bar{\\mathbf{w}}_{t}),k\\in S_{t}$   \n6: end if   \n7: for $k\\in S_{t}$ do   \n8: $\\mathbf{w}_{t+1}^{k}\\leftarrow\\mathbf{ClientUpdate}(t,k,\\mathbf{w}_{t}^{k})$   \n9: end for   \n10: if $t+1\\in\\mathcal{T}_{E}$ then   \n11: Get $a_{k}$ from testing accuracy of each client $k\\in S_{t^{\\prime}}$ on $\\mathcal{D}_{v}$   \n12: $\\begin{array}{r l}&{p_{k}=\\frac{a_{k}}{\\sum_{i\\in{\\mathcal{S}_{t^{\\prime}}}}a_{i}}}\\\\ &{\\mathbf{w}_{t+1}\\leftarrow\\sum_{k\\in{\\mathcal{S}_{t^{\\prime}}}}p_{k}\\mathbf{w}_{t+1}^{k}}\\\\ &{\\bar{\\mathbf{w}}_{t+1}\\leftarrow\\lambda\\bar{\\mathbf{w}}_{t^{\\prime}}+(1-\\lambda)\\mathbf{w}_{t+1}}\\end{array}$   \n13:   \n14:   \n15: end if   \n16: end for   \n17: Return: $\\bar{\\bf w}_{T}$   \n18:   \n19: ClientUpdate $(t,k,w_{t}^{k})$ :   \n20: Get batch $(x_{k,j_{t}},y_{k,j_{t}})$ from $\\mathcal{D}_{k}$   \n21: Forward Propagation:   \n22: $\\begin{array}{r l}&{(a_{t}^{k})^{(0)}=\\bar{x}_{k,j_{t}}}\\\\ &{(a_{t}^{k})^{(l)}=Q_{A}\\big(f_{l}\\big((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)}\\big)\\big),\\forall l\\in[1,L]}\\\\ &{\\mathbf{rkward\\,Propagation:}}\\\\ &{(e_{t}^{k})^{(L)}=\\nabla_{(a_{t}^{k})^{(L)}}\\ell\\big((a_{t}^{k})^{(L)},y_{k,j_{t}}\\big)}\\\\ &{(e_{t}^{k})^{(l-1)}=Q_{E}\\big(\\frac{\\partial f_{l}((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)})}{\\partial(a_{t}^{k})^{(l-1)}}(e_{t}^{k})^{(l)}\\big),\\forall l\\in[1,L]}\\\\ &{(g_{t}^{k})^{(l)}=Q_{G}\\big(\\frac{\\partial f_{l}((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)})}{\\partial(w_{t}^{k})^{(l)}}(e_{t}^{k})^{(l)}\\big),\\forall l\\in[1,L]}\\end{array}$   \n23:   \n24: B   \n25:   \n2276::   \n28: Low Precision SGD Update:   \n29: $\\begin{array}{r l}&{(v_{t+1}^{k})^{(l)}\\leftarrow Q_{M}(\\rho(\\dot{v}_{t}^{k})^{(l)}+(g_{t}^{k})^{(l)}),\\forall l\\in[1,L]}\\\\ &{(w_{t+1}^{k})_{\\,\\,\\cdot}^{(l)}\\leftarrow Q_{W}((w_{t}^{k})^{(l)}-\\eta_{t}\\cdot(v_{t+1}^{k})^{(l)}),\\forall l\\in[1,L]}\\end{array}$   \n30:   \n31: Returtn+:1 wtk+1 ", "page_idx": 27}, {"type": "text", "text": "Algorithm 4 Low Precision FL with FedProx ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Input: Quantization functions $Q_{A}$ , $Q_{E}$ , $Q_{G}$ , $Q_{M}$ , $Q_{W}$ ; Momentum coefficient $\\rho$ ; L layers DNN   \n$\\{f_{1},f_{2},\\ldots,f_{L}\\}$ ; Loss function $\\ell$ ; FedProx proximal term $\\mu$ .   \n1: Initialize: $\\mathbf{w}_{0}$ $\\mathbf{\\Delta},\\bar{\\bf w}_{0}\\leftarrow\\mathbf{w}_{0}$   \n2: for $t=0,1,\\dots,T-1\\,\\mathbf{d}$ o   \n3: if t \u22610 (mod $E$ ) then   \n4: Select $K$ clients from $[N]$ to be $\\mathcal{S}_{t}$   \n5: $\\mathbf{w}_{t}^{k}\\leftarrow Q(\\bar{\\mathbf{w}}_{t}),k\\in S_{t}$   \n6: end if   \n7: for $k\\in S_{t}$ do   \n8: $\\mathbf{w}_{t+1}^{k}\\leftarrow\\mathbf{ClientUpdate}(t,k,\\mathbf{w}_{\\lfloor\\frac{t}{E}\\rfloor E}^{k},\\mathbf{w}_{t}^{k})$   \n9: end for   \n10: if $t+1\\in\\mathcal{T}_{E}$ then   \n11: $\\begin{array}{r}{\\mathbf{w}_{t+1}\\leftarrow\\overline{{\\sum}}_{k\\in S_{t^{\\prime}}}\\ \\frac{p_{k}}{q_{t^{\\prime}}}\\mathbf{w}_{t+1}^{k}}\\end{array}$   \n12: $\\bar{\\mathbf{w}}_{t+1}\\xleftarrow\\lambda\\bar{\\mathbf{w}}_{t^{\\prime}}+(1-\\lambda)\\mathbf{w}_{t+1}$   \n13: end if   \n14: end for   \n15: Return: $\\bar{\\bf w}_{T}$   \n16:   \n17: ClientUpdate $(t,k,w_{\\lfloor\\frac{t}{E}\\rfloor E}^{k},w_{t}^{k})$   \n18: FedProx loss functioEn $\\begin{array}{r}{\\mathcal{H}=\\ell+\\frac{\\mu}{2}||w_{\\lfloor\\frac{t}{E}\\rfloor E}^{k}-w_{t}^{k}||^{2}}\\end{array}$   \n19: Get batch $(x_{k,j_{t}},y_{k,j_{t}})$ from $\\mathcal{D}_{k}$   \n20: Forward Propagation:   \n21: $\\begin{array}{r l}&{(a_{t}^{k})^{(0)}=\\dot{x}_{k,j_{t}}^{\\hdots}}\\\\ &{(a_{t}^{k})^{(l)}=Q_{A}(f_{l}((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)})),\\forall l\\in[1,L]}\\\\ &{(e_{t}^{k}\\mathbf{ward}\\mathbf{\\Theta}\\mathbf{Propagation:}}\\\\ &{(e_{t}^{k})^{(L)}=\\nabla_{(a_{t}^{k})^{(L)}}\\ell\\big((a_{t}^{k})^{(L)},y_{k,j_{t}}\\big)}\\\\ &{(e_{t}^{k})^{(l-1)}=Q_{E}(\\frac{\\partial f_{l}((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)})}{\\partial(a_{t}^{k})^{(l-1)}}(e_{t}^{k})^{(l)}),\\forall l\\in[1,L]}\\\\ &{(g_{t}^{k})^{(l)}=Q_{G}(\\frac{\\partial f_{l}((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)})}{\\partial(w_{t}^{k})^{(l)}}(e_{t}^{k})^{(l)}+\\mu((w_{t}^{k})^{(l)}-(w_{\\lfloor\\frac{t}{E}\\rfloor E}^{k})^{(l)})),\\forall l\\in[1,L]}\\end{array}$   \n22:   \n23: B   \n24:   \n2265::   \n27: Low Precision SGD Update:   \n28: $(v_{t+1}^{k})^{(l)}\\gets Q_{M}(\\rho(\\dot{v}_{t}^{k})^{(l)}+(g_{t}^{k})^{(l)}),\\forall l\\in[1,L]$   \n29: (wtk+1)(l) \u2190QW ((wtk )(l) \u2212\u03b7t \u00b7 (vtk+1)(l)), \u2200l \u2208[1, L]   \n30: Return: wtk+ ", "page_idx": 28}, {"type": "text", "text": "Algorithm 5 Low Precision FL with FedGen ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Input: Quantization functions $Q_{A}$ , $Q_{E}$ , $Q_{G}$ , $Q_{M}$ , $Q_{W}$ ; Momentum coefficient $\\rho$ ; L layers DNN   \n$\\{f_{1},f_{2},\\ldots,f_{L}\\}$ ; Loss function $\\ell$ ; Generator parameter $\\theta$ ; $\\hat{p}(y)$ uniformly initialized; local label   \ncounter $c_{k}$ .   \n1: Initialize: w0, w\u00af0 \u2190w0   \n2: for $t=0,1,\\ldots,T-1$ do   \n3: i $\\ell\\equiv0\\;(\\mathrm{mod}\\;E)$ then   \n4: Select $K$ clients from $[N]$ to be $\\mathcal{S}_{t}$   \n5: Update $c_{k},k\\in S_{t}$   \n6: $\\mathbf{w}_{t}^{k}\\leftarrow Q(\\bar{\\mathbf{w}}_{t}),k\\in S_{t}$   \n7: end if   \n8: for $k\\in S_{t}$ do   \n9: $\\mathbf{w}_{\\underline{{t}}+1}^{k}\\leftarrow\\mathbf{ClientUpdate}(t,k,\\mathbf{w}_{t}^{k},\\hat{p}(y),\\theta)$   \n10: end for   \n11: if $t+1\\in\\mathcal{T}_{E}$ then   \n12: wt+1 \u2190 k\u2208St\u2032qptk\u2032   \n13: $\\bar{\\mathbf{w}}_{t+1}\\xleftarrow\\lambda\\bar{\\mathbf{w}}_{t^{\\prime}}+(1-\\lambda)\\mathbf{w}_{t+1}$   \n14: Server updates $\\hat{p}(y)$ based on $\\left\\{c_{k}\\right\\}k\\!\\in\\!S_{t^{\\prime}}$   \n15: Generator updates $\\begin{array}{r}{\\theta=\\underset{\\theta}{\\operatorname{argmin}}\\,\\mathbb{E}_{y\\sim\\hat{p}(y)}\\mathbb{E}_{z\\sim G_{\\theta}(z\\mid y)}\\big[\\ell\\big(\\frac{1}{K}\\sum_{k\\in{\\mathcal S}_{t^{\\prime}}}f_{L}(z,(\\mathbf w_{t+1})^{(L)}),y\\big)\\big]}\\end{array}$   \n16: end if   \n17: end for   \n18: Return: $\\bar{\\bf w}_{T}$   \n19:   \n20: ClientUpdate $(t,k,w_{t}^{k},\\hat{p}(y),\\theta);$ :   \n21: Get batch $(x_{k,j_{t}},y_{k,j_{t}})$ from $\\mathcal{D}_{k},\\hat{y}_{t}^{k}\\sim\\hat{p}(y),\\hat{z}_{t}^{k}\\sim G_{\\theta}(\\cdot|\\hat{y}_{t}^{k})$   \n22: Forward Propagation:   \n23: $\\begin{array}{r l}&{(a_{t}^{k})^{(0)}=\\frac{\\star}{x_{k,j_{t}}}}\\\\ &{(a_{t}^{k})^{(l)}=Q_{A}\\big(f_{l}\\big((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)}\\big)\\big),\\forall l\\in[1,L]}\\\\ &{\\mathbf{ckward\\,\\,\\mathbf{Propagation:}}}\\\\ &{(e_{t}^{k})^{(L)}=\\nabla_{(a_{t}^{k})^{(L)}}\\ell\\big((a_{t}^{k})^{(L)},y_{k,j_{t}}\\big)}\\\\ &{(e_{t}^{k})^{(l-1)}=Q_{E}\\big(\\frac{\\partial f_{l}\\big((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)}\\big)}{\\partial(a_{t}^{k})^{(l-1)}}\\big(e_{t}^{k}\\big)^{(l)}\\big),\\forall l\\in[1,L]}\\\\ &{(g_{t}^{k})^{(l)}=Q_{G}\\big(\\frac{\\partial f_{l}\\big((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)}\\big)}{\\partial(w_{t}^{k})^{(l)}}\\big(e_{t}^{k}\\big)^{(l)}+\\frac{\\partial\\ell\\big(f_{L}\\big(\\hat{z}_{t}^{k},(w_{t}^{k})^{(L)}\\big),\\hat{y}_{t}^{k}\\big)}{\\partial(w_{t}^{k})^{(L)}}\\big),\\forall l\\in[1,L]}\\end{array}$   \n24:   \n25: Ba   \n26:   \n2278::   \n29: Low Precision SGD Update:   \n30: $(v_{t+1}^{k})_{\\quad\\dots}^{(l)}\\leftarrow Q_{M}(\\rho(\\dot{v}_{t}^{k})_{\\quad\\dots}^{(l)}+(g_{t}^{k})_{\\quad,}^{(l)}),\\forall l\\in[1,L]\\qquad$   \n3321:: Ret(uwrtkn+:1 )w(ltk)+1\u2190QW ((wtk )(l)\u2212\u03b7t \u00b7 (vtk+1)(l)), \u2200l \u2208[1, L]   \nInput: Quantization functions $Q_{A}$ , $Q_{E}$ , $Q_{G}$ , $Q_{M}$ , $Q_{W}$ ; Momentum coefficient $\\rho$ ; L layers DNN   \n$\\{f_{1},f_{2},\\ldots,f_{L}\\}$ ; Loss function $\\ell$ ; Generator parameter $\\theta$ ; Server training iteration $I$ ; Inner   \ntraining iteration of the generator and the server $I_{g},I_{d};\\ell_{m d},\\ell_{c l s},\\ell_{d i s}$ is the loss used in ([40]).   \n1: Initialize: $\\mathbf{w}_{0},\\bar{\\mathbf{w}}_{0}\\gets\\mathbf{w}_{0}$   \n2: for $t=0,1,\\ldots,T-1$ do   \n3: if $t\\equiv0$ (mod $E$ ) then   \n4: Select $K$ clients from $[N]$ to be $\\mathcal{S}_{t}$   \n5: $\\mathbf{w}_{t}^{k}\\leftarrow Q(\\bar{\\mathbf{w}}_{t}),k\\in S_{t}$   \n6: end if   \n7: for $k\\in S_{t}$ do   \n8: $\\mathbf{w}_{t+1}^{k}\\leftarrow\\mathbf{ClientUpdate}(t,k,\\mathbf{w}_{t}^{k})$   \n9: end for   \n10: if $t+1\\in\\mathcal{T}_{E}$ then   \n11: $\\begin{array}{r l}&{\\mathbf{w}_{t+1}\\overset{\\cdot}{\\leftarrow}\\mathbf{ServerUpdate}(\\theta,\\{\\mathbf{w}_{t+1}^{k}\\}_{k\\in{\\mathcal{S}}_{t^{\\prime}}})}\\\\ &{\\bar{\\mathbf{w}}_{t+1}\\leftarrow\\lambda\\bar{\\mathbf{w}}_{t^{\\prime}}+(1-\\lambda)\\mathbf{w}_{t+1}}\\end{array}$   \n12:   \n13: end if   \n14: end for   \n15: Return: $\\bar{\\bf w}_{T}$   \n16:   \n17: ClientUpdate $(t,k,w_{t}^{k})$ :   \n18: Get batch $(x_{k,j_{t}},y_{k,j_{t}})$ from $\\mathcal{D}_{k}$   \n19: Forward Propagation:   \n20: $\\begin{array}{r l}&{(a_{t}^{k})^{(0)}=\\bar{x}_{k,j_{t}}}\\\\ &{(a_{t}^{k})^{(l)}=Q_{A}\\big(f_{l}\\big((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)}\\big)\\big),\\forall l\\in[1,L]}\\end{array}$   \n21:   \n22: Backward Propagation:   \n23: $\\begin{array}{r l}&{(e_{t}^{k})^{(L)}=\\bar{\\nabla_{(a_{t}^{k})^{(L)}}}\\ell\\big((a_{t}^{k})^{(L)},y_{k,j_{t}}\\big)}\\\\ &{(e_{t}^{k})^{(l-1)}=Q_{E}\\big(\\frac{\\partial f_{l}((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)})}{\\partial(a_{t}^{k})^{(l-1)}}(e_{t}^{k})^{(l)}\\big),\\forall l\\in[1,L]}\\\\ &{(g_{t}^{k})^{(l)}=Q_{G}\\big(\\frac{\\partial f_{l}((a_{t}^{k})^{(l-1)},(w_{t}^{k})^{(l)})}{\\partial(w_{t}^{k})^{(l)}}(e_{t}^{k})^{(l)}\\big),\\forall l\\in[1,L]}\\end{array}$   \n24:   \n25:   \n26: Low Precision SGD Update:   \n27: $\\begin{array}{r l}&{(v_{t+1}^{k})^{(l)}\\leftarrow Q_{M}(\\rho(\\dot{v}_{t}^{k})^{(l)}+(g_{t}^{k})^{(l)}),\\forall l\\in[1,L]}\\\\ &{(w_{t+1}^{k})^{(l)}\\leftarrow Q_{W}((w_{t}^{k})^{(l)}-\\eta_{t}\\cdot(v_{t+1}^{k})^{(l)}),\\forall l\\in[1,L]}\\\\ &{\\pmb{\\mathfrak{m}}_{t+1}^{k}}\\end{array}$   \n28:   \n29: Retu   \n30:   \n31: ServerUpdate( $\\boldsymbol{\\vartheta},\\{\\mathbf{w}_{t+1}^{k}\\}_{k\\in S_{t^{\\prime}}})$ :   \n32: $\\begin{array}{r}{\\mathbf{w}_{t+1}=\\sum_{k\\in S_{t^{\\prime}}}\\frac{p_{k}}{q_{t^{\\prime}}}\\mathbf{w}_{t+1}^{k}}\\end{array}$   \n33: Compute $\\begin{array}{r}{p_{t^{\\prime}}(y)\\propto\\sum_{k\\in S_{t^{\\prime}}}\\sum_{j=1}^{|\\mathcal{D}_{k}|}\\mathbb{E}_{(x_{k,j},y_{k,j})\\sim\\mathcal{D}_{k}}\\left[1_{y_{k,j}=y}\\right]=\\sum_{k\\in S_{t^{\\prime}}}n_{k}^{y}}\\end{array}$   \n34: for $i=1,2,\\dots,I$ do   \n35: Get batch $(Z,Y)$ from $z\\sim\\mathcal{N}(0,1)$ and $y\\sim p_{t^{\\prime}}(y)$   \n36: for $j=1,2,\\dots,I_{g}$ do   \n37: Update $\\theta$ according to $\\operatorname*{min}_{\\mathbf{w}_{t+1}}\\operatorname*{max}_{\\theta}\\mathbb{E}_{z\\sim\\mathcal{N}(\\mathbf{0},1),y\\sim p_{t^{\\prime}}(y)}\\left[\\ell_{m d}-\\lambda_{c l s}\\ell_{c l s}-\\lambda_{d i s}\\ell_{d i s}\\right]$   \n38: end for   \n39: for $j=1,2,\\dots,I_{d}$ do   \n40: Update $\\mathbf{w}_{t+1}$ according to $\\operatorname*{min}_{\\mathbf{w}_{t+1}}\\operatorname*{max}\\theta\\mathbb{E}_{z\\sim\\mathcal{N}(\\mathbf{0},1),y\\sim p_{t^{\\prime}}(y)}\\left[\\ell_{m d}-\\lambda_{c l s}\\ell_{c l s}-\\lambda_{d i s}\\ell_{d i s}\\right]$   \n41: end for   \n42: end for   \n43: Return wt+1 ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The algorithms mentioned in the introduction and abstract can be found in Section 4 of the article. Theoretical result can be founded in section 5. The convergence proof of our algorithm is located in appendix A and B. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 31}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Justification: Limitations can be found in appendix F. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 31}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: Theoretical result and its assumptions can be founded in section 5. The proof of theoretical result located in appendix A and B. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 32}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: We have showed the detail hyperparameters configurations in Section 6 and Appendix C. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 32}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: We have added the code to the supplementary materials. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 33}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: In the configuration of Section 6, we introduced the hyperparameters and model settings, most of which are adopted from previous work. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 33}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: In Section 6, we specified that the average of the last five rounds was used as the accuracy, and the standard deviation was calculated. When calculating the training loss of the clients, we also introduced the use of 9 clients for separate experiments to calculate the mean and standard deviation. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 33}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 34}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: The hardware we use is mentioned in Appendix C. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 34}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: We have reviewed the Code of Ethics carefully and we preserve anonymity. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 34}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: Broader Impacts can be founded in appendix G. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 34}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 35}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: Our study does not carry these risks. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 35}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: We used public data and models properly under the license and terms, which were also properly cited. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 36}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: We didn\u2019t release some new assets in this work. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 36}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: Our experiments didn\u2019t include the crowdsourcing and research with human subjects. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 36}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: Our experiments didn\u2019t include the crowdsourcing and research with human subjects. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 36}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 37}]