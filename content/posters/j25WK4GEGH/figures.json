[{"figure_path": "j25WK4GEGH/figures/figures_2_1.jpg", "caption": "Figure 1: Analysis on polarized effect of data augmentations on in-distribution (ID) and out-of-distribution (OOD). (a) mAP (%) on Market-1501 of models trained on the same dataset (ID) and MS+CS+C3 (OOD) with varying augmentation probabilities. (b) Alignment (Lalign) and uniformity (Luniform) of OOD scenarios (MS+CS+C3 \u2192 M). Counterintuitively, augmentations lead to more alignment but less uniformity, indicating that the model fails to sufficiently preserve the diverse information from the data distribution. (c) Uniformity (-Luniform) vs. augmentation probability for the source and target datasets in MS+CS+C3 \u2192 M. Higher probabilities result in less uniformity, especially under distribution shifts, indicating an insufficiency in representing OOD data.", "description": "This figure analyzes the impact of data augmentation on the performance of person re-identification models, specifically focusing on the trade-off between in-distribution (ID) and out-of-distribution (OOD) performance.  Subfigure (a) shows that while augmentations improve ID mAP, they negatively affect OOD mAP. Subfigures (b) and (c) reveal the underlying cause: augmentations increase alignment but decrease uniformity in the feature space, indicating a failure to capture diverse data distribution. This lack of uniformity is particularly pronounced in OOD scenarios.", "section": "3.1 Polarized Effect of Data Augmentation on In- and Out-of-Distribution"}, {"figure_path": "j25WK4GEGH/figures/figures_3_1.jpg", "caption": "Figure 2: Grad-CAM [68] across different probabilities of data augmentations.", "description": "The figure visualizes Grad-CAM results for different augmentation probabilities (p=0.0, p=0.5, p=1.0) applied to two sample images. Grad-CAM highlights the regions in the images that are most relevant to the model's predictions. The results show that as the augmentation probability increases, the model focuses increasingly on specific regions, potentially neglecting other important information, which may negatively impact generalization.", "section": "3.1 Polarized Effect of Data Augmentation on In- and Out-of-Distribution"}, {"figure_path": "j25WK4GEGH/figures/figures_4_1.jpg", "caption": "Figure 3: Overview of the proposed framework. In (b) and (c), each color represents a different identity and domain, respectively. (a) With original and augmented images, we apply alignment and uniformity losses to balance feature discriminability and generalization capability. We further introduce a domain-specific uniformity loss to mitigate domain bias. (b) Lalign pulls positive features closer, while Luniform pushes all features apart to maintain diversity. (c) Ldomain uniformly distributes each domain\u2019s features and prototypes, reducing domain bias and thus enhancing generalization.", "description": "This figure illustrates the Balancing Alignment and Uniformity (BAU) framework.  It shows how the framework uses both original and augmented images to apply alignment and uniformity losses to balance feature discriminability and generalization.  Additionally, a domain-specific uniformity loss is introduced to reduce domain bias.  Subfigures (b) and (c) visually explain the effects of the alignment, uniformity, and domain-specific losses on the feature embedding space.", "section": "3.2 Balancing Alignment and Uniformity"}, {"figure_path": "j25WK4GEGH/figures/figures_8_1.jpg", "caption": "Figure 4: Analysis of alignment and uniformity. (a) Alignment (Lalign) and uniformity (Luniform) on Market-1501 when MS+CS+C3 \u2192 M under Protocol-3 with varying augmentation probabilities. (b) T-SNE visualization with and without the domain-specific uniformity loss Ldomain. The values in parentheses in each legend label indicate the uniformity of the corresponding domain.", "description": "This figure analyzes the effects of the proposed method (BAU) on the alignment and uniformity of feature representations in the context of person re-identification.  Panel (a) shows how alignment and uniformity change with varying augmentation probabilities in an out-of-distribution setting (Market-1501, using data from MSMT17, CUHK03, and CUHK-SYSU for training).  It demonstrates that BAU maintains a better balance between alignment and uniformity compared to a baseline, especially when high augmentation probabilities are used. Panel (b) displays t-SNE visualizations of feature embeddings with and without the domain-specific uniformity loss (Ldomain). The visualization highlights that adding Ldomain improves the uniformity of feature distributions, especially across different source domains, thus enhancing the generalization capability of the model.", "section": "Analysis of alignment and uniformity"}, {"figure_path": "j25WK4GEGH/figures/figures_9_1.jpg", "caption": "Figure 5: Analysis of the weighting strategy. (a) Quantitative comparison of mAP (%) across varying augmentation probabilities, with and without the weighting strategy, on MS+CS+C3 \u2192 M under Protocol-3. The weighting strategy consistently improves performance, especially at higher augmentation probabilities, where the mAP drops significantly without it. (b) Qualitative analysis of the weight score w for different pairs of original and augmented images.", "description": "Figure 5 shows the effect of the weighting strategy for the alignment loss. Subfigure (a) shows a quantitative comparison of the mean average precision (mAP) using different augmentation probabilities with and without the weighting strategy. The results show that the weighting strategy consistently improves the performance, especially when the augmentation probability is high. Subfigure (b) shows a qualitative analysis of the weight scores for different pairs of original and augmented images. This visualization demonstrates how the weighting strategy focuses on augmented samples that are semantically similar to the original images, which improves the model's ability to learn from informative augmentations.", "section": "3.2 Balancing Alignment and Uniformity"}, {"figure_path": "j25WK4GEGH/figures/figures_15_1.jpg", "caption": "Figure 1: Analysis on polarized effect of data augmentations on in-distribution (ID) and out-of-distribution (OOD). (a) mAP (%) on Market-1501 of models trained on the same dataset (ID) and MS+CS+C3 (OOD) with varying augmentation probabilities. (b) Alignment (Lalign) and uniformity (Luniform) of OOD scenarios (MS+CS+C3 \u2192 M). Counterintuitively, augmentations lead to more alignment but less uniformity, indicating that the model fails to sufficiently preserve the diverse information from the data distribution. (c) Uniformity (-Luniform) vs. augmentation probability for the source and target datasets in MS+CS+C3 \u2192 M. Higher probabilities result in less uniformity, especially under distribution shifts, indicating an insufficiency in representing OOD data.", "description": "This figure analyzes the impact of data augmentation on the performance of person re-identification models, specifically focusing on the trade-off between in-distribution (ID) and out-of-distribution (OOD) performance.  Subfigure (a) shows that increasing augmentation probability improves ID performance but decreases OOD performance. Subfigures (b) and (c) show that while augmentations improve alignment in feature space, they reduce uniformity, which is detrimental to generalisation. This suggests that data augmentation can have a polarized effect; improving ID performance while hurting OOD.", "section": "3.1 Polarized Effect of Data Augmentation on In- and Out-of-Distribution"}, {"figure_path": "j25WK4GEGH/figures/figures_15_2.jpg", "caption": "Figure 1: Analysis on polarized effect of data augmentations on in-distribution (ID) and out-of-distribution (OOD). (a) mAP (%) on Market-1501 of models trained on the same dataset (ID) and MS+CS+C3 (OOD) with varying augmentation probabilities. (b) Alignment (Lalign) and uniformity (Luniform) of OOD scenarios (MS+CS+C3 \u2192 M). Counterintuitively, augmentations lead to more alignment but less uniformity, indicating that the model fails to sufficiently preserve the diverse information from the data distribution. (c) Uniformity (-Luniform) vs. augmentation probability for the source and target datasets in MS+CS+C3 \u2192 M. Higher probabilities result in less uniformity, especially under distribution shifts, indicating an insufficiency in representing OOD data.", "description": "This figure analyzes the impact of data augmentation on the performance of person re-identification models, particularly focusing on the trade-off between in-distribution and out-of-distribution performance.  Subfigure (a) shows that increasing augmentation probability improves in-distribution mAP but reduces out-of-distribution mAP.  Subfigures (b) and (c) show that increased augmentation probability leads to higher alignment but lower uniformity in the feature representation space, highlighting that simply increasing augmentation doesn't guarantee better generalization; rather, it can lead to an overemphasis on in-distribution features at the expense of out-of-distribution features.", "section": "3.1 Polarized Effect of Data Augmentation on In- and Out-of-Distribution"}, {"figure_path": "j25WK4GEGH/figures/figures_18_1.jpg", "caption": "Figure 8: Parameter analysis of k and \u03bb on MS+C3+CS \u2192 M under Protocol-3. (a) mAP/Rank-1 (%) with varying k-reciprocal nearest neighbors for the weighting strategy. (b) mAP/Rank-1 (%) with varying the weighting parameter \u03bb for the alignment loss.", "description": "This figure shows the result of parameter analysis for the weighting strategy (k) and the alignment loss (\u03bb) under Protocol-3.  The left subplot (a) shows how changing the number of k-reciprocal nearest neighbors affects the model's performance (mAP and Rank-1 accuracy). The right subplot (b) shows the same performance metrics, but this time in response to changes in the weighting parameter (\u03bb) for the alignment loss.  Optimal values for k and \u03bb are determined through this analysis.", "section": "4.4 Ablation Study and Analysis"}]