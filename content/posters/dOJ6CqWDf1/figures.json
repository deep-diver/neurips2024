[{"figure_path": "dOJ6CqWDf1/figures/figures_1_1.jpg", "caption": "Figure 1: Weak-to-strong search enhances the alignment of large models through test-time guidance from small models (dashed lines). This method is applicable to white-box models that use the same or different vocabularies as the small models, as well as to black-box models. We present the results for the instruction-tuned models from each family (e.g., Llama2-7B denotes Llama-2-7b-chat).", "description": "This figure shows the improvement in AlpacaEval 2.0 length-controlled win rates against GPT-4-turbo when using weak-to-strong search.  The win rates are displayed for various large language models (LLMs), both with and without the weak-to-strong search method. The dashed lines represent the performance of small, tuned and untuned models used as guidance for the weak-to-strong search. The figure highlights the effectiveness of the method in improving the alignment of large language models, even when the guidance comes from relatively weak small models.", "section": "Experiments"}, {"figure_path": "dOJ6CqWDf1/figures/figures_4_1.jpg", "caption": "Figure 2: Illustration of Chunk-level Beam Search with W, K = 2, 2.", "description": "This figure illustrates the Chunk-Level Beam Search (CBS) algorithm.  It shows how the algorithm maintains a hypothesis set of partial sequences (H). For each hypothesis, it samples successor chunks (YL) from the base language model.  The top-W best successors, based on a scoring function using the log probability difference between a tuned and untuned small language model, are selected to expand. This process continues until a complete response is generated.", "section": "4.2 Chunk-level Beam Search (CBS)"}, {"figure_path": "dOJ6CqWDf1/figures/figures_6_1.jpg", "caption": "Figure 3: The gold reward achieved for different large pre-trained models under the gpt2 guidance. We show the mean reward (\u00b1 standard deviations) across three random seeds. EFT (3*) denotes the best EFT results among \u03b2\u2208 {1/4,1/2, 1, 2, 4}; Weak-to-strong search (4, 4, 5) denotes CBS with W, K, L = 4, 4, 5; BoN (16) denotes BoN with N = 16.", "description": "This figure compares the performance of different methods for aligning large language models using small tuned and untuned gpt2 models as guidance on two tasks: controlled-sentiment generation and summarization.  The gold reward, a metric reflecting alignment with human preferences, is plotted for each method on several large models (gpt2-large, gpt2-xl, Llama2-7B, Llama3-8B).  The results demonstrate the effectiveness of weak-to-strong search in improving alignment, particularly compared to baselines like BoN and EFT. ", "section": "5.1 Controlled-Sentiment Generation & Summarization"}, {"figure_path": "dOJ6CqWDf1/figures/figures_7_1.jpg", "caption": "Figure 1: Weak-to-strong search enhances the alignment of large models through test-time guidance from small models (dashed lines). This method is applicable to white-box models that use the same or different vocabularies as the small models, as well as to black-box models. We present the results for the instruction-tuned models from each family (e.g., Llama2-7B denotes Llama-2-7b-chat).", "description": "The figure shows the improvement in the alignment of large language models (LLMs) by using weak-to-strong search.  The dashed lines represent the performance of small tuned and untuned models, which are used to guide the decoding process of the LLMs. The results demonstrate that the method works across various tasks (controlled sentiment generation, summarization, and instruction-following) and model architectures (white-box and black-box).  The method is effective even when the guiding small models have low win rates (around 10%).", "section": "Experiments"}, {"figure_path": "dOJ6CqWDf1/figures/figures_7_2.jpg", "caption": "Figure 1: Weak-to-strong search enhances the alignment of large models through test-time guidance from small models (dashed lines). This method is applicable to white-box models that use the same or different vocabularies as the small models, as well as to black-box models. We present the results for the instruction-tuned models from each family (e.g., Llama2-7B denotes Llama-2-7b-chat).", "description": "The figure shows the results of using weak-to-strong search to improve the alignment of large language models.  The dashed lines represent the performance of the method using small tuned models as guidance, demonstrating improvements over baseline methods (solid bars) across various large models (Llama 2, Llama 3, GPT3.5).  The results highlight the flexibility of the approach across different model architectures and vocabularies, including black-box models.", "section": "Experiments"}, {"figure_path": "dOJ6CqWDf1/figures/figures_8_1.jpg", "caption": "Figure 1: Weak-to-strong search enhances the alignment of large models through test-time guidance from small models (dashed lines). This method is applicable to white-box models that use the same or different vocabularies as the small models, as well as to black-box models. We present the results for the instruction-tuned models from each family (e.g., Llama2-7B denotes Llama-2-7b-chat).", "description": "The figure shows the results of applying weak-to-strong search to several large language models.  The dashed lines represent the performance improvement achieved by using the proposed weak-to-strong search method, which guides the larger models using smaller, tuned and untuned models.  This demonstrates how the alignment of large language models can be improved without direct fine-tuning, and that the technique works with both white-box and black-box models (models that do or do not share the same vocabulary as the smaller guidance models). The results show improved performance on various benchmarks, particularly AlpacaEval 2.0.", "section": "Experiments"}, {"figure_path": "dOJ6CqWDf1/figures/figures_16_1.jpg", "caption": "Figure 1: Weak-to-strong search enhances the alignment of large models through test-time guidance from small models (dashed lines). This method is applicable to white-box models that use the same or different vocabularies as the small models, as well as to black-box models. We present the results for the instruction-tuned models from each family (e.g., Llama2-7B denotes Llama-2-7b-chat).", "description": "The figure shows the results of using weak-to-strong search to improve the alignment of large language models.  The dashed lines represent the performance gains achieved by incorporating guidance from smaller, tuned language models during test time.  The figure demonstrates the method's applicability to both white-box (models sharing vocabularies) and black-box (models with different vocabularies) large language models across multiple instruction-following benchmarks.  The results are presented for instruction-tuned models from various families.", "section": "Experiments"}, {"figure_path": "dOJ6CqWDf1/figures/figures_17_1.jpg", "caption": "Figure 1: Weak-to-strong search enhances the alignment of large models through test-time guidance from small models (dashed lines). This method is applicable to white-box models that use the same or different vocabularies as the small models, as well as to black-box models. We present the results for the instruction-tuned models from each family (e.g., Llama2-7B denotes Llama-2-7b-chat).", "description": "This figure shows the results of using weak-to-strong search to improve the alignment of large language models.  The dashed lines represent the performance gains achieved by incorporating test-time guidance from smaller, tuned models.  The figure demonstrates the effectiveness of this approach on various models, including both white-box and black-box models, with the x-axis showing different models and the y-axis showing the AlpacaEval 2.0 LC win rate (%).  The key takeaway is that even small, tuned models can significantly improve larger models' performance.", "section": "Experiments"}, {"figure_path": "dOJ6CqWDf1/figures/figures_17_2.jpg", "caption": "Figure 4: W, K ablations for CBS (L = 5). We show the mean rewards across three random seeds. With the same computation budget (i.e., same WK), the optimal hyperparameters differ by tasks.", "description": "This figure shows the results of ablation studies on the hyperparameters W (beam width) and K (successors per state) of the Chunk-level Beam Search (CBS) algorithm, with a fixed chunk length L=5.  The experiments were conducted on controlled-sentiment generation and summarization tasks. The plots show the mean reward across three random seeds for different combinations of W and K. Notably, while maintaining the same computational budget (WK), the optimal settings for W and K vary depending on the task, indicating a task-specific optimal balance between exploring multiple hypotheses and focusing computational resources on promising ones.", "section": "5.1 Controlled-Sentiment Generation & Summarization"}, {"figure_path": "dOJ6CqWDf1/figures/figures_20_1.jpg", "caption": "Figure 1: Weak-to-strong search enhances the alignment of large models through test-time guidance from small models (dashed lines). This method is applicable to white-box models that use the same or different vocabularies as the small models, as well as to black-box models. We present the results for the instruction-tuned models from each family (e.g., Llama2-7B denotes Llama-2-7b-chat).", "description": "The figure displays the results of using weak-to-strong search to improve the alignment of large language models.  It shows that using smaller, already tuned language models as test-time guidance improves the performance of larger models across different tasks, even when the vocabularies don't match and the models are treated as \"black boxes\". The dashed lines represent the small models, while the solid bars represent the large models before and after the application of the weak-to-strong search method. The figure highlights the improvement in AlpacaEval 2.0 length-controlled win rates against GPT-4-turbo.", "section": "Experiments"}]