[{"figure_path": "eOonmxzzno/figures/figures_1_1.jpg", "caption": "Figure 1: The difference between the TSG and TSG-RF tasks. TSG always predicts the start and end boundaries of the grounded segments, even in the absence of video content relevant to the given query text. By contrast, TSG-RF provides relevance feedback on whether exist query-related content in the given video, and selectively predicts the start and end boundaries of the grounded segments, according to the presence or absence of query-related segments in videos.", "description": "This figure shows the difference between the traditional Temporal Sentence Grounding (TSG) task and the proposed Temporal Sentence Grounding with Relevance Feedback (TSG-RF) task.  In TSG, the model always predicts a video segment even if the query is not present in the video. In TSG-RF, the model provides relevance feedback (indicating whether the query is relevant to the video), and only predicts a segment if the query is present.  This demonstrates the key improvement of TSG-RF in handling real-world scenarios where relevant content may be missing from the input video.", "section": "1 Introduction"}, {"figure_path": "eOonmxzzno/figures/figures_4_1.jpg", "caption": "Figure 2: The overall framework of our proposed RaTSG for addressing TSG-RF task. It mainly depends on a multi-granularity relevance discriminator that is employed to learn query-video relevance, and a relation-aware segment grounding module that is used to selectively perform grounding.", "description": "This figure illustrates the architecture of the Relation-aware Temporal Sentence Grounding (RaTSG) network, which is proposed to address the Temporal Sentence Grounding with Relevance Feedback (TSG-RF) task. The network consists of two main components: a multi-granularity relevance discriminator and a relation-aware segment grounding module. The relevance discriminator determines whether query-related segments are present in the video. The grounding module localizes the segments if they exist.  The multi-granularity relevance discriminator works at the frame and video levels to capture the relevance between text and video at different granularities. The relation-aware segment grounding module selectively performs grounding based on the relevance feedback.", "section": "3 The Proposed Method"}, {"figure_path": "eOonmxzzno/figures/figures_8_1.jpg", "caption": "Figure 3: t-SNE visualization of relation signal vectors of all test samples on Charades-RF, where red dots represent relevant samples and blue points represent irrelevant samples of queries and videos.", "description": "This figure visualizes the relation signal vectors obtained from the multi-granularity relevance discriminator using t-SNE (t-distributed Stochastic Neighbor Embedding).  The t-SNE algorithm reduces the dimensionality of the high-dimensional relation signal vectors, allowing for visualization in a 2D space. Each point represents a sample from the Charades-RF test set, colored red if it is a relevant sample (i.e., query-video pair where the query text is semantically relevant to the video content) and blue if it is irrelevant. The visualization helps to understand how effectively the model distinguishes between relevant and irrelevant samples based on their relation signal vectors. The clustering of points suggests that the model effectively captures semantic relationships between the query text and video segments.", "section": "4.3.3 Mutual Enhancement between Relevance Discrimination and Segment Grounding"}, {"figure_path": "eOonmxzzno/figures/figures_9_1.jpg", "caption": "Figure 1: The difference between the TSG and TSG-RF tasks. TSG always predicts the start and end boundaries of the grounded segments, even in the absence of video content relevant to the given query text. By contrast, TSG-RF provides relevance feedback on whether exist query-related content in the given video, and selectively predicts the start and end boundaries of the grounded segments, according to the presence or absence of query-related segments in videos.", "description": "This figure highlights the key difference between the traditional Temporal Sentence Grounding (TSG) task and the proposed Temporal Sentence Grounding with Relevance Feedback (TSG-RF) task.  TSG always outputs temporal boundaries for a query, even if the query is not present in the video. In contrast, TSG-RF first determines whether the query is relevant to the video and then selectively grounds the segment only if relevant. This makes TSG-RF more realistic for real-world applications.", "section": "1 Introduction"}, {"figure_path": "eOonmxzzno/figures/figures_9_2.jpg", "caption": "Figure 5: Visualization of two bad examples obtained by our proposed RaTSG.", "description": "This figure shows two examples where the proposed RaTSG model makes mistakes. In the first example, the model incorrectly judges the relevance feedback due to a lack of audio cues (which are important for identifying the action of sneezing). In the second example, the model misinterprets the temporal sequence of actions (mistaking a closing action for an opening action). These examples demonstrate that the model struggles with audio-related actions and temporally sensitive content.  The figure also includes visualizations of the model's output probabilities for start and end boundaries, as well as foreground frame prediction scores.", "section": "4.4 Analysis of Grounding Examples"}, {"figure_path": "eOonmxzzno/figures/figures_16_1.jpg", "caption": "Figure 6: The organizational structure of reconstructed dataset.", "description": "The figure illustrates how the datasets were reconstructed for the Temporal Sentence Grounding with Relevance Feedback (TSG-RF) task.  Each video (V1) in the original datasets had multiple associated query sentences (S11, S12... S1m) with grounding results. To create the TSG-RF datasets, for each of these (query, video) pairs, another video (Vn) was randomly selected, and a new (query, video) pair was formed.  This new pair is considered a sample without grounding results because the video (Vn) might not have any segment related to the query sentence.  The figure visually represents this process, clearly differentiating samples with and without grounding results. This new dataset design allows the model to learn relevance feedback.", "section": "4.1 Experimental Setup"}, {"figure_path": "eOonmxzzno/figures/figures_17_1.jpg", "caption": "Figure 2: The overall framework of our proposed RaTSG for addressing TSG-RF task. It mainly depends on a multi-granularity relevance discriminator that is employed to learn query-video relevance, and a relation-aware segment grounding module that is used to selectively perform grounding.", "description": "This figure shows the architecture of the Relation-aware Temporal Sentence Grounding (RaTSG) network.  The network consists of two main modules: a multi-granularity relevance discriminator and a relation-aware segment grounding module. The relevance discriminator determines if a query is relevant to a video by assessing relevance at both the frame and video levels. If the query is relevant, the segment grounding module then identifies the precise temporal segment in the video that matches the query. If the query is not relevant, the grounding module does not produce any results.", "section": "3.3 Multi-Granularity Relevance Discriminator"}, {"figure_path": "eOonmxzzno/figures/figures_18_1.jpg", "caption": "Figure 8: Performance Comparison across different models at varying sample quantity ratios.", "description": "This figure presents a performance comparison of several models on the task of temporal sentence grounding with relevance feedback (TSG-RF). The x-axis represents the ratio of samples without grounding results to samples with grounding results in the test set.  The y-axis shows the mean Intersection over Union (mIoU), a metric evaluating the accuracy of segment localization.  The results demonstrate that as the proportion of samples without grounding results increases, the performance of all models improves, but RaTSG (the proposed model) shows the most significant improvement. This highlights RaTSG's ability to effectively handle the TSG-RF task, especially in situations where a significant portion of the data lacks relevant segments.", "section": "4.3 Ablation Studies"}]