[{"type": "text", "text": "Stabilizing Linear Passive-Aggressive Online Learning with Weighted Reservoir Sampling ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Skyler Wu Booz Allen Hamilton Harvard University Stanford University wu_skyler@bah.com ", "page_idx": 0}, {"type": "text", "text": "Fred Lu Booz Allen Hamilton University of Maryland, Baltimore County lu_fred@bah.com ", "page_idx": 0}, {"type": "text", "text": "Edward Raff James Holt Booz Allen Hamilton Laboratory for Physical Sciences University of Maryland, Baltimore County holt@lps.umd.edu raff_edward@bah.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Online learning methods, like the seminal Passive-Aggressive (PA) classifier, are still highly effective for high-dimensional streaming data, out-of-core processing, and other throughput-sensitive applications. Many such algorithms rely on fast adaptation to individual errors as a key to their convergence. While such algorithms enjoy low theoretical regret, in real-world deployment they can be sensitive to individual outliers that cause the algorithm to over-correct. When such outliers occur at the end of the data stream, this can cause the final solution to have unexpectedly low accuracy. We design a weighted reservoir sampling (WRS) approach to obtain a stable ensemble model from the sequence of solutions without requiring additional passes over the data, hold-out sets, or a growing amount of memory. Our key insight is that good solutions tend to be error-free for more iterations than bad solutions, and thus, the number of passive rounds provides an estimate of a solution\u2019s relative quality. Our reservoir thus contains $K$ previous intermediate weight vectors with high survival times. We demonstrate our WRS approach on the Passive-Aggressive Classifier (PAC) and First-Order Sparse Online Learning (FSOL), where our method consistently and significantly outperforms the unmodified approach. We show that the risk of the ensemble classifier is bounded with respect to the regret of the underlying online learning method. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Online learning algorithms are especially attractive when working with high-volume and highdimensional streaming data, out-of-core processing, and other throughput-sensitive applications [1]. For example, the seminal Vowpal Wabbit uses importance-weighted online learning algorithms [2] to reach high quality solutions quickly, with an optional second pass using LBFGS to refine the solution. The MOA library still uses the Pegasos algorithm as its linear classifier [3]. Most relevantly, online learning algorithms are particularly appealing for binary classification tasks, such as web spam classification [1]. Such algorithms often enjoy fast theoretical convergence rates due to their fast adaptation to errors on individual data points, as opposed to batch or offline learning. ", "page_idx": 0}, {"type": "text", "text": "However, in real-world deployment, online algorithms can be very sensitive to noisy observations in the data stream and over-correct, resulting in out-of-sample performance dropping precipitously between timesteps. Indeed, in many cases (see Figure 1), an online learning algorithm might achieve over $90\\%$ test accuracy after a given timestep, but then see its test accuracy drop by $20-30\\%$ after over-correcting on the next observation in the data stream. In many real-world settings, it may be infeasible computationally or memory-wise to maintain a hold-out evaluation set to select the highest-performance solutions learned by our online algorithm. It may also be practically infeasible to train our classifier over multiple passes of a given dataset or when online algorithms are used for \u201cany-time\u201d ready predictions. ", "page_idx": 0}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/8672643ec738484a960f387843b3f01c2b5b9b9d45d5df41b2bd3e359ea691b5.jpg", "img_caption": ["Figure 1: Test accuracies $y$ -axis) over timestep ( $x$ -axis) for PAC-WRS and FSOL-WRS on Avazu (App) and News20. Light grey lines: test accuracies of the baseline methods \u2014 PAC or FSOL \u2014 at each timestep. Solid black lines: test accuracies of the \u201coracle\" models, computed as the cumulative maximum of the baselines. Solid blue lines: test accuracies of WRS-enhanced models. Note massive fluctuations of grey lines and stability of blue lines. All variants shown are using standard sampling weights for WRS, with simple-averaging. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In this paper, we introduce a weighted reservoir sampling (WRS) [4] based approach that dramatically mitigates the aforementioned accuracy fluctuations. Our proposed method, WRS-Augmented Training (WAT), neither requires a hold-out evaluation set nor additional passes over the training data. Most importantly, WAT can be used to stabilize any passive-aggressive online learning algorithm. We demonstrate the promise of our WAT method on the Passive Aggressive Classifier (PAC) [5] and First-Order Sparse Online Learning (FSOL) [1] methods \u2014 creating two new methods PAC-WRS and FSOL-WRS. Strikingly, across 16 benchmark datasets, WAT is able to mitigate test accuracy fluctuations in all 16 datasets on FSOL and 14 datasets on PAC. To analyze the theoretical effectiveness of our method, we situate our approach in the online-to-batch conversion literature, enabling us to obtain generalization bounds on i.i.d. data streams. ", "page_idx": 1}, {"type": "text", "text": "2 Review of related work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Our work is motivated in part by a real-world need in malware detection [6], in which large datasets make online methods particularly attractive [7, 8], and a naturally noisy labeling process inhibits standard passive-aggressive methods [9, 10, 11, 12]. We show results for the EMBER malware benchmark in Appendix C. ", "page_idx": 1}, {"type": "text", "text": "Online learning. In online learning for linear binary classification, one maintains a solution vector $\\mathbf{w}_{t}\\in\\mathbb{R}^{D}$ , where $D$ is the dimensionality of our data points (usually quite large), and $t$ represents the timestep. At each timestep $t$ , we observe a single observation $\\left(\\pmb{x}_{t},y_{t}\\right)$ from a high-throughput data stream, with feature vector $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathbb{R}^{D}$ and class label $y_{t}\\in\\{+1,-1\\}$ . Given $\\left(\\pmb{x}_{t},y_{t}\\right)$ , an online learning algorithm will make a minor (potentially no effect) update to ${\\bf w}_{t}$ to output $\\mathbf{w}_{t+1}$ , before receiving the next $(\\pmb{x}_{t+1},y_{t+1})$ in the data stream. The classification rule using ${\\bf w}_{t}$ on any test point $x^{*}$ is simply $\\hat{y}^{*}=\\mathrm{sign}(\\mathbf{w}_{t}^{\\top}\\mathbf{x}^{*})$ . The goal is that as $t\\to\\infty$ , the sequence of ${\\bf w}_{t}$ will enjoy low cumulative loss. Towards this end, many online learning algorithms with various update rules have been proposed in the literature, including the Passive-Aggressive Classifier (PAC) [5], the Adaptive Regularization of Weight Vectors (AROW) methods [13] and the Adaptive Subgradient method (ADAGRAD) [14]. Some online learning algorithms have also been designed to specifically learn sparse solutions for ${\\bf w}_{t}$ (proportion of zero entries), such as Truncated Gradient method [15], Stochastic MIrror Descent Algorithm made Sparse method (SMIDAS) [16], Regularized Dual Averaging (RDA) method [17], and First-Order and Second-Order Sparse Online Learning methods (FSOL and SSOL) [1]. In general, these sparsity-inducing methods are powered by some combination of solution truncation and L1 norm minimization. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Passive-aggressive online learning. Within the family of online learning algorithms, a passiveaggressive algorithm is one whose update rule makes no update to ${\\bf w}_{t}$ if $(\\pmb{x}_{t},y_{t})$ is classified correctly with sufficient margin. That is, we passively leave $\\mathbf{w}_{t+1}\\;=\\;\\mathbf{w}_{t}$ . If a margin error occurs, we aggressively update $\\mathbf{w}_{t+1}$ such that the error is fully correct (though a regularization penalty $C$ will tamper the degree of aggressiveness). Usually, correct classification with sufficient margin is defined using the hinge loss $\\ell$ \u2014 the algorithm remains passive at timestep $t$ if $\\ell\\left(\\mathbf{w}_{t};(x_{t},y_{t})\\right)=$ max $\\left(1-y_{t}\\mathbf{w}_{t}^{\\top}\\mathbf{x}_{t},0\\right)=0$ . Next, we introduce the two passive-aggressive algorithms that we will use to test our WRS-Augmented Training method. ", "page_idx": 2}, {"type": "text", "text": "Passive-Aggressive Classifier $(P A C)$ . Introduced by Crammer et al., PAC is actually a family of three algorithms: PA, PA-I, and PA-II [5]. The base PA algorithm update rule seeks to solve the following constrained optimization problem: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbf{w}_{t+1}=\\mathop{\\operatorname{arg\\,min}}_{\\mathbf{w}\\in\\mathbb{R}^{D}}\\frac{1}{2}\\|\\mathbf{w}-\\mathbf{w}_{t}\\|^{2}~\\mathrm{~s.t.~}~\\ell(\\mathbf{w};(\\mathbf{x}_{t},y_{t}))=0.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Because of the hard constraint of forcing $\\mathbf{w}_{t+1}$ to satisfy $\\ell(\\mathbf{w};(\\mathbf{x}_{t},y_{t}))\\,=\\,0$ , the optimization is particularly vulnerable to noisy data. As such, Crammer et al. introduce a new constrained optimization function with a slackness hyperparameter $C_{e r r}$ to allow for some residual hinge loss and induce less aggressive, but presumably more stable updates: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbf{w}_{t+1}=\\mathop{\\mathrm{arg\\,min}}_{\\mathbf{w}\\in\\mathbb{R}^{D}}\\frac{1}{2}\\|\\mathbf{w}-\\mathbf{w}_{t}\\|^{2}+C_{e r r}\\epsilon^{m}\\;\\mathrm{~s.t.~}\\;\\ell(\\mathbf{w};(\\boldsymbol{x}_{t},y_{t}))\\leq\\epsilon\\;\\mathrm{and}\\;\\;\\epsilon\\geq0,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where setting $m=1$ corresponds to PA-I and $m=2$ to PA-II. From initial testing, PA-I and PA-II performed very similarly, with a slight edge to PA-II. As such, for this paper, we will focus on PA-II, which performs the following closed-form update when in aggressive mode [5]: $\\mathbf{w}_{t+1}\\,=$ $\\mathbf{w}_{t}+\\frac{\\ell(\\mathbf{w}_{t};(\\pmb{x}_{t},y_{t}))}{\\|\\pmb{x}_{t}\\|^{2}+\\frac{1}{2C_{e r r}}}y_{t}\\pmb{x}_{t}$ . For the remainder of this paper, \u201cPAC\" will refer to PA-II. ", "page_idx": 2}, {"type": "text", "text": "First-Order Sparse Online Learning (FSOL). Introduced by Zhao et al. [1], FSOL is a passiveaggressive algorithm which attempts to find sparse solutions for ${\\bf w}_{t}$ . Governed by a learning rate $\\eta$ and a sparsity parameter $\\lambda$ , FSOL keeps track of two vectors $\\pmb{\\theta}_{t}$ $\\mathbf{\\Omega},\\mathbf{w}_{t}\\in\\mathbb{R}^{D}$ and performs the following update rules when in aggressive mode [1]: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\theta_{t+1}=\\theta_{t}+\\eta y_{t}x_{t};\\;\\;\\mathbf{w}_{t+1}=\\mathrm{sign}(\\theta_{t+1})\\odot[|\\theta_{t+1}|-\\lambda_{t}]+,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\lambda_{t}=\\eta\\lambda$ and $[{\\pmb v}]_{+}$ takes the maximum of each element in $\\pmb{v}$ and 0. Zhao et al. note that the above update rules are identical to that of Xiao\u2019s RDA method with soft 1-norm regularization [17, 1]. ", "page_idx": 2}, {"type": "text", "text": "Weighted Reservoir Sampling (WRS). Suppose we have a collection of items $V=\\{\\pmb{v}_{1},\\dots,\\pmb{v}_{T}\\}$ , with corresponding nonnegative weights $w_{1},\\dots,w_{T}$ . Our goal is to collect a size- $K$ weighted random sample from $V$ in one pass (imagine this process is indexed by time), where the population size $T=|V|$ is potentially unknown. Introduced by Efraimidis and Spirakis [4], weighted random sampling with a reservoir, which we shorten to weighted reservoir sampling (WRS), is an algorithm that allows us to collect such a size- $K$ weighted random sample under the aforementioned conditions. Specifically, as we are making our one pass through the items in $V$ , at each timestep $t$ , we maintain and update a reservoir \u2014 a temporary storage unit with a maximum capacity of $K$ items, with each item in the reservoir a potential candidate for our final size- $K$ sample. At time $T$ , the $K$ items that are currently in the reservoir will constitute our sample of size- $K$ . We invite the interested reader to look at Algorithm A in [4] for specific details. ", "page_idx": 2}, {"type": "text", "text": "Online-to-batch conversion. Online learning algorithms such as PAC generally do not impose any restrictions on the distribution of the training data sequence. Their regret bounds aim to control the cumulative loss $M_{T}$ of the algorithm over any sequence of data, compared with a minimal-loss fixed model w\u02c6: $\\begin{array}{r}{\\mathrm{reg}_{T}:=\\sum_{t=1}^{T}\\bar{\\ell(\\mathbf{w}_{t};z_{t})}-\\sum_{t=1}^{T}\\bar{\\ell(\\hat{\\mathbf{w}};z_{t})}=M_{T}-\\sum_{t=1}^{T^{*}}\\bar{\\ell}(\\hat{\\mathbf{w}};z_{t})}\\end{array}$ . When using a fixed model to classify u nseen data, we need to impose an i.i.d. assumption on the data stream in order to measure the risk, or expected generalization error, of the model. Note that the distribution $\\mathcal{D}$ itself is arbitrary and can still permit outliers or mixtures. Then the population risk is defined as $R_{\\mathcal{D}}(\\mathbf{w}):=\\mathbb{E}_{z\\sim\\mathcal{D}}[\\ell(\\mathbf{w};z)]$ . ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "To theoretically describe our algorithm, we leverage work on online-to-batch conversion, which takes an online algorithm with known regret bounds on an i.i.d. sequence of data and extracts a stable final model with low risk. For example, in the online perceptron algorithm, earlier work studied the pocket approach, which selects the longest-surviving model in the sequence as the final model [18, 19]. Other well-known approaches use the uniform average of the whole model sequence or the best-performing model over a validation set [20]. ", "page_idx": 3}, {"type": "text", "text": "As will be seen, our method generalizes these approaches to utilize multiple long-survival models as an ensemble model. Furthermore, we will introduce novel improvements, including a limitedsize reservoir with probabilistic sampling. The risk bounds for our WAT model leverage improved techniques from [21, 22]. Our experimental results also demonstrate that our novel conversion technique outperforms prior baselines (see Appendix D). ", "page_idx": 3}, {"type": "text", "text": "3 Our method: WRS-Augmented Training (WAT) ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In one extreme, if a candidate solution ${\\bf w}_{t}$ from a passive-aggressive algorithm had perfect classification with sufficient margin on any given data point, then the subsequent number of passive steps taken after time $t$ (i.e., number of timesteps that our algorithm is in passive mode before going aggressive again) would be infinite. In the other extreme, if a candidate solution $\\mathbf{w}_{t}$ had extremely low performance, then our passive-aggressive algorithm is likely to go aggressive very soon after time $t$ , implying a very small subsequent number of passive steps after time $t$ . In short, our key insight is that high-performing solutions $\\mathbf{w}_{t}$ tend to be error-free for more iterations than low-performing solutions. As such, the subsequent number of passive steps taken after the formation of ${\\bf w}_{t}$ provides an estimate of ${\\bf w}_{t}$ \u2019s relative quality (i.e., test accuracy). ", "page_idx": 3}, {"type": "text", "text": "However, we do not want to take the intermediate solution ${\\bf w}_{t}$ that had the most passive updates as this, too, can be noise (and luck) sensitive. Ideally, we would like to sample from the merging distribution of ${\\bf w}_{t}$ as they occur, and take an average of those solutions to obtain a singular, highly robust, solution vector that performs well with little variance. But, we do not wish to store all $\\mathbf{w}_{t}$ due to intractability. ", "page_idx": 3}, {"type": "text", "text": "Putting these thoughts together, our WRS-Augmented Training (WAT) method functions as follows. Given a base passive-aggressive algorithm (e.g., PAC or FSOL), we will run said algorithm through our data stream $\\{(\\mathbf{\\boldsymbol{x}}_{t},\\boldsymbol{y}_{t})\\}_{t=1}^{\\top}$ , as normal, but keep a size- $K$ reservoir of promising candidate solutions. The reservoir approach allows us to run through our data stream and collect a weighted random sample of candidate solutions of size- $\\mathcal{K}$ , weighted by their subsequent number of passive steps and without storing all intermediate solutions. ", "page_idx": 3}, {"type": "text", "text": "Naturally, this setup is suited for Efraimidis and Spirakis\u2019s WRS algorithm. Procedurally, every timestep that our algorithm goes aggressive, we obtain a new active candidate solution. Right before we apply our aggressive mode update rule, we will add the outgoing candidate solution to our size- $K$ reservoir (and remove a current resident of the reservoir, if necessary) following the steps of the WRS algorithm. At any timestep $t$ , we can form an ensemble solution $\\mathbf{W}\\mathbf{R}\\mathbf{S}$ by taking an average of the candidate solutions currently in our reservoir. Hopefully, at any timestep $t$ , wWRS will have more stable test performance than the current active candidate solution ${\\bf w}_{t}$ . ", "page_idx": 3}, {"type": "text", "text": "3.1 WAT variants ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We will experiment with a few additional variants of the WAT method. First, instead of weighting using the subsequent number of passive steps (which we denote as standard weights), what if we weight using the exponentiated subsequent number of passive steps (which we denote as exponential weights)? The idea with exponential weights is that it is closer in practice to deterministically picking the candidate solutions with the largest number of subsequent passive steps, while still maintaining some stochasticity \u2014 i.e., a \u201cgreedier\" policy. Second, when constructing our ensemble solution ", "page_idx": 3}, {"type": "text", "text": "Input: w - initial solution vector, $\\{(\\mathbf{\\boldsymbol{x}}_{t},y_{t})\\}_{t=1}^{T}$ - data stream, $K$ - reservoir size, WS - weighting   \nscheme (\u201cStandard\" or \u201cExponential\"), AS - averaging scheme (\u201cSimple Average\" or \u201cWeighted   \nAverage\"), VZ - voting-based zeroing (True or False), and other base-method-specific hyperpa  \nrameters $\\mathcal{H}$ (e.g., for PAC or FSOL)   \nOutput: WRS-stabilized solution vector wWRS.   \n1: function WAT(w, $\\{(\\mathbf{\\boldsymbol{x}}_{t},y_{t})\\}_{t=1}^{T}$ ; K, WS, AS, VZ, H)   \n2: # Initializing intermediate data structures   \n3: $s\\to0$ $\\triangleright$ Counter for subsequent passive steps of current solution candidate   \n4: $\\mathcal{R}\\rightarrow[]$ $\\triangleright$ Size- $K$ reservoir for storing promising solutions, as array   \n5: $b,\\mathbf{k}\\rightarrow[],[]$ \u25b7Size- $\\cal{K}$ arrays for weights $b_{r}$ and auxiliary $k_{r}$ values for solutions in $\\mathcal{R}$   \n6: # At each timestep, we observe $\\left(\\pmb{x}_{t},y_{t}\\right)$   \n7: for $t\\gets1$ to $T$ do   \n8: if $\\ell(\\mathbf{w};\\mathbf{x}_{t},y_{t})>0$ then $\\triangleright$ If made error, in aggressive mode   \n9: # Terminate current solution, probabilistically add to reservoir using WRS [4]   \n10: Draw $u^{*}\\sim\\mathrm{Unif}(0,1)$   \n11: if $\\mathrm{WS==}$ \u201cStandard\u201d then   \n12: $b^{*}\\leftarrow s$   \n13: else if $\\mathrm{WS==}$ \u201cExponential\u201d then   \n14: $b^{*}\\leftarrow\\exp(s)$   \n15: $k^{*}\\gets\\left(u^{*}\\right)^{\\frac{1}{b^{*}+\\epsilon}}$ \u25b7 $\\epsilon=10^{-8}$ to prevent division by 0   \n16: $\\tau\\gets\\operatorname*{min}_{j\\in1,\\dots,K}\\mathbf{k}[j]$ ; $i\\gets\\mathrm{arg\\,min}_{j\\in1,\\dots,K}\\,\\mathbf{k}[j]$   \n17: if $k^{*}>\\tau$ or $\\mathcal{R}$ is not full with $K$ solutions then   \n18: $\\mathcal{R}[i]\\leftarrow\\mathbf{w},b[i]\\leftarrow b^{*},\\mathbf{k}[i]\\leftarrow k^{*}$   \n19: # Base method update rule   \n20: $\\begin{array}{l}{\\mathbf{w}\\leftarrow\\mathbf{w}+g(\\dots)}\\\\ {s\\leftarrow0}\\end{array}$ $\\mathsf{\\sf~\\sf~p}\\left(\\cdot\\cdot\\cdot\\right)$ specific to base algorithm (e.g., PAC or FSOL)   \n21: \u25b7Reset number of subsequent passive steps   \n22: else $\\triangleright$ correctly-classified, still in passive mode   \n23: $s\\gets s+1$ $\\triangleright$ Increment number of subsequent passive steps   \n24: # Forming our PAC-WRS solution   \n25: if $\\mathrm{AS==}$ \u201cSimple Average\u201d then   \n26: $\\begin{array}{r}{\\mathbf{w}_{\\mathrm{WRS}}\\leftarrow\\frac{1}{K}\\!\\sum_{j=1}^{K}\\mathcal{R}[j]}\\end{array}$ $\\triangleright$ Simple average of solutions in reservoir   \n27: else if $\\mathrm{AS==}$ \u201cWeighted Average\u201d then   \n28: $\\begin{array}{r}{\\mathbf{w}_{\\mathrm{WRS}}\\leftarrow\\sum_{j=1}^{K}\\bar{\\mathbf{b}}[j]\\mathcal{R}[j]/(\\bar{\\sum}_{j=1}^{K}\\mathbf{b}[j])}\\end{array}$ $\\triangleright$ Weighted avg. of solutions in reservoir   \n29: # Voting-based zeroing for extra sparsity   \n30: if VZ is True then   \n31: Zero out entries in wWRS where the majority of solutions $\\mathcal{R}[j]$ contain zeroes.   \n32: Return wWRS. ", "page_idx": 4}, {"type": "text", "text": "wWRS, should we take a simple average of the residents in our reservoir or a weighted average? Third, there are reasonable concerns that constructing wWRS via averaging might negate the sparsity advantages of a method like FSOL, due to different candidates in the reservoir containing 0s in different entries. However, if the majority of candidate solutions in the reservoir contain 0s at a given entry, what if we tried zeroing out said entry in wWRS, as it is likely to be uninformative? We denote this add-on as voting-based zeroing. ", "page_idx": 4}, {"type": "text", "text": "We present the WAT method in full detail in Algorithm 1. To clarify, the elements in the data structures $\\mathcal{R}$ , $\\mathbf{b}$ , and $\\mathbf{k}$ (all of which are size- $.K$ arrays) are paired with each other, so that when we add/remove an element in $\\mathcal{R}$ , the corresponding elements in b and $\\mathbf{k}$ are removed as well. To be fully clear, $\\mathcal{R}$ contains candidate solution vectors ${\\bar{\\mathcal{R}}}[1],\\ldots,{\\mathcal{R}}[K]$ , with each $\\mathcal{R}[k]\\in\\mathbb{R}^{D}$ . The vector $^{b}$ contains scalar values $b[1],\\dots,b[K]$ , and likewise for the vector $\\mathbf{k}$ . ", "page_idx": 4}, {"type": "text", "text": "3.2 Theoretical Analysis ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "One of the goals of our method is to choose a set of effective models as the algorithm runs live, without the need for expensive evaluation on a validation set. In this section we first provide validity arguments for using observed survival as a proxy to select high-accuracy models. These are finitesample bounds based on reasoning about the reservoir $\\mathcal{R}$ . Note that we are interested in studying generalization to unseen data, a complementary setting to prior work which shows convergence in terms of training set error for the perceptron model [19]. After establishing validity, we will turn to learning bounds for our ensemble model risk in the i.i.d. setting. Proofs are deferred to Appendix A. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Validity analysis. We assume a given dataset $\\boldsymbol{z}_{1}^{T}=\\{\\boldsymbol{z}_{t}\\}_{t=1}^{T}$ is an i.i.d. sequence sampled from a generating distribution $\\mathcal{D}$ . We first suppose that $\\ell(\\mathbf{w};z)$ is the 0-1 loss, that is $\\ell(\\mathbf{w};(x,y))=\\mathbb{1}(\\hat{y}\\neq$ $y)$ . Then the risk $R_{D}(\\mathbf{w})$ is the probability that a random $z\\sim\\mathcal{D}$ is misclassified by w. At any time $t$ , we have an online model ${\\bf w}_{t}$ , for which we define the survival time $s_{\\mathbf{w}_{t}}$ to be the number of subsequent correct classifications, stopping when ${\\bf w}_{t}$ misclassifies a sample. As ${\\bf w}_{t}$ does not change until an error occurs, at any finite time we only collect $K$ updated models $\\{\\mathbf{w}^{(j)}\\}_{j=1}^{K}$ into $\\mathcal{R}$ . ", "page_idx": 5}, {"type": "text", "text": "Our first result bounds the difference in risk among two models in $\\mathcal{R}$ : (1) the minimal-risk hypothesis $\\tilde{\\mathbf{w}}\\,=\\,\\arg\\operatorname*{min}_{\\mathbf{\\boldsymbol{R}}\\_{\\mathbf{\\boldsymbol{D}}}}(\\mathbf{w}^{(j)})$ which we do not know, and (2) the longest-surviving hypothesis $\\mathbf{w}_{s}\\,=$ $\\arg\\operatorname*{min}{s_{\\mathbf{w}^{(j)}}}$ which we observe. We also denote $S_{\\mathbf{\\tilde{w}}}$ and $s_{\\mathbf{w}_{s}}$ to be their respective survival times. ", "page_idx": 5}, {"type": "text", "text": "Theorem 1. Let $\\mathbf{w}^{(1)},\\ldots,\\mathbf{w}^{(k)}\\in\\mathcal{R}$ be the updated outputs of an online PA algorithm on inputs $Z_{1}^{T}\\sim\\mathcal{D}$ . Also define $r_{m}$ as the minimal achievable risk of any model, such that $r_{m}\\,\\leq\\,R_{\\mathcal{D}}(\\tilde{\\mathbf{w}})$ almost surely. Then ", "page_idx": 5}, {"type": "equation", "text": "$$\nP(R_{\\mathcal{D}}(\\mathbf{w}_{s})>R_{\\mathcal{D}}(\\Tilde{\\mathbf{w}})+\\varepsilon)\\leq\\operatorname*{min}\\left\\{K\\frac{r_{m}}{2r_{m}+\\varepsilon-r_{m}(r_{m}+\\varepsilon)},e^{-r_{m}^{K}(r_{m}+\\varepsilon)}\\right\\}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "This immediately leads to ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{Corollary\\_1.}\\ \\ W i t h\\ p r o b.\\ 1-\\delta,\\ R_{D}(\\mathbf{w}_{s})\\leq R_{D}(\\Tilde{\\mathbf{w}})+\\operatorname*{min}\\bigg\\{\\frac{1-\\delta-r_{m}^{K+1}}{r_{m}^{K}},\\frac{r_{m}(K-\\delta(2-r_{m}))}{\\delta(1-r_{m})}\\bigg\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "While this bound explains the use of top-1 survival in the worst case, we further justify the use of an ensemble (or reservoir) of top-surviving models. Specifically, given the use of top- $B$ models, there is always a certain probability that the top- $(B+1)$ can lower the risk. Since $B=1$ is a base case, this implies that any value of $B$ is worthy of consideration, until this probability decays to 0. ", "page_idx": 5}, {"type": "text", "text": "To simplify the notation, we sort the models in $\\mathcal{R}$ by decreasing survival time $s_{1}^{\\prime},\\ldots,s_{k}^{\\prime}$ , with corresponding re-indexed weights $w_{1}^{\\prime},\\dots,w_{k}^{\\prime}$ and risks $R_{1}^{\\prime},\\ldots,R_{k}^{\\prime}$ . We also add an assumption, that there is a partition of $\\mathcal{R}=\\mathcal{R}_{g}\\cup\\mathcal{R}_{b}$ such that $\\mathcal{R}_{g}=\\{\\overset{\\cdot}{\\mathbf{w}}\\in\\mathcal{R}:\\ddot{r}_{m}\\leq R_{\\mathcal{D}}(\\mathbf{w})\\leq r_{m}+\\varepsilon\\}$ and $\\mathcal{R}_{b}=\\{\\mathbf{w}\\in\\mathcal{R}:r_{m}+\\varepsilon<R_{\\mathcal{D}}(\\mathbf{w})\\leq r_{m}+3\\varepsilon\\}$ , and that $|\\mathcal{R}_{b}|\\ge B$ . That is, there is a set of good and bad models in terms of risk. In the Appendix we show that the assumption is readily satisfied. ", "page_idx": 5}, {"type": "text", "text": "Theorem 2. Let $\\bar{R}_{\\ensuremath{\\mathcal \u1e0a D \u1e0c }}(\\mathbf{w}_{B})$ be the averaged risk of the top- $B$ surviving models, and let $\\bar{R}_{\\cal D}({\\bf w}_{B+1})$ be the averaged risk including the next highest survival model. Then $\\bar{R}_{\\mathcal{D}}(\\mathbf{w}_{B+1})\\leq\\bar{R}_{\\mathcal{D}}(\\mathbf{w}_{B})$ with probability at least $|\\mathcal{R}_{g}|\\binom{|\\mathcal{R}_{b}|}{B}r_{m}^{2}(r_{m}+3\\varepsilon)^{|\\mathcal{R}_{b}|-B}(1-r_{m}-3\\varepsilon)^{B}$ . ", "page_idx": 5}, {"type": "text", "text": "Finally note that we can define an averaged model (weighted or unweighted) $\\bar{\\bf w}_{B}$ . For any convex $\\ell_{h}(\\mathbf{w};z)$ with risk $R_{\\mathcal{D}}^{h}$ , such as the hinge loss, Jensen\u2019s inequality gives $\\bar{R}_{\\mathcal{D}}^{h}(\\bar{\\mathbf{w}}_{B+1})\\leq\\bar{R}_{\\mathcal{D}}(\\mathbf{\\dot{w}}_{B+1})$ . ", "page_idx": 5}, {"type": "text", "text": "Learning bounds. Now we turn to generalization bounds of our method, when run to a fixed stopping time $T$ . We assume more generally that $\\ell(\\mathbf{w};z)$ is convex, such as the hinge loss. Furthermore we suppose that the loss of any point in the training set is bounded by $C$ . This is a safe assumption for many passive-aggressive algorithms, where the input data is normalized and the update steps are not too large. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3. Suppose $\\ell$ is convex and bounded from above by $C$ . By time $T$ , suppose the reservoir contains $K_{T}$ models, with survival time of each at least $s_{T}$ . Let $\\begin{array}{r}{M_{w r s}=\\sum_{t=1}^{T}\\pi_{t}\\ell(\\mathbf{w}_{t-1};z_{t})}\\end{array}$ be the cumulative loss of the WAT reservoir sequence, with $\\pi_{t}$ formally defined in the proof. Then w.p. $1-\\delta$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\nR_{\\mathcal{D}}(\\mathbf{w}_{w r s})\\leq\\frac{M_{w r s}}{K_{T}s_{T}}+\\sqrt{\\frac{2C\\log\\left(\\frac{T}{\\delta}\\right)M_{w r s}}{(K_{T}s_{T})^{2}}}+\\frac{7C\\log\\left(\\frac{T}{\\delta}\\right)}{K_{T}s_{T}}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The result shows that the risk of the ensemble model is stochastically bounded by the cumulative loss of the online procedure. By applying known regret bounds for the underlying online algorithms (e.g. PAC or FSOL), we can further bound the risk in terms of the original learner, and subsequently the optimal risk. In particular, we can \u201cabstract out\u201d the actual online learning method in the proof, as a generic regret bound of\u221a form $\\begin{array}{r}{\\frac{M_{T}}{T}\\,\\leq\\,\\frac{1}{T}\\sum_{t=1}^{T}\\ell(\\mathbf{w};z_{t})\\,+\\,\\frac{r(T)}{T}}\\end{array}$ , for any w. Depending on the algorithm often $r(T)=O({\\sqrt{T}})$ or even $O(1)$ . ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "With this in hand, we can show that the risk actually approaches the minimal risk. One additional assumption is required: $\\begin{array}{r}{M_{w r s}/\\sum_{t=1}^{T}\\pi_{t}\\leq\\frac{1}{T}\\sum_{t}\\ell(\\mathbf{w}_{t-1};z_{t})=\\frac{M_{T}}{T}}\\end{array}$ (the WRS sequence has lower cumulative loss than the original learner). By definition, the reservoir contains the models which have longest survivals, and hence lowest regret density. So this statement is readily satisfied, as long as the distributions of non-zero losses are not different among the two sequences. In fact, under certain conditions, the inequality is likely strict which further improves the bound. Altogether we obtain: ", "page_idx": 6}, {"type": "text", "text": "Theorem 4. Given a PA algorithm, let $M_{T}$ be its cumulative loss, and $r(T)$ be the algorithm-specific excess regret. Then with probability $1-\\delta$ , the deviation in risk of our WRS model $\\mathbf{w}_{w r s}$ from the optimal model $\\mathbf{w}^{*}$ is bounded as ", "page_idx": 6}, {"type": "equation", "text": "$$\nR_{\\mathcal{D}}(\\mathbf{w}_{w r s})\\leq R_{\\mathcal{D}}(\\mathbf{w}^{*})+\\frac{r(T)}{T}+\\sqrt{\\frac{2C\\log\\left(\\frac{2T}{\\delta}\\right)M_{T}}{T K_{T}s_{T}}}+\\frac{7C\\log\\left(\\frac{2T}{\\delta}\\right)}{K_{T}s_{T}}+C\\sqrt{\\frac{\\log\\left(\\frac{2}{\\delta}\\right)}{2T}}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "table", "img_path": "FNOBf6JM7r/tmp/b05b3bd1b80be6f4f76bd4a681430e3202df321ea504864e746b3ee3231f4b6a.jpg", "table_caption": ["Table 1: Sizes, dimensions, and sparsities of all datasets used for numerical experiments. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "4 Numerical experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We combine WAT with base PAC and FSOL, forming two new methods PAC-WRS and FSOL-WRS1. We evaluate their performances across 16 binary classification datasets listed in Table 1. Please see Appendix B for more dataset details. We are interested in three metrics: 1) Final test accuracy: proportion of test set data points correctly-classified by solution obtained after making one pass through the training data. 2) Final sparsity: proportion of zeroes in our classification solution obtained after making one pass through the training data. 3) Relative oracle performance (ROP): let $p_{t,\\mathrm{base}}$ be the test accuracy of our base model (either PAC or FSOL) at time $t$ and $p_{t}$ be the test accuracy of our model of interest (either base PAC, base FSOL, PAC-WRS, or FSOL-WRS). Then, define $p_{t,\\mathrm{oracle}}\\;=\\;\\mathrm{max_{base}}\\:p_{t,\\mathrm{base}}$ to be the cumulative maximum test accuracy of the base method at time $t$ . In other words, $p_{t}$ ,oracle represents the highest performance we could obtain if we had an oracle telling us which candidate solution vector we encountered was best. Then, define $\\begin{array}{r}{\\mathrm{ROP}=\\frac{1}{T}\\sum_{t=1}^{\\top}(p_{t,\\mathrm{oracle}}-p_{t})}\\end{array}$ . Intuitively, if a method has very stable test accuracy over time with minimal fluctuations, then ROP should be close to 0, or negative (i.e. achieving a higher test accuracy than the oracle). In contrast, a large, positive ROP suggests fluctuations in test accuracy. ", "page_idx": 6}, {"type": "text", "text": "Because we are interested in the stability of WAT\u2019s test-set accuracy over the entirety of the training run, it is most illustrative to look at figures when possible. Representative figures will be shown in the main paper, with all figures for all datasets in the appendix. When running any algorithm (PAC, FSOL, PAC-WRS, or FSOL-WRS) on any dataset, we perform a random 70/30 train-test split. We begin by tuning the $C_{e r r}$ , $\\eta$ , and $\\lambda$ hyperparameters for base PAC and FSOL, with details located in Appendix B. For PAC-WRS and FSOL-WRS, we use the hyperparameters for the corresponding base models, but try all possible WAT variants of weighting scheme (standard or exponential), averaging scheme (simple vs. weighted), voting-based zeroing (True or False), and reservoir size $K\\in\\{\\bar{1},\\bar{4},16,64\\}$ . We perform five trials for each PAC-WRS and FSOL-WRS variant with randomized shuffles of the training and test data, running through the training data only once for each trial. All candidate solutions are initialized as the 0 vector. Please see more experimental details in Appendix B. ", "page_idx": 6}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/1df6bb796177f22ae946a08ce8992724df6903354a29b85d62388df697646c3a.jpg", "img_caption": ["Figure 2: Relative oracle performances $y$ -axis) of base PAC and PAC-WRS using standard weights over reservoir sizes $K$ ( $x$ -axis) on 3 representative datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. Blue: WRS-augmented variants via simple average of reservoir members. Red: WRS-augmented variants via weighted average of reservoir members. Dotted lines: indicates voting-based zeroing was performed for additional sparsity. Lower values indicate more stable performance. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "4.1 Stabilizing test performance ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Figure 1 shows visually how PAC-WRS and FSOL-WRS are highly-effective at stabilizing base PAC and FSOL\u2019s wildly-fluctuating test accuracy on Avazu (App) and News20. Corresponding figures for all 16 datasets and PAC-WRS/FSOL-WRS variants can be found in Appendix G.2. From Figure 2, we see that PAC-WRS is highly-effective at reducing ROP compared to base PAC, and that the larger the reservoir size $K$ , the more stable the resultant test accuracy for wWRS becomes. Furthermore, looking more carefully at MNIST8 $(4\\!+\\!9)$ , we observe that many PAC-WRS variants were able to achieve negative ROP values, suggesting that wWRS could achieve higher test accuracies than even the oracle. Corresponding figures for all 16 datasets can be found in Appendix G.1. ", "page_idx": 7}, {"type": "text", "text": "From Table 2, we observe that FSOL-WRS with standard weights and simple averaging successfully stabilized test accuracy in all 16 tested datasets compared to base FSOL, as measured via ROP. ", "page_idx": 7}, {"type": "text", "text": "PAC-WRS with exponential weights and simple averaging successfully stabilized test accuracy in 14 of 16 tested datasets compared to base PAC. Following the best practices in [38, 39], we perform Wilcoxon signed-rank tests for sta", "page_idx": 7}, {"type": "text", "text": "Table 2: Numbers of datasets out of 16 where each PAC-WRS or FSOL-WRS variant with $K\\,=\\,64$ outperformed its corresponding base method (PAC or FSOL), as measured by ROP averaged across 5 randomized trials. ", "page_idx": 7}, {"type": "table", "img_path": "FNOBf6JM7r/tmp/b76dc309f4ec00fe157e8feb8c4ba3752d8110f21d08e626986fc2f6b6ecdbad.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "tistical significance on the differences in ROP between PAC/FSOL-WRS versus base PAC and FSOL, taking into account performance on all 16 datasets. At a significance level of $\\alpha=0.05$ , we find that both PAC/FSOL-WRS achieve statistically-significant reductions in ROP compared to their corresponding base models when equipped with standard weights $p<0.0386$ in each case, see Table 6 in Appendix F). ", "page_idx": 7}, {"type": "text", "text": "These results also suggest that standard weights are preferable to exponential weights. This makes sense because using exponential weights may be too \u201cgreedy,\" causing the algorithm to overly trust in the number of passive steps as an indicator of test performance, polluting the reservoir with poor \u201clucky\" candidate solutions, and refusing to remove them later. ", "page_idx": 7}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/948f8457c8963586c00e6ee26b6d81eb51f6d597daab2f996339160f7bbf837c.jpg", "img_caption": ["Figure 3: Final test accuracies ( $y$ -axis) of base FSOL and FSOL-WRS using standard weights over reservoir sizes $K$ ( $x$ -axis) on 3 representative datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. See Figure 2 for legend description. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "A note on final test accuracy. From Figure 3, we see that the final test accuracies achieved by FSOL-WRS are not only higher on average than base FSOL, but also have significantly lower variance. On these datasets, there is no significant difference between FSOL-WRS variants with or without voting-based zeroing. As expected, final test accuracy seems to be higher for larger values of reservoir size $K$ . However, Wilcoxon signed-rank tests to compare PAC-WRS and FSOL-WRS\u2019s improvements in final test accuracy over base PAC and FSOL indicate that FSOL-WRS with standard weights yields a statistically-significant improvement in final test accuracy compared to base FSOL, but PAC-WRS does not compared to base PAC (see Table 7 in Appendix F). One hypothesis for this discrepancy is that it is relatively unlikely for any given training data point to cause a massive drop in test accuracy. Furthermore, subsequent data points will usually help the base model self-correct (see Appendix G.2). Thus, this explains why the base method\u2019s mean final test accuracy after a particular fixed timestep (e.g., $N_{\\mathrm{train},}$ ) will not differ significantly from that of the WRS-augmented method, especially not across only 5 trials. ", "page_idx": 8}, {"type": "text", "text": "Nonetheless, there are enough data points in the training stream that these massive fluctuations in test accuracy could still happen thousands of times throughout the training process, corroborating what we saw in Figure 1. If such a drop in test accuracy were to occur at an unlucky timestep when the model training is stopped, the consequences could be unacceptable. Furthermore, in continuously updated \u201cany-time\u201d environments, it is hard to assess if one of these drops has occurred. As such, WAT is valuable as a simple and effective way of preventing such fluctuations in test accuracy. ", "page_idx": 8}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/c5f1ca46329a9d9985e1a8cce9dbb8ad08deff3bc7b96e0218c0512b786d1c0d.jpg", "img_caption": ["Figure 4: Final sparsities $y$ -axis) of base FSOL and FSOL-WRS using standard weights over reservoir sizes $K$ ( $\\scriptstyle x$ -axis) on 3 representative datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. See Figure 2 for legend description. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Preservation of sparsity. Finally, we aim to retain the favorable weight sparsity from FSOL. From Figure 4, we observe that even with reservoir size $K=64$ , the final sparsities achieved by FSOL-WRS are quite similar to that of base FSOL. Furthermore, we observe that with voting-based zeroing, FSOLWRS often achieves even higher sparsity than the base model. Please see Appendix G.1 for additional ", "page_idx": 8}, {"type": "text", "text": "Table 3: Numbers of datasets out of 16 where each top-64 PAC or FSOL variant outperformed its corresponding base method (PAC or FSOL), as measured by relative oracle performance averaged across 5 trials. ", "page_idx": 8}, {"type": "table", "img_path": "FNOBf6JM7r/tmp/35d9b2a021c7475f2f655f35503d0efe58676be0908198cac1da656e5a3de8bd.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "errorbar-type plots and Appendix G.2 for sparsity over timestep. One explanation for why even FSOL-WRS variants without voting-based zeroing can achieve similar sparsity to base FSOL is that the final reservoir will likely contain candidate solutions from significantly earlier timesteps, when weights were sparser due to fewer aggressive updates. Thus, WAT can maintain sparsity despite the use of weight averaging. ", "page_idx": 9}, {"type": "text", "text": "4.2 Ablations and extensions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Top- $K$ ablation. A natural question that one might ask is \u2014 instead of probabilistically sampling candidate solutions, what if we deterministically picked the top- $K$ candidate solutions with the largest subsequent numbers of passive steps and took their simple and/or weighted average? Setting $K=64$ , we see from Table 3 that the best top-64 PAC/FSOL variants are not as effective as stabilizing test accuracy as the best PAC/FSOL-WRS variants, as shown in Table 2 and measured via ROP. Furthermore, Wilcoxon signed-rank test $p$ -values from Table 4 also suggest that this top-64 ablation cannot produce as statistically-significant increases in test accuracy stability compared to WAT, as measured via ROP. Like WAT, top- $K$ is also ineffective at producing statistically-significant increases in final test accuracy on PAC. On FSOL, top- $K$ can produce statistically significant increases in final test accuracy, but these $p$ -values are over an order of magnitude larger than FSOL-WRS\u2019s (see Table 7 in Appendix F). As such, WAT is still the best for stabilizing test accuracy. ", "page_idx": 9}, {"type": "table", "img_path": "FNOBf6JM7r/tmp/67e3dfb106ad42c6644ebf007447616494a79cda30c39724daf14d2c0e4744cc.jpg", "table_caption": ["Table 4: Wilcoxon signed-rank test $p$ -values testing whether differences in relative oracle performance and final test accuracy between top-64 PAC/FSOL variants and base PAC/FSOL are statistically significant. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Additional ablations and comparisons. For the interested reader, in Appendix $\\mathrm{D}$ we include empirical performance comparisons of WRS-Augmented Training against two traditional ensembling mechanisms: moving average (e.g., averaging the most-recently-observed $K=64$ weight vectors at each timestep) and exponential average (e.g., forming an ensemble vector $\\bar{\\mathbf{w}}_{t}=\\gamma\\mathbf{w}_{t}+(1-\\gamma)\\bar{\\mathbf{w}}_{t-1}$ at each timestep), where ${\\bf w}_{t}$ is the base algorithm\u2019s candidate solution at timestep $t$ . In short, especially in more real-world, large-scale settings where evaluation and checking are prohibitively expensive, WRS-Augmented Training is the fastest, most accurate, and most reliable method compared to all the aforementioned baselines. ", "page_idx": 9}, {"type": "text", "text": "Modifying WAT for non-passive aggressive methods. While the main theoretical and empirical results in this paper were primarily oriented towards passive-aggressive base models, in Appendix E, we include empirical simulations of applying a modified form of WRS-Augmented Training on top of three non-passive-aggressive online learning methods: Stochastic Gradient Descent with Momentum [40], ADAGRAD [14], and Truncated Gradient Descent [15]. In general, our modified WRS-Augmented Training effectively mitigates test accuracy when it exists, and does minimal harm when it does not. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion, limitations, and future work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we introduced WRS-Augmented Training (WAT), a procedure that can be used to stabilize any passive-aggressive online learning algorithm, neither requiring a hold-out evaluation set nor additional passes over the training data. We applied WAT to base PAC and FSOL, demonstrating across 16 datasets that WAT is highly effective at mitigating the massive fluctuations in test accuracy between timesteps that affect many online learning algorithms. WAT runs at minimal cost, with only a fixed $K$ multiple on memory for multiple weight vectors to be saved. ", "page_idx": 9}, {"type": "text", "text": "One limitation of this work is that WAT implicitly assumes that the training and test data come from fixed distributions that do not change over time. However, some data distributions will evolve over time. As such, a candidate solution that entered the reservoir early on due to having a large number of subsequent passive steps might not actually retain its performance as the data distribution evolves over time. While they may eventually be replaced, non-IID adaptions may be useful in the future. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Peilin Zhao, Dayong Wang, Pengcheng Wu, and Steven CH Hoi. A Unified Framework for Sparse Online Learning. ACM Transactions on Knowledge Discovery from Data (TKDD), 14(5):1\u201320, 2020.   \n[2] Nikos Karampatziakis and John Langford. Online Importance Weight Aware Updates, 2011.   \n[3] Albert Bifet, Geoff Holmes, Bernhard Pfahringer, Philipp Kranen, Hardy Kremer, Timm Jansen, and Thomas Seidl. Moa: Massive online analysis, a framework for stream classification and clustering. In Proceedings of the first workshop on applications of pattern analysis, pages 44\u201350. PMLR, 2010.   \n[4] Pavlos S Efraimidis and Paul G Spirakis. Weighted Random Sampling with a Reservoir. Information Processing Letters, 97(5):181\u2013185, 2006.   \n[5] Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. Online Passive-Aggressive Algorithms. Journal of Machine Learning Research, 7(19):551\u2013585, 2006.   \n[6] Edward Raff, Bobby Filar, and James Holt. Getting Passive Aggressive About False Positives: Patching Deployed Malware Detectors. In 2020 International Conference on Data Mining Workshops (ICDMW), pages 506\u2013515. IEEE, nov 2020.   \n[7] H. S. Anderson and P. Roth. EMBER: An Open Dataset for Training Static PE Malware Machine Learning Models. ArXiv e-prints, April 2018.   \n[8] Richard Harang and Ethan M. Rudd. Sorel-20m: A large scale benchmark dataset for malicious pe detection. In Proceedings of the Conference on Applied Machine Learning for Information Security, 2021.   \n[9] Robert J Joyce, Edward Raff, Charles Nicholas, and James Holt. MalDICT: Benchmark Datasets on Malware Behaviors, Platforms, Exploitation, and Packers. Proceedings of the Conference on Applied Machine Learning in Information Security, 2023.   \n[10] Robert J Joyce, Edward Raff, and Charles Nicholas. A Framework for Cluster and Classifier Evaluation in the Absence of Reference Labels. In Proceedings of the 14th ACM Workshop on Artificial Intelligence and Security (AISec \u201921). Association for Computing Machinery, 2021.   \n[11] Robert J Joyce, Edward Raff, and Charles Nicholas. Rank-1 Similarity Matrix Decomposition For Modeling Changes in Antivirus Consensus Through Time. In Proceedings of the Conference on Applied Machine Learning for Information Security, 2021.   \n[12] Robert J. Joyce, Tirth Patel, Charles Nicholas, and Edward Raff. AVScan2Vec: Feature Learning on Antivirus Scan Data for Production-Scale Malware Corpora. In Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security, AISec \u201923, page 185\u2013196, New York, NY, USA, 2023. Association for Computing Machinery.   \n[13] Koby Crammer, Alex Kulesza, and Mark Dredze. Adaptive Regularization of Weight Vectors. Machine learning, 91:155\u2013187, 2013.   \n[14] John Duchi, Elad Hazan, and Yoram Singer. Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. Journal of Machine Learning Research, 12(7), 2011.   \n[15] John Langford, Lihong Li, and Tong Zhang. Sparse Online Learning via Truncated Gradient. Journal of Machine Learning Research, 10(3), 2009.   \n[16] Shai Shalev-Shwartz and Ambuj Tewari. Stochastic Methods for L1 Regularized Loss Minimization. In Proceedings of the 26th Annual International Conference on Machine Learning, pages 929\u2013936, 2009.   \n[17] Lin Xiao. Dual Averaging Method for Regularized Stochastic Learning and Online Optimization. Advances in Neural Information Processing Systems, 22, 2009.   \n[18] Yoav Freund and Robert E Schapire. Large Margin Classification Using the Perceptron Algorithm. In Proceedings of the eleventh annual conference on Computational learning theory, pages 209\u2013217, 1998.   \n[19] Marco Muselli. On convergence properties of pocket algorithm. IEEE Transactions on Neural Networks, 8(3):623\u2013629, 1997.   \n[20] Nicolo Cesa-Bianchi, Alex Conconi, and Claudio Gentile. On the Generalization Ability of On-line Learning Algorithms. IEEE Transactions on Information Theory, 50(9):2050\u20132057, 2004.   \n[21] Nicolo Cesa-Bianchi and Claudio Gentile. Improved Risk Tail Bounds for On-line Algorithms. IEEE Transactions on Information Theory, 54(1):386\u2013390, 2008.   \n[22] Ofer Dekel. From Online to Batch Learning with Cutoff-Averaging. Advances in Neural Information Processing Systems, 21, 2008.   \n[23] Steve Wang and Will Cukierski. Click-Through Rate Prediction. Kaggle. https://kaggle.com/competitions/avazu-ctr-prediction, 2014.   \n[24] Isabelle Guyon, Steve Gunn, Asa Ben-Hur, and Gideon Dror. Dexter. UCI Machine Learning Repository, 2008. DOI: https://doi.org/10.24432/C5P898.   \n[25] Isabelle Guyon, Steve Gunn, Asa Ben-Hur, , and Gideon Dror. Dorothea. UCI Machine Learning Repository, 2008. DOI: https://doi.org/10.24432/C5NK6X.   \n[26] J. Stamper, A. Niculescu-Mizil, S. Ritter, G.J. Gordon, and K.R. Koedinger. Algebra I 2008- 2009. Challenge Data Set from KDD Cup 2010 Educational Data Mining Challenge. Find it at http://pslcdatashop.web.cmu.edu/KDDCup/downloads.jsp, 2010.   \n[27] Jingwei Liang and Clarice Poon. Screening for Sparse Online Learning. arXiv preprint arXiv:2101.06982, 2021.   \n[28] Ga\u00eblle Loosli, St\u00e9phane Canu, and L\u00e9on Bottou. Training Invariant Support Vector Machines using Selective Sampling. In L\u00e9on Bottou, Olivier Chapelle, Dennis DeCoste, and Jason Weston, editors, Large Scale Kernel Machines, pages 301\u2013320. MIT Press, Cambridge, MA., 2007.   \n[29] S Sathiya Keerthi, Dennis DeCoste, and Thorsten Joachims. A Modified Finite Newton Method for Fast Solution of Large Scale Linear SVMs. Journal of Machine Learning Research, 6(3), 2005.   \n[30] Ken Lang. Newsweeder: Learning to Filter NetNews. In Proceedings of the Twelfth International Conference on Machine Learning, pages 331\u2013339, 1995.   \n[31] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12:2825\u20132830, 2011.   \n[32] Jundong Li, Kewei Cheng, Suhang Wang, Fred Morstatter, Robert P Trevino, Jiliang Tang, and Huan Liu. Feature Selection: A Data Perspective. ACM Computing Surveys (CSUR), 50(6):94, 2018.   \n[33] David D Lewis, Yiming Yang, Tony Russell-Rose, and Fan Li. Rcv1: A New Benchmark Collection for Text Categorization Research. Journal of machine learning research, 5(Apr):361\u2013 397, 2004.   \n[34] Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. Recursive Deep Models for Semantic Compositionality over a Sentiment Treebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1631\u20131642, 2013.   \n[35] Justin Ma, Lawrence K Saul, Stefan Savage, and Geoffrey M Voelker. Identifying Suspicious urls: An Application of Large-Scale Online Learning. In Proceedings of the 26th Annual International Conference on Machine Learning, pages 681\u2013688, 2009.   \n[36] John C Platt. Fast Training of Support Vector Machines Using Sequential Minimal Optimization. 1998.   \n[37] Steve Webb, James Caverlee, and Calton Pu. Introducing the Webb Spam Corpus: Using Email Spam to Identify Web Spam Automatically. In CEAS, 2006.   \n[38] Alessio Benavoli, Giorgio Corani, and Francesca Mangili. Should We Really Use Post-Hoc Tests Based on Mean-Ranks? Journal of Machine Learning Research, 17(5):1\u201310, 2016.   \n[39] Janez Dem\u0161ar. Statistical Comparisons of Classifiers over Multiple Data Sets. Journal of Machine Learning Research, 7(1):1\u201330, 2006.   \n[40] Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton. On the importance of initialization and momentum in deep learning. In International conference on machine learning, pages 1139\u20131147. PMLR, 2013.   \n[41] David A Freedman. On tail probabilities for martingales. the Annals of Probability, pages 100\u2013118, 1975. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Proofs ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Validity analysis ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Proof of Theorem 1. The main statement involves two independent bounds. See the proofs for Theorem 5 and Theorem 6. ", "page_idx": 13}, {"type": "text", "text": "Theorem 5. Let $\\mathbf{w}^{(1)},\\ldots,\\mathbf{w}^{(k)}\\in\\mathcal{R}$ be the updated outputs of an online PA algorithm on inputs $z_{1}^{T}\\sim\\mathcal{D}$ . Define ${\\bf w}_{s}$ and w\u02dc as previously. Also define $r_{m}$ as the minimal achievable risk of any model, such that $r_{m}\\leq R_{D}(\\tilde{\\mathbf{w}})$ almost surely. ", "page_idx": 13}, {"type": "text", "text": "Then ", "page_idx": 13}, {"type": "equation", "text": "$$\nP(R_{\\mathcal{D}}(\\mathbf{w}_{s})>R_{\\mathcal{D}}(\\tilde{\\mathbf{w}})+\\varepsilon)\\leq K\\frac{r_{m}}{2r_{m}+\\varepsilon-r_{m}(r_{m}+\\varepsilon)}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Proof. First note that while $R_{\\mathcal{D}}(\\mathbf{w})$ is a constant value for any fixed w, $R_{D}(\\mathbf{w}_{s})$ and $R_{\\mathcal{D}}(\\tilde{\\mathbf{w}})$ are random variables induced by the distribution of $Z_{1}^{T}$ . The sequence of observed samples affects both the algorithm\u2019s output w as well as the subsequent survival of w. ", "page_idx": 13}, {"type": "text", "text": "Next, we define the event of interest $A=\\left\\{R_{\\mathcal{D}}(\\mathbf{w}_{s})>R_{\\mathcal{D}}(\\tilde{\\mathbf{w}})+\\varepsilon\\right\\}$ . For a given realization of $Z_{1}^{T}$ let the set $\\mathcal{R}_{\\varepsilon}=\\left\\{\\mathbf{w}\\in\\mathcal{R}:R_{D}(\\mathbf{w})>R_{D}(\\tilde{\\mathbf{w}})+\\varepsilon\\right\\}$ . Then ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{A\\subseteq\\{\\exists\\mathbf{w}\\in\\mathcal{R}:(s_{\\mathbf{w}}\\geq s_{\\tilde{\\mathbf{w}}})\\cap(R_{\\mathcal{D}}(\\mathbf{w})>R_{\\mathcal{D}}(\\tilde{\\mathbf{w}})+\\varepsilon)\\}}\\\\ &{\\quad=\\{\\exists\\mathbf{w}\\in\\mathcal{R}_{\\varepsilon}:s_{\\mathbf{w}}\\geq s_{\\tilde{\\mathbf{w}}}\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We aim to split this into separate events and apply a union bound, but the contents and size of $\\mathcal{R}$ depend on $\\bar{Z}_{1}^{T}$ . ", "page_idx": 13}, {"type": "text", "text": "uTph etroe , ee ennaublminerga tthe et hine dmexo etlos  rweiftehri nt oe tahceh $\\mathcal{R}_{\\varepsilon}$ r iens pthoen doirndge r mthoedye la cieni vaendy: $\\{\\mathbf{w}_{\\varepsilon}^{(1)},\\mathbf{w}_{\\varepsilon}^{(2)},\\dots\\},$ $\\mathbf{w}_{\\varepsilon}^{(K)}$ $i$ $\\mathbf{w}_{\\varepsilon}^{(i)}$ $Z_{1}^{T}$ Then we can split the event that a hypothesis in the reservoir has longer survival into the union of events on each ordered hypothesis. ", "page_idx": 13}, {"type": "text", "text": "We have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{A\\subseteq\\{\\exists\\mathbf{w}\\in\\mathcal{R}_{\\varepsilon}:s_{\\mathbf{w}}\\ge s_{\\tilde{\\mathbf{w}}}\\}}\\\\ &{\\quad\\subseteq\\bigcup\\{s_{\\mathbf{w}_{\\varepsilon}^{(i)}}\\ge s_{\\tilde{\\mathbf{w}}}\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Applying the union bound, Lemma 1, and then Lemma 2, ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P(A)\\leq\\displaystyle\\sum_{i}{P(s_{\\mathbf{w}_{\\varepsilon}^{(i)}}\\geq s_{\\tilde{\\mathbf{w}}})}}\\\\ &{\\qquad\\leq\\displaystyle\\sum_{i}{\\mathbb{E}}_{\\mathbf{w}_{\\varepsilon}^{(i)},\\tilde{\\mathbf{w}}}P(s_{\\mathbf{w}_{\\varepsilon}^{(i)}}\\geq s_{\\tilde{\\mathbf{w}}}|\\mathbf{w}_{\\varepsilon}^{(i)},\\tilde{\\mathbf{w}})}\\\\ &{\\qquad=\\displaystyle\\sum_{i}{\\mathbb{E}}_{\\mathbf{w}_{\\varepsilon}^{(i)},\\tilde{\\mathbf{w}}}P(S(\\mathbf{w}_{\\varepsilon}^{(i)})\\geq S(\\tilde{\\mathbf{w}})|\\mathbf{w}_{\\varepsilon}^{(i)},\\tilde{\\mathbf{w}})}\\\\ &{\\qquad=\\displaystyle\\sum_{i}{\\mathbb{E}}_{\\mathbf{w}_{\\varepsilon}^{(i)},\\tilde{\\mathbf{w}}}\\frac{R_{D}(\\tilde{\\mathbf{w}})}{R_{D}(\\mathbf{w}_{\\varepsilon}^{(i)})+R_{D}(\\tilde{\\mathbf{w}})-R_{D}(\\mathbf{w}_{\\varepsilon}^{(i)})R_{D}(\\tilde{\\mathbf{w}})}}\\\\ &{\\qquad\\leq K\\frac{r_{m}}{2r_{m}+\\varepsilon-r_{m}(r_{m}+\\varepsilon)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "To further clarify, the probabilities are computed over the probability space of $Z_{1}^{T}\\sim\\mathcal{D}$ , and w\u02dc depends on the realization of $Z_{1}^{T}$ . Lemma 1 allows us to reason about the dependent model instances as independent geometric variables, but we need to extract $\\tilde{\\bf w}$ into a instance-independent state. Thus we need to condition on the weight values, and then bound the probability uniformly across the expectation, using the premise that the weight risks are $\\varepsilon$ -distant. \u53e3 ", "page_idx": 13}, {"type": "text", "text": "Theorem 6. (Alternative bound) Let the same conditions hold as in Theorem 5. Then ", "page_idx": 14}, {"type": "equation", "text": "$$\nP(R_{\\mathcal{D}}(\\mathbf{w}_{s})>R_{\\mathcal{D}}(\\tilde{\\mathbf{w}})+\\varepsilon)\\leq e^{-r_{m}^{K}(r_{m}+\\varepsilon)}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Proof. As before, let $A=\\left\\{R_{\\mathcal{D}}(\\mathbf{w}_{s})>R_{\\mathcal{D}}(\\tilde{\\mathbf{w}})+\\varepsilon\\right\\}$ . Then ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{A\\subseteq\\{R_{\\mathcal{D}}(\\mathbf{w}_{s})>R_{\\mathcal{D}}(\\tilde{\\mathbf{w}})\\}\\subseteq\\{\\mathbf{w}_{s}\\neq\\tilde{\\mathbf{w}}\\}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\{\\mathbf{w}_{s}=\\tilde{\\mathbf{w}}\\}^{c}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\{s_{\\tilde{\\mathbf{w}}}\\geq s_{\\mathbf{w}},\\forall\\mathbf{w}\\in\\mathcal{R}\\}^{c}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The event $\\{\\mathbf{w}_{s}~=~\\tilde{\\mathbf{w}}\\}^{c}$ implies $\\tilde{\\mathbf{w}}$ had or was tied for the highest survival, and we make the simplification that ties are resolved in favor of $\\tilde{\\mathbf{w}}$ . Then ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P(A)\\leq1-P(s_{\\tilde{\\mathbf{w}}}\\geq s_{\\mathbf{w}},\\forall\\mathbf{w}\\in\\mathcal{R})}\\\\ &{\\qquad=1-P(s_{\\tilde{\\mathbf{w}}}\\geq\\displaystyle\\operatorname*{max}_{\\mathbf{w}}s_{\\mathbf{w}},\\forall\\mathbf{w}\\in\\mathcal{R})}\\\\ &{\\qquad=1-\\displaystyle\\sum_{x=1}^{\\infty}R_{D}(\\tilde{\\mathbf{w}})\\big(1-R_{D}(\\tilde{\\mathbf{w}})\\big)^{x-1}\\displaystyle\\prod_{j=1}^{K}\\Big(1-(1-R_{D}(\\mathbf{w}^{(j)}))^{x}\\Big)}\\\\ &{\\qquad\\leq1-\\displaystyle\\sum_{x=1}^{\\infty}R_{D}(\\tilde{\\mathbf{w}})\\big(1-R_{D}(\\tilde{\\mathbf{w}})\\big)^{x-1}\\Big(1-(1-R_{D}(\\tilde{\\mathbf{w}})^{x}\\Big)^{K-1}\\Big(1-(1-R_{D}(\\tilde{\\mathbf{w}})-\\varepsilon)^{x}\\Big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where in the third step, we apply Lemma 3. In the last step, we use the premise to suppose that there is at least one hypothesis which is $\\varepsilon$ -worse than $\\tilde{\\mathbf{w}}$ . ", "page_idx": 14}, {"type": "text", "text": "Considering the first-term only, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P(A)\\leq1-R_{\\mathcal{D}}(\\tilde{\\mathbf w})(R_{\\mathcal{D}}(\\tilde{\\mathbf w}))^{K-1}(R_{\\mathcal{D}}(\\tilde{\\mathbf w})+\\varepsilon)}\\\\ &{\\qquad=1-R_{\\mathcal{D}}(\\tilde{\\mathbf w})^{K}(R_{\\mathcal{D}}(\\tilde{\\mathbf w})+\\varepsilon)}\\\\ &{\\qquad\\leq\\exp\\big(-R_{\\mathcal{D}}(\\tilde{\\mathbf w})^{K}(R_{\\mathcal{D}}(\\tilde{\\mathbf w})+\\varepsilon)\\big)}\\\\ &{\\qquad\\leq\\exp\\big(-r_{m}^{K}(r_{m}+\\varepsilon)\\big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Remark. Note that this gives the worst-case bound presuming no knowledge over the distribution of risks among the $K$ hypotheses. In such a scenario, the worst case is that all hypotheses achieve $\\dot{R}_{\\mathcal{D}}(\\tilde{\\mathbf{w}})$ except for one which is $R_{\\mathcal{D}}(\\tilde{\\mathbf{w}})+\\varepsilon$ . This is unrealistically adversarial, but the bound can easily be tightened by adding assumptions that the risks $R_{\\mathcal{D}}(\\mathbf{w}^{(j)})$ are well-behaved and applying those in the last step. ", "page_idx": 14}, {"type": "text", "text": "Lemma 1. Let $R_{\\mathcal{D}}(\\mathbf{w})$ be the misclassification risk. Suppose an online learner outputs hypothesis ${\\bf w}_{t}$ at time $t$ after observing samples $Z_{1}^{t}$ . Let $s_{t}$ be the subsequent survival time of ${\\bf w}_{t}$ , conditional on the observed sequence ${\\bar{Z}}_{1}^{t}$ . Also let $\\bar{S}({\\bf w}_{t})$ be the survival of ${\\bf w}_{t}$ over the distribution of sample sequences from $\\mathcal{D}$ . Then $\\bar{S}(\\bar{\\mathbf{w}}_{t})$ has a Geometric distribution with parameter $R(\\mathbf{w}_{t})$ . In addition $s_{t}\\,\\underline{{\\underline{{d}}}}_{\\mathbf{\\Pi}}(\\mathbf{w})$ . ", "page_idx": 14}, {"type": "text", "text": "Proof. For the first statement, observe that when sampling $z$ independently from $\\mathcal{D}$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\nR(\\mathbf{w}_{t})=\\mathbb{E}_{\\mathcal{D}}[\\mathbb{1}(\\mathbf{w}_{t}(x)\\neq y)]=P_{(x,y)\\sim\\mathcal{D}}(\\mathbf{w}_{t}(x)\\neq y)\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Since each i.i.d. sample has a probability $R(\\mathbf{w}_{t})$ to be misclassified, the number of trials until the first misclassification is a Geometric distribution with parameter $R(\\mathbf{w}_{t})$ . ", "page_idx": 14}, {"type": "text", "text": "For the second, we need to consider a sequence of correct/incorrect classifications by ${\\bf w}_{t}$ as a Bernoulli process of r.v. $W_{i}$ with parameter $R(\\mathbf{w}_{t})$ , with a stopping time $\\tau$ indicated by the first misclassification. $\\tau$ is a random variable and we see that $S_{t}=\\tau-t$ . Similarly $S(\\mathbf{w}_{t})$ can be defined on another Bernoulli process starting from $t=0$ . From the memoryless property, these have the same distribution. \u53e3 ", "page_idx": 14}, {"type": "text", "text": "Lemma 2. Given random variables $X$ and $Y$ which are independent Geometric with parameters p and q respectively (e.g. PMF of $X$ is $P(X=k)=(1-p)^{k-1}p,$ , then ", "page_idx": 15}, {"type": "equation", "text": "$$\nP(X\\geq Y)={\\frac{q}{p+q-p q}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and ", "page_idx": 15}, {"type": "equation", "text": "$$\nP(X>Y)={\\frac{q-p q}{p+q-p q}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. For the first statement, ", "page_idx": 15}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}{P(X\\geq Y)={\\frac{\\sum_{i}^{n}P(Y=y)\\cdot P(X=y)}{\\sum_{i}^{n}P(X=y)\\cdot P(X=y)}}}\\\\ {=}&{\\sum_{i}^{n}P(X\\geq y)\\cdot P(Y=y)}\\\\ {=}&{{\\frac{\\sum_{i}^{n}P(X\\geq z)\\cdot P(Y=y)}{\\sum_{i}^{n}P(X=y)\\cdot P(X=y)}}}\\\\ {=}&{\\sum_{i=1}^{n}\\sum_{j=1}^{n}P(X=y)P(Y=y)}\\\\ {=}&{\\sum_{i=1}^{n}\\sum_{j=1}^{n}(1-P(X=y))\\cdot P(1-q^{j-1}y)}\\\\ {=}&{P(X=y)\\cdot{\\frac{1}{\\sum_{i}^{n}P(X=y)}}\\sum_{i=1}^{n}(1-P(X=y))\\cdot{\\Bigg(}}\\\\ {=}&{\\rho;{\\frac{\\sum_{i}^{n}(1-P(X=y))\\cdot P(X=y)-P(X=y)}{\\sum_{i=1}^{n}(1-P(X=y))\\cdot P(X=y)}}}\\\\ {=}&{\\rho;{\\frac{\\sum_{i=1}^{n}(1-P(X=y))\\cdot P(X=y)}{\\sum_{i=1}^{n}(1-P(X=y))\\cdot P(X=y)}}}\\\\ {=}&{{\\frac{1}{1-P(X=y)}}}\\\\ {=}&{{\\frac{1}{\\sqrt{1+{\\frac{(n-p)}{n}}}}}(1-\\rho).}\\end{array}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "For the second, note that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{P(X>Y)=1-P(Y\\geq X)=1-\\frac{p}{p+q-p q}}}\\\\ &{}&{=\\frac{q-p q}{p+q-p q}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Lemma 3. Let $Y_{1},\\ldots,Y_{t}$ be independent Geometric random variables with respective parameters $q_{1},\\ldots,q_{t}$ . Let $X\\sim\\operatorname{Geom}(p)$ be independent. Then ", "page_idx": 15}, {"type": "equation", "text": "$$\nP(X\\geq\\operatorname*{max}_{i}Y_{i})=\\sum_{x=1}^{\\infty}p(1-p)^{x-1}\\prod_{i=1}^{t}\\left(1-(1-q_{t})^{x}\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{P(X\\geq\\operatorname*{max}_{i}Y_{i})=\\sum_{x=1}^{\\infty}P(X=x\\cap\\operatorname*{max}_{i}Y_{i}\\leq x)}}\\\\ &{}&{\\qquad=\\displaystyle\\sum_{x=1}^{\\infty}P(X=x)P(\\operatorname*{max}_{i}Y_{i}\\leq x)}\\\\ &{}&{\\qquad=\\displaystyle\\sum_{x=1}^{\\infty}P(X=x)\\prod_{i=1}^{t}P(Y_{i}\\leq x)}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "by independence. Substitute the PMF and CMFs of the geometric distribution to finish. ", "page_idx": 16}, {"type": "text", "text": "Proof of Theorem 2. ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Proof. Note that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\cal A}=\\left\\{\\frac{1}{B+1}\\sum_{j=1}^{B+1}R_{j}^{\\prime}<\\frac{1}{B}\\sum_{j=1}^{B}R_{j}^{\\prime}\\right\\}}}\\\\ {{\\displaystyle{}~~~=\\left\\{B\\sum_{j=1}^{B+1}R_{j}^{\\prime}<(B+1)\\sum_{j=1}^{B}R_{j}^{\\prime}\\right\\}}}\\\\ {{\\displaystyle{}~~~=\\left\\{R_{B+1}^{\\prime}<\\frac{1}{B}\\sum_{j=1}^{B}R_{j}^{\\prime}\\right\\}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We now consider a subset of this event. We will compute the probability that $R_{1}^{\\prime},\\ldots,R_{B}^{\\prime}\\in\\mathcal{R}_{b}$ and that $R_{B+1}^{\\prime}\\in\\mathcal{R}_{g}$ . By definition, this latter event falls into $A$ . ", "page_idx": 16}, {"type": "text", "text": "For this to occur, note from Lemma 1 that each survival is drawn from a Geometric distribution. We want the chance that the $B$ largest survivals are from set $\\mathcal{R}_{b}$ and then the next largest is from $\\mathcal{R}_{g}$ . For additional simplicity, we further minimize the probability of this event by assigning all entries in $\\mathcal{R}_{g}$ risk $r_{m}$ and all entries in $\\mathcal{R}_{b}$ risk $r_{m}+3\\varepsilon$ . ", "page_idx": 16}, {"type": "text", "text": "Conditioning on $s_{B+1}^{\\prime}=x$ , all entries from $\\mathcal{R}_{g}$ are below $x$ except for one, which is equal to $x$ .   \nThere are $\\lvert\\mathcal{R}_{g}\\rvert$ ways to pick this largest one. ", "page_idx": 16}, {"type": "text", "text": "Then $|\\mathcal{R}|-B$ of the models in $\\mathcal{R}_{b}$ are also below $x$ , and $B$ are above $x$ . There are $\\binom{|\\mathcal{R}_{b}|}{B}$ ways to choose such $B$ ", "page_idx": 16}, {"type": "text", "text": "Finally this probability is summed over all values of $x$ . This is ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{r=1}^{\\infty}|\\mathcal{R}_{g}|(1-(1-r_{m})^{x})(1-r_{m})^{x-1}r_{m}\\cdot\\binom{|\\mathcal{R}_{b}|}{B}(1-(1-r_{m}-3\\varepsilon)^{x})^{|\\mathcal{R}_{b}|-B}(1-r_{m}-3\\varepsilon)^{B x}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "As before, to get a simpler expression, we just consider $x=1$ , yielding ", "page_idx": 16}, {"type": "equation", "text": "$$\nP(A)\\geq|\\mathcal{R}_{g}|\\binom{|\\mathcal{R}_{b}|}{B}r_{m}^{2}(r_{m}+3\\varepsilon)^{|\\mathcal{R}_{b}|-B}(1-r_{m}-3\\varepsilon)^{B}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We also discuss the additional assumption of this Theorem to show that it is readily satisfied. ", "page_idx": 16}, {"type": "text", "text": "Assumption. There is a partition of $\\mathcal{R}=\\mathcal{R}_{g}\\cup\\mathcal{R}_{b}$ such that $\\mathcal{R}_{g}=\\left\\{\\mathbf{w}\\in\\mathcal{R}:r_{m}\\leq R_{\\mathcal{D}}(\\mathbf{w})\\leq\\right.$ $r_{m}+\\varepsilon\\bar{\\}$ and $\\mathcal{R}_{b}=\\{\\mathbf{w}\\in\\mathcal{R}:r_{m}+\\varepsilon<R_{\\mathcal{D}}(\\mathbf{\\bar{w}})\\leq r_{m}+3\\varepsilon\\}.$ , and that $|\\mathcal{R}_{b}|\\ge B$ . That is, there is a set of good and bad models in terms of risk. ", "page_idx": 16}, {"type": "text", "text": "We can set $\\varepsilon>0$ to be any small number that satisfies a partition within the reservoir separating \"good\" from \"bad\" models \u2013 e.g. $\\varepsilon=(\\operatorname*{max}_{k}R_{k}^{\\prime}-r_{m})/4$ works. For demonstration, suppose the underlying risks of the models in the reservoir range from 0.1 to 0.3, with 0.1 being the best risk $r_{m}$ . Then $\\varepsilon=0.05$ . $\\mathcal{R}_{g}$ then contains the models with risks in [0.1, 0.15] and $\\mathcal{R}_{b}$ contains those with risks in (0.15, 0.3]. The only time this isn\u2019t satisfied for any $\\varepsilon$ is if one of the partitions always ends up empty, which only happens if all the $K$ models have the same risk, a highly unlikely scenario where it is obvious that an ensemble isn\u2019t needed. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "A.2 Learning bounds ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Our bound follows from the following lemma from [22]. This itself is based on martingale inequalities from [41] and developments in [21]. ", "page_idx": 17}, {"type": "text", "text": "Lemma 4 (Dekel). Let $L_{1},\\L_{\\cdot}\\dots,L_{T}$ be a sequence of real-valued random variables and let $Z_{1},\\L...,Z_{T}$ be a sequence of random variables such that $L_{t}\\,=\\,\\mathbb{E}[L_{t}|Z_{1},\\ldots,Z_{t}]$ . Also assume that $L_{t}\\in[0,C]$ for all $t,$ . Define $U_{t}=\\mathbb{E}[L_{t}|Z_{1},\\ldots,Z_{t-1}]$ , and let $\\begin{array}{r}{\\tilde{L}_{t}=\\sum_{i=1}^{t}L_{i}}\\end{array}$ . Then for any $T\\geq4$ and $\\delta\\in(0,1)$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\nP\\Bigg(\\forall t\\in\\{1,\\dots,T\\},\\quad\\sum_{i=1}^{t}U_{i}>\\tilde{L}_{t}+\\sqrt{2C\\log\\Big(\\frac{T}{\\delta}\\Big)\\tilde{L}_{t}}+7C\\log\\Big(\\frac{T}{\\delta}\\Big)\\Bigg)<\\delta\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "From this we obtain our learning bound. The proof follows analogously to the one in [22], with modifications to handle our specific algorithm. ", "page_idx": 17}, {"type": "text", "text": "Proof of Theorem 3. ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proof. In our method we have a reservoir $\\mathcal{R}$ containing $K$ models w with associated weights $b_{\\mathbf{w}}$ . We focus on the case where the weight is equal to the passive steps survived by the model. To simplify this proof we consider a slightly modified algorithm, where all models with survival exceeding a threshold $s$ are included in the reservoir. ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\pi_{t}={\\left\\{\\begin{array}{l l}{0,}&{{\\mathrm{if~}}s(\\mathbf{w}_{t})<s}\\\\ {s,}&{{\\mathrm{if~}}s(\\mathbf{w}_{t})=s}\\\\ {1,}&{{\\mathrm{otherwise}}}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We rewrite the weighted average of the reservoir models as a function of the entire training sequence of length $T$ by defining $\\pi_{t}$ to be 1 if ${\\bf w}_{t}$ is in $\\mathcal{R}$ and 0 otherwise. Furthermore on the first instance that $\\mathbf{w}_{t}$ joins $\\mathcal{R}$ , the $\\pi_{t}$ is instead set to $s$ . This makes the weighting deterministic with respect to the information at time $t-1$ , at the cost of the reservoir size not being explicitly defined. While this is analogous to a top- $\\cdot\\mathbf{k}$ averaging scheme, the full WRS scheme will follow from the same reasoning, with a more complicated definition of $\\pi_{t}$ . This is because all decision-making is performed using information that has already been seen. ", "page_idx": 17}, {"type": "text", "text": "Then we write $\\begin{array}{r}{\\mathbf{w}_{w r s}=\\frac{1}{\\sum_{t=1}^{T}\\pi_{t}}\\sum_{t=1}^{T}\\pi_{t}\\mathbf{w}_{t}}\\end{array}$ , and our goal is to control $R_{D}(\\mathbf{w}_{w r s})$ . Furthermore, ddiefffeinree ntth fer ocum mthuel aotibvsee rlvoesds  caus $\\begin{array}{r}{M_{w r s}\\,=\\,\\sum_{t=1}^{T}\\pi_{t}\\ell\\big(\\mathbf{w}_{t-1},z_{t}\\big)}\\end{array}$ .h e (reWqeu inroetme etnhta to ft rheisw teeirghmt iinsg  ao lni ttthlee $s$ -th survival.) ", "page_idx": 17}, {"type": "text", "text": "In the lemma, let $L_{t}~=~\\pi_{t}\\ell(\\mathbf{w}_{t-1},z_{t})$ and let $U_{t}\\;=\\;\\mathbb{E}[\\pi_{t}\\ell(\\mathbf{w}_{t-1},z_{t})|z_{1}^{t-1}]$ . Noting that $L_{t}$ is deterministic when conditioning on $z_{1}^{t}$ , the assumptions are met. Then with probability $1-\\delta$ , we have $\\begin{array}{r}{\\sum_{i=1}^{T}U_{i}<\\tilde{L}_{T}+\\sqrt{2C\\log\\left(\\frac{T}{\\delta}\\right)\\tilde{L}_{T}}+7C\\log{\\left(\\frac{T}{\\delta}\\right)}.}\\end{array}$   \nNow $\\begin{array}{r}{\\sum_{i=1}^{T}U_{i}=\\sum_{t=1}^{T}\\pi_{t}\\mathbb{E}[\\ell(\\mathbf{w}_{t-1},z_{t})|z_{1}^{t-1}]=\\sum_{t=1}^{T}\\pi_{t}R_{\\mathcal{D}}(\\mathbf{w}_{t-1})}\\end{array}$ , where the first equality uses the fa ct that $\\pi_{t}$ is  determined by the filtration $\\mathcal{F}_{t-1}$ , and the second similarly uses the conditioning information to fix $\\mathbf{w}_{t-1}$ and the i.i.d. assumption over $z$ . ", "page_idx": 17}, {"type": "text", "text": "Finally, we have $\\begin{array}{r l r}{R_{\\mathcal{D}}({\\mathbf w}_{w r s})\\!\\!}&{=}&{\\!\\!R_{\\mathcal{D}}\\Big(\\frac{1}{\\sum_{t=1}^{T}\\pi_{t}}\\sum_{t=1}^{T}\\pi_{t}{\\mathbf w}_{t}\\Big)\\!\\!}&{\\le}&{\\!\\!\\frac{1}{\\sum_{t=1}^{T}\\pi_{t}}\\sum_{t=1}^{T}\\pi_{t}R_{\\mathcal{D}}({\\mathbf w}_{t})}\\end{array}$ from Jensen\u2019s inequality. ", "page_idx": 17}, {"type": "text", "text": "Dividing the previous statement by $\\textstyle\\sum_{t=1}^{T}\\pi_{t}$ , we put the pieces together to conclude ", "page_idx": 18}, {"type": "equation", "text": "$$\nR_{\\mathcal{D}}(\\mathbf{w}_{w r s})\\leq\\frac{M_{w r s}}{\\sum_{t}\\pi_{t}}+\\sqrt{\\frac{2C\\log\\left(\\frac{T}{\\delta}\\right)M_{w r s}}{(\\sum_{t}\\pi_{t})^{2}}}+\\frac{7C\\log\\left(\\frac{T}{\\delta}\\right)}{\\sum_{t}\\pi_{t}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Finally, note that $\\textstyle\\sum_{t}\\pi_{t}$ is the total time steps involved with the reservoir weights, which is at least $K_{T}s_{T}$ with $K_{T}$ weights and $s_{T}$ the minimal survival time of the reservoir. Substituting completes the proof. ", "page_idx": 18}, {"type": "text", "text": "Proof of Theorem 4. ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proof. Combining the penultimate form of Theorem 3 (with $\\sum_{t}\\pi_{t}$ instead of $K_{T}s_{T}$ ) and the deduction that $M\\overset{\\biggr>}{w r s}/\\sum_{t}\\pi_{t}\\leq M_{T}/T$ we have ", "page_idx": 18}, {"type": "equation", "text": "$$\nR_{\\mathcal{D}}(\\mathbf{w}_{w r s})\\leq\\frac{M_{T}}{T}+\\sqrt{\\frac{2C\\log\\left(\\frac{T}{\\delta}\\right)M_{T}}{T\\sum_{t}\\pi_{t}}}+\\frac{7C\\log\\left(\\frac{T}{\\delta}\\right)}{\\sum_{t}\\pi_{t}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Next, we turn our attention to the generic base-model online regret bound. From this we get $\\begin{array}{r}{M_{T}/T\\le\\frac{1}{T}\\sum_{t}\\ell(\\mathbf{w}^{*};z_{t})+r(T)/T}\\end{array}$ . ", "page_idx": 18}, {"type": "text", "text": "We need to bound the cumulative loss of $\\mathbf{w}^{*}$ , that is $\\begin{array}{r}{\\frac{1}{T}\\sum_{t}\\ell(\\mathbf{w}^{*};z_{t})}\\end{array}$ , in terms of the risk: $R_{\\mathcal{D}}(\\mathbf{w}^{*})$ . Using an application of Hoeffding bound, we get ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{1}{T}\\sum_{t=1}^{T}\\ell(\\mathbf{w}^{*},z_{t})\\leq R_{\\mathcal{D}}(\\mathbf{w}^{*})+C\\sqrt{\\frac{\\log\\left(\\frac{1}{\\delta}\\right)}{2T}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "which holds with probability $1-\\delta$ . ", "page_idx": 18}, {"type": "text", "text": "Combining the undesired tail events under the union bound, we get ", "page_idx": 18}, {"type": "equation", "text": "$$\nR_{\\mathcal{D}}(\\mathbf{w}_{w r s})\\leq R_{\\mathcal{D}}(\\mathbf{w}^{*})+\\frac{r(T)}{T}+\\sqrt{\\frac{2C\\log\\left(\\frac{T}{\\delta}\\right)M_{T}}{T\\sum_{t}\\pi_{t}}}+\\frac{7C\\log\\left(\\frac{T}{\\delta}\\right)}{\\sum_{t}\\pi_{t}}+C\\sqrt{\\frac{\\log\\left(\\frac{1}{\\delta}\\right)}{2T}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "with probability $1-2\\delta$ . As before, substitute in $K_{T}s_{T}$ for $\\textstyle\\sum_{t}\\pi_{t}$ to complete. ", "page_idx": 18}, {"type": "text", "text": "Remark. The use of the online regret bound also indicates that the base models ${\\bf w}_{t}$ are improving over time. This means that their risks are decreasing, and hence the observed survival times are increasing. Thus even in the error term without $T$ in the denominator, $s_{T}$ is an increasing function of $T$ so we expect the error terms to decay in $T$ . ", "page_idx": 18}, {"type": "text", "text": "B Additional details on methods and experimental setups ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "B.1 Datasets ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Of the 16 datasets used in our study (see Table 1), 14 are directly from existing repositories and/or literature, while 2 of them \u2014 Newsgroups (Binary, CS) and SST-2 \u2014 were modified from pre-existing assets. First, Newsgroups (binary, CS) was formed by taking the original multi-class Newsgroups dataset hosted in [31] and combining the labels \u201cComputers\" and \u201cScience\" as a $+1$ class, and all other labels as the $-1$ class. Second, SST-2 is a sentiment classification dataset originally containing text excerpts that we transformed into a linear classification dataset by using the CountVectorizer from [31]. ", "page_idx": 19}, {"type": "text", "text": "B.2 Base PAC and FSOL hyperparameter tuning ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We start our set of experiments by tuning the $C_{e r r}$ hyperparameter for base PAC, testing values in the set 10\u22123, 10\u22122, . $10^{-2},\\dotsc,10^{2},10^{3}$ . For base FSOL, following Zhao et al.\u2019s approach, we test $\\eta$ values in $2^{-3},2^{-2},\\ldots,2^{8},2^{9}$ and $\\lambda$ values in $0,10^{-3},10^{-2},\\ldots,10^{2},10^{3}.$ . For each dataset, we perform five runs of our base PAC and FSOL variants with randomized shuffles of the training and test data, running through the training data only once for each run. For each dataset, we pick the $C_{e r r}$ , $\\eta$ , and $\\lambda$ values corresponding to the base PAC and FSOL variants, within the top $2.5\\%$ in terms of final test accuracy, that had the highest ROP, with all metrics averaged across the five runs. This experimental choice was made to strike a balance between simulating as difficult and risky conditions as possible and still choosing useful base model variants. ", "page_idx": 19}, {"type": "text", "text": "B.3 Metrics logging ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Given that some of our datasets contain up to 36 million training points, it would be computationally and storage-wise unfeasible to record metrics at each timestep. As such, for each dataset, we record metrics at $\\approx200$ evenly-spaced timesteps (exact number depends on divisibility and integer division of $N_{\\mathrm{train}}$ by 200) throughout the training stream, in addition to the initial and final timesteps. As such ROP was also approximated by proxying oracle accuracy by taking the cumulative maximum base model test accuracy across timesteps where metrics were recorded. As shown in the over-time figures in Appendix G.2, such a reduced resolution still tells us a very clear picture, while cutting down computation and storage requirements by many orders of magnitude. ", "page_idx": 19}, {"type": "text", "text": "B.4 Compute requirements and code availability ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "All experiments were run on a Linux computing cluster with 32 nodes, each with 40 Intel Xeon E5-2650 CPU cores and a total of $500\\:\\mathrm{GB}$ of RAM per node, managed using SLURM. Nonetheless, no experiments require multiprocessing or multiple cores. Depending on dataset size, some trials could take less than a minute to run, while the largest datasets would take a couple hours at max. However, larger datasets like Criteo will require 32 GB of RAM to load the dataset into memory. ", "page_idx": 19}, {"type": "text", "text": "Our source code for reproducing all experiments can be found at https://github.com/FutureComputing4AI/Weighted-Reservoir-Sampling-AugmentedTraining/tree/main. All experiments were run on CPU. ", "page_idx": 19}, {"type": "text", "text": "C Applications to Malware Classification ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Given that the original motivation for this work was a real-world need in malware detection, we present empirical results of PAC, PAC-WRS, FSOL, and FSOL-WRS on the EMBER malware classification dataset [7]. The EMBER dataset is comprised of features extracted from 1.1M benign and malicious Windows portable executable flies and thus can be considered very close to a real-world test case of our WRS-Augmented Training method on a real-world deployment setting. ", "page_idx": 20}, {"type": "text", "text": "In Figure 5, we observe that both base PAC and FSOL experience significant and frequent test accuracy fluctuations throughout the training process. However, both PAC-WRS and FSOL-WRS very successfully mitigate these test accuracy fluctuations and even outperform the oracle model, all without the use of a separate validation set. ", "page_idx": 20}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/d614392ba82f586810d6bd31eae65ec71e8d47c4b8dbebc01d62867184be9f63.jpg", "img_caption": ["Figure 5: Test accuracies $y$ -axis) over timestep ( $x$ -axis) for PAC/FSOL and PAC/FSOL-WRS on the EMBER benchmark dataset for malware classification. "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Indeed, WRS-Augmented Training is a promising tool towards stabilizing test accuracy performance in real-world deployment settings like malware detection. ", "page_idx": 20}, {"type": "text", "text": "D Comparisons to other ensembling and averaging schemes ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "One natural question a reader may ask is: how does WRS-Augmented Training compare to traditional weight-averaging schemes such as moving average (e.g., averaging the most-recently-observed $K=64$ weight vectors at each timestep) or exponential average (e.g., forming an ensemble vector $\\bar{\\mathbf{w}}_{t}=\\gamma\\mathbf{w}_{t}+(1-\\gamma)\\bar{\\mathbf{w}}_{t-1}$ at each timestep), where ${\\bf w}_{t}$ is the base algorithm\u2019s candidate solution at timestep $t$ . ", "page_idx": 21}, {"type": "text", "text": "From Figures 6 and 7, we observe that the exponential average scheme is consistently ineffective at mitigating the test accuracy instabilities of the base models PAC and FSOL. The stability of the exponential average scheme is usually not much better than that of the base model, which makes sense because it still puts the majority of the weighting on the most recent candidate solution. From these figures, we also observe that the $K=64$ moving average also has very mixed effectiveness. Overall, we see that WRS-Augmented Training is more preferable to the $K=64$ moving average. This makes sense because with WRS-Augmented Training, we are much more selective about the quality of the candidate solutions that we retain in our reservoir, compared to moving average, which necessarily by definition must include poor-performing solutions as they appear. ", "page_idx": 21}, {"type": "text", "text": "Third, from Table $5^{2}$ , we see that for datasets with dimension $D\\,>\\,100K$ , the moving average method can be significantly computationally slower per iteration than WRS-Augmented Training. For example, with PAC as the base model, the moving average method was, on average, $6.579\\mathrm{x}$ slower per iteration than WRS-Augmented Training on KDD2010 (Algebra) and 10.050x slower per iteration than WRS-Augmented Training on URL. Similar trends hold when using FSOL as the base algorithm. These results make sense because with WRS-Augmented Training, we do not always add candidate solutions to our reservoir for averaging, while with the moving average method, we must always add new candidate solutions into our set. These insertion and deletion costs will accrue over time. On smaller datasets, the moving average is faster or slower depending on the dataset, but runtime is dominated by IO and all methods finish within minutes. However, in more real-world, large-scale settings where evaluation and checking are prohibitively expensive, WRS-Augmented Training is the fastest, most accurate, and most reliable method compared to all the baselines. ", "page_idx": 21}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/3e4b3a3224b260988fadee72d21b71f8f5cd01746297ac92fc2e892329e8e05c.jpg", "img_caption": ["Figure 6: Test accuracies $y$ -axis) over timestep ( $x_{\\mathrm{~\\,~}}$ -axis) for WRS-Augmented Training $\\langle K=64\\rangle$ ), moving average (most recent $K=64$ ) and exponential average $(\\gamma=0.9)$ ), using PAC as the base. "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/4d8a23c7c5569fb942edaa29bccafa8c6648eb86b74df3cf194a7123eccf0abc.jpg", "img_caption": ["Figure 7: Test accuracies $y$ -axis) over timestep ( $x_{\\mathrm{~\\,~}}$ -axis) for WRS-Augmented Training $\\langle K=64\\rangle$ ), moving average (most recent $K=64$ ) and exponential average $(\\gamma=0.9)$ ), using FSOL as the base. "], "img_footnote": [], "page_idx": 23}, {"type": "table", "img_path": "FNOBf6JM7r/tmp/f169e602da5c7a7575a5695be4746315b1af0ddde30963e89174b96e56ca43a0.jpg", "table_caption": ["Table 5: Compute times per iteration (in seconds) of moving average and exponential average relative to WRS-augmented training, with PAC (left) and FSOL (right) as base models. For example, on URL with PAC, moving average was, on average, $10.050x$ slower per iteration than WRS-augmented training. "], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "E Modified WRS-Augmented Training on non-passive aggressive online learning methods ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In this section, we explore applying a modified form of WRS-Augmented Training (WAT) on top of three non-passive-aggressive online learning methods: Stochastic Gradient Descent with Momentum [40], ADAGRAD [14], and Truncated Gradient Descent [15], all using default hyperparameters. We emphasize that these three methods are not passive-aggressive as they always update their weight vectors at each time step, even if the data point was correctly classified. As such, the original WAT is not directly applicable. ", "page_idx": 24}, {"type": "text", "text": "However, we can modify WAT as follows. First, we define a pseudo-passive step as one where the current solution candidate made no classification error (i.e., no more concept of margin). Second, at a time step when the current solution candidate does make an error, we will sample the last weight vector before a mistake was made into our reservoir with probability proportional to the number of pseudo-passive steps, before resetting our counter. The rest of WAT operates as normal under this pseudo-passive step weighting. ", "page_idx": 24}, {"type": "text", "text": "From Figures 8 - 10, we observe that all three non-passive-aggressive online algorithms, in particular Stochastic Gradient Descent with Momentum $\\mathrm{{\\DeltaSGD+M})}$ ) and Truncated Gradient Descent (TGD), are susceptible to experiencing concerning fluctuations in test accuracy. Consistently, across the algorithms, we observe that when such fluctuations are present, modified WAT effectively mitigates such fluctuations very well. On the other hand, when there is little fluctuation in the base model (e.g., see ADAGRAD), applying modified WAT will do little to no harm. We emphasize that WAT was not designed for non-passive-aggressive algorithms, but is still demonstrably useful and adaptable to a wider class of base models, which can constitute fruitful future work. ", "page_idx": 24}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/1e05fb5ab805afa0ca16829e6001300388125d2ad7de9c14d22d4cc3c15bf5cf.jpg", "img_caption": ["Figure 8: Test accuracies ( $y$ -axis) over timestep $x$ -axis) for modified WRS-Augmented Training ( $K=64$ ) on Stochastic Gradient Descent with Momentum. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/8251d8f3b3c3df97e6ad131e714095e180f2bf487c090698e509d9c7c0509c9b.jpg", "img_caption": ["Figure 9: Test accuracies ( $y$ -axis) over timestep $x$ -axis) for modified WRS-Augmented Training ( $K=64$ ) on ADAGRAD. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/bfe49cc2a8ef17d5e2e74814c0ca9958a06e68d63f4d2dc199a74bae2c9d8ea1.jpg", "img_caption": ["Figure 10: Test accuracies $y$ -axis) over timestep $x$ -axis) for modified WRS-Augmented Training ( $K=64$ ) on Truncated Gradient Descent. "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "F Tables of $p$ -values for Wilcoxon Signed-Rank Tests ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Below, we provide full tables of $p$ -values computed using Wilcoxon Signed-Rank Tests towards probing the statistical significance of the differences in ROP and final test accuracy between PAC/FSOLWRS and their base model counterparts. ", "page_idx": 27}, {"type": "text", "text": "Table 6: Wilcoxon signed-rank test $p$ -values testing whether differences in relative oracle performance between $K=64$ PAC/FSOL-WRS variants and base PAC/FSOL methods are statistically significant. ", "page_idx": 27}, {"type": "table", "img_path": "FNOBf6JM7r/tmp/9c11046b82f3901faf9aa26723da00e14b95e3dc4c1f4a8a8971ddda4b5fbd98.jpg", "table_caption": [], "table_footnote": [], "page_idx": 27}, {"type": "table", "img_path": "FNOBf6JM7r/tmp/ed07d2b8766342cb8516c6a8aa775ca16c5bb7cb37418721e2b739a191df65cc.jpg", "table_caption": ["Table 7: Wilcoxon signed-rank test $p$ -values testing whether differences in final test accuracy between $K=64$ PAC/FSOL-WRS variants and base PAC/FSOL methods are statistically significant. "], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "G Additional results figures for PAC-WRS and FSOL-WRS ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "G.1 Uncertainty-quantified aggregate metrics across runs ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Below, we provide figures with error bars (minimum and maximum across 5 trials) showing the relative oracle performances (ROP), final test accuracies, and final sparsities of PAC-WRS and FSOL-WRS alongside the base PAC and FSOL models, across all 16 datasets. The main takeaways are that a) PAC-WRS and FSOL-WRS overall incur substantially-lower ROP than their corresponding base models; b) PAC-WRS and FSOL-WRS overall achieve comparable, if not improved, final test accuracy compared to their corresponding base models, consistently with lower variance, too; c) the final sparsities of PAC-WRS and FSOL-WRS are overall comparable, if not higher than those of their corresponding base models. ", "page_idx": 28}, {"type": "text", "text": "G.1.1 FSOL and FSOL-WRS ", "text_level": 1, "page_idx": 28}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/904ff904a8f5b4877b011edca2c064d026468706a014f671b9a7ca4a4f370057.jpg", "img_caption": ["Figure 11: Relative oracle performances $y$ -axis) of base FSOL and FSOL-WRS using standard weights over reservoir sizes $K$ $x$ -axis) on all datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. Blue: WRS-augmented variants via simple average of reservoir members. Red: WRS-augmented variants via weighted average of reservoir members. Dotted lines: indicates voting-based zeroing was performed for additional sparsity. Lower values indicate more stable performance. "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/bb9eb049c636c307bb3edb74b7089115b2fb4f75bdeab153679969be695b42a8.jpg", "img_caption": ["Figure 12: Final test accuracies ( $y$ -axis) of base FSOL and FSOL-WRS using standard weights over reservoir sizes $K$ ( $x$ -axis) on all datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. Blue: WRS-augmented variants via simple average of reservoir members. Red: WRS-augmented variants via weighted average of reservoir members. Dotted lines: indicates voting-based zeroing was performed for additional sparsity. "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/c47a69d7c41531af9cc352d78b0bfa77c61f96b63ffbcc121d5c9b0cb1fbc49f.jpg", "img_caption": ["Figure 13: Final sparsities $y$ -axis) of base FSOL and FSOL-WRS using standard weights over reservoir sizes $K$ ( $\\scriptstyle x$ -axis) on all datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. Blue: WRS-augmented variants via simple average of reservoir members. Red: WRS-augmented variants via weighted average of reservoir members. Dotted lines: indicates voting-based zeroing was performed for additional sparsity. "], "img_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/eaa1ca75f785744ff84c5eff21f44f1c1076bf1ccf1b5a69b7da5ea4590f2455.jpg", "img_caption": ["Figure 14: Relative oracle performances $y$ -axis) of base FSOL and FSOL-WRS using exponential weights over reservoir sizes $K$ ( $x$ -axis) on all datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. Blue: WRS-augmented variants via simple average of reservoir members. Red: WRS-augmented variants via weighted average of reservoir members. Dotted lines: indicates voting-based zeroing was performed for additional sparsity. Lower values indicate more stable performance. "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/b65fac811573f84b37afd3edfb98f6f37e7f46df08240f495430312cb2f4eca4.jpg", "img_caption": ["Figure 15: Final test accuracies ( $y$ -axis) of base FSOL and FSOL-WRS using exponential weights over reservoir sizes $K$ $x$ -axis) on all datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. Blue: WRS-augmented variants via simple average of reservoir members. Red: WRS-augmented variants via weighted average of reservoir members. Dotted lines: indicates voting-based zeroing was performed for additional sparsity. "], "img_footnote": [], "page_idx": 32}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/fb91b9af2fb452f9940d4b756ccc0d38bf0c7de7ce14359adaf39814c2d5acc6.jpg", "img_caption": ["Figure 16: Final sparsities $y$ -axis) of base FSOL and FSOL-WRS using exponential weights over reservoir sizes $K$ ( $\\scriptstyle x$ -axis) on all datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. Blue: WRS-augmented variants via simple average of reservoir members. Red: WRS-augmented variants via weighted average of reservoir members. Dotted lines: indicates voting-based zeroing was performed for additional sparsity. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/98a38d704c119408e10a5505cf24a5472e5a9e9b57e365e9b4de031d16afd8ea.jpg", "img_caption": ["Figure 17: Relative oracle performances ( $y$ -axis) of base PAC and PAC-WRS using standard weights over reservoir sizes $K$ $x$ -axis) on all datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. Blue: WRS-augmented variants via simple average of reservoir members. Red: WRS-augmented variants via weighted average of reservoir members. Dotted lines: indicates voting-based zeroing was performed for additional sparsity. Lower values indicate more stable performance. "], "img_footnote": [], "page_idx": 34}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/ae7435afdf43ddde76e596951384d4c536f2533d04cd49b0b3161cff8ab68557.jpg", "img_caption": ["Figure 18: Final test accuracies $y_{\\mathrm{~\\,~}}$ -axis) of base PAC and PAC-WRS using standard weights over reservoir sizes $K$ ( $\\scriptstyle x$ -axis) on all datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. Blue: WRS-augmented variants via simple average of reservoir members. Red: WRS-augmented variants via weighted average of reservoir members. Dotted lines: indicates voting-based zeroing was performed for additional sparsity. "], "img_footnote": [], "page_idx": 35}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/346ff935b47d55dad8b272712643a37fc3f8a5d5c58efb1a93566bd3ce63d915.jpg", "img_caption": ["Figure 19: Final sparsities ( $y$ -axis) of base PAC and PAC-WRS using standard weights over reservoir sizes $K$ ( $\\scriptstyle x$ -axis) on all datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. Blue: WRS-augmented variants via simple average of reservoir members. Red: WRS-augmented variants via weighted average of reservoir members. Dotted lines: indicates voting-based zeroing was performed for additional sparsity. "], "img_footnote": [], "page_idx": 36}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/bc304cdab07e9ff9fbc782bbe1a3a32cb9521ef9b8a0333df6e58a80ea8ef84b.jpg", "img_caption": ["Figure 20: Relative oracle performances ( $y$ -axis) of base PAC and PAC-WRS using exponential weights over reservoir sizes $K$ ( $x$ -axis) on all datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. Blue: WRS-augmented variants via simple average of reservoir members. Red: WRS-augmented variants via weighted average of reservoir members. Dotted lines: indicates voting-based zeroing was performed for additional sparsity. Lower values indicate more stable performance. "], "img_footnote": [], "page_idx": 37}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/27a81e558e83b1d122b07ea930c0d1a93620a8506503cae2bacf1dc3e4730f95.jpg", "img_caption": ["Figure 21: Final test accuracies $y$ -axis) of base PAC and PAC-WRS using exponential weights over reservoir sizes $K$ ( $x$ -axis) on all datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. Blue: WRS-augmented variants via simple average of reservoir members. Red: WRS-augmented variants via weighted average of reservoir members. Dotted lines: indicates voting-based zeroing was performed for additional sparsity. "], "img_footnote": [], "page_idx": 38}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/eadbeb0739487aa1cd95e4171bf206a4b77375b338b1a523073a8b97fdeb2a51.jpg", "img_caption": ["Figure 22: Final sparsities ( $y$ -axis) of base PAC and PAC-WRS using exponential weights over reservoir sizes $K$ ( $\\scriptstyle x$ -axis) on all datasets. Error bars represent the minimum and maximum values achieved across 5 randomized trials. Blue: WRS-augmented variants via simple average of reservoir members. Red: WRS-augmented variants via weighted average of reservoir members. Dotted lines: indicates voting-based zeroing was performed for additional sparsity. "], "img_footnote": [], "page_idx": 39}, {"type": "text", "text": "G.2 Test accuracies and sparsities over time ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Below, we provide figures showing test accuracies and sparsities over time on individual runs of PAC-WRS and FSOL-WRS, compared against their base model counterparts, on all 16 datasets. The main takeaways are that a) test accuracies over time on PAC-WRS and FSOL-WRS are overall much stabler, if not also higher, than their base model counterparts (and much closer to that of the oracle); b) applying WAT to PAC and FSOL does not significantly impact sparsity \u2014 in some cases, especially with voting-based zeroing, sparsity actually increases compared to the base model! ", "page_idx": 40}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/fea9255a6eba292ca62bcacbfbfac3a0dc46205c55f043fb42c4271958e98abe.jpg", "img_caption": ["G.2.1 FSOL and FSOL-WRS ", "Figure 23: Test accuracies $y$ -axis) over timestep ( $x$ -axis) for FSOL-WRS with reservoir size $K=64$ using standard weighting on all 16 tested datasets. Light grey lines: test accuracies of the FSOL baseline methods at each timestep. Solid black lines: test accuracies of the \u201coracle\" models, computed as the cumulative maximum of the FSOL baselines. Blue: corresponds to FSOL-WRS variants ensembled via simple averaging. Red: corresponds to FSOL-WRS variants ensembled via weighted averaging. Dotted lines: indicate whether voting-based zeroing was applied for additional sparsity. "], "img_footnote": [], "page_idx": 40}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/ffba2e33b26adcda13951a0c26c8e8f6d64817b1b619c5544540c9d558a2b081.jpg", "img_caption": ["Figure 24: Sparsity ( $y$ -axis) over timestep ( $x$ -axis) for FSOL-WRS with reservoir size $K=64$ using standard weighting on all 16 tested datasets. Light grey lines: sparsities of the FSOL baseline methods at each timestep. Blue: corresponds to FSOL-WRS variants ensembled via simple averaging. Red: corresponds to FSOL-WRS variants ensembled via weighted averaging. Dotted lines: indicate whether voting-based zeroing was applied for additional sparsity. "], "img_footnote": [], "page_idx": 41}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/6d4623753709ce13fe269dda0e9a3568d4434e1cadff8cf8e8097f58869f550a.jpg", "img_caption": ["Figure 25: Test accuracies $y$ -axis) over timestep ( $x$ -axis) for FSOL-WRS with reservoir size $K=64$ using exponential weighting on all 16 tested datasets. Light grey lines: test accuracies of the FSOL baseline methods at each timestep. Solid black lines: test accuracies of the \u201coracle\" models, computed as the cumulative maximum of the FSOL baselines. Blue: corresponds to FSOL-WRS variants ensembled via simple averaging. Red: corresponds to FSOL-WRS variants ensembled via weighted averaging. Dotted lines: indicate whether voting-based zeroing was applied for additional sparsity. "], "img_footnote": [], "page_idx": 42}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/47c6836d4243cfc6b37334c1f9e94082829d2d39e435cdb691a88c1138dd59a3.jpg", "img_caption": ["Figure 26: Sparsity ( $y$ -axis) over timestep ( $x$ -axis) for FSOL-WRS with reservoir size $K=64$ using exponential weighting on all 16 tested datasets. Light grey lines: sparsities of the FSOL baseline methods at each timestep. Blue: corresponds to FSOL-WRS variants ensembled via simple averaging. Red: corresponds to FSOL-WRS variants ensembled via weighted averaging. Dotted lines: indicate whether voting-based zeroing was applied for additional sparsity. "], "img_footnote": [], "page_idx": 43}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/e2232cc0f60a606c5c4f7a2ab1c494403dd3b0502a4cffdfe71ab92e6c14f847.jpg", "img_caption": ["Figure 27: Test accuracies $y$ -axis) over timestep ( $x$ -axis) for PAC-WRS with reservoir size $K=64$ using standard weighting on all 16 tested datasets. Light grey lines: test accuracies of the PAC baseline methods at each timestep. Solid black lines: test accuracies of the \u201coracle\" models, computed as the cumulative maximum of the PAC baselines. Blue: corresponds to PAC-WRS variants ensembled via simple averaging. Red: corresponds to PAC-WRS variants ensembled via weighted averaging. Dotted lines: indicate whether voting-based zeroing was applied for additional sparsity. "], "img_footnote": [], "page_idx": 44}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/f7f54cfe0daeae7c979a73eccb16d6e9110e0428bbef20293faff8233055ed21.jpg", "img_caption": ["Figure 28: Sparsity ( $y$ -axis) over timestep ( $x$ -axis) for PAC-WRS with reservoir size $K=64$ using standard weighting on all 16 tested datasets. Light grey lines: sparsities of the PAC baseline methods at each timestep. Blue: corresponds to PAC-WRS variants ensembled via simple averaging. Red: corresponds to PAC-WRS variants ensembled via weighted averaging. Dotted lines: indicate whether voting-based zeroing was applied for additional sparsity. "], "img_footnote": [], "page_idx": 45}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/db8d32f754ef245313c4acfb547daabf8e5d1fccdb4b115e5781a8c74311c924.jpg", "img_caption": ["Figure 29: Test accuracies $y$ -axis) over timestep ( $x$ -axis) for PAC-WRS with reservoir size $K=64$ using exponential weighting on all 16 tested datasets. Light grey lines: test accuracies of the PAC baseline methods at each timestep. Solid black lines: test accuracies of the \u201coracle\" models, computed as the cumulative maximum of the PAC baselines. Blue: corresponds to PAC-WRS variants ensembled via simple averaging. Red: corresponds to PAC-WRS variants ensembled via weighted averaging. Dotted lines: indicate whether voting-based zeroing was applied for additional sparsity. "], "img_footnote": [], "page_idx": 46}, {"type": "image", "img_path": "FNOBf6JM7r/tmp/d6aef04b9b124f71bbffacc80b1c8100edc2fc0a12019ebcf53947da0b3c20b8.jpg", "img_caption": ["Figure 30: Sparsity ( $y$ -axis) over timestep ( $x$ -axis) for PAC-WRS with reservoir size $K=64$ using exponential weighting on all 16 tested datasets. Light grey lines: sparsities of the PAC baseline methods at each timestep. Blue: corresponds to PAC-WRS variants ensembled via simple averaging. Red: corresponds to PAC-WRS variants ensembled via weighted averaging. Dotted lines: indicate whether voting-based zeroing was applied for additional sparsity. "], "img_footnote": [], "page_idx": 47}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 48}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 48}, {"type": "text", "text": "Justification: Please see our Abstract and Introduction. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 48}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 48}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Justification: Please see Section 5. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 48}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 48}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 48}, {"type": "text", "text": "Justification: Please see Section 3.2 and Appendix A. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 49}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 49}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 49}, {"type": "text", "text": "Justification: Please see Section 4 and Appendix B. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 49}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 49}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 50}, {"type": "text", "text": "Justification: Please see our GitHub at https://github.com/FutureComputing4AI/WeightedReservoir-Sampling-Augmented-Training/tree/main, with a detailed README.md file. ", "page_idx": 50}, {"type": "text", "text": "Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 50}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 50}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 50}, {"type": "text", "text": "Justification: Please see Algorithm 1, Section 4, and Appendix B, as well as our GitHub at https://github.com/FutureComputing4AI/Weighted-Reservoir-SamplingAugmented-Training/tree/main. ", "page_idx": 50}, {"type": "text", "text": "Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 50}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 50}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Justification: Please see error bars and significance tests in Section 4 and Appendix G.1 Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 50}, {"type": "text", "text": "", "page_idx": 51}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 51}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 51}, {"type": "text", "text": "Justification: Please see Appendix B. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 51}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 51}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 51}, {"type": "text", "text": "Justification: We have carefully read the NeurIPS Code of Ethics and have made sure that our research conforms to it. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 51}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 51}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 51}, {"type": "text", "text": "Justification: This paper introduces a foundational research method that does not have any direct paths to negative societal impacts, aside from the general interactions of machine learning with society. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 51}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 52}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 52}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 52}, {"type": "text", "text": "Justification: This paper does not involve any data or models that have a high risk for misuse. Guidelines: ", "page_idx": 52}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 52}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 52}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 52}, {"type": "text", "text": "Justification: We enumerate and cite all datasets in Table 1. Aside from our own preprocessed versions of Newsgroups (Binary, CS) and SST-2, the 14 other datasets are all publicly available. ", "page_idx": 52}, {"type": "text", "text": "Guidelines: ", "page_idx": 52}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 52}, {"type": "text", "text": "", "page_idx": 53}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 53}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 53}, {"type": "text", "text": "Justification: Please see the README.md file in our accompanying GitHub https://github.com/FutureComputing4AI/Weighted-Reservoir-Sampling-AugmentedTraining/tree/main. ", "page_idx": 53}, {"type": "text", "text": "Guidelines: ", "page_idx": 53}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 53}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 53}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 53}, {"type": "text", "text": "Justification: No crowdsourcing or work with human subjects was performed for this paper. Guidelines: ", "page_idx": 53}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 53}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 53}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 53}, {"type": "text", "text": "Justification: This paper does not have any study participants and/or crowdsourcing. ", "page_idx": 53}, {"type": "text", "text": "Guidelines: ", "page_idx": 53}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 53}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 54}]