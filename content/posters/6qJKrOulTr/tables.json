[{"figure_path": "6qJKrOulTr/tables/tables_3_1.jpg", "caption": "Algorithm 1 The Singular Metric Equivalence Class (SiMEC) algorithm. Algorithm 2 The Singular Metric Exploration (SiM-Exp) algorithm.", "description": "These algorithms are used for input space exploration. SiMEC aims to reconstruct the equivalence class of an input by exploring the input space using eigenvectors associated with the zero eigenvalue of the pullback metric. SiMExp, on the other hand, helps to navigate between equivalence classes by utilizing eigenvectors related to non-zero eigenvalues. Both algorithms involve iterative computations, including calculating the pullback metric, performing eigen-decomposition, randomly selecting an eigenvector, and updating the current input based on the selected eigenvector and a step size. Finally, the algorithm projects the updated input to the nearest feasible region.", "section": "3.1 Input Space Exploration"}, {"figure_path": "6qJKrOulTr/tables/tables_4_1.jpg", "caption": "Figure 3: Example output from Algorithm 3 applied to digit classification. These two instances are predicted as 3 (left) and 4 (right). The brightness of the color indicates the eigenvalue's magnitude. The brighter the color, the more sensitive the patch. This indicates that changes in the values of these sensitive patches are likely to have a greater impact on the prediction probabilities. Each patch in the heatmap corresponds to a 2 \u00d7 2 square pixel.", "description": "This figure shows example outputs from Algorithm 3, which is used for feature importance analysis. It displays heatmaps for two MNIST digit classification instances (predicted as 3 and 4). Brighter colors represent higher eigenvalues, indicating more sensitive image patches, meaning that changes in those areas have a greater effect on prediction probabilities.", "section": "3.2 Interpretability"}, {"figure_path": "6qJKrOulTr/tables/tables_6_1.jpg", "caption": "Algorithm 5 Interpretation for Exploration results for ViT and BERT models.", "description": "This algorithm details how to interpret the results of exploring the embedding space using SiMEC/SiMExp for both Vision Transformers (ViTs) and BERT models.  It involves initializing a decoder (with weights from the embedding layer for ViTs, or using intermediate and final BERT layers for MLM for BERT), using original embedding distributions to cap modified embeddings, decoding those modified embeddings to generate corresponding images/sentences, and then replacing segments in the original input with those from the decoded output. The final output is a modified input (image or sentence) for each iteration of SiMEC/SiMExp.", "section": "3.2 Interpretability"}]