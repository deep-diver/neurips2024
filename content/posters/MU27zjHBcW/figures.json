[{"figure_path": "MU27zjHBcW/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison of fitness landscape prediction methods. WT: wildtype sequence. MTs: mutant sequences. A2B: Amino acid A in wildtype mutates to B. GT.: groundtruth. Corr.: Correlation.", "description": "This figure compares three different methods for predicting protein fitness landscapes: self-supervised methods using only PLMs, supervised methods that fine-tune PLMs with additional data, and the proposed DePLM method.  Self-supervised methods use PLMs to predict the likelihood of mutations, while supervised methods add a fitness header to the PLM for more accurate predictions. DePLM enhances the evolutionary information by denoising the likelihoods in the rank space of property values to achieve better generalization. The figure highlights the key differences in approach and the use of correlation metrics in evaluating the models.", "section": "1 Introduction"}, {"figure_path": "MU27zjHBcW/figures/figures_3_1.jpg", "caption": "Figure 2: The architecture overview of DePLM. Left: DePLM utilizes evolutionary likelihoods derived from PLMs as input, and generates denoised likelihoods tailored to specific properties for predicting the effects of mutations. Middle & Right: Denoising module utilizes a feature encoder to derive representations of proteins, taking into account both primary and tertiary structures. These representations are then employed to filter out noise from the likelihoods via denoising blocks.", "description": "This figure illustrates the architecture of the DePLM model.  The model takes as input protein sequences and evolutionary likelihoods from pre-trained protein language models (PLMs). A feature encoder processes the protein sequences, integrating both primary and tertiary structure information. This information is then used in the denoising module to filter out irrelevant information from the evolutionary likelihoods, generating denoised likelihoods specifically tailored to the target protein properties. The denoising module uses denoising blocks to refine the noisy input to produce property-specific mutation likelihoods.", "section": "3 Method"}, {"figure_path": "MU27zjHBcW/figures/figures_4_1.jpg", "caption": "Figure 3: The training process of DePLM. Left: The training of DePLM involves two main steps: rank-based controlled forward corruption and learned denoising backward processes. In the corruption step, we use sorting algorithms to generate trajectories, shifting from the rank of property-specific likelihood to that of the evolutionary likelihood. DePLM is trained to model the backward process. Right: We illustrate the alteration of the Spearman coefficient during the transformation from evolutionary likelihood to property-specific likelihood via the sorting algorithm.", "description": "This figure illustrates the training process of the DePLM model.  The left panel shows a schematic of the two main steps: a forward corruption process and a learned denoising backward process. The forward process uses sorting algorithms to create trajectories in rank space, moving from property-specific likelihoods to evolutionary likelihoods. The model is then trained to reverse this process (denoising backward process). The right panel shows a graph illustrating how the Spearman correlation coefficient changes during this transformation from evolutionary to property-specific likelihoods.", "section": "3 Method"}, {"figure_path": "MU27zjHBcW/figures/figures_8_1.jpg", "caption": "Figure 4: Visualization of the impact of optimization targets and size of training data on performance.", "description": "This figure visualizes the impact of different optimization targets and the size of training datasets on the model's performance. The left panel is a heatmap showing the Spearman's rank correlation (\u0394\u03c1) between the testing and training properties.  The right panel shows the Spearman's rank correlation (\u03c1) for each property (stability, fitness, expression, binding, activity) as a function of the number of training datasets per property. The heatmap reveals the extent of cross-correlation or interference between different protein properties, while the line graph illustrates how the model's generalizability increases with more training data for each target property.", "section": "4.5 Analysis and Discussion (Q4)"}, {"figure_path": "MU27zjHBcW/figures/figures_8_2.jpg", "caption": "Figure 5: Visualization of the impact of denoising process on the evolutionary likelihood.", "description": "The figure visualizes how the denoising process in DePLM refines the noisy evolutionary likelihood to isolate property-specific information. It shows the evolutionary likelihood of a protein (UniRef ID: P84126, Aldolase-type TIM barrel) and compares it with property-specific likelihoods for binding, active, and stability.  The color gradient represents entropy, ranging from lowest (blue) to highest (red). Differences between evolutionary likelihood and property-specific likelihoods are shown, highlighting how DePLM effectively filters out noise and enhances relevant signals.", "section": "4.5 Analysis and Discussion (Q4)"}, {"figure_path": "MU27zjHBcW/figures/figures_18_1.jpg", "caption": "Figure 6: DePLM with varying diffusion steps. Star: the best of performance across different steps.", "description": "This figure shows the performance of DePLM model with varying numbers of diffusion steps (0 to 5). The performance is measured by Spearman's rank correlation.  The star indicates the optimal number of diffusion steps for each dataset. The results suggest that a small number of diffusion steps are sufficient for optimal performance of the DePLM model and that increasing the number of steps may lead to overfitting. ", "section": "4.2 Performance Comparison (Q1)"}, {"figure_path": "MU27zjHBcW/figures/figures_19_1.jpg", "caption": "Figure 7: Results random cross-validation scheme. We report the DMS-level performance (measured by the Spearman's rank correlation \u03c1 between model scores and experimental measurements) of DePLM and other baselines", "description": "This figure shows the performance of DePLM and other baselines using the Spearman's rank correlation. The x-axis represents different datasets, and the y-axis represents the Spearman's rank correlation between the predicted and experimental measurements. Each point represents a dataset, and the color of the point represents the model.  The figure helps in visualizing the performance of DePLM against other baselines across various datasets. The results are from a random cross-validation experiment.", "section": "4.2 Performance Comparison (Q1)"}, {"figure_path": "MU27zjHBcW/figures/figures_20_1.jpg", "caption": "Figure 1: Comparison of fitness landscape prediction methods. WT: wildtype sequence. MTs: mutant sequences. A2B: Amino acid A in wildtype mutates to B. GT.: groundtruth. Corr.: Correlation.", "description": "This figure compares different methods for predicting protein fitness landscapes. It highlights the difference between self-supervised and supervised methods, and introduces the proposed DePLM approach.  The diagram shows how various methods utilize protein language models (PLMs) and evolutionary information to predict the fitness of mutant protein sequences compared to the wildtype sequence.  DePLM's unique feature is its denoising process conducted in the rank space, enhancing model generalization. ", "section": "1 Introduction"}]