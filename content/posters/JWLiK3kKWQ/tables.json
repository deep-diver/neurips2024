[{"figure_path": "JWLiK3kKWQ/tables/tables_6_1.jpg", "caption": "Table 1: Results on Meta-Dataset under the \u201ctrain on all datasets", "description": "This table presents the results of the proposed CoPA method and other state-of-the-art methods on the Meta-Dataset benchmark under the \"train on all datasets\" setting.  It shows the mean accuracy and 95% confidence intervals for each dataset, categorized into seen and unseen domains. The average accuracy across seen and unseen domains and average ranks of the models are also provided. This provides a comprehensive performance comparison of various few-shot learning models in a cross-domain setting.", "section": "5 Main Results & Analysis"}, {"figure_path": "JWLiK3kKWQ/tables/tables_6_2.jpg", "caption": "Table 1: Results on Meta-Dataset under the \u201ctrain on all datasets", "description": "This table presents the results of various few-shot learning methods on the Meta-Dataset benchmark, using the \"train on all datasets\" setting.  The first 8 datasets are considered \"seen domains,\" while the remaining 5 are \"unseen domains.\"  The table shows the mean accuracy and 95% confidence interval for each method across all datasets.  It allows for a comparison of different methods on both seen and unseen data, revealing their generalization capabilities to new datasets.", "section": "5 Main Results & Analysis"}, {"figure_path": "JWLiK3kKWQ/tables/tables_17_1.jpg", "caption": "Table 3: Average gaps between prototype and image instance embeddings/representations. The results are the average value of the gaps of 600 random tasks under \"train on all datasets\" settings.", "description": "This table presents the average gap between prototype and image instance embeddings/representations across 8 datasets in the Meta-Dataset benchmark.  The gap is calculated as the Euclidean distance between the centroids of normalized prototype and image instance embeddings. Three gap measurements are shown: the original gap from the pre-trained backbone (||Aembed||), the gap after applying the same transformation as in the URL method (||AURL||), and the gap after applying the CoPA method (||ACOPA||). The table demonstrates that CoPA enlarges the gap, while URL shrinks it.", "section": "B Detailed Study on Gaps between Prototypes and Images"}, {"figure_path": "JWLiK3kKWQ/tables/tables_21_1.jpg", "caption": "Table 4: Comparisons of CoPA respectively with linear transformation head and visual Transformation under both \"train on all datasets\" and \"train on ImageNet only\" settings. Mean accuracy and 95% confidence interval are reported. All results are the average of 5 reproductions with seeds 41-45.", "description": "This table compares the performance of CoPA using a linear transformation head and a visual transformer.  The results are shown for two experimental settings: training on all datasets and training only on ImageNet.  Mean accuracy and 95% confidence intervals are provided for each dataset across five separate runs, each initialized with a different random seed (41-45).", "section": "5 Main Results & Analysis"}, {"figure_path": "JWLiK3kKWQ/tables/tables_24_1.jpg", "caption": "Table 5: Results under vary-way 5-shot task setting (under \u201cTrained on all datasets\u201d setting). Mean accuracy, 95% confidence interval reported.", "description": "This table presents the results of the vary-way 5-shot task setting under the \"train on all datasets\" setting from the Meta-Dataset benchmark.  The table compares the performance of several methods, including Sim-CNAPS, SUR, URT, URL, CoPA, TSA, and CoPA + TSA, across various datasets.  Mean accuracy and a 95% confidence interval are provided for each method and dataset.  The results showcase the average performance across multiple random seeds.", "section": "5.1 Main Results & Analysis"}, {"figure_path": "JWLiK3kKWQ/tables/tables_24_2.jpg", "caption": "Table 5: Results under vary-way 5-shot task setting (under \u201cTrained on all datasets\u201d setting). Mean accuracy, 95% confidence interval reported.", "description": "This table presents the results of the vary-way 5-shot experiments on the Meta-Dataset, where the number of classes and shots are randomly determined for each task.  It compares the performance of CoPA against several other state-of-the-art methods, showing mean accuracy and 95% confidence intervals for each dataset.  The \"Average Seen,\" \"Average Unseen,\" and \"Average All\" rows provide summary statistics across all datasets, and the \"Rank\" row shows the average ranking of each method.", "section": "5.1 Main Results & Analysis"}, {"figure_path": "JWLiK3kKWQ/tables/tables_26_1.jpg", "caption": "Table 7: Study of the size of support set (Under \u201ctrain on all dataset\u201d settings).", "description": "This table shows the results of the analysis on how the number of support data affects the performance of CoPA. The experiment was conducted under the setting of training on all datasets. The minimum, maximum, and average number of support samples for each dataset are shown in this table. The analysis helps to understand the impact of the support data size on CoPA's performance.", "section": "F.2.2 Study on Effect of Support Data Size"}, {"figure_path": "JWLiK3kKWQ/tables/tables_27_1.jpg", "caption": "Table 1: Results on Meta-Dataset under the \u201ctrain on all datasets", "description": "This table presents the results of the proposed CoPA method and several other state-of-the-art methods on the Meta-Dataset benchmark under the \"train on all datasets\" setting.  The first 8 datasets are considered \"seen domains\", while the last 5 are \"unseen domains.\" The table reports mean accuracy and 95% confidence intervals for each method on each dataset, offering a comprehensive comparison of their performance across various visual domains.", "section": "5.1 Main Results & Analysis"}, {"figure_path": "JWLiK3kKWQ/tables/tables_28_1.jpg", "caption": "Table 9: Effect of the number of parameters (Under \"Train on all dataset\" settings).", "description": "This table presents the results of an ablation study conducted to investigate the impact of the number of model parameters on the performance of the proposed CoPA method and a variant of URL with a similar number of parameters. The results are reported for various datasets under the \"Train on all datasets\" setting, showing the mean accuracy and 95% confidence intervals for each method and dataset.  The purpose is to determine if the improved performance of CoPA stems solely from its increased number of parameters or from other design features.", "section": "F More Experimental Results"}, {"figure_path": "JWLiK3kKWQ/tables/tables_28_2.jpg", "caption": "Table 1: Results on Meta-Dataset under the \u201ctrain on all datasets", "description": "This table presents the results of the proposed CoPA method and other existing methods on the Meta-Dataset benchmark under the setting where all datasets are used for training.  It shows the mean accuracy and 95% confidence interval for each dataset, broken down into seen and unseen domains. The table also provides an average ranking of the methods across all datasets. ", "section": "5.1 Main Results & Analysis"}]