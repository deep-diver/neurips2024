{"references": [{"fullname_first_author": "M. Courbariaux", "paper_title": "BinaryConnect: Training Deep Neural Networks with Binary Weights during Propagations", "publication_date": "2015-12-01", "reason": "This paper introduces the BinaryConnect method, a foundational work in the field of binary neural networks (BNNs), which is heavily referenced and built upon in the target paper."}, {"fullname_first_author": "I. Hubara", "paper_title": "Binarized Neural Networks", "publication_date": "2016-12-01", "reason": "This paper further develops the concept of BNNs, introducing techniques for binarizing both weights and activations, which is central to the target paper's approach."}, {"fullname_first_author": "S. Han", "paper_title": "Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding", "publication_date": "2015-01-01", "reason": "This paper introduces several model compression techniques, including pruning and quantization, which are relevant to the energy efficiency goals of the target paper."}, {"fullname_first_author": "V. Sze", "paper_title": "Efficient Processing of Deep Neural Networks: A Tutorial and Survey", "publication_date": "2017-12-01", "reason": "This survey paper provides a comprehensive overview of efficient deep learning techniques, including low-precision arithmetic and hardware-aware designs, which is highly relevant to the context of the target paper."}, {"fullname_first_author": "K. He", "paper_title": "Deep Residual Learning for Image Recognition", "publication_date": "2016-06-01", "reason": "This paper introduces the ResNet architecture, a widely used deep learning model that the target paper uses as a baseline for its experiments and modifications."}]}