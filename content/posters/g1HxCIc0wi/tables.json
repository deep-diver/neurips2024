[{"figure_path": "g1HxCIc0wi/tables/tables_3_1.jpg", "caption": "Figure 7: Speedup for speculative MCTS across various speculative look-ahead steps, with each sub-figure representing a different (game, NN size) setting. OOM denotes \u201cout-of-memory\u201d evaluation.", "description": "This figure presents the results of evaluating the speedup achieved by the proposed speculative MCTS approach.  Different settings are used, varying the number of speculative look-ahead steps and the size of the neural network (NN).  Each subfigure shows the results for a specific game (9x9 Go, 9x9 NoGo, or 19x19 Go) and NN configuration. The speedup is calculated relative to the baseline (original) MCTS execution without speculation.  The \"OOM\" label indicates scenarios where the evaluation ran out of memory.", "section": "5.2 Evaluation of Training Latency"}, {"figure_path": "g1HxCIc0wi/tables/tables_4_1.jpg", "caption": "Figure 7: Speedup for speculative MCTS across various speculative look-ahead steps, with each sub-figure representing a different (game, NN size) setting. OOM denotes \u201cout-of-memory\u201d evaluation.", "description": "This figure shows the speedup achieved by speculative Monte Carlo Tree Search (MCTS) with different numbers of speculative look-ahead steps, compared to the baseline MCTS without speculation. The results are presented for four different combinations of game (9x9 Go, 9x9 NoGo, 19x19 Go) and neural network (NN) size.  Each subfigure displays the speedup with and without NN caching for each lookahead step, indicating the synergistic effect of speculation and caching.  'OOM' stands for 'Out Of Memory', indicating that the experiment ran out of memory.", "section": "5.2 Evaluation of Training Latency"}]