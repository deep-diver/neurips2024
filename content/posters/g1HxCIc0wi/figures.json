[{"figure_path": "g1HxCIc0wi/figures/figures_1_1.jpg", "caption": "Figure 1: AlphaZero training consists of self-play and NN training, where self-play is highly resource-consuming. We categorized the intrinsic \u201cparallelism\u201d in the self-play phase into three categories (a) inter-game, which is embarrassingly parallel, (b) intra-decision, such as parallel search algorithms, and (c) inter-decision, which enables parallel execution for moves within a single game. Our proposed work aims to address the problem of lack of inter-decision parallelism.", "description": "The figure illustrates the AlphaZero training process, which involves self-play and neural network training.  The self-play phase is highlighted as being highly resource-intensive.  The caption breaks down the parallelism within the self-play phase into three categories:\n\n(a) **Inter-game parallelism:** This is embarrassingly parallel, meaning multiple games can be run concurrently.\n(b) **Intra-decision parallelism:**  This involves parallel search algorithms within a single move, such as parallel Monte Carlo Tree Search (MCTS).\n(c) **Inter-decision parallelism:** This involves the parallel execution of future moves before the current move's computation is finished, which is the problem the paper aims to address.\n\nThe figure visually depicts the sequential nature of the MCTS process, indicating a high latency, and shows that the paper's proposed method will focus on improving inter-decision parallelism.", "section": "1 Introduction"}, {"figure_path": "g1HxCIc0wi/figures/figures_2_1.jpg", "caption": "Figure 2: Prediction accuracy when using fewer simulation counts to predict the 1600-simulation's search results.", "description": "The figure shows the prediction accuracy when using a smaller number of simulations to predict the results of a full MCTS search with 1600 simulations.  The x-axis represents the number of simulations used for prediction, and the y-axis represents the prediction accuracy.  The graph shows that as the number of simulations used for prediction increases, the prediction accuracy also increases, demonstrating that partial MCTS searches can reasonably predict the full MCTS results.", "section": "2.2 Motivation"}, {"figure_path": "g1HxCIc0wi/figures/figures_4_1.jpg", "caption": "Figure 5: The finite state machine corresponds to the speculation pipeline in Figure 3(b), containing two states: successful (S) and failed (F) speculation, and the prediction accuracy p.", "description": "This figure is a finite state machine representing the speculation pipeline in Figure 3(b). It has two states: a successful (S) state and a failed (F) state. The probability of a successful prediction is represented by p. The transitions between states are determined by the prediction accuracy.", "section": "4.2 Speculation Analysis"}, {"figure_path": "g1HxCIc0wi/figures/figures_5_1.jpg", "caption": "Figure 6: In speculative MCTS, parallel moves share cached NN inference results, which accelerate the execution mutually.", "description": "This figure illustrates how speculative MCTS improves efficiency by sharing cached neural network (NN) inference results between parallel moves.  The diagram shows that while the current move's MCTS simulation is in progress, the next move's simulation begins speculatively, using the cached results from the current move. This overlap reduces latency, even if the speculative prediction for the next move is incorrect, because cached results from discarded nodes can still be utilized for the current move. The cache is represented as a table storing NN inference results, allowing for faster retrieval when the same node is encountered in subsequent moves.", "section": "4.3 Synergizing Speculation and Neural Network Caching"}, {"figure_path": "g1HxCIc0wi/figures/figures_6_1.jpg", "caption": "Figure 7: Speedup for speculative MCTS across various speculative look-ahead steps, with each sub-figure representing a different (game, NN size) setting. OOM denotes \u201cout-of-memory\u201d evaluation.", "description": "This figure presents the results of evaluating the per-iteration self-play latency with different speculation look-ahead steps and NN caching. Each sub-figure represents a different combination of game and neural network (NN) size.  The x-axis shows the number of speculative look-ahead steps, while the y-axis shows the speedup achieved compared to the baseline (original) MCTS with no speculation (0 look-ahead steps).  The bars represent the speedup, broken down into estimated values (light blue and orange) and evaluated values (dark blue and orange), with and without NN caching.  OOM indicates that the evaluation ran out of memory.", "section": "5.2 Evaluation of Training Latency"}, {"figure_path": "g1HxCIc0wi/figures/figures_7_1.jpg", "caption": "Figure 8: NN cache hit rate across different speculative look-ahead steps.", "description": "This figure shows the Neural Network (NN) cache hit rate for different numbers of speculative look-ahead steps in speculative Monte Carlo Tree Search (MCTS).  The x-axis represents the number of speculative look-ahead steps, and the y-axis represents the cache hit rate. As the number of speculative look-ahead steps increases, the NN cache hit rate also increases. This demonstrates the synergy between speculation and NN caching in improving performance.", "section": "5.3 Evaluation of Cache Hit Rate"}, {"figure_path": "g1HxCIc0wi/figures/figures_7_2.jpg", "caption": "Figure 9: NN cache hit rate for each move across various speculative look-ahead steps.", "description": "This figure displays the NN cache hit rate for each move during the game, categorized by the number of speculative look-ahead steps used in the speculative MCTS algorithm.  It illustrates how the cache hit rate changes throughout a game (x-axis representing moves), varying with different speculation strategies (different lines representing different look-ahead steps).  This helps visualize the impact of speculation on cache utilization.  Generally, higher speculation leads to a higher cache hit rate, particularly in the beginning and end game where similar game states are more likely to occur.", "section": "5.3 Evaluation of Cache Hit Rate"}, {"figure_path": "g1HxCIc0wi/figures/figures_8_1.jpg", "caption": "Figure 10: End-to-end training evaluation against the state-of-the-art method, KataGo.", "description": "This figure shows the comparison of end-to-end training performance between the proposed speculative MCTS method and the state-of-the-art KataGo program.  The x-axis represents the wall-clock time in minutes, and the y-axis represents the Elo rating, a measure of performance. Three lines are presented: one for the proposed speculative MCTS with 1-step look-ahead, one for the proposed speculative MCTS without speculation (0-step look-ahead), and one for KataGo. The figure shows that the speculative MCTS with 1-step look-ahead achieves a significant speedup compared to KataGo while reaching the same Elo rating.", "section": "5.4 Evaluation of End-to-End Training"}, {"figure_path": "g1HxCIc0wi/figures/figures_12_1.jpg", "caption": "Figure 7: Speedup for speculative MCTS across various speculative look-ahead steps, with each sub-figure representing a different (game, NN size) setting. OOM denotes \u201cout-of-memory\u201d evaluation.", "description": "This figure evaluates the per-iteration self-play latency with different configurations of speculation look-ahead steps and NN caching.  The speedup of the speculative MCTS, compared to the baseline (original) MCTS, is shown for various game and neural network sizes. The light blue and orange bars represent the expected speedup (without and with NN caching respectively), and the dark blue and orange bars show the actual speedup (without and with NN caching respectively).", "section": "5.2 Evaluation of Training Latency"}, {"figure_path": "g1HxCIc0wi/figures/figures_12_2.jpg", "caption": "Figure 3: (a) Original execution where each move proceeds sequentially, and (b) Speculation pipeline where the next move is speculatively executed in parallel based on the prediction. Each 1/2 block indicates half of the MCTS computation for a move.", "description": "This figure illustrates the difference between the original sequential MCTS execution and the proposed speculative MCTS. In the original method (a), each move is processed sequentially, completing one half of the MCTS computation before moving on. In the speculative method (b), the next move's computation starts based on the prediction from the current move. The figure shows how this speculative execution is pipelined and the possibility of successful or failed speculations, influencing the overall computation time.", "section": "4.1 Speculative MCTS"}, {"figure_path": "g1HxCIc0wi/figures/figures_13_1.jpg", "caption": "Figure 13: The finite state machine corresponds to Figure 12, containing two states: g1 (guess 1-step ahead) and g2 (guess 2-step ahead), and the prediction accuracy Pg1, Pg2.", "description": "This figure depicts a finite state machine that models a speculation pipeline with two stages.  The states represent successful (g1) and failed (g2) speculation attempts for predicting the next move in a game.  The transition probabilities between the states are based on the prediction accuracy (Pg1 and Pg2) for each stage, showing the probability of transitioning to a successful or failed prediction depending on the results of the current step.", "section": "4.2 Speculation Analysis"}]