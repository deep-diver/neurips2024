[{"figure_path": "FOfU3qhcIG/figures/figures_1_1.jpg", "caption": "Figure 1: TuneTables: a novel prompt-tuning technique for prior-data fitted networks. TuneTables performs prompt tuning on a pre-trained prior-fitted network (TabPFN) to distill real-world datasets into learned embeddings, allowing for stronger performance and faster inference time than TabPFN in many cases. TuneTables also expands the capabilities of pre-trained PFNs; by way of example, we demonstrate its effectiveness for bias mitigation, and as an interpretability tool.", "description": "This figure illustrates the TuneTables method, a novel prompt-tuning technique for prior-data fitted networks (PFNs).  It compares TuneTables to the original TabPFN approach, highlighting key differences and advantages.  TuneTables uses prompt tuning on a pre-trained TabPFN to create compact, learned embeddings representing large datasets.  This leads to improved performance and faster inference times. The figure also showcases TuneTables' additional capabilities in bias mitigation and interpretability.", "section": "1 Introduction"}, {"figure_path": "FOfU3qhcIG/figures/figures_4_1.jpg", "caption": "Figure 2: TuneTables and state-of-the-art tabular models. A critical difference plot according to mean accuracy rank across the 98 datasets in Table 1 of [51]. Algorithms which are not significantly different (p > 0.05) are connected with a horizontal black bar. TuneTables achieves the highest mean rank of any algorithm.", "description": "This figure shows a critical difference plot comparing TuneTables to 18 other state-of-the-art tabular classification algorithms across 98 datasets.  The algorithms are ranked by their average accuracy rank.  Algorithms with statistically insignificant differences in performance are connected by a horizontal line.  TuneTables achieves the highest average rank, indicating superior overall performance.", "section": "Experiments"}, {"figure_path": "FOfU3qhcIG/figures/figures_5_1.jpg", "caption": "Figure 3: TuneTables addresses TabPFN's limitations. (Left) Motivating example (using the subset of [51]on which both CatBoost and TabPFNs3000 report results): TabPFNs3000 is best on small datasets, but when scaled past 3000 datapoints and 100 features, TabPFNs3000 significantly underperforms. (Middle) CatBoost vs. TuneTables on LARGESCALETABLES: By contrast, TuneTables is competitive with CatBoost on all datasets, mitigating the limitations of TabPFN. (Right) TabPFNs3000 vs. TuneTables on LARGESCALETABLES : TuneTables outperforms TabPFNs3000 on datasets with a high number of datapoints or features. The colorbar on the y axis represents the comparative change in per-dataset accuracy between two algorithms (A: blue, B: red). Positive numbers represent the absolute gain in accuracy of B w.r.t. A, negative numbers represent the absolute gain in accuracy of A w.r.t. B\u0392.", "description": "This figure compares the performance of TuneTables, CatBoost, and TabPFNs3000 across datasets with varying sizes and number of features.  The left panel shows that TabPFNs3000, while strong on smaller datasets, underperforms CatBoost on larger ones. The middle and right panels demonstrate that TuneTables consistently outperforms TabPFNs3000 across the datasets and is competitive with CatBoost, addressing the scalability limitations of TabPFNs3000.", "section": "Experiments"}, {"figure_path": "FOfU3qhcIG/figures/figures_7_1.jpg", "caption": "Figure 4: Dataset with high accuracies from just two datapoints. Shown is a two-example prompt dataset for the breast cancer dataset [78]. Malign class example has higher values for all features than benign class.", "description": "This figure shows a two-example prompt dataset for the breast cancer dataset.  The two examples, one benign and one malignant, are used as a minimal context for the TabPFN model.  The plot visually demonstrates that the malignant example has higher values for all features compared to the benign example, suggesting that high feature values are associated with malignancy. This highlights TuneTables' ability to extract discriminative features even from a tiny dataset.", "section": "5 TuneTables Extensions"}, {"figure_path": "FOfU3qhcIG/figures/figures_16_1.jpg", "caption": "Figure 2: TuneTables and state-of-the-art tabular models. A critical difference plot according to mean accuracy rank across the 98 datasets in Table 1 of [51]. Algorithms which are not significantly different (p > 0.05) are connected with a horizontal black bar. TuneTables achieves the highest mean rank of any algorithm.", "description": "This figure shows a critical difference plot comparing the performance of TuneTables against 18 other state-of-the-art tabular classification algorithms across 98 datasets.  The algorithms are ranked by their mean accuracy rank.  Algorithms with statistically insignificant differences in performance are connected by horizontal bars. The plot highlights TuneTables' superior average performance compared to the other algorithms.", "section": "Experiments"}, {"figure_path": "FOfU3qhcIG/figures/figures_16_2.jpg", "caption": "Figure 2: TuneTables and state-of-the-art tabular models. A critical difference plot according to mean accuracy rank across the 98 datasets in Table 1 of [51]. Algorithms which are not significantly different (p > 0.05) are connected with a horizontal black bar. TuneTables achieves the highest mean rank of any algorithm.", "description": "This figure compares the performance of TuneTables against other state-of-the-art tabular classification models across 98 datasets using a critical difference plot.  The plot visually shows the mean accuracy rank of each algorithm, indicating TuneTables' superior performance in achieving the highest average rank compared to its competitors.  Algorithms with statistically insignificant differences in performance are linked by horizontal bars.", "section": "Experiments"}, {"figure_path": "FOfU3qhcIG/figures/figures_19_1.jpg", "caption": "Figure 2: TuneTables and state-of-the-art tabular models. A critical difference plot according to mean accuracy rank across the 98 datasets in Table 1 of [51]. Algorithms which are not significantly different (p > 0.05) are connected with a horizontal black bar. TuneTables achieves the highest mean rank of any algorithm.", "description": "This figure shows a critical difference plot comparing TuneTables to other state-of-the-art tabular classification models across 98 datasets.  The plot displays the mean accuracy rank of each algorithm, with statistically insignificant differences (p > 0.05) indicated by horizontal bars connecting the algorithms. TuneTables is shown to have the highest average ranking, demonstrating superior performance compared to other methods.", "section": "Experiments"}, {"figure_path": "FOfU3qhcIG/figures/figures_19_2.jpg", "caption": "Figure 1: TuneTables: a novel prompt-tuning technique for prior-data fitted networks. TuneTables performs prompt tuning on a pre-trained prior-fitted network (TabPFN) to distill real-world datasets into learned embeddings, allowing for stronger performance and faster inference time than TabPFN in many cases. TuneTables also expands the capabilities of pre-trained PFNs; by way of example, we demonstrate its effectiveness for bias mitigation, and as an interpretability tool.", "description": "This figure illustrates the TuneTables method, which enhances prior-data fitted networks (PFNs) by using prompt tuning.  It shows how TuneTables improves performance and speed compared to the original TabPFN.  The image also highlights additional benefits of the technique such as bias mitigation and interpretability.", "section": "1 Introduction"}, {"figure_path": "FOfU3qhcIG/figures/figures_20_1.jpg", "caption": "Figure 4: Dataset with high accuracies from just two datapoints. Shown is a two-example prompt dataset for the breast cancer dataset [78]. Malign class example has higher values for all features than benign class.", "description": "This figure shows a two-example prompt dataset for the breast cancer dataset.  It demonstrates that TuneTables can achieve high accuracy using just two datapoints as context, effectively summarizing the dataset's key discriminative features. Notably, the malign class example exhibits higher values across all features compared to the benign class, highlighting the importance of these features for classification.", "section": "5 TuneTables Extensions"}]