{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-19", "reason": "This paper introduces CLIP, a highly influential model that demonstrates the effectiveness of contrastive learning for vision-language tasks, providing a strong foundation for many subsequent works, including this one."}, {"fullname_first_author": "Michael Tschannen", "paper_title": "Image captioners are scalable vision learners too", "publication_date": "2023-12-01", "reason": "This paper shows that image captioning can be an effective method for visual pretraining, serving as a direct inspiration for LocCa's approach and providing key insights into the architecture used for this work."}, {"fullname_first_author": "Lucas Beyer", "paper_title": "A study of autoregressive decoders for multi-tasking in computer vision", "publication_date": "2023-03-17", "reason": "This work introduces the multi-task learning paradigm for vision decoders employed in LocCa, enabling the efficient handling of multiple tasks within a shared decoder architecture."}, {"fullname_first_author": "Xi Chen", "paper_title": "PaLI: A jointly-scaled multilingual language-image model", "publication_date": "2022-09-06", "reason": "This paper introduces PaLI, a large multilingual vision-language model, providing a substantial dataset and serving as a baseline model for comparison with LocCa."}, {"fullname_first_author": "Peng Wang", "paper_title": "OFA: unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework", "publication_date": "2022-07-19", "reason": "This work introduces OFA, a unified model that can handle various vision-language tasks, demonstrating the potential of a multi-task learning approach and offering a comparison model for LocCa."}]}