[{"figure_path": "LdZ0u1FuXb/tables/tables_2_1.jpg", "caption": "Table 1: Comparative analysis of decentralized environments for (nearly) minimax optimality of representative collaborative learning algorithms with kernel regression. nFedAvg indicates the nonparametric version of FedAvg in [58]. Note that IED [48] achieves a weaker version of minimax optimality.", "description": "This table compares several decentralized collaborative learning algorithms using kernel regression, focusing on their ability to achieve near minimax optimality while addressing challenges such as local data privacy, massive distribution, and non-i.i.d. (independent and identically distributed) data.  It highlights whether each algorithm protects local data privacy, functions well in massively distributed settings, and handles non-i.i.d. data effectively. The table also notes that one algorithm, IED, achieves a weaker form of minimax optimality compared to the ideal.", "section": "Decentralized Learning with Kernel Regression"}, {"figure_path": "LdZ0u1FuXb/tables/tables_9_1.jpg", "caption": "Table 2: Performance comparison of FedMD, FedHeNN, KT-pFL, and DCL-NN on five datasets. The values are presented as the average of RMSEs along with standard deviations. For calibration, the performance of standalone models and centralized models is also provided.", "description": "This table compares the performance of four different collaborative learning algorithms (FedMD, FedHeNN, KT-pFL, and DCL-NN) against standalone and centralized models on five regression datasets (Toy-3D, Energy, RotatedMNIST, UTKFace, and IMDB-WIKI).  The results, presented as average RMSE and standard deviation, show that DCL-NN outperforms all baselines, demonstrating its effectiveness in collaborative learning settings.", "section": "5.2 Results on Neural Network-based Algorithms"}, {"figure_path": "LdZ0u1FuXb/tables/tables_14_1.jpg", "caption": "Table 1: Comparative analysis of decentralized environments for (nearly) minimax optimality of representative collaborative learning algorithms with kernel regression. nFedAvg indicates the nonparametric version of FedAvg in [58]. Note that IED [48] achieves a weaker version of minimax optimality.", "description": "This table compares several decentralized collaborative learning algorithms based on kernel regression, focusing on their ability to achieve near minimax optimality without directly sharing private data or models.  It considers factors such as interaction methods, local data privacy, distributed nature of data, and whether the data is independently and identically distributed (i.i.d.) or not. The table highlights that the proposed DCL-KR algorithm achieves nearly minimax optimality under heterogeneous conditions, unlike most existing methods.", "section": "Decentralized Learning with Kernel Regression"}, {"figure_path": "LdZ0u1FuXb/tables/tables_41_1.jpg", "caption": "Table 1: Comparative analysis of decentralized environments for (nearly) minimax optimality of representative collaborative learning algorithms with kernel regression. nFedAvg indicates the nonparametric version of FedAvg in [58]. Note that IED [48] achieves a weaker version of minimax optimality.", "description": "This table compares several decentralized collaborative learning algorithms based on kernel regression, focusing on their ability to achieve (near) minimax optimality while addressing challenges such as local data privacy, massively distributed data, and non-independent and identically distributed (non-i.i.d.) data.  It highlights the unique features of each algorithm regarding data interaction methods and the types of decentralized environments they effectively handle.", "section": "Decentralized Learning with Kernel Regression"}, {"figure_path": "LdZ0u1FuXb/tables/tables_43_1.jpg", "caption": "Table 1: Comparative analysis of decentralized environments for (nearly) minimax optimality of representative collaborative learning algorithms with kernel regression. nFedAvg indicates the nonparametric version of FedAvg in [58]. Note that IED [48] achieves a weaker version of minimax optimality.", "description": "This table compares several decentralized collaborative learning algorithms based on kernel regression, focusing on their ability to achieve near-minimax optimality in various decentralized settings. It considers factors such as local data privacy, massive distribution, and non-i.i.d. (independent and identically distributed) data.  The table highlights the algorithms' success in these challenging environments while preserving local data privacy.  Note that the nonparametric version of the FedAvg algorithm is included for comparison. ", "section": "Decentralized Learning with Kernel Regression"}, {"figure_path": "LdZ0u1FuXb/tables/tables_43_2.jpg", "caption": "Table 1: Comparative analysis of decentralized environments for (nearly) minimax optimality of representative collaborative learning algorithms with kernel regression. nFedAvg indicates the nonparametric version of FedAvg in [58]. Note that IED [48] achieves a weaker version of minimax optimality.", "description": "This table compares several decentralized collaborative learning algorithms based on kernel regression, focusing on their ability to achieve (near) minimax optimality in various decentralized environments.  It considers factors like the method of interaction between parties (e.g., divide-and-conquer, model exchange, knowledge distillation), whether local data privacy is preserved, whether the data is massively distributed, and whether the data is independently and identically distributed (i.i.d.) or not.  The table highlights that the proposed DCL-KR algorithm is notable for achieving near minimax optimality without directly sharing local data or models, unlike many other approaches.", "section": "Decentralized Learning with Kernel Regression"}, {"figure_path": "LdZ0u1FuXb/tables/tables_43_3.jpg", "caption": "Table 1: Comparative analysis of decentralized environments for (nearly) minimax optimality of representative collaborative learning algorithms with kernel regression. nFedAvg indicates the nonparametric version of FedAvg in [58]. Note that IED [48] achieves a weaker version of minimax optimality.", "description": "This table compares several decentralized collaborative learning algorithms based on kernel regression, focusing on their ability to achieve (nearly) minimax optimality in various decentralized settings.  It highlights whether each algorithm preserves local data privacy, handles massively distributed data, and tolerates non-identically independently distributed (non-i.i.d.) and unbalanced data.", "section": "Decentralized Learning with Kernel Regression"}, {"figure_path": "LdZ0u1FuXb/tables/tables_44_1.jpg", "caption": "Table 8: Hyperparameters for KT-pFL", "description": "This table shows the hyperparameters used for the KT-pFL algorithm in the experiments.  The hyperparameters include the number of communication rounds, sample size of public data, learning rate, distillation epochs, batch size (local), and batch size (public) for five datasets: Toy-3D, Energy, MNIST, UTKFace, and IMDB.", "section": "5 Experiments"}, {"figure_path": "LdZ0u1FuXb/tables/tables_44_2.jpg", "caption": "Table 1: Comparative analysis of decentralized environments for (nearly) minimax optimality of representative collaborative learning algorithms with kernel regression. nFedAvg indicates the nonparametric version of FedAvg in [58]. Note that IED [48] achieves a weaker version of minimax optimality.", "description": "This table compares several decentralized collaborative learning algorithms based on kernel regression, focusing on their ability to achieve (near) minimax optimality in various decentralized environments.  It considers factors like data privacy, data distribution (i.i.d. or non-i.i.d.), and the scale of the distributed system. The table highlights whether each algorithm preserves local data privacy, handles massive datasets, manages non-identically independently distributed (non-i.i.d.) data across multiple parties, and achieves (near) minimax optimality.", "section": "Decentralized Learning with Kernel Regression"}, {"figure_path": "LdZ0u1FuXb/tables/tables_45_1.jpg", "caption": "Table 1: Comparative analysis of decentralized environments for (nearly) minimax optimality of representative collaborative learning algorithms with kernel regression. nFedAvg indicates the nonparametric version of FedAvg in [58]. Note that IED [48] achieves a weaker version of minimax optimality.", "description": "This table compares several decentralized collaborative learning algorithms based on kernel regression, focusing on their ability to achieve near minimax optimality without directly sharing private data or models.  It highlights the interaction methods (divide-and-conquer, model exchange, knowledge distillation), data privacy considerations, data distribution characteristics (massively distributed, non-i.i.d., unbalanced), and whether each algorithm achieves (near) minimax optimality.  The table shows that the proposed DCL-KR algorithm using knowledge distillation is the only one that achieves near minimax optimality in massively distributed, statistically heterogeneous settings while preserving data privacy.", "section": "Decentralized Learning with Kernel Regression"}]