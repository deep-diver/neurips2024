[{"figure_path": "O5XbOoi0x3/figures/figures_0_1.jpg", "caption": "Figure 1. The visual comparison between our Hyper-SDXL and other methods. From the first to the fourth column, the prompts for these images are (1) a dog wearing a white t-shirt, with the word \"hyper\" written on it (2) abstract beauty, approaching perfection, pure form, golden ratio, minimalistic, unfinished,... (3) a crystal heart laying on moss in a serene zen garden ... (4) anthropomorphic art of a scientist stag, victorian inspired clothing by krenz cushart ...., respectively.", "description": "This figure visually compares the image generation results of Hyper-SDXL with three other methods: SDXL-Base, SDXL-Lightning, and SDXL-Turbo.  Four different image prompts were used for each model, showcasing the visual differences in output quality and style across the various models, particularly highlighting Hyper-SDXL's performance.", "section": "Introduction"}, {"figure_path": "O5XbOoi0x3/figures/figures_4_1.jpg", "caption": "Figure 2. An illustration of the two-stage Trajectory Segmented Consistency Distillation. The first stage involves consistency distillation in two separate time segments: [0, T] and [1, T] to obtain the two segments consistency ODE. Then, this ODE trajectory is adopted to train a global consistency model in the subsequent stage.", "description": "This figure illustrates the two-stage process of Trajectory Segmented Consistency Distillation (TSCD).  The first stage (left panel) divides the time steps into four segments and performs consistency distillation within each segment, resulting in a four-segment consistent ODE trajectory.  The second stage (right panel) uses the results from the first stage to train a model that provides a two-segment consistent ODE trajectory, effectively reducing the number of segments and improving efficiency and model fitting.  The arrows in the figure show the flow of the process.", "section": "3.1 Trajectory Segmented Consistency Distillation"}, {"figure_path": "O5XbOoi0x3/figures/figures_5_1.jpg", "caption": "Figure 3. Score distillation comparison between score-based model and consistency model. The estimated score produced by the score-based model may exhibit a greater estimation error than the consistency model.", "description": "This figure illustrates the concept of score distillation by comparing the performance of score-based models and consistency models. The x-axis represents the time steps, while the y-axis represents the average score. The green curve shows the ground truth (GT) average score, while the orange dashed line shows the predicted average score of the consistency model. The black dots indicate the predicted scores at specific time steps. The red arrow highlights the estimation error of the score-based model compared to the consistency model. The figure shows that the consistency model is able to produce more accurate predictions closer to the ground truth, while the score-based model has a larger estimation error.", "section": "3.3 One-step Generation Enhancement"}, {"figure_path": "O5XbOoi0x3/figures/figures_7_1.jpg", "caption": "Figure 1. The visual comparison between our Hyper-SDXL and other methods. From the first to the fourth column, the prompts for these images are (1) a dog wearing a white t-shirt, with the word \"hyper\" written on it (2) abstract beauty, approaching perfection, pure form, golden ratio, minimalistic, unfinished,... (3) a crystal heart laying on moss in a serene zen garden ... (4) anthropomorphic art of a scientist stag, victorian inspired clothing by krenz cushart ...., respectively.", "description": "This figure compares the image generation quality of Hyper-SDXL against other methods (SDXL-Turbo, SDXL-Lightning, and SDXL-Base) using four different prompts.  Each column represents a different prompt, showcasing Hyper-SDXL's performance across various styles and complexities, emphasizing its ability to generate high-quality images even with a small number of inference steps.", "section": "Introduction"}, {"figure_path": "O5XbOoi0x3/figures/figures_7_2.jpg", "caption": "Figure 5. The user study about the comparison between our method and other methods.", "description": "This figure presents the results of a user study comparing the preference rates for images generated by Hyper-SD and other methods.  The chart shows the percentage of users who preferred each method's images, broken down by the number of inference steps and whether LoRA or UNet was used. The results visually demonstrate the superiority of Hyper-SD in terms of user preference across various conditions.", "section": "4.2 Main Results"}, {"figure_path": "O5XbOoi0x3/figures/figures_13_1.jpg", "caption": "Figure 6. Qualitative comparisons with LoRA-based approaches on SD15 architecture.", "description": "This figure compares image generation results of different methods on the SD15 architecture using LoRA-based approaches.  It shows four different prompts and their generated images by the baseline model (SD15-Base), SD15-LCM, SD15-TCD, SD15-PeRFlow and Hyper-SD15.  Hyper-SD15 is the proposed method, and the comparison highlights its superior performance using only 1 step, compared to other methods requiring 4 or 25 steps to achieve similar quality.", "section": "C.1 SD15 Architecture with LoRA training"}, {"figure_path": "O5XbOoi0x3/figures/figures_13_2.jpg", "caption": "Figure 7. Qualitative comparisons with UNet-based approaches on SDXL architecture.", "description": "This figure compares the image generation quality of several models (SDXL-Turbo, SDXL-Lightning, and Hyper-SDXL) using different approaches (UNet-based) on the SDXL architecture.  It showcases four different prompts and their respective generated images to illustrate the visual differences between the methods. The figure highlights Hyper-SDXL's ability to generate high-quality images, even with a single step. This shows the efficacy of the proposed Hyper-SD model in terms of image quality when compared to other approaches.", "section": "C.2 SDXL Architecture with UNet training"}, {"figure_path": "O5XbOoi0x3/figures/figures_14_1.jpg", "caption": "Figure 8. Qualitative results on unified LoRAs.", "description": "This figure demonstrates the results of using a unified LoRA for both Hyper-SD15 and Hyper-SDXL models.  The unified LoRA is designed to work effectively across different numbers of inference steps (1, 2, 4, and 8 steps). The images in each row show the output generated from the same prompt at varying step counts, providing a visual comparison of consistency and quality across different inference steps.  The prompts used are diverse, ranging from descriptions of nature to more complex scenes like racing cars or parks.", "section": "C.3 Unified LoRA"}, {"figure_path": "O5XbOoi0x3/figures/figures_14_2.jpg", "caption": "Figure 9. Our unified LoRAs are compatible with ControlNet. The examples are conditioned on either scribble or canny images.", "description": "This figure demonstrates the compatibility of the proposed Hyper-SD model's unified LoRA with ControlNet.  Two examples are shown: one using a scribble control image and the other using a canny edge control image.  For each control image, the generated images using the unified LoRA at different inference steps (1, 2, 4, and 8 steps) are displayed, showcasing the model's consistent performance across various numbers of inference steps, despite using ControlNet's additional constraints. This highlights the robustness and versatility of Hyper-SD.", "section": "C.4 Compatibility with ControlNet"}, {"figure_path": "O5XbOoi0x3/figures/figures_15_1.jpg", "caption": "Figure 10. Our LoRAs with different steps can be applied to different base models and consistently generate high-quality images.", "description": "This figure demonstrates the versatility of the proposed Hyper-SD model.  It shows that the same LoRA (Low-Rank Adaptation) models, trained using the Hyper-SD method and with varying numbers of inference steps (1, 2, and 4), can be successfully applied to different base diffusion models. These base models represent various artistic styles and levels of realism, ranging from anime-style images (DreamShaper XL) to photorealistic portraits (Juggernaut XL) and fantasy art (ZavyChromaXL). The consistent high quality of the generated images across all base models and inference steps highlights the effectiveness and generalizability of the Hyper-SD approach.", "section": "C.5 Compatibility with Base Model"}]