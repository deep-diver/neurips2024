[{"figure_path": "FCsEvaMorw/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of RAINBOW TEAMING against PAIR [8] for eliciting harmful behaviours from JailbreakBench [9]. Top: (n/k) indicates the total number of successful jailbreaks (n) and the total number of behaviours jailbroken (k) for each method and classifier (best of 4 responses). Bottom: Self-BLEU similarity score.", "description": "This table compares the performance of RAINBOW TEAMING against two versions of the PAIR method in identifying harmful behaviors from the JailbreakBench dataset.  The top part shows the number of successful jailbreaks achieved by each method, using two different classifiers (JailbreakBench Classifier and Llama Guard). A higher number indicates better performance. The bottom part shows the Self-BLEU score, which measures the diversity of the generated prompts. A lower score indicates higher diversity, suggesting more varied attacks.", "section": "JailbreakBench Results"}, {"figure_path": "FCsEvaMorw/tables/tables_6_2.jpg", "caption": "Table 2: Transfer of adversarial prompts across different models. We take 3 archives for each original target, apply them to the transfer target, and report the mean and standard deviation of the ASR as evaluated by Llama Guard (best of 4 responses). 50% of adversarial prompts transfer on average, but the exact transfer varies drastically between models. All models reported are instruction fine-tuned.", "description": "This table presents the Attack Success Rate (ASR) when transferring adversarial prompts generated by RAINBOW TEAMING across different LLMs.  It shows the ASR of prompts generated against a specific model when applied to four other models.  The results demonstrate that the prompts exhibit some level of transferability across various models, with an average transfer rate of around 50%, although this varies significantly depending on the source and target models.  This highlights the potential generality of the generated adversarial prompts, suggesting that many are not model-specific.", "section": "Transfer of Adversarial Prompts"}, {"figure_path": "FCsEvaMorw/tables/tables_6_3.jpg", "caption": "Table 3: Analysis of the effect of a mutation-level similarity filter of RAINBOW TEAMING on ASR measured by GPT-4 and archive diversity (self-BLEU, BERTScore, ROGUE-L, and gzip compression ratio). Filtering out prompts that are too similar to their parent maintains a balance between ASR and diversity, whereas removing the filter encourages the method to reuse highly effective prompts across multiple cells. The filter is set at T = 0.6, discarding ~ 24% of mutated prompts. We report mean and standard error over 3 independent runs.", "description": "This table presents the results of an experiment comparing the performance of RAINBOW TEAMING with and without a similarity filter.  The similarity filter removes prompts that are too similar to their parent prompts. The results show that using the filter improves the diversity of the prompts in the archive while maintaining a high attack success rate (ASR).  Metrics such as self-BLEU, BERTScore, and ROGUE-L were used to assess the diversity of the prompts, while gzip compression ratio was used to assess the compactness of the archive.", "section": "Impact of the Similarity Filter"}, {"figure_path": "FCsEvaMorw/tables/tables_7_1.jpg", "caption": "Table 4: Safety and capabilities scores of the Llama 2-chat 7B model before and after SFT on RAINBOW TEAMING-generated data. Fine-tuning greatly improves robustness to adversarial prompts without hurting capabilities.", "description": "This table presents the results of fine-tuning the Llama 2-chat 7B model with data generated by RAINBOW TEAMING.  It shows the Attack Success Rate (ASR) before and after fine-tuning, as measured by two different safety classifiers (GPT-4 and Llama Guard), and also on the JailbreakBench dataset.  Additionally, it reports the model's performance on general capability benchmarks (GSM8K and MMLU), and its safety and helpfulness scores before and after fine-tuning.", "section": "4 RAINBOW TEAMING for Safety"}, {"figure_path": "FCsEvaMorw/tables/tables_8_1.jpg", "caption": "Table 5: Comparison of RAINBOW TEAMING to a baseline generating new questions from scratch each turn for the Q&A domain. Without reusing past questions as stepping stones, performance is worse across all metrics considered. We report the mean and standard deviation over 3 seeds.", "description": "This table compares the performance of RAINBOW TEAMING against a baseline method in a question answering task.  RAINBOW TEAMING leverages previously generated questions as \"stepping stones\" to guide the generation of new questions, while the baseline generates questions from scratch independently for each iteration. The table shows that RAINBOW TEAMING outperforms the baseline across three metrics: Mean Fitness (higher is better, indicating more effective adversarial questions), Coverage (higher is better, representing the breadth of the archive), and Self-BLEU (lower is better, indicating greater diversity of generated questions).  This demonstrates the advantage of utilizing past findings in the iterative search process for discovering high-quality and diverse adversarial examples.", "section": "6.1 Question Answering"}, {"figure_path": "FCsEvaMorw/tables/tables_8_2.jpg", "caption": "Table 6: Cybersecurity ASR of RAINBOW TEAMING on four Targets, as reported by CyberSecurityEval [4] (3 seeds), and human expert evaluation (1 seed).", "description": "This table presents the results of a cybersecurity assessment for various target models on prompts generated by RAINBOW TEAMING.  It shows the Attack Success Rate (ASR) as evaluated by two methods: CyberSecurityEval (an automated tool) and human expert evaluation. The table demonstrates the high effectiveness of RAINBOW TEAMING in generating adversarial prompts that elicit malicious behavior across different models.", "section": "6.2 Cybersecurity"}, {"figure_path": "FCsEvaMorw/tables/tables_19_1.jpg", "caption": "Table 7: Attack success rate against Llama 2-chat 7B model with different system prompts. \"Legacy\" is an original Llama 2-chat system prompt that explicitly promotes safety, but was deprecated as it results in a high false refusal rate [65]. Nonetheless, it makes the model significantly more robust, supporting the idea that system prompts are an imperfect but low-effort defence mechanism against adversarial attacks.", "description": "This table presents the results of an experiment evaluating the effectiveness of different system prompts in mitigating adversarial attacks against the Llama 2-chat 7B language model.  Three scenarios are compared: no system prompt, a helpful system prompt, and a legacy system prompt known to enhance safety but prone to high false positives.  The attack success rate (ASR) is measured using two different evaluators (GPT-4 and Llama Guard) to assess the model's vulnerability to adversarial prompts under each condition. The results show that the legacy prompt significantly improves robustness, although the helpful prompt still provides increased resistance compared to no prompt at all.", "section": "4.1 Results"}, {"figure_path": "FCsEvaMorw/tables/tables_19_2.jpg", "caption": "Table 1: Comparison of RAINBOW TEAMING against PAIR [8] for eliciting harmful behaviours from JailbreakBench [9]. Top: (n/k) indicates the total number of successful jailbreaks (n) and the total number of behaviours jailbroken (k) for each method and classifier (best of 4 responses). Bottom: Self-BLEU similarity score.", "description": "This table compares the performance of RAINBOW TEAMING against two versions of the PAIR method in eliciting harmful behaviours from the JailbreakBench dataset.  It shows the total number of successful jailbreaks and the total number of behaviours successfully jailbroken for each method using two different classifiers (JailbreakBench Classifier and Llama Guard).  Lower Self-BLEU scores indicate higher diversity in the generated prompts.", "section": "4.1 Results"}, {"figure_path": "FCsEvaMorw/tables/tables_22_1.jpg", "caption": "Table 1: Comparison of RAINBOW TEAMING against PAIR [8] for eliciting harmful behaviours from JailbreakBench [9]. Top: (n/k) indicates the total number of successful jailbreaks (n) and the total number of behaviours jailbroken (k) for each method and classifier (best of 4 responses). Bottom: Self-BLEU similarity score.", "description": "This table compares the performance of RAINBOW TEAMING against two variants of the PAIR method in eliciting harmful behaviors from the JailbreakBench dataset.  It shows the number of successful jailbreaks achieved by each method, categorized by the classifier used (JailbreakBench Classifier and Llama Guard). A lower Self-BLEU score indicates greater diversity in the generated prompts.", "section": "JailbreakBench Results"}, {"figure_path": "FCsEvaMorw/tables/tables_31_1.jpg", "caption": "Table 10: List of hyperparameters used in safety experiments.", "description": "This table lists the hyperparameters used in the safety experiments of the RAINBOW TEAMING approach.  It includes the number of initial examples used to seed the algorithm, batch size for training, the number of iterations run, the BLEU similarity filter threshold for diversity, the archive sampling temperature controlling exploration-exploitation balance, the size of the archive, generation temperature, top-k sampling parameter, maximum tokens for prompt generation, learning rate for fine-tuning (SFT), batch size for SFT, learning rate scheduler used, and sequence length for SFT.", "section": "4 RAINBOW TEAMING for Safety"}, {"figure_path": "FCsEvaMorw/tables/tables_31_2.jpg", "caption": "Table 11: List of hyperparameters used in question answering experiments.", "description": "This table lists the hyperparameters used in the question answering experiments of the RAINBOW TEAMING approach.  It details values for parameters related to the RAINBOW TEAMING algorithm itself (number of initial examples, dataset used, batch size, iterations, BLEU similarity filter threshold, archive sampling temperature, and archive size) as well as for the prompt generation process (temperature, top-k sampling, and maximum number of tokens).  These settings were crucial in controlling the diversity and effectiveness of the generated adversarial questions.", "section": "3.1 Prompt Features"}, {"figure_path": "FCsEvaMorw/tables/tables_31_3.jpg", "caption": "Table 1: Comparison of RAINBOW TEAMING against PAIR [8] for eliciting harmful behaviours from JailbreakBench [9]. Top: (n/k) indicates the total number of successful jailbreaks (n) and the total number of behaviours jailbroken (k) for each method and classifier (best of 4 responses). Bottom: Self-BLEU similarity score.", "description": "This table compares the performance of RAINBOW TEAMING against two versions of the PAIR method in eliciting harmful behaviors from the JailbreakBench dataset.  It shows the number of successful jailbreaks achieved by each method, using two different classifiers: the JailbreakBench classifier and Llama Guard. A lower Self-BLEU score indicates higher diversity in the generated prompts.", "section": "4.1 Results"}]