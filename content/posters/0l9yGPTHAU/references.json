{"references": [{"fullname_first_author": "Alekh Agarwal", "paper_title": "Model-based reinforcement learning with a generative model is minimax optimal", "publication_date": "2020-00-00", "reason": "This paper establishes the minimax optimality of model-based reinforcement learning with a generative model, a benchmark result that the current paper builds upon and improves."}, {"fullname_first_author": "Mohammad Gheshlaghi Azar", "paper_title": "Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model", "publication_date": "2013-00-00", "reason": "This is a foundational paper on the sample complexity of reinforcement learning that provides a benchmark for the current work's analysis of distributionally robust reinforcement learning."}, {"fullname_first_author": "Jose Blanchet", "paper_title": "Quantifying distributional model risk via optimal transport", "publication_date": "2019-00-00", "reason": "This paper introduces a novel framework for quantifying distributional model risk using optimal transport, which is highly relevant to the distributionally robust setting studied in the current work."}, {"fullname_first_author": "Pierre Clavier", "paper_title": "Towards minimax optimality of model-based robust reinforcement learning", "publication_date": "2023-00-00", "reason": "This paper is directly related to the current work, providing state-of-the-art upper bounds for solving robust MDPs with specific Lp norms that the current paper improves upon."}, {"fullname_first_author": "Garud N Iyengar", "paper_title": "Robust dynamic programming", "publication_date": "2005-00-00", "reason": "This paper is a foundational work in distributionally robust dynamic programming, introducing many key concepts and techniques used in the current paper's theoretical analysis."}]}