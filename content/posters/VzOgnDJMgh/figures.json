[{"figure_path": "VzOgnDJMgh/figures/figures_3_1.jpg", "caption": "Figure 1: Unlearning efficacy and utility performance of NPO-based unlearning on TOFU dataset vs. sparsity of unlearned weights (i.e., the proportion of weights required for unlearning updates), which is achieved using the LLM pruning method Wanda.", "description": "This figure shows the trade-off between unlearning efficacy and model utility when using different levels of weight sparsity in the NPO-based unlearning method.  The x-axis represents the percentage of weights updated during the unlearning process (sparsity), achieved through the Wanda pruning method. The y-axis shows two metrics: unlearning efficacy and utility.  As sparsity increases (more weights are pruned), unlearning efficacy initially improves but then sharply decreases.  Meanwhile, utility shows the opposite trend generally increasing with sparsity, suggesting a trade-off between effectively removing unwanted knowledge and preserving the model's overall functionality.  This highlights the challenge of finding an optimal balance between removing undesirable data and preserving model utility, motivating the need for a more principled approach to weight selection in LLM unlearning, which the paper introduces.", "section": "Weight attribution in LLM unlearning: Rationale and motivation"}, {"figure_path": "VzOgnDJMgh/figures/figures_8_1.jpg", "caption": "Figure 1: Unlearning efficacy and utility performance of NPO-based unlearning on TOFU dataset vs. sparsity of unlearned weights (i.e., the proportion of weights required for unlearning updates), which is achieved using the LLM pruning method Wanda.", "description": "This figure shows the performance of negative preference optimization (NPO) based unlearning on the TOFU dataset as the sparsity of unlearned weights changes.  Sparsity is controlled using the Wanda LLM pruning method.  The graph plots both unlearning efficacy and model utility.  It demonstrates a trade-off: higher sparsity leads to better unlearning efficacy but reduces model utility. This highlights the challenge of finding an optimal subset of weights that balances efficacy and utility preservation during LLM unlearning, underscoring the need for a more principled approach to weight selection than simple pruning.", "section": "Weight attribution in LLM unlearning: Rationale and motivation"}, {"figure_path": "VzOgnDJMgh/figures/figures_8_2.jpg", "caption": "Figure 2: Density of selected weights within each module of a fine-tuned LLaMA2-7B-chat LLM on TOFU, with an overall weight selection ratio 80%.", "description": "This figure shows the density of selected weights within each module of the LLaMA2-7B-chat large language model after fine-tuning on the TOFU dataset using a weight selection ratio of 80%. The modules include input layer (in), layer normalization (ln), multi-layer perceptron (MLP) components (dn, gt, up), post-attention layer (post), self-attention components (sa_q, sa_k, sa_v, sa_o).  The comparison is made between weights selected based on their magnitude and the weights selected by the proposed WAGLE method. It highlights the different distributions of influential weights in each module of the model, showcasing how the WAGLE method's weight attribution contrasts with magnitude-based selection.", "section": "Exploring model fingerprint of LLM unlearning from weight attribution"}, {"figure_path": "VzOgnDJMgh/figures/figures_9_1.jpg", "caption": "Figure 1: Unlearning efficacy and utility performance of NPO-based unlearning on TOFU dataset vs. sparsity of unlearned weights (i.e., the proportion of weights required for unlearning updates), which is achieved using the LLM pruning method Wanda.", "description": "This figure shows the relationship between unlearning efficacy and model utility as a function of the sparsity of unlearned weights.  The experiment used the NPO (Negative Preference Optimization) unlearning method on the TOFU (Fictitious Unlearning) dataset.  The sparsity was manipulated using the Wanda LLM pruning method.  The results indicate a strong trade-off between unlearning efficacy and model utility, demonstrating that simply pruning weights is not an effective unlearning strategy.  As the sparsity increases (meaning fewer weights are updated during unlearning), the unlearning efficacy sharply decreases, while the utility (measured as the model's ability to perform well on the retained data) remains more stable. This suggests a need for more principled methods of selecting which weights to update during unlearning.", "section": "Weight attribution in LLM unlearning: Rationale and motivation"}, {"figure_path": "VzOgnDJMgh/figures/figures_18_1.jpg", "caption": "Figure A1: UE vs. different weight selection ratios for weight attribution on the TOFU unlearning task across different unlearning objectives.", "description": "This figure displays the unlearning efficacy (UE) on the TOFU dataset for different weight selection ratios (60%, 80%, 95%, 99%) used in weight attribution.  It shows three separate lines, one each for the NPO, GradDiff, and PO unlearning methods.  The graph helps visualize how the average unlearning efficacy changes for each method depending on the percentage of weights updated during the process. This allows for an analysis of the optimal weight sparsity for different unlearning algorithms, revealing the trade-off between the unlearning efficacy and utility.", "section": "C Additional Experiments"}, {"figure_path": "VzOgnDJMgh/figures/figures_18_2.jpg", "caption": "Figure A2: Density of selected weights within each layer of a fine-tuned LLaMA2-7B-chat LLM on TOFU, with an overall weight selection ratio 80%.", "description": "This figure shows the density of selected weights in each layer of a fine-tuned LLaMA2-7B-chat large language model (LLM) on the TOFU dataset.  The overall weight selection ratio is 80%, meaning that only 80% of the weights were selected for unlearning. The figure compares the density of weights selected using the proposed WAGLE method with the density of weights selected based solely on their magnitudes. The comparison highlights how the method focuses more on selecting weights from certain layers (early-to-mid layers) while the magnitude based selection is less selective.", "section": "C Additional Experiments"}]