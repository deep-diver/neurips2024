[{"figure_path": "ykQnxko1cJ/figures/figures_1_1.jpg", "caption": "Figure 1: Visualization of the samples with different similarities. Given an inquiry image, it can form a hypersphere based on similarity to the inquiry image, where samples with the same similarity share the same radius. Samples with similarities between 0 to 1 with an interval of 0.33 are shown. With our proposed CemiFace, each inquiry image finally forms a novel subject.", "description": "This figure visualizes how the proposed method, CemiFace, generates synthetic face images with varying degrees of similarity to an input (inquiry) image.  It illustrates the concept of a hypersphere in the latent feature space where samples of the same identity are clustered. Samples with different similarity levels (0, 0.33, 0.66, 1.0) to the inquiry image are shown, demonstrating how the generated samples range from highly similar to dissimilar to the input.", "section": "3 The proposed approach"}, {"figure_path": "ykQnxko1cJ/figures/figures_3_1.jpg", "caption": "Figure 2: Samples with different similarity groups from CASIA-WebFace dataset. From left to right are samples with lower similarity to the identity center", "description": "This figure shows samples from the CASIA-WebFace dataset grouped by their similarity to their respective identity centers.  Each row represents a different level of similarity, ranging from high similarity (left) to low similarity (right). The purpose is to visually demonstrate the impact of sample similarity to the identity center on the effectiveness of face recognition model training.  Samples with intermediate similarity levels are hypothesized to be most effective.", "section": "3.1 The Relationship between Samples Similarity and Performance Degradation"}, {"figure_path": "ykQnxko1cJ/figures/figures_4_1.jpg", "caption": "Figure 3: Illustration of our proposed method. The left part is the training framework for learning images with various levels of similarity. Firstly noise is added to the clean facial image before it is processed by the diffusion model. Then similarity controlling condition m ranging between [-1,1] with facial embedding is injected to guide the generation. Consequently, the model outputs the estimated noise, which is adopted to calculate the estimated image. We add similarity matching loss LsimMat between the estimated image and the input image. For generation, we gradually denoise a noising image with time step scaling from T to 0, conditions for identity and similarity are left fixed. The two diffusion models in the generation part mean the same diffusion model at two different time steps. The right bottom part is the details of using cross-attention to inject similarity condition and facial embedding into the diffusion models", "description": "This figure illustrates the CemiFace model's training and inference processes.  The left side shows the training process, involving noise addition to input images, condition injection (similarity and identity), and loss calculation (LMSE and LSimMat). The right side details the inference process: starting with random noise and gradually denoising based on identity and similarity conditions, producing synthetic facial images.", "section": "3.2 Center-based Semi-hard Face Image Generator"}, {"figure_path": "ykQnxko1cJ/figures/figures_6_1.jpg", "caption": "Figure 4: Accuracy of samples with different similarity varying from -1 to 1. The left figure is the specific performance on each evaluation dataset. The right figure is the average accuracy of our CemiFace", "description": "This figure displays the impact of different similarity levels (m) on face recognition model performance.  The left panel shows the accuracy on five different benchmark datasets (LFW, CFP-FP, AgeDB-30, CALFW, CPLFW) for samples generated with varying similarity to their identity centers (m ranges from -1 to 1). The right panel shows the average accuracy across these five datasets. The results indicate an optimal performance around m = 0, suggesting that samples with a moderate degree of similarity to their identity centers are most effective for training.", "section": "4.2 Ablation Studies"}, {"figure_path": "ykQnxko1cJ/figures/figures_9_1.jpg", "caption": "Figure 5: Sample Visualization under different similarity. From left to right are inquiry images, images with m from 1 to -1 and samples generated by DCFace. Different rows in each inquiry group represent the results produced by different noises. The first column are the inquiry images. The yellow dashed box includes samples where we obtain the best accuracy. Pink dashed boxes are samples that vary vastly.", "description": "This figure visualizes samples generated with different similarity factors (m) ranging from 1.0 to -1.0, demonstrating how the generated images change as the similarity to the input image varies.  The leftmost column shows the input images. Each row uses the same random noise to highlight the effect of the similarity factor. The yellow boxes show samples with the best accuracy while the pink boxes show samples with the most variation.  Results from DCFace are included for comparison.", "section": "4.3.2 Qualitative Results"}, {"figure_path": "ykQnxko1cJ/figures/figures_15_1.jpg", "caption": "Figure 5: Sample Visualization under different similarity. From left to right are inquiry images, images with m from 1 to -1 and samples generated by DCFace. Different rows in each inquiry group represent the results produced by different noises. The first column are the inquiry images. The yellow dashed box includes samples where we obtain the best accuracy. Pink dashed boxes are samples that vary vastly.", "description": "This figure visualizes samples generated with different similarity values (m) ranging from 1 to -1, demonstrating the impact of this parameter on the diversity and similarity to the inquiry image. The results generated by DCFace are also shown for comparison.  The yellow boxes highlight samples achieving the best accuracy, while pink boxes indicate highly varied samples.", "section": "4.3.2 Qualitative Results"}, {"figure_path": "ykQnxko1cJ/figures/figures_16_1.jpg", "caption": "Figure 7: T-SNE visualization. The bottom figure is the T-SNE generated by 1-shot data with similarity of 1.0, 0.0 and -1.0 respectively. The upper figure is different inquiry centers with two similarities 1.0 and -1.0, the random center is also given. Red circles are samples worth noticing, with their order being green, red, and grey, positioned from center to outside", "description": "This figure visualizes the results of t-distributed stochastic neighbor embedding (t-SNE) on different datasets. The upper panel compares samples generated from 1-shot data, class center data, and random center data. It shows how different data sources and similarity levels affect the clustering of samples. The lower panel shows the clustering of samples with varying similarity levels (1.0, 0.0, and -1.0) using 1-shot data, highlighting the effect of similarity on sample distribution.", "section": "4.2.1 Impact of Similarity m"}, {"figure_path": "ykQnxko1cJ/figures/figures_17_1.jpg", "caption": "Figure 5: Sample Visualization under different similarity. From left to right are inquiry images, images with m from 1 to -1 and samples generated by DCFace. Different rows in each inquiry group represent the results produced by different noises. The first column are the inquiry images. The yellow dashed box includes samples where we obtain the best accuracy. Pink dashed boxes are samples that vary vastly.", "description": "This figure visualizes samples generated with different similarity levels (m) ranging from 1 to -1. Each row uses the same noise input, demonstrating how varying the similarity factor affects the generated images.  The leftmost column shows the inquiry images used as input.  A yellow box highlights samples with the best accuracy, while pink boxes show samples with significant variations. The comparison with DCFace generated samples is also included.", "section": "4.3.2 Qualitative Results"}, {"figure_path": "ykQnxko1cJ/figures/figures_19_1.jpg", "caption": "Figure 5: Sample Visualization under different similarity. From left to right are inquiry images, images with m from 1 to -1 and samples generated by DCFace. Different rows in each inquiry group represent the results produced by different noises. The first column are the inquiry images. The yellow dashed box includes samples where we obtain the best accuracy. Pink dashed boxes are samples that vary vastly.", "description": "This figure visualizes samples generated with different similarity (m) values ranging from 1.0 to -1.0, along with samples generated by DCFace.  Each row uses the same noise input to highlight variations based on the similarity parameter.  The leftmost column shows the input (inquiry) images. Yellow boxes show the samples that produced the best accuracy; pink boxes highlight samples showing significant variations.", "section": "4.3.2 Qualitative Results"}]