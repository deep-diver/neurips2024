[{"figure_path": "DHucngOEe3/tables/tables_5_1.jpg", "caption": "Table 1: Performance of MGPO compared with baseline methods. Each result shows the average performance on all test tasks in the environment and the standard deviation across 3 random seeds for online test. Goal-conditioned BC has no error bars since it does not perform online optimization.", "description": "This table compares the performance of MGPO against several baseline methods across various environments (MazeRunner-15, MazeRunner-30, Kitchen, GridWorld, and Crafter).  The metrics reported are the average performance across all test tasks within each environment and the standard deviation is calculated from 3 independent runs.  Goal-conditioned BC serves as a simple baseline without online optimization, hence it doesn't have error bars.", "section": "4 Experiments"}, {"figure_path": "DHucngOEe3/tables/tables_6_1.jpg", "caption": "Table 2: Performance of MGPO with different prompt optimization methods. Each result shows the average performance on all test tasks in the environment and the standard deviation across 3 random seeds for online test.", "description": "This table presents the average performance and standard deviation across three random seeds of MGPO using five different prompt optimization methods (GRIPS, BBT, explore, UCB, and BPE) on four different environments (MazeRunner-15, MazeRunner-30, Kitchen, GridWorld, and Crafter).  The results demonstrate the performance of each prompt optimization strategy in the online adaptation phase of MGPO.", "section": "4.3 Prompt Optimization Methods"}, {"figure_path": "DHucngOEe3/tables/tables_6_2.jpg", "caption": "Table 3: Performance of prompts optimized with different methods in Kitchen with noisy observations or actions. Each result shows the average performance on all test tasks and the decrease compared with the environment without noise.", "description": "This table presents the performance of different prompt optimization methods (GRIPS, BBT, UCB, BPE) in the Kitchen environment under noisy conditions.  It shows the average performance on all test tasks and the performance decrease compared to a noise-free environment.  The results are useful for comparing the robustness of different methods to noisy observations and actions.", "section": "4.3 Prompt Optimization Methods"}, {"figure_path": "DHucngOEe3/tables/tables_7_1.jpg", "caption": "Table 4: Results of ablation study on MGPO with varying maximal prompt length K and hyperparameter c in UCB.", "description": "This table presents the results of an ablation study conducted on the Multi-Goal Transformers with Prompt Optimization (MGPO) method.  The study investigated the impact of two key factors: the maximal prompt length (K) and the hyperparameter (c) used in the Upper Confidence Bound (UCB) algorithm for prompt optimization. The results are shown for three different environments: Maze Runner-15, Maze Runner-30, and Kitchen.  The table allows for a comparison of MGPO's performance under different settings of K and c, facilitating an understanding of their relative contributions to the overall performance of the model.", "section": "4.4 Ablation Study"}, {"figure_path": "DHucngOEe3/tables/tables_15_1.jpg", "caption": "Table 5: Results of ablation study on varying dataset quality, evaluated with MGPO-UCB.", "description": "This table shows the ablation study result of MGPO-UCB on varying dataset quality. The datasets are collected using A* algorithm with a maximum of n goal switches per episode as A*-n, and datasets from a random exploration policy as Random. The results show that MGPO achieves better performance trained on A*-2 datasets than A*-1, indicating its efficacy with data containing diverse long-horizon behaviors. The comparatively lower performance on the A*-4 dataset in MazeRunner-30 and Random datasets suggests MGPO\u2019s reliance on the quality of data collection policies.", "section": "B.3 Ablation Study on Dataset Quality"}, {"figure_path": "DHucngOEe3/tables/tables_19_1.jpg", "caption": "Table 1: Performance of MGPO compared with baseline methods. Each result shows the average performance on all test tasks in the environment and the standard deviation across 3 random seeds for online test. Goal-conditioned BC has no error bars since it does not perform online optimization.", "description": "This table compares the performance of the proposed MGPO method against several baseline methods across various environments (Maze Runner-15, Maze Runner-30, Kitchen, GridWorld, and Crafter).  The results show the average performance and standard deviation across three random seeds for each method on all test tasks within each environment.  Goal-conditioned BC serves as a baseline representing performance without online optimization, thus it lacks error bars.", "section": "4 Experiments"}, {"figure_path": "DHucngOEe3/tables/tables_20_1.jpg", "caption": "Table 1: Performance of MGPO compared with baseline methods. Each result shows the average performance on all test tasks in the environment and the standard deviation across 3 random seeds for online test. Goal-conditioned BC has no error bars since it does not perform online optimization.", "description": "This table compares the performance of the proposed method MGPO against several baseline methods across various tasks. The metrics used are the average performance and standard deviation of the return obtained across three different random seeds for each method on all test tasks in the environment.  The goal-conditioned BC baseline is included, but lacks error bars because it does not perform any online optimization.", "section": "4 Experiments"}, {"figure_path": "DHucngOEe3/tables/tables_20_2.jpg", "caption": "Table 1: Performance of MGPO compared with baseline methods. Each result shows the average performance on all test tasks in the environment and the standard deviation across 3 random seeds for online test. Goal-conditioned BC has no error bars since it does not perform online optimization.", "description": "This table presents the average performance and standard deviation across three random seeds for five different methods (Goal-conditioned BC, BC-finetune, SPiRL, PTGM, and MGPO) on four different tasks (Maze Runner-15, Maze Runner-30, Kitchen, GridWorld, and Crafter).  Goal-conditioned BC serves as a baseline representing the initial performance before online optimization. The table highlights the significant improvement in performance achieved by MGPO compared to existing methods in all tasks.", "section": "4 Experiments"}, {"figure_path": "DHucngOEe3/tables/tables_21_1.jpg", "caption": "Table 1: Performance of MGPO compared with baseline methods. Each result shows the average performance on all test tasks in the environment and the standard deviation across 3 random seeds for online test. Goal-conditioned BC has no error bars since it does not perform online optimization.", "description": "This table compares the performance of the proposed MGPO method against several baseline methods across four different environments (MazeRunner-15, MazeRunner-30, Kitchen, GridWorld, and Crafter).  The performance is measured by the average return obtained during online adaptation, using 100 episodes. Error bars represent standard deviations across three random seeds. The goal-conditioned BC baseline serves as a reference, representing performance without online optimization.", "section": "4 Experiments"}, {"figure_path": "DHucngOEe3/tables/tables_21_2.jpg", "caption": "Table 8: Performance of the BC-finetune baseline with different RL algorithms.", "description": "This table compares the performance of the BC-finetune baseline method using two different reinforcement learning algorithms: REINFORCE and PPO.  The results are shown for five different environments: MazeRunner-15, MazeRunner-30, Kitchen, GridWorld, and Crafter.  The average performance and standard deviation across three random seeds are provided for each environment and algorithm.", "section": "4.2 Baselines and Main Results"}, {"figure_path": "DHucngOEe3/tables/tables_21_3.jpg", "caption": "Table 1: Performance of MGPO compared with baseline methods. Each result shows the average performance on all test tasks in the environment and the standard deviation across 3 random seeds for online test. Goal-conditioned BC has no error bars since it does not perform online optimization.", "description": "This table presents a comparison of the proposed MGPO method against several baseline methods across various environments (MazeRunner-15, MazeRunner-30, Kitchen, GridWorld, and Crafter).  The metrics shown represent the average performance and standard deviation across three random seeds during online testing.  Goal-conditioned BC serves as a baseline representing performance without online optimization and thus shows no error bars.", "section": "4 Experiments"}, {"figure_path": "DHucngOEe3/tables/tables_22_1.jpg", "caption": "Table 1: Performance of MGPO compared with baseline methods. Each result shows the average performance on all test tasks in the environment and the standard deviation across 3 random seeds for online test. Goal-conditioned BC has no error bars since it does not perform online optimization.", "description": "This table compares the performance of the proposed method MGPO against several baseline methods across various environments. The results show the average performance and standard deviation across three random seeds for each environment. Goal-conditioned BC, which doesn't use online optimization, is included as a baseline for comparison.", "section": "4 Experiments"}]