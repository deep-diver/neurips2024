[{"figure_path": "FwhM1Zpyft/tables/tables_8_1.jpg", "caption": "Table 1: Comparison of different toolkits and BICCOS on VNN-COMP benchmarks. Results on non-CROWN or BICCOS were run on different hardware. \"-\" indicates that the benchmark was not supported.", "description": "This table compares the performance of various neural network verification tools on the VNN-COMP benchmarks.  The tools include nnenum, Marabou, ERAN, OVAL, Venus2, VeriNet, MN-BaB, and PyRAT, along with the baseline methods B-CROWN and GCP-CROWN (using MIP cuts).  The main focus is on the scalability and effectiveness of the proposed BICCOS method, indicated by the number of verified instances and the verification time for each benchmark.  The '-' indicates that a specific method did not support a given benchmark.", "section": "4 Experiments"}, {"figure_path": "FwhM1Zpyft/tables/tables_8_2.jpg", "caption": "Table 2: Verified accuracy (Ver.%) and avg. per-example verification time (s) on 7 models from [15].", "description": "This table presents the verified accuracy and average per-example verification time for seven different models.  The models were tested using various verification methods including PRIMA, B-CROWN, MN-BaB, Venus2, GCP-CROWN (with MIP cuts), and BICCOS.  The results show a comparison of the performance of these different methods across various models and highlight the improvement offered by BICCOS.", "section": "4 Experiments"}, {"figure_path": "FwhM1Zpyft/tables/tables_9_1.jpg", "caption": "Table 1: Comparison of different toolkits and BICCOS on VNN-COMP benchmarks. Results on non-CROWN or BICCOS were run on different hardware. \"-\" indicates that the benchmark was not supported.", "description": "This table compares the performance of various neural network verification tools, including BICCOS, on several benchmarks from the VNN-COMP competition.  The tools are evaluated based on their verification time and the number of instances successfully verified.  The table highlights BICCOS's superior performance, particularly on larger network architectures where other tools struggle.", "section": "4 Experiments"}, {"figure_path": "FwhM1Zpyft/tables/tables_20_1.jpg", "caption": "Table 1: Comparison of different toolkits and BICCOS on VNN-COMP benchmarks. Results on non-CROWN or BICCOS were run on different hardware. \"-\" indicates that the benchmark was not supported.", "description": "This table compares the performance of various neural network verification tools on several VNN-COMP benchmarks.  It shows the verification time and the number of verified instances for each tool on different benchmark datasets. The tools compared include several state-of-the-art methods (nnenum, Marabou, ERAN, OVAL, Venus2, VeriNet, MN-BaB, PyRAT, B-CROWN, GCP-CROWN with MIP cuts) and the proposed BICCOS method.  The table highlights BICCOS's superior performance, particularly on larger networks that other cutting-plane methods struggle with.", "section": "4 Experiments"}]