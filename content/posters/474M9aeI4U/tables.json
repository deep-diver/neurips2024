[{"figure_path": "474M9aeI4U/tables/tables_8_1.jpg", "caption": "Table 1: Quantitative comparison among COVE and a wide range of state-of-the-art video editing methods. The evaluation metrics [31] can effectively reflect the temporal consistency and frame quality of generated videos. COVE illustrates superior performance in both keeping the temporal consistency and generating frames with high quality in edited videos.", "description": "This table presents a quantitative comparison of COVE with five state-of-the-art video editing methods using four metrics from VBench [31]: Subject Consistency, Motion Smoothness, Aesthetic Quality, and Imaging Quality.  It also includes the results of a user study comparing user preference for the different methods.  COVE demonstrates superior performance across all metrics, particularly in user preference.", "section": "4.3 Quantitative Results"}, {"figure_path": "474M9aeI4U/tables/tables_8_2.jpg", "caption": "Table 2: Ablation study on the value of K in correspondence-guided attention. w/o means without correspondence-guided attention in Unet. When K = 3 the quality of the video is the best.", "description": "This table presents the results of an ablation study on the impact of the number of tokens (K) used in correspondence-guided attention on video quality.  It compares different values of K (1, 3, and 5) against a baseline (w/o) where correspondence-guided attention is not used. The metrics used are Subject Consistency, Motion Smoothness, Aesthetic Quality, and Imaging Quality.  The results show that increasing K from 1 to 3 improves all metrics, but further increasing K to 5 provides only minimal gains.", "section": "4.4 Ablation Study"}, {"figure_path": "474M9aeI4U/tables/tables_9_1.jpg", "caption": "Table 3: Ablation Study on the effect of temporal dimensional token merging. Temporal dimensional token merging can speed up the editing process and save GPU memory usage while hardly impairing the quality of the generated video. The experiment is conducted on a single RTX3090 GPU with a 10-frame source video. k is set to 3.", "description": "This table presents the results of an ablation study on the impact of temporal dimensional token merging in the video editing process.  The study compared three different configurations: (1) without correspondence-guided attention and without token merging; (2) with correspondence-guided attention but without token merging; and (3) with both correspondence-guided attention and token merging. The metrics used for comparison were speed and GPU memory usage.  The results show that token merging significantly improves speed and reduces GPU memory usage without substantial loss in video quality.", "section": "4.4 Ablation Study"}, {"figure_path": "474M9aeI4U/tables/tables_14_1.jpg", "caption": "Table 1: Quantitative comparison among COVE and a wide range of state-of-the-art video editing methods. The evaluation metrics [31] can effectively reflect the temporal consistency and frame quality of generated videos. COVE illustrates superior performance in both keeping the temporal consistency and generating frames with high quality in edited videos.", "description": "This table quantitatively compares COVE against five state-of-the-art video editing methods across multiple metrics.  The metrics used assess subject consistency, motion smoothness, aesthetic quality, and imaging quality.  COVE shows superior results in all four categories, demonstrating improved temporal consistency and higher overall quality compared to existing methods.", "section": "4.3 Quantitative Results"}, {"figure_path": "474M9aeI4U/tables/tables_15_1.jpg", "caption": "Table 5: Accuracy of Correspondance.", "description": "This table presents the accuracy (PCK) of correspondence obtained using two different methods: Optical-flow Correspondence and Diffusion feature Correspondence.  The diffusion feature correspondence method demonstrates higher accuracy (0.92) compared to the optical-flow method (0.87). This highlights the superior precision of using diffusion features for identifying corresponding tokens in video frames.", "section": "D Accuracy of Correspondance"}]