[{"figure_path": "Prw98p1nV0/figures/figures_4_1.jpg", "caption": "Figure 1: Interactive teaching, Sharpness Reduction Interactive Teaching (SRIT), the plane in the figure represents the loss landscape, which gradually becomes flat during the iterative optimization process due to the receipt of flat gradient information cues from each other.", "description": "This figure illustrates the iterative process of interactive teaching and its enhancement with Sharpness Reduction Interactive Teaching (SRIT). The loss landscape is represented as a 3D surface, showing how the landscape changes over iterations.  Initially, the landscape is complex and has many sharp peaks (high loss values).  As interactive teaching proceeds,  both models (f and g) learn to focus on low-loss regions by selectively discarding high-loss data points, leading to a gradual flattening of the landscape. SRIT further refines this by incorporating gradient information into the exchange process, leading to even greater flattening and improved generalization.", "section": "4 Theoretical Analysis and Solution"}, {"figure_path": "Prw98p1nV0/figures/figures_4_2.jpg", "caption": "Figure 2: Loss landscape, we can broadly assume that in each iteration, a fixed cutting plane is used to remove the peaks with high loss values.", "description": "This figure is a 3D plot showing a loss landscape.  The landscape is a complex, multi-peaked surface representing the loss function of a model across different parameter settings (x and y axes). A flat plane, the \"cutting plane\", intersects the landscape. The cutting plane cuts off the high loss regions in each iteration. The caption indicates that the process iteratively removes regions of high loss, shaping the loss landscape to be more desirable for training.", "section": "4.1 Analysis of parameter update mechanism"}, {"figure_path": "Prw98p1nV0/figures/figures_6_1.jpg", "caption": "Figure 1: Interactive teaching, Sharpness Reduction Interactive Teaching (SRIT), the plane in the figure represents the loss landscape, which gradually becomes flat during the iterative optimization process due to the receipt of flat gradient information cues from each other.", "description": "This figure illustrates the iterative optimization process of interactive teaching and SRIT methods on the loss landscape.  The plane represents the loss landscape.  Interactive teaching methods iteratively update parameters, leading to a flatter loss landscape. SRIT further enhances this by incorporating gradient information, resulting in even greater flatness.", "section": "4.1 Analysis of parameter update mechanism"}, {"figure_path": "Prw98p1nV0/figures/figures_9_1.jpg", "caption": "Figure 3: Testings of five datasets by noise type, and the noise ratio is 20%.", "description": "This figure displays the testing performance of five datasets (MNIST, FMNIST, CIFAR10, CIFAR100, SVHN) under four different noise types (Pairflip, Symmetric, Tridiagonal, Instance) and with a noise rate of 20%.  The charts compare the performance of co-teaching and the proposed Sharpness Reduction Interactive Teaching (SRIT) method. It visually demonstrates the improvement in accuracy and generalization capability achieved by SRIT across different datasets and noise types. The x-axis represents the training epochs, and the y-axis represents the test accuracy.", "section": "5 Experiments"}, {"figure_path": "Prw98p1nV0/figures/figures_15_1.jpg", "caption": "Figure 3: Testings of five datasets by noise type, and the noise ratio is 20%.", "description": "This figure shows the test accuracy of five datasets (MNIST, FMNIST, CIFAR10, SVHN, CIFAR100) under four different noise types (Pairflip, Symmetric, Tridiagonal, Instance) with a noise ratio of 20%.  The results compare the performance of co-teaching and the proposed SRIT (Sharpness Reduction Interactive Teaching) method.  Each subplot represents a dataset and shows how the test accuracy changes over epochs for each noise type and algorithm. The plots visually demonstrate that SRIT consistently achieves better generalization performance compared to co-teaching across all datasets and noise types.", "section": "5 Experiments"}, {"figure_path": "Prw98p1nV0/figures/figures_16_1.jpg", "caption": "Figure 3: Testings of five datasets by noise type, and the noise ratio is 20%.", "description": "This figure displays the accuracy performance of the co-teaching and SRIT (Sharpness Reduction Interactive Teaching) methods across five different datasets (MNIST, FMNIST, CIFAR10, SVHN, CIFAR100) under four types of noise (Pairflip, Symmetric, Tridiagonal, Instance) with a noise rate of 20%.  Each subplot represents a specific noise type, showing accuracy plotted against epochs for both co-teaching and SRIT. The purpose is to visually compare the performance of the two methods under various noise conditions and across diverse datasets.", "section": "5 Experiments"}, {"figure_path": "Prw98p1nV0/figures/figures_16_2.jpg", "caption": "Figure 3: Testings of five datasets by noise type, and the noise ratio is 20%.", "description": "This figure displays the accuracy performance of the Co-teaching and SRIT methods across five datasets (MNIST, FMNIST, CIFAR10, SVHN, and CIFAR100) under four different noise types (Pairflip, Symmetric, Tridiagonal, and Instance) with a noise ratio of 20%. Each subplot represents a dataset, and within each subplot, the accuracy curves for Co-teaching and SRIT are shown.  The figure demonstrates the superior generalization performance of SRIT across various datasets and noise types.", "section": "5 Experiments"}, {"figure_path": "Prw98p1nV0/figures/figures_16_3.jpg", "caption": "Figure 3: Testings of five datasets by noise type, and the noise ratio is 20%.", "description": "This figure shows the test accuracy for five datasets (MNIST, FMNIST, CIFAR10, SVHN, and CIFAR100) with four different noise types (Pairflip, Symmetric, Trid, and Instance) at a noise rate of 20%.  Each subplot represents a different dataset and shows the accuracy over epochs for both the co-teaching and the SRIT (Sharpness Reduction Interactive Teaching) methods.  The plots visually compare the performance and convergence speed of the two methods under various noise conditions.", "section": "5 Experiments"}, {"figure_path": "Prw98p1nV0/figures/figures_16_4.jpg", "caption": "Figure 3: Testings of five datasets by noise type, and the noise ratio is 20%.", "description": "This figure displays the test accuracy over epochs for five datasets (MNIST, FMNIST, CIFAR10, SVHN, CIFAR100) under four different noise types (Pairflip, Symmetric, Trid, Instance) with a noise rate of 20%.  It compares the performance of the co-teaching method with the proposed SRIT (Sharpness Reduction Interactive Teaching) method.  The plots visualize how the accuracy changes over the training epochs for each method, dataset, and noise type, showing SRIT's generally superior performance and robustness to noisy data.", "section": "5 Experiments"}]