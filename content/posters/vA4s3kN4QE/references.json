{"references": [{"fullname_first_author": "Aaron van den Oord", "paper_title": "Neural discrete representation learning", "publication_date": "2017-12-03", "reason": "This paper introduces the Vector Quantized Variational Autoencoder (VQ-VAE), a foundational model for the vector quantization methods used in the current paper."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-06-14", "reason": "This paper introduces VQ-GAN, a significant advancement in vector quantization for image generation, directly influencing the current paper's approach."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-26", "reason": "CLIP, introduced in this paper, is a crucial component of the current paper's language-guided codebook learning framework, providing pre-trained text semantics."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-14", "reason": "This paper's introduction of high-resolution image synthesis techniques using latent diffusion models is relevant to the current paper's goals of improving image generation quality."}, {"fullname_first_author": "Baoquan Zhang", "paper_title": "Codebook transfer with part-of-speech for vector-quantized image modeling", "publication_date": "2024-06-17", "reason": "This paper, also by members of the current research team, is likely important because of its close relationship to the present work, potentially providing foundational methods or datasets used in the present work."}]}