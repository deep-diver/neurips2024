{"references": [{"fullname_first_author": "Rohan Anil", "paper_title": "Gemini: A family of highly capable multimodal models", "publication_date": "2023-12-11", "reason": "This paper introduces Gemini, a family of multimodal models that achieves state-of-the-art results on various tasks and is directly relevant to the capabilities of VLMs."}, {"fullname_first_author": "Tom B. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This foundational paper demonstrates the capabilities of language models as few-shot learners, which is crucial to the zero-shot learning approach of SpatialPIN."}, {"fullname_first_author": "Boyuan Chen", "paper_title": "SpatialVLM: Endowing vision-language models with spatial reasoning capabilities", "publication_date": "2024-01-12", "reason": "This paper is the most directly related work, focusing on enhancing VLMs with spatial reasoning capabilities, thus providing a strong baseline for comparison and a key context for SpatialPIN's advancements."}, {"fullname_first_author": "Tim Brooks", "paper_title": "Instructpix2pix: Learning to follow image editing instructions", "publication_date": "2023-06-01", "reason": "This paper presents a method for improving image understanding through language-guided editing, an approach directly relevant to SpatialPIN's method of improving VLM spatial understanding through progressive prompting."}, {"fullname_first_author": "Shariq Farooq Bhat", "paper_title": "Zoedepth: Zero-shot transfer by combining relative and metric depth", "publication_date": "2023-02-12", "reason": "This paper introduces a method for zero-shot depth estimation, crucial to SpatialPIN's ability to leverage 3D information from foundation models without requiring additional training or fine-tuning."}]}