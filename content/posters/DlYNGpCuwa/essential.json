{"importance": "This paper is important because it presents a novel and efficient approach to improve the alignment of large language models (LLMs) with user preferences using readily available user edit data, thus reducing the cost and complexity of traditional fine-tuning methods.  It offers a scalable solution for personalizing LLM agents without sacrificing safety guarantees or interpretability, opening new avenues for research in interactive learning and LLM personalization.", "summary": "PRELUDE, a novel framework, leverages user edits of LLM outputs to learn latent preferences, improving agent alignment and minimizing edit costs.  CIPHER, its efficient algorithm, infers preferences from user edits and uses them to guide future responses.", "takeaways": ["User edits are effectively used to learn latent preferences, improving LLM agents' alignment with users.", "CIPHER, an efficient algorithm, infers and reuses user preferences to generate better responses and minimize user edit costs.", "The proposed approach avoids costly fine-tuning, enhances interpretability, and scales well for various users and tasks."], "tldr": "Many applications utilize Large Language Models (LLMs) as language agents; however, aligning these agents to individual user preferences remains a challenge.  Traditional fine-tuning approaches are costly, challenging to scale, and may degrade performance.  This paper introduces PRELUDE, a framework that infers user preferences from their edits to the agent's responses.  This avoids the need for costly and complex fine-tuning.\nThe core of PRELUDE is CIPHER, a simple yet effective algorithm that utilizes an LLM to infer user preferences based on edit history.  CIPHER retrieves similar contexts from the history to aggregate preferences, which are used to improve future responses.  Evaluated on summarization and email writing tasks using a GPT-4 simulated user, CIPHER significantly outperformed baselines in terms of lower edit distance while only having a small overhead in LLM query cost. The learned user preferences also showed significant similarity to ground truths.", "affiliation": "Microsoft Research", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "DlYNGpCuwa/podcast.wav"}