[{"figure_path": "Yu6cDt7q9Z/tables/tables_7_1.jpg", "caption": "Table 1: Comparative table of diffusion noise schedules and their performance metrics. Bold values indicate the best results, while underlined values denote the second-best results.", "description": "This table presents a quantitative comparison of three different diffusion noise schedules (Linear, Cosine, and Logistic) across eight distinct image editing tasks.  For each task and schedule, it reports several metrics evaluating the performance:  *Structure*: how well the edited image maintains the structural integrity of the original image.  *Background Preservation*: how well the background content is preserved during the editing process (measured using PSNR, LPIPS, MSE, and SSIM). *CLIP Similarity*: how well the edited image aligns with both the visual and textual aspects of the target prompt (measured using CLIP similarity scores for both visual and textual aspects). The table highlights the superior performance of the Logistic Schedule across these metrics, demonstrating its effectiveness in content preservation and edit fidelity.", "section": "5.1 Experimental Settings"}, {"figure_path": "Yu6cDt7q9Z/tables/tables_8_1.jpg", "caption": "Table 1: Comparative table of diffusion noise schedules and their performance metrics. Bold values indicate the best results, while underlined values denote the second-best results.", "description": "This table compares the performance of different noise schedules (Linear, Cosine, and Logistic) across various image editing tasks.  Metrics are provided for structure preservation (Structure Dist., PSNR, LPIPS, MSE, SSIM), visual and textual CLIP similarity, and background preservation.  The best-performing schedule for each metric in each task is shown in bold, with the second-best underlined.  This allows for a direct comparison of how different noise schedules impact image editing quality.", "section": "5.2 Qualitative and Quantitative Comparison"}, {"figure_path": "Yu6cDt7q9Z/tables/tables_9_1.jpg", "caption": "Table 1: Comparative table of diffusion noise schedules and their performance metrics. Bold values indicate the best results, while underlined values denote the second-best results.", "description": "This table compares the performance of different diffusion noise schedules (Linear, Cosine, and Logistic) across various image editing tasks.  For each task and schedule, it provides quantitative metrics assessing:  *Structure*: how well the overall image structure is preserved during editing (measured by DINO-I distance); *Background Preservation*: how well the background is maintained (measured by PSNR, LPIPS, MSE, and SSIM); and *CLIP Similarity*: how well the editing reflects the textual prompt (both visually and textually).  The bold values indicate the best-performing schedule for each metric, and underlined values highlight the second-best. This helps readers quickly compare the relative strengths of each schedule across different image editing tasks.", "section": "5.2 Qualitative and Quantitative Comparison"}, {"figure_path": "Yu6cDt7q9Z/tables/tables_9_2.jpg", "caption": "Table 1: Comparative table of diffusion noise schedules and their performance metrics. Bold values indicate the best results, while underlined values denote the second-best results.", "description": "This table presents a quantitative comparison of three different diffusion noise schedules (Linear, Cosine, and Logistic) across eight distinct image editing tasks.  For each task and schedule, the table provides several metrics to assess performance. These metrics evaluate the structural integrity of the edited image, the preservation of the background, and the overall consistency between the edited image and the associated text prompt.  Higher values generally indicate better performance for each metric, except for LPIPS and MSE, where lower is better. The table highlights the Logistic Schedule's superior performance across multiple metrics, demonstrating its effectiveness in content preservation and edit fidelity.", "section": "5.2 Qualitative and Quantitative Comparison"}, {"figure_path": "Yu6cDt7q9Z/tables/tables_24_1.jpg", "caption": "Table 1: Comparative table of diffusion noise schedules and their performance metrics. Bold values indicate the best results, while underlined values denote the second-best results.", "description": "This table quantitatively compares the performance of different diffusion noise schedules (Linear, Cosine, and Logistic) across various image editing tasks.  For each task and schedule, it provides several metrics related to structural fidelity (Structure Distance), background preservation (PSNR, LPIPS, MSE, SSIM), and text-image consistency (Visual and Textual CLIP Similarity).  The best performing schedule for each metric is highlighted in bold, indicating the superior performance of the Logistic Schedule in most scenarios.", "section": "5.1 Experimental Settings"}, {"figure_path": "Yu6cDt7q9Z/tables/tables_27_1.jpg", "caption": "Table 1: Comparative table of diffusion noise schedules and their performance metrics. Bold values indicate the best results, while underlined values denote the second-best results.", "description": "This table presents a quantitative comparison of three different diffusion noise schedules (Linear, Cosine, and Logistic) across eight image editing tasks.  For each task and schedule, the table provides metrics evaluating three aspects of the editing results:  structural similarity (Structure Distance), background preservation (PSNR, LPIPS, MSE, SSIM), and image-text consistency (Visual and Textual CLIP Similarity).  The best performance for each metric within each editing task is highlighted in bold, and the second-best is underlined, providing a clear comparison of the effectiveness of each noise schedule in different editing contexts.", "section": "5.2 Qualitative and Quantitative Comparison"}, {"figure_path": "Yu6cDt7q9Z/tables/tables_28_1.jpg", "caption": "Table 1: Comparative table of diffusion noise schedules and their performance metrics. Bold values indicate the best results, while underlined values denote the second-best results.", "description": "This table presents a quantitative comparison of three different noise schedules (Linear, Cosine, and Logistic) across eight distinct image editing tasks.  For each task and schedule, the table shows several metrics evaluating performance: Structure Distance, PSNR, LPIPS, MSE, SSIM, Visual CLIP Similarity, and Textual CLIP Similarity.  Higher PSNR and SSIM values generally indicate better image quality, while lower LPIPS and MSE values suggest better perceptual similarity. The Visual and Textual CLIP Similarity scores reflect how well the edited images align with the desired visual and textual prompts, respectively.  Bold values highlight the best-performing schedule for each metric within each task, and underlined values indicate the second-best performer.  This allows for a direct comparison of the effectiveness of each noise schedule across different editing scenarios.", "section": "5.1 Experimental Settings"}, {"figure_path": "Yu6cDt7q9Z/tables/tables_29_1.jpg", "caption": "Table 1: Comparative table of diffusion noise schedules and their performance metrics. Bold values indicate the best results, while underlined values denote the second-best results.", "description": "This table presents a quantitative comparison of different diffusion noise schedules (Linear, Cosine, and Logistic) across various image editing tasks.  For each schedule, the table shows several metrics evaluating performance: Structure Distance (lower is better), PSNR (higher is better), LPIPS (lower is better), MSE (lower is better), SSIM (higher is better), and CLIP similarity scores for both visual and textual aspects (higher is better). The bold values highlight the best-performing schedule for each metric within each task, while underlined values indicate the second-best. This allows for a direct comparison of the effectiveness of each noise schedule in preserving the image structure and overall fidelity across a range of image editing tasks.", "section": "5.2 Qualitative and Quantitative Comparison"}, {"figure_path": "Yu6cDt7q9Z/tables/tables_29_2.jpg", "caption": "Table 1: Comparative table of diffusion noise schedules and their performance metrics. Bold values indicate the best results, while underlined values denote the second-best results.", "description": "This table presents a quantitative comparison of three different diffusion noise schedules (Linear, Cosine, and Logistic) across eight distinct image editing tasks.  For each task and schedule, it provides multiple metrics assessing performance in three key aspects: 1) Structural fidelity, measured by the Structure Distance (lower is better); 2) Background preservation, evaluated using PSNR (higher is better), LPIPS (lower is better), MSE (lower is better), and SSIM (higher is better); and 3) Textual and visual consistency with the editing prompts, measured by the CLIP Similarity scores for both visual and textual aspects (higher is better). Bold values highlight the best-performing schedule for each metric within each task, while underlined values indicate the second-best performance. This allows for a comprehensive comparison of the noise schedules' effectiveness across various image editing scenarios.", "section": "5.2 Qualitative and Quantitative Comparison"}, {"figure_path": "Yu6cDt7q9Z/tables/tables_31_1.jpg", "caption": "Table 1: Comparative table of diffusion noise schedules and their performance metrics. Bold values indicate the best results, while underlined values denote the second-best results.", "description": "This table quantitatively compares the performance of three different diffusion noise schedules (Linear, Cosine, and Logistic) across various image editing tasks.  For each task and schedule, it presents metrics related to structural preservation (Structure Distance), background preservation (PSNR, LPIPS, MSE, SSIM), and image-text consistency (Visual and Textual CLIP Similarity).  Bold values highlight the best-performing schedule for each metric in each task, while underlined values indicate the second-best performance. This allows for a direct comparison of the effectiveness of each noise schedule in different aspects of image editing.", "section": "5.2 Qualitative and Quantitative Comparison"}, {"figure_path": "Yu6cDt7q9Z/tables/tables_31_2.jpg", "caption": "Table 1: Comparative table of diffusion noise schedules and their performance metrics. Bold values indicate the best results, while underlined values denote the second-best results.", "description": "This table presents a quantitative comparison of three different diffusion noise schedules (Linear, Cosine, and Logistic) across eight distinct image editing tasks.  For each task and schedule, the table displays several metrics evaluating the quality of the edited images.  These metrics assess structural similarity, background preservation (using PSNR, LPIPS, MSE, and SSIM), and visual and textual consistency with the target prompt (using CLIP scores).  The bold values highlight the best-performing schedule for each task, while underlined values indicate the second-best.", "section": "5.2 Qualitative and Quantitative Comparison"}]