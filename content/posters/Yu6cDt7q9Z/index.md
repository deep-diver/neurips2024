---
title: "Schedule Your Edit: A Simple yet Effective Diffusion Noise Schedule for Image Editing"
summary: "Logistic Schedule: A novel noise schedule revolutionizes image editing by improving DDIM inversion, enhancing content preservation and edit fidelity without model retraining!"
categories: []
tags: ["Computer Vision", "Image Generation", "üè¢ State Grid Corporation of China",]
showSummary: true
date: 2024-09-26
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} Yu6cDt7q9Z {{< /keyword >}}
{{< keyword icon="writer" >}} Haonan Lin et el. {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://openreview.net/forum?id=Yu6cDt7q9Z" target="_blank" >}}
‚Üó OpenReview
{{< /button >}}
{{< button href="https://neurips.cc/virtual/2024/poster/94668" target="_blank" >}}
‚Üó NeurIPS Homepage
{{< /button >}}{{< button href="https://huggingface.co/papers/2410.18756" target="_blank" >}}
‚Üó Hugging Face
{{< /button >}}
{{< button href="https://huggingface.co/spaces/huggingface/paper-central?tab=tab-chat-with-paper&paper_id=Yu6cDt7q9Z&paper_from=neurips" target="_blank" >}}
‚Üó Chat
{{< /button >}}



<audio controls>
    <source src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/podcast.wav" type="audio/wav">
    Your browser does not support the audio element.
</audio>


### TL;DR


{{< lead >}}

Current text-guided image editing methods rely heavily on Diffusion Denoising Implicit Models (DDIM) for image inversion. However, DDIM inversion often suffers from accumulated prediction errors during the diffusion process, especially when dealing with conditional inputs such as text prompts for image manipulation. These errors hinder content preservation and edit fidelity, resulting in unsatisfactory editing outcomes. 

The paper introduces the "Logistic Schedule," a novel noise schedule designed to mitigate these issues.  This schedule addresses the singularity problem inherent in traditional noise schedules by using a logistic function to ensure smooth noise transitions during the inversion process.  The Logistic Schedule improves inversion stability, reduces prediction errors, and creates a better noise space for image editing.  Extensive experiments across multiple editing tasks demonstrate its superior performance over existing methods in terms of both content preservation and edit fidelity, without the need for additional model retraining.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} The Logistic Schedule significantly improves the stability and accuracy of DDIM inversion in image editing. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} The proposed schedule effectively reduces noise prediction errors, leading to more faithful and high-fidelity edits. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} The method is compatible with existing image editing methods and requires no additional model retraining. {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
This paper is crucial for researchers in image editing and diffusion models.  It **directly addresses limitations** of current DDIM inversion techniques, a **major bottleneck** in text-guided image editing.  By proposing the Logistic Schedule, it **opens new avenues** for improving content preservation and edit fidelity without model retraining, thus impacting numerous applications.

------
#### Visual Insights



![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_1_1.jpg)

> This figure showcases the results of image editing using different noise schedules (linear, cosine, and the proposed Logistic schedule).  Six different image editing tasks are presented: (a) Attributes Content, (b) Object Addition, (c) Object Switch, (d) Style Transferring, (e) Scene Transferring, and (f) Non-Rigid (Pose) Editing. For each task and noise schedule, sample images are displayed along with their corresponding text prompts which highlight changes made to the images. The results demonstrate the Logistic Schedule‚Äôs superior performance in preserving original image content and achieving high-fidelity edits.





![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/tables_7_1.jpg)

> This table presents a quantitative comparison of three different diffusion noise schedules (Linear, Cosine, and Logistic) across eight distinct image editing tasks.  For each task and schedule, it reports several metrics evaluating the performance:  *Structure*: how well the edited image maintains the structural integrity of the original image.  *Background Preservation*: how well the background content is preserved during the editing process (measured using PSNR, LPIPS, MSE, and SSIM). *CLIP Similarity*: how well the edited image aligns with both the visual and textual aspects of the target prompt (measured using CLIP similarity scores for both visual and textual aspects). The table highlights the superior performance of the Logistic Schedule across these metrics, demonstrating its effectiveness in content preservation and edit fidelity.





### In-depth insights


#### Logistic Noise Schedule
The proposed "Logistic Noise Schedule" addresses limitations in existing diffusion models used for image editing.  Traditional noise schedules suffer from singularity problems, leading to instability during the inversion process and hindering accurate content preservation. **The Logistic Schedule mitigates this by eliminating singularities**, ensuring a smoother, more stable inversion.  This results in **improved fidelity** and **better preservation of original content** in edited images, as demonstrated through experiments across various image editing tasks.  The approach is particularly effective when integrated with inversion-based image editing methods.  Furthermore, the **Logistic Schedule is compatible with existing models and techniques without requiring retraining**, making it a readily implementable and effective enhancement to current image editing pipelines.

#### DDIM Inversion Failure
The failure of DDIM (Denoising Diffusion Implicit Models) inversion in image editing primarily stems from its reliance on a local linearization approximation.  This approximation, while simplifying the inversion process, introduces noise prediction errors that accumulate during the reverse diffusion process. These errors are particularly detrimental when dealing with conditional inputs, as required in image editing, resulting in **inferior content preservation and reduced fidelity**. The core issue is identified as the **singularity problem** inherent in traditional noise schedules, which causes unreliable noise predictions from the very beginning of inversion. This singularity problem ultimately limits the inversion process's ability to accurately reconstruct and edit images, hindering the effectiveness of text-guided image editing techniques.  Addressing this singularity issue is crucial for improving the stability and accuracy of DDIM inversion in image editing, paving the way for more effective and high-fidelity content modification.

#### Image Editing Fidelity
Image editing fidelity, in the context of diffusion models, refers to how well the edited image maintains the visual quality and semantic consistency of the original.  High fidelity means the edits appear natural and don't introduce artifacts or distortions.  Factors influencing fidelity include the accuracy of the image inversion process (mapping the image to the model's latent space), the effectiveness of the noise schedule in guiding the diffusion process, and the choice of editing method. **A key challenge is balancing the preservation of original content with the successful implementation of the desired edit.**  Suboptimal noise schedules, for instance, can lead to error accumulation during inversion, resulting in poor fidelity.  **Methods that improve inversion accuracy by reducing noise prediction errors naturally improve editing fidelity**. Therefore, a well-designed noise schedule is crucial for high fidelity image editing, ensuring that modifications are applied accurately and smoothly within the latent space without causing significant visual degradation or content loss.  The quality of the final edited image serves as a direct measure of the method's fidelity.

#### Ablation Experiments
Ablation studies systematically remove components of a model to assess their individual contributions.  In the context of a diffusion model for image editing, ablation experiments would likely involve testing variations of the proposed noise schedule.  This could include comparing performance against established baselines (linear, cosine) by removing key elements of the novel logistic schedule like the specific functional form, hyperparameters (k, to), or the integration with different editing methods. The results would reveal **the relative importance of each component**, highlighting which aspects drive the model's improved image fidelity and stability.  Analyzing the results might also reveal **unexpected interactions between components**, potentially leading to refinements of the design and optimization. Ultimately, a comprehensive ablation study is crucial for **validating the claims** of the proposed method, ensuring its improvements aren't simply a result of one isolated element but rather the synergistic effect of the overall design.

#### Future Research
Future research directions stemming from this work could explore several promising avenues.  **Extending the Logistic Schedule to other diffusion models** beyond those tested is crucial to demonstrate its broad applicability.  A key area involves **investigating dynamic noise schedules**, adapting the noise level throughout the inversion process based on image content. This could significantly improve edit fidelity, particularly for intricate edits. Furthermore, **exploring alternative formulations of the logistic function** or other noise schedule designs might reveal even more effective methods for preserving content during image editing.  The current study focuses primarily on image editing; however, **research into leveraging the Logistic Schedule for other diffusion-based tasks** such as image generation and inpainting would be beneficial.  Finally, a deeper investigation into the theoretical underpinnings of the schedule's effectiveness could provide a stronger foundation for future developments and **address the singularity challenges found in traditional noise schedules**, thereby opening up novel approaches to generative modeling.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_2_1.jpg)

> This figure illustrates the DDIM inversion process in image editing and highlights its challenges. The left panel shows the process, starting from the source image (x0), approximating the ideal latent (x*) with the inverted latent (x*), and then sampling in two branches (with source and target conditions) to obtain reconstructed and edited images. The right panel shows that traditional noise schedules (linear and cosine) have singularities at t=0, which lead to noise prediction errors during inversion. 


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_4_1.jpg)

> This figure compares three different noise schedules (scaled linear, cosine, and logistic) and shows their impact on image editing. The left panel displays the noise scales (‚àö1 ‚àí ·æ∂t) over time for each schedule. The right panel focuses specifically on the logistic schedule and shows the derivative of x with respect to t (dxt/dt).  This derivative is key to inversion stability; the logistic schedule's smooth derivative prevents singularities that hinder accurate noise prediction, leading to improved fidelity in image editing.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_6_1.jpg)

> This figure showcases the results of six different image editing tasks using two different noise schedules: the linear schedule and the proposed Logistic Schedule.  Each row represents a different editing task: (a) Attributes Content, (b) Object Addition, (c) Object Switch, (d) Style Transferring, (e) Scene Transferring, and (f) Non-Rigid (Pose) Editing. The left column shows the original image and the next three columns present the results using the linear schedule and the Logistic Schedule, respectively.  Red text in the prompt indicates the part of the prompt related to the image edit. The figure demonstrates that the Logistic Schedule produces edits that better preserve the original content of the image, while successfully applying the desired edits, across all six tasks.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_8_1.jpg)

> This figure shows the effect of the hyperparameter k on the logistic noise schedule. The left panel shows the change in the remaining signal (ƒÅt) and log signal-to-noise ratio (logSNR) with different values of k.  The right panel shows the corresponding edited images resulting from using different values of k, demonstrating how the steepness of the logistic function affects the inversion process and final image output.  Higher values of k result in more rapid changes in ƒÅt and logSNR, and this leads to greater changes in the images, whereas smaller k values result in smoother transitions.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_8_2.jpg)

> This figure shows the effect of the hyperparameter to (midpoint of the logistic function) on the logistic noise schedule. The left panel shows the change in ƒÅt (remaining signal in latent space) and logSNR (log signal-to-noise ratio) with different values of to. The right panel shows the image editing results for three random seeds with varying values of to.  The different values of to illustrate how the change in ƒÅt and logSNR impact the resulting image edits. By changing the midpoint of the logistic function, the editing process is influenced, affecting the level of detail and fidelity in the edited image.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_27_1.jpg)

> This figure showcases the results of image editing experiments using different noise schedules. The top row displays the original images, and the subsequent rows illustrate the edited images produced using the scaled linear noise schedule (ours) and the logistic noise schedule. Each column represents a different image editing task: (a) attributes content editing, (b) object addition, (c) object switch, (d) style transferring, (e) scene transferring, and (f) non-rigid (pose) editing. The figure demonstrates that the logistic noise schedule produces superior results in terms of content preservation and edit fidelity compared to the scaled linear noise schedule.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_28_1.jpg)

> This figure showcases the results of image editing using different noise schedules.  It compares the performance of the proposed Logistic Schedule against a linear noise schedule across six different editing tasks: (a) attribute content editing, (b) object addition, (c) object switch, (d) style transferring, (e) scene transferring, and (f) non-rigid (pose) editing. The results highlight the Logistic Schedule's ability to maintain high fidelity and preserve the high-level semantics of the source image, significantly outperforming the linear schedule in most tasks.  Each task's text prompt is provided below the image samples.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_29_1.jpg)

> This figure showcases the results of image editing using different noise schedules.  The Logistic Schedule is compared to a linear schedule, demonstrating its superiority in maintaining high-fidelity and preserving the high-level semantics of the original image across various image manipulation tasks, including attribute changes, object addition and removal, style transfer, and non-rigid transformations.  Each subfigure (a-f) illustrates different editing tasks with the corresponding text prompts provided below each image.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_30_1.jpg)

> This figure showcases the results of image editing experiments using different noise schedules.  It compares the performance of the proposed 'Logistic Schedule' against a 'linear noise schedule'. Six different image editing tasks are presented, illustrating the superior performance of the Logistic Schedule in maintaining high-level semantic content, even when making detailed attribute changes or complex object manipulations.  Each task shows the original image, the edited image using a linear schedule, and the edited image using the Logistic Schedule.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_30_2.jpg)

> This figure shows the impact of varying guidance scales during both the forward (inversion) and reverse (denoising) processes of the DDIM method.  The x-axis represents the inversion guidance scale, ranging from 1 to 10, while the y-axis represents the denoising guidance scale, ranging from 3 to 25. Each cell in the grid displays an image generated using a specific combination of inversion and denoising guidance scales.  This visualizes how different combinations of guidance scales affect the final edited image.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_32_1.jpg)

> This figure showcases the results of image editing experiments using different noise schedules.  The Logistic Schedule is compared to a linear schedule across six editing tasks: attribute content, object addition, object switch, style transferring, scene transferring, and non-rigid pose editing.  Each task is illustrated with examples showing that the Logistic Schedule preserves more of the original image's semantics and achieves higher fidelity.  The text prompts used to guide the edits are shown below each image.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_33_1.jpg)

> This figure showcases the results of image editing experiments using different noise schedules.  It compares the performance of the proposed Logistic Schedule against a standard linear schedule.  Six types of image editing tasks are demonstrated: attributes content editing, object addition, object switch, style transferring, scene transferring, and non-rigid (pose) editing. For each task, examples are shown with the original image, the edited image using a linear schedule, and the edited image using the Logistic Schedule. The images clearly demonstrate the superior performance of the Logistic Schedule in preserving the original image content while making the desired modifications, highlighting the method's ability to maintain high-level semantics and fidelity.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_33_2.jpg)

> This figure shows a qualitative comparison of the proposed Logistic Schedule against linear and cosine schedules across eight different image editing tasks. Each task involves a different method, such as preserving background content, style transfer, or non-rigid pose editing.  It demonstrates the superior performance of the Logistic Schedule in maintaining high fidelity in the edited images while preserving the high-level semantics of the original image. The results highlight the adaptability and effectiveness of the Logistic Schedule across various editing tasks.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_34_1.jpg)

> This figure showcases qualitative results comparing the performance of the proposed Logistic Noise Schedule against the baseline linear schedule across six different image editing tasks.  Each row shows a different task (attributes content, object addition, object switch, style transferring, scene transferring, and non-rigid pose editing). The left column shows the original image, the middle column shows the result using the linear schedule, and the right column uses the Logistic schedule. The figure demonstrates that the Logistic Schedule achieves better preservation of the original image content, higher fidelity, and successful alteration across multiple image editing scenarios.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_35_1.jpg)

> This figure shows a qualitative comparison of image editing results using three different noise schedules (Linear, Cosine, and Logistic) across eight distinct editing tasks. Each task involves modifying different aspects of an image, such as attributes (color, material), object manipulation (addition, switch), scene modification, and non-rigid transformations (pose). The results highlight the superior performance of the Logistic Schedule in preserving the original image content while achieving high-fidelity editing results compared to Linear and Cosine schedules. Different editing methods are used depending on the task to maintain image quality and consistency.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_35_2.jpg)

> This figure shows a qualitative comparison of the Logistic Schedule against linear and cosine schedules across eight different image editing tasks. Each row represents a specific editing task, and three columns show the results for each noise schedule (Real Image, Linear Schedule, Cosine Schedule, Logistic Schedule). The results demonstrate that Logistic Schedule achieves higher fidelity and better preserves the original content than the other noise schedules across various image editing tasks.  The figure also indicates which specific editing methods were used to achieve the visual results for each task.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_36_1.jpg)

> This figure showcases the results of image editing using different noise schedules.  The Logistic Schedule is compared to a linear schedule, demonstrating its ability to maintain high-fidelity in various image editing tasks, including attribute content editing, object addition, object switching, style transferring, scene transferring, and non-rigid pose editing.  Each row represents a different editing task with examples, showing the original image and the results using both linear and logistic schedules.


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/figures_36_2.jpg)

> This figure displays a qualitative comparison of the Logistic Schedule against linear and cosine schedules for eight different image editing tasks. Each task is shown with the results from each of the three noise schedules and the original image.  The tasks include attribute editing, object switching, object addition, style transfer, scene transfer, and non-rigid pose editing. The figure aims to demonstrate the Logistic Schedule's superior performance in content preservation and edit fidelity.


</details>




<details>
<summary>More on tables
</summary>


![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/tables_8_1.jpg)
> This table compares the performance of different noise schedules (Linear, Cosine, and Logistic) across various image editing tasks.  Metrics are provided for structure preservation (Structure Dist., PSNR, LPIPS, MSE, SSIM), visual and textual CLIP similarity, and background preservation.  The best-performing schedule for each metric in each task is shown in bold, with the second-best underlined.  This allows for a direct comparison of how different noise schedules impact image editing quality.

![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/tables_9_1.jpg)
> This table compares the performance of different diffusion noise schedules (Linear, Cosine, and Logistic) across various image editing tasks.  For each task and schedule, it provides quantitative metrics assessing:  *Structure*: how well the overall image structure is preserved during editing (measured by DINO-I distance); *Background Preservation*: how well the background is maintained (measured by PSNR, LPIPS, MSE, and SSIM); and *CLIP Similarity*: how well the editing reflects the textual prompt (both visually and textually).  The bold values indicate the best-performing schedule for each metric, and underlined values highlight the second-best. This helps readers quickly compare the relative strengths of each schedule across different image editing tasks.

![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/tables_9_2.jpg)
> This table presents a quantitative comparison of three different diffusion noise schedules (Linear, Cosine, and Logistic) across eight distinct image editing tasks.  For each task and schedule, the table provides several metrics to assess performance. These metrics evaluate the structural integrity of the edited image, the preservation of the background, and the overall consistency between the edited image and the associated text prompt.  Higher values generally indicate better performance for each metric, except for LPIPS and MSE, where lower is better. The table highlights the Logistic Schedule's superior performance across multiple metrics, demonstrating its effectiveness in content preservation and edit fidelity.

![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/tables_24_1.jpg)
> This table quantitatively compares the performance of different diffusion noise schedules (Linear, Cosine, and Logistic) across various image editing tasks.  For each task and schedule, it provides several metrics related to structural fidelity (Structure Distance), background preservation (PSNR, LPIPS, MSE, SSIM), and text-image consistency (Visual and Textual CLIP Similarity).  The best performing schedule for each metric is highlighted in bold, indicating the superior performance of the Logistic Schedule in most scenarios.

![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/tables_27_1.jpg)
> This table presents a quantitative comparison of three different diffusion noise schedules (Linear, Cosine, and Logistic) across eight image editing tasks.  For each task and schedule, the table provides metrics evaluating three aspects of the editing results:  structural similarity (Structure Distance), background preservation (PSNR, LPIPS, MSE, SSIM), and image-text consistency (Visual and Textual CLIP Similarity).  The best performance for each metric within each editing task is highlighted in bold, and the second-best is underlined, providing a clear comparison of the effectiveness of each noise schedule in different editing contexts.

![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/tables_28_1.jpg)
> This table presents a quantitative comparison of three different noise schedules (Linear, Cosine, and Logistic) across eight distinct image editing tasks.  For each task and schedule, the table shows several metrics evaluating performance: Structure Distance, PSNR, LPIPS, MSE, SSIM, Visual CLIP Similarity, and Textual CLIP Similarity.  Higher PSNR and SSIM values generally indicate better image quality, while lower LPIPS and MSE values suggest better perceptual similarity. The Visual and Textual CLIP Similarity scores reflect how well the edited images align with the desired visual and textual prompts, respectively.  Bold values highlight the best-performing schedule for each metric within each task, and underlined values indicate the second-best performer.  This allows for a direct comparison of the effectiveness of each noise schedule across different editing scenarios.

![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/tables_29_1.jpg)
> This table presents a quantitative comparison of different diffusion noise schedules (Linear, Cosine, and Logistic) across various image editing tasks.  For each schedule, the table shows several metrics evaluating performance: Structure Distance (lower is better), PSNR (higher is better), LPIPS (lower is better), MSE (lower is better), SSIM (higher is better), and CLIP similarity scores for both visual and textual aspects (higher is better). The bold values highlight the best-performing schedule for each metric within each task, while underlined values indicate the second-best. This allows for a direct comparison of the effectiveness of each noise schedule in preserving the image structure and overall fidelity across a range of image editing tasks.

![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/tables_29_2.jpg)
> This table presents a quantitative comparison of three different diffusion noise schedules (Linear, Cosine, and Logistic) across eight distinct image editing tasks.  For each task and schedule, it provides multiple metrics assessing performance in three key aspects: 1) Structural fidelity, measured by the Structure Distance (lower is better); 2) Background preservation, evaluated using PSNR (higher is better), LPIPS (lower is better), MSE (lower is better), and SSIM (higher is better); and 3) Textual and visual consistency with the editing prompts, measured by the CLIP Similarity scores for both visual and textual aspects (higher is better). Bold values highlight the best-performing schedule for each metric within each task, while underlined values indicate the second-best performance. This allows for a comprehensive comparison of the noise schedules' effectiveness across various image editing scenarios.

![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/tables_31_1.jpg)
> This table quantitatively compares the performance of three different diffusion noise schedules (Linear, Cosine, and Logistic) across various image editing tasks.  For each task and schedule, it presents metrics related to structural preservation (Structure Distance), background preservation (PSNR, LPIPS, MSE, SSIM), and image-text consistency (Visual and Textual CLIP Similarity).  Bold values highlight the best-performing schedule for each metric in each task, while underlined values indicate the second-best performance. This allows for a direct comparison of the effectiveness of each noise schedule in different aspects of image editing.

![](https://ai-paper-reviewer.com/Yu6cDt7q9Z/tables_31_2.jpg)
> This table presents a quantitative comparison of three different diffusion noise schedules (Linear, Cosine, and Logistic) across eight distinct image editing tasks.  For each task and schedule, the table displays several metrics evaluating the quality of the edited images.  These metrics assess structural similarity, background preservation (using PSNR, LPIPS, MSE, and SSIM), and visual and textual consistency with the target prompt (using CLIP scores).  The bold values highlight the best-performing schedule for each task, while underlined values indicate the second-best.

</details>




### Full paper

{{< gallery >}}
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/Yu6cDt7q9Z/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}