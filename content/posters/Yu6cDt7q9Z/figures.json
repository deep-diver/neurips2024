[{"figure_path": "Yu6cDt7q9Z/figures/figures_1_1.jpg", "caption": "Figure 1: Compared to linear noise schedule, Logistic Schedule demonstrates high fidelity in attributes content editing (a, b) with EF-DDPM [21], preserves the high-level semantics of the source image while performing object translation (c) with pix2pix-zero [45] and style/scene transferring (d, e) with StyleDiffusion [63], and successfully conducts non-rigid alteration (f) via MasaCtrl [6]. Text prompts corresponding to each input image are presented beneath each sample, with words introduced for image editing distinctly highlighted in red.", "description": "This figure showcases the results of image editing using different noise schedules (linear, cosine, and the proposed Logistic schedule).  Six different image editing tasks are presented: (a) Attributes Content, (b) Object Addition, (c) Object Switch, (d) Style Transferring, (e) Scene Transferring, and (f) Non-Rigid (Pose) Editing. For each task and noise schedule, sample images are displayed along with their corresponding text prompts which highlight changes made to the images. The results demonstrate the Logistic Schedule\u2019s superior performance in preserving original image content and achieving high-fidelity edits.", "section": "1 Introduction"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_2_1.jpg", "caption": "Figure 2: Illustration of the DDIM inversion in image editing and its challenges. Left: starting from the source image x0, the ideal latent x, is approximated by the inverted latent x using DDIM inversion. The perturbed noisy latent x is then sampled in two branches\u2014one for the source condition and one for the target condition\u2014yielding the reconstructed and edited images respectively. Right: the numerical computations of dx\u2081/dt for scaled linear and cosine noise schedules, highlighting the singularity at t = 0 that leads to potential inaccuracies in noise prediction during inversion.", "description": "This figure illustrates the DDIM inversion process in image editing and highlights its challenges. The left panel shows the process, starting from the source image (x0), approximating the ideal latent (x*) with the inverted latent (x*), and then sampling in two branches (with source and target conditions) to obtain reconstructed and edited images. The right panel shows that traditional noise schedules (linear and cosine) have singularities at t=0, which lead to noise prediction errors during inversion. ", "section": "3 On the Failure of DDIM Inversion"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_4_1.jpg", "caption": "Figure 3: Left: trends of \u221a1 \u2212 \u1fb6t (noise scales) for scaled linear, cosine, and logistic noise schedules. Right: dxt/dt for the logistic schedule, highlighting its smooth transition, which prevents singularities and maintains the integrity of the initial latent vector x0.", "description": "This figure compares three different noise schedules (scaled linear, cosine, and logistic) and shows their impact on image editing. The left panel displays the noise scales (\u221a1 \u2212 \u1fb6t) over time for each schedule. The right panel focuses specifically on the logistic schedule and shows the derivative of x with respect to t (dxt/dt).  This derivative is key to inversion stability; the logistic schedule's smooth derivative prevents singularities that hinder accurate noise prediction, leading to improved fidelity in image editing.", "section": "4 Better Noise Schedule Helps Inversion and Editing"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_6_1.jpg", "caption": "Figure 1: Compared to linear noise schedule, Logistic Schedule demonstrates high fidelity in attributes content editing (a, b) with EF-DDPM [21], preserves the high-level semantics of the source image while performing object translation (c) with pix2pix-zero [45] and style/scene transferring (d, e) with StyleDiffusion [63], and successfully conducts non-rigid alteration (f) via MasaCtrl [6]. Text prompts corresponding to each input image are presented beneath each sample, with words introduced for image editing distinctly highlighted in red.", "description": "This figure showcases the results of six different image editing tasks using two different noise schedules: the linear schedule and the proposed Logistic Schedule.  Each row represents a different editing task: (a) Attributes Content, (b) Object Addition, (c) Object Switch, (d) Style Transferring, (e) Scene Transferring, and (f) Non-Rigid (Pose) Editing. The left column shows the original image and the next three columns present the results using the linear schedule and the Logistic Schedule, respectively.  Red text in the prompt indicates the part of the prompt related to the image edit. The figure demonstrates that the Logistic Schedule produces edits that better preserve the original content of the image, while successfully applying the desired edits, across all six tasks.", "section": "3 On the Failure of DDIM Inversion"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_8_1.jpg", "caption": "Figure 6: Impact of k on the logistic schedule. Left: change in \u0101t and logSNR with different k values. Right: the effect of k on edited images.", "description": "This figure shows the effect of the hyperparameter k on the logistic noise schedule. The left panel shows the change in the remaining signal (\u0101t) and log signal-to-noise ratio (logSNR) with different values of k.  The right panel shows the corresponding edited images resulting from using different values of k, demonstrating how the steepness of the logistic function affects the inversion process and final image output.  Higher values of k result in more rapid changes in \u0101t and logSNR, and this leads to greater changes in the images, whereas smaller k values result in smoother transitions.", "section": "Ablation Studies"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_8_2.jpg", "caption": "Figure 7: Impact of to on the logistic schedule. Left: change in \u0101t and logSNR with different to values. Right: each column represents edited results within three random seeds, under a specific to.", "description": "This figure shows the effect of the hyperparameter to (midpoint of the logistic function) on the logistic noise schedule. The left panel shows the change in \u0101t (remaining signal in latent space) and logSNR (log signal-to-noise ratio) with different values of to. The right panel shows the image editing results for three random seeds with varying values of to.  The different values of to illustrate how the change in \u0101t and logSNR impact the resulting image edits. By changing the midpoint of the logistic function, the editing process is influenced, affecting the level of detail and fidelity in the edited image.", "section": "4 Better Noise Schedule Helps Inversion and Editing"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_27_1.jpg", "caption": "Figure 1: Compared to linear noise schedule, Logistic Schedule demonstrates high fidelity in attributes content editing (a, b) with EF-DDPM [21], preserves the high-level semantics of the source image while performing object translation (c) with pix2pix-zero [45] and style/scene transferring (d, e) with StyleDiffusion [63], and successfully conducts non-rigid alteration (f) via MasaCtrl [6]. Text prompts corresponding to each input image are presented beneath each sample, with words introduced for image editing distinctly highlighted in red.", "description": "This figure showcases the results of image editing experiments using different noise schedules. The top row displays the original images, and the subsequent rows illustrate the edited images produced using the scaled linear noise schedule (ours) and the logistic noise schedule. Each column represents a different image editing task: (a) attributes content editing, (b) object addition, (c) object switch, (d) style transferring, (e) scene transferring, and (f) non-rigid (pose) editing. The figure demonstrates that the logistic noise schedule produces superior results in terms of content preservation and edit fidelity compared to the scaled linear noise schedule.", "section": "1 Introduction"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_28_1.jpg", "caption": "Figure 1: Compared to linear noise schedule, Logistic Schedule demonstrates high fidelity in attributes content editing (a, b) with EF-DDPM [21], preserves the high-level semantics of the source image while performing object translation (c) with pix2pix-zero [45] and style/scene transferring (d, e) with StyleDiffusion [63], and successfully conducts non-rigid alteration (f) via MasaCtrl [6]. Text prompts corresponding to each input image are presented beneath each sample, with words introduced for image editing distinctly highlighted in red.", "description": "This figure showcases the results of image editing using different noise schedules.  It compares the performance of the proposed Logistic Schedule against a linear noise schedule across six different editing tasks: (a) attribute content editing, (b) object addition, (c) object switch, (d) style transferring, (e) scene transferring, and (f) non-rigid (pose) editing. The results highlight the Logistic Schedule's ability to maintain high fidelity and preserve the high-level semantics of the source image, significantly outperforming the linear schedule in most tasks.  Each task's text prompt is provided below the image samples.", "section": "1 Introduction"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_29_1.jpg", "caption": "Figure 1: Compared to linear noise schedule, Logistic Schedule demonstrates high fidelity in attributes content editing (a, b) with EF-DDPM [21], preserves the high-level semantics of the source image while performing object translation (c) with pix2pix-zero [45] and style/scene transferring (d, e) with StyleDiffusion [63], and successfully conducts non-rigid alteration (f) via MasaCtrl [6]. Text prompts corresponding to each input image are presented beneath each sample, with words introduced for image editing distinctly highlighted in red.", "description": "This figure showcases the results of image editing using different noise schedules.  The Logistic Schedule is compared to a linear schedule, demonstrating its superiority in maintaining high-fidelity and preserving the high-level semantics of the original image across various image manipulation tasks, including attribute changes, object addition and removal, style transfer, and non-rigid transformations.  Each subfigure (a-f) illustrates different editing tasks with the corresponding text prompts provided below each image.", "section": "1 Introduction"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_30_1.jpg", "caption": "Figure 1: Compared to linear noise schedule, Logistic Schedule demonstrates high fidelity in attributes content editing (a, b) with EF-DDPM [21], preserves the high-level semantics of the source image while performing object translation (c) with pix2pix-zero [45] and style/scene transferring (d, e) with StyleDiffusion [63], and successfully conducts non-rigid alteration (f) via MasaCtrl [6]. Text prompts corresponding to each input image are presented beneath each sample, with words introduced for image editing distinctly highlighted in red.", "description": "This figure showcases the results of image editing experiments using different noise schedules.  It compares the performance of the proposed 'Logistic Schedule' against a 'linear noise schedule'. Six different image editing tasks are presented, illustrating the superior performance of the Logistic Schedule in maintaining high-level semantic content, even when making detailed attribute changes or complex object manipulations.  Each task shows the original image, the edited image using a linear schedule, and the edited image using the Logistic Schedule.", "section": "1 Introduction"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_30_2.jpg", "caption": "Figure 11: Qualitative comparison of varying guidance scales during the inversion (forward) and denoising (reversing) processes of DDIM. The guidance scales for inversion are varied across the columns (1 to 10), and the guidance scales for denoising are varied across the rows (3 to 25).", "description": "This figure shows the impact of varying guidance scales during both the forward (inversion) and reverse (denoising) processes of the DDIM method.  The x-axis represents the inversion guidance scale, ranging from 1 to 10, while the y-axis represents the denoising guidance scale, ranging from 3 to 25. Each cell in the grid displays an image generated using a specific combination of inversion and denoising guidance scales.  This visualizes how different combinations of guidance scales affect the final edited image.", "section": "5 Experiments"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_32_1.jpg", "caption": "Figure 1: Compared to linear noise schedule, Logistic Schedule demonstrates high fidelity in attributes content editing (a, b) with EF-DDPM [21], preserves the high-level semantics of the source image while performing object translation (c) with pix2pix-zero [45] and style/scene transferring (d, e) with StyleDiffusion [63], and successfully conducts non-rigid alteration (f) via MasaCtrl [6]. Text prompts corresponding to each input image are presented beneath each sample, with words introduced for image editing distinctly highlighted in red.", "description": "This figure showcases the results of image editing experiments using different noise schedules.  The Logistic Schedule is compared to a linear schedule across six editing tasks: attribute content, object addition, object switch, style transferring, scene transferring, and non-rigid pose editing.  Each task is illustrated with examples showing that the Logistic Schedule preserves more of the original image's semantics and achieves higher fidelity.  The text prompts used to guide the edits are shown below each image.", "section": "1 Introduction"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_33_1.jpg", "caption": "Figure 1: Compared to linear noise schedule, Logistic Schedule demonstrates high fidelity in attributes content editing (a, b) with EF-DDPM [21], preserves the high-level semantics of the source image while performing object translation (c) with pix2pix-zero [45] and style/scene transferring (d, e) with StyleDiffusion [63], and successfully conducts non-rigid alteration (f) via MasaCtrl [6]. Text prompts corresponding to each input image are presented beneath each sample, with words introduced for image editing distinctly highlighted in red.", "description": "This figure showcases the results of image editing experiments using different noise schedules.  It compares the performance of the proposed Logistic Schedule against a standard linear schedule.  Six types of image editing tasks are demonstrated: attributes content editing, object addition, object switch, style transferring, scene transferring, and non-rigid (pose) editing. For each task, examples are shown with the original image, the edited image using a linear schedule, and the edited image using the Logistic Schedule. The images clearly demonstrate the superior performance of the Logistic Schedule in preserving the original image content while making the desired modifications, highlighting the method's ability to maintain high-level semantics and fidelity.", "section": "1 Introduction"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_33_2.jpg", "caption": "Figure 5: Qualitative comparison of the Logistic Schedule with linear and cosine schedules across various image editing tasks. To preserve background content during \u2460 attribute editing tasks (e.g., colors, and materials), we employ Edit Friendly DDPM [21]; for tasks requiring background preservation such as object translation, we use Zero-shot Pix2Pix [45]; for tasks involving \u2462 scene or style transfer, while maintaining object semantics, we utilize StyleDiffusion [63]; to validate spatial context preservation in \u2463 non-rigid editing tasks (e.g., motion, pose), we consider MasaCtrl [6].", "description": "This figure shows a qualitative comparison of the proposed Logistic Schedule against linear and cosine schedules across eight different image editing tasks. Each task involves a different method, such as preserving background content, style transfer, or non-rigid pose editing.  It demonstrates the superior performance of the Logistic Schedule in maintaining high fidelity in the edited images while preserving the high-level semantics of the original image. The results highlight the adaptability and effectiveness of the Logistic Schedule across various editing tasks.", "section": "5 Experiments"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_34_1.jpg", "caption": "Figure 1: Compared to linear noise schedule, Logistic Schedule demonstrates high fidelity in attributes content editing (a, b) with EF-DDPM [21], preserves the high-level semantics of the source image while performing object translation (c) with pix2pix-zero [45] and style/scene transferring (d, e) with StyleDiffusion [63], and successfully conducts non-rigid alteration (f) via MasaCtrl [6]. Text prompts corresponding to each input image are presented beneath each sample, with words introduced for image editing distinctly highlighted in red.", "description": "This figure showcases qualitative results comparing the performance of the proposed Logistic Noise Schedule against the baseline linear schedule across six different image editing tasks.  Each row shows a different task (attributes content, object addition, object switch, style transferring, scene transferring, and non-rigid pose editing). The left column shows the original image, the middle column shows the result using the linear schedule, and the right column uses the Logistic schedule. The figure demonstrates that the Logistic Schedule achieves better preservation of the original image content, higher fidelity, and successful alteration across multiple image editing scenarios.", "section": "1 Introduction"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_35_1.jpg", "caption": "Figure 5: Qualitative comparison of the Logistic Schedule with linear and cosine schedules across various image editing tasks. To preserve background content during \u2460 attribute editing tasks (e.g., colors, and materials), we employ Edit Friendly DDPM [21]; for tasks requiring background preservation such as object translation, we use Zero-shot Pix2Pix [45]; for tasks involving \u2462 scene or style transfer, while maintaining object semantics, we utilize StyleDiffusion [63]; to validate spatial context preservation in \u2463 non-rigid editing tasks (e.g., motion, pose), we consider MasaCtrl [6].", "description": "This figure shows a qualitative comparison of image editing results using three different noise schedules (Linear, Cosine, and Logistic) across eight distinct editing tasks. Each task involves modifying different aspects of an image, such as attributes (color, material), object manipulation (addition, switch), scene modification, and non-rigid transformations (pose). The results highlight the superior performance of the Logistic Schedule in preserving the original image content while achieving high-fidelity editing results compared to Linear and Cosine schedules. Different editing methods are used depending on the task to maintain image quality and consistency.", "section": "5 Experiments"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_35_2.jpg", "caption": "Figure 5: Qualitative comparison of the Logistic Schedule with linear and cosine schedules across various image editing tasks. To preserve background content during \u2460 attribute editing tasks (e.g., colors, and materials), we employ Edit Friendly DDPM [21]; for tasks requiring background preservation such as object translation, we use Zero-shot Pix2Pix [45]; for tasks involving \u2462 scene or style transfer, while maintaining object semantics, we utilize StyleDiffusion [63]; to validate spatial context preservation in \u2463 non-rigid editing tasks (e.g., motion, pose), we consider MasaCtrl [6].", "description": "This figure shows a qualitative comparison of the Logistic Schedule against linear and cosine schedules across eight different image editing tasks. Each row represents a specific editing task, and three columns show the results for each noise schedule (Real Image, Linear Schedule, Cosine Schedule, Logistic Schedule). The results demonstrate that Logistic Schedule achieves higher fidelity and better preserves the original content than the other noise schedules across various image editing tasks.  The figure also indicates which specific editing methods were used to achieve the visual results for each task.", "section": "5 Experiments"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_36_1.jpg", "caption": "Figure 1: Compared to linear noise schedule, Logistic Schedule demonstrates high fidelity in attributes content editing (a, b) with EF-DDPM [21], preserves the high-level semantics of the source image while performing object translation (c) with pix2pix-zero [45] and style/scene transferring (d, e) with StyleDiffusion [63], and successfully conducts non-rigid alteration (f) via MasaCtrl [6]. Text prompts corresponding to each input image are presented beneath each sample, with words introduced for image editing distinctly highlighted in red.", "description": "This figure showcases the results of image editing using different noise schedules.  The Logistic Schedule is compared to a linear schedule, demonstrating its ability to maintain high-fidelity in various image editing tasks, including attribute content editing, object addition, object switching, style transferring, scene transferring, and non-rigid pose editing.  Each row represents a different editing task with examples, showing the original image and the results using both linear and logistic schedules.", "section": "1 Introduction"}, {"figure_path": "Yu6cDt7q9Z/figures/figures_36_2.jpg", "caption": "Figure 5: Qualitative comparison of the Logistic Schedule with linear and cosine schedules across various image editing tasks. To preserve background content during \u2460 attribute editing tasks (e.g., colors, and materials), we employ Edit Friendly DDPM [21]; for tasks requiring background preservation such as object translation, we use Zero-shot Pix2Pix [45]; for tasks involving \u2462 scene or style transfer, while maintaining object semantics, we utilize StyleDiffusion [63]; to validate spatial context preservation in \u2463 non-rigid editing tasks (e.g., motion, pose), we consider MasaCtrl [6].", "description": "This figure displays a qualitative comparison of the Logistic Schedule against linear and cosine schedules for eight different image editing tasks. Each task is shown with the results from each of the three noise schedules and the original image.  The tasks include attribute editing, object switching, object addition, style transfer, scene transfer, and non-rigid pose editing. The figure aims to demonstrate the Logistic Schedule's superior performance in content preservation and edit fidelity.", "section": "5 Experiments"}]