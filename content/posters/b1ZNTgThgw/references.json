{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces CLIP, a vision-language model that is foundational to the work in this paper."}, {"fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "publication_date": "2023-00-00", "reason": "This paper introduces SAM, a powerful segmentation model that is highly relevant to this research."}, {"fullname_first_author": "Kaiyang Zhou", "paper_title": "Learning to prompt for vision-language models", "publication_date": "2022-00-00", "reason": "This paper is highly influential in the area of prompt learning for vision-language models, a core topic in this paper."}, {"fullname_first_author": "Manli Shu", "paper_title": "Test-time prompt tuning for zero-shot generalization in vision-language models", "publication_date": "2022-00-00", "reason": "This paper is a key precursor to the current work, introducing the concept of test-time prompt tuning."}, {"fullname_first_author": "Chun-Mei Feng", "paper_title": "Diverse data augmentation with diffusions for effective test-time prompt tuning", "publication_date": "2023-00-00", "reason": "This paper is another important precursor that builds upon the test-time prompt tuning idea, using diffusion models for data augmentation."}]}