[{"figure_path": "LUsx0chTsL/figures/figures_2_1.jpg", "caption": "Figure 1: Language models are often sensitive to arbitrary changes in a prompt, for example the order in which objects are listed (right). This problem is more pronounced as the number of objects increases (left) even though it is not obvious where the issue stems from in the model. We broadly explore how information is routed through a model and focus on a mechanism that is in part responsible for this (in)ability.", "description": "This figure shows the performance of language models on a laundry list task where the model must predict which item from a list is missing based on an incomplete second list.  The left panel shows that accuracy decreases as the number of items in the list increases. The right panel shows an example demonstrating sensitivity to the order of items in the prompt. The figure illustrates a key problem the paper addresses: language models exhibit unexpected and arbitrary sensitivity to seemingly minor changes in prompts.", "section": "1 Introduction"}, {"figure_path": "LUsx0chTsL/figures/figures_3_1.jpg", "caption": "Figure 2: Showing the relationship between the composition score (weight-based, bottom) and inhibition score (data-based, top) between various inhibition head components and mover head 9.9 for the IOI task. The inhibition of each inhibition head is generally highly concentrated in one or two components of the matrix, removing it causes a large drop in the later mover head's ability to downweight one of the names. We therefore show that we can use the composition score when considering decomposed matrices.", "description": "This figure displays the relationship between weight-based composition scores and data-based inhibition scores for different inhibition heads connected to mover head 9.9 in the IOI (Indirect Object Identification) task.  The key observation is that the inhibition effect is highly concentrated in one or two components of each inhibition head's matrix. Removing those specific components significantly reduces the mover head's capacity to inhibit one of the names in the IOI task, highlighting the importance of low-rank subspaces within the interaction between heads. The visualization demonstrates that using the composition score, especially with the decomposition of component matrices, is effective for analyzing and interpreting the inter-layer communication.", "section": "Identifying Communication Channels in Low-Rank Subspaces"}, {"figure_path": "LUsx0chTsL/figures/figures_5_1.jpg", "caption": "Figure 3: Because component matrices are rank-1, their output spaces are 1D and interpreting them becomes easier. On the left, inhibition component activations go to either side of the origin, and selectively inhiibt the name in either position one or position two in the IOI task. We can scale a vector lying on this line by some scalar alpha and observe how this changes behavior when we add it to the residual stream, or replace the output of an attention head with it (right), which we show in Figure 4.", "description": "This figure shows that because the component matrices are rank-1, their output spaces are 1D, making them easier to interpret.  The left panel displays a PCA of mover head 9.9 queries, showing inhibition component activations distributed along a line.  The right panel illustrates how scaling a vector along this line (representing inhibition strength) and adding it to the residual stream or replacing an attention head's output can change model behavior, as further demonstrated in Figure 4.", "section": "3.3 Model Editing"}, {"figure_path": "LUsx0chTsL/figures/figures_6_1.jpg", "caption": "Figure 4: We find that the 1D inhibition components and 2D duplicate token components finely control which name is avoided by the mover head. On the top, we can selectively inhibit either the first or second name depending on how we scale a vector lying on the 8.10.1 output space. This is strictly controlling relative position. On the bottom, we find that adding or removing duplicate token information from the duplicate channel at the IO or S1 tokens also effectively modulates which name is inhibited. Neither random heads, nor non-communication channel components exhibit these same effects (right). See Appendix E for results on other heads.", "description": "This figure shows the results of experiments manipulating the 1D inhibition components and 2D duplicate token components to control the mover head's attention. The top part demonstrates that scaling a vector in the 8.10.1 output space can selectively inhibit either the first or second name. The bottom part shows how adding or removing duplicate token information from the duplicate channel affects the inhibition of names.  The results highlight the fine-grained control these components exert over the model's behavior and the specificity of their effects.", "section": "3.3 Model Editing"}, {"figure_path": "LUsx0chTsL/figures/figures_8_1.jpg", "caption": "Figure 5: Scaling the inhibition component for a single head (here 8.10, left) is not expressive enough to get the mover head to index between the various objects. Scaling the top three inhibition components (middle) gives us enough expressive power to selectively attend to one of the objects. Here, one dot represents a run on the corresponding dataset and the color represents the index of the object the mover head pays the most attention to on average. A surprising structure emerges that partitions the space according to the index of the objects. However, the neat structure begins to break down as the number of objects grows around 10 or higher, and affects the mover head's ability to attend to the right object, which impacts accuracy. Right: Accuracy improvements as a result of sampling from inhibition space. The model becomes much more capable of handling a bigger number of objects in that the accuracy for N objects after the intervention is about as high as the unaltered model when it sees N/2 objects. However, the representational power of the inhibition channel reaches capacity as the number of objects increases, and performance can not improve as much.", "description": "This figure shows the results of experiments on manipulating the inhibition components to control the mover head's attention. The leftmost panel shows that manipulating a single inhibition component is not sufficient to control attention to individual items in a list. The middle panels show that manipulating multiple inhibition components allows for more precise control, but that this ability breaks down as the length of the list increases. The rightmost panel shows the improvement in accuracy after intervention.", "section": "5 The Inhibition Channel is Crucial in Context Retrieval Tasks"}, {"figure_path": "LUsx0chTsL/figures/figures_14_1.jpg", "caption": "Figure 6: Larger models also degrade performance rapidly as we increase the number of objects in the Laundry List task, although more slowly than smaller models. Pythia 6.9B retains strong performance up to around 10 objects.", "description": "This figure shows the performance of four different language models (GPT2-XL, OPT-2.7B, OPT-6.7B, and Pythia-6.9B) on the Laundry List task as the number of objects in the list increases. The x-axis represents the number of objects, and the y-axis represents the accuracy of the model. As can be seen, the accuracy of all four models decreases as the number of objects increases. However, the larger models (OPT-6.7B and Pythia-6.9B) maintain relatively high accuracy for a larger number of objects compared to the smaller models (GPT2-XL and OPT-2.7B). This suggests that larger models are more robust to the challenges posed by the Laundry List task.", "section": "5 The Inhibition Channel is Crucial in Context Retrieval Tasks"}, {"figure_path": "LUsx0chTsL/figures/figures_14_2.jpg", "caption": "Figure 7: Examples of composition scores of individual components with other heads. 4.11 is a previous token head, 5.5 is an induction head, 3.0 is a duplicate token head, 8.10 is an inhibition head, and 9.9 is a mover head. We find that there are large outlier components in value and query composition, but not in the induction head, thus motivating our focus on those heads in the main text.", "description": "This figure presents composition scores between individual component matrices of different attention heads in a transformer language model.  The composition score measures the interaction strength between heads, revealing communication pathways.  Three types of compositions are shown: query, value, and key compositions.  The figure highlights outlier components with unusually high composition scores in value and query compositions, but not in key composition.  These outliers are in heads that play specific roles (duplicate token, inhibition, and mover heads) in established language model circuits. The lack of outliers in the key composition supports the authors' focus on other types of composition in their subsequent analysis.", "section": "3 Identifying Communication Channels in Low-Rank Subspaces"}, {"figure_path": "LUsx0chTsL/figures/figures_14_3.jpg", "caption": "Figure 2: Showing the relationship between the composition score (weight-based, bottom) and inhibition score (data-based, top) between various inhibition head components and mover head 9.9 for the IOI task. The inhibition of each inhibition head is generally highly concentrated in one or two components of the matrix, removing it causes a large drop in the later mover head's ability to downweight one of the names. We therefore show that we can use the composition score when considering decomposed matrices.", "description": "This figure displays the relationship between the weight-based composition score and the data-based inhibition score for different inhibition heads in relation to mover head 9.9 within the Indirect Object Identification (IOI) task.  The lower graphs show the composition score, while the upper graphs depict the inhibition score. The key observation is the strong concentration of inhibition within one or two components of each inhibition head's matrix. Removing these components significantly reduces the mover head's capacity to suppress a name, thus highlighting the importance of these components and the efficacy of using composition scores in the context of decomposed matrices for analysis. ", "section": "Identifying Communication Channels in Low-Rank Subspaces"}, {"figure_path": "LUsx0chTsL/figures/figures_15_1.jpg", "caption": "Figure 9: Effect of applying the top component interventions at the same time to some token. We can control the inhibition by selecting which token these components attend to. Higher score means more inhibition on S2, and lower score means more inhibition on IO.", "description": "This figure shows the effect of applying top component interventions to some tokens.  By selectively zeroing out components of the inhibition heads, the researchers can influence which token (IO or S1) receives less attention from the mover head (9.9). A higher score indicates more inhibition on S2, while a lower score means more inhibition on IO. This demonstrates the ability to manipulate the model's selective attention behavior by directly targeting specific component interactions.", "section": "3.3.2 Results"}, {"figure_path": "LUsx0chTsL/figures/figures_16_1.jpg", "caption": "Figure 10: Effect on the inhibition score when removing components from the inhibition heads. If we only take the top-1 composing heads that affect the inhibition score (circled in Figure 2) we retain close to have of the average inhibition score (0.7 to 0.3). If we only use the component matrices that correspond to the 0th singular value of the inhibition heads, which represents the subspace most strongly written to by the head, the average inhibition score is only 0.04. Recall that a negative inhibition score means placing more attention on the subject rather than IO token.", "description": "This figure shows the results of an experiment where components were removed from the inhibition heads of a language model, and the impact on the inhibition score was measured.  The experiment shows that removing the top components reduces the inhibition score by roughly half, indicating their importance to the model's behavior. Removing the lowest-ranked components, however, results in a significantly smaller effect, suggesting a low-rank structure in the inhibition mechanisms.", "section": "3.3 Model Editing"}, {"figure_path": "LUsx0chTsL/figures/figures_16_2.jpg", "caption": "Figure 3: Because component matrices are rank-1, their output spaces are 1D and interpreting them becomes easier. On the left, inhibition component activations go to either side of the origin, and selectively inhiibt the name in either position one or position two in the IOI task. We can scale a vector lying on this line by some scalar alpha and observe how this changes behavior when we add it to the residual stream, or replace the output of an attention head with it (right), which we show in Figure 4.", "description": "This figure shows how the rank-1 property of component matrices simplifies the analysis of their influence on model behavior.  The left panel displays a PCA projection of inhibition component activations, illustrating their one-dimensional nature.  The right panel demonstrates how scaling these activations (\u03b1) and incorporating them into the residual stream affects the model's output.  This manipulation allows for a controlled way to study the impact of individual components on model decisions, particularly in the context of the IOI task.", "section": "3.3 Model Editing"}, {"figure_path": "LUsx0chTsL/figures/figures_18_1.jpg", "caption": "Figure 1: Language models are often sensitive to arbitrary changes in a prompt, for example the order in which objects are listed (right). This problem is more pronounced as the number of objects increases (left) even though it is not obvious where the issue stems from in the model. We broadly explore how information is routed through a model and focus on a mechanism that is in part responsible for this (in)ability.", "description": "This figure shows two plots. The left plot shows how the accuracy of language models on a laundry list task decreases as the number of objects in the list increases. The right plot shows an example of how the order of objects in a prompt can affect the model's ability to correctly answer a simple question. The figure highlights the sensitivity of language models to seemingly arbitrary changes in prompts and introduces the laundry list task that will be used in the paper to illustrate these problems.", "section": "1 Introduction"}, {"figure_path": "LUsx0chTsL/figures/figures_19_1.jpg", "caption": "Figure 1: Language models are often sensitive to arbitrary changes in a prompt, for example the order in which objects are listed (right). This problem is more pronounced as the number of objects increases (left) even though it is not obvious where the issue stems from in the model. We broadly explore how information is routed through a model and focus on a mechanism that is in part responsible for this (in)ability.", "description": "The figure shows two plots. The left plot shows how the accuracy of language models decreases as the number of objects in a laundry list increases. The right plot shows an example of how changing the order of items in a laundry list can affect the model's ability to correctly identify the item.", "section": "1 Introduction"}, {"figure_path": "LUsx0chTsL/figures/figures_20_1.jpg", "caption": "Figure 1: Language models are often sensitive to arbitrary changes in a prompt, for example the order in which objects are listed (right). This problem is more pronounced as the number of objects increases (left) even though it is not obvious where the issue stems from in the model. We broadly explore how information is routed through a model and focus on a mechanism that is in part responsible for this (in)ability.", "description": "The figure shows two plots. The left plot shows how the accuracy of language models in a laundry list task decreases as the number of items in the list increases. The right plot shows an example of how changing the order of items in a prompt can significantly impact the model's accuracy, even though the model should be able to access information from anywhere in the context.  This demonstrates the arbitrary sensitivities of large language models (LLMs) to seemingly minor prompt variations.", "section": "1 Introduction"}, {"figure_path": "LUsx0chTsL/figures/figures_21_1.jpg", "caption": "Figure 2: Showing the relationship between the composition score (weight-based, bottom) and inhibition score (data-based, top) between various inhibition head components and mover head 9.9 for the IOI task. The inhibition of each inhibition head is generally highly concentrated in one or two components of the matrix, removing it causes a large drop in the later mover head's ability to downweight one of the names. We therefore show that we can use the composition score when considering decomposed matrices.", "description": "This figure displays the relationship between weight-based composition scores and data-based inhibition scores for different inhibition heads communicating with a specific mover head (9.9) in the Indirect Object Identification (IOI) task.  The graph shows that inhibition within each head is concentrated in one or two components. Removing those components significantly reduces the mover head's ability to inhibit specific items.  This suggests that communication channels are low-rank subspaces within the residual stream. The results support the use of the composition score when examining decomposed matrices for improved interpretability.", "section": "Identifying Communication Channels in Low-Rank Subspaces"}, {"figure_path": "LUsx0chTsL/figures/figures_22_1.jpg", "caption": "Figure 7: Examples of composition scores of individual components with other heads. 4.11 is a previous token head, 5.5 is an induction head, 3.0 is a duplicate token head, 8.10 is an inhibition head, and 9.9 is a mover head. We find that there are large outlier components in value and query composition, but not in the induction head, thus motivating our focus on those heads in the main text.", "description": "This figure shows composition scores for different types of head interactions: previous token to induction head (key), duplicate token to inhibition head (value), and inhibition to mover head (query).  The figure demonstrates that some types of head interactions show clear signals in specific component matrices of the weight matrices (as revealed by Singular Value Decomposition), while others do not. This finding supports the authors' focus on certain types of head interactions in their analysis.", "section": "3 Identifying Communication Channels in Low-Rank Subspaces"}, {"figure_path": "LUsx0chTsL/figures/figures_23_1.jpg", "caption": "Figure 18: Pythia training progression of inhibition component (6.6.2) and effect of model editing. Adding the component matrix to the inhibition head strengthens the inhibition channel and improves the ability to use inhibition in earlier checkpoints, subtracting it makes inhibition weaker. Separability is simply the extent to which activations for IOI minimal pairs are split into clusters based on the order of names (IO, S1 or S1, IO).", "description": "This figure shows the training progression of the inhibition component subspace and the mover head inhibition score in the Pythia model. It demonstrates the effect of adding or removing the inhibition component on the model's ability to inhibit certain tokens. The separability metric indicates how well the model separates activations for minimal pairs based on the order of names, showing the impact of the inhibition component on the model's performance.", "section": "H.2 Training Progression of Inhibition Components"}, {"figure_path": "LUsx0chTsL/figures/figures_24_1.jpg", "caption": "Figure 19: Decomposing weight matrices cleans up the composition score enough that we can start to read off components that belong to the IOI circuit without running the model. By starting with a known inhibition head component (7.9.6) we can find the heads that compose into that component and the heads for which the inhibition component composes into that belong to the IOI circuit from Wang et al. [2022]. Left graphs show the composition score without any decomposition, which is noisy. On the right, we find in-circuit heads (circled) qualitatively to stand out more. See Wang et al. [2022] for more details.", "description": "This figure shows the results of decomposing weight matrices to find communication channels between attention heads.  The left side shows the noisy composition score without decomposition, while the right side shows the improved clarity after decomposition, highlighting in-circuit heads that communicate strongly.", "section": "Identifying Communication Channels in Low-Rank Subspaces"}, {"figure_path": "LUsx0chTsL/figures/figures_28_1.jpg", "caption": "Figure 19: Decomposing weight matrices cleans up the composition score enough that we can start to read off components that belong to the IOI circuit without running the model. By starting with a known inhibition head component (7.9.6) we can find the heads that compose into that component and the heads for which the inhibition component composes into that belong to the IOI circuit from Wang et al. [2022]. Left graphs show the composition score without any decomposition, which is noisy. On the right, we find in-circuit heads (circled) qualitatively to stand out more. See Wang et al. [2022] for more details.", "description": "This figure shows the results of decomposing weight matrices to find communication channels between attention heads. The left side shows the noisy composition scores without decomposition, while the right side shows the clearer results after decomposition, highlighting the in-circuit heads (circled in red).  The decomposition helps isolate the communication channels within the model's weights, allowing for identification of components belonging to the Indirect Object Identification (IOI) circuit without actually running the model.", "section": "3 Identifying Communication Channels in Low-Rank Subspaces"}, {"figure_path": "LUsx0chTsL/figures/figures_28_2.jpg", "caption": "Figure 2: Showing the relationship between the composition score (weight-based, bottom) and inhibition score (data-based, top) between various inhibition head components and mover head 9.9 for the IOI task. The inhibition of each inhibition head is generally highly concentrated in one or two components of the matrix, removing it causes a large drop in the later mover head's ability to downweight one of the names. We therefore show that we can use the composition score when considering decomposed matrices.", "description": "This figure displays the correlation between weight-based composition scores and data-based inhibition scores for different inhibition heads connected to mover head 9.9 in the IOI task. The low-rank nature of inhibition within individual heads is highlighted, showing that removing a component leads to reduced mover head performance. This supports the use of composition scores when considering decomposed matrices.", "section": "Identifying Communication Channels in Low-Rank Subspaces"}, {"figure_path": "LUsx0chTsL/figures/figures_29_1.jpg", "caption": "Figure 25: When predicting the continuation of sentences like \u2018I saw the book. I am reading the\u2019, head 8.3 is attends much more strongly to the given noun (book) when the verb is appropriate vs. inappropriate (e.g., eating). The average attention score is around 35% for likely nouns and around 5% for unlikely nouns.", "description": "This figure shows the results of an experiment designed to test the hypothesis that head 8.3 in GPT-2 attends to tokens that are logically appropriate continuations of the current context.  The experiment used a synthetic dataset of verb-noun pairs, with some pairs being semantically consistent (likely nouns) and others not (unlikely nouns). The results show a statistically significant difference in the mean attention scores of head 8.3 for likely vs. unlikely nouns, supporting the hypothesis that head 8.3 plays a role in identifying semantically appropriate continuations.", "section": "4.1 Interventions on Communication Channels"}, {"figure_path": "LUsx0chTsL/figures/figures_29_2.jpg", "caption": "Figure 25: When predicting the continuation of sentences like 'I saw the book. I am reading the', head 8.3 is attends much more strongly to the given noun (book) when the verb is appropriate vs. inappropriate (e.g., eating). The average attention score is around 35% for likely nouns and around 5% for unlikely nouns.", "description": "This figure shows the results of an experiment designed to test the hypothesis that head 8.3 in GPT-2 is involved in selecting relevant continuations of the current context.  The experiment used a synthetic dataset of verb-noun pairs, where the noun was either a likely or unlikely object of the verb. The figure displays the average attention score (probability mass assigned to a token) of head 8.3 to the noun in each condition. The results clearly indicate that head 8.3 attends much more strongly to nouns that are likely objects of the verb, providing further support for its role in contextual continuation.", "section": "4.1 Interventions on Communication Channels"}, {"figure_path": "LUsx0chTsL/figures/figures_30_1.jpg", "caption": "Figure 27: How the 3D inhibition subspace responds to a different number of objects in laundry list prompts. As we add objects, a new \u2018slice\u2019 of the space is allocated (not always visible) for attention to that object until the middle set of objects is squeezed into a small neighborhood of the space. The space is very well structured, except for two cases where artifacts form in the 8 and 10 object settings.", "description": "This figure visualizes how the 3D inhibition subspace of a language model changes with increasing numbers of objects in a laundry list task.  Each subplot represents a different number of objects, showing how the model allocates attention in its 3D inhibition subspace.  The color of each point corresponds to which object the model attends to.  As the number of objects increases, the subspace becomes more densely packed, leading to a breakdown of the clear structure for higher object counts.", "section": "5.2 Intervention Experiments"}, {"figure_path": "LUsx0chTsL/figures/figures_31_1.jpg", "caption": "Figure 4: We find that the 1D inhibition components and 2D duplicate token components finely control which name is avoided by the mover head. On the top, we can selectively inhibit either the first or second name depending on how we scale a vector lying on the 8.10.1 output space. This is strictly controlling relative position. On the bottom, we find that adding or removing duplicate token information from the duplicate channel at the IO or S1 tokens also effectively modulates which name is inhibited. Neither random heads, nor non-communication channel components exhibit these same effects (right). See Appendix E for results on other heads.", "description": "This figure shows how the 1D inhibition components and 2D duplicate token components precisely control which name is avoided by the mover head.  By scaling a vector in the output space of an inhibition component, either the first or second name can be selectively inhibited.  Similarly, adding or removing duplicate token information from the duplicate channel also affects which name is inhibited. The experiment demonstrates that only these specific components have this causal effect on the model's behavior.", "section": "3.3 Model Editing"}, {"figure_path": "LUsx0chTsL/figures/figures_32_1.jpg", "caption": "Figure 27: How the 3D inhibition subspace responds to a different number of objects in laundry list prompts. As we add objects, a new \u2018slice\u2019 of the space is allocated (not always visible) for attention to that object until the middle set of objects is squeezed into a small neighborhood of the space. The space is very well structured, except for two cases where artifacts form in the 8 and 10 object settings.", "description": "This figure visualizes how the model's 3D inhibition subspace handles an increasing number of objects in a laundry list task. Each point represents a model's attention to a specific object. As more items are added, the space becomes more crowded, impacting the model's ability to accurately index and retrieve the correct information, especially from the middle of the list. The structure is surprisingly neat, except for a few instances where artifacts appear.", "section": "5.2 Intervention Experiments"}, {"figure_path": "LUsx0chTsL/figures/figures_33_1.jpg", "caption": "Figure 5: Scaling the inhibition component for a single head (here 8.10, left) is not expressive enough to get the mover head to index between the various objects. Scaling the top three inhibition components (middle) gives us enough expressive power to selectively attend to one of the objects. Here, one dot represents a run on the corresponding dataset and the color represents the index of the object the mover head pays the most attention to on average. A surprising structure emerges that partitions the space according to the index of the objects. However, the neat structure begins to break down as the number of objects grows around 10 or higher, and affects the mover head's ability to attend to the right object, which impacts accuracy. Right: Accuracy improvements as a result of sampling from inhibition space. The model becomes much more capable of handling a bigger number of objects in that the accuracy for N objects after the intervention is about as high as the unaltered model when it sees N/2 objects. However, the representational power of the inhibition channel reaches capacity as the number of objects increases, and performance can not improve as much.", "description": "This figure shows the effect of scaling different combinations of inhibition components on the mover head's attention to different items in the laundry list task.  The left panel shows that scaling a single component isn't sufficient for large lists. The middle panel reveals that scaling three components creates a structured space where different regions correspond to different item positions, but this structure degrades with larger list sizes. The right panel presents the accuracy improvement resulting from sampling from this inhibition space, demonstrating that this intervention greatly helps for longer lists while showing a capacity limit.", "section": "5 The Inhibition Channel is Crucial in Context Retrieval Tasks"}, {"figure_path": "LUsx0chTsL/figures/figures_34_1.jpg", "caption": "Figure 27: How the 3D inhibition subspace responds to a different number of objects in laundry list prompts. As we add objects, a new \u2018slice\u2019 of the space is allocated (not always visible) for attention to that object until the middle set of objects is squeezed into a small neighborhood of the space. The space is very well structured, except for two cases where artifacts form in the 8 and 10 object settings.", "description": "This figure visualizes how the model's 3D inhibition subspace handles an increasing number of objects in the laundry list task.  Each sub-figure represents a different number of objects.  As more objects are added, the model allocates more space within the 3D subspace to represent them. However, this representation capacity has limits; the middle objects become crowded together in the space, which negatively affects the model's performance in the task.", "section": "5.2 Intervention Experiments"}, {"figure_path": "LUsx0chTsL/figures/figures_35_1.jpg", "caption": "Figure 5: Scaling the inhibition component for a single head (here 8.10, left) is not expressive enough to get the mover head to index between the various objects. Scaling the top three inhibition components (middle) gives us enough expressive power to selectively attend to one of the objects. Here, one dot represents a run on the corresponding dataset and the color represents the index of the object the mover head pays the most attention to on average. A surprising structure emerges that partitions the space according to the index of the objects. However, the neat structure begins to break down as the number of objects grows around 10 or higher, and affects the mover head's ability to attend to the right object, which impacts accuracy. Right: Accuracy improvements as a result of sampling from inhibition space. The model becomes much more capable of handling a bigger number of objects in that the accuracy for N objects after the intervention is about as high as the unaltered model when it sees N/2 objects. However, the representational power of the inhibition channel reaches capacity as the number of objects increases, and performance can not improve as much.", "description": "This figure shows the results of manipulating the inhibition components.  The left panel shows that manipulating a single inhibition component doesn't allow for selecting specific objects, while manipulating three components (middle) creates a surprisingly well-organized structure in the attention space.  However, this structure degrades with more items. The right panel shows the accuracy increase achieved by randomly sampling within the inhibition space.  The improvement is substantial for smaller lists but plateaus with larger ones because the model's ability to index the items in the list is capacity-limited.", "section": "5 The Inhibition Channel is Crucial in Context Retrieval Tasks"}, {"figure_path": "LUsx0chTsL/figures/figures_36_1.jpg", "caption": "Figure 5: Scaling the inhibition component for a single head (here 8.10, left) is not expressive enough to get the mover head to index between the various objects. Scaling the top three inhibition components (middle) gives us enough expressive power to selectively attend to one of the objects. Here, one dot represents a run on the corresponding dataset and the color represents the index of the object the mover head pays the most attention to on average. A surprising structure emerges that partitions the space according to the index of the objects. However, the neat structure begins to break down as the number of objects grows around 10 or higher, and affects the mover head's ability to attend to the right object, which impacts accuracy. Right: Accuracy improvements as a result of sampling from inhibition space. The model becomes much more capable of handling a bigger number of objects in that the accuracy for N objects after the intervention is about as high as the unaltered model when it sees N/2 objects. However, the representational power of the inhibition channel reaches capacity as the number of objects increases, and performance can not improve as much.", "description": "This figure shows the results of experiments manipulating the inhibition channel to improve the model's ability to recall items from a list (Laundry List Task).  The left and middle panels show that interventions on the inhibition channel allow for finer-grained control over which item the model attends to, but this ability degrades as the list length increases.  The right panel shows that manipulating this channel leads to significant accuracy improvements in recalling items from the list, especially when the number of items is small to moderate.", "section": "5 The Inhibition Channel is Crucial in Context Retrieval Tasks"}, {"figure_path": "LUsx0chTsL/figures/figures_37_1.jpg", "caption": "Figure 5: Scaling the inhibition component for a single head (here 8.10, left) is not expressive enough to get the mover head to index between the various objects. Scaling the top three inhibition components (middle) gives us enough expressive power to selectively attend to one of the objects. Here, one dot represents a run on the corresponding dataset and the color represents the index of the object the mover head pays the most attention to on average. A surprising structure emerges that partitions the space according to the index of the objects. However, the neat structure begins to break down as the number of objects grows around 10 or higher, and affects the mover head's ability to attend to the right object, which impacts accuracy. Right: Accuracy improvements as a result of sampling from inhibition space. The model becomes much more capable of handling a bigger number of objects in that the accuracy for N objects after the intervention is about as high as the unaltered model when it sees N/2 objects. However, the representational power of the inhibition channel reaches capacity as the number of objects increases, and performance can not improve as much.", "description": "This figure shows the effect of manipulating the inhibition components on the mover head's attention and the model's accuracy on the Laundry List task.  The left panel shows that scaling a single inhibition component is insufficient to control attention to specific objects in the list. The middle panel demonstrates that scaling a combination of three inhibition components allows for fine-grained control over which object is attended to, revealing an intricate structure in the model's representation of list items. However, this structure breaks down as the list length increases, demonstrating a capacity limit of the inhibition mechanism. The right panel illustrates the improvement in task accuracy achieved by strategically sampling from the inhibition space.", "section": "5.2 Intervention Experiments"}, {"figure_path": "LUsx0chTsL/figures/figures_38_1.jpg", "caption": "Figure 27: How the 3D inhibition subspace responds to a different number of objects in laundry list prompts. As we add objects, a new \u2018slice\u2019 of the space is allocated (not always visible) for attention to that object until the middle set of objects is squeezed into a small neighborhood of the space. The space is very well structured, except for two cases where artifacts form in the 8 and 10 object settings.", "description": "This figure visualizes how the three-dimensional inhibition subspace in a language model handles an increasing number of objects in a laundry list task. Each sub-figure represents a different number of objects (3-10 and 20).  The colors indicate which object the model is primarily focusing on. The plot shows that as the number of objects increases, the model's attention to the objects gets increasingly compressed and less structured, especially in the middle range of objects, potentially indicating a capacity limitation in this mechanism.", "section": "5.2 Intervention Experiments"}, {"figure_path": "LUsx0chTsL/figures/figures_39_1.jpg", "caption": "Figure 5: Scaling the inhibition component for a single head (here 8.10, left) is not expressive enough to get the mover head to index between the various objects. Scaling the top three inhibition components (middle) gives us enough expressive power to selectively attend to one of the objects. Here, one dot represents a run on the corresponding dataset and the color represents the index of the object the mover head pays the most attention to on average. A surprising structure emerges that partitions the space according to the index of the objects. However, the neat structure begins to break down as the number of objects grows around 10 or higher, and affects the mover head's ability to attend to the right object, which impacts accuracy. Right: Accuracy improvements as a result of sampling from inhibition space. The model becomes much more capable of handling a bigger number of objects in that the accuracy for N objects after the intervention is about as high as the unaltered model when it sees N/2 objects. However, the representational power of the inhibition channel reaches capacity as the number of objects increases, and performance can not improve as much.", "description": "This figure visualizes how scaling inhibition components affects the mover head's attention and model accuracy in a laundry list task.  The left panel shows that scaling a single inhibition component is insufficient for precise object selection. The middle panel demonstrates that scaling three inhibition components reveals a structured representation space where attention is partitioned by object index; this structure degrades with a larger number of objects. The right panel displays accuracy improvements resulting from sampling within the inhibition space, showing enhanced performance but limited capacity.", "section": "5 The Inhibition Channel is Crucial in Context Retrieval Tasks"}]