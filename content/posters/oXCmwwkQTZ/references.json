{"references": [{"fullname_first_author": "Adlam, B.", "paper_title": "A random matrix perspective on mixtures of nonlinearities in high dimensions", "publication_date": "2022", "reason": "This paper provides a theoretical framework for analyzing the impact of nonlinearities on the generalization performance of neural networks, which is crucial for understanding the implicit regularization effects studied in the main paper."}, {"fullname_first_author": "Ali, A.", "paper_title": "The implicit regularization of stochastic gradient flow for least squares", "publication_date": "2020", "reason": "This paper investigates the implicit regularization effects induced by stochastic gradient descent for least squares regression, providing a theoretical basis for understanding the behavior of neural networks in overparameterized settings."}, {"fullname_first_author": "Bartlett, P. L.", "paper_title": "Benign overfitting in linear regression", "publication_date": "2020", "reason": "This paper provides a theoretical analysis of the phenomenon of benign overfitting in linear regression, which is relevant to the study of implicit regularization in high-dimensional settings."}, {"fullname_first_author": "Mei, S.", "paper_title": "The generalization error of random features regression: Precise asymptotics and the double descent curve", "publication_date": "2022", "reason": "This paper provides a detailed analysis of the generalization error of random features regression, which is closely related to the study of implicit regularization in kernel methods and neural networks."}, {"fullname_first_author": "Patil, P.", "paper_title": "Generalized equivalences between subsampling and ridge regularization", "publication_date": "2023", "reason": "This paper establishes generalized equivalences between subsampling and ridge regularization, which directly addresses the main topic of the current paper and serves as a foundation for many of the results."}]}