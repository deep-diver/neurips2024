[{"figure_path": "cM2gU9XGti/figures/figures_2_1.jpg", "caption": "Figure 1: Overview of PRB stopping behavior when f : [0, 1]\u00b2 \u2192 R is drawn from a model with noise variance \u03b3\u00b2 = 10\u207b\u2074. Regret bounds \u03b5 > 0 dictate how close f(x) must be to the optimum f* for x \u2208 X to be satisfactory. Tolerances \u03b4 > 0 upper bound the chance of returning an unsatisfactory point. Left: Percent of runs that stopped before time T = 128. Middle: Percent of stopped runs that returned \u03b5-optimal points. Right: Median number of trials performed by stopped runs.", "description": "This figure visualizes the performance of the Probabilistic Regret Bound (PRB) stopping rule under different parameter settings. It shows how the percentage of runs stopped, the success rate (percentage of stopped runs that found an \u03b5-optimal solution), and the median number of trials vary with different regret bounds (\u03b5) and risk tolerances (\u03b4).  The results highlight the trade-off between stopping early and ensuring a high probability of finding a good solution.", "section": "3 Method"}, {"figure_path": "cM2gU9XGti/figures/figures_3_1.jpg", "caption": "Figure 2: Left: Posterior mean and two standard deviations of f (blue) given eight noisy observations (black dots). The goal is to find a point x \u2208 X whose true function (black) value is within \u20ac > 0 of the optimum f* (orange star). Middle: Draws of ft ~ GP(\u00b5t, kt) and f* (orange stars). Right: Estimators for \u03a8t. Ground truth (dashed black) was established using location-scale sampling on a dense grid. The joint-sampling strategy from Section 3.1 is shown in blue. Competing methods analytically integrated out ft(x) | f* by approximating it with: ft(x), ft(x) | ft(x) \u2264 ft, or ft(x) | ft(x) \u2264 ft ft(x) = ft where ft and x \u2208 arg max\u2208x ft(x) were jointly sampled.", "description": "This figure shows three panels that illustrate the task of simulating whether a point x \u2208 X satisfies the stopping condition, which is that the true function value f(x) is within epsilon of the optimum f*.  The left panel shows the posterior mean and standard deviation of a Gaussian process (GP) model for the function f given noisy observations.  The middle panel illustrates the simulation of ft using different methods (the proposed method and three competing methods), showing several draws from the posterior distribution of the GP model with the true function value overlaid. The right panel compares several estimators of the probability that the simple regret is less than epsilon.", "section": "How to simulate stopping conditions"}, {"figure_path": "cM2gU9XGti/figures/figures_4_1.jpg", "caption": "Figure 3: Left: Median number of draws used by Algorithm 2 to decide if the expectation of a Bernoulli random variable Z ~ Bern(p) exceeds \u03bb = 10\u22125 (chosen arbitrarily). Middle: Empirical CDFs of \u03a8t when optimizing draws from known priors GP(0, k) in two, four, and six dimensions with noise variance \u03b3\u00b2 = 10\u22126 (solid, \u25cb) or \u03b3\u00b2 = 10\u22122 (dashed, \u00d7). PRB parameters were set to \u03b5 = 0.1 and \u03b4mod = \u03b4dest = 2.5%. Right: Runtimes for Algorithm 2 using the generative strategy from Section 3.1 and a (wall) time limit of roughly one thousand seconds.", "description": "This figure summarizes the performance of Algorithm 2 for different settings. The left panel shows how many samples are needed to decide whether the expectation of a Bernoulli random variable exceeds a certain threshold, for various Bernoulli parameters and risk tolerances. The middle panel illustrates the cumulative distribution functions (CDFs) of the estimator \u03a8t under different conditions, showing that the estimator performs well in terms of accurately estimating the probabilities even for high-dimensional settings. Finally, the right panel shows that the algorithm can achieve efficiency in terms of runtime, which automatically adapts to the problem's difficulty.", "section": "3.2 How to efficiently make robust decisions with Monte Carlo estimates"}, {"figure_path": "cM2gU9XGti/figures/figures_12_1.jpg", "caption": "Figure 1: Overview of PRB stopping behavior when f : [0, 1]2 \u2192 R is drawn from a model with noise variance y\u00b2 = 10\u22124. Regret bounds \u20ac > 0 dictate how close f(x) must be to the optimum f* for x \u2208 X to be satisfactory. Tolerances \u03b4 > 0 upper bound the chance of returning an unsatisfactory point. Left: Percent of runs that stopped before time T = 128. Middle: Percent of stopped runs that returned e-optimal points. Right: Median number of trials performed by stopped runs.", "description": "This figure shows the results of experiments evaluating the probabilistic regret bound (PRB) stopping rule.  The experiment simulates a two-dimensional black-box function (f) sampled from a Gaussian process model.  The figure displays the performance of the PRB stopping rule under varying parameters (\u20ac, \u03b4, which control the desired accuracy and confidence of the solution). Three panels are shown: (left) Percentage of runs that stopped before a time limit (T=128),  (middle) Percentage of runs that stopped and returned an e-optimal solution, and (right) Median number of function evaluations performed by the stopped runs. This illustrates the adaptive nature of the PRB rule, which automatically adjusts the number of evaluations required based on how quickly an acceptable solution is found. ", "section": "3 Method"}]