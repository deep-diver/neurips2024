{"references": [{"fullname_first_author": "Haotian Liu", "paper_title": "Improved baselines with visual instruction tuning", "publication_date": "2024-00-00", "reason": "This paper provides improved baselines for visual instruction tuning, which is a core technique used in many Large Vision-Language Models (LVLMs) and directly relevant to the topic of the current paper."}, {"fullname_first_author": "Wenliang Dai", "paper_title": "InstructBLIP: Towards general-purpose vision-language models with instruction tuning", "publication_date": "2023-00-00", "reason": "InstructBLIP is a significant LVLMs, and its use of instruction tuning is a key method discussed and compared in the current paper."}, {"fullname_first_author": "Qinghao Ye", "paper_title": "mPLUG-Owl: Modularization empowers large language models with multimodality", "publication_date": "2023-00-00", "reason": "This paper introduces mPLUG-Owl, another important LVLMs that is referenced and compared against in the current paper's experiments."}, {"fullname_first_author": "Jinze Bai", "paper_title": "Qwen-VL: A frontier large vision-language model with versatile abilities", "publication_date": "2023-00-00", "reason": "Qwen-VL is a strong LVLMs, and its capabilities are relevant to the current paper's goals of improving modality alignment and reducing hallucinations."}, {"fullname_first_author": "Anna Rohrbach", "paper_title": "Object hallucination in image captioning", "publication_date": "2018-09-00", "reason": "This early work is highly influential because it first identified and defined the phenomenon of hallucination in image captioning, a core problem that the current paper addresses."}]}