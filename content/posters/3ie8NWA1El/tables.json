[{"figure_path": "3ie8NWA1El/tables/tables_7_1.jpg", "caption": "Table 1: Convergence Rates in terms of n, p, m, and T", "description": "This table compares the convergence rates of the HyperPrism framework with those of other methods from related works.  The convergence rate is expressed in Big O notation, showing the dependence on parameters n (learning rate), p (power degree), m (number of devices), and T (number of rounds). The 'Recovered' column indicates whether the theoretical convergence rate is consistent with the empirical observations from prior studies.", "section": "5.3 Comparison to Previous Work"}, {"figure_path": "3ie8NWA1El/tables/tables_9_1.jpg", "caption": "Table 2: Comparison on Different non-IID Degree", "description": "This table compares the performance of different algorithms (SwarmSGD, DPSGD, Mudag, ADOM, and the proposed HyperPrism) under varying degrees of non-IID data distribution (Dirichlet 0.1, 1, and 10).  For each setting, it shows the maximum accuracy achieved and the number of convergence rounds for both Logistic Regression (LR) on MNIST and Convolutional Neural Network (CNN) on CIFAR-10. The results highlight the impact of data heterogeneity on the algorithms' performance, demonstrating the effectiveness of HyperPrism in handling non-IID data.", "section": "6.2 Experimental Results"}, {"figure_path": "3ie8NWA1El/tables/tables_9_2.jpg", "caption": "Table 3: Comparison on Different Connection Densities", "description": "This table presents the performance of various methods (SwarmSGD, DPSGD, Mudag, ADOM, and the proposed HyperPrism) under different communication densities (0.2, 0.5, and 0.8).  The results are shown for both the Logistic Regression model on MNIST and the CNN model on CIFAR-10 datasets.  The metrics reported include the maximum accuracy achieved and the number of convergence rounds required.  The percentage change in performance compared to the baseline methods is also displayed for HyperPrism, illustrating its superior performance and robustness across varying connectivity conditions.", "section": "6.2 Experimental Results"}, {"figure_path": "3ie8NWA1El/tables/tables_9_3.jpg", "caption": "Table 4: Comparison on Different Device Numbers", "description": "This table presents a comparison of the performance of various decentralized machine learning methods (including HyperPrism and baselines) across different numbers of devices (20, 50, and 100).  It shows the maximum accuracy achieved and the number of convergence rounds for each method across two datasets (LR + MNIST and CNN + CIFAR-10) under non-IID data distributions.  The results highlight the scalability and performance of each method as the number of devices increases.  The last row shows the percentage improvement in accuracy and convergence rounds for HyperPrism compared to the baselines.", "section": "6.2 Experimental Results"}, {"figure_path": "3ie8NWA1El/tables/tables_14_1.jpg", "caption": "Table 1: Convergence Rates in terms of n, p, m, and T", "description": "This table compares the convergence rates of different frameworks for distributed machine learning in terms of key parameters: n (learning rate), p (degree of power mean), m (number of devices), and T (number of rounds). It shows the theoretical convergence rates achieved by HyperPrism and several existing methods.  The table is useful for understanding the relative scalability and efficiency of these frameworks under various conditions.", "section": "5.3 Comparison to Previous Work"}]