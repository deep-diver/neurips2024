{"references": [{"fullname_first_author": "Richard S. Sutton", "paper_title": "Reinforcement learning: An introduction", "publication_date": "1998-01-01", "reason": "This is a foundational textbook in reinforcement learning, providing the basic concepts and algorithms used throughout the field."}, {"fullname_first_author": "Sepp Hochreiter", "paper_title": "Long short-term memory", "publication_date": "1997-01-01", "reason": "This paper introduces Long Short-Term Memory (LSTM) networks, a crucial recurrent neural network architecture used extensively in the paper's recurrent RL methods."}, {"fullname_first_author": "Tuomas Haarnoja", "paper_title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor", "publication_date": "2018-01-01", "reason": "Soft Actor-Critic (SAC) is a key off-policy reinforcement learning algorithm that is extended in the paper to handle recurrent networks."}, {"fullname_first_author": "Tianwei Ni", "paper_title": "Recurrent model-free RL can be a strong baseline for many POMDPs", "publication_date": "2022-01-01", "reason": "This paper establishes recurrent model-free RL as a strong baseline for partially observable Markov decision processes (POMDPs), a problem the current paper directly addresses and improves upon."}, {"fullname_first_author": "Albert Gu", "paper_title": "Mamba: Linear-time sequence modeling with selective state spaces", "publication_date": "2023-01-01", "reason": "This paper introduces Mamba, a recurrent neural network architecture used in the paper's experiments, offering improved computational efficiency."}]}