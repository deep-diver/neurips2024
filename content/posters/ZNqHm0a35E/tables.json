[{"figure_path": "ZNqHm0a35E/tables/tables_7_1.jpg", "caption": "Table 1: IVLOD results on ODinW-13 and ZCOCO. All results are based on the same Grounding DINO. \u201cShots", "description": "This table presents the results of the Incremental Vision-Language Object Detection (IVLOD) experiments conducted on the ODinW-13 and ZCOCO datasets.  The results are broken down by the number of shots (training samples) used during adaptation training for different models: Original Model, TFA, iDETR, AT, and ZiRa. The performance metrics are ZCOCO (zero-shot performance on COCO) and Avg (average performance across the 13 ODinW-13 datasets).  Individual dataset results (Ae, Aq, Co, etc.) are also included for a detailed analysis.  All experiments utilize the same Grounding DINO model as the base.", "section": "4.1 Setup"}, {"figure_path": "ZNqHm0a35E/tables/tables_7_2.jpg", "caption": "Table 1: IVLOD results on ODinW-13 and ZCOCO. All results are based on the same Grounding DINO. \u201cShots\u201d means how many samples are used when adaptation training.", "description": "This table presents the results of the Incremental Vision-Language Object Detection (IVLOD) experiments using Grounding DINO on the ODinW-13 and COCO datasets. It shows a comparison of different methods (Original Model, TFA, iDETR, AT, and ZiRa) in terms of zero-shot Average Precision (AP) on COCO (ZCOCO) and average AP across 13 downstream tasks (Avg) in ODinW-13.  The number of shots (samples used for adaptation training) is also specified for each method.  The table helps demonstrate the effectiveness of the ZiRa method in maintaining zero-shot generalization capability while adapting to new tasks incrementally.", "section": "4.1 Setup"}, {"figure_path": "ZNqHm0a35E/tables/tables_8_1.jpg", "caption": "Table 1: IVLOD results on ODinW-13 and ZCOCO. All results are based on the same Grounding DINO. \u201cShots\u201d means how many samples are used when adaptation training.", "description": "This table presents the results of the Incremental Vision-Language Object Detection (IVLOD) experiments.  It compares the performance of different methods (Original Model, TFA, iDETR, AT, and ZiRa) across various metrics (ZCOCO and average performance across 13 downstream tasks in ODinW-13 dataset). The results are shown for different numbers of training samples (\u201cShots\u201d) used for adaptation. All experiments used the same pre-trained Grounding DINO model.", "section": "4.1 Setup"}, {"figure_path": "ZNqHm0a35E/tables/tables_9_1.jpg", "caption": "Table 4: Comparison of learning on different modalities.", "description": "This table presents a comparison of the performance of the proposed ZiRa method when learning is conducted on different modalities, including only vision, only language, both vision and language, and various combinations thereof.  The results are shown in terms of ZCOCO (zero-shot COCO performance), Avg (average performance across 13 downstream tasks), and hAP (harmonic mean of ZCOCO and Avg).  The table highlights the impact of learning on both vision and language aspects for better performance on zero-shot and downstream tasks.  The results indicate that learning on both sides delivers better performance.", "section": "4.2 Comparison with Existing Methods"}, {"figure_path": "ZNqHm0a35E/tables/tables_9_2.jpg", "caption": "Table 5: Comparison of different additional branch structures. We compared the results of introducing a single branch (denoted as SB), dual branches (denoted as DB), and RDB (DB + Rep+).", "description": "This table compares the performance of three different branch structures (Single Branch, Dual Branch, and Reparameterizable Dual Branch) in the context of incremental vision-language object detection.  The results show the Zero-shot Average Precision (ZCOCO), the average Average Precision across downstream tasks (Avg), and the harmonic mean of ZCOCO and Avg (hAP). The RDB structure consistently outperforms the other two.", "section": "4.2 Comparison with Existing Methods"}, {"figure_path": "ZNqHm0a35E/tables/tables_13_1.jpg", "caption": "Table 6: Results with varying \u03bb for ZiL.", "description": "This table shows the impact of different values of the hyperparameter \u03bb (lambda) on the model's performance.  \u03bb controls the influence of the Zero-Interference Loss (ZiL) in the overall loss function.  The table presents the zero-shot Average Precision (ZCOCO), the average Average Precision across 13 downstream tasks (Avg), and the harmonic mean of ZCOCO and Avg (hAP) for different values of \u03bb. The results indicate that an optimal value of \u03bb exists that balances zero-shot performance and performance on downstream tasks, with values that are too small or too large leading to suboptimal results.", "section": "4.3 Ablation Study"}, {"figure_path": "ZNqHm0a35E/tables/tables_13_2.jpg", "caption": "Table 7: Results with varying \u03b7.", "description": "This table presents the results of an ablation study on the impact of the hyperparameter \u03b7 (eta) on the performance of the ZiRa model. Eta controls the learning rate ratio between the Low-learning rate Branch (LLRB) and the High-learning rate Branch (HLRB) within the Reparameterizable Dual Branch (RDB) structure. The table shows that there is a balance to be achieved with this parameter: Too low of a value, and the model doesn't adapt enough, too high, and the model forgets previous knowledge.  The results are measured using ZCOCO (zero-shot COCO performance), Avg (average performance across downstream tasks), and hAP (harmonic mean of ZCOCO and Avg). The best results across all three metrics are observed with \u03b7 = 0.20.", "section": "4.3 Ablation Study"}, {"figure_path": "ZNqHm0a35E/tables/tables_14_1.jpg", "caption": "Table 8: Impact of Different Initial Values of the Scaling Factor.", "description": "This table presents the results of an ablation study investigating the impact of different initial values for the scaling factor 's' in the Reparameterizable Dual Branch (RDB) on the performance of the model. The scaling factor 's' is used in the equation Xrdb = HLRB(x)\u00b7s + LLRB(x), where Xrdb is the output of the RDB, HLRB(x) is the output of the High-learning rate Branch, and LLRB(x) is the output of the Low-learning rate Branch. The table shows how variations in the initial values of 's' for both language and vision components affect the model's performance across different metrics, such as ZCOCO, Avg, and hAP. The results demonstrate that asymmetrical scaling (different values for language and vision) is often better than symmetrical scaling (same value for both).", "section": "4.3 Ablation Study"}, {"figure_path": "ZNqHm0a35E/tables/tables_14_2.jpg", "caption": "Table 9: Results with Varying Norm Types of ZiL.", "description": "This table presents the results of an ablation study that investigates the impact of different norm types (L1, L2, and Smooth L1) used in the Zero-interference Loss (ZiL) on the overall performance of the proposed approach.  The performance is measured using three metrics: ZCOCO (zero-shot performance on the COCO dataset), Avg (average performance across 13 downstream tasks in the ODinW-13 dataset), and hAP (harmonic mean of ZCOCO and Avg).  The table shows how the choice of norm type affects the balance between zero-shot generalizability and performance on the downstream tasks.", "section": "4.3 Ablation Study"}]