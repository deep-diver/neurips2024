[{"figure_path": "UO7Mvch1Z5/figures/figures_0_1.jpg", "caption": "Figure 1: Gallery of Unique3D. High-fidelity and diverse textured mesh generated by Unique3D from single-view wild images within 30 seconds.", "description": "This figure shows a gallery of 3D models generated by the Unique3D model.  Each model was generated from a single, unconstrained image in under 30 seconds, demonstrating the model's speed and ability to generate high-fidelity, detailed meshes with diverse textures.", "section": "Abstract"}, {"figure_path": "UO7Mvch1Z5/figures/figures_0_2.jpg", "caption": "Figure 1: Gallery of Unique3D. High-fidelity and diverse textured mesh generated by Unique3D from single-view wild images within 30 seconds.", "description": "This figure showcases a variety of 3D models generated by the Unique3D model.  The models demonstrate the system's ability to produce high-fidelity and diverse textured meshes from single images, highlighting its ability to capture details and nuances of the original images.  The speed of generation (within 30 seconds) is also emphasized.", "section": "Abstract"}, {"figure_path": "UO7Mvch1Z5/figures/figures_3_1.jpg", "caption": "Figure 2: Pipeline of our Unique3D. Given a single in-the-wild image as input, we first generate four orthographic multi-view images from a multi-view diffusion model. Then, we progressively improve the resolution of generated multi-views through a multi-level upscale process. Given generated color images, we train a normal diffusion model to generate normal maps corresponding to multi-view images and utilize a similar strategy to lift it to high-resolution space. Finally, we reconstruct high-quality 3D meshes from high-resolution color images and normal maps with our instant and consistent mesh reconstruction algorithm ISOMER.", "description": "This figure illustrates the pipeline of the Unique3D framework. It starts with a single input image and uses a multi-view diffusion model to generate four orthographic views.  These views are then upscaled to higher resolution using a multi-level approach.  A normal diffusion model is used to create corresponding normal maps, which are also upscaled.  Finally, the high-resolution images and normal maps are fed into the ISOMER algorithm to reconstruct a high-quality 3D textured mesh.", "section": "3 Method"}, {"figure_path": "UO7Mvch1Z5/figures/figures_6_1.jpg", "caption": "Figure 3: Qualitative Comparison. Our approach provides superior geometry and texture.", "description": "This figure presents a qualitative comparison of the 3D models generated by the proposed Unique3D method and several existing state-of-the-art image-to-3D techniques.  For each method, the input image and the resulting 3D model are shown, demonstrating the high-fidelity geometry and texture details achieved by Unique3D.  The results show that Unique3D generates superior results compared to the baselines in terms of both geometry and texture.", "section": "4 Experiments"}, {"figure_path": "UO7Mvch1Z5/figures/figures_7_1.jpg", "caption": "Figure 4: Detailed Comparison. We compare our model with InstantMesh [63], CRM [60] and OpenLRM [11]. Our models generates accurate geometry and detailed texture.", "description": "This figure compares the 3D mesh reconstruction results of Unique3D against three other state-of-the-art methods: InstantMesh, CRM, and OpenLRM.  The comparison highlights the superior quality of Unique3D in terms of both geometric accuracy (shape) and textural detail (surface appearance).  For each input image, the figure shows the generated 3D models from all four methods, allowing for a direct visual comparison.", "section": "4 Experiments"}, {"figure_path": "UO7Mvch1Z5/figures/figures_8_1.jpg", "caption": "Figure 5: Ablation Study on ISOMER. (a) Without ExplicitTarget, the output mesh result has obvious defects. (b) Without expansion regularization, the output result collapses in some cases.", "description": "This figure shows the ablation study performed on the ISOMER (Instant and consistent mesh reconstruction) algorithm.  The results demonstrate the importance of two key components: ExplicitTarget and expansion regularization.  (a) shows that without the ExplicitTarget, the generated mesh suffers from significant defects, particularly in regions with detailed textures or complex shapes. (b) reveals that without expansion regularization, the mesh often collapses in several areas.", "section": "3.2 ISOMER: An Efficient Method for Direct Mesh Reconstruction"}, {"figure_path": "UO7Mvch1Z5/figures/figures_8_2.jpg", "caption": "Figure 6: Ablation on Colorize. We show a comparison of whether or not to apply ExplicitTarget in coloring, and we can see that the group that does not use ExplicitTarget has significant artifacts, as there is no precise consistency across multiple views.", "description": "This figure shows an ablation study comparing the results of mesh coloring with and without the ExplicitTarget method. The top row displays meshes colored using ExplicitTarget, resulting in consistent and artifact-free coloring across multiple views. The bottom row displays meshes colored without ExplicitTarget, showcasing significant artifacts and inconsistencies in coloring across different views. This demonstrates the efficacy of ExplicitTarget in achieving color consistency in multi-view mesh reconstruction.", "section": "4.3 Ablation Study and Discussion"}, {"figure_path": "UO7Mvch1Z5/figures/figures_9_1.jpg", "caption": "Figure 7: Ablation on Resolution. The visualization of the generated multi-views images at different stages is shown. Multi-level super-resolution does not change the general structure, but only improves the detail resolution, allowing the model to remain well-detailed.", "description": "This figure shows an ablation study on the effect of multi-level super-resolution on the generated multi-view images.  It demonstrates that increasing the resolution from 256 to 512 to 2048 progressively improves the detail and fidelity of the generated images, without significantly altering the overall structure. This highlights the effectiveness of the proposed multi-level upscale process in enhancing the quality of the 3D mesh generation.", "section": "4.1 Experimental Setting"}, {"figure_path": "UO7Mvch1Z5/figures/figures_9_2.jpg", "caption": "Figure 8: Challenging examples", "description": "This figure demonstrates the capability of Unique3D to generate high-quality 3D textured meshes from challenging input images.  The examples showcase the model's ability to handle complex geometries, intricate textures, and diverse styles.", "section": "4 Experiments"}, {"figure_path": "UO7Mvch1Z5/figures/figures_14_1.jpg", "caption": "Figure 9: More generated results of our method from a single image.", "description": "This figure showcases additional examples of 3D textured meshes generated by the Unique3D model from single input images.  It expands on Figure 1, demonstrating the model's ability to generate diverse and high-fidelity 3D models from a wider variety of input images. The figure shows various objects and characters such as cartoon characters, animals, and robots, each presented in multiple views to showcase the quality and consistency of the generated 3D models.", "section": "A More Results"}, {"figure_path": "UO7Mvch1Z5/figures/figures_16_1.jpg", "caption": "Figure 2: Pipeline of our Unique3D. Given a single in-the-wild image as input, we first generate four orthographic multi-view images from a multi-view diffusion model. Then, we progressively improve the resolution of generated multi-views through a multi-level upscale process. Given generated color images, we train a normal diffusion model to generate normal maps corresponding to multi-view images and utilize a similar strategy to lift it to high-resolution space. Finally, we reconstruct high-quality 3D meshes from high-resolution color images and normal maps with our instant and consistent mesh reconstruction algorithm ISOMER.", "description": "This figure illustrates the pipeline of the Unique3D framework. It starts with a single image as input, generates multi-view images and normal maps using diffusion models, enhances the resolution through multi-level upscaling, and finally reconstructs a high-quality 3D mesh using the ISOMER algorithm.", "section": "3 Method"}, {"figure_path": "UO7Mvch1Z5/figures/figures_17_1.jpg", "caption": "Figure 10: Correlation between prediction value and prediction errors.", "description": "This figure displays the correlation between the cosine of angles (representing the angle between the predicted normal and the ground truth normal) and the direction error of the prediction.  A negative correlation is observed, indicated by the red line of best fit, suggesting that as the cosine of the angle increases (angle decreases and the predicted normal is closer to the ground truth normal), the direction error decreases. The marginal distributions (histograms) on the top and right side show the distribution of the cosine of angles and direction error, respectively. The plot reveals insights into the accuracy of normal prediction, highlighting a higher accuracy for normals closer to the ground truth direction.", "section": "D ExplicitTarget algorithm"}, {"figure_path": "UO7Mvch1Z5/figures/figures_18_1.jpg", "caption": "Figure 11: Ablations on Mesh Initialization. We compare the results of using our fast initialization method, versus using a sphere as an initialization.", "description": "This figure shows an ablation study comparing the performance of the paper's proposed fast mesh initialization method against a common alternative using a sphere as initialization.  The input images are displayed on the left, followed by the results using the authors' method and then a sphere-based initialization.  Red circles highlight areas where the sphere-based initialization struggles to accurately capture the shape of the object. The comparison demonstrates that while a sphere initialization can sometimes produce reasonable results, the proposed method generally produces superior results.", "section": "F Ablation Study on Mesh Initialization"}]