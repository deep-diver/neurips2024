{"references": [{"fullname_first_author": "Tim Brooks", "paper_title": "InstructPix2Pix: Learning to Follow Image Editing Instructions", "publication_date": "2023-00-00", "reason": "This paper introduces a method for image editing based on instructions, which is highly relevant to the task of controlled image generation in the target paper."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion Models Beat GANs on Image Synthesis", "publication_date": "2021-00-00", "reason": "This is foundational work for diffusion models and provides a strong baseline that the current paper builds upon and improves."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-Resolution Image Synthesis with Latent Diffusion Models", "publication_date": "2022-00-00", "reason": "This paper presents a significant advancement in diffusion models, enabling high-resolution image generation, which is directly relevant to the high-quality image synthesis goal of the target paper."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Classifier-Free Diffusion Guidance", "publication_date": "2022-00-00", "reason": "This paper introduces a technique for classifier-free guidance in diffusion models, which is directly adopted and extended in the target paper for controllable generation."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning Transferable Visual Models From Natural Language Supervision", "publication_date": "2021-00-00", "reason": "CLIP is a fundamental vision-language model used in the target paper for both image and text encoding, making this paper a crucial foundation for the work."}]}