[{"figure_path": "b1XPHC7MQB/tables/tables_5_1.jpg", "caption": "Table 1: FID-5k for SD1.5 starting from the noise latents obtained using different encoding strategies, and NLL for these latents. Though encoding with dynamic CFG produces consistently more plausible latents than constant CFG, the unguided encoding remains preferable.", "description": "This table presents the Fr\u00e9chet Inception Distance (FID) scores and negative log-likelihood (NLL) values for Stable Diffusion 1.5 (SD1.5) noise latents generated using different encoding strategies.  The strategies compared include no classifier-free guidance (CFG), dynamic CFG with thresholds of 0.6 and 0.8, and constant CFG. Lower FID scores indicate better image quality, while lower NLL indicates that the generated latents are closer to the true data distribution. The results show that while dynamic CFG produces more realistic latents compared to constant CFG, the best performance is still achieved with no CFG during the encoding phase.", "section": "4 Experiments"}, {"figure_path": "b1XPHC7MQB/tables/tables_7_1.jpg", "caption": "Table 2: Exploration of iCD-SD1.5 configurations in terms of image inversion performance.", "description": "This table presents a comprehensive evaluation of different configurations of the Invertible Consistency Distillation (iCD) framework, specifically using the Stable Diffusion 1.5 model (iCD-SD1.5), for image inversion.  It compares various settings, including the number of forward and reverse consistency model steps (2, 3, or 4), the inclusion of preservation losses (Lf and Lr), and the use of dynamic classifier-free guidance (d.CFG). The performance is assessed using three metrics: LPIPS, DinoV2, and PSNR, to quantify the quality of the inverted images. Both unguided (w=1) and guided (w=8) decoding settings are explored, providing a complete picture of iCD's performance under different conditions.", "section": "4.1 Inversion quality of iCD"}, {"figure_path": "b1XPHC7MQB/tables/tables_9_1.jpg", "caption": "Table 3: Automatic metrics (top) and human evaluation (bottom) for iCD-XL and ReNoise [25].", "description": "This table presents a quantitative and qualitative comparison of the proposed iCD-XL model against the ReNoise baseline for text-guided image editing.  The automatic metrics section includes CLIP score (for target prompt alignment), DinoV2 (for reference image preservation), and CLIP score (for overall editing quality). The human preference section shows the percentage of human evaluators who preferred each method's results for both COCO and PieBench datasets.  The results demonstrate that iCD-XL achieves competitive performance compared to ReNoise, often with higher human preference, especially on the COCO benchmark.", "section": "4.2.2 Text-guided image editing with iCD-XL"}, {"figure_path": "b1XPHC7MQB/tables/tables_15_1.jpg", "caption": "Table 4: Text-to-image performance of the SD1.5 model in terms of FID-5K, CLIP score and ImageReward for w = 8 using 5K prompts from the MS-COCO dataset.", "description": "This table shows the FID, CLIP score and ImageReward of different configurations of the SD1.5 model for text-to-image generation.  It compares the performance of the original DDIM model against different variations of Consistency Distillation (CD) models with and without dynamic Classifier-Free Guidance (d.CFG). The different configurations allow for the analysis of the influence of the number of steps and d.CFG in image generation.", "section": "4.2.1 Text-guided image editing with iCD-SD1.5"}, {"figure_path": "b1XPHC7MQB/tables/tables_16_1.jpg", "caption": "Table 2: Exploration of iCD-SD1.5 configurations in terms of image inversion performance.", "description": "This table presents a comprehensive evaluation of different configurations of the Invertible Consistency Distillation (iCD) framework applied to the Stable Diffusion 1.5 model for image inversion.  It compares various settings, including the number of forward and reverse consistency models (fCDm and CDm), the inclusion of preservation losses (Lf and Lr), and the use of dynamic classifier-free guidance (d.CFG).  The performance is measured using three metrics: LPIPS (lower is better), DinoV2 (higher is better), and PSNR (higher is better).  The table is divided into two sections, one for unguided decoding (w = 1) and one for guided decoding (w = 8), allowing for a comparison of inversion quality under different guidance strategies.", "section": "4.1 Inversion quality of iCD"}, {"figure_path": "b1XPHC7MQB/tables/tables_16_2.jpg", "caption": "Table 6: The time required to invert a single image for different approaches.", "description": "This table presents the time taken to perform image inversion using different methods.  The methods include the proposed method (Ours, 8 steps) for both Stable Diffusion 1.5 (SD1.5) and SDXL models, along with baseline methods such as Null-text Inversion (NTI), Negative-prompt Inversion (NPI), and ReNoise LCM-XL.  The time is measured in seconds, and the values represent the mean \u00b1 standard deviation.", "section": "4.1 Inversion quality of iCD"}]