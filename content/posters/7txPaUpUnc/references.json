{"references": [{"fullname_first_author": "Nelson Elhage", "paper_title": "Toy models of superposition", "publication_date": "2022-XX-XX", "reason": "This paper introduced the concept of superposition in neural networks, which is a central problem addressed by this paper's proposed method."}, {"fullname_first_author": "Hoagy Cunningham", "paper_title": "Sparse autoencoders find highly interpretable features in language models", "publication_date": "2023-09-08", "reason": "This paper is a key antecedent, applying sparse autoencoders to language models to find interpretable features, a method extended upon in this work."}, {"fullname_first_author": "Trenton Bricken", "paper_title": "Towards monosemanticity: Decomposing language models with dictionary learning", "publication_date": "2023-XX-XX", "reason": "This paper discusses the problem of feature splitting, a phenomenon analyzed in this work to compare against the proposed method."}, {"fullname_first_author": "Samuel Marks", "paper_title": "Sparse feature circuits: Discovering and editing interpretable causal graphs in language models", "publication_date": "2024-03-19", "reason": "This paper uses causal mediation analysis on sparse autoencoder features, providing a comparison method for evaluating the proposed method's results."}, {"fullname_first_author": "Benjamin Wright", "paper_title": "Addressing feature suppression in SAEs", "publication_date": "2024-02-XX", "reason": "This paper addresses feature suppression in sparse autoencoders, a problem relevant to this paper's discussion of reconstruction error and the effects of sparsity."}]}