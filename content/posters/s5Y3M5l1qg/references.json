{"references": [{"fullname_first_author": "Ian Goodfellow", "paper_title": "Explaining and Harnessing Adversarial Examples", "publication_date": "2015-01-01", "reason": "This paper is foundational to the field of adversarial machine learning, introducing the concept and many of the key techniques."}, {"fullname_first_author": "Aleksander Madry", "paper_title": "Towards Deep Learning Models Resistant to Adversarial Attacks", "publication_date": "2018-01-01", "reason": "This paper significantly advanced the state-of-the-art in adversarial defense by introducing the PGD attack and a strong defense mechanism based on adversarial training."}, {"fullname_first_author": "Francesco Croce", "paper_title": "Reliable Evaluation of Adversarial Robustness with an Ensemble of Diverse Parameter-free Attacks", "publication_date": "2020-01-01", "reason": "This paper introduced a more robust and comprehensive benchmark for evaluating the robustness of models against adversarial attacks."}, {"fullname_first_author": "Sven Gowal", "paper_title": "Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples", "publication_date": "2020-01-01", "reason": "This paper highlighted the limitations of adversarial training, providing insights into why it's sometimes difficult to achieve sufficiently high robustness levels."}, {"fullname_first_author": "Guang Lin", "paper_title": "Robust Diffusion Models for Adversarial Purification", "publication_date": "2024-01-01", "reason": "This paper introduced a state-of-the-art defense mechanism based on diffusion models, demonstrating a significant improvement in adversarial robustness."}]}