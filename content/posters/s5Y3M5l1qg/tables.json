[{"figure_path": "s5Y3M5l1qg/tables/tables_7_1.jpg", "caption": "Table 2: Clean (results in italic) and adversarial (results in upright) accuracy for the different models and datasets used in the respective scenarios. The following abbreviations are used: Scen: scenario considered; AT/C1: clean accuracy for the adversarially-pretrained model used as the classifier, when considered alone; C/C1: clean accuracy for the CARSO architecture; AT/AA: robust accuracy (by the means of AUTOATTACK) for the adversarially-pretrained model used as the classifier, when considered alone; C/randAA: robust accuracy for the CARSO architecture, when attacked end-to-end by AUTOATTACK for randomised defences; Best AT/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial training alone (any model); Best P/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial purification (any model). Robust accuracies in round brackets are obtained using the PGD+EOT [38] pipeline, developed for diffusion-based purifiers. The best clean and robust accuracies per dataset are shown in bold. The clean accuracies for the models referred to in the Best columns are shown in Table 15 (in Appendix F).", "description": "This table presents a comparison of clean and adversarial accuracy for different models and datasets across three scenarios.  It shows the performance of adversarially-trained models alone (AT/C1, AT/AA), the CARSO architecture (C/C1, C/randAA), and the best-performing models using adversarial training or purification methods.  The table uses several abbreviations to denote specific metrics and model types, and highlights the best results for each dataset.", "section": "5.2 Results and discussion"}, {"figure_path": "s5Y3M5l1qg/tables/tables_7_2.jpg", "caption": "Table 2: Clean (results in italic) and adversarial (results in upright) accuracy for the different models and datasets used in the respective scenarios. The following abbreviations are used: Scen: scenario considered; AT/C1: clean accuracy for the adversarially-pretrained model used as the classifier, when considered alone; C/C1: clean accuracy for the CARSO architecture; AT/AA: robust accuracy (by the means of AUTOATTACK) for the adversarially-pretrained model used as the classifier, when considered alone; C/randAA: robust accuracy for the CARSO architecture, when attacked end-to-end by AUTOATTACK for randomised defences; Best AT/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial training alone (any model); Best P/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial purification (any model). Robust accuracies in round brackets are obtained using the PGD+EOT [38] pipeline, developed for diffusion-based purifiers. The best clean and robust accuracies per dataset are shown in bold. The clean accuracies for the models referred to in the Best columns are shown in Table 15 (in Appendix F).", "description": "This table presents a comparison of clean and robust accuracies for different models and datasets across three scenarios.  It shows the performance of adversarially-trained models alone (AT/C1, AT/AA), the CARSO architecture (C/C1, C/randAA), and the best-performing models using adversarial training and purification methods (Best AT/AA, Best P/AA). Robust accuracy is measured using AUTOATTACK, and results in parentheses represent those obtained using a PGD+EOT pipeline for diffusion-based models.", "section": "5.2 Results and discussion"}, {"figure_path": "s5Y3M5l1qg/tables/tables_8_1.jpg", "caption": "Table 2: Clean (results in italic) and adversarial (results in upright) accuracy for the different models and datasets used in the respective scenarios. The following abbreviations are used: Scen: scenario considered; AT/C1: clean accuracy for the adversarially-pretrained model used as the classifier, when considered alone; C/C1: clean accuracy for the CARSO architecture; AT/AA: robust accuracy (by the means of AUTOATTACK) for the adversarially-pretrained model used as the classifier, when considered alone; C/randAA: robust accuracy for the CARSO architecture, when attacked end-to-end by AUTOATTACK for randomised defences; Best AT/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial training alone (any model); Best P/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial purification (any model). Robust accuracies in round brackets are obtained using the PGD+EOT [38] pipeline, developed for diffusion-based purifiers. The best clean and robust accuracies per dataset are shown in bold. The clean accuracies for the models referred to in the Best columns are shown in Table 15 (in Appendix F).", "description": "This table presents a comparison of clean and robust accuracies for different models and datasets across three scenarios.  It compares the performance of adversarially trained models alone (AT/C1, AT/AA), the CARSO architecture (C/C1, C/randAA), and the best-performing models using adversarial training and purification techniques (Best AT/AA, Best P/AA).  Robust accuracy is measured using AUTOATTACK, with results in parentheses indicating the use of a PGD+EOT pipeline for diffusion-based methods.  The table highlights the best clean and robust accuracies for each dataset.", "section": "5.2 Results and discussion"}, {"figure_path": "s5Y3M5l1qg/tables/tables_15_1.jpg", "caption": "Table 2: Clean (results in italic) and adversarial (results in upright) accuracy for the different models and datasets used in the respective scenarios. The following abbreviations are used: Scen: scenario considered; AT/C1: clean accuracy for the adversarially-pretrained model used as the classifier, when considered alone; C/C1: clean accuracy for the CARSO architecture; AT/AA: robust accuracy (by the means of AUTOATTACK) for the adversarially-pretrained model used as the classifier, when considered alone; C/randAA: robust accuracy for the CARSO architecture, when attacked end-to-end by AUTOATTACK for randomised defences; Best AT/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial training alone (any model); Best P/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial purification (any model). Robust accuracies in round brackets are obtained using the PGD+EOT [38] pipeline, developed for diffusion-based purifiers. The best clean and robust accuracies per dataset are shown in bold. The clean accuracies for the models referred to in the Best columns are shown in Table 15 (in Appendix F).", "description": "This table presents a comparison of clean and adversarial accuracy for different models and datasets across three scenarios.  It compares the performance of a standard adversarially trained classifier against the CARSO architecture under various attacks (AUTOATTACK). The table also shows the best results achieved using only adversarial training or purification methods for reference.  Robust accuracy results in parentheses indicate the results obtained using a different evaluation pipeline, PGD+EOT, for better comparison with existing diffusion-based purification approaches.", "section": "5.2 Results and discussion"}, {"figure_path": "s5Y3M5l1qg/tables/tables_16_1.jpg", "caption": "Table 2: Clean (results in italic) and adversarial (results in upright) accuracy for the different models and datasets used in the respective scenarios. The following abbreviations are used: Scen: scenario considered; AT/C1: clean accuracy for the adversarially-pretrained model used as the classifier, when considered alone; C/C1: clean accuracy for the CARSO architecture; AT/AA: robust accuracy (by the means of AUTOATTACK) for the adversarially-pretrained model used as the classifier, when considered alone; C/randAA: robust accuracy for the CARSO architecture, when attacked end-to-end by AUTOATTACK for randomised defences; Best AT/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial training alone (any model); Best P/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial purification (any model). Robust accuracies in round brackets are obtained using the PGD+EOT [38] pipeline, developed for diffusion-based purifiers. The best clean and robust accuracies per dataset are shown in bold. The clean accuracies for the models referred to in the Best columns are shown in Table 15 (in Appendix F).", "description": "This table compares the clean and robust accuracy of different models across three scenarios (datasets).  It shows the performance of the adversarially-trained classifier alone, the CARSO architecture, and the state-of-the-art models.  Robust accuracy is measured using AUTOATTACK, with a version for stochastic defenses used for CARSO.  Abbreviations clarify the meaning of each column.", "section": "5.2 Results and discussion"}, {"figure_path": "s5Y3M5l1qg/tables/tables_16_2.jpg", "caption": "Table 2: Clean (results in italic) and adversarial (results in upright) accuracy for the different models and datasets used in the respective scenarios. The following abbreviations are used: Scen: scenario considered; AT/C1: clean accuracy for the adversarially-pretrained model used as the classifier, when considered alone; C/C1: clean accuracy for the CARSO architecture; AT/AA: robust accuracy (by the means of AUTOATTACK) for the adversarially-pretrained model used as the classifier, when considered alone; C/randAA: robust accuracy for the CARSO architecture, when attacked end-to-end by AUTOATTACK for randomised defences; Best AT/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial training alone (any model); Best P/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial purification (any model). Robust accuracies in round brackets are obtained using the PGD+EOT [38] pipeline, developed for diffusion-based purifiers. The best clean and robust accuracies per dataset are shown in bold. The clean accuracies for the models referred to in the Best columns are shown in Table 15 (in Appendix F).", "description": "This table presents a comparison of clean and robust accuracy for different models and datasets across three scenarios.  It compares the performance of a standard adversarially-trained classifier (AT/C1 and AT/AA) against the proposed CARSO architecture (C/C1 and C/randAA).  It also shows the best-performing models from the literature for both adversarial training (Best AT/AA) and adversarial purification (Best P/AA) for reference.  Robust accuracy is measured using AUTOATTACK, with results in parentheses representing the PGD+EOT pipeline.", "section": "5.2 Results and discussion"}, {"figure_path": "s5Y3M5l1qg/tables/tables_17_1.jpg", "caption": "Table 2: Clean (results in italic) and adversarial (results in upright) accuracy for the different models and datasets used in the respective scenarios. The following abbreviations are used: Scen: scenario considered; AT/C1: clean accuracy for the adversarially-pretrained model used as the classifier, when considered alone; C/C1: clean accuracy for the CARSO architecture; AT/AA: robust accuracy (by the means of AUTOATTACK) for the adversarially-pretrained model used as the classifier, when considered alone; C/randAA: robust accuracy for the CARSO architecture, when attacked end-to-end by AUTOATTACK for randomised defences; Best AT/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial training alone (any model); Best P/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial purification (any model). Robust accuracies in round brackets are obtained using the PGD+EOT [38] pipeline, developed for diffusion-based purifiers. The best clean and robust accuracies per dataset are shown in bold. The clean accuracies for the models referred to in the Best columns are shown in Table 15 (in Appendix F).", "description": "This table presents a comparison of the clean and adversarial accuracy for different models and datasets across three scenarios.  It shows the performance of the adversarially-trained classifier alone (AT/C1 and AT/AA), the CARSO architecture (C/C1 and C/randAA), and the best-performing models from the literature (Best AT/AA and Best P/AA).  The table also uses abbreviations to define the different metrics. Robust accuracy is assessed using both AUTOATTACK and the PGD+EOT pipeline.", "section": "5.2 Results and discussion"}, {"figure_path": "s5Y3M5l1qg/tables/tables_17_2.jpg", "caption": "Table 2: Clean (results in italic) and adversarial (results in upright) accuracy for the different models and datasets used in the respective scenarios. The following abbreviations are used: Scen: scenario considered; AT/C1: clean accuracy for the adversarially-pretrained model used as the classifier, when considered alone; C/C1: clean accuracy for the CARSO architecture; AT/AA: robust accuracy (by the means of AUTOATTACK) for the adversarially-pretrained model used as the classifier, when considered alone; C/randAA: robust accuracy for the CARSO architecture, when attacked end-to-end by AUTOATTACK for randomised defences; Best AT/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial training alone (any model); Best P/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial purification (any model). Robust accuracies in round brackets are obtained using the PGD+EOT [38] pipeline, developed for diffusion-based purifiers. The best clean and robust accuracies per dataset are shown in bold. The clean accuracies for the models referred to in the Best columns are shown in Table 15 (in Appendix F).", "description": "This table presents a comparison of clean and robust accuracies for different models and datasets across three scenarios.  It shows the performance of adversarially-trained classifiers alone, the CARSO architecture, and the best-performing models from adversarial training and purification literature.  Robust accuracy is measured using AUTOATTACK, with results for stochastic defenses shown separately.  Best-performing models' clean accuracies are detailed in a separate table (Table 15).", "section": "5.2 Results and discussion"}, {"figure_path": "s5Y3M5l1qg/tables/tables_17_3.jpg", "caption": "Table 2: Clean (results in italic) and adversarial (results in upright) accuracy for the different models and datasets used in the respective scenarios. The following abbreviations are used: Scen: scenario considered; AT/C1: clean accuracy for the adversarially-pretrained model used as the classifier, when considered alone; C/C1: clean accuracy for the CARSO architecture; AT/AA: robust accuracy (by the means of AUTOATTACK) for the adversarially-pretrained model used as the classifier, when considered alone; C/randAA: robust accuracy for the CARSO architecture, when attacked end-to-end by AUTOATTACK for randomised defences; Best AT/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial training alone (any model); Best P/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial purification (any model). Robust accuracies in round brackets are obtained using the PGD+EOT [38] pipeline, developed for diffusion-based purifiers. The best clean and robust accuracies per dataset are shown in bold. The clean accuracies for the models referred to in the Best columns are shown in Table 15 (in Appendix F).", "description": "This table presents a comparison of clean and adversarial accuracy for different models and datasets across three scenarios.  It compares the performance of a standard adversarially trained model, the CARSO architecture, and the state-of-the-art models for both adversarial training and purification.  The table uses abbreviations to represent various accuracy metrics and highlights the best results for each dataset.", "section": "5.2 Results and discussion"}, {"figure_path": "s5Y3M5l1qg/tables/tables_18_1.jpg", "caption": "Table 2: Clean (results in italic) and adversarial (results in upright) accuracy for the different models and datasets used in the respective scenarios. The following abbreviations are used: Scen: scenario considered; AT/C1: clean accuracy for the adversarially-pretrained model used as the classifier, when considered alone; C/C1: clean accuracy for the CARSO architecture; AT/AA: robust accuracy (by the means of AUTOATTACK) for the adversarially-pretrained model used as the classifier, when considered alone; C/randAA: robust accuracy for the CARSO architecture, when attacked end-to-end by AUTOATTACK for randomised defences; Best AT/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial training alone (any model); Best P/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial purification (any model). Robust accuracies in round brackets are obtained using the PGD+EOT [38] pipeline, developed for diffusion-based purifiers. The best clean and robust accuracies per dataset are shown in bold. The clean accuracies for the models referred to in the Best columns are shown in Table 15 (in Appendix F).", "description": "This table presents a comparison of the clean and robust accuracy for different models and datasets across three scenarios.  It compares the performance of the adversarially-trained classifier alone (AT/C1, AT/AA), the CARSO architecture (C/C1, C/randAA), and the best results reported in literature using adversarial training (Best AT/AA) and purification (Best P/AA) methods.  Robust accuracy is assessed via AUTOATTACK, and values in parentheses indicate results obtained using the PGD+EOT pipeline for diffusion-based models.", "section": "5.2 Results and discussion"}, {"figure_path": "s5Y3M5l1qg/tables/tables_18_2.jpg", "caption": "Table 2: Clean (results in italic) and adversarial (results in upright) accuracy for the different models and datasets used in the respective scenarios. The following abbreviations are used: Scen: scenario considered; AT/C1: clean accuracy for the adversarially-pretrained model used as the classifier, when considered alone; C/C1: clean accuracy for the CARSO architecture; AT/AA: robust accuracy (by the means of AUTOATTACK) for the adversarially-pretrained model used as the classifier, when considered alone; C/randAA: robust accuracy for the CARSO architecture, when attacked end-to-end by AUTOATTACK for randomised defences; Best AT/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial training alone (any model); Best P/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial purification (any model). Robust accuracies in round brackets are obtained using the PGD+EOT [38] pipeline, developed for diffusion-based purifiers. The best clean and robust accuracies per dataset are shown in bold. The clean accuracies for the models referred to in the Best columns are shown in Table 15 (in Appendix F).", "description": "This table presents a comparison of clean and robust accuracy for different models and datasets across three scenarios. It compares the performance of adversarially-trained models alone, the CARSO architecture, and the state-of-the-art models for both adversarial training and purification.  Robust accuracy is measured using AUTOATTACK, with a version (randAA) adapted for stochastic defenses like CARSO.  It highlights the trade-off between clean accuracy and robust accuracy.", "section": "5.2 Results and discussion"}, {"figure_path": "s5Y3M5l1qg/tables/tables_19_1.jpg", "caption": "Table 12: Hyperparameters for the attacks used for training and testing the purifier The FGSM and PDG attacks refer to the training phase (see subsection 4.4), whereas the PGD+EOT attack [38] refers to the robustness assessment pipeline. The entry CCE denotes the Categorical CrossEntropy loss function. The l\u221e threat model is assumed, and all inputs are linearly rescaled within [0.0, 1.0] before the attack.", "description": "This table lists the hyperparameters used for the three different attacks (FGSM, PGD, and PGD+EOT) during the training and testing phases of the purifier.  It specifies the input clipping range, number of steps, step size, loss function, number of Expectation over Transformation (EOT) iterations (for PGD+EOT only), and the optimizer used.  The table clarifies that the attacks are used for training the purifier (FGSM and PGD) and for robustness assessment (PGD+EOT).  The l\u221e threat model is used, and inputs are linearly rescaled for consistency.", "section": "5.1 Setup"}, {"figure_path": "s5Y3M5l1qg/tables/tables_19_2.jpg", "caption": "Table 2: Clean (results in italic) and adversarial (results in upright) accuracy for the different models and datasets used in the respective scenarios. The following abbreviations are used: Scen: scenario considered; AT/C1: clean accuracy for the adversarially-pretrained model used as the classifier, when considered alone; C/C1: clean accuracy for the CARSO architecture; AT/AA: robust accuracy (by the means of AUTOATTACK) for the adversarially-pretrained model used as the classifier, when considered alone; C/randAA: robust accuracy for the CARSO architecture, when attacked end-to-end by AUTOATTACK for randomised defences; Best AT/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial training alone (any model); Best P/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial purification (any model). Robust accuracies in round brackets are obtained using the PGD+EOT [38] pipeline, developed for diffusion-based purifiers. The best clean and robust accuracies per dataset are shown in bold. The clean accuracies for the models referred to in the Best columns are shown in Table 15 (in Appendix F).", "description": "This table presents a comparison of clean and adversarial accuracy for different models and datasets across three scenarios.  It shows the performance of the adversarially-trained classifier alone, the CARSO architecture, and the best-performing models from existing literature using adversarial training and purification methods.  Robust accuracy is evaluated using AUTOATTACK, with results for standard and randomized defense variations given.  Abbreviations are provided for clarity.", "section": "5.2 Results and discussion"}, {"figure_path": "s5Y3M5l1qg/tables/tables_19_3.jpg", "caption": "Table 2: Clean (results in italic) and adversarial (results in upright) accuracy for the different models and datasets used in the respective scenarios. The following abbreviations are used: Scen: scenario considered; AT/C1: clean accuracy for the adversarially-pretrained model used as the classifier, when considered alone; C/C1: clean accuracy for the CARSO architecture; AT/AA: robust accuracy (by the means of AUTOATTACK) for the adversarially-pretrained model used as the classifier, when considered alone; C/randAA: robust accuracy for the CARSO architecture, when attacked end-to-end by AUTOATTACK for randomised defences; Best AT/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial training alone (any model); Best P/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial purification (any model). Robust accuracies in round brackets are obtained using the PGD+EOT [38] pipeline, developed for diffusion-based purifiers. The best clean and robust accuracies per dataset are shown in bold. The clean accuracies for the models referred to in the Best columns are shown in Table 15 (in Appendix F).", "description": "This table presents a comparison of clean and adversarial accuracies for different models and datasets across three scenarios.  It shows the performance of the adversarially-trained classifier alone (AT/C1 and AT/AA), the CARSO architecture (C/C1 and C/randAA), and the best results achieved by adversarial training and purification methods from other works (Best AT/AA and Best P/AA). The table also highlights the best clean and robust accuracies for each dataset.  Parenthesized values represent results obtained using a specific pipeline (PGD+EOT) for diffusion-based purifiers.", "section": "5.2 Results and discussion"}, {"figure_path": "s5Y3M5l1qg/tables/tables_20_1.jpg", "caption": "Table 2: Clean (results in italic) and adversarial (results in upright) accuracy for the different models and datasets used in the respective scenarios. The following abbreviations are used: Scen: scenario considered; AT/C1: clean accuracy for the adversarially-pretrained model used as the classifier, when considered alone; C/C1: clean accuracy for the CARSO architecture; AT/AA: robust accuracy (by the means of AUTOATTACK) for the adversarially-pretrained model used as the classifier, when considered alone; C/randAA: robust accuracy for the CARSO architecture, when attacked end-to-end by AUTOATTACK for randomised defences; Best AT/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial training alone (any model); Best P/AA: best robust accuracy result for the respective dataset (by the means of AUTOATTACK), obtained by adversarial purification (any model). Robust accuracies in round brackets are obtained using the PGD+EOT [38] pipeline, developed for diffusion-based purifiers. The best clean and robust accuracies per dataset are shown in bold. The clean accuracies for the models referred to in the Best columns are shown in Table 15 (in Appendix F).", "description": "This table presents a comparison of clean and adversarial accuracy for different models and datasets across three scenarios.  It shows the performance of adversarially-trained classifiers alone (AT/C1, AT/AA), the CARSO architecture (C/C1, C/randAA), and the best results from the literature (Best AT/AA, Best P/AA).  The table uses several abbreviations which are explained in the caption. Robust accuracy is assessed using AUTOATTACK, with results in parentheses indicating use of the PGD+EOT pipeline for diffusion-based purifiers.", "section": "5.2 Results and discussion"}]