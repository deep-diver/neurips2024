{"references": [{"fullname_first_author": "Radford", "paper_title": "Learning Transferable Visual Models From Natural Language Supervision", "publication_date": "2021-03-00", "reason": "This paper introduces CLIP, a foundational vision-language model that enables zero-shot image classification and is heavily used in the field of text-to-image generation."}, {"fullname_first_author": "Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduces Stable Diffusion, a key model architecture used in many current text-to-image generation models, and is crucial to the work in this paper."}, {"fullname_first_author": "Ramesh", "paper_title": "Zero-shot text-to-image generation", "publication_date": "2021-00-00", "reason": "This paper is among the earliest to demonstrate high-quality text-to-image generation using diffusion models, providing a baseline for subsequent advancements."}, {"fullname_first_author": "Saharia", "paper_title": "Photorealistic text-to-image diffusion models with deep language understanding", "publication_date": "2022-00-00", "reason": "This paper introduces Imagen, a model known for its high-quality image generation capabilities which is used as a comparison model for this paper."}, {"fullname_first_author": "Ho", "paper_title": "Classifier-free diffusion guidance", "publication_date": "2021-00-00", "reason": "This paper introduces a technique that improves the quality and controllability of images generated by diffusion models, a crucial aspect of the presented research."}]}