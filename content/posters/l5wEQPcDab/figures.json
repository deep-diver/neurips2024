[{"figure_path": "l5wEQPcDab/figures/figures_6_1.jpg", "caption": "Figure 1: (a) illustrates the equivalence classes [r]U and [rE]U, corresponding to the transition laws P0, P1, P from Example 3.3, for a small \u03b2, in RS\u00d7A/1. The blue lines correspond to P0, the red lines to P1, and the gray lines to P. Furthermore, the shaded areas illustrate the approximation error around [rE]Upk, as guaranteed by Lemma 3.6. (b) illustrates the uncertainty set for the recovered reward when learning from two experts, as discussed in the proof sketch of Theorem 3.10.", "description": "Figure 1(a) shows the reward equivalence classes for Example 3.3 in the quotient space RS\u00d7A/1, illustrating how the closeness of the recovered reward to the expert reward depends on the principal angles between the transition laws. Figure 1(b) illustrates Theorem 3.10's proof sketch by showing the uncertainty set for the reward recovered from two experts.", "section": "3 Transferability"}, {"figure_path": "l5wEQPcDab/figures/figures_6_2.jpg", "caption": "Figure 1: (a) illustrates the equivalence classes [r]U and [rE]U, corresponding to the transition laws P0, P1, P from Example 3.3, for a small \u03b2, in RS\u00d7A/1. The blue lines correspond to P0, the red lines to P1, and the gray lines to P. Furthermore, the shaded areas illustrate the approximation error around [rE]Upk, as guaranteed by Lemma 3.6. (b) illustrates the uncertainty set for the recovered reward when learning from two experts, as discussed in the proof sketch of Theorem 3.10.", "description": "Figure 1(a) shows the equivalence classes of rewards corresponding to the transition laws P0, P1, and P from Example 3.3 in the quotient space RS\u00d7A/1. The shaded areas show the approximation error around the true reward [rE]Upk, as proved in Lemma 3.6. Figure 1(b) shows the uncertainty set of recovered rewards when using two experts, as shown in the proof of Theorem 3.10.", "section": "3.3 Theoretical insights"}, {"figure_path": "l5wEQPcDab/figures/figures_9_1.jpg", "caption": "Figure 2: (a) shows the second principal angle between the experts, for varying wind strength \u03b2. (b) shows the distance between  r\u0302 and rE in RS\u00d7A/1 for a varying number of expert demonstrations NE and wind strength \u03b2. (c) and (d) show the transferability to PSouth and PShifted in terms of lpSouth(rE, RLpSouth(r\u0302)) and lpShifted(rE, RLpShifted(r\u0302)), respectively. The circles indicate the median and the shaded areas the 0.2 and 0.8 quantiles over 10 independent realizations of the expert data.", "description": "Figure 2 shows the results of experiments conducted to validate the transferability of rewards in a WindyGridworld environment. The plots illustrate how the second principal angle between two experts, the distance between the recovered reward and the true reward, and the transferability to different environments (with south wind and cyclically shifted actions) vary with changes in wind strength (\u03b2) and the number of expert demonstrations (NE).  The shaded regions represent the 20th and 80th percentiles across 10 independent trials, demonstrating the variability of the results.", "section": "5 Experiments"}, {"figure_path": "l5wEQPcDab/figures/figures_26_1.jpg", "caption": "Figure 3: The set of occupancy measures Mpo and Mp1 are illustrated in RS\u00d7A/1 \u2248 R\u00b9. For a two-state-two-action MDP, the set of occupancy measures is given by the intersection of a two-dimensional affine subspace (a plane in RS\u00d7A/1) with the probability simplex in R\u2074 (a tetrahedron in RS\u00d7A/1). We see that for a small \u03b2, the sets Mpo and Mp1 are approximately parallel. That is, the angle between their normal vectors, which span the potential shaping spaces Upo and Up1, is small. In contrast, for a large \u03b2 the orientation of Mpo and Mp1 is very different, resulting in a large angle between the corresponding normal vectors.", "description": "This figure shows the set of occupancy measures for two different transition laws (P\u2070 and P\u00b9), in the quotient space RS\u00d7A/1 (which is isomorphic to R\u00b9 in this case).  For a small \u03b2 (parameter controlling the difference between the transition laws), the sets of occupancy measures Mpo and Mp1 are almost parallel, indicating high similarity between the transition laws.  Conversely, as \u03b2 increases, the sets become less parallel, visually representing increasing dissimilarity between P\u2070 and P\u00b9. The caption explains that this angle between the sets' normal vectors (which are closely related to the potential shaping spaces Upo and Up1) is what really matters in determining the transferability of rewards learned via IRL.", "section": "3.3 Theoretical insights"}, {"figure_path": "l5wEQPcDab/figures/figures_34_1.jpg", "caption": "Figure 2: (a) shows the second principal angle between the experts, for varying wind strength \u03b2. (b) shows the distance between r\u0302 and rE in RS\u00d7A/1 for a varying number of expert demonstrations NE and wind strength \u03b2. (c) and (d) show the transferability to PSouth and PShifted in terms of lPSouth(rE, RLPSouth(r\u0302)) and lPShifted(rE, RLPShifted(r\u0302)), respectively. The circles indicate the median and the shaded areas the 0.2 and 0.8 quantiles over 10 independent realizations of the expert data.", "description": "Figure 2 shows the results of experiments on a WindyGridworld environment. Subfigure (a) shows how the second principal angle between two experts changes with wind strength. Subfigures (b), (c), and (d) show how reward distance and transferability to two different test environments change with the number of expert demonstrations and wind strength. The results show that increased wind strength leads to larger second principal angles, resulting in better transferability.", "section": "5 Experiments"}]