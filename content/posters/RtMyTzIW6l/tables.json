[{"figure_path": "RtMyTzIW6l/tables/tables_4_1.jpg", "caption": "Table 1: Top-m% errors (\u2193) of model f(K) and f(K) averaged over different datasets.", "description": "This table compares the Top-m% errors of two models, f(K) and f(K), trained using different empirical risks.  The Top-m% error measures the minimum distance between predictions and the nearest equivalent solutions. Lower values indicate better performance. The table shows that the symmetry-aware model, f(K), consistently achieves lower Top-m% errors across different datasets and values of m%, demonstrating its superior solution prediction accuracy.", "section": "6.1 On empirical risks and Top-m% error"}, {"figure_path": "RtMyTzIW6l/tables/tables_7_1.jpg", "caption": "Table 1: Top-m% errors (\u2193) of model f(K) and f(K) averaged over different datasets.", "description": "This table compares the Top-m% errors of the models trained using the classic empirical risk (f(K)) and the symmetry-aware empirical risk (f(K)).  Top-m% error is defined as the sum of the absolute differences between rounded prediction values and their closest equivalent solution values for the top m% of variables with the largest difference between the rounded prediction and actual values. Lower values indicate better performance. The results are averaged across four different datasets: IP, SMSP, PESP, and PESPD, each with varying levels of symmetry.  The table demonstrates that the symmetry-aware approach consistently achieves lower Top-m% errors compared to the classic approach for all m% values across all datasets, highlighting its improved performance.", "section": "6.1 On empirical risks and Top-m% error"}, {"figure_path": "RtMyTzIW6l/tables/tables_7_2.jpg", "caption": "Table 2: Time cost for minimizing different empirical risks (in seconds).", "description": "This table shows the time taken to minimize the empirical risk (r) and the symmetry-aware empirical risk (rs) for each dataset.  The column 't' represents the average time spent solving the permutation decisions per instance during the minimization of rs. It demonstrates that the proposed alternating optimization algorithm (SymILO) for updating model parameters and permutation operations is computationally efficient, with the added step of updating permutations in the rs minimization not significantly increasing the overall time.", "section": "6 Numerical results"}, {"figure_path": "RtMyTzIW6l/tables/tables_8_1.jpg", "caption": "Table 3: Average relative primal gaps (\u2193) of different downstream tasks at 800 second. The values in this table are averaged over primal gaps of all test data for each benchmark problem. \u201cTuned CPLEX\u201d is the result of the tuned CPLEX running on a single thread.", "description": "This table presents the average relative primal gaps achieved by different methods across four benchmark datasets, for three different downstream tasks: fix and optimize, local branching, and node selection.  The \"gain\" column shows the percentage improvement of SymILO over the baseline methods for each task and dataset.  Tuned CPLEX serves as a reference point representing the performance of a well-tuned commercial solver.", "section": "6.2 Downstream results"}, {"figure_path": "RtMyTzIW6l/tables/tables_15_1.jpg", "caption": "Table 4: Hyper-parameters for different down-stream tasks", "description": "This table shows the hyperparameters used for the three downstream tasks (fix and optimize, local branching, and node selection) for each dataset (IP, SMSP, PESP, PESPD).  The hyperparameters \u03b1 and \u03b2 are tuned for both the classic empirical risk (r) and the symmetry-aware empirical risk (rs) approaches.  The values indicate the optimal settings found for each configuration.", "section": "E.1 Hyper-parameter tuning"}, {"figure_path": "RtMyTzIW6l/tables/tables_15_2.jpg", "caption": "Table 1: Top-m% errors (\u2193) of model f(K) and f(K) averaged over different datasets.", "description": "This table presents the Top-m% errors for different values of m (10%, 30%, 50%, 70%, 90%) achieved by the classic model f(K) and the symmetry-aware model f(K). Lower values indicate better performance.  The results are averaged across four different datasets: IP, SMSP, PESP, and PESPD. This comparison shows how using symmetry awareness improves the prediction accuracy.", "section": "6.1 On empirical risks and Top-m% error"}, {"figure_path": "RtMyTzIW6l/tables/tables_15_3.jpg", "caption": "Table 3: Average relative primal gaps (\u2193) of different downstream tasks at 800 second. The values in this table are averaged over primal gaps of all test data for each benchmark problem. \u201cTuned CPLEX", "description": "This table presents the average relative primal gaps achieved by three different downstream tasks (fix-and-optimize, local branching, node selection) at 800 seconds of solving time. It compares the performance of SymILO against three baselines (ND, PS, MIP-GNN) and tuned CPLEX. The relative primal gap is a metric that measures the relative difference between the objective value of a feasible solution obtained and the optimal solution's objective value. Lower values indicate better performance.  The table also shows the percentage gain achieved by SymILO compared to each baseline. ", "section": "6.2 Downstream results"}]