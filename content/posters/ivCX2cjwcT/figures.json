[{"figure_path": "ivCX2cjwcT/figures/figures_3_1.jpg", "caption": "Figure 1: Scatter plots of matched distribution (1)c (left) and (2)c (right) when c follows the Gaussian distribution. Colors in the scatter plot represent alignment; same color represent the data are aligned.", "description": "This figure shows scatter plots of the shared component 'c' after applying the proposed method to two different modalities. The left plot corresponds to modality 1, and the right plot corresponds to modality 2.  The colors represent the alignment of the data points. Data points of the same color in both plots indicate they are aligned, sharing the same underlying shared component 'c'. The Gaussian distribution of 'c' ensures the data points are clustered appropriately in each plot.", "section": "3 Proposed Approach"}, {"figure_path": "ivCX2cjwcT/figures/figures_5_1.jpg", "caption": "Figure 3: Validation of Theorem 1. Top row: results under assumption (a). Bottom row: results under assumption (b).", "description": "This figure validates Theorem 1 presented in the paper, which provides sufficient conditions for identifying shared components from unaligned multimodal linear mixtures.  The theorem offers two sets of conditions (a) and (b). The top row shows results obtained using data generated under condition (a), which assumes statistically independent and non-Gaussian content components. The bottom row presents results from data generated under condition (b), which assumes the support of the content component distribution is a hyper-rectangle. In both rows, the scatter plots visualize the learned shared components (represented by color) against the data from each modality. The consistency across conditions (a) and (b) demonstrates that the model effectively identifies shared components under different distributional assumptions.", "section": "Enhanced Identifiability via Structural Constraints"}, {"figure_path": "ivCX2cjwcT/figures/figures_8_1.jpg", "caption": "Figure 4: k-NN accuracy for single-cell sequence alignment.", "description": "This figure shows the k-NN accuracy for single-cell sequence alignment using different methods and varying numbers of paired samples.  The x-axis represents the value of k in the k-NN evaluation metric, and the y-axis shows the corresponding accuracy. The plot compares the performance of the proposed method with and without weak supervision (different numbers of paired samples) against a baseline approach (CM-AE). Error bars are included to show the variation in the results.", "section": "Numerical Validation"}, {"figure_path": "ivCX2cjwcT/figures/figures_22_1.jpg", "caption": "Figure 5: Validation of Theorem 3: dc = 3 and dp = 1.", "description": "This figure shows the results of a numerical validation for Theorem 3.  The experiment varies the number of aligned cross-domain samples (anchors) used in the unaligned shared component analysis (SCA) problem. The top row displays the 2D t-SNE visualization of the shared component c obtained under different conditions: ground truth, no anchors, 1 anchor, and 3 anchors.  The bottom rows show the corresponding 2D t-SNE visualizations of the private components p(1) and p(2) for each modality. The black crosses in the plots mark the centroids of each cluster. The results demonstrate that the proposed method effectively identifies the shared component when enough aligned samples are available, which is consistent with Theorem 3.", "section": "Enhanced Identifiability via Structural Constraints"}, {"figure_path": "ivCX2cjwcT/figures/figures_24_1.jpg", "caption": "Figure 6: Office-31 dataset: DSLR images features represented as circle markers, Amazon images features represented as triangle markers. Different color represent different classes.", "description": "This figure visualizes the results of applying t-SNE to reduce the dimensionality of features extracted from the Office-31 dataset using CLIP and the proposed method.  The left panel shows the original CLIP features (768 dimensions), demonstrating some clustering by class but significant overlap. The right panel shows the lower-dimensional (256 dimensions) features produced by the proposed method. The improved separation of classes in the right panel illustrates the effectiveness of the proposed method in enhancing the discriminability of the data.", "section": "G.1 Domain Adaptation"}, {"figure_path": "ivCX2cjwcT/figures/figures_28_1.jpg", "caption": "Figure 3: Validation of Theorem 1. Top row: results under assumption (a). Bottom row: results under assumption (b).", "description": "This figure validates Theorem 1 presented in the paper, which provides conditions for identifying shared components from unaligned multimodal linear mixtures.  The top row shows results obtained under assumption (a) of the theorem, where the individual elements of the shared components are statistically independent and non-Gaussian. The bottom row displays results under assumption (b), where the shared components follow a hyper-rectangular distribution. Each plot visually represents the learned shared components against the true shared components, demonstrating that the proposed method accurately recovers the shared components under the specified conditions.", "section": "Enhanced Identifiability via Structural Constraints"}]