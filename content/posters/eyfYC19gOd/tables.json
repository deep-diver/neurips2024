[{"figure_path": "eyfYC19gOd/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative comparisons on the synthetic D-NeRF [31] dataset. The higher PSNR (\u2191), higher SSIM (\u2191) and lower LPIPS (\u2193) denote better rendering quality. The color of each cell shows the best and the second best.", "description": "This table presents a quantitative comparison of the proposed Grid4D model against several state-of-the-art methods on the synthetic D-NeRF dataset.  The metrics used for evaluation are PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity Index), and LPIPS (Learned Perceptual Image Patch Similarity). Higher PSNR and SSIM values, along with lower LPIPS values, indicate better rendering quality.  The table highlights the best and second-best performing methods for each scene.", "section": "4.2 Comparisons"}, {"figure_path": "eyfYC19gOd/tables/tables_7_2.jpg", "caption": "Table 2: Quantitative comparison on the validation rig part (Rig) and the interpolation part (Interpolation) of the real-world HyperNeRF [28] dataset. The higher PSNR (\u2191) and higher MS-SSIM (\u2191) denote better rendering quality. The color of each cell shows the best and the second best.", "description": "This table presents a quantitative comparison of the proposed Grid4D model against two baseline models, TiNeuVox and 4D-GS, on the HyperNeRF dataset. The evaluation metrics used are PSNR and MS-SSIM, which measure peak signal-to-noise ratio and multi-scale structural similarity index, respectively.  The dataset is split into two parts: 'Rig' (4 scenes) and 'Interpolation' (6 scenes).  Higher scores for PSNR and MS-SSIM indicate better rendering quality.  The table highlights the best and second-best performance for each metric and scene category.", "section": "4.2 Comparisons"}, {"figure_path": "eyfYC19gOd/tables/tables_8_1.jpg", "caption": "Table 3: Quantitative comparison on the real-world Neu3D [16] dataset. The higher PSNR (\u2191) and higher SSIM (\u2191) denote better rendering quality. The color of each cell shows the best.", "description": "This table presents a quantitative comparison of the Grid4D model and the 4D-GS model on the Neu3D dataset.  The evaluation metrics used are PSNR and SSIM, which measure peak signal-to-noise ratio and structural similarity, respectively. Higher values for both metrics indicate better visual quality. The table is organized to show the results for each scene in the dataset (Coffee Martini, Cook Spinach, Cut Beef, Flame Salmon, Flame Steak, Sear Steak).  The best performing model for each metric in each scene is highlighted by color.", "section": "4.2 Comparisons"}, {"figure_path": "eyfYC19gOd/tables/tables_8_2.jpg", "caption": "Table 4: Rendering speed comparison on the synthetic D-NeRF [31] dataset. We report the FPS based on the number of Gaussian points. Compared to other models, our model still achieves high rendering speed and real-time rendering when facing a much larger amount of Gaussians.", "description": "This table compares the rendering speed (FPS) of Grid4D against other state-of-the-art models on the synthetic D-NeRF dataset. The number of Gaussian points used in each model is also provided to allow for a fairer comparison, as different models use different numbers of Gaussians. Grid4D demonstrates high rendering speed, maintaining real-time performance even with a large number of Gaussians.", "section": "4.2 Comparisons"}, {"figure_path": "eyfYC19gOd/tables/tables_14_1.jpg", "caption": "Table 2: Quantitative comparison on the validation rig part (Rig) and the interpolation part (Interpolation) of the real-world HyperNeRF [28] dataset. The higher PSNR (\u2191) and higher MS-SSIM (\u2191) denote better rendering quality. The color of each cell shows the best and the second best.", "description": "This table presents a quantitative comparison of the visual quality of different models on the HyperNeRF dataset, broken down into two parts: the validation rig and the interpolation. The metrics used are PSNR and MS-SSIM, both higher values indicate better quality.  The table highlights the best and second-best performing models for each scene.", "section": "4.2 Comparisons"}, {"figure_path": "eyfYC19gOd/tables/tables_14_2.jpg", "caption": "Table 7: Additional ablation results of model architecture on the synthetic D-NeRF [31] dataset. The color of each cell shows the best and the second best.", "description": "This table presents ablation study results on the model architecture, specifically focusing on the impact of different configurations of the 4D decomposed hash encoder.  It compares the performance using various depths and levels within the encoder, as well as a variant without rotation and translation (w/o RT). The PSNR metric is used to evaluate the rendering quality.", "section": "4.3 Ablation Study and Analysis"}, {"figure_path": "eyfYC19gOd/tables/tables_14_3.jpg", "caption": "Table 8: Comparison of average training computational cost on the D-NeRF [31] dataset with a single RTX 3090 GPU.", "description": "This table compares the training computational cost of four different dynamic scene rendering models: 4D-GS, DeformGS, SC-GS, and Grid4D.  The comparison includes training time, GPU memory usage, and the resulting PSNR (Peak Signal-to-Noise Ratio) value.  Grid4D demonstrates a balance between training time and memory consumption compared to other models, while achieving a high PSNR.", "section": "4.2 Comparisons"}]