[{"figure_path": "1FikBPewU9/tables/tables_7_1.jpg", "caption": "Table 1: The Quantitative point cloud evaluation results on DTU evaluation set. The lower the Accuracy (Acc), Completeness (Comp), Overall, the better. We split methods into four categories and highlight the best in bold for each.", "description": "This table presents a quantitative comparison of point cloud evaluation results on the DTU evaluation dataset for various multi-view stereo methods.  The metrics used are Accuracy (Acc), Completeness (Comp), and Overall, where lower values indicate better performance. The methods are categorized into four groups for easier comparison, and the best-performing method within each group is highlighted in bold.", "section": "4.3 Experimental Performance"}, {"figure_path": "1FikBPewU9/tables/tables_8_1.jpg", "caption": "Table 2: The Quantitative point cloud evaluation results on Tanks and Temples benchmark. The metric is F-score and \"Mean\" refers to the average F-score of all scenes (higher is better). We split methods into four categories and highlight the best in bold for each.", "description": "This table presents a quantitative comparison of different multi-view stereo (MVS) methods on the Tanks and Temples benchmark dataset.  The performance metric used is the F-score, representing a balance between accuracy and completeness of the 3D point cloud reconstruction. The table is organized to show the average F-score across all scenes, as well as a breakdown of scores for each individual scene.  Methods are categorized into groups to facilitate comparison based on their approaches.  The best performing method within each category is highlighted in bold.", "section": "4.3 Experimental Performance"}, {"figure_path": "1FikBPewU9/tables/tables_8_2.jpg", "caption": "Table 3: Quantitative evaluation of the effectiveness of each component of the model was conducted on the DTU dataset. The lower the Accuracy (Acc), Completeness (Comp), Overall, the better.", "description": "This table presents the ablation study results on the DTU dataset, showing the impact of different components of the proposed multi-view stereo method on accuracy, completeness, and overall performance.  Each row represents a configuration with a specific combination of pose embedding, uncertainty estimation, and disparity hidden states enabled or disabled, allowing for a comparison of their individual contributions to the final results.", "section": "4.4 Ablation Study"}, {"figure_path": "1FikBPewU9/tables/tables_9_1.jpg", "caption": "Table 1: The Quantitative point cloud evaluation results on DTU evaluation set. The lower the Accuracy (Acc), Completeness (Comp), Overall, the better. We split methods into four categories and highlight the best in bold for each.", "description": "This table presents a quantitative comparison of point cloud evaluation results on the DTU dataset's evaluation set.  Three metrics are used: Accuracy (Acc), Completeness (Comp), and Overall. Lower values indicate better performance. The methods are categorized into four groups, and the best performing method in each group is highlighted.", "section": "4.3 Experimental Performance"}, {"figure_path": "1FikBPewU9/tables/tables_9_2.jpg", "caption": "Table 1: The Quantitative point cloud evaluation results on DTU evaluation set. The lower the Accuracy (Acc), Completeness (Comp), Overall, the better. We split methods into four categories and highlight the best in bold for each.", "description": "This table presents a quantitative comparison of different multi-view stereo (MVS) methods on the DTU evaluation dataset.  The metrics used are Accuracy (Acc), Completeness (Comp), and Overall, all measured in millimeters (mm). Lower values indicate better performance. The table categorizes the MVS methods into four groups (traditional, CNN-based, RNN-based, and scale-agnostic) and highlights the best-performing method within each group in bold.", "section": "4.3 Experimental Performance"}]