[{"figure_path": "8JmUmTgKiY/tables/tables_7_1.jpg", "caption": "Table 1: Squared population MMD (\u2193) between test data and samples from the methods trained on 65536 samples, averaged over five random initializations with the standard deviation calculated with Bessel's correction in the parentheses. The proposed KSGAN with k<sub>c</sub> = 1 performs on par with the WGAN-GP trained with five times the budget k<sub>c</sub> = 5. See appendix D.1 for qualitative comparison.", "description": "This table presents the results of the experiment on eight synthetic 2D datasets.  It compares the performance of three generative models: GAN, WGAN-GP, and KSGAN in terms of squared population MMD.  MMD (Minimum Mean Discrepancy) measures the distance between the generated and true data distributions.  Lower MMD indicates better performance. The table shows that KSGAN achieves comparable performance to WGAN-GP, even with significantly fewer training steps.", "section": "6.1 Synthetic distributions"}, {"figure_path": "8JmUmTgKiY/tables/tables_8_1.jpg", "caption": "Table 2: The number of captured modes and Kullback-Leibler divergence between the distribution of sampled digits and target uniform distribution averaged over five random initializations with the standard deviation calculated with Bessel's correction in the parentheses. All the methods were trained with the same budget k_c = 1, k_g = 1. WGAN-GP and KSGAN cover all the modes in all experiments while demonstrating low KL divergence.", "description": "This table shows the performance of GAN, WGAN-GP, and KSGAN on MNIST and 3StackedMNIST datasets.  The number of modes captured and the Kullback-Leibler (KL) divergence (a measure of the difference between two probability distributions) are reported.  The results are averages over five runs with different random initializations, showing the standard deviation in parentheses. All models used the same training budget (k_c = 1, k_g = 1).", "section": "6.2 MNIST"}, {"figure_path": "8JmUmTgKiY/tables/tables_8_2.jpg", "caption": "Table 3: Inception Score (IS) and Fr\u00e9chet inception distance (FID) metrics averaged over five random initializations with the standard deviation calculated with Bessel's correction in the parentheses. All the methods were trained with the same budget k\u03c6 = 1, k\u03b8 = 1. The scores for the training dataset are included in the top row, as \"Real data\" for reference. WGAN-GP and KSGAN perform similarly on average, while KSGAN exhibits lower variance between networks' initialization.", "description": "This table presents the Inception Score (IS) and Fr\u00e9chet Inception Distance (FID) for three Generative Adversarial Networks (GAN, WGAN-GP, and KSGAN) trained on the CIFAR-10 dataset.  The scores are averaged over five different random initializations, with standard deviations included. The table also shows the IS and FID for the real CIFAR-10 data as a benchmark.  The results indicate that KSGAN and WGAN-GP achieve similar performance, but KSGAN shows less variance across different random initializations.", "section": "6.3 CIFAR-10"}, {"figure_path": "8JmUmTgKiY/tables/tables_13_1.jpg", "caption": "Table 1: Squared population MMD (\u2193) between test data and samples from the methods trained on 65536 samples, averaged over five random initializations with the standard deviation calculated with Bessel's correction in the parentheses. The proposed KSGAN with k<sub>c</sub> = 1 performs on par with the WGAN-GP trained with five times the budget k<sub>c</sub> = 5. See appendix D.1 for qualitative comparison.", "description": "This table presents the results of the squared population MMD (Minimum Mean Discrepancy) experiment.  It compares the performance of three Generative Adversarial Networks (GAN, WGAN-GP, and KSGAN) on eight different synthetic 2D datasets. The lower the MMD score, the better the model's performance in approximating the true distribution.  The table shows that KSGAN, even with a smaller budget (k<sub>c</sub> = 1) achieves comparable performance to WGAN-GP (k<sub>c</sub> = 5).", "section": "6.1 Synthetic distributions"}]