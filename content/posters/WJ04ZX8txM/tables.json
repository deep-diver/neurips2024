[{"figure_path": "WJ04ZX8txM/tables/tables_24_1.jpg", "caption": "Table 1: Examples of contexts in Relation IDs from COUNTERFACT", "description": "This table lists four examples of contexts from the COUNTERFACT dataset, each associated with a different relation ID.  For each example, the table provides the context, the true target token, and a false target token that could be used to mislead a language model.", "section": "Hijacking based on relation IDs"}, {"figure_path": "WJ04ZX8txM/tables/tables_24_2.jpg", "caption": "Table 2: Examples of hijack and reverse hijack formats based on Relation IDs", "description": "This table shows example sentences used in the context hijacking experiments based on different relation IDs. For each relation ID, two example sentences are provided: one for the hijacking scheme (where the goal is to mislead the model into outputting an incorrect answer) and one for the reverse hijacking scheme (where the goal is to make the model produce the correct answer). The format of these sentences uses placeholders such as {subject} and {target_true} or {target_false} which are replaced with appropriate values during the experiment. This aids in systematic manipulation of the model's output.", "section": "Additional experiments - context hijacking"}]