[{"figure_path": "v416YLOQuU/tables/tables_4_1.jpg", "caption": "Table 1: Summary of convergence rates for different optimizers.", "description": "This table summarizes the convergence rates achieved by various optimization algorithms, including Adam, clipped Adam, and SGD, under different assumptions on the objective function (smooth, non-smooth, and strongly convex). It highlights the optimal convergence rates achievable in each setting and shows which algorithms attain these optimal rates.", "section": "5 Optimality and gradient adaptivity"}]