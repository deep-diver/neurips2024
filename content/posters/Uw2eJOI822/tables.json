[{"figure_path": "Uw2eJOI822/tables/tables_2_1.jpg", "caption": "Table 1: Examples of context names and generated candidate names for three selected classes from ADE20K. Context names are key to comprehending general terms such as \u201cfield\u201d and \u201cbox\u201d and disambiguating polysemous terms like \u201ccradle\u201d, which, in this context, refers to a baby bed rather than a phone cradle or a mining tool.", "description": "This table shows examples of how context names are used to generate candidate names for three classes from the ADE20K dataset.  It highlights the importance of context in disambiguating polysemous words (words with multiple meanings) and generating more precise and descriptive names for the visual segments.  The original names are compared with generated candidate names, showing how the context helps to refine the descriptions.", "section": "3 RENOVATE: Renaming Segmentation Benchmarks"}, {"figure_path": "Uw2eJOI822/tables/tables_6_1.jpg", "caption": "Table 2: Statistics of renovated datasets.", "description": "This table presents a comparison of statistics for three popular panoptic segmentation datasets (COCO, ADE20K, and Cityscapes) before and after applying the RENOVATE name renovation process.  The \"Original classes\" column shows the number of unique classes in each dataset as originally defined. The \"Segments/Class\" column indicates the average number of image segments per class.  The lower half of the table shows the corresponding statistics after the renovation process: \"RENOVATE names\" is the number of distinct names generated by RENOVATE, and \"Segments/Name\" is the average number of segments per new name.  The comparison highlights that RENOVATE increases the number of distinct names significantly, creating a finer-grained categorization of segments within each dataset.", "section": "5.1 Obtaining renovated names"}, {"figure_path": "Uw2eJOI822/tables/tables_7_1.jpg", "caption": "Table 3: Training with renovated names. During inference, test names are merged from Original, OpenSeg, and RENOVATE names for fair comparison. Our results demonstrate that RENOVATE names can help train stronger open-vocabulary models.", "description": "This table presents the results of training open-vocabulary segmentation models on the MS COCO dataset using different sets of names: original names, OpenSeg names, synonym names, candidate names, and RENOVATE names.  The table shows that using RENOVATE names leads to significant improvements in model performance, as measured by PQ, AP, and mIoU metrics.  During inference, to ensure a fair comparison, the test names were a combination of all name types. The results highlight the effectiveness of using high-quality, contextually relevant names for training.", "section": "4.1 Training with RENOVATE names"}, {"figure_path": "Uw2eJOI822/tables/tables_16_1.jpg", "caption": "Table B.1: Ablation on the context name sources.", "description": "This table presents the results of ablation studies conducted on the context name sources used in the candidate name generation phase.  The experiment compares different methods for generating context names: no context names, captions from BLIP2, image tags from RAM, and captions from CaSED. The table shows that using captions from CaSED resulted in the highest PQ, AP, and mIoU scores, indicating that the quality of context names significantly impacts the performance of the candidate name generation.", "section": "B More Experiment Results"}, {"figure_path": "Uw2eJOI822/tables/tables_16_2.jpg", "caption": "Table B.3: Ablation on GPT-4 prompts.", "description": "This table presents the ablation study results on different GPT-4 prompts used for generating candidate names.  It shows the impact of various components of the prompt, such as using context names, suggestions on name types, and instructions on original names, on the performance metrics (PQ, AP, mIoU) on the ADE20K dataset.  The results indicate the importance of each component for generating high-quality candidate names.", "section": "B More Experiment Results"}, {"figure_path": "Uw2eJOI822/tables/tables_17_1.jpg", "caption": "Table 3: Training with renovated names. During inference, test names are merged from Original, OpenSeg, and RENOVATE names for fair comparison. Our results demonstrate that RENOVATE names can help train stronger open-vocabulary models.", "description": "This table presents the results of training open-vocabulary segmentation models on the MS COCO dataset using different sets of names: Original, OpenSeg, Synonym, Candidate, and RENOVATE.  The performance is evaluated using PQ, AP, and mIoU metrics on the MS COCO, ADE20K, and Cityscapes datasets.  It highlights the improved performance achieved by using RENOVATE names, demonstrating their effectiveness in training stronger models.", "section": "4.1 Training with RENOVATE names"}, {"figure_path": "Uw2eJOI822/tables/tables_20_1.jpg", "caption": "Table 3: Training with renovated names. During inference, test names are merged from Original, OpenSeg, and RENOVATE names for fair comparison. Our results demonstrate that RENOVATE names can help train stronger open-vocabulary models.", "description": "This table presents the results of training open-vocabulary segmentation models using different sets of names: original names, OpenSeg names, synonym names, candidate names, and RENOVATE names.  The models were evaluated using standard metrics (PQ, AP, mIoU) on MS COCO, ADE20K, and Cityscapes datasets.  The table shows that using RENOVATE names for training leads to significant performance improvements compared to the other name sets.  During testing, names from all sets were used for fair comparison.", "section": "4.1 Training with RENOVATE names"}]