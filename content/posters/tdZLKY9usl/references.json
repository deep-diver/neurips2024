{"references": [{"fullname_first_author": "J. Wei", "paper_title": "Emergent abilities of large language models", "publication_date": "2022-06-07", "reason": "This paper is foundational to the understanding of large language models, which are becoming increasingly important in various applications, and are relevant to the work on collaborative inference."}, {"fullname_first_author": "Z. He", "paper_title": "Model inversion attacks against collaborative inference", "publication_date": "2019-10-28", "reason": "This paper is highly relevant as it introduces model inversion attacks, a critical threat against collaborative inference systems, which this paper aims to defend against."}, {"fullname_first_author": "Z. He", "paper_title": "Attacking and protecting data privacy in edge-cloud collaborative inference systems", "publication_date": "2020-06-01", "reason": "This paper directly addresses the security challenges in collaborative inference, providing important context to this paper's defense mechanism."}, {"fullname_first_author": "L. Zhu", "paper_title": "Deep leakage from gradients", "publication_date": "2019-12-01", "reason": "This paper's exploration of gradient leakage in deep learning models is crucial to understanding the potential vulnerabilities in collaborative inference."}, {"fullname_first_author": "C. Fu", "paper_title": "Label inference attacks against vertical federated learning", "publication_date": "2022-08-01", "reason": "This paper explores label inference attacks, another critical vulnerability in collaborative and federated learning, which motivates the approach in this paper."}]}