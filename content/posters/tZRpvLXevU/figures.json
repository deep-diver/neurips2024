[{"figure_path": "tZRpvLXevU/figures/figures_3_1.jpg", "caption": "Figure 1: Latent Diffusion Models stack a diffusion model (orange) on top of an Auto-Encoder (green).", "description": "This figure illustrates the architecture of a Latent Diffusion Model (LDM).  It consists of two main stages: a Regularized AutoEncoder (RAE) and a diffusion model. The RAE (green boxes) takes an image (x) as input and outputs a latent representation (z).  The RAE includes an encoder (q\u03c6) and a decoder (p\u03b8).  The latent representation (z) is then used as input to the diffusion model (orange boxes), which learns the distribution of the latent representations and is responsible for generating variations of the image. The diffusion model takes the latent representation (z) of an exemplar image (y) as conditioning input and outputs a denoised latent representation (z0). Finally, the decoder (p\u03b8) converts the denoised latent representation (z0) into the generated image (x'). The figure highlights how the diffusion model uses the latent representation from the autoencoder and how the regularizations are applied to the latent space via the autoencoder.", "section": "4 One-shot Latent Diffusion Models"}, {"figure_path": "tZRpvLXevU/figures/figures_5_1.jpg", "caption": "Figure 2: Samples from LDMs w/ different regularizers. The LDMs correspond to the larger data points in Fig. 3.", "description": "This figure displays samples generated by Latent Diffusion Models (LDMs) trained with different regularizers. Each row represents a different regularizer (No reg., Proto., Classif., Barlow, SimCLR, KL, VQ), and each column shows samples for the same category. The samples shown correspond to the LDMs that exhibit the closest performance to human performance, indicated as larger data points in Figure 3. The image helps visualize the impact of different inductive biases on the quality and style of generated drawings.", "section": "5 Results"}, {"figure_path": "tZRpvLXevU/figures/figures_6_1.jpg", "caption": "Figure 3: Effect of increasing the regularization weights on the originality vs. recognizability framework (QuickDraw-FS dataset). Each data point represents an LDM trained with different values of regularization weights (\u03b2). The curves represent the parametric fits, oriented in the direction of an increase of \u03b2. a): For the LDMs with \"standard\" regularizers, the \u03b2 is applied on the KL (LKL in Eq. 2) or on the VQ regularizers (LvQ in Eq. 3). b): For the supervised regularizers, the \u03b2 is applied on the CL (LCL in Eq. 4) or on the prototype-based regularizers (LPR in Eq. 5). c): For the contrastive regularizers, the \u03b2 is applied on the SimCLR (LSimCLR in Eq. 14) or on the Barlow regularizers (LBAR in Eq. 15). See A.5 for more information on the range of \u03b2 we have explored for each regularizer. Larger data points indicate models whose performance is closer to that of humans for each type of regularization. For comparison, we include an LDM leveraging a non-regularized RAE (hexagon marker) and a diffusion model trained directly on the pixel space (cross marker). The human performance corresponds to the recognizability and originality computed on human drawings (shown with a grey star).", "description": "This figure shows the effect of different regularization weights on the originality and recognizability of one-shot drawings generated by Latent Diffusion Models (LDMs).  Each subplot represents a different type of regularization (standard, supervised, contrastive). The curves show the trade-off between originality and recognizability as the regularization weight increases.  The proximity of the data points to the human data point (grey star) indicates how well the LDMs mimic human drawing performance.", "section": "5 Results"}, {"figure_path": "tZRpvLXevU/figures/figures_7_1.jpg", "caption": "Figure 3: Effect of increasing the regularization weights on the originality vs. recognizability framework (QuickDraw-FS dataset). Each data point represents an LDM trained with different values of regularization weights (\u03b2). The curves represent the parametric fits, oriented in the direction of an increase of \u03b2. a): For the LDMs with \u201cstandard\u201d regularizers, the \u03b2 is applied on the KL (LKL in Eq. 2) or on the VQ regularizers (Lvq in Eq. 3). b): For the supervised regularizers, the \u03b2 is applied on the CL (LCL in Eq. 4) or on the prototype-based regularizers (LPR in Eq. 5). c): For the contrastive regularizers, the \u03b2 is applied on the SimCLR (LSimCLR in Eq. 14) or on the Barlow regularizers (LBar in Eq. 15). See A.5 for more information on the range of \u03b2 we have explored for each regularizer. Larger data points indicate models whose performance is closer to that of humans for each type of regularization. For comparison, we include an LDM leveraging a non-regularized RAE (hexagon marker) and a diffusion model trained directly on the pixel space (cross marker). The human performance corresponds to the recognizability and originality computed on human drawings (shown with a grey star).", "description": "This figure shows the effect of different regularization weights on the originality and recognizability of one-shot drawings generated by Latent Diffusion Models (LDMs).  It compares various LDMs against human performance, revealing that prototype-based and Barlow regularizations yield results closest to human-like drawings.", "section": "5 Results"}, {"figure_path": "tZRpvLXevU/figures/figures_8_1.jpg", "caption": "Figure 5: Feature importance maps comparison. a) The visualizations include feature importance maps for humans (top row) and LDMs (six bottom rows). All the maps are overlaid on exemplars. Hot vs. cold pixels show image locations that are more vs. less important. Maps for humans were computed using psychophysical data from Boutin et al. [30]. For the LDMs, they are obtained for each category by averaging (x, y) (see Eq. 9) over 10 different image variations (x) belonging to the same category. The models' maps are computed on the more human-like LDMs for each regularization (larger data points in Fig. 5). b) Spearman's rank correlation coefficient between humans and LDMs feature importance maps. The error bar is computed as the standard deviation of the Spearman coefficients over all categories (25 in total). Stars indicate the p-value (*** : p < 10-3 and * : p < 5.10-2) of pair-wise statistical test between models (Wilcoxon signed-rank test, see A.8.4). The black line corresponds to an LDM without any regularization. The dashed line is the human consistency (0.88), it quantifies how much two populations of humans agree with each other on feature importance maps (see A.8.3 for details on the human consistency computation).", "description": "This figure compares feature importance maps generated by humans and LDMs with different regularizers. (a) shows examples of feature importance maps, where hot/cold colors represent high/low importance. The human maps are derived from psychophysical data, while LDM maps highlight category-diagnostic features by back-projecting intermediate noisy latent states to pixel space using the RAE decoder. (b) quantifies the similarity between human and LDM maps using Spearman's rank correlation.  Higher correlation indicates better alignment between human and machine visual strategies.", "section": "5.2 Comparing humans and LDM perceptual strategies"}, {"figure_path": "tZRpvLXevU/figures/figures_15_1.jpg", "caption": "Figure A.1: Examples of distinct visual concepts belonging to the same object category in the Quick, Draw! dataset.", "description": "This figure shows examples of how the Quick, Draw! dataset contains drawings that are semantically related but not necessarily visually similar.  For example, the category \"alarm clock\" includes both analog and digital alarm clocks, representing distinct visual concepts. This illustrates a key limitation of using the original Quick, Draw! dataset for purely visual one-shot generation tasks because the categories do not always represent the same visual concept.", "section": "A.1 QuickDraw-FS dataset"}, {"figure_path": "tZRpvLXevU/figures/figures_15_2.jpg", "caption": "Figure 2: Samples from LDMs w/ different regularizers. The LDMs correspond to the larger data points in Fig. 3.", "description": "This figure shows samples generated by Latent Diffusion Models (LDMs) trained with different regularizers. Each row corresponds to a specific regularizer (No reg., Proto., Classif., Barlow, SimCLR, KL, VQ), showcasing the diversity of generated drawings depending on the inductive biases in the latent space.  The selection of LDMs shown is based on those models having performance closest to that of human participants, as detailed further in Figure 3.", "section": "5 Results"}, {"figure_path": "tZRpvLXevU/figures/figures_17_1.jpg", "caption": "Figure 3: Effect of increasing the regularization weights on the originality vs recognizability framework (QuickDraw-FS dataset). Each data point represents an LDM trained with different values of regularization weights (\u03b2). The curves represent the parametric fits, oriented in the direction of an increase of \u03b2. a): For the LDMs with \"standard\" regularizers, the \u03b2 is applied on the KL (LKL in Eq. 2) or on the VQ regularizers (Lvq in Eq. 3). b): For the supervised regularizers, the \u03b2 is applied on the CL (LCL in Eq. 4) or on the prototype-based regularizers (LPR in Eq. 5). c): For the contrastive regularizers, the \u03b2 is applied on the SimCLR (LSimCLR in Eq. 14) or on the Barlow regularizers (LBar in Eq. 15). See A.5 for more information on the range of \u03b2 we have explored for each regularizer. Larger data points indicate models whose performance is closer to that of humans for each type of regularization. For comparison, we include an LDM leveraging a non-regularized RAE (hexagon marker) and a diffusion model trained directly on the pixel space (cross marker). The human performance corresponds to the recognizability and originality computed on human drawings (shown with a grey star).", "description": "This figure shows the impact of different regularization weights on the originality vs. recognizability of one-shot drawings generated by Latent Diffusion Models (LDMs). The x-axis represents originality, the y-axis represents recognizability.  Each subplot displays results for a different group of regularizers (standard, supervised, contrastive). The lines show the parametric fit of the data points and indicate how the performance changes as the regularization weight increases. The results suggest that prototype-based and Barlow regularizations yield samples closer to those generated by humans, indicating that these inductive biases are crucial for one-shot drawing tasks. ", "section": "5 Results"}, {"figure_path": "tZRpvLXevU/figures/figures_20_1.jpg", "caption": "Figure A.3: The directed graphical model considered in this work. Dotted and plain arrows represent the forward (i.e., noise injection) and the reverse processes (i.e., noise removal), respectively. Zy and Zo are the latent representations of the exemplar image y and the image x, respectively (exemplified with skull drawings). Zt corresponds to the sequence of partially corrupted latent representations. Zy and Zo are obtained using the RAE encoder q\u03c6(z|x) and can be mapped to the input space using the RAE decoder p\u03b8(x|z). The \u2018dummy\u2019 distributions located on top of the zi variables, illustrate the noise injection process, starting from an \u2018informative\u2019 multimodal distribution to a fully \u2018uninformative\u2019 Gaussian distribution.", "description": "This figure shows the directed graphical model used in the latent diffusion model. The model progressively denoises latent representations conditioned on exemplar images to generate new images.", "section": "A.4 Diffusion Model"}, {"figure_path": "tZRpvLXevU/figures/figures_24_1.jpg", "caption": "Figure 3: Effect of increasing the regularization weights on the originality vs recognizability framework (QuickDraw-FS dataset). Each data point represents an LDM trained with different values of regularization weights (\u03b2). The curves represent the parametric fits, oriented in the direction of an increase of \u03b2. a): For the LDMs with \"standard\" regularizers, the \u03b2 is applied on the KL (LKL in Eq. 2) or on the VQ regularizers (LvQ in Eq. 3). b): For the supervised regularizers, the \u03b2 is applied on the CL (LCL in Eq. 4) or on the prototype-based regularizers (LPR in Eq. 5). c): For the contrastive regularizers, the \u03b2 is applied on the SimCLR (LSimCLR in Eq. 14) or on the Barlow regularizers (LBar in Eq. 15). See A.5 for more information on the range of \u03b2 we have explored for each regularizer. Larger data points indicate models whose performance is closer to that of humans for each type of regularization. For comparison, we include an LDM leveraging a non-regularized RAE (hexagon marker) and a diffusion model trained directly on the pixel space (cross marker). The human performance corresponds to the recognizability and originality computed on human drawings (shown with a grey star).", "description": "The figure shows the results of an experiment evaluating the effect of different regularization techniques on the performance of Latent Diffusion Models (LDMs) in a one-shot drawing task. The x-axis represents originality, and the y-axis represents recognizability. Each plot shows the results for different regularizers (KL, VQ, Classification, Prototype, SimCLR, Barlow).  The curves show the trend of how the originality and recognizability change as the regularization strength (\u03b2) is increased.", "section": "5 Results"}, {"figure_path": "tZRpvLXevU/figures/figures_25_1.jpg", "caption": "Figure 3: Effect of increasing the regularization weights on the originality vs. recognizability framework (QuickDraw-FS dataset). Each data point represents an LDM trained with different values of regularization weights (\u03b2). The curves represent the parametric fits, oriented in the direction of an increase of \u03b2. a): For the LDMs with \u201cstandard\u201d regularizers, the \u03b2 is applied on the KL (LKL in Eq. 2) or on the VQ regularizers (Lvq in Eq. 3). b): For the supervised regularizers, the \u03b2 is applied on the CL (LCL in Eq. 4) or on the prototype-based regularizers (LPR in Eq. 5). c): For the contrastive regularizers, the \u03b2 is applied on the SimCLR (LSimCLR in Eq. 14) or on the Barlow regularizers (LBar in Eq. 15). See A.5 for more information on the range of \u03b2 we have explored for each regularizer. Larger data points indicate models whose performance is closer to that of humans for each type of regularization. For comparison, we include an LDM leveraging a non-regularized RAE (hexagon marker) and a diffusion model trained directly on the pixel space (cross marker). The human performance corresponds to the recognizability and originality computed on human drawings (shown with a grey star).", "description": "This figure shows the effect of different regularization strengths on the originality and recognizability of one-shot drawings generated by Latent Diffusion Models (LDMs).  Each subplot represents a different type of regularization (standard, supervised, contrastive). The x-axis represents originality (how different the drawings are from the exemplar), and the y-axis represents recognizability (how easily the drawings are classified). The curves show how the balance between originality and recognizability changes with increasing regularization strength. The plot also includes a comparison to human performance.", "section": "5 Results"}, {"figure_path": "tZRpvLXevU/figures/figures_25_2.jpg", "caption": "Figure 3: Effect of increasing the regularization weights on the originality vs recognizability framework (QuickDraw-FS dataset). Each data point represents an LDM trained with different values of regularization weights (\u03b2). The curves represent the parametric fits, oriented in the direction of an increase of \u03b2. a): For the LDMs with \"standard\" regularizers, the \u03b2 is applied on the KL (LKL in Eq. 2) or on the VQ regularizers (LvQ in Eq. 3). b): For the supervised regularizers, the \u03b2 is applied on the CL (LCL in Eq. 4) or on the prototype-based regularizers (LPR in Eq. 5). c): For the contrastive regularizers, the \u03b2 is applied on the SimCLR (LSimCLR in Eq. 14) or on the Barlow regularizers (LBar in Eq. 15). See A.5 for more information on the range of \u03b2 we have explored for each regularizer. Larger data points indicate models whose performance is closer to that of humans for each type of regularization. For comparison, we include an LDM leveraging a non-regularized RAE (hexagon marker) and a diffusion model trained directly on the pixel space (cross marker). The human performance corresponds to the recognizability and originality computed on human drawings (shown with a grey star).", "description": "This figure shows the impact of different regularization strengths (\u03b2) on the trade-off between originality and recognizability of one-shot drawings generated by Latent Diffusion Models (LDMs).  Each subplot represents a different type of regularization (standard, supervised, contrastive), showing how increasing \u03b2 affects the balance between the two metrics.  The human performance is shown as a grey star, providing a benchmark for comparison.", "section": "5 Results"}, {"figure_path": "tZRpvLXevU/figures/figures_26_1.jpg", "caption": "Figure 3: Effect of increasing the regularization weights on the originality vs recognizability framework (QuickDraw-FS dataset). Each data point represents an LDM trained with different values of regularization weights (\u03b2). The curves represent the parametric fits, oriented in the direction of an increase of \u03b2. a): For the LDMs with \"standard\" regularizers, the \u03b2 is applied on the KL (LKL in Eq. 2) or on the VQ regularizers (Lvq in Eq. 3). b): For the supervised regularizers, the \u03b2 is applied on the CL (LCL in Eq. 4) or on the prototype-based regularizers (LPR in Eq. 5). c): For the contrastive regularizers, the \u03b2 is applied on the SimCLR (LSimCLR in Eq. 14) or on the Barlow regularizers (LBAR in Eq. 15). See A.5 for more information on the range of \u03b2 we have explored for each regularizer. Larger data points indicate models whose performance is closer to that of humans for each type of regularization. For comparison, we include an LDM leveraging a non-regularized RAE (hexagon marker) and a diffusion model trained directly on the pixel space (cross marker). The human performance corresponds to the recognizability and originality computed on human drawings (shown with a grey star).", "description": "This figure shows the results of an experiment comparing different regularization techniques in latent diffusion models for one-shot drawing.  It plots originality (x-axis) against recognizability (y-axis) for several models with varying regularization weights.  The plots illustrate the trade-off between originality and recognizability, and how different regularization methods affect model performance relative to human-level performance.", "section": "5 Results"}, {"figure_path": "tZRpvLXevU/figures/figures_26_2.jpg", "caption": "Figure 3: Effect of increasing the regularization weights on the originality vs recognizability framework (QuickDraw-FS dataset). Each data point represents an LDM trained with different values of regularization weights (\u03b2). The curves represent the parametric fits, oriented in the direction of an increase of \u03b2. a): For the LDMs with \"standard\" regularizers, the \u03b2 is applied on the KL (LKL in Eq. 2) or on the VQ regularizers (Lvq in Eq. 3). b): For the supervised regularizers, the \u03b2 is applied on the CL (LCL in Eq. 4) or on the prototype-based regularizers (LPR in Eq. 5). c): For the contrastive regularizers, the \u03b2 is applied on the SimCLR (LSimCLR in Eq. 14) or on the Barlow regularizers (LBar in Eq. 15). See A.5 for more information on the range of \u03b2 we have explored for each regularizer. Larger data points indicate models whose performance is closer to that of humans for each type of regularization. For comparison, we include an LDM leveraging a non-regularized RAE (hexagon marker) and a diffusion model trained directly on the pixel space (cross marker). The human performance corresponds to the recognizability and originality computed on human drawings (shown with a grey star).", "description": "This figure shows the effect of different regularization weights on the originality and recognizability of one-shot drawings generated by Latent Diffusion Models (LDMs).  It compares the performance of LDMs with different regularizers (KL, VQ, Classification, Prototype, SimCLR, Barlow) against human performance, visualized as a grey star. The x-axis represents originality (how different the drawing is from the exemplar), and the y-axis represents recognizability (how well the drawing is classified). Each subplot shows the results for a different type of regularizer, with increasing regularization weight moving along the curves.  LDMs using prototype-based and Barlow regularizations show better performance, approaching human-like results.", "section": "5 Results"}, {"figure_path": "tZRpvLXevU/figures/figures_27_1.jpg", "caption": "Figure 3: Effect of increasing the regularization weights on the originality vs recognizability framework (QuickDraw-FS dataset). Each data point represents an LDM trained with different values of regularization weights (\u03b2). The curves represent the parametric fits, oriented in the direction of an increase of \u03b2. a): For the LDMs with \"standard\" regularizers, the \u03b2 is applied on the KL (LKL in Eq. 2) or on the VQ regularizers (Lvq in Eq. 3). b): For the supervised regularizers, the \u03b2 is applied on the CL (LCL in Eq. 4) or on the prototype-based regularizers (LPR in Eq. 5). c): For the contrastive regularizers, the \u03b2 is applied on the SimCLR (LSimCLR in Eq. 14) or on the Barlow regularizers (LBar in Eq. 15). See A.5 for more information on the range of \u03b2 we have explored for each regularizer. Larger data points indicate models whose performance is closer to that of humans for each type of regularization. For comparison, we include an LDM leveraging a non-regularized RAE (hexagon marker) and a diffusion model trained directly on the pixel space (cross marker). The human performance corresponds to the recognizability and originality computed on human drawings (shown with a grey star).", "description": "This figure shows the effect of different regularization strengths on the originality and recognizability of one-shot drawings generated by Latent Diffusion Models (LDMs).  It compares the performance of LDMs with various regularizers (KL, VQ, classification, prototype-based, SimCLR, and Barlow) against human performance, illustrating the trade-off between originality and recognizability. The optimal regularization strength varies for each regularizer, and prototype-based and Barlow regularization show the closest alignment with human performance.", "section": "5 Results"}, {"figure_path": "tZRpvLXevU/figures/figures_27_2.jpg", "caption": "Figure 3: Effect of increasing the regularization weights on the originality vs recognizability framework (QuickDraw-FS dataset). Each data point represents an LDM trained with different values of regularization weights (\u03b2). The curves represent the parametric fits, oriented in the direction of an increase of \u03b2. a): For the LDMs with \"standard\" regularizers, the \u03b2 is applied on the KL (LKL in Eq. 2) or on the VQ regularizers (LvQ in Eq. 3). b): For the supervised regularizers, the \u03b2 is applied on the CL (LCL in Eq. 4) or on the prototype-based regularizers (LPR in Eq. 5). c): For the contrastive regularizers, the \u03b2 is applied on the SimCLR (LSimCLR in Eq. 14) or on the Barlow regularizers (LBar in Eq. 15). See A.5 for more information on the range of \u03b2 we have explored for each regularizer. Larger data points indicate models whose performance is closer to that of humans for each type of regularization. For comparison, we include an LDM leveraging a non-regularized RAE (hexagon marker) and a diffusion model trained directly on the pixel space (cross marker). The human performance corresponds to the recognizability and originality computed on human drawings (shown with a grey star).", "description": "This figure shows the effect of different regularization weights on the originality and recognizability of one-shot drawings generated by Latent Diffusion Models (LDMs).  Each subplot shows results for a different type of regularizer (standard, supervised, contrastive), plotting recognizability against originality. The curves show a tradeoff between these metrics, and the best-performing LDMs are highlighted, demonstrating a closer similarity to human performance.", "section": "5 Results"}, {"figure_path": "tZRpvLXevU/figures/figures_28_1.jpg", "caption": "Figure 2: Samples from LDMs w/ different regularizers. The LDMs correspond to the larger data points in Fig. 3.", "description": "This figure shows example sketches generated by Latent Diffusion Models (LDMs) trained with different types of regularizers. Each row represents a different regularizer (No reg., Proto, Classif., Barlow, SimCLR, KL, VQ), and each column shows a different generated sketch from that regularizer.  The LDMs highlighted correspond to the models with the best performance according to the Originality vs Recognizability metrics discussed in the paper, corresponding to the larger points in Figure 3. This allows for a visual comparison of the different generated drawings and how the chosen inductive biases affect the sketches.", "section": "5 Results"}, {"figure_path": "tZRpvLXevU/figures/figures_29_1.jpg", "caption": "Figure A.14: Samples generated by LDMs with contrastive regularizer. a) SimCLR regularizer (obtained with \\(\\beta_{SimCLR} = 10^{-2}\\)). b) Barlow regularizer (obtained with \\(\\beta_{Barlow} = 30\\)).", "description": "This figure shows samples generated by Latent Diffusion Models (LDMs) using two different contrastive regularizers: SimCLR and Barlow.  The top row displays the exemplars used to condition the LDMs for each category. The remaining rows show samples generated by the LDMs.  The left column shows results using the SimCLR regularizer, and the right column shows results using the Barlow regularizer. The figure helps to visually compare the effects of these two regularizers on the diversity and quality of generated samples.", "section": "A.7 Samples generated by the one-shot LDMS"}, {"figure_path": "tZRpvLXevU/figures/figures_29_2.jpg", "caption": "Figure A.11: Samples generated by a LDM without regularization. For this LDM, \u03b2 is set to 0.", "description": "This figure shows samples generated by a Latent Diffusion Model (LDM) without any regularization applied.  The top row shows the exemplars used for conditioning. The remaining samples are variations generated by the model. The lack of regularization results in samples that are less diverse and may not accurately represent the intended concept compared to regularized models.", "section": "A.7 Samples generated by the one-shot LDMS"}, {"figure_path": "tZRpvLXevU/figures/figures_30_1.jpg", "caption": "Figure A.14: Samples generated by LDMs with contrastive regularizer. a) SimCLR regularizer (obtained with \\(\\beta_{SimCLR} = 10^{-2}\\). b) Barlow regularizer (obtained with \\(\\beta_{Barlow} = 30\\).", "description": "This figure shows samples generated by Latent Diffusion Models (LDMs) using contrastive regularizers.  The top row displays the exemplars used to condition the models. The remaining rows show variations generated for each exemplar.  (a) shows samples generated using SimCLR regularization with a hyperparameter value of 0.01, while (b) presents samples from an LDM using Barlow Twins regularization with a hyperparameter value of 30.  The results illustrate the difference in generated variations obtained from these two distinct methods.", "section": "A.7 Samples generated by the one-shot LDMs"}, {"figure_path": "tZRpvLXevU/figures/figures_32_1.jpg", "caption": "Figure 5: Feature importance maps comparison. a) The visualizations include feature importance maps for humans (top row) and LDMs (six bottom rows). All the maps are overlaid on exemplars. Hot vs. cold pixels show image locations that are more vs. less important. Maps for humans were computed using psychophysical data from Boutin et al. [30]. For the LDMs, they are obtained for each category by averaging (x, y) (see Eq. 9) over 10 different image variations (x) belonging to the same category. The models' maps are computed on the more human-like LDMs for each regularization (larger data points in Fig. 5). b) Spearman\u2019s rank correlation coefficient between humans and LDMs feature importance maps. The error bar is computed as the standard deviation of the Spearman coefficients over all categories (25 in total). Stars indicate the p-value (*** : p < 10\u22123 and * : p < 5\u00b710\u22122) of pair-wise statistical test between models (Wilcoxon signed-rank test, see A.8.4). The black line corresponds to an LDM without any regularization. The dashed line is the human consistency (0.88), it quantifies how much two populations of humans agree with each other on feature importance maps (see A.8.3 for details on the human consistency computation).", "description": "This figure compares the feature importance maps obtained from human subjects and those generated by Latent Diffusion Models (LDMs) with different regularizations.  Panel (a) shows example maps visually, highlighting important regions in the drawings for both humans and LDMs. Panel (b) presents a quantitative comparison, showing the Spearman rank correlation between human and LDM feature importance maps, along with statistical significance tests.", "section": "5.2 Comparing humans and LDM perceptual strategies"}, {"figure_path": "tZRpvLXevU/figures/figures_32_2.jpg", "caption": "Figure 5: Feature importance maps comparison. a) The visualizations include feature importance maps for humans (top row) and LDMs (six bottom rows). All the maps are overlaid on exemplars. Hot vs. cold pixels show image locations that are more vs. less important. Maps for humans were computed using psychophysical data from Boutin et al. [30]. For the LDMs, they are obtained for each category by averaging (x, y) (see Eq. 9) over 10 different image variations (x) belonging to the same category. The models' maps are computed on the more human-like LDMs for each regularization (larger data points in Fig. 5). b) Spearman\u2019s rank correlation coefficient between humans and LDMs feature importance maps. The error bar is computed as the standard deviation of the Spearman coefficients over all categories (25 in total). Stars indicate the p-value (*** : p < 10\u22123 and * : p < 5.10\u22122) of pair-wise statistical test between models (Wilcoxon signed-rank test, see A.8.4). The black line corresponds to an LDM without any regularization. The dashed line is the human consistency (0.88), it quantifies how much two populations of humans agree with each other on feature importance maps (see A.8.3 for details on the human consistency computation).", "description": "This figure compares feature importance maps between humans and several latent diffusion models (LDMs) with different regularizations.  (a) shows example maps, demonstrating the spatial distribution of importance weights for various categories. The heatmaps highlight areas deemed most crucial for object recognition.  (b) presents a quantitative comparison, showing the Spearman rank correlation between human and model maps for each regularization and statistical significance tests. The prototype-based and Barlow regularized models show the highest correlation with human perception.", "section": "5.2 Comparing humans and LDM perceptual strategies"}, {"figure_path": "tZRpvLXevU/figures/figures_33_1.jpg", "caption": "Figure 5: Feature importance maps comparison. a) The visualizations include feature importance maps for humans (top row) and LDMs (six bottom rows). All the maps are overlaid on exemplars. Hot vs. cold pixels show image locations that are more vs. less important. Maps for humans were computed using psychophysical data from Boutin et al. [30]. For the LDMs, they are obtained for each category by averaging  (see Eq. 9) over 10 different image variations (x) belonging to the same category. The models' maps are computed on the more human-like LDMs for each regularization (larger data points in Fig. 5). b) Spearman\u2019s rank correlation coefficient between humans and LDMs feature importance maps. The error bar is computed as the standard deviation of the Spearman coefficients over all categories (25 in total). Stars indicate the p-value (*** : p < 10\u22123 and * : p < 5\u00b710\u22122) of pair-wise statistical test between models (Wilcoxon signed-rank test, see A.8.4). The black line corresponds to an LDM without any regularization. The dashed line is the human consistency (0.88), it quantifies how much two populations of humans agree with each other on feature importance maps (see A.8.3 for details on the human consistency computation).", "description": "This figure compares feature importance maps between humans and LDMs with different regularizers. (a) shows example maps, highlighting which image regions are most important for category recognition. (b) quantifies the similarity between human and machine maps using Spearman rank correlation, revealing that prototype-based and Barlow regularized LDMs show the best alignment with human perception.", "section": "5.2 Comparing humans and LDM perceptual strategies"}, {"figure_path": "tZRpvLXevU/figures/figures_33_2.jpg", "caption": "Figure 5: Feature importance maps comparison. a) The visualizations include feature importance maps for humans (top row) and LDMs (six bottom rows). All the maps are overlaid on exemplars. Hot vs. cold pixels show image locations that are more vs. less important. Maps for humans were computed using psychophysical data from Boutin et al. [30]. For the LDMs, they are obtained for each category by averaging  (see Eq. 9) over 10 different image variations (x) belonging to the same category. The models' maps are computed on the more human-like LDMs for each regularization (larger data points in Fig. 5). b) Spearman\u2019s rank correlation coefficient between humans and LDMs feature importance maps. The error bar is computed as the standard deviation of the Spearman coefficients over all categories (25 in total). Stars indicate the p-value (*** : p < 10\u22123 and * : p < 5\u00b710\u22122) of pair-wise statistical test between models (Wilcoxon signed-rank test, see A.8.4). The black line corresponds to an LDM without any regularization. The dashed line is the human consistency (0.88), it quantifies how much two populations of humans agree with each other on feature importance maps (see A.8.3 for details on the human consistency computation).", "description": "This figure compares feature importance maps generated by humans and LDMs using different regularizers.  The maps highlight which image regions are most important for object recognition.  Part (a) shows examples of the maps, and part (b) provides a quantitative comparison showing that the prototype-based and Barlow regularizers show the strongest agreement with human perception.", "section": "5.2 Comparing humans and LDM perceptual strategies"}, {"figure_path": "tZRpvLXevU/figures/figures_34_1.jpg", "caption": "Figure A.19: Examples of variations generated by Dall-e 3 when prompted with a single image of a self-balancing bike", "description": "This figure shows the limitations of current Latent Diffusion Models in producing faithful variations when given a single image exemplar.  The example uses a self-balancing bike, an unusual vehicle not frequently represented in image datasets. Dall-E 3 generates variations missing key features of the self-balancing bike concept, such as the single wheel.", "section": "A.8.5 Illustration of the limited one-shot ability of Dall-e"}]