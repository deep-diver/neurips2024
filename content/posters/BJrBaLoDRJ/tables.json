[{"figure_path": "BJrBaLoDRJ/tables/tables_7_1.jpg", "caption": "Table 1: Comparison results on KITTI dataset [13] using the FPFH [26] and FCGF [9] descriptors.", "description": "This table presents a comparison of the proposed method's performance against other state-of-the-art methods on the KITTI dataset for outdoor point cloud registration.  It shows the registration recall (RR), rotation error (RE), and translation error (TE) for both FPFH and FCGF descriptors.  The results highlight the superior performance of the proposed method compared to traditional and learning-based approaches.", "section": "4.3 Evaluation on Outdoor Scenes"}, {"figure_path": "BJrBaLoDRJ/tables/tables_8_1.jpg", "caption": "Table 2: Comparisons results on 3DMatch [44] using FPFH, FCGF, and 3DSmoothNet descriptors.", "description": "This table presents a comparison of the proposed method's performance against state-of-the-art traditional and learning-based methods on the 3DMatch dataset.  The comparison is done using three different types of descriptors: FPFH, FCGF, and 3DSmoothNet. The metrics used for comparison are Registration Recall (RR), Rotation Error (RE), and Translation Error (TE).  Lower values for RE and TE are better, while a higher RR is preferred. The table is divided into two sections: traditional methods and deep learning methods. The \"Time(s)\" column shows the computational time taken by each method.", "section": "4.3 Evaluation on Indoor Scenes"}, {"figure_path": "BJrBaLoDRJ/tables/tables_9_1.jpg", "caption": "Table 3: Registration rate on the 3DLoMatch dataset [17] with different number of correspondences.", "description": "This table presents the registration recall (RR) achieved by different methods on the 3DLoMatch dataset, which contains point clouds with low overlap.  The RR is shown for different numbers of correspondences, allowing for the evaluation of method performance under varying data density.  The Predator descriptor was used for feature extraction in these experiments.", "section": "4.3 Evaluation on Outdoor Scenes"}, {"figure_path": "BJrBaLoDRJ/tables/tables_15_1.jpg", "caption": "Table 1: Comparison results on KITTI dataset [13] using the FPFH [26] and FCGF [9] descriptors.", "description": "This table compares the performance of different point cloud registration methods on the KITTI dataset.  It shows the registration recall (RR), rotation error (RE), and translation error (TE) for both FPFH and FCGF descriptors. The methods are categorized into traditional and deep learning-based approaches.  The table highlights the performance of the proposed method compared to the state-of-the-art.", "section": "4.3 Evaluation on Outdoor Scenes"}, {"figure_path": "BJrBaLoDRJ/tables/tables_18_1.jpg", "caption": "Table 1: Comparison results on KITTI dataset [13] using the FPFH [26] and FCGF [9] descriptors.", "description": "This table compares the performance of different point cloud registration methods on the KITTI dataset.  It shows the registration recall (RR), rotation error (RE), and translation error (TE) for both traditional and deep learning-based methods. Two different feature descriptors, FPFH and FCGF, were used for feature extraction and correspondence establishment.  The results highlight the robustness and accuracy of the proposed method compared to existing approaches.", "section": "4.3 Evaluation on Outdoor Scenes"}, {"figure_path": "BJrBaLoDRJ/tables/tables_19_1.jpg", "caption": "Table 1: Comparison results on KITTI dataset [13] using the FPFH [26] and FCGF [9] descriptors.", "description": "This table compares the performance of different point cloud registration methods on the KITTI dataset.  Two sets of results are shown, one using FPFH descriptors and the other using FCGF descriptors.  The methods compared include traditional methods (FGR, RANSAC, TEASER++, SC2-PCR, MAC, TR-DE, TEAR) and deep learning-based methods (DGR, PointDSC, VBReg). The table shows the registration recall (RR), rotation error (RE), and translation error (TE) for each method.  Lower RE and TE values, and higher RR values indicate better performance.", "section": "4.3 Evaluation on Outdoor Scenes"}, {"figure_path": "BJrBaLoDRJ/tables/tables_19_2.jpg", "caption": "Table 6: Ablation of the number of correspondences in each local set.", "description": "This table presents the results of an ablation study on the number of correspondences (N2) used in each local set for point cloud registration. The study varies N2 from 5 to 20 and reports the registration recall (RR), rotation error (RE), and translation error (TE) for each value of N2.  The purpose is to determine the sensitivity of the proposed method to the choice of N2. The results show that the performance is relatively stable across different values of N2, indicating the robustness of the method.", "section": "A.9 Sensitivity to parameters"}, {"figure_path": "BJrBaLoDRJ/tables/tables_21_1.jpg", "caption": "Table 2: Comparisons results on 3DMatch [44] using FPFH, FCGF, and 3DSmoothNet descriptors.", "description": "This table presents a comparison of the performance of different methods on the 3DMatch dataset for point cloud registration.  It breaks down the results based on three different types of 3D descriptors: FPFH (Fast Point Feature Histograms), FCGF (Fully Convolutional Geometric Features), and 3DSmoothNet. For each descriptor, the table shows the registration recall (RR), rotation error (RE), and translation error (TE) for several methods, including traditional methods (FGR, RANSAC, TEASER++, SC2-PCR, MAC, TR-DE, TEAR) and deep learning-based methods (DGR, PointDSC, VBReg).  The \"Time(s)\" column shows the runtime of each method.  The table is divided into traditional and deep-learned methods, allowing for a direct comparison between these approaches.", "section": "4.3 Evaluation on Indoor Scenes"}]