[{"type": "text", "text": "A robust inlier identification algorithm for point cloud registration via $\\ell_{0}$ -minimization ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yinuo Jiang1\u2217 Xiuchuan Tang2 \u2217 Cheng Cheng1 Ye Yuan1\u2020 ", "page_idx": 0}, {"type": "text", "text": "1School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, China 2Department of Automation, Tsinghua University, China {jiangyinuo,c_cheng,yye}@hust.edu.cn; tangxiuchuan@mail.tsinghua.edu.cn https://github.com/HAIRLAB/inlier-identification-via-l0 ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Correspondences in point cloud registration are prone to outliers, significantly reducing registration accuracy and highlighting the need for precise inlier identification. In this paper, we propose a robust inlier identification algorithm for point cloud registration by reformulating the conventional registration problem as an alignment error $\\ell_{0}$ -minimization problem. The $\\ell_{0}$ -minimization problem is formulated for each local set, where those local sets are built on a compatibility graph of input correspondences. To resolve the $\\ell_{0}$ -minimization, we develop a novel two-stage decoupling strategy, which first decouples the alignment error into a rotation ftiting error and a translation ftiting error. Second, null-space matrices are employed to decouple inlier identification from the estimation of rotation and translation respectively, thereby applying Bayes Theorem to $\\ell_{0}$ -minimization problems and solving for fitting errors. Correspondences with the smallest errors are identified as inliers to generate a transformation hypothesis for each local set. The best hypothesis is selected to perform registration. We demonstrate that the proposed inlier identification algorithm is robust under high outlier ratios and noise through experiments. Extensive results on the KITTI, 3DMatch, and 3DLoMatch datasets demonstrate that our method achieves state-of-the-art performance compared to both traditional and learning-based methods in various indoor and outdoor scenes. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Point cloud registration is a fundamental task in vision and robotics, playing an important role in many applications such as 3D perception and reconstruction, simultaneous localization and mapping (SLAM), and autonomous driving [38, 45, 33]. It aims to align two partially overlapping point clouds by estimating a rigid transformation between them. A common registration pipeline involves extracting features through 3D local descriptors, establishing correspondences based on feature matching, and estimating the rigid transformation [38, 41]. However, due to the less effectiveness of 3D local descriptors in feature extraction [39], correspondences established through feature matching are prone to outliers, resulting in inaccurate registration. ", "page_idx": 0}, {"type": "text", "text": "Recent works in point could registration with outliers can generally be categorized into three groups: learning-based, geometry-only, and optimization-based methods. Learning-based methods [1, 8, 19] use networks to estimate confidence for correspondences and select those with high confidence for transformation estimation. These networks, however, are typically trained on specific scenarios, leading to limited generalization for outlier removal across various datasets [45]. Geometry-only methods [6, 45], such as $\\mathrm{SC^{2}}$ -PCR [6] and MAC [45], filter out outliers using geometric relations between correspondences. Such methods [6, 45] rely on effective geometric features and may not produce acceptable inlier ratios in complex scenes or noisy environments [18]. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "On the other hand, optimization-based methods [4, 5, 18, 40, 46] solve the registration problem by formulating some non-convex objectives [18]. The Branch-and-Bound (BnB) algorithm is widely used to solve non-convex objectives [4, 5, 40] due to its ability to guarantee global optimality. However, the efficiency of BnB is affected by the dimensions of search space and the bounds on objectives [18], which may lead to worst-case exponential time [18, 39]. An alternative approach is to relax the non-convex registration problem into a convex semidefinite program [3, 39]. However, semidefinite relaxation is computationally expensive and may introduce outliers or noise, leading to poor estimation results. Therefore, achieving robust and efficient registration in scenarios with high outlier ratios and noise remains a challenging problem. ", "page_idx": 1}, {"type": "text", "text": "To address these challenges, we propose a robust inlier identification algorithm for point cloud registration, which reformulates the conventional registration problem as an alignment error $\\ell_{0}.$ - minimization problem. More specifically, we define the alignment error and formulate an $\\ell_{0}$ - minimization problem for each local set, where these sets are built from the compatibility graph of input correspondences. To resolve the non-convex $\\ell_{0}$ -minimization problem effectively, we design a two-stage decoupling strategy. First, the alignment error is decoupled into a rotation ftiting error and a translation ftiting error by calculating the relative positions between points. This decoupling results in two fitting error $\\ell_{0}$ -minimization problems with respect to rotation and translation, respectively. Second, null-spaces are introduced to remove rotation or translation from the constraints of fitting error $\\ell_{0}$ -minimization problems, thereby decoupling inlier identification from the estimation of rotation or translation. The final decoupled $\\ell_{0}$ -minimization problems are solved for fitting errors through Bayes Theorem. For each local set, correspondences with the smallest errors are identified as inliers to generate a transformation hypothesis. The best hypothesis is selected to perform registration. ", "page_idx": 1}, {"type": "text", "text": "To the best of our knowledge, we are the first to propose a $\\ell_{0}$ -norm based approach to solve the registration problem. We experimentally demonstrate that the proposed algorithm is robust to high outlier ratios and noise, and is efficient with varying numbers of correspondences. Extensive results on the KITTI, 3DMatch, and 3DLoMatch datasets also demonstrate that our method achieves the highest registration accuracy while being competitive in time efficiency compared to state-of-the-art methods. In summary, our main contributions are as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 A novel robust inlier identification algorithm is proposed by reformulating the conventional registration as an alignment error $\\ell_{0}$ -minimization problem, which can effectively identify inliers and perform accurate registration under high outlier ratios and noise. \u2022 A two-stage decoupling strategy is designed for the proposed $\\ell_{0}$ -minimization problem. This strategy first decouples rotation and translation, and then decouples inlier identification from rotation or translation estimation. A robust Bayesian-based approach is proposed to solve the decoupled $\\ell_{0}$ -minimization problem and identify inliers, enhancing the algorithm\u2019s performance on noisy data. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "3D local descriptors. Early handcrafted descriptors like PFH [27] and FPFH [26] mainly represent local features by encoding geometric histograms [38]. More recent works attempt to encode 3D local descriptors in a data-driven way. FCGF [9] extracts features through a fully convolutional neural network. Predator [17] applies an attention mechanism to extract salient points in overlapping regions of point clouds. 3DMatch [44] and 3DSmoothNet [14] build a Siamese deep learning architecture for extracting local information. Although these feature descriptors achieve significant performance improvements, it is difficult to establish correspondences that are completely free of outliers [6]. Therefore, robust registration is very important for accurate registration. ", "page_idx": 1}, {"type": "text", "text": "Learning-based methods. Inspired by the success of deep learning in 3D perception [34, 32, 37, 29], recent works have adopted learning networks for point cloud registration [1, 8, 19, 20, 44]. Deep global registration (DGR)[8] utilizes sparse convolution and point-by-point MLPs to classify input correspondences. PointDSC[1] explores a spatial consistency-guided non-local inlier classifier to remove outliers. VBReg [19] introduces a variational non-local network for outlier rejection and learns features with Bayesian-driven long-range contextual dependencies. Despite significant advancements in learning-based registration, these methods are designed for specific scenarios and lack generalization across different datasets, which limits their applicability. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Geometry-only and optimization-based methods. Traditional methods have shown great value in practical applications because they are generalized and require no training. They are primarily classified into two categories: geometry-only and optimization-based methods. Geometry-only methods [6, 45, 12] rely on geometric relations and graph-theory frameworks to estimate transformations. $\\mathrm{SC^{2}}$ -PCR [6] uses a second order spatial compatibility measure to compute the similarity between correspondences. MAC [45] loosens the maximum clique constraint to mine more local consensus information in a graph. However, these methods can not guarantee global optimality and may fail under high outlier ratios or noise. Optimization-based methods [46, 39, 5, 19, 35] aim to estimate optimal solutions (in the maximum likelihood sense) for transformations [39]. FGR [46] employs the Geman-McClure cost function and graduated non-convexity to solve the resulting non-convex optimization. Although it is fast and simple, it performs poorly with high outlier ratios [39, 45]. There are also some methods [4, 5, 40] relying on the branch-and-bound (BnB) algorithm for global registration. However, they suffer from high computational complexity and may require exponential time in the worst case [45]. Therefore, achieving robust and efficient registration in scenarios with high outlier ratios and noise remains challenging. ", "page_idx": 2}, {"type": "text", "text": "3 Methods ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 Conventional Point Cloud Registration Problem Statement ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Given the source point cloud $\\mathcal{P}\\ =\\ \\left\\{\\mathbf{p}_{i}\\in\\mathbb{R}^{3}\\ \\vert\\ i=1,\\ldots,N\\right\\}$ and target point cloud $\\mathcal{Q}\\mathbf{\\Lambda}=\\mathbf{\\Lambda}$ $\\left\\{\\mathbf{q}_{i}\\in\\mathbb{R}^{3}\\mid i=1,\\ldots,M\\right\\}$ , the objective of point cloud registration is to align these two point clouds by estimating an optimal rigid transformation $\\mathbf{T}=\\lbrace\\mathbf{R},\\mathbf{t}\\rbrace$ , where $\\ R\\in\\mathrm{SO}(3)$ denotes the rotation matrix and $\\bar{\\mathbf{t}}\\in\\mathbb{R}^{3}$ denotes the translation vector. The transformation is then solved by the following registration problem [5, 25]: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{R},\\mathbf{t}}\\sum_{(\\mathbf{p}_{i},\\mathbf{q}_{i})\\in\\mathcal{C}}\\|\\mathbf{R}\\mathbf{p}_{i}+\\mathbf{t}-\\mathbf{q}_{i}\\|_{2}^{2}\\ ,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mathcal{C}=\\{\\mathbf{c}_{i}\\ |\\ i=1,\\ldots,N_{c}\\}$ is the initial correspondence set. Each correspondence $\\mathbf{c}_{i}=\\left(\\mathbf{p}_{i},\\mathbf{q}_{i}\\right)$ is formed through feature matching, using descriptors extracted from both point clouds. ", "page_idx": 2}, {"type": "text", "text": "3.2 Inlier Identification via $\\ell_{0}$ -minimization ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "However, the initial correspondence set $\\mathcal{C}$ contains a large proportion of outliers due to incorrect feature matching, leading to inaccurate registration. We aim to identify inliers within $\\mathcal{C}$ by solving the proposed alignment error $\\ell_{0}$ -minimization problem. The pipeline of our method is shown in Fig. 1. ", "page_idx": 2}, {"type": "text", "text": "For the input correspondences, we construct a global compatibility graph using the second-order compatibility measure [6], where correspondences are represented as nodes and edges link geometrically compatible nodes [45]. Based on the compatibility scores, we select $N_{1}$ correspondences as reliable seeds, denoted as $\\mathcal{C}_{s}=\\{\\mathbf{c}_{i}~|~i=1,\\ldots,N_{1}\\}$ . For each seed, we identify $N_{2}$ compatible correspondences to form a local set [1] (refer to Appendix A.1 for details). The alignment error $\\ell_{0}$ -minimization problem is formulated for each local set. Specifically, for correspondences in the $k$ -th local set $\\{\\mathbf{c}_{k_{i}}^{\\bar{\\mathbf{\\alpha}}}=(\\mathbf{p}_{k_{i}},\\mathbf{q}_{k_{i}})\\mid i=1,\\ldots,N_{2}\\}$ , the $\\ell_{0}$ -minimization problem is defined as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbf{O}_{k}^{*}=\\arg\\operatorname*{min}_{\\mathbf{O}_{k}}\\|\\mathbf{O}_{k}\\|_{\\ell_{0}}\\,,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where ${\\bf P}_{k}=\\{{\\bf p}_{k}\\}\\in\\mathbb{R}^{N_{2}\\times3}$ and ${\\bf Q}_{k}=\\left\\{{\\bf q}_{k}\\right\\}\\in\\mathbb{R}^{N_{2}\\times3}$ denote the source and target points in the $k$ -th local set. $\\mathbf{O}_{k}$ represents the introduced alignment error, $\\Xi_{k}$ represents the Gaussian noise, and 1 is a column vector of ones, ensuring the translation vector $\\mathbf{t}$ is applied to each point in $\\mathbf{P}_{k}$ . The alignment error $\\mathbf{O}_{k}$ also serves as an inlier indicator. If the $i$ -th correspondence $\\mathbf{c}_{k_{i}}=(\\mathbf{p}_{k_{i}},\\mathbf{q}_{k_{i}})$ is an inlier (i.e., it satisfies $|\\mathbf{R}\\mathbf{p}_{k_{i}}+\\mathbf{t}-\\mathbf{q}_{k_{i}}|\\leq\\xi_{k_{i}}$ with the Gaussian noise $\\xi_{k_{i}}$ ), $\\mathbf{o}_{k_{i}}$ should ideally be a zero vector. Consequently, the indices of zero vectors in the solution $\\mathbf{O}_{k}^{*}$ of Eq. (2) correspond to the inlier indices in the $k$ -th set. The formulations for other local sets are defined in a similar way. ", "page_idx": 2}, {"type": "image", "img_path": "BJrBaLoDRJ/tmp/5581d4e38b25c2346bfe2cd56d1c8abb947203d403ad536b8cc8bbdfae98ba29.jpg", "img_caption": ["Figure 1: Pipeline of our method. 1. Define alignment errors and formulate the $\\ell_{0}$ -minimization problem for each local set. 2. Decouple alignment error into rotation and translation fitting errors and decouple inlier identification from the estimation of rotation or translation through the Bayes Theorem. 3. Select the best hypothesis for registration. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "A key insight into our approach is the use of $\\ell_{0}$ norm to optimize alignment errors. This is based on the principle that only inliers can be fitted by the same transformation [5], and the optimal transformation is estimated as the one that ftis the largest number of inlier correspondences. Therefore, our optimization objective is to maximize the count of zero vectors in the alignment error. Compared to the common formulations for point cloud registration [18], such as consensus maximization [5, 7] and truncated least-squares [39], our formulation reduces the impact of outliers through $\\ell_{0}$ norm. The focus of this norm is to minimize the number of non-zero vectors rather than their magnitudes, thereby enhancing the robustness of our method to outliers and noise. ", "page_idx": 3}, {"type": "text", "text": "3.3 Two-stage Decoupling Strategy ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To resolve the proposed $\\ell_{0}$ -minimization problem, we design a two-stage decoupling strategy. The solution process is described for the $k$ -th local set and similarly applied to other local sets. ", "page_idx": 3}, {"type": "text", "text": "Decoupling the alignment error into rotation and translation fitting errors. Simultaneously estimating the rigid transformation with 6 degrees of freedom (DOF) is time-consuming due to the high-dimensional parameter space [5, 39]. To effectively resolve the $\\ell_{0}$ -minimization problem proposed in Eq. (2) for each local set, we decouple the 6-DOF transformation into 3-DOF rotation and 3-DOF translation by computing the relative positions between point pairs. For any two given points $\\mathbf{p}_{k_{i}}$ and $\\mathbf{q}_{k_{j}}$ in the $k$ -th local set, the translation vector $\\mathbf{t}_{k}$ cancels out in the subtraction [39]: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{q}_{k_{j}}-\\mathbf{q}_{k_{i}}=\\mathbf{R}_{k}\\left(\\mathbf{p}_{k_{j}}-\\mathbf{p}_{k_{i}}\\right)+\\left(\\mathbf{o}_{k_{j}}-\\mathbf{o}_{k_{i}}\\right)+\\left(\\xi_{k_{j}}-\\xi_{k_{i}}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Based on Eq. (3), we define $\\bar{\\mathbf{q}}_{k_{i j}}=\\mathbf{q}_{k_{j}}-\\mathbf{q}_{k_{i}}$ and $\\bar{\\mathbf{p}}_{k_{i j}}=\\mathbf{p}_{k_{j}}-\\mathbf{p}_{k_{i}}$ as the relative positions. $\\bar{\\mathbf{o}}_{k_{i j}}=$ $\\mathbf{o}_{k_{j}}-\\mathbf{o}_{k_{i}}$ represents the rotation ftiting error to minimize, unaffected by translation. $\\bar{\\xi}_{k_{i j}}=\\xi_{k_{j}}-\\xi_{k_{i}}$ is the Gaussian noise. If both the $i$ -th and $j$ -th correspondences are inliers, $\\bar{\\mathbf{o}}_{k_{i j}}$ should ideally be a zero vector. Therefore, the rotation fitting error $\\bar{\\mathbf{o}}_{k_{i j}}$ for the correspondence pair $\\mathbf{c}_{k_{i}}=(\\mathbf{p}_{k_{i}},\\mathbf{q}_{k_{i}})$ and $\\mathbf{c}_{k_{j}}=(\\mathbf{p}_{k_{j}},\\mathbf{q}_{k_{j}})$ is formulated as: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\bar{\\mathbf{o}}_{k_{i j}}=\\bar{\\mathbf{q}}_{k_{i j}}-\\mathbf{R}_{k}\\bar{\\mathbf{p}}_{k_{i j}}-\\bar{\\xi}_{k_{i j}}\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Having decoupled rotation from translation, we can now formulate the $\\ell_{0}$ -minimization problem for the rotation fitting error $\\bar{\\bf O}_{k}$ in the $k$ -th local set, focusing on the 3-DOF rotation $\\mathbf{R}_{k}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\bar{\\mathbf{O}}_{k}^{*}=\\arg\\operatorname*{min}_{\\bar{\\mathbf{O}}_{k}}\\|\\bar{\\mathbf{O}}_{k}\\|_{\\ell_{0}}\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\bar{\\mathbf{Q}}_{k}\\in\\mathbb{R}^{\\bar{N}\\times3}$ and $\\bar{\\mathbf{P}}_{k}\\in\\mathbb{R}^{\\bar{N}\\times3}$ are relative positions between all point pairs in $\\mathbf{Q}_{k}$ and $\\mathbf{P}_{k}$ , respectivel y. Here, $\\begin{array}{r}{\\bar{N}=\\frac{N_{2}(N_{2}-1)}{2}}\\end{array}$ is the number of relative point pairs in a local set. The Gaussian noise $\\bar{\\Xi}_{k}$ is modeled as $\\mathcal{N}(0,\\lambda_{R}\\mathbf{I})$ , where $\\lambda_{R}$ indicates the variance. ", "page_idx": 4}, {"type": "text", "text": "Once obtaining the rotation estimate ${\\bf R}_{k}^{*}$ by solving Eq. (5), we can substitute it back into Eq. (2) to estimate the translation. The $\\ell_{0}$ -minimization problem for the translation fitting error $\\hat{\\mathbf{O}}_{k}$ is formulated as follows, focusing on the 3-DOF translation $\\mathbf{t}_{k}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{\\mathbf{O}}_{k}^{*}=\\arg\\operatorname*{min}_{\\hat{\\mathbf{O}}_{k}}\\|\\hat{\\mathbf{O}}_{k}\\|_{\\ell_{0}}\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\Xi_{k}$ is modeled as $\\mathcal{N}(0,\\lambda_{t}\\mathbf{I})$ , where $\\lambda_{t}$ indicates the variance of Gaussian noise. The translation $\\mathbf{t}_{k}^{\\ast}$ is estimated by solving Eq. (6). ", "page_idx": 4}, {"type": "text", "text": "Decoupling rotation estimation from $\\ell_{0}$ -minimization. Optimizing the estimation of rotation while simultaneously identifying inliers is a chicken-and-egg problem, because reliable identification of inliers depends on the precise rotation estimation (as shown in Eq. (5)). To address this, we further decouple inlier identification from the estimation of rotation. The inliers that can be fitted by the same rotation are identified through Bayes Theorem and used for the subsequent rotation estimation. ", "page_idx": 4}, {"type": "text", "text": "We incorporate a robust Bayesian approach to solve Eq. (5), improving the algorithm\u2019s robustness to noisy data [42]. The key step is to define a null-space matrix $\\bar{\\Theta}_{k}^{\\,\\!}$ , whose rows form a basis for the left null space of $\\bar{\\mathbf{P}}_{k}$ . By left-multiplying each term in the constraint of Eq. (5) with $\\bar{\\Theta}_{k}$ , the component associated with the rotation $\\mathbf{R}_{k}$ is eliminated: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\bar{\\Theta}_{k}\\bar{\\mathbf O}_{k}=\\bar{\\Theta}_{k}\\bar{\\mathbf Q}_{k}-\\bar{\\Theta}_{k}\\bar{\\Xi}_{k}\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\bar{\\Theta}_{k}\\bar{\\mathbf{O}}_{k}$ represents the transformed rotation fitting error. Given that $\\bar{\\Xi}_{k}$ is Gaussian noise and the left-multiplication by $\\bar{\\Theta}_{k}$ is a linear operation, $\\bar{\\Theta}_{k}\\breve{\\Xi}_{k}$ also follows a Gaussian distribution with a covariance matrix of $\\lambda_{R}\\bar{\\Theta}_{k}\\bar{\\Theta}_{k}^{T}$ . The likelihood is formulated as: ", "page_idx": 4}, {"type": "equation", "text": "$$\nP(\\tilde{\\mathbf{Q}}_{k}\\mid\\tilde{\\mathbf{O}}_{k})=\\mathcal{N}(\\bar{\\mathbf{Q}}_{k}\\bar{\\mathbf{O}}_{k},\\lambda_{R}\\bar{\\mathbf{I}}\\mathbf{\\bar{I}}_{k})\\propto\\exp\\left[-\\frac{1}{2\\lambda_{R}}\\left\\|(\\tilde{\\mathbf{Q}}_{k}-\\bar{\\mathbf{Q}}_{k}\\bar{\\mathbf{O}}_{k})^{T}\\bar{\\mathbf{I}}_{k}^{-1}(\\tilde{\\mathbf{Q}}_{k}-\\bar{\\mathbf{Q}}_{k}\\bar{\\mathbf{O}}_{k})\\right\\|_{F}^{2}\\right]\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\tilde{\\bar{\\mathbf{Q}}}_{k}=\\bar{\\Theta}_{k}\\bar{\\mathbf{Q}}_{k}$ and $\\bar{\\Theta}_{k}\\bar{\\Theta}_{k}^{T}=\\bar{\\Pi}_{k}$ . Based on the Bayes Theorem and Maximum A Posteriori (MAP) estimate, the unconstrained optimization for rotation fitting error $\\ell_{0}$ -minimization in Eq. (5) is redefined as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\bar{\\mathbf{O}}_{k}}\\frac{1}{2}\\left\\|(\\tilde{\\bar{\\mathbf{Q}}}_{k}-\\bar{\\boldsymbol{\\Theta}}\\bar{\\boldsymbol{\\mathbf{O}}}_{k})^{T}\\bar{\\boldsymbol{\\Pi}}_{k}^{-1}(\\tilde{\\bar{\\mathbf{Q}}}_{k}-\\bar{\\boldsymbol{\\Theta}}_{k}\\bar{\\boldsymbol{\\mathbf{O}}}_{k})\\right\\|_{F}^{2}+\\lambda_{R}\\left\\|\\bar{\\boldsymbol{\\mathbf{O}}}_{k}\\right\\|_{\\ell_{0}}^{2}\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\lambda_{R}$ is the regularization parameter that trades off the fitting error and model complexity. However, since the formulation incorporating the $\\ell_{0}$ norm is known to be computationally expensive, we use the following convex relaxation: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\bar{\\mathbf{O}}_{k}}\\frac{1}{2}\\left\\|(\\tilde{\\bar{\\mathbf{Q}}}_{k}-\\bar{\\boldsymbol{\\Theta}}\\bar{\\mathbf{O}}_{k})^{T}\\bar{\\boldsymbol{\\Pi}}_{k}^{-1}(\\tilde{\\bar{\\mathbf{Q}}}_{k}-\\bar{\\boldsymbol{\\Theta}}_{k}\\bar{\\mathbf{O}}_{k})\\right\\|_{F}^{2}+\\lambda_{R}\\left\\|\\bar{\\mathbf{O}}_{k}\\right\\|_{F}^{2}\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\|\\cdot\\|_{F}$ is the Frobenius norm ( $F$ norm), which is both differentiable and convex. To find the optimal solution, we set the gradient of the objective function with respect to $\\bar{\\bf O}_{k}$ to zero: ", "page_idx": 4}, {"type": "equation", "text": "$$\n-\\bar{\\Theta}_{k}^{T}\\bar{\\Pi}_{k}^{-1}\\big(\\tilde{\\bar{\\bf Q}}_{k}-\\bar{\\Theta}_{k}\\bar{\\bf O}_{k}\\big)+2\\lambda_{R}\\bar{\\bf O}_{k}=0\\,.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The optimal explicit solution $\\bar{\\mathbf{O}}_{k}^{*}$ can be directly calculated as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\bar{\\bf O}_{k}^{*}=(\\bar{\\bf\\Theta}_{k}^{T}\\bar{\\bf H}_{k}^{-1}\\bar{\\bf\\Theta}_{k}+2\\lambda_{R}{\\bf I})_{k}^{-1}\\bar{\\bf\\Theta}_{k}^{T}\\bar{\\bf H}_{k}^{-1}\\tilde{\\bf\\tilde{Q}}_{k}\\,.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Based on $\\bar{\\mathbf{O}}_{k}^{*}$ , we identify top- $\\cdot K_{R}$ correspondences with minimal rotation fitting error for accurate rotation estimation. These correspondences, indexed by $\\mathcal{T}_{R}$ , provide the basis for estimating rotation from the SVD decomposition of the matrix $H=U\\dot{\\Sigma}V^{T}\\,\\in\\,\\mathbb{R}^{3\\times3}$ [23]. For the $k$ -th local set, the rotation hypothesis is estimated as [5, 2]: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\boldsymbol{H}=\\sum_{(i,j)\\in\\mathbb{Z}_{R}}\\bar{\\mathbf{P}}_{k_{i}}\\bar{\\mathbf{Q}}_{k_{j}}^{T}\\,,\\,\\,\\mathbf{R}_{k}^{*}=U\\operatorname{diag}\\left(1,1,\\operatorname*{det}\\left(U V^{T}\\right)\\right)V\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Decoupling translation estimation from $\\ell_{0}$ -minimization. Employing a strategy similar to that used for rotation estimation, we utilize a null-space matrix $\\Theta_{k}$ that satisfies $\\mathbf{\\Theta}_{\\epsilon}\\mathbf{1}=\\mathbf{0}$ to isolate the translation. By applying $\\Theta_{k}$ to the transpose of the constraint in Eq. (6), we eliminate the components associated with translation ${\\bf t}_{k}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Theta_{k}\\hat{\\mathbf{O}}_{k}^{T}=\\Theta_{k}\\big(\\mathbf{Q}_{k}-\\mathbf{P}_{k}\\mathbf{R}_{k}^{*}\\big)^{T}-\\Theta_{k}\\Xi_{k}^{T}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Incorporating the Bayes Theorem, we formulate the following convex relaxation for the unconstrained optimization problem: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\hat{\\mathbf{O}}_{k}}\\frac{1}{2}\\left\\|(\\mathbf{X}_{k}-\\Theta_{k}\\hat{\\mathbf{O}}_{k}^{T})^{T}\\mathbf{H}_{k}^{-1}(\\mathbf{X}_{k}-\\Theta_{k}\\hat{\\mathbf{O}}_{k}^{T})\\right\\|_{F}^{2}+\\lambda_{t}\\left\\|\\hat{\\mathbf{O}}_{k}\\right\\|_{F}^{2}\\,,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\mathbf{X}_{k}=\\Theta_{k}(\\mathbf{Q}_{k}^{T}-(\\mathbf{P}_{k}\\mathbf{R}_{k}^{*})^{T})$ and $\\mathbf{I}\\mathbf{I}_{k}=\\pmb{\\Theta}_{k}\\pmb{\\Theta}_{k}^{T}$ . The explicit solution $\\hat{\\mathbf{O}}_{k}^{*}$ is obtained by solving the gradient of the objective function with respect to $\\hat{\\mathbf{O}}_{k}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\hat{\\mathbf{O}}_{k}^{*}=((2\\lambda_{t}\\mathbf{I}+\\Theta_{k}^{T}\\mathbf{I}\\mathbf{I}_{k}^{-1}\\Theta_{k})^{-1}\\Theta_{k}^{T}\\mathbf{I}\\mathbf{I}_{k}^{-1}\\mathbf{X}_{k})^{T}\\,,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where I denotes the identity matrix. Using $\\hat{\\mathbf{O}}_{k}^{*}$ , top- $\\cdot K_{t}$ correspondences with the smallest errors are identified as inliers for translation estimation. Their index set is denoted as $\\mathcal{T}_{t}$ . The translation hypothesis $\\mathbf{t}_{k}^{\\ast}$ for the $k$ -th local set is estimated based on these inliers $(\\mathbf{p}_{k_{i}},\\mathbf{q}_{k_{j}})$ , with $(i,j)\\in\\mathcal{T}_{t}$ . ", "page_idx": 5}, {"type": "text", "text": "3.4 Hypothesis Selection ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Finally, we evaluate and select the best estimation from the transformation hypotheses computed for all local sets: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\left(\\mathbf{R}^{*},\\mathbf{t}^{*}\\right)=\\arg\\operatorname*{max}_{\\mathbf{R}_{k}^{*},\\mathbf{t}_{k}^{*}}\\sum_{i=1}^{N}\\left[\\left\\|\\mathbf{R}_{k}^{*}\\mathbf{p}_{i}+\\mathbf{t}_{k}^{*}-\\mathbf{q}_{i}\\right\\|_{2}<\\tau\\right]\\,,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $N_{c}$ is the number of input initial correspondences and $\\tau$ is a predefined error threshold. For each transformation hypothesis, we quantify its effectiveness by counting the number of correspondences that satisfy the constraints within $\\tau$ . The transformation with the highest inlier count is selected for registration. ", "page_idx": 5}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "4.1 Datasets and Experimental Setup ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Synthetic dataset. We evaluate the accuracy, robustness, and efficiency of our algorithm using the Bunny point cloud from the Stanford 3D Scan Repository [10]. Similar to [5, 39], the Bunny model is downsampled to $N_{c}$ points and resized to fit a $[0,1]^{3}$ cube, creating the source point cloud $\\mathcal{P}$ . To generate the target point cloud $\\mathcal{Q}_{\\mathrm{.}}$ , a random transformation $(\\mathbf{R},\\mathbf{t})$ is applied to $\\mathcal{P}$ and then Gaussian noise $\\epsilon_{i}\\sim\\mathcal{N}(\\bar{0_{,}}\\sigma^{\\dot{2}}\\mathbf{I}_{3})$ is added. A pair of the original and moved points defines an inlier. The inliers are contaminated with outliers generated by random transformations. ", "page_idx": 5}, {"type": "text", "text": "Outdoor scenes. For evaluations on outdoor scenes, we conduct experiments on the KITTI dataset [13]. Following [5, 6], we use 555 pairs of point clouds from scenes 8 to 10 for testing. We construct a $30\\mathrm{cm}$ voxel grid to downsample point clouds and form correspondences using handcrafted FPFH [26] and learned FCGF [9] descriptors. ", "page_idx": 5}, {"type": "text", "text": "Indoor scenes. We conduct experiments on the 3DMatch dataset [44] to evaluate performance on indoor scenes. Following [5, 6, 45], we use RGB-D scans from 8 real indoor scenes for testing. The point clouds are downsampled using a 5cm voxel grid. We use the hand-crafted FPFH [26] along with two learned descriptors, FCGF [26] and 3DSmoothNet [14], for feature extraction. To evaluate our method in more challenging scenarios, we conduct experiments on 3DLoMatch [17] (overlap rate between scenes $<30\\%$ ). Following [5, 19], the Predator descriptor [17] is used in 3DLoMatch. ", "page_idx": 5}, {"type": "image", "img_path": "BJrBaLoDRJ/tmp/3a8d88c914f4174caaff9016f7ead37991cdca2e4d40f682cb2739b797db4c4b.jpg", "img_caption": ["Figure 2: Robustness to outliers. The first row compares the rotation and translation errors as the outlier ratio increases from $10\\%$ to $90\\%$ on the Bunny dataset [10], while the second row focuses on the scenarios of extreme outliers, i.e., the outlier ratio varies from $91\\%$ to $99\\%$ . Our method demonstrates to be more robust to outliers compared to other methods [4, 12, 39, 45, 46]. "], "img_footnote": [], "page_idx": 6}, {"type": "image", "img_path": "BJrBaLoDRJ/tmp/5246b713668333bb4e8664099fcbb5cf86cb94dcfc85b882922dea57ac7ec238.jpg", "img_caption": ["Figure 3: Robustness to noise. Comparison results with [4, 12, 39, 45, 46] as the noise standard deviation increases from 0.01 to 0.09 on the Bunny dataset [10]. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Evaluation criteria. Following [5, 39], we use the rotation error (RE), translation error (TE), and registration recall (RR) as evaluation metrics. The registration is considered successful when the $\\mathrm{RE}\\le15^{\\circ}$ , $\\mathrm{TE}\\leq30\\mathrm{cm}$ on 3DMatch & 3DLoMatch datasets, and $\\mathrm{RE}\\le5^{\\circ}$ , $\\mathrm{TE}\\leq60\\mathrm{cm}$ on KITTI dataset. Average RE and TE are computed only on the successfully registered pairs [5, 6]. ", "page_idx": 6}, {"type": "text", "text": "Implementation details. We implement our method in PyTorch [24]. All the experiments are conducted on a machine with an Intel Xeon Gold 6134 CPU and a single NVIDIA GTX3090. ", "page_idx": 6}, {"type": "text", "text": "4.2 Evaluation on Synthetic Dataset ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Robustness to outliers. We evaluate the robustness to outliers by increasing the outlier ratio from $10\\%$ to $90\\%$ . The Bunny point cloud is downsampled to $N_{c}=500$ . We add zero-mean Gaussian noise with a standard deviation set to $\\sigma=0.01$ . For each outlier ratio, we conduct 50 independent trials and report the average rotation error (RE) and translation error (TE). We compare our method with state-of-the-art traditional methods [4, 12, 39, 45, 46]. As shown in the first row of Fig. 2, the rotation and translation errors of FGR [46] increase sharply as the proportion of outliers increases. RANSAC [12] and GORE [4] start failing at an outlier ratio of $60\\%$ . Our method remains robust to outliers up to $90\\%$ and produces more accurate estimates than all other methods. We further compare the performance of different methods under extreme outlier ratios, i.e., when the outlier ratio increases from $91\\%$ to $99\\%$ . The second row of Fig. 2 shows that even with outlier ratios as high as $99\\%$ , our method continues to perform well, consistently producing lower transformation errors than other methods. ", "page_idx": 6}, {"type": "image", "img_path": "BJrBaLoDRJ/tmp/81b37798be67c7ec1a3968e34c7e83f051f7168978517818fcc2bb5e73e10286.jpg", "img_caption": ["Figure 4: Efficiency and effectiveness. The experiment results on the Bunny dataset [10]. (a) Efficiency comparison with other methods [4, 12, 39, 45, 46] with respect to the number of correspondences. (b) Comparison of the proposed two-stage decoupling strategy (TDS) with optimization-based methods at an outlier ratio of $90\\%$ . "], "img_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "BJrBaLoDRJ/tmp/27a0b69446d716564c69776680e79d081818b1887415155b75925e93f752f502.jpg", "table_caption": ["Table 1: Comparison results on KITTI dataset [13] using the FPFH [26] and FCGF [9] descriptors. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Robustness to noise. We further evaluate the robustness against Gaussian noise with different variances. As the noise standard deviation increases from $\\sigma\\,=\\,0.01$ to $\\sigma\\,=\\,0.1$ , the geometric structure of the Bunny model is completely destroyed [39] (refer to Appendix A.5). Fig. 3 shows the comparison results as $\\sigma$ increases from 0.01 to 0.09. When the noise variance reaches 0.03, the translation errors of geometric-only method MAC [45] significantly increase. Both FGR [46] and RANSAC [12] show large rotation errors when $\\sigma$ increases to 0.05. In contrast, our method achieves the lowest rotation and translation errors under high noise, demonstrating its robustness to noise. ", "page_idx": 7}, {"type": "text", "text": "Efficiency and accuracy. We increase the number of correspondences $N_{c}$ from 250 to 5000 to compare efficiency and accuracy. We set the noise standard deviation $\\sigma$ to 0.01 and the outlier ratio to $50\\%$ . The comparison results are shown in Fig. 4(a). As the number of correspondences increases, the running time of GORE [4] and $\\mathrm{TEASER++}$ [39] increases significantly. Notably, when $N_{c}$ grows to 2500, the running time of GORE is about $10^{4}$ times longer than that of our method. Our method solves the $\\ell_{0}$ -minimization problems with explicit solutions, significantly enhancing efficiency through parallel matrix computations and GPU execution. The curves of FGR, RANSAC, MAC, and our method in Fig. 4(a) are flat and difficult to visually distinguish, indicating the efficiency of these methods. However, as shown in Appendix A.6, our method outperforms FGR [46], RANSAC [12], and MAC [45] in registration accuracy. Therefore, our inlier identification algorithm via $\\ell_{0}$ -minimization is efficient while maintaining high accuracy. ", "page_idx": 7}, {"type": "text", "text": "Effectiveness of the two-stage decoupling strategy. We evaluate the effectiveness of the twostage decoupling strategy (TDS) by formulating the $\\ell_{0}$ -minimization problem directly on the Bunny data instead of local sets and estimating the final rotation and translation. Specifically, we set $N_{c}=100$ and $\\sigma\\,=\\,0.01$ . As shown in Fig. 4(b), we compare the TDS with optimization-based methods [4, 12, 39, 46] at an outlier ratio of $90\\%$ . Our TDS achieves the highest registration accuracy, demonstrating its inlier identification capability. Additional competitive results as the outlier ratio increases from $0\\%$ to $90\\%$ are provided in Appendix A.7. ", "page_idx": 7}, {"type": "image", "img_path": "BJrBaLoDRJ/tmp/feaabb6784f1ab2f7ab4d43473988710d1d6715c5a0919fa0230ddd13efe9f33.jpg", "img_caption": ["Figure 5: Qualitative comparisons with other methods. Qualitative comparisons on the 3DMatch (the first row) and 3DLoMatch (the second row) datasets. "], "img_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "BJrBaLoDRJ/tmp/6b4448d7dc146d4ec6084054730b006be5f74b274c3d558c0e2cc9cd7f6224a7.jpg", "table_caption": ["Table 2: Comparisons results on 3DMatch [44] using FPFH, FCGF, and 3DSmoothNet descriptors. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "4.3 Evaluation on Outdoor Scenes ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "To evaluate our algorithm on real outdoor scenes, we conduct experiments on the KITTI dataset [13]. The comparison results with state-of-the-art traditional [5, 6, 12, 18, 39, 45, 46] and learningbased [1, 8, 19] methods are reported in Table 1. We first use the FPFH [26] descriptor to generate initial correspondences. As shown in the left column of Table 2, our method outperforms traditional and learning-based methods on all metrics. For the most important criterion of registration recall (RR), our method improves by about $2\\%$ over the nearest competitor MAC [45]. Following [6], the average RE and TE are only calculated on successfully registered pairs, which makes methods with high registration recall more likely to have larger average errors. Nonetheless, our method still achieves the best results on RE and TE. Besides, we report the comparison results with the FCGF [9] descriptor in the right column of Table 2. Our method achieves the highest RR and the lowest RE due to its effective inlier identification algorithm. The superior performance demonstrates the ability of our method to align sparse and non-uniformly distributed data in outdoor scenes. In addition to its high accuracy, our method also achieves comparable efficiency, making it highly competitive for practical applications. The visualizations of registration results on KITTI are provided in Appendix A.12. ", "page_idx": 8}, {"type": "text", "text": "4.4 Evaluation on Indoor Scenes ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We further conduct experiments on the 3DMatch [44] and 3DLoMatch [17] datasets to evaluate the performance in real indoor scenes. The comparison results are reported in Table 2 and Table 3. ", "page_idx": 8}, {"type": "text", "text": "Combined with FPFH, FCGF, and 3DSmoothNet descriptors. As shown in the left column of Table 2, compared to both traditional and learning-based methods, our method achieves the highest RR with the handcrafted FPFH [26] descriptor. The middle column of Table 2 reports the comparison results with the learned FCGF [9] descriptor. Our method achieves the lowest RE and TE. Compared to $\\mathrm{{SC^{2}}}$ -PCR [6], our method improves the RR, RE, and TE by $0.13\\%$ , $0.97\\%$ , and $0.77\\%$ respectively, which benefit from our $\\ell_{0}$ -minimization formulation for inlier identification. Since TR-DE [5] and TEAR [18] have not made their code or results for FPFH and FCGF publicly available, their results are excluded in the left and middle columns of Table 2. Following [18], we also compare the registration accuracy using the learned 3DSmoothNet [14] to extract features. The results in the right column of Table 2 show that our method outperforms all other methods across all evaluation metrics, demonstrating the robustness of our method to different local descriptors. We show the results of qualitative comparisons in Fig. 5 and Appendix A.12. Methods such as MAC may fail in scenes with ambiguous features or limited overlap. Our algorithm still achieves satisfactory alignment and is close to the ground truth. ", "page_idx": 8}, {"type": "image", "img_path": "BJrBaLoDRJ/tmp/ae48007f7c876e7d36464662fad91ba274a85657d046606e15ea98e03d20589f.jpg", "img_caption": ["Figure 6: Comparison results on output inlier ratio. We compare the predicted inlier counts of correct and incorrect correspondences in 3DLoMatch [17]. The first column provides the ground truth alignment, which shows that overlap is very limited. The significantly larger inlier ratio can be observed from the incorrect (red lines) and correct (green lines) correspondences. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Robust to lower overlap ratios. Furthermore, we report results for a more challenging dataset: 3DLoMatch [17] (overlap rate $<30\\%$ ). Following [5, 19], we use the Predator [17] descriptor to generate the initial correspondences. We compare the registration recall (RR) under different numbers of correspondences. As shown in Table 3, the proposed method improves the average RR by $7\\%$ over TR-DE [5], demonstrating the effectiveness of our method in dealing with ", "page_idx": 9}, {"type": "table", "img_path": "BJrBaLoDRJ/tmp/888e147b3939b37aff75987a0e8b296c0d4684a8d402cc9ec9b4bffc93274088.jpg", "table_caption": ["Table 3: Registration rate on the 3DLoMatch dataset [17] with different number of correspondences. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "low-overlap scenarios. In Fig. 6, we compare the output inlier ratio with traditional methods [6, 39, 45] in the low overlap scenario. Our method is more effective with more correct predicted inliers. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we propose a robust inlier identification algorithm by reformulating the conventional registration problem as an alignment error $\\ell_{0}$ -minimization problem. For each local set, we resolve the $\\ell_{0}$ -minimization problem using a designed two-stage decoupling strategy. First, the alignment error is decoupled to a rotation ftiting error and a translation ftiting error, formulating two decoupled $\\ell_{0}$ -minimization problems. Second, null-space matrices are introduced to decouple the inlier identification from the estimation of rotation or translation respectively, there by applying a robust Bayesian approach to decoupled $\\ell_{0}$ -minimization problems and solving for fitting errors. Correspondences with the smallest errors are identified as inliers to generate a transformation hypothesis for each local set. We experimentally demonstrate that the proposed algorithm is robust to high outlier ratios and noise. Extensive results on the KITTI, 3DMatch, and 3DLoMatch datasets also demonstrate that our method achieves state-of-the-art registration accuracy while being comparable in efficiency in both indoor and outdoor scenes. Limitations and broader impact are discussed in Appendix A.10. ", "page_idx": 9}, {"type": "text", "text": "6 Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported by the National Natural Science Foundation of China (Grant numbers 92167201, 52188102, 62373160). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Bai, X., Luo, Z., Zhou, L., Chen, H., Li, L., Hu, Z., Fu, H., Tai, C.L., 2021. Pointdsc: Robust point cloud registration using deep spatial consistency, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 15859\u201315869.   \n[2] Besl, P.J., McKay, N.D., 1992. Method for registration of 3-d shapes, in: Sensor fusion IV: control paradigms and data structures, Spie. pp. 586\u2013606. [3] Briales, J., Gonzalez-Jimenez, J., 2017. Convex global 3d registration with lagrangian duality, in: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4960\u20134969.   \n[4] Bustos, A.P., Chin, T.J., 2017. Guaranteed outlier removal for point cloud registration with correspondences. IEEE transactions on pattern analysis and machine intelligence 40, 2868\u20132882.   \n[5] Chen, W., Li, H., Nie, Q., Liu, Y.H., 2022a. Deterministic point cloud registration via novel transformation decomposition, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 6348\u20136356.   \n[6] Chen, Z., Sun, K., Yang, F., Tao, W., 2022b. Sc2-pcr: A second order spatial compatibility for efficient and robust point cloud registration, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 13221\u201313231.   \n[7] Chin, T.J., Suter, D., 2022. The maximum consensus problem: recent algorithmic advances. Springer Nature.   \n[8] Choy, C., Dong, W., Koltun, V., 2020. Deep global registration, in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 2514\u20132523.   \n[9] Choy, C., Park, J., Koltun, V., 2019. Fully convolutional geometric features, in: Proceedings of the IEEE/CVF international conference on computer vision, pp. 8958\u20138966.   \n[10] Curless, B., Levoy, M., 1996. A volumetric method for building complex models from range images, in: Proceedings of the 23rd annual conference on Computer graphics and interactive techniques, pp. 303\u2013312.   \n[11] Dai, A., Nie\u00dfner, M., Zollh\u00f6fer, M., Izadi, S., Theobalt, C., 2017. Bundlefusion: Real-time globally consistent 3d reconstruction using on-the-fly surface reintegration. ACM Transactions on Graphics (ToG) 36, 1.   \n[12] Fischler, M.A., Bolles, R.C., 1981. Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography. Communications of the ACM 24, 381\u2013395.   \n[13] Geiger, A., Lenz, P., Urtasun, R., 2012. Are we ready for autonomous driving? the kitti vision benchmark suite, in: 2012 IEEE conference on computer vision and pattern recognition, IEEE. pp. 3354\u20133361.   \n[14] Gojcic, Z., Zhou, C., Wegner, J.D., Wieser, A., 2019. The perfect match: 3d point cloud matching with smoothed densities, in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 5545\u20135554.   \n[15] Guo, J., Wang, Q., Park, J.H., 2020. Geometric quality inspection of prefabricated mep modules with 3d laser scanning. Automation in Construction 111, 103053.   \n[16] Halber, M., Funkhouser, T., 2017. Fine-to-coarse global registration of rgb-d scans, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1755\u20131764.   \n[17] Huang, S., Gojcic, Z., Usvyatsov, M., Wieser, A., Schindler, K., 2021. Predator: Registration of 3d point clouds with low overlap, in: Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition, pp. 4267\u20134276.   \n[18] Huang, T., Peng, L., Vidal, R., Liu, Y.H., 2024. Scalable 3d registration via truncated entry-wise absolute residuals. arXiv preprint arXiv:2404.00915 .   \n[19] Jiang, H., Dang, Z., Wei, Z., Xie, J., Yang, J., Salzmann, M., 2023. Robust outlier rejection for 3d registration with variational bayes, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1148\u20131157.   \n[20] Jiang, Y., Zhou, B., Liu, X., Li, Q., Cheng, C., 2024. Gtinet: Global topology-aware interactions for unsupervised point cloud registration. IEEE Transactions on Circuits and Systems for Video Technology .   \n[21] Lai, K., Bo, L., Fox, D., 2014. Unsupervised feature learning for 3d scene labeling, in: 2014 IEEE International Conference on Robotics and Automation (ICRA), IEEE. pp. 3050\u20133057.   \n[22] Mises, R., Pollaczek-Geiringer, H., 1929. Praktische verfahren der gleichungsaufl\u00f6sung. ZAMM-Journal of Applied Mathematics and Mechanics/Zeitschrift f\u00fcr Angewandte Mathematik und Mechanik 9, 58\u201377.   \n[23] Papadopoulo, T., Lourakis, M.I., 2000. Estimating the jacobian of the singular value decomposition: Theory and applications, in: Computer Vision-ECCV 2000: 6th European Conference on Computer Vision Dublin, Ireland, June 26\u2013July 1, 2000 Proceedings, Part I 6, Springer. pp. 554\u2013570.   \n[24] Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., et al., 2019. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems 32.   \n[25] Qin, Z., Yu, H., Wang, C., Guo, Y., Peng, Y., Xu, K., 2022. Geometric transformer for fast and robust point cloud registration, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 11143\u201311152.   \n[26] Rusu, R.B., Blodow, N., Beetz, M., 2009. Fast point feature histograms (fpfh) for 3d registration, in: 2009 IEEE international conference on robotics and automation, IEEE. pp. 3212\u20133217.   \n[27] Rusu, R.B., Blodow, N., Marton, Z.C., Beetz, M., 2008. Aligning point cloud views using persistent feature histograms, in: 2008 IEEE/RSJ international conference on intelligent robots and systems, IEEE. pp. 3384\u20133391.   \n[28] Shotton, J., Glocker, B., Zach, C., Izadi, S., Criminisi, A., Fitzgibbon, A., 2013. Scene coordinate regression forests for camera relocalization in rgb-d images, in: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2930\u20132937.   \n[29] Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H., 2021. Neuralrecon: Real-time coherent 3d reconstruction from monocular video, in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 15598\u201315607.   \n[30] Turk, G., Levoy, M., 1994. Zippered polygon meshes from range images, in: Proceedings of the 21st annual conference on Computer graphics and interactive techniques, pp. 311\u2013318.   \n[31] Valentin, J., Dai, A., Nie\u00dfner, M., Kohli, P., Torr, P., Izadi, S., Keskin, C., 2016. Learning to navigate the energy landscape, in: 2016 Fourth International Conference on 3D Vision (3DV), IEEE. pp. 323\u2013332.   \n[32] Wang, Y., Pan, Z., Li, X., Cao, Z., Xian, K., Zhang, J., 2022. Less is more: Consistent video depth estimation with masked frames modeling, in: Proceedings of the 30th ACM International Conference on Multimedia, pp. 6347\u20136358.   \n[33] Wang, Y., Shi, M., Li, J., Hong, C., Huang, Z., Peng, J., Cao, Z., Zhang, J., Xian, K., Lin, G., 2024. Nvds+: Towards efficient and versatile neural stabilizer for video depth estimation. IEEE Transactions on Pattern Analysis and Machine Intelligence doi:10.1109/TPAMI.2024.3476387.   \n[34] Wang, Y., Shi, M., Li, J., Huang, Z., Cao, Z., Zhang, J., Xian, K., Lin, G., 2023. Neural video depth stabilizer, in: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 9466\u20139476.   \n[35] Wu, Y., Ding, H., Gong, M., Qin, A.K., Ma, W., Miao, Q., Tan, K.C., 2022. Evolutionary multiform optimization with two-stage bidirectional knowledge transfer strategy for point cloud registration. IEEE Transactions on Evolutionary Computation 28, 62\u201376.   \n[36] Xiao, J., Owens, A., Torralba, A., 2013. Sun3d: A database of big spaces reconstructed using sfm and object labels, in: Proceedings of the IEEE international conference on computer vision, pp. 1625\u20131632.   \n[37] Yang, B., Wen, H., Wang, S., Clark, R., Markham, A., Trigoni, N., 2017. 3d object reconstruction from a single depth view with adversarial learning, in: Proceedings of the IEEE international conference on computer vision workshops, pp. 679\u2013688.   \n[38] Yang, F., Guo, L., Chen, Z., Tao, W., 2022. One-inlier is first: Towards efficient position encoding for point cloud registration. Advances in Neural Information Processing Systems 35, 6982\u20136995.   \n[39] Yang, H., Shi, J., Carlone, L., 2020. Teaser: Fast and certifiable point cloud registration. IEEE Transactions on Robotics 37, 314\u2013333.   \n[40] Yang, J., Li, H., Jia, Y., 2013. Go-icp: Solving 3d registration efficiently and globally optimally, in: Proceedings of the IEEE International Conference on Computer Vision, pp. 1457\u20131464.   \n[41] Yew, Z.J., Lee, G.H., 2022. Regtr: End-to-end point cloud correspondences with transformers, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 6677\u20136686.   \n[42] Yuan, Y., Tang, X., Zhou, W., Pan, W., Li, X., Zhang, H.T., Ding, H., Goncalves, J., 2019. Data driven discovery of cyber physical systems. Nature communications 10, 4894.   \n[43] Yuan, Y., Wu, Y., Fan, X., Gong, M., Ma, W., Miao, Q., 2023. Egst: Enhanced geometric structure transformer for point cloud registration. IEEE Transactions on Visualization and Computer Graphics .   \n[44] Zeng, A., Song, S., Nie\u00dfner, M., Fisher, M., Xiao, J., Funkhouser, T., 2017. 3dmatch: Learning the matching of local 3d geometry in range scans, in: CVPR, p. 4.   \n[45] Zhang, X., Yang, J., Zhang, S., Zhang, Y., 2023. 3d registration with maximal cliques, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 17745\u201317754.   \n[46] Zhou, Q.Y., Park, J., Koltun, V., 2016. Fast global registration, in: Computer Vision\u2013ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14, Springer. pp. 766\u2013782. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In the appendix, we first provide the detailed construction for local sets (Sec. A.1), the rigorous definitions of evaluation metrics (Sec. A.2), then describe the pseudocode for key parts (Sec. A.3) and the hyper-parameter selection (Sec. A.4). We further provide additional experimental results (Sec. A.5, Sec. A.6, Sec. A.7, and Sec. A.8), ablation studies on parameters (Sec. A.9), and discuss the limitations (Sec. A.10) and scalability (Sec. A.11) of our work. Finally, we show more qualitative results of registration on 3DMatch, 3DLoMatch, and KITTI (Sec. A.12) and provide the detailed information for these datasets (Sec. A.13). ", "page_idx": 13}, {"type": "text", "text": "A.1 Local set construction ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we provide the detailed construction for local sets. We first construct a global compatibility graph for input correspondences. Specifically, we calculate the Euclidean distance between the correspondence pair $(\\mathbf{c}_{i},\\mathbf{c}_{j})$ as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\nd_{(\\mathbf{c}_{i},\\mathbf{c}_{j})}=|\\|\\mathbf{p}_{i}-\\mathbf{p}_{j}\\|-\\|\\mathbf{q}_{i}-\\mathbf{q}_{j}\\||\\mathrm{~,~}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\mathbf{p}_{i}$ and $\\mathbf{p}_{j}$ denote points in the source point cloud and $\\mathbf{q}_{i}$ and ${\\bf q}_{j}$ are the corresponding points in the target point cloud. The first order compatibility score for each pair $(\\mathbf{c}_{i},\\mathbf{c}_{j})$ is calculated based on the Euclidean distance, as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\nS_{(\\mathbf{c}_{i},\\mathbf{c}_{j})}=1-\\left(\\frac{d_{(\\mathbf{c}_{i},\\mathbf{c}_{j})}}{d_{t}}\\right)^{2},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $d_{t}$ is the threshold for distance. When the distance difference between two correspondences is less than $d_{t}$ , they are considered compatible due to the length consistency of rigid transformations [6]. The hard compatibility matrix can be formulated as: ", "page_idx": 13}, {"type": "equation", "text": "$$\nS_{(\\mathbf{c}_{i},\\mathbf{c}_{j})}^{h}=\\left\\{\\begin{array}{l l}{1\\,;}&{d_{(\\mathbf{c}_{i},\\mathbf{c}_{j})}\\leq d_{t}}\\\\ {0\\,;}&{d_{(\\mathbf{c}_{i},\\mathbf{c}_{j})}>d_{t}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "However, the first order compatibility measure suffers from outliers due to locality and ambiguity [6]. Following [45], we calculate the second order compatibility scores [6] as edges in the graph. The second order compatibility score between the correspondence pair $(\\mathbf{c}_{i},\\mathbf{c}_{j})$ is computed based on the hard compatibility matrix: ", "page_idx": 13}, {"type": "equation", "text": "$$\nS_{({\\bf c}_{i},{\\bf c}_{j})}^{2}=S_{({\\bf c}_{i},{\\bf c}_{j})}^{h}\\cdot\\sum_{k=1}^{N_{c}}S_{({\\bf c}_{i},{\\bf c}_{k})}^{h}\\cdot S_{({\\bf c}_{k},{\\bf c}_{j})}^{h}\\,,\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $N_{c}$ is the number of input correspondences. Based on the compatibility graph, we select $K$ reliable correspondences as seeds and construct local sets for each seed. Specifically, following [1, 6], we use first-order compatibility scores to compute the leading eigenvectors via the power iteration method [22]. These leading feature vectors serve as confidence scores for reliable seed selection. For each seed, we explore its top- $N_{f}$ neighbors in the second order measure space. Then, within each neighbor set, we recompute the second-order compatibility score and select the top- $N_{2}$ $\\left(N_{2}<N_{f}\\right)$ ) correspondences as the local set for the $i$ -th seed [6]. ", "page_idx": 13}, {"type": "text", "text": "A.2 Evaluation Metrics ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Rotation Error (RE) measures the geometric distance in degrees between the estimated and groundtruth rotation matrices: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathrm{RE}=\\operatorname{arccos}\\left({\\frac{\\operatorname{trace}\\left(\\mathbf{R}^{T}\\mathbf{R}_{g t}\\right)-1}{2}}\\right)\\,,\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\mathbf{R}$ denotes the estimated rotation matrix and $\\mathbf{R}_{g t}$ denotes the ground-truth rotation matrix. ", "page_idx": 13}, {"type": "text", "text": "Translation Error (TE) measures the Euclidean distance between the estimated and ground-truth translation vectors: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{TE}=\\left\\lVert\\mathbf{t}-\\mathbf{t}_{g t}\\right\\rVert_{2}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where t denotes the estimated translation vector and $\\mathbf{t}_{g t}$ denotes the ground-truth translation vector. ", "page_idx": 13}, {"type": "text", "text": "Registration Recall (RR) measures the fraction of correctly registered point cloud pairs whose RE and TE are both below certain thresholds: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{{\\displaystyle\\mathrm{RR}_{3\\mathrm{DMatch}\\&3\\mathrm{DLoMatch}}=\\frac{1}{\\mathrm{N}}\\sum_{i=1}^{\\mathrm{N}}\\left[\\mathrm{RE}_{i}<15^{\\circ}\\wedge\\mathrm{TE}_{i}<30\\;\\mathrm{m}\\right]}\\;.}\\\\ {{\\displaystyle\\mathrm{RR}_{\\mathrm{KITII}}=\\frac{1}{\\mathrm{N}}\\sum_{i=1}^{\\mathrm{N}}\\left[\\mathrm{RE}_{i}<5^{\\circ}\\wedge\\mathrm{TE}_{i}<60\\;\\mathrm{m}\\right]}\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Following [1, 5, 6, 39], we compute the mean RE and TE only with the correctly registered point cloud pairs . ", "page_idx": 14}, {"type": "text", "text": "A.3 Pseudocode for key parts of our algorithm ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "There are two key parts in our algorithm: Inlier Identification via $\\ell_{0}$ -minimization and two-stage decoupling strategy. ", "page_idx": 15}, {"type": "table", "img_path": "BJrBaLoDRJ/tmp/7b21a7aec64ecc277001e9c594bef0c9f50c9b234e80878c8451e94655a923d1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "Data: Given point pairs in the $k$ -th local set $\\mathbf{P}_{k}=\\{\\mathbf{p}_{k_{i}}\\}_{i=1}^{K_{2}}$ and $\\mathbf{Q}_{k}=\\{\\mathbf{q}_{k_{i}}\\}_{i=1}^{K_{2}}$ , parameters $\\lambda_{R}$ , $\\lambda_{t}$ , $K_{R}$ , $K_{t}$ Result: Estimated rotation $\\mathbf{R}_{k}^{*}$ and translation $\\mathbf{t}_{k}^{\\ast}$ hypothesis for the $k$ -th local set $\\textbf{1\\ \\%}$ Decoupling the alignment error into a rotation fitting error and a translation fitting error 2 Calculate relative positions $\\bar{\\mathbf{P}}_{k}$ and $\\bar{\\mathbf{Q}}_{k}$ for all pairs: $\\bar{\\mathbf{p}}_{k_{i j}}=\\mathbf{p}_{k_{j}}-\\mathbf{p}_{k_{i}}$ and $\\bar{\\mathbf{q}}_{k_{i j}}=\\mathbf{q}_{k_{j}}-\\mathbf{q}_{k_{i}}$ $3\\ \\%$ Decoupling the inlier identification from the rotation estimation ", "page_idx": 16}, {"type": "text", "text": "4 Formulate the $\\ell_{0}$ -minimization problem for the rotation fitting error $\\bar{\\bf O}_{k}$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\bar{\\mathbf{O}}_{k}^{*}=\\arg\\underset{\\bar{\\mathbf{O}}_{k}}{\\operatorname*{min}}\\,\\|\\bar{\\mathbf{O}}_{k}\\|_{\\ell_{0}}\\,,\\qquad\\qquad}\\\\ {\\mathrm{subject}\\,\\mathrm{to:}\\,\\bar{\\mathbf{O}}_{k}=\\bar{\\mathbf{Q}}_{k}-\\bar{\\mathbf{P}}_{k}\\mathbf{R}_{k}-\\bar{\\Xi}_{k}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "$\\mathfrak{s}\\ \\%$ Bayesian-based inlier identification and rotation estimation ", "page_idx": 16}, {"type": "text", "text": "6 Construct $\\bar{\\Theta}_{k}$ from the left null-space of $\\bar{\\mathbf{P}}_{k}$ $\\mathbf{\\bar{\\rho}}_{k}\\colon\\bar{\\Theta}_{k}\\bar{\\mathbf{P}}_{k}=\\mathbf{0}$   \n7 Eliminate the components related to $\\mathbf{R}_{k}$ in the constraints of rotation fitting error $\\ell_{0}$ -minimization: $\\bar{\\Theta}_{k}\\bar{\\mathbf{O}}_{k}=\\bar{\\Theta}_{k}\\bar{\\mathbf{Q}}_{k}-\\bar{\\Theta}_{k}\\bar{\\Xi}_{k}$ ", "page_idx": 16}, {"type": "text", "text": "8 Define $\\tilde{\\bar{\\mathbf{Q}}}_{k}=\\bar{\\Theta}_{k}\\bar{\\mathbf{Q}}_{k}$ and $\\bar{\\Pi}_{k}=\\bar{\\Theta}_{k}\\bar{\\Theta}_{k}^{T}$ and formulate the unconstrained problem for rotation fitting error: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\bar{\\mathbf{O}}_{k}}\\frac{1}{2}\\left\\|(\\tilde{\\bar{\\mathbf{Q}}}_{k}-\\bar{\\boldsymbol{\\Theta}}_{k}\\bar{\\boldsymbol{\\mathbf{O}}}_{k})^{T}\\bar{\\boldsymbol{\\Pi}}_{k}^{-1}(\\tilde{\\bar{\\mathbf{Q}}}_{k}-\\bar{\\boldsymbol{\\Theta}}_{k}\\bar{\\boldsymbol{\\mathbf{O}}}_{k})\\right\\|_{F}^{2}+\\lambda_{R}\\left\\|\\bar{\\boldsymbol{\\mathbf{O}}}_{k}\\right\\|_{F}^{2}\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "9 The explicit solution can be calculated directly: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\bar{\\bf O}_{k}^{*}=(\\bar{\\bf\\Theta}_{k}^{T}\\bar{\\bf H}_{k}^{-1}\\bar{\\bf\\Theta}_{k}+2\\lambda_{R}{\\bf I})_{k}^{-1}\\bar{\\bf\\Theta}_{k}^{T}\\bar{\\bf H}_{k}^{-1}\\tilde{\\bf\\tilde{Q}}_{k}\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "10 Solve ${\\bf R}_{k}^{*}$ using SVD on the identified top $K_{R}$ pairs with the smallest error $\\bar{\\bf P}_{\\mathcal{Z}_{R}}$ and $\\bar{\\bf Q}_{\\mathcal{T}_{R}}$ ", "page_idx": 16}, {"type": "text", "text": "11 $\\%$ Decoupling the inlier identification from the translation estimation ", "page_idx": 16}, {"type": "text", "text": "12 Based on the estimated ${\\bf R}_{k}^{*}$ , the $\\ell_{0}$ -minimization problem for the translation fitting error $\\hat{\\mathbf{O}}_{k}$ is formulated as: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{\\mathbf{O}}_{k}^{*}=\\arg\\operatorname*{min}_{\\hat{\\mathbf{O}}_{k}}\\|\\hat{\\mathbf{O}}_{k}\\|_{\\ell_{0}}\\,,\\qquad\\qquad\\qquad}\\\\ {{\\mathrm{subject}}\\,{\\mathrm{to:}}\\;\\hat{\\mathbf{O}}_{k}=\\mathbf{Q}_{k}-\\mathbf{P}_{k}\\mathbf{R}_{k}^{*}-\\mathbf{t}_{k}\\mathbf{1}^{T}-\\boldsymbol{\\Xi}_{k}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "13 Define $\\Theta$ satisfying $\\mathbf{61}=\\mathbf{0}$ . Eliminate the components associated with translation: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Theta_{k}\\hat{\\mathbf{O}}_{k}^{T}=\\Theta_{k}\\big(\\mathbf{Q}_{k}-\\mathbf{P}_{k}\\mathbf{R}_{k}^{*}\\big)^{T}-\\Theta_{k}\\Xi_{k}^{T}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "14 $\\%$ Bayesian-based inlier identification and translation estimation ", "page_idx": 16}, {"type": "text", "text": "15 Define $\\mathbf{X}_{k}=\\Theta_{k}(\\mathbf{Q}_{k}^{T}-(\\mathbf{P}_{k}\\mathbf{R}_{k}^{*})^{T})$ and $\\mathbf{I}\\mathbf{I}_{k}=\\pmb{\\Theta}_{k}\\pmb{\\Theta}_{k}^{T}$ . Formulate the unconstrained optimization problem: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\hat{\\mathbf{O}}_{k}^{T}}\\frac{1}{2}\\left\\|(\\mathbf{X}_{k}-\\pmb{\\Theta}_{k}\\hat{\\mathbf{O}}_{k}^{T})^{T}\\Pi_{k}^{-1}(\\mathbf{X}_{k}-\\pmb{\\Theta}_{k}\\hat{\\mathbf{O}}_{k}^{T})\\right\\|_{F}^{2}+\\lambda_{t}\\left\\|\\hat{\\mathbf{O}}_{k}^{T}\\right\\|_{F}^{2}\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "16 The explicit solution can be calculated directly: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\hat{\\mathbf{O}}_{k}^{*}=((2\\lambda_{t}\\mathbf{I}+\\Theta_{k}^{T}\\mathbf{I}\\mathbf{I}_{k}^{-1}\\Theta_{k})^{-1}\\Theta_{k}^{T}\\mathbf{I}\\mathbf{I}_{k}^{-1}\\mathbf{X}_{k})^{T}\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "17 Solve $\\mathbf{t}_{k}^{\\ast}$ based on the identified top- $\\mathbf{\\nabla}K_{t}$ correspondences with the smallest error $\\mathbf{P}_{\\mathcal{T}_{t}}$ and $\\mathbf{Q}_{\\mathcal{T}_{t}}$ . ", "page_idx": 16}, {"type": "text", "text": "A.4 Hyper-parameter selection ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The $K_{1}$ and $K_{2}$ are set to 30 and 20 for all experiments. For other hyper-parameters $(\\lambda_{R},\\,\\lambda_{t},\\,K_{R}$ and $K_{t}$ ), we employ a grid search strategy with criterion of maximizing inliers. For a given set of ", "page_idx": 16}, {"type": "text", "text": "parameters $(\\lambda_{R},K_{R})$ , the optimization criterion for $\\mathbf{R}_{k}$ is shown as: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\mathbf{R}_{k}}{\\operatorname*{max}}\\big\\lfloor\\mathbb{I}_{R}\\big\\rfloor\\,,}\\\\ &{\\mathrm{subject\\,to};\\,\\bar{\\mathbf{q}}_{k_{i j}}-\\mathbf{R}_{k}\\bar{\\mathbf{p}}_{k_{i j}}=\\bar{\\xi}_{k_{i j}}\\,,\\forall i\\in\\mathbb{I}_{R}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\mathbb{I}_{R}$ is the index set of the inlier correspondence pairs and the operation $\\lfloor\\cdot\\rfloor$ denotes the cardinality of the set. Similarly, the selection criterion for the translation vector $\\mathbf{t}_{k}$ is established as follows: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\mathbf{t}_{k}}{\\operatorname*{max}}\\big\\lfloor\\mathbb{I}_{t}\\big\\rfloor\\,,}\\\\ &{\\mathrm{subject~to};\\,\\mathbf{q}_{k_{i}}-\\mathbf{R}_{k}^{*}\\mathbf{p}_{k_{i}}-\\mathbf{t}_{k}=\\xi_{k_{i}}\\,,\\forall i\\in\\mathbb{I}_{t}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\mathbb{I}_{R}$ is the index set of inlier correspondences. ", "page_idx": 17}, {"type": "text", "text": "A.5 Impact of noise standard deviation ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we visually illustrate the impact of noise standard deviation on the point cloud. As shown in Fig. 7, compared with (a) the clean Bunny model, when the noise standard deviation is increased to 0.01, the geometric structure of the model in (b) remains mostly recognizable. Therefore, 0.01 is often used as the noise standard. However, as the noise standard deviation increases up to 0.1, the geometric structure of the Bunny is severely degraded, going beyond the noise levels typically encountered in robotics and computer vision applications. ", "page_idx": 17}, {"type": "image", "img_path": "BJrBaLoDRJ/tmp/f52905af7ddfe290e4dec4558ed05397de9c8027fbc3dd4dab83e4d70f1eed5a.jpg", "img_caption": ["Figure 7: The impact of Gaussian noise changes on the scanning model. Bunny point cloud scaled inside unit cube $[0,1]^{3}$ and corrupted by different levels of noise and outliers, all viewed from the same perspective angle. (a) Clean Bunny model point cloud. (b) Bunny dataset, generated from (a) by adding isotropic Gaussian noise with a standard deviation $\\sigma=0.01$ . (c) Bunny dataset, generated from (a) by adding isotropic Gaussian noise with $\\sigma=0.1$ . "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "A.6 Efficiency and accuracy. ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we report the inference time, rotation error, and translation error by increasing the corresponding number $N_{c}$ from 250 to 5000. The curves of FGR, RANSAC, MAC, and our method are flat and difficult to distinguish visually, demonstrating their efficiency. In addition, when there are fewer inputs, the influence of outliers is more obvious. The registration accuracy of FGR and RANSAC decreases significantly as the number of points decreases. The rotation and translation errors of our method are less affected by the number of correspondences. Compared with other methods, our method achieves the most accurate and fast registration for each number of input correspondences. ", "page_idx": 17}, {"type": "text", "text": "A.7 Effectiveness of the two-stage decoupling strategy. ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We evaluate the effectiveness of our proposed two-stage decoupling strategy (TDS) by formulating the alignment error $\\ell_{0}$ -minimization problem directly on the Bunny data instead of local sets. The rotation and translation are estimated without hypotheses. We provide a comparison with other optimization-based methods [46, 12, 4, 39] as the outlier ratio increases from $0\\%$ to $90\\%$ . Our TDS consistently achieves the highest registration accuracy, demonstrating its inlier identification capability. ", "page_idx": 17}, {"type": "image", "img_path": "BJrBaLoDRJ/tmp/0ff2d8b1464da913a9b6b5dbef33e02b34b0e0ff4cfc12cc532697ec9bff4ce1.jpg", "img_caption": ["Figure 8: Comparison results with respect to the number of correspondences. "], "img_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "BJrBaLoDRJ/tmp/7a2058452c993a1bd552fef37678214667f99f3381e2595750e663b5484cb4aa.jpg", "img_caption": ["Figure 9: Comparison results of our two-stage decoupling strategy with optimization-based methods. We compare the rotation error and translation error of our proposed two-stage decoupling strategy (TDS) with optimization-based methods [46, 12, 4, 39, 45]. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "A.8 Additional comparisons. ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We also provide a comparison with learning-based registration method EGST [43], we re-evaluate our method under the same dataset settings and metrics as EGST. The comparison results on KITTI and 3DMatch are shown in Table 4 below. The results of EGST reported in the table follow its published paper. Our method shows better performance in rotation error and comparable results in translation error. ", "page_idx": 18}, {"type": "table", "img_path": "BJrBaLoDRJ/tmp/3c48940695eaa9f127ea0f0ef51ecc0a7292b34b9b7cf098b02b7c77ef41ceee.jpg", "table_caption": ["Table 4: Comparison results with EGST. "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "A.9 Sensitivity to parameters. ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We conduct ablation studies on the KITTI dataset to evaluate the sensitivity of our algorithm to various parameters. Firstly, we ablate the number of local sets $N_{1}$ and correspondences $N_{2}$ in each local set. As shown in tables below, our method is insensitive to $N_{1}$ and $N_{2}$ , achieving high registration rates (RR) and low errors (RE and TE). Then, we evaluate the impact of rotation estimation threshold $K_{R}$ and translation estimation threshold $K_{t}$ . As shown in Fig. 10, the curves of registration metrics (RR, RE and TE) remain stable when $K_{R}$ and $K_{t}$ increase, indicating the insensitivity of our method to these parameters. ", "page_idx": 19}, {"type": "table", "img_path": "BJrBaLoDRJ/tmp/7e428f79a4168e6a9a3cd6132596a5cff9a81c1d8bd278f1bcfbb33778a9bb09.jpg", "table_caption": ["Table 5: Ablation of the number of local sets. "], "table_footnote": [], "page_idx": 19}, {"type": "table", "img_path": "BJrBaLoDRJ/tmp/9ad8587d930e4c37fdf72e29a60c20f4066cb04984e84ec59f41aa0ec929c7d4.jpg", "table_caption": ["Table 6: Ablation of the number of correspondences in each local set. "], "table_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "BJrBaLoDRJ/tmp/c80d5d7ca8ad79a76db5b477fd1c3bb86aa478c19eaa497e1b90e40889c0deaf.jpg", "img_caption": ["The results demonstrate that our method is parameter insensitive, making it reliable in practical implementations. ", "Figure 10: Ablation of inlier thresholds $K_{R}$ and $K_{t}$ . "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "A.10 Limitations and broader impact. ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We propose a $\\ell_{0}$ -norm based method to solve the point cloud registration problem. The method is robust to high outlier ratios and noise, and effective for different numbers of correspondences. It introduces a novel perspective to achieve accurate point cloud registration in practical applications. Our algorithm is most likely to be used in quality inspection and autonomous driving. It can provide fast and accurate alignment between workpieces and templates, as well as enhance localization and scene perception for autonomous vehicles. Furthermore, we wish to test the effectiveness of our method in other areas involving registration tasks, including multimodal medical image registration. One possible situation is a quality inspection scenario, where our algorithm may fail when dealing with large workpiece surfaces without obvious features. Future research will focus on enhancing the robustness of our algorithm to featureless data. ", "page_idx": 19}, {"type": "text", "text": "A.11 Scalability of our algorithm. ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Exploring the scalability of our algorithm and its suitability for real-time applications is important for practical deployment. Existing algorithms struggle to achieve both fast speed and high accuracy. Our experiments demonstrate that our algorithm not only achieves high accuracy and robustness but also remains competitive in terms of efficiency, highlighting its potential for real-time applications. The speed of our method can be further improved through techniques such as parallel computing and $C++$ implementation. Notably, the two-stage decoupling strategy (TDS) consumes most of the running time $95\\%$ of the total), and thus, it could particularly benefit from parallelization. In the first stage of TDS, we compute the relative positions for all point pairs. In the second stage, the computation of null-space matrices also requires substantial processing time. Therefore, these two components are the primary targets for acceleration. Regarding scalability, the proposed two-stage decoupling strategy is a crucial step for inlier identification and can be flexibly combined with other methods to improve accuracy. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "A.12 Qualitative results. ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We show qualitative results on 3DMatch [44] and 3DLoMatch [17] in Fig. 12. The yellow and blue point clouds represent the source and target point clouds, respectively. The first column represents the input point clouds and the second column represents the aligned point clouds transformed with the ground-truth transformations. Compared to other methods [6, 45], our approach achieves better alignment results. We also provide registration results on the KITTI [13] dataset in Fig. 13. The input source and target point clouds are in different poses, and the point clouds transformed using our estimated transformations are successfully registered. ", "page_idx": 20}, {"type": "text", "text": "The visualization of failure cases is provided in Fig. 11 . We observe that when there are repeated patterns (e.g., similar chairs appearing in different locations) or textureless structures (e.g., walls, floors), failure cases may occur due to the feature matching ambiguity. These remain challenging problems in point cloud registration and have not yet been effectively addressed. Potential solutions include improving feature extraction or applying point cloud completion based on the scene context. ", "page_idx": 20}, {"type": "image", "img_path": "BJrBaLoDRJ/tmp/c0738205060551fed0ec508285ec5f5849ca2732a959c0dc5db956c7a1836451.jpg", "img_caption": ["Figure 11: Failure cases on the 3DMatch dataset. "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "A.13 Datasets. ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Stanford Bunny The Bunny model from the Stanford 3D Scanning Repository [10] is scanned with a Cyberware 3030 MS scanner, with licensing restrictions against commercial use.Each scan takes the form of a range image, described in the local coordinate system of the scanner. These range images are merged using a modified ICP algorithm [30]. ", "page_idx": 20}, {"type": "text", "text": "Odometry KITTI KITTI [15] is published under the NonCommercial-ShareAlike 3.0 License. It contains 11 sequences scanned by a Velodyne HDL-64 3D laser scanner in outdoor driving scenarios. Following [5, 6], we use sequences 8-10 for testing. ", "page_idx": 20}, {"type": "text", "text": "3DMatch and 3DLoMatch 3DMatch [44] comprises 62 scenes from SUN3D [36], 7-Scenes [28], RGB-D Scenes v.2 [21], Analysis-by-Synthesis [31], BundleFusion [11], and Halbel et al. [16] (Table. 7). These scenes are captured from diverse indoor environments using different sensors like the Microsoft Kinect and Intel Realsense, and are processed into point cloud fragments by fusing 50 consecutive depth frames using TSDF volumetric fusion [10]. The dataset contains 46 scenes for training, 8 scenes for validation and 8 scenes for testing. The original 3DMatch [44] only considers point cloud pairs with $>30\\%$ overlap. In addition to this benchmark (3DMatch), we follow [17] to include point cloud pairs with overlaps between $10\\%$ and $30\\%$ to form another benchmark (3DLoMatch). ", "page_idx": 20}, {"type": "image", "img_path": "BJrBaLoDRJ/tmp/dbf6f023fb33aa81c29b3c0fa24637abcb8559f64892b3d83a3ee0508a894d2b.jpg", "img_caption": ["Figure 12: Qualitative registration results on the 3DMatch and 3DLoMatch datasets. "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "table", "img_path": "BJrBaLoDRJ/tmp/c03c19c5b76032bbc1122b12a1d9216a824e49afceb09d52667814bc947a6782.jpg", "table_caption": ["Table 7: Raw data used in the 3DMatch dataset and their licenses. "], "table_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "BJrBaLoDRJ/tmp/5cb85da4734801a14cf84921456897bf2c18b2925c353fa8d0c4942e901dc10d.jpg", "img_caption": [], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Figure 13: Visualizations of registration results on the KITTI dataset. ", "page_idx": 22}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The contribution and scope of the paper are accurately stated in the abstract and introduction. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 23}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Justification: The paper discusses the limitations of the work in Appendix A.10 ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 23}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: The paper provides theorems and formulas in Sec. 3 and theoretical results in Sec. 4.2. However, the paper does not include a full set of assumptions and proofs. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 24}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: The main experimental results of the paper are reproducible, and we will release our code after the paper is accepted. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 24}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 25}, {"type": "text", "text": "Answer: [No] ", "page_idx": 25}, {"type": "text", "text": "Justification: We will make the complete code public following the acceptance of the paper. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 25}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: The experimental setup and implement details are provided in Sec. 4.1, as well as in Appendix A.4. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 25}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We perform 50 independent trials for each experiment in Sec. 4.2 and report the average results. Our experiments are stable across multiple runs. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We provide information on the compute workers and model efficiency in Sec. 4.1 and Sec. 4.2. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 26}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: This article complies in all respects with the NeurIPS Code of Ethics. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 26}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The potential positive and negative societal impacts of the work are discussed in Appendix A.10. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 26}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 27}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 27}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: The paper uses publicly available datasets and code for training and comparative evaluation, adhering to all protocol restrictions attached to the publication. Detailed licenses for the datasets used are provided in the appendix A.13. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: We will release the our code under the CC BY-NC-SA 4.0 license after the acceptance of the paper. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 28}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 28}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}]