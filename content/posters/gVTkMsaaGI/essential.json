{"importance": "This paper is crucial for researchers working with diffusion models, particularly in tackling intractable inference problems.  It offers a novel, asymptotically unbiased training objective, **relative trajectory balance (RTB)**, enabling efficient posterior sampling. The versatility across diverse domains (vision, language, control) and state-of-the-art results in offline reinforcement learning make this a significant contribution with broad applicability and inspire future research on unbiased inference.", "summary": "Amortized sampling from complex posteriors using diffusion models is achieved via a novel data-free learning objective, Relative Trajectory Balance (RTB).  RTB's asymptotic correctness is proven, offering unbiased inference across vision, language, and control tasks.", "takeaways": ["A novel data-free learning objective, Relative Trajectory Balance (RTB), enables accurate and efficient amortized sampling from complex posteriors using diffusion models.", "RTB is theoretically proven to be asymptotically correct, providing unbiased posterior inference across various applications.", "Demonstrated state-of-the-art performance across vision, language, and control tasks, highlighting its versatility and broad applicability."], "tldr": "Many downstream applications using diffusion models require sampling from complex posterior distributions, a computationally challenging task. Existing methods often provide only approximate solutions or are limited to specific cases. This paper tackles this challenge by proposing a novel data-free learning objective called \"Relative Trajectory Balance\" (RTB) for training diffusion models to sample from arbitrary posteriors.  The method is rooted in viewing diffusion models as generative flow networks. \n\nRTB is proven to be asymptotically correct and leverages deep reinforcement learning for improved mode coverage.  Experimental results across diverse domains including vision, language, and offline reinforcement learning demonstrate RTB's versatility and superior performance compared to existing techniques.  The paper showcases unbiased posterior inference and achieves state-of-the-art results in offline reinforcement learning, highlighting the broader implications of RTB for various fields.", "affiliation": "Mila, Universit\u00e9 de Montr\u00e9al", "categories": {"main_category": "Machine Learning", "sub_category": "Reinforcement Learning"}, "podcast_path": "gVTkMsaaGI/podcast.wav"}