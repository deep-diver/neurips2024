[{"figure_path": "grrefkWEES/figures/figures_1_1.jpg", "caption": "Figure 1: Decomposition of spatial-temporal consistency in 4D generation. The proposed Diffusion4D embeds geometrical consistency and temporal coherence into a single network.", "description": "This figure illustrates the concept of spatial-temporal consistency in 4D generation.  It decomposes the challenge into three aspects: spatial consistency (consistent 3D geometry at each timestamp), temporal consistency (smooth and coherent appearance and movement across timestamps), and spatial-temporal consistency (combining both). The figure then shows how the proposed Diffusion4D method integrates all three aspects into a unified network for efficient and consistent 4D content generation.", "section": "1 Introduction"}, {"figure_path": "grrefkWEES/figures/figures_3_1.jpg", "caption": "Figure 2: Our proposed Diffusion4D consists of a 4D-aware video diffusion model and explicit 4D construction, capable of synthesizing 4D assets conditioned on text, single images, or static 3D assets.", "description": "This figure illustrates the architecture of the proposed Diffusion4D framework. It shows how a 4D-aware video diffusion model generates orbital videos of dynamic 3D assets from various input prompts (text, image, or static 3D model).  The model incorporates a 3D-to-4D motion magnitude metric to control the dynamic strength of the assets. The generated orbital views are then used for explicit 4D construction via Gaussian splatting, resulting in a final 4D asset.", "section": "3 Method"}, {"figure_path": "grrefkWEES/figures/figures_6_1.jpg", "caption": "Figure 3: Qualitative comparisons between Diffusion4D and other baselines in Text-to-4D (upper) and Image-to-4D (lower) generation. For our method, we show five views from consecutive timestamps. (* results from 4D-aware video diffusion model).", "description": "This figure showcases a qualitative comparison of 4D object generation results between the proposed Diffusion4D method and several existing baselines (4DFY, Animate124, 4DGen, and STAG4D).  The comparison is done for both text-to-4D and image-to-4D generation tasks. For Diffusion4D, five different views of the generated 4D object at consecutive timestamps are displayed to highlight the temporal consistency achieved by the model.  The baselines primarily show only two viewpoints (start and end), thereby lacking the dynamic view demonstration that is a major feature of Diffusion4D.", "section": "4 Experimentation"}, {"figure_path": "grrefkWEES/figures/figures_7_1.jpg", "caption": "Figure 4: Visualization of Static-3D conditioned Diffusion4D. The first row shows the conditions, and the rest shows the results. (* results from 4D-aware video diffusion model.)", "description": "This figure visualizes the results of using Diffusion4D with static 3D assets as input.  The top row shows the input static 3D models used as conditioning. The subsequent rows show the generated 4D assets from different conditioning methods: Image-conditioned (using a single image), Static-3D conditioned (using a static 3D model), and Static-3D conditioned (*), which uses results from the 4D-aware video diffusion model. The circled areas highlight how well the model captures the input characteristics.", "section": "4.3 Main Results"}, {"figure_path": "grrefkWEES/figures/figures_8_1.jpg", "caption": "Figure 3: Qualitative comparisons between Diffusion4D and other baselines in Text-to-4D (upper) and Image-to-4D (lower) generation. For our method, we show five views from consecutive timestamps. (* results from 4D-aware video diffusion model).", "description": "This figure presents a qualitative comparison of 4D generation results between the proposed Diffusion4D method and several other state-of-the-art baselines.  The comparison is shown for both text-to-4D and image-to-4D generation tasks.  For each method and task, several consecutive frames of the generated 4D asset are displayed from multiple viewpoints.  The asterisk (*) denotes results obtained directly from the 4D-aware video diffusion model (before the explicit 4D construction step). This allows a visual assessment of the quality, realism, and dynamic consistency of each approach.", "section": "4 Experimentation"}]