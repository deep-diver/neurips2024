[{"type": "text", "text": "Score-Optimal Diffusion Schedules ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Christopher Williams Department of Statistics University of Oxford ", "page_idx": 0}, {"type": "text", "text": "Andrew Campbell Department of Statistics University of Oxford ", "page_idx": 0}, {"type": "text", "text": "Arnaud Doucet Department of Statistics University of Oxford ", "page_idx": 0}, {"type": "text", "text": "Saifuddin Syed Department of Statistics University of Oxford ", "page_idx": 0}, {"type": "text", "text": "{williams,campbell,doucet,saifuddin.syed}@stats.ox.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Denoising diffusion models (DDMs) offer a flexible framework for sampling from high dimensional data distributions. DDMs generate a path of probability distributions interpolating between a reference Gaussian distribution and a data distribution by incrementally injecting noise into the data. To numerically simulate the sampling process, a discretisation schedule from the reference back towards clean data must be chosen. An appropriate discretisation schedule is crucial to obtain high quality samples. However, beyond hand crafted heuristics, a general method for choosing this schedule remains elusive. This paper presents a novel algorithm for adaptively selecting an optimal discretisation schedule with respect to a cost that we derive. Our cost measures the work done by the simulation procedure to transport samples from one point in the diffusion path to the next. Our method does not require hyperparameter tuning and adapts to the dynamics and geometry of the diffusion path. Our algorithm only involves the evaluation of the estimated Stein score, making it scalable to existing pre-trained models at inference time and online during training. We find that our learned schedule recovers performant schedules previously only discovered through manual search and obtains competitive FID scores on image datasets. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Denoising Diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020; Song et al., 2021) or DDMs are state-of-the-art generative models. They are formulated through considering a forward noising process that interpolates from the target to a reference Gaussian distribution by gradually introducing noise into an empirical data distribution. Simulating the time reversal of this process then produces samples from the data distribution. Specifically, we evolve data distribution $p_{0}$ through the forward diffusion process on time interval $[0,1]$ , described by ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{d}X_{t}=f(t)X_{t}\\mathrm{d}t+g(t)\\mathrm{d}W_{t},\\qquad X_{0}\\sim p_{0},}\\end{array}\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "with drift $f(t)X_{t}$ , diffusion coefficient $g(t)$ and Brownian noise increment $\\mathrm{d}W_{t}$ . The coefficients $f(t)$ and $g(t)$ are chosen such that at time $t=1$ the distribution of $X_{1}$ is very close to a reference Gaussian distribution $p_{1}$ in distribution. A sample starting at $p_{0}$ and following Equation (1) until time $t$ will be distributed according to $p_{t}$ which is a mollified version of the data distribution ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\begin{array}{r}{p_{t}(x_{t})=\\int_{X_{0}}p_{0}(x_{0})p_{t|0}(x_{t}|x_{0})\\mathrm{d}x_{0},\\qquad p_{t|0}(x_{t}|x_{0})=\\mathcal{N}(x_{t};s(t)x_{0},\\sigma^{2}(t)I).}\\end{array}\n$$", "text_format": "latex", "page_idx": 0}, {"type": "image", "img_path": "0rl5vWOzRU/tmp/dd90e782fc8adcabf78ec0416a853d1d6c06d37d7f22c2887254e30efc0db39f.jpg", "img_caption": ["Figure 1: Density estimates of the mollified Cantor distribution (left) using a DDM with schedule $\\bar{\\mathcal{T}}=\\{t_{i}\\}_{i=0}^{100}$ generated with 100 linearly spaces discretisation times $t_{i}=i/100$ (middle), compared to the optimised schedule $\\mathcal{T}^{*}=\\{t_{i}^{*}\\}_{i=0}^{50}$ with 50 discretisation times $t_{i}^{*}$ generated by Algorithm 1 (right). The eight modes present in our true mollified distribution are shown in grey on each plot. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "The parameters $s(t)$ and $\\sigma^{2}(t)$ define the noising schedule. They can be found in closed form in terms of $f(t)$ and $g(t)$ (Karras et al., 2022). To obtain samples from $p_{0}$ , we can reverse the dynamics of the forward diffusion in Equation (1) to obtain the backward diffusion, ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{d}X_{t}=\\big(f(t)X_{t}-g(t)^{2}\\nabla_{x}\\log p_{t}(X_{t})\\big)\\,\\mathrm{d}t+g(t)\\mathrm{d}\\widetilde{W}_{t},\\qquad X_{1}\\sim p_{1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "By simulating Equation (3) backwards in time, we evolve reference samples $X_{1}\\sim p_{1}$ from $t=1$ to $t=0$ to obtain samples that are terminally distributed according to the data distribution $p_{\\mathrm{0}}$ . To simulate Equation (3) numerically, we must decide upon a discretisation of time, $\\mathcal{T}=\\{t_{i}\\}_{i=0}^{T}$ with $t_{T}=1$ , $t_{0}=0$ , which we refer to as the discretisation schedule. For a given noising schedule, it is important to select an appropriate discretisation schedule such that (3) can be simulated accurately, i.e. $p_{t_{i}}$ and $p_{t_{i-1}}$ should not differ significantly. In this paper, we derive a methodology to compute an optimal discretisation schedule. ", "page_idx": 1}, {"type": "text", "text": "Prior work has often joined together the choice of noising schedule and discretisation schedule. A uniform splitting of time would be chosen, $t_{i}=i/T$ , with the noising schedule dictating the change between $p_{t_{i}}$ and $p_{t_{i-1}}$ . Two prominent examples have the form $s(t)=\\sqrt{\\bar{\\alpha}(t)}$ , $\\sigma^{2}(t)=1-\\bar{\\alpha}(t)$ with the linear schedule introduced by Ho et al. (2020) having $\\begin{array}{r}{\\bar{\\alpha}(t)=1-\\exp\\bigr(-\\int_{0}^{\\iota}\\beta(s)\\mathrm{d}s\\bigr)}\\end{array}$ with linear $\\beta(t)=\\beta_{\\mathrm{min}}+t(\\beta_{\\mathrm{max}}-\\beta_{\\mathrm{min}})$ . Alternatively, Nichol and Dhariwal (2021) introduce the cosine schedule with \u03b1\u00af(t) = f(t)/f(0), f(t) = cos t1++\u03f5\u03f5 for $\\epsilon=0.008$ . Karras et al. (2022) refines this approach by splitting the choice of noising schedule from that of the discretisation schedule, however, picking the discretisation schedule is still a matter of hyperparameter tuning. ", "page_idx": 1}, {"type": "text", "text": "A good discretisation schedule can drastically impact the efficiency of the training and inference of the generative model, but unfortunately can be difficult to select for complex target distributions. For example, for a distribution supported on the Cantor set (Figure 1, left), the default linear schedule fails entirely to capture the modes of the data distribution (Figure 1, middle). However, our optimised schedule learned using Algorithm 1 recovers these modes (Figure 1, right). Without such an automatic algorithm, finding performant discretisation schedules often reduces to an expensive and laborious hyperparameter sweep. ", "page_idx": 1}, {"type": "text", "text": "We devise a method for selecting a discretisation schedule that yields high-quality samples from $p_{0}$ . Our key contribution is defining an appropriate notion of cost incurred when simulating from one step in the diffusion path to the next. We then choose our discretisation schedule to minimise the total cost incurred when simulating the entire path from $p_{1}$ to $p_{0}$ . Our cost purely depends on the distributional shifts along the diffusion path and assumes perfect score estimation, hence, we refer to our schedules as score-optimal diffusion schedules. The resulting algorithm is cheap to compute, easy to implement and requires no hyperparameter search. Our algorithm can be applied to find discretisation schedules for sampling pre-trained models as well as performed online during DDM training. We demonstrate our proposed method on highly complex 1D distributions and show our method scales to high dimensional image data where it recovers previously known performant discretisation schedules discovered only through manual hyperparameter search. To the best of our knowledge, this is the first online data-dependent adaptive discretisation schedule tuning algorithm. ", "page_idx": 1}, {"type": "text", "text": "2 The Cost of Traversing the Diffusion Path ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "To derive our optimal discretisation schedule, we first need to derive a notion of cost of traversing from our reference distribution $p_{1}$ to the data distribution $p_{0}$ through each intermediate distribution $p_{t}$ , referred to as the diffusion path. We will then later find the discretisation schedule that minimises the total cost of traversing this path. Our notion of cost is based on the idea that while integrating Equation (3) from time $t$ to $t^{\\prime}$ will always take you from $p_{t}$ to $p_{t^{\\prime}}$ , the simulation step will need to do more work to make sure the samples are distributed according to $p_{t^{\\prime}}$ if $p_{t}$ and $p_{t^{\\prime}}$ are very different distributions rather than if they are close. In the following, we will make this intuition precise. ", "page_idx": 2}, {"type": "text", "text": "2.1 Predictor/Corrector Decomposition of the Diffusion Update ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "To begin, let $\\mathbb{X}=\\mathbb{R}^{d}$ and $\\mathbb{P}(\\mathbb{X})$ be the space of Lebesgue probability measures on $\\mathbb{X}$ with smooth densities. For $t\\in[0,1]$ , define the diffusion path $p_{t}\\in\\mathbb{P}(\\mathbb{X})$ as the law of $X_{t}$ satisfying the forward diffusion Equation (1) initialised at the data distribution $X_{0}\\sim p_{0}$ , or equivalently the law of the $X_{t}$ satisfying the backward diffusion Equation (3) initialised at the reference distribution $X_{1}\\sim p_{1}$ . ", "page_idx": 2}, {"type": "text", "text": "Given a sample $X_{t}\\sim p_{t}$ , a sample $X_{t^{\\prime}}\\sim p_{t^{\\prime}}$ can be generated by integrating the backward diffusion Equation (3). In Song et al. (2021), it was shown that we can further decompose the backward diffusion Equation (3) at time $t$ into a deterministic flow governed by the probability flow ODE, and the stochastic flow driven by Langevin dynamics targeting $p_{t}$ , ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{d}X_{t}=\\underbrace{\\left(f(t)X_{t}-\\frac{1}{2}g(t)^{2}\\nabla\\log p_{t}(X_{t})\\right)}_{\\mathrm{Probability~Flow~Prediction~ODE}}\\quad+\\quad\\underbrace{-\\frac{1}{2}g(t)^{2}\\nabla\\log p_{t}(X_{t})\\mathrm{d}t+g(t)\\mathrm{d}\\widetilde{W}_{t}}_{\\mathrm{Lapevin~Correction~SDE}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "This decomposition into a deterministic flow and a correction will help us derive our cost in Section 2.2 by analysing the work done by the correction to keep the samples on the diffusion path. Here, we will first expand upon this decomposition by defining a hypothetical two-step sampling procedure that could be used to sample the DDM. It consists of: (1) a predictor step that generates a deterministic prediction of $X_{t^{\\prime}}$ and (2) a corrector step that uses Langevin dynamics targeting $p_{t^{\\prime}}$ to correct any accrued error. Note we are not advocating for the implementation of such a procedure, only that by imagining simulating with this hypothetical predictor-corrector algorithm, it will be helpful for our theoretical derivation of a cost intrinsically linked to the sampling of DDMs. The two stages of the predictor-corrector algorithm are rigorously defined as follows. ", "page_idx": 2}, {"type": "text", "text": "Definition 2.1. A predictor for $t,t^{\\prime}\\in[0,1]$ is a smooth bijective mapping $F_{t,t^{\\prime}}:\\mathbb{X}\\mapsto\\mathbb{X}_{\\mathrm{~\\scriptsize~}}$ , such that det $\\nabla F_{t,t^{\\prime}}\\neq0$ , and the predicted distribution is the pushforward of $p_{t}$ by $F_{t,t^{\\prime}}$ denoted $F_{t,t^{\\prime}}^{\\sharp}p_{t}$ . ", "page_idx": 2}, {"type": "text", "text": "Definition 2.2. A corrector for $t\\in[0,1],\\tau\\in[0,\\infty)$ is a one-parameter family Markov transition kernel $L_{t,\\tau}:\\mathbb{X}\\times\\mathbb{P}(\\mathbb{X})\\,\\mapsto\\,[0,1]$ such that $\\bar{Z_{\\tau}}\\,\\sim\\,\\bar{L}_{t,\\tau}(z,\\mathrm{d}z_{\\tau})$ is the law of Langevin dynamics stationary distribution $p_{t}$ at time $\\tau$ , initialised at $z\\in\\mathbb{X}$ , and running at speed $v(t)>0$ , ", "page_idx": 2}, {"type": "equation", "text": "$$\nZ_{0}=z,\\quad\\mathrm{d}Z_{\\tau}=v(t)\\nabla\\log p_{t}(Z_{\\tau})\\mathrm{d}\\tau+\\sqrt{2v(t)}\\mathrm{d}W_{\\tau}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The corrector map $L_{t,\\tau}$ is specified through an integration time $\\tau$ and time-dependent speed $v(t)$ . We assume $\\tau$ is fixed and we will describe the appropriate choice of $v(t)$ in Section 3.3. The predictorcorrector algorithm, given $X_{t}\\sim p_{t}$ , first applies the predictor $Z_{0}\\,=\\,F_{t,t^{\\prime}}(X_{t})$ and then uses the corrector to drive the predicted samples towards $p_{t^{\\prime}}$ , ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{Predictor:}}&{\\boldsymbol{Z_{0}}=F_{t,t^{\\prime}}\\big(\\boldsymbol{X}_{t}\\big)\\qquad\\mathrm{Corrector:}\\quad\\boldsymbol{X}_{t^{\\prime},\\tau}\\sim L_{t^{\\prime},\\tau}\\big(\\boldsymbol{Z}_{0},\\mathrm{d}\\boldsymbol{x}_{\\tau}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "In general, $Z_{0}$ will not be a sample from $p_{t^{\\prime}}$ exactly because $F_{t,t^{\\prime}}$ may not be a perfect transport from $p_{t}$ to $p_{t^{\\prime}}$ . In Section 2.2, assessing the work done by $L_{t^{\\prime},\\tau}$ to drive the $Z_{0}$ towards $p_{t^{\\prime}}$ will be key in deriving our cost. Our cost will then depend upon the specific choice for $F_{t,t^{\\prime}}$ . Two natural choices for $F_{t,t^{\\prime}}$ are apparent. Setting $F_{t,t^{\\prime}}$ to the identity means our hypothetical sampling algorithm reduces to the annealed Langevin algorithm for DDMs introduced by Song and Ermon (2019). The second natural choice is to set $F_{t,t^{\\prime}}$ to the integrator of the probability flow ODE (Song et al., 2021). ", "page_idx": 2}, {"type": "text", "text": "Example 2.1 (Annealed Langevin). The predictor step is trivial when the predictor map is the identity $F_{t,t^{\\prime}}(x)=x$ . In such a case, the predicted state reduces to the initial state, $F_{t,t^{\\prime}}(\\bar{X_{t}})=X_{t}\\sim p_{t}$ . The work done by the corrector step will then be related to the full discrepancy between $p_{t}$ and $p_{t^{\\prime}}$ because the predictor provides no help in transporting the sample. ", "page_idx": 2}, {"type": "text", "text": "Example 2.2 (Probability Flow ODE). The predictor step is optimal when $F_{t,t^{\\prime}}$ is a transport from $p_{t}$ to $p_{t^{\\prime}}$ . In such a case, the predicted state produces a sample from the target distribution, $F_{t,t^{\\prime}}(X_{t})\\sim p_{t^{\\prime}}$ , and so the corrector step would have to perform no work. An optimal predictor map $F_{t,t^{\\prime}}$ can be obtained by integrating the probability flow ODE from time $t,t^{\\prime}$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\frac{\\mathrm{d}x_{t}}{\\mathrm{d}t}=f(t)x_{t}-\\frac{1}{2}g(t)^{2}\\nabla\\log p_{t}(x_{t}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Practical algorithms numerically integrate Equation (7), e.g. an Euler step with $\\Delta t=t^{\\prime}-t$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{F_{t,t^{\\prime}}(x)=x+\\big(f(t)x-\\frac12g(t)^{2}\\nabla\\log p_{t}(x)\\big)\\Delta t.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In such a case, the work done by the corrector depends on the error in the probability flow integrator. ", "page_idx": 3}, {"type": "text", "text": "2.2 The Incremental Cost of Correction ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We now focus on deriving a cost related to the work done by the corrector step in the predictorcorrector algorithm. Later, in Section 3, we will find the discretisation schedule that minimises the total cost. To derive the cost, we will analyse the movement of $Z_{0}$ under the corrector step\u2019s dynamics $L_{t^{\\prime},\\tau}(Z_{0},\\mathrm{d}x_{\\tau})$ . This requires some care because even if $Z_{0}$ is already at stationarity, i.e. perfectly distributed according to $p_{t^{\\prime}}$ , applying the Langevin correction step will still result in movement of $Z_{0}$ due to the stochasticity of the update. However, the computed work done by the correction step in this case should be 0. To correctly assign the work done, we will compare two processes. The first is the trajectory of Langevin dynamics, $Z_{\\tau}$ , defined by the corrector $L_{t^{\\prime},\\tau}$ initialised at $Z_{0}=F_{t,t^{\\prime}}(X_{t})$ targeting $p_{t^{\\prime}}$ . The second is a virtual coupled Langevin dynamics $\\tilde{Z}_{\\tau}$ initialised at $F_{t,t^{\\prime}}(X_{t})$ , driven by the same noise and speed but targeting the stationary distribution of the predictor $F_{t,t^{\\prime}}^{\\sharp}p_{t}$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{Z_{0}=F_{t,t^{\\prime}}(X_{t}),\\quad\\mathrm{d}Z_{\\tau}=v(t^{\\prime})\\nabla\\log p_{t^{\\prime}}(Z_{\\tau})\\mathrm{d}\\tau+\\sqrt{2v(t^{\\prime})}\\mathrm{d}W_{\\tau},}\\\\ &{\\tilde{Z}_{0}=F_{t,t^{\\prime}}(X_{t}),\\quad\\mathrm{d}\\tilde{Z}_{\\tau}=v(t^{\\prime})\\nabla\\log F_{t,t^{\\prime}}^{\\sharp}p_{t}(\\tilde{Z}_{\\tau})\\mathrm{d}\\tau+\\sqrt{2v(t^{\\prime})}\\mathrm{d}W_{\\tau}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Notably, $Z_{\\tau}\\overset{d}{=}X_{t^{\\prime},\\tau}$ and $\\tilde{Z}_{\\tau}\\overset{d}{=}F_{t,t^{\\prime}}(X_{t})$ share the same law as the corrected sample and predicted sample respectively. Since $Z_{\\tau}$ and $\\tilde{Z}_{\\tau}$ are coupled to have the same noise, the difference in their trajectory, $\\bar{Z}_{\\tau}-\\tilde{Z}_{\\tau}$ , isolates the change in corrector dynamics due to discrepancy between $F_{t,t^{\\prime}}^{\\sharp}p_{t}$ and $p_{t^{\\prime}}$ . If $F_{t,t^{\\prime}}^{\\sharp}p_{t}$ is very different to $p_{t^{\\prime}}$ , then $Z_{\\tau}-\\tilde{Z}_{\\tau}$ will be large, signifying the corrector is needing to do lots of work to push the distribution of $Z$ towards the target $p_{t^{\\prime}}$ . Conversely, if $F_{t,t^{\\prime}}^{\\sharp}p_{t}=p_{t^{\\prime}}^{\\phantom{\\dagger}}$ then $Z_{\\tau}-\\tilde{Z}_{\\tau}=0$ and no work is done. For small $\\tau$ , $(Z_{\\tau}-Z_{0})/\\tau$ is the initial velocity of $Z$ under the $p_{t^{\\prime}}$ corrector dynamics, and similarly for $(\\tilde{Z}_{\\tau}-Z_{0})/\\tau$ . We can then define the incremental cost $\\mathcal{L}(t,t^{\\prime})$ by taking limits as $\\tau\\to0^{+}$ , measuring the expected $L^{2}$ norm $\\Vert\\cdot\\Vert$ of the difference, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{L}(t,t^{\\prime})=\\operatorname*{lim}_{\\tau\\to0^{+}}\\tau^{-2}\\operatorname{\\mathbb{E}}\\left[\\left\\|(Z_{\\tau}-Z_{0})-(\\tilde{Z}_{\\tau}-Z_{0})\\right\\|^{2}\\right]=\\operatorname*{lim}_{\\tau\\to0^{+}}\\tau^{-2}\\operatorname{\\mathbb{E}}\\left[\\left\\|Z_{\\tau}-\\tilde{Z}_{\\tau}\\right\\|^{2}\\right].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We can approximate $Z_{\\tau}-\\tilde{Z}_{\\tau}$ using an Euler step, noting that the coupled noise terms cancel, ", "page_idx": 3}, {"type": "equation", "text": "$$\nZ_{\\tau}-\\tilde{Z}_{\\tau}=\\tau v(t^{\\prime})(\\nabla\\log p_{t^{\\prime}}(Z_{t,t^{\\prime}})-\\nabla\\log F_{t,t^{\\prime}}^{\\sharp}p_{t}(Z_{t,t^{\\prime}}))+o(\\tau).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "By substituting Equation (12) in Equation (11), we have ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{L}(t,t^{\\prime})=v(t^{\\prime})^{2}\\mathbb{E}\\left[\\left\\Vert\\nabla\\log p_{t^{\\prime}}(Z_{0})-\\nabla\\log F_{t,t^{\\prime}}^{\\sharp}p_{t}(Z_{0})\\right\\Vert^{2}\\right]=v(t^{\\prime})^{2}D(p_{t^{\\prime}}\\|F_{t,t^{\\prime}}^{\\sharp}p_{t}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $D(p||q)=\\mathbb{E}_{X\\sim q}[\\|\\nabla\\log p(X)-\\nabla\\log q(X)\\|^{2}]$ is a statistical divergence on $p,q\\in\\mathbb{P}(\\mathbb{X})$ , measuring the $L^{2}$ distance between the scores of $q$ and $p$ with respect $q$ . $D(p||q)$ is referred to as the Stein divergence or the Fisher divergence; see e.g. (Johnson, 2004). For a given choice of $v(t)$ and $F_{t,t^{\\prime}}$ we now have a cost measuring the change from $p_{t}$ to $p_{t^{\\prime}}$ . This cost is intrinsically linked with the effort performed by a DDM sampling algorithm because it is derived through considering the work done by a hypothetical predictor-corrector style update. We note, however, that this general cost can be used to obtain discretisation schedules for use in any style of DDM sampler. ", "page_idx": 3}, {"type": "text", "text": "2.3 Corrector and Predictor Optimised Cost ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "By inverting $Z_{0}=F_{t,t^{\\prime}}(X_{t})$ , we can express Equation (13) in terms of an expectation with respect to the reference sample $X_{t}\\sim p_{t}$ , and the score of $G_{t,t^{\\prime}}:\\mathbb{X}\\mapsto\\mathbb{R}_{+}$ , the incremental weight function associated with the transport $F_{t,t^{\\prime}}$ from the Sequential Monte Carlo literature (Arbel et al., 2021), ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{L}(t,t^{\\prime})=v(t^{\\prime})^{2}\\mathbb{E}\\left[\\|\\nabla\\log G_{t,t^{\\prime}}(X_{t})\\|^{2}\\right],\\quad G_{t,t^{\\prime}}(x)=\\frac{p_{t^{\\prime}}(F_{t,t^{\\prime}}(x))}{p_{t}(x)}\\left|\\operatorname*{det}\\nabla F_{t,t^{\\prime}}(x)\\right|.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In most cases, it is infeasible to efficiently compute the Jacobian correction in Equation (14). When $F_{t,t^{\\prime}}(x)=x$ is the identity map corresponding to the corrector optimised update from Example 2.1 Equation (14) reduces a rescaled Stein discrepancy between $p_{t}$ and $p_{t^{\\prime}}$ , and $\\bar{G}_{t,t}(x)=p_{t^{\\prime}}(x)\\bar{/}p_{t}(x)$ reduces to the likelihood-ratio between $p_{t^{\\prime}}$ and $p_{t}$ . We will refer to this case as the corrector-optimised cost denoted $\\mathcal{L}_{c}(t,t^{\\prime})$ , to distinguished it from the predictor-optimised cost $\\mathcal{L}_{p}(t,t^{\\prime})$ derived above, where when relevant, we will use subscripts $c$ and $p$ to distinguish between the two: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{L}_{c}(t,t^{\\prime})=v(t^{\\prime})^{2}D(p_{t^{\\prime}}\\|p_{t}),\\qquad\\mathcal{L}_{p}(t,t^{\\prime})=v(t^{\\prime})^{2}D(p_{t^{\\prime}}\\|F_{t,t^{\\prime}}^{\\sharp}p_{t}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The corrector-optimised cost $\\mathcal{L}_{c}(t,t^{\\prime})$ provides meaningful information during the update from reference $p_{t}$ to the target $p_{t^{\\prime}}$ . It is worth computing even when the predictor-optimised cost $\\mathcal{L}_{p}(t,t^{\\prime})$ is accessible. $\\mathcal{L}_{c}(t,t^{\\prime})$ measures the change between the reference and target distribution independent of the predictor, whereas $\\mathcal{L}_{p}(t,t^{\\prime})$ measures the residual error between the predictor and target. Notably, $\\mathcal{L}_{c}(t,t^{\\prime})$ encodes information about the incremental geometry of the diffusion path, whereas $\\mathcal{L}_{p}(t,t^{\\prime})$ quantifies information about the incremental efficiency of the predictor. Generally, one does not dominate the other, but if the predictor is well-tuned and the predictor flows samples $X_{t}\\sim p_{t}$ towards $p_{t^{\\prime}}$ , we would expect $\\mathcal{L}_{p}(\\bar{t},t^{\\prime})\\leq\\mathcal{L}_{c}(t,t^{\\prime})$ . ", "page_idx": 4}, {"type": "text", "text": "For deriving our optimal discretisation schedule, we require a notion of how $\\mathcal{L}(t,t^{\\prime})$ increases with small increases in $t^{\\prime}$ i.e. knowing local changes in incremental cost. In Section 3, we use this local cost to assign distances to schedules through time, enabling us to find the best schedule. We derive the desired local cost in Theorem 2.1, see Appendix A for a PDE and geometric interpretation. ", "page_idx": 4}, {"type": "text", "text": "Theorem 2.1. Suppose $p_{t}(x),F_{t,t^{\\prime}}(x),v(t)$ and $G_{t,t^{\\prime}}(\\boldsymbol{x})$ are three-times continuously differentiable in $t,t^{\\prime},x$ and let $\\begin{array}{r}{\\dot{F}_{t}(x)\\,=\\,\\frac{\\partial}{\\partial t^{\\prime}}F_{t,t^{\\prime}}(x)\\big|_{t^{\\prime}=t}}\\end{array}$ and $\\begin{array}{r}{\\dot{G}_{t}(x)=\\left.\\frac{\\partial}{\\partial t^{\\prime}}G_{t,t^{\\prime}}(x)\\right|_{t^{\\prime}=t}}\\end{array}$ . Suppose the following hold: $(I)$ for all $x\\in\\mathbb{X},t\\in[0,1]$ , $F_{t,t}(x)=x$ and (2) there exists $V:\\mathbb{X}\\mapsto\\mathbb{R}$ such that for all $x\\in\\mathbb{X}$ and $t\\in[0,1]$ , $\\|\\nabla\\dot{G}_{t}(x)\\|^{2}\\leq V(x)$ and $\\operatorname*{sup}_{t\\in[0,1]}\\mathbb{E}_{X_{t}\\sim p_{t}}[V(X_{t})]<\\infty$ . Then for all $t\\in[0,1]$ , we have $\\mathcal{L}(t,t^{\\prime})=\\delta(t)\\Delta t^{2}+O(\\Delta t^{3})$ , where ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\delta(t)=v(t)^{2}\\mathbb{E}_{X_{t}\\sim p_{t}}\\left[\\left\\Vert\\nabla\\dot{G}_{t}(X_{t})\\right\\Vert^{2}\\right],\\quad\\dot{G}_{t}=\\frac{\\partial}{\\partial t}\\log p_{t}+\\nabla\\log p_{t}\\cdot\\dot{F}_{t}+\\mathrm{Tr}\\nabla\\dot{F}_{t}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Theorem 2.1 shows that, under regularity assumptions, then the incremental cost is $\\mathscr{L}(t,t^{\\prime})\\approx\\delta(t)\\Delta t^{2}$ is locally quadratic and controlled by the local cost $\\delta(t)$ . The $\\delta(t)$ measures the sensitivity of the incremental cost $\\mathcal{L}(t,t^{\\prime})$ to moving samples along the diffusion path to $t^{\\prime}\\approx t$ . Notably, $\\delta(t)=0$ if and only if the predictor satisfies the continuity equation, $\\begin{array}{r}{\\frac{\\partial}{\\partial t}p_{t}+\\nabla\\cdot\\left(p_{t}\\dot{F}_{t}\\right)=0}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "3 Score-Optimal Schedules ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Given a discretisation schedule $\\tau=(t_{i})_{i=0}^{T}$ satisfying $0=t_{0}<\\dots<t_{T}=1$ , our hypothetical predictor-corrector algorithm recursively uses the predictor and corrector maps to generate a sequence $(X_{i})_{i=0}^{T}$ starting at $X_{T}\\sim p_{1}$ such that the terminal state $X_{0}$ approximates samples from $p_{0}$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\nX_{i}\\sim L_{t_{i},\\tau}(F_{t_{i+1},t_{i}}(X_{i+1}),\\mathrm{d}x_{i}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We want to identify a discretisation schedule that maximises the efficiency of this iterative procedure. This is not generally possible due to the potential complex interactions that arise from the accrued errors. To simplify our analysis, we make the following assumption. ", "page_idx": 4}, {"type": "text", "text": "Assumption 3.1. For all $t,t^{\\prime}$ , if $X_{t}\\sim p_{t}$ and $X_{t^{\\prime},\\tau}=L_{t^{\\prime},\\tau}(F_{t,t^{\\prime}}(X_{t}),\\mathrm{d}x_{\\tau}),$ , then $X_{t^{\\prime},\\tau}\\sim p_{t^{\\prime}}$ . ", "page_idx": 4}, {"type": "text", "text": "Assumption 3.1 is reasonable if, in our hypothetical corrector steps, $\\tau$ is set sufficiently large such that the Langevin correction converges to stationarity. We find in our experiments that even if the schedules derived under Assumption 3.1 are used in sampling algorithms for which Assumption 3.1 does not hold, we still obtain high quality samples. Equipped with Assumption 3.1, we can measure the efficiency of the path update through total accumulated cost $\\begin{array}{r}{\\mathcal{L}=\\sum_{i=1}^{T}\\mathcal{L}(t_{i+1},t_{i})}\\end{array}$ , which we will use as our objective to optimise $\\tau$ . In this section, we will ident ify the optimal schedule $\\tau^{*}$ minimising the cost $\\mathcal{L}$ by considering an infinitely dense limit. We will then provide a tuning procedure amenable to online schedule optimisation during training. Finally, we will discuss a suitable choice for $v(t)$ , the velocity of our hypothetical corrector steps, as well as related work. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "3.1 Diffusion Schedule Path Length and Energy ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Let $\\varphi:[0,1]\\,\\mapsto\\,[0,1]$ be a strictly increasing, differentiable function such that $\\varphi(0)\\,=\\,0$ and $\\varphi(1)\\,=\\,1$ . We will say $\\tau$ is generated by $\\varphi$ if $t_{i}\\,=\\,\\varphi(i/T)$ for all $i\\,=\\,0,\\dots,T$ . The schedule generator $\\varphi$ dictates how fast our samples move through their diffusion path. Since every schedule $\\tau$ of size $T$ is generated by some $\\varphi$ , optimising $\\tau$ is equivalent to finding a generator $\\varphi$ minimising $\\mathcal{L}(\\varphi,T)$ , the total cost accumulated by the schedule of size $T$ generated by $\\varphi$ . By Jensen\u2019s inequality, we have $\\mathcal{L}(\\varphi,T)\\ge\\Lambda(\\varphi,T)^{2}/T$ , where for $t_{i}=\\varphi(i/T)$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathcal{L}(\\varphi,T):=\\sum_{i=1}^{T}\\mathcal{L}(t_{i+1},t_{i}),\\quad\\Lambda(\\varphi,T)=\\sum_{i=1}^{T}\\sqrt{\\mathcal{L}(t_{i+1},t_{i})}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "As we later prove in Theorem 3.1, in the dense schedule limit as $T\\to\\infty$ , the cost $\\mathcal{L}(\\varphi,T)$ and its lower bound $\\Lambda(\\varphi,T)$ are controlled by the energy $E(\\varphi)$ and length $\\Lambda$ respectively where, ", "page_idx": 5}, {"type": "equation", "text": "$$\nE(\\varphi)=\\int_{0}^{1}\\delta(\\varphi(s))\\dot{\\varphi}(s)^{2}\\mathrm{d}s,\\quad\\Lambda=\\int_{0}^{1}\\sqrt{\\delta(t)}\\mathrm{d}t.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The intuition for why $E(\\varphi)$ is an energy, and $\\Lambda$ a length can be gained by first conceptualising the diffusion time $t$ as a spatial variable rescaled by the metric $\\delta(t)$ defined by our cost $\\mathcal{L}$ . We have $\\varphi$ and $\\dot{\\varphi}$ are position and velocity, respectively. Integrating the speed $\\begin{array}{r}{\\int_{0}^{1}\\sqrt{\\delta(\\varphi(s))}\\dot{\\varphi}(s)\\mathrm{d}s=\\int_{0}^{1}\\sqrt{\\delta(t)}\\mathrm{d}t}\\end{array}$ along a curve $\\varphi(s)$ obtains the \u201clength\u201d $\\Lambda$ , whilst integrating a speed squared, $\\begin{array}{r}{\\int_{0}^{1}\\delta(\\varphi(s))\\dot{\\varphi}(s)^{2}\\mathrm{d}s}\\end{array}$ obtains a \u201ckinetic energy\u201d $E(\\varphi)$ . Note that the length is an invariant of the schedule, whereas the kinetic energy is not. The length $\\Lambda$ measures the intrinsic difficulty of traversing the diffusion path according to the cost independent of $\\varphi$ , whereas $E(\\varphi)$ measures the efficiency of how the path was traversed using $\\varphi$ . This geometric intuition hints at the solution to the optimal scheduling problem. The optimal $\\varphi$ should travel on a geodesic path from $p_{1}$ to $p_{0}$ , at a constant speed with respect to metric $\\delta$ . For this optimal $\\varphi$ , we then have the kinetic energy being equal to the square of length between $p_{1}$ and $p_{0}$ . Theorem 3.1 makes the previous discussion precise. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.1. Suppose the assumptions of Theorem 2.1 hold. For all schedule generators $\\varphi$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{T\\to\\infty}T{\\mathcal{L}}(\\varphi,T)=E(\\varphi),\\quad\\operatorname*{lim}_{T\\to\\infty}\\Lambda(\\varphi,T)=\\Lambda.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Moreover, $E(\\varphi)\\geq\\Lambda^{2}$ , with equality if and only if $\\varphi^{*}$ satisfies, ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\varphi^{*}(s)=\\Lambda^{-1}(\\Lambda s),\\quad\\Lambda(t)=\\int_{0}^{t}\\sqrt{\\delta(u)}\\mathrm{d}u.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Notably independent of the choice of $\\varphi$ , as $T\\to\\infty$ , the cost $\\mathcal{L}(\\varphi,T)\\sim E(\\varphi)/T$ . This implies that the cost decays to zero at a linear rate, proportional to $E(\\varphi)$ and ${\\mathcal{L}}(\\varphi,T)\\gtrsim\\Lambda^{2}/T$ independent of $\\varphi$ . Equation (21) provides an explicit formula for the optimal schedule generator that minimises the dense limit of the total cost and obtains the lower bound $E(\\varphi^{*})=\\Lambda^{2}$ . The intuition for the formula $\\varphi^{*}(s)=\\Lambda^{-1}(\\Lambda s)$ is that this implies $\\Lambda(\\varphi^{*}(s))=\\Lambda s$ meaning say $10\\%$ of the way through the optimal schedule, we should have traversed $10\\%$ of the way along the distance between $p_{1}$ and $p_{0}$ i.e. $0.1\\times\\Lambda$ . This relation holds for constant speed straight lines, meaning $\\varphi^{*}$ is the optimal schedule. For a finite $T$ , Theorem 2.1 implies the optimal schedule $\\boldsymbol{T}^{*}=\\{t_{i}^{*}\\}_{i=0}^{T}$ generated by $\\varphi^{*}$ ensures the incremental cost is constant $\\bar{\\mathcal{L}}(t_{i+1}^{*},t_{i}^{*})\\stackrel{*}{\\approx}\\Lambda^{2}/T^{2}$ for all $i=0,\\ldots,T-1$ . ", "page_idx": 5}, {"type": "text", "text": "Our geometric intuition in the language of differential geometry is that the diffusion path $\\mathcal{M}=$ $\\{p_{t}\\}_{t\\in[0,1]}$ is Riemannian manifold with metric $\\delta$ endowed by the incremental cost $\\mathcal{L}(t,t^{\\prime})$ . The schedule generator defines a curve $s\\mapsto p_{\\varphi(s)}\\in\\mathcal{M}$ reparametrising the diffusion path between $p_{0}$ and $p_{1}$ . Theorem 3.1 shows that $\\varphi^{*}$ is the geodesic of length $\\Lambda$ in $\\mathcal{M}$ between $p_{1}$ and $p_{0}$ that traverses the diffusion path at a constant speed $\\sqrt{\\delta(\\varphi^{*}(s))}\\dot{\\varphi}^{*}(s)=\\Lambda$ with respect to $\\delta$ and minimises the cost. ", "page_idx": 5}, {"type": "text", "text": "3.2 Estimation of Score-Optimal Schedules ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Given a schedule $\\mathcal{T}=\\{t_{i}\\}_{i=0}^{T}$ and estimates of the incremental cost $\\mathcal{L}(t_{i+1},t_{i})$ , Algorithm 1 adapts Algorithm 3 from Syed et al. (2021) to estimate the optimal schedule $\\tau^{*}=\\{t_{i}^{*}\\}_{i=0}^{T}$ generated by $\\varphi^{*}$ . We can use Algorithm 1 to refine the schedule for a pre-trained DDM or learn the schedule jointly with the score function. For this joint procedure, we detail in Appendix B.1 how function evaluations can be reused to estimate the cost to minimise computational overhead. For $\\mathcal{L}_{c}(t,t^{\\prime})$ we need only evaluate $\\nabla\\log p_{t}(X_{t})$ and $\\nabla\\log p_{t^{\\prime}}(X_{t})$ both available through our model\u2019s score estimate. Computing $\\mathcal{L}_{p}(t,t^{\\prime})$ is more challenging since there are Hessian terms that arise in Equation (14). Under the assumption that the step size $\\Delta t>0$ is sufficiently small, we can approximate $\\nabla\\log\\vert\\operatorname*{det}\\nabla F_{t,t^{\\prime}}(X_{t})\\vert$ through Proposition B.1. This approximation only requires us to compute the gradient trace of the Jacobian of our predicted score. With computational cost proportionate to the computational effort for computing the first derivative. Using a Hutchinson trace (Hutchinson, 1989) like estimator in Proposition B.1, we compute this quantity memory-efficiently in high dimensions, requiring only standard auto-differentiation back-propagation. ", "page_idx": 6}, {"type": "text", "text": "3.3 Choice of Velocity Scaling ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Recall that our cost is derived by considering a Langevin dynamics step with velocity $v(t)$ . This velocity should be selected so that Langevin dynamics explores the same proportion of our distribution at varying times throughout our diffusion path. Thus, $v(t)$ should be on the same scale as the spread of the target, $p_{t}$ . Commonly used noising schedules have $s(t)\\leq1$ , and our data distribution is normalised so the scale of $p_{t}$ is on the order of $\\sigma(t)$ . We therefore set $v(t)\\,=\\,\\sigma(t)$ . This results in a $\\sigma(t^{\\prime})$ -weighted divergence for our incremental cost $\\mathcal{L}(t,t^{\\prime})\\,=\\,\\sigma(t^{\\prime})^{2}\\dot{D}(p_{t^{\\prime}}||p_{t})$ . This can be compared to the weighted denoising score matching loss used to train DDMs (Song et al., 2021), which is also a squared norm of score differences: $\\boldsymbol{\\lambda}(\\dot{t})\\mathbb{E}_{X_{0},X_{t}}\\left[\\|s_{\\theta}(X_{t},t)-\\nabla\\log p_{t|0}^{-}(X_{t}|X_{0})\\|^{2}\\right]$ for some weighting function $\\lambda(t)$ chosen to equalise the magnitude of the cost over the path. In Song et al. (2021), $\\bar{\\lambda}(t)\\,\\mathrm{\\bar{~}{\\alpha}}\\,1/\\mathbb{E}[\\|\\nabla\\operatorname{log}p_{t|0}(X_{t}|X_{0})\\|^{2}]$ was chosen, which, as we show in Appendix B.3, is $\\lambda(t)\\propto\\sigma^{2}(t)$ . This choice of velocity scaling provides an alternative perspective on this commonly used weighting of squared norms of score differences. ", "page_idx": 6}, {"type": "table", "img_path": "0rl5vWOzRU/tmp/89e1258c8d40c2c39bf61b526a133750e25dd04ae219251fcc60350247cfa1d6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "3.4 Related Work ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Previous works have devised algorithms and heuristics for designing noising and discretisation schedules. The DDM training objective is invariant to the noising schedule shape, as demonstrated by Kingma et al. (2021), necessitating auxiliary costs and objectives for schedule design. Uniform steps in the signal-to-noise ratio, $\\log{\\left(s(t_{i})/\\sigma(t_{i})\\right)}$ , are used by Lu et al. (2022), but this ignores the target distribution\u2019s geometry. Watson et al. (2021) optimise the schedule by differentiating through sampling to maximise quality, but GPU memory constraints necessitate gradient rematerialisation. We avoid this with a simulation-free cost. Closely related to our work is Sabour et al. (2024), who minimise a pathwise KL-divergence between discretised and continuous processes. They require multi-stage optimisation with early stopping to prevent over-optimisation of their objective which would otherwise result in worse schedules. Amongst the wider literature, various strategies for discretisation schedule tuning have been proposed. Das et al. (2023) derive an equally spaced schedule using the Fisher metric but assume Gaussian data. Santos et al. (2023) assign time points proportional to the Fisher information of $p_{t|0}(x_{t}\\mid x_{0})$ , ignoring the true target distribution. Xue et al. (2024) derive a schedule to control ODE simulation error, but their cost depends only on the ODE solver, and not on the data distribution. ", "page_idx": 6}, {"type": "text", "text": "4 Computational Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "4.1 Sampling the Mollified Cantor Distribution ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The Cantor distribution (Cantor, 1884) lacks a Lebesgue density, with its cumulative distribution function represented by the Devil\u2019s staircase and its support being the Cantor set, forming a challenging 1-D test example. When mollified with Gaussian noise, it becomes absolutely continuous and possesses a Stein score. We mollify by running a diffusion with the linear schedule for time $t=10^{-5}$ . With this mollification, our data density has eight pronounced peaks. We train a one-dimensional DDM for 150,000 iterations using both a fixed linear schedule and our optimisation algorithm Algorithm 2 initialised at the linear schedule. We find that the non-data-specific default schedule fails to capture these modes, whilst our adaptive method faithfully reproduces the data distribution. In Figure 7 we show the complexity of the learned score which displays a self-similar fractal structure. ", "page_idx": 7}, {"type": "text", "text": "4.2 Adaptive Schedule Learning for Bimodal Example ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We train a DDM on a simple bimodal Gaussian distribution. When the variance of the target bimodal Gaussian is low, it becomes difficult to adequately sample from the target distribution. In our instance, the standard Gaussian reference from the diffusion is given, and the target is the density $\\begin{array}{r}{p_{0}(x)=\\frac{1}{2}p_{\\mathrm{left}}(x)+\\frac{1}{2}p_{\\mathrm{right}}(x)}\\end{array}$ , where $p_{\\mathrm{left}}$ and $p_{\\mathrm{right}}$ are normal distributions with means $-6$ and 6, respectively, and a common variance $\\sigma^{2}=0.1^{2}$ . ", "page_idx": 7}, {"type": "text", "text": "We learn two diffusion models, one using the linear schedule, and the other using a schedule that is learned online during training. We compute the likelihood of the samples generated from either model during training, which is possible in this example because the true probability density is known. It can be seen in Figure 2 that when the schedule is learned during training, the likelihood evaluation increases and the true score error decreases, in contrast to the linear schedule that remains constant, or worsens, in this regard during training. ", "page_idx": 7}, {"type": "image", "img_path": "0rl5vWOzRU/tmp/502ae345eeb8f57ed9b3cfcc4bce76055cea65f1ba4ed4a399c50353c7c0e140.jpg", "img_caption": ["Figure 2: Comparison of Linear and Learned Schedules over Training Iterations for the bimodal example. Each point corresponds to 500 training iterations. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "4.3 Scalable Schedule Learning Diffusion ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Here we demonstrate that jointly learning the schedule and score using our online training methodology (Algorithm 2) scales to high-dimensional data and converges to a stable solution. We train DDMs on CIFAR-10 and MNIST initialised at the cosine schedule using the codebase from Nichol and Dhariwal (2021). In Figure 3 (left), we show the incremental costs $\\sqrt{\\mathcal{L}(t_{j+1},t_{j})}$ for the cosine schedule and our learned schedule, finding that the increments approximately equalise over the diffusion path as expected by the discussion in Section 3.1. Figure 3 (right) shows the learned schedule spends more time at high-frequency details, we visualise a sampling trajectory in Figure 11. ", "page_idx": 7}, {"type": "text", "text": "Table 1: Sample quality measured by Fr\u00e9chet Inception Distance (FID) versus schedule on CIFAR10 $(32\\times32)$ , FFHQ, AFHQv2, ImageNet $(64\\times64)$ . Pretrained models are used from Karras et al. (2022). All FIDs are calculated using 50000 samples. We highlight the best FID in bold. The ImageNet model lacks second-order differentiation, so no predictor optimised schedule is shown. ", "page_idx": 8}, {"type": "table", "img_path": "0rl5vWOzRU/tmp/5aa21ee47ccf8fc30b4801bd12cc9c67508e6375104e5e4de7ff5d221a79bbb5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "0rl5vWOzRU/tmp/86ac99d6e6216517540626dff1f60c1db3a7cee9e789e5c93716de4f1c884167.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 4: (Left) Costs associated with different schedule choices for the CIFAR10 dataset. Schedules are ordered from lowest FID to highest FID. We compare our Corrector-optimised (CO) cost and Predictor-optimised (PO) cost versus the Kullback-Leibler Upper Bound (KLUB) from Sabour et al. (2024). The minimum value for each cost is highlighted in bold. Note low cost is associated with low FID for our cost and not for the KLUB. (Right) Visualisation of schedules during generative sampling with 100 timesteps. \u201crho $=3^{\\circ}$ and \u201crho $\\scriptstyle=7^{\\circ}$ refer to Eq 22 with $\\rho=3$ and $\\rho=7$ respectively. LogLinear from Lu et al. (2022) and a convex schedule are also shown. We show our cost optimised schedules for CIFAR10 both using the corrector optimised cost and the predictor optimised cost. ", "page_idx": 8}, {"type": "image", "img_path": "0rl5vWOzRU/tmp/65d97cbca59db5a0c6c467a68f2559f4c2c3121e4efc41b84eb34adec941c20b.jpg", "img_caption": ["Figure 3: (Left) Incremental costs $\\sqrt{\\mathcal{L}(t_{j+1},t_{j})}$ for the cosine schedule and our online adaptive algorithm. Higher learning rates enforce equalisation of costs more quickly. (Right) Progr\u221aession of the learned schedule during $40\\mathrm{k}$ training iterations, depicted through the standard-deviation $\\sqrt{1-{\\bar{\\alpha}}_{t}}$ . "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "4.4 Sampling Pre-Trained Models ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this experiment we demonstrate that our algorithm can recover performant schedules for large image models used in practice and our schedules generate high quality samples. We use the pretrained models from Karras et al. (2022), whose DDM is parameterised such that the forward noising distribution is of the form $p_{t|0}(x_{t}|x_{0})=\\mathcal{N}(x_{t};x_{0},\\sigma_{t}^{2}I)$ . The scheduling problem then reduces to deciding on a stepping scheme through $\\{\\sigma_{i}\\}_{i=1}^{N}$ , $\\sigma_{N}=0$ . Karras et al. (2022) suggest a polynomial based schedule with a parameter $\\rho$ that controls the curvature of the schedule ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sigma_{i<N}=\\Big(\\sigma_{\\mathrm{max}}^{\\frac{1}{\\rho}}+\\frac{i}{N-1}\\Big(\\sigma_{\\mathrm{min}}^{\\frac{1}{\\rho}}-\\sigma_{\\mathrm{max}}^{\\frac{1}{\\rho}}\\Big)\\Big)^{\\rho}\\quad\\mathrm{and}~\\sigma_{N}=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "A lower $\\rho$ value results in steps near $\\sigma_{\\mathrm{min}}$ being shortened and steps near $\\sigma_{\\mathrm{max}}$ being lengthened. Through analysing the truncation error for sampling in Karras et al. (2022), they find that setting $\\rho=3$ approximately equalises this error, however it is found empirically that $\\rho=7$ results in better sample quality. We also compare against a schedule that takes uniform steps in $\\log\\sigma$ space Lu et al. (2022) which we refer to as the LogLinear schedule and a schedule that takes a convex shape in log space. Schedule visualisations are provided in Figure 4 (right). ", "page_idx": 9}, {"type": "text", "text": "We sampled the pre-trained models using these schedules and computed the sample quality using FID. We use the same number of schedule steps (18 for CIFAR10, 40 for FFHQ and AFHQv2, 256 for ImageNet) and solver (Heun second order) as Karras et al. (2022). Our results are shown in Figure 4. Our optimised schedules are able to achieve competitive FID to the best performing $\\rho=7$ schedule hand-tuned in Karras et al. (2022). This is expected as our schedules take a similar shape to the $\\rho=7$ schedule as shown in Figure 4 (right). Therefore, our method provides an entirely automatic and hyperparameter free algorithm to recover this performant schedule that was previously only discovered through trial-and-error. ", "page_idx": 9}, {"type": "text", "text": "We further analyse how the number of discretisation points, $T$ , used during sampling affects the quality of generated samples for different schedules. We report our results on CIFAR10 in Table 2. Notably, the FID decreases with $T$ for all schedules and achieves comparable FID once $T$ is large enough. However, when $T$ is small, only the optimised schedules maintain stable performance. This empirically demonstrates an optimised schedule can improve the sampling efficiency by allowing for coarser discretisations and, hence, faster sampling, as predicted by Theorem 3.1. We observe an identical trend for sFID in Table 3 in the Appendix C.2. ", "page_idx": 9}, {"type": "table", "img_path": "0rl5vWOzRU/tmp/5afb67dac03796d0dd0a266ab790750520e259921906996b1b141dcfa79b2cdd.jpg", "table_caption": ["Table 2: Comparison of FID across different amounts of discretisation points for different schedules on CIFAR10. CO stands for our corrector optimised schedule. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "We also compare corrector optimised schedules to predictor optimised schedules in Table 1. They provide similar performance so, on image datasets, we encourage the use of the cheaper to compute corrector optimised schedule. Finally, in Figure 4 (left), we report the raw values of our corrector optimised costs and compare these costs to the values of the objective introduced in Sabour et al. (2024). Both algorithms aim to find schedules that minimise these costs and therefore it is desirable for low values of cost to be associated with good sample quality (i.e. low FID). We find that low values of our cost correlate much more closely with low FID than the objective introduced by Sabour et al. (2024). Indeed, Sabour et al. (2024) introduce a bespoke multi-stage optimisation for their cost because they found over-optimising their objective can lead to worse schedules which is explained by the objective not correlating well with FID. We further find that our predictor optimised costs are lower than the corrector optimised costs which is to be expected as the predictor reduces the work done by the corrector and thus reduces the incremental cost. The overall shape of schedule, however, between the corrector optimised and predictor optimised costs is similar. ", "page_idx": 9}, {"type": "text", "text": "5 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We have introduced a method for selecting an optimal DDM discretisation schedule by minimising a cost linked to the work done in transporting samples along the diffusion path. Our algorithm is computationally cheap and does not require hyperparameter tuning. Our learned schedule achieves competitive FID scores. Regarding limitations, the computation of $\\mathcal{L}_{p}$ can be computationally expensive due the calculation of second derivatives, however, in Section 4.4 we found $\\mathcal{L}_{c}$ to provide a cheap and performant alternative. Furthermore, our theory is derived assuming perfect score estimation. Future work can expand on the geometric interpretation of the diffusion path and links to information geometry to further refine the DDM methodology. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Arbel, M., Matthews, A., and Doucet, A. (2021). Annealed flow transport Monte Carlo. In International Conference on Machine Learning.   \nCantor, G. (1884). De la puissance des ensembles parfaits de points: Extrait d\u2019une lettre adress\u00e9e \u00e0 l\u2019\u00e9diteur. Acta Mathematica, 4:381\u2013392. Reprinted in: E. Zermelo (Ed.), Gesammelte Abhandlungen Mathematischen und Philosophischen Inhalts, Springer, New York, 1980.   \nChoi, Y., Uh, Y., Yoo, J., and Ha, J.-W. (2020). Stargan v2: Diverse image synthesis for multiple domains. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.   \nDas, A., Fotiadis, S., Batra, A., Nabiei, F., Liao, F., Vakili, S., Shiu, D.-s., and Bernacchia, A. (2023). Image generation with shortest path diffusion. In International Conference on Machine Learning.   \nDeng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. (2009). Imagenet: A large-scale hierarchical image database. IEEE Conference on Computer Vision and Pattern Recognition.   \nFritsch, F. N. and Carlson, R. E. (1980). Monotone piecewise cubic interpolation. SIAM Journal on Numerical Analysis, 17(2):238\u2013246.   \nHo, J., Jain, A., and Abbeel, P. (2020). Denoising diffusion probabilistic models. In Advances in Neural Information Processing Systems.   \nHutchinson, M. (1989). A stochastic estimator of the trace of the influence matrix for Laplacian smoothing splines. Communications in Statistics - Simulation and Computation, 18(3):1059\u20131076.   \nJohnson, O. (2004). Information Theory and the Central Limit Theorem. World Scientific.   \nKarras, T., Aittala, M., Aila, T., and Laine, S. (2022). Elucidating the design space of diffusion-based generative models. In Advances in Neural Information Processing Systems.   \nKarras, T., Laine, S., and Aila, T. (2018). A style-based generator architecture for generative adversarial networks. arxiv e-prints. In Conference on Computer Vision and Pattern Recognition (CVPR).   \nKingma, D., Salimans, T., Poole, B., and Ho, J. (2021). Variational diffusion models. In Advances in Neural Information Processing Systems.   \nKrizhevsky, A., Hinton, G., et al. (2009). Learning multiple layers of features from tiny images.   \nLu, C., Zhou, Y., Bao, F., Chen, J., Li, C., and Zhu, J. (2022). DPM-solver: A fast ODE solver for diffusion probabilistic model sampling in around 10 steps. In Advances in Neural Information Processing Systems.   \nNichol, A. Q. and Dhariwal, P. (2021). Improved denoising diffusion probabilistic models. In International Conference on Machine Learning.   \nPoincar\u00e9, H. (1890). Sur les \u00e9quations aux d\u00e9riv\u00e9es partielles de la physique math\u00e9matique. American Journal of Mathematics, pages 211\u2013294.   \nSabour, A., Fidler, S., and Kreis, K. (2024). Align your steps: Optimizing sampling schedules in diffusion models. In International Conference on Machine Learning.   \nSantos, J. E., Fox, Z. R., Lubbers, N., and Lin, Y. T. (2023). Blackout diffusion: generative diffusion models in discrete-state spaces. In International Conference on Machine Learning.   \nSohl-Dickstein, J., Weiss, E. A., Maheswaranathan, N., and Ganguli, S. (2015). Deep unsupervised learning using nonequilibrium thermodynamics. In International Conference on Machine Learning.   \nSong, Y. and Ermon, S. (2019). Generative modeling by estimating gradients of the data distribution. In Advances in Neural Information Processing Systems.   \nSong, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. (2021). Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations.   \nSyed, S., Bouchard-C\u00f4t\u00e9, A., Deligiannidis, G., and Doucet, A. (2021). Non-reversible parallel tempering: a scalable highly parallel MCMC scheme. Journal of the Royal Statistical Society (Series B), 84:321\u2013350.   \nWatson, D., Ho, J., Norouzi, M., and Chan, W. (2021). Learning to efficiently sample from diffusion probabilistic models. arXiv preprint arXiv:2106.03802.   \nXue, S., Liu, Z., Chen, F., Zhang, S., Hu, T., Xie, E., and Li, Z. (2024). Accelerating diffusion sampling with optimized time steps. arXiv preprint arXiv:2402.17376. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Analysis of incremental cost ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A.1 Proof of Theorem 2.1 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Proof. We first note that by the mean value theorem, there exists $s(t,t^{\\prime})\\in[t,t^{\\prime}]$ ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\Bar{\\mathcal{L}}(t,t^{\\prime})}{|t^{\\prime}-t|^{2}}=v(t^{\\prime})^{2}\\mathbb{E}_{X_{t}\\sim p_{t}}\\left[\\left\\|\\frac{\\nabla\\bar{G}_{s(t,t^{\\prime})}(X_{t})}{t^{\\prime}-t}\\right\\|^{2}\\right]}\\\\ {=v(t^{\\prime})^{2}\\mathbb{E}_{X_{t}\\sim p_{t}}\\left[\\left\\|\\nabla\\dot{G}_{s(t,t^{\\prime})}(X_{t})\\right\\|^{2}\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Since all $t,t^{\\prime}$ we have $\\|\\nabla\\dot{G}_{s}(t,t^{\\prime})(x)\\|^{2}\\leq V(x)$ , and $\\mathbb{E}_{X_{t}\\sim p_{t}}[V(X_{t})]<\\infty$ , the dominated convergence theorem and the continuity of $v(t^{\\prime})$ implies, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{t^{\\prime}\\mapsto t}{\\operatorname*{lim}}\\,\\frac{\\mathcal{L}(t,t^{\\prime})}{|t^{\\prime}-t|^{2}}=v(t)^{2}\\mathbb{E}_{X_{t}\\sim p_{t}}\\left[\\left\\Vert\\underset{t^{\\prime}\\mapsto t}{\\operatorname*{lim}}\\,\\nabla\\dot{G}_{s(t,t^{\\prime})}(X_{t})\\right\\Vert^{2}\\right]}\\\\ &{\\qquad\\qquad\\qquad=v(t)^{2}\\mathbb{E}_{X_{t}\\sim p_{t}}\\left[\\left\\Vert\\nabla\\dot{G}_{s(t,t^{\\prime})}(X_{t})\\right\\Vert^{2}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "The last equality follows since $\\nabla\\dot{G}_{t}$ is continuous in $t$ . ", "page_idx": 12}, {"type": "text", "text": "We will now compute $\\dot{G}_{t}$ . Since $F_{t,t}(x)=x$ , we have $G_{t,t}(x)=1$ for all $x$ . This implies, we can express $\\dot{G}_{t}$ in terms of the derivative of $\\log G_{t,t^{\\prime}}$ , ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\dot{G}_{t}(x)=\\left.\\frac{\\partial}{\\partial t^{\\prime}}\\log G_{t,t^{\\prime}}(x)\\right|_{t^{\\prime}=t},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where $\\log G_{t,t^{\\prime}}$ equals, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\log G_{t,t^{\\prime}}(x)=\\log p_{t^{\\prime}}(F_{t,t^{\\prime}}(x))-p_{t}(x)+\\log\\operatorname*{det}\\nabla F_{t,t^{\\prime}}(x).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "By combining Equation (27) to Equation (28), we obtain, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\dot{G}_{t}(\\boldsymbol{x})=\\left.\\frac{\\partial}{\\partial t^{\\prime}}\\log p_{t^{\\prime}}(F_{t,t^{\\prime}}(\\boldsymbol{x}))\\right|_{t^{\\prime}=t}+\\left.\\frac{\\partial}{\\partial t^{\\prime}}\\log\\operatorname*{det}\\nabla F_{t,t^{\\prime}}(\\boldsymbol{x})\\right|_{t^{\\prime}=t}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "For the first term in Equation (29), we use chain rule to obtain, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\frac{\\partial}{\\partial t^{\\prime}}\\log p_{t^{\\prime}}(F_{t,t^{\\prime}}(x))=\\frac{1}{p_{t^{\\prime}}(F_{t,t^{\\prime}}(x))}\\left(\\frac{\\partial p_{t^{\\prime}}}{\\partial t^{\\prime}}(F_{t,t^{\\prime}}(x))+\\nabla p_{t^{\\prime}}(F_{t,t^{\\prime}}(x))\\cdot\\frac{\\partial F_{t,t^{\\prime}}}{\\partial t^{\\prime}}(x)\\right),\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where \u2018\u00b7\u2019 denotes a dot product of vectors. By evaluating at $t^{\\prime}=t$ , we have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\frac{\\partial}{\\partial t^{\\prime}}\\log p_{t^{\\prime}}(F_{t,t^{\\prime}}(x))\\Bigg|_{t^{\\prime}=t}=\\frac{1}{p_{t}(x)}\\frac{\\partial p_{t}}{\\partial t}(x)+\\frac{1}{p_{t}(x)}\\nabla p_{t}(x)\\cdot\\dot{F}_{t}(x)}}\\\\ &{}&{=\\frac{\\partial}{\\partial t}\\log p_{t}(x)+\\nabla\\log p_{t}(x)\\cdot\\dot{F}_{t}(x).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "For the second term in Equation (29), we note that as $\\Delta t=t^{\\prime}-t\\to0$ ", "page_idx": 12}, {"type": "equation", "text": "$$\nF_{t,t^{\\prime}}(x)=x+\\dot{F}_{t}(x)\\Delta t+O(\\Delta t^{2}).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "This implies that the Jacobian determinant admits the following asymptotic expansion, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log\\operatorname*{det}\\nabla F_{t,t^{\\prime}}=\\log\\operatorname*{det}(I+\\nabla\\dot{F}_{t}\\Delta t+o(\\Delta t))}\\\\ &{\\qquad\\qquad\\qquad=\\log(1+\\mathrm{Tr}\\nabla\\dot{F}_{t}\\Delta t+o(\\Delta t))}\\\\ &{\\qquad\\qquad\\quad=\\mathrm{Tr}\\nabla\\dot{F}_{t}\\Delta t+O(\\Delta t^{2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Consequentially we have, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\left.\\frac{\\partial}{\\partial t^{\\prime}}\\log\\operatorname*{det}\\nabla F_{t,t^{\\prime}}(x)\\right|_{t^{\\prime}=t}=\\mathrm{Tr}\\nabla\\dot{F}_{t}(x).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "By substituting in Equations (32) and (37) into Equation (29) we obtain, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\dot{G}_{t}(x)=\\frac{\\partial}{\\partial t}\\log p_{t}(x)+\\nabla\\log p_{t}(x)\\cdot\\dot{F}_{t}(x)+\\mathrm{Tr}\\nabla\\dot{F}_{t}(x).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "A.2 Proof of Theorem 3.1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Proof. Let $s_{i}=i/T$ and $t_{i}=\\varphi(s_{i})$ , Theorem 2.1 implies ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathcal{L}(t_{i+1},t_{i})=\\delta(t_{i+1})\\Delta t_{i}^{2}+o(\\Delta_{T}^{2}),\n$$", "text_format": "latex", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sqrt{\\mathscr{L}(t_{i+1},t_{i})}=\\sqrt{\\delta(t_{i+1})}\\Delta t_{i}+o(\\Delta_{T}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\Delta_{T}=\\operatorname*{max}_{i}|\\Delta t_{i}|$ . By the the mean value theorem, $\\Delta_{T}\\leq\\operatorname*{sup}_{s\\in[0,1]}\\dot{\\varphi}(s)/T$ and hence is $O(T^{-1})$ as $T\\to\\infty$ . ", "page_idx": 13}, {"type": "text", "text": "We will first establish the convergence of $\\Lambda(\\varphi,T)$ . Using Equation (40) we obtain the following estimate for $T{\\mathcal{L}}(\\varphi,T)$ , ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\Lambda(\\varphi,T)=\\sum_{i=0}^{T-1}\\sqrt{\\mathcal{L}(t_{i+1},t_{i})}=\\sum_{i=0}^{T-1}\\sqrt{\\delta(t_{i+1})}\\Delta t_{i}+o(1).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "In the limit as $T\\to\\infty$ , this Riemann sum converges to $\\Lambda$ , ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{T\\rightarrow\\infty}\\Lambda(\\varphi,T)=\\int_{0}^{1}\\sqrt{\\delta(t)}\\mathrm{d}t.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We will now obtain the limit of $T{\\mathcal{L}}(\\varphi,T)$ . First denote $s_{i}\\,=\\,i/T$ and $\\Delta s_{i}\\,=\\,1/T$ . Using the differentiability of $\\varphi$ we have, ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\Delta t_{i}=\\varphi(s_{i+1})-\\varphi(s_{i})=\\frac{\\dot{\\varphi}(s_{i+1})}{T}+o\\left(T^{-1}\\right).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Substituting Equation (46) into Equation (39), we obtain the following estimate for $T{\\mathcal{L}}(\\varphi,T)$ , ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle T{\\mathcal L}(\\varphi,T)=T\\sum_{i=0}^{T-1}{\\mathcal L}(t_{i+1},t_{i})}}\\\\ {{\\displaystyle\\qquad\\qquad=T\\sum_{i=0}^{T-1}\\delta(t_{i+1})\\Delta t_{i}^{2}+o(T^{-1})}}\\\\ {{\\displaystyle\\qquad=\\sum_{i=0}^{T-1}\\delta(\\varphi(s_{i+1}))\\dot{\\varphi}(s_{i+1})^{2}\\Delta s_{i}+o(1).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "In the limit as $t\\to\\infty$ , this converges to the integral for $E(\\varphi)$ , ", "page_idx": 13}, {"type": "equation", "text": "$$\nT\\mathcal{L}(\\varphi,T)=\\int_{0}^{1}\\delta(\\varphi(s))\\dot{\\varphi}(s)^{2}\\mathrm{d}s=E(\\varphi).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Combining Jensen\u2019s inequality with the fact that $\\varphi$ is increasing implies, ", "page_idx": 13}, {"type": "equation", "text": "$$\nE(\\varphi)=\\int_{0}^{1}\\delta(\\varphi(s))\\dot{\\varphi}(s)^{2}\\mathrm{d}s\\geq\\left(\\int_{0}^{1}\\sqrt{\\lambda(\\varphi(s))}\\dot{\\varphi}(s)\\mathrm{d}s\\right)^{2}=\\left(\\int_{0}^{1}\\sqrt{\\delta(t)}\\mathrm{d}t\\right)^{2}=\\Lambda^{2}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "The last equality follows by substituting $t=\\varphi(s)$ . Note a schedule generator $\\varphi^{*}$ obtains the Jensen lower bound if only if there is a $C$ such that for all $s\\in[0,1]$ , ", "page_idx": 13}, {"type": "equation", "text": "$$\nC=\\delta(\\varphi^{*}(s))\\dot{\\varphi}^{*}(s)^{2}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "By taking square roots and integrating from 0 to $s$ , ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sqrt{C}s=\\int_{0}^{s}\\sqrt{\\delta(\\varphi^{*}(s^{\\prime}))}\\dot{\\varphi}^{*}(s^{\\prime})\\mathrm{d}s^{\\prime}=\\int_{0}^{\\varphi^{*}(s)}\\sqrt{\\delta(t)}\\mathrm{d}t=\\Lambda(\\varphi^{*}(s)).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "B\u221ay using the substitution in $s=1$ , along with the constraints $\\Lambda(1)=\\Lambda$ and $\\varphi^{*}(1)=1$ we obtain ${\\sqrt{C}}=\\Lambda$ , ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sqrt{C}=\\Lambda(\\varphi^{*}(1))=\\Lambda(1)=\\Lambda.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Finally, by inverting Equation (50), we conclude our proof, ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\varphi^{*}(s)=\\Lambda^{-1}(\\sqrt{C}s)=\\Lambda^{-1}(\\Lambda s).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "A.3 Comparison to Fisher Information ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "When $F_{t,t^{\\prime}}(x)=x$ , the quantity $G_{t,t^{\\prime}}(x)=p_{t^{\\prime}}(x)/p_{t}(x)$ reduces to the Radon\u2013Nykodym derivative between $p_{t^{\\prime}}$ and $p_{t}$ , and $\\dot{G}_{t}(x)$ reduce to the Fisher score function, $\\begin{array}{r}{\\frac{\\partial}{\\partial t}\\log p_{t}(x)}\\end{array}$ . By Theorem 2.1 the corrector optimised cost satisfies, $\\mathcal{L}_{c}(t,t^{\\prime})=\\delta_{c}(t)\\Delta t^{2}+o(\\Delta t)$ , where ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\delta_{c}(t)=v(t)^{2}\\mathbb{E}_{X_{t}\\sim p_{t}}\\left[\\left\\Vert\\nabla\\dot{G}_{t}^{2}\\right\\Vert^{2}\\right]=v(t)^{2}\\mathbb{E}_{X_{t}\\sim p_{t}}\\left[\\left\\Vert\\nabla\\frac{\\partial}{\\partial t}\\log p_{t}\\right\\Vert^{2}\\right].\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Suppose $p_{t}$ is sufficiently regular, and the Poincar\u00e9 inequality (Poincar\u00e9, 1890) holds. Since the expectation of the Fisher score with respect to $p_{t}$ is zero, we have, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\delta_{c}(t)\\geq C(t)v(t)\\mathbb{E}_{X_{t}\\sim p_{t}}\\left[\\left(\\frac{\\partial}{\\partial t}\\log p_{t}\\right)^{2}\\right]=C(t)v(t)\\delta_{F}(t),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "twhhe edrief $C(t)>0$ t ihs o. mSeu pcpoonsstea nwte.  vHieerwe $\\begin{array}{r}{\\delta_{F}(t)=\\operatorname{Var}_{X_{t}\\sim p_{t}}\\left[\\frac{\\partial}{\\partial t}\\log p_{t}\\right]}\\end{array}$ ni st hthe ep rFoisbhaebri liintfyo drimstartiibount ifoonr $p_{t}$   \nspace with metric $\\delta_{c}(t)$ . Equation (54) shows that the topology induced by $\\delta_{c}(t)$ is stronger than the   \nFisher information, and geometry is more regular. ", "page_idx": 14}, {"type": "text", "text": "B Training Algorithms ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.1 Adaptive training ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We may incorporate Algorithm 1 into an online algorithm used during training. For a fixed score function along the diffusion path, there is an optimal schedule. Similarly, for a fixed schedule, there is an optimal score function that can be learnt from the data. To incorporate these two steps, we propose a two-step algorithm for online training. ", "page_idx": 14}, {"type": "text", "text": "First, for a fixed schedule, we optimise the score function. Then, using this estimated score function, we compute the optimal schedule through Algorithm 1. To add regularity throughout training, as our score predictions are over batches rather than the entire dataset, we do not replace the current schedule with our computed optimal one. Instead, we take a weighted combination of the current schedule with the computed optimal one. ", "page_idx": 14}, {"type": "text", "text": "The weighting factor $\\gamma\\in(0,1)$ is akin to a learning rate for the schedule optimisation. If $\\gamma$ is set too high, our schedule learning may be overly influenced by the current batch, which could negatively affect the score training performance. ", "page_idx": 14}, {"type": "text", "text": "Algorithm 2 AdaptiveScheduleTraining ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Require: Initial schedule $\\mathcal{T}=\\{t_{i}\\}_{i=0}^{T}$ , learning rate $\\gamma\\in(0,1)$ , score estimate $s_{\\theta}$   \n1: while not converged do   \n2: for each batch $B$ from data do   \n3: Fix $\\tau$ and assign $\\theta\\gets\\mathrm{argmin}_{\\theta}\\mathcal{L}_{\\mathrm{training}}(\\theta,B,T)$   \n4: Fix $s\\theta^{*}$ and over batch estimate $\\mathcal{L}(t_{i+1},t_{i}),\\quad i=0,\\ldots,T-1$   \n5: Assign $\\tau^{\\ast}\\gets$ UpdateSchedule $:(\\mathcal{T},\\mathcal{L}(t_{i+1},t_{i}))$   \n6: Update time locations $t_{i}\\gets\\gamma t_{i}^{*}+(1-\\gamma)t_{i}$   \n7: end for ", "page_idx": 14}, {"type": "text", "text": "", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "8: end while ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.2 Estimating predictor optimised cost ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Proposition B.1. Let $F_{t,t^{\\prime}}$ be the predictor map given by the forward Euler discretisation (8) of the probability flow ODE. For $N\\in\\mathbb{N}$ and let $\\hat{J}_{t,N}(x)$ to be the Jacobian of the Hutchinson trace estimator (Hutchinson, 1989) for $\\nabla(\\nabla\\log p_{t}(x)))$ at $x\\in\\mathbb{X}$ and $t\\in[0,1]$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\hat{J}_{t,N}(x)=\\frac{1}{N}\\sum_{n=1}^{N}\\nabla(v_{n}^{T}J_{t}(x)v_{n}),\\quad v_{n}\\sim{\\mathcal{N}}(0,I).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "If $\\Delta t$ is small enough such that, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\Delta t\\mathrm{Tr}\\left(f(t)I-\\frac{1}{2}g(t)^{2}\\nabla^{2}\\log p_{t}(x)\\right)<1.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Then, as $N\\rightarrow\\infty$ the following limit exists almost surely, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\nabla\\log\\operatorname*{det}\\nabla F_{t,t^{\\prime}}(x)=-\\frac{\\Delta t}{2}g(t)^{2}\\operatorname*{lim}_{N\\rightarrow\\infty}\\hat{J}_{t,N}+O(\\Delta t^{2}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. The probability flow ODE update is given through ", "page_idx": 15}, {"type": "equation", "text": "$$\nF_{t,t^{\\prime}}(x)=x+\\Delta t\\left(f(x)x-\\frac{1}{2}g(t)^{2}\\nabla\\log p_{t}(x)\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "By taking the gradient, we have, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\nabla F_{t,t^{\\prime}}(x)=I+\\Delta t\\left(f(t)I-{\\frac{1}{2}}g(t)\\nabla^{2}\\log p_{t}(x)\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since $\\log\\mathrm{det}(1+\\Delta t)\\;=\\;\\Delta t\\mathrm{Tr}A\\,+\\,O(\\Delta t^{2})$ that holds when $\\operatorname{Tr}(A)\\;<\\;1$ , our assumption in Equation (56) hold, we can apply a Taylor expansion ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\log\\operatorname*{det}\\nabla F_{t,t^{\\prime}}(x)=\\Delta t\\mathrm{Tr}\\left(f(t)I-\\frac{1}{2}g(t)\\nabla^{2}\\log p_{t}(x)\\right)+O(\\Delta t^{2}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "By taking a gradient, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla\\log\\operatorname*{det}\\nabla F_{t,t^{\\prime}}(x)=-\\frac{\\Delta t}{2}g(t)^{2}\\nabla\\mathrm{Tr}\\left(\\nabla^{2}\\log p_{t}(X)\\right)+O(\\Delta t^{2})}\\\\ &{\\qquad\\qquad\\qquad=-\\mathbb{E}(v v^{T})\\frac{\\Delta t}{2}g(t)^{2}\\nabla\\mathrm{Tr}\\left(\\nabla^{2}\\log p_{t}(X)\\right)+O(\\Delta t^{2})}\\\\ &{\\qquad\\qquad\\qquad=-\\frac{\\Delta t}{2}g(t)^{2}\\mathbb{E}\\,\\nabla\\mathrm{Tr}\\left(v^{T}\\nabla^{2}\\log p_{t}(X)v\\right)+O(\\Delta t^{2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The last line used the fact that the Hessian of $\\log{p_{t}}$ is equivalently the Jacobian $\\nabla(\\nabla\\log{p_{t}})$ , the latter we can approximate unbiasedly using the Hutchinson trace estimator to gain $\\hat{J}_{t,N}(x)$ . ", "page_idx": 15}, {"type": "text", "text": "B.3 Denoising Score Matching Weighting ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The standard denoising score matching weighting used by Song et al. (2021) is $\\lambda(t)\\ \\propto$ $1/\\mathbb{E}[||\\nabla\\log p_{t|0}(X_{t}|X_{0})||^{2}]$ . For $p_{t|0}(x_{t}|\\bar{x}_{0})=\\bar{\\mathcal{N}}(x_{t};s(t)x_{0},\\bar{\\sigma}^{2}(t)I)$ we have, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\log p_{t|0}(x_{t}|x_{0})=-\\frac{1}{2}\\frac{||x_{t}-s(t)x_{0}||^{2}}{\\sigma(t)^{2}}-\\frac{d}{2}\\log\\left(2\\pi\\sigma(t)^{2}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Therefore, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\nabla_{x_{t}}\\log{p_{t|0}(x_{t}|x_{0})}=\\frac{s(t)x_{0}-x_{t}}{\\sigma(t)^{2}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The expectation for $\\mathbb{E}[||\\nabla\\log p_{t|0}(X_{t}|X_{0})||^{2}]$ is taken with respect to $X_{t}\\sim p_{t|0}$ . We therefore have, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\|\\nabla\\log p_{t(\\theta)}(X_{t}|X_{0})\\|^{2}]=\\mathbb{E}_{p_{t(\\theta)}(X_{t}|X_{0})}\\left[\\left\\|\\frac{s(t)X_{0}-X_{t}}{\\sigma(t)^{2}}\\right\\|^{2}\\right]}\\\\ &{=\\mathbb{E}_{X(\\epsilon;0,I)}\\left[\\left\\|\\frac{s(t)X_{0}-s(t)X_{0}-\\sigma(t)\\epsilon}{\\sigma(t)^{2}}\\right\\|^{2}\\right]}\\\\ &{=\\mathbb{E}_{X(\\epsilon;0,I)}\\left[\\left\\|\\frac{-\\epsilon}{\\sigma(t)}\\right\\|^{2}\\right]}\\\\ &{=\\frac{1}{\\sigma(t)^{2}}\\mathbb{E}_{X(\\epsilon;0,I)}\\left[\\|\\epsilon\\|^{2}\\right]}\\\\ &{=\\frac{d}{\\sigma(t)^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where on the second line we have used the reparameterisation trick. Therefore, we have that the standard weighting for denoising score matching is $\\lambda(t)\\propto\\sigma(t)^{2}$ . ", "page_idx": 15}, {"type": "image", "img_path": "0rl5vWOzRU/tmp/70b0dfe0f17d6fcaa9a72d28b14756b85eb9fcd2b10409ce0e13fcd1b2ab2420.jpg", "img_caption": ["Figure 5: Schedules and density estimates for: linear (blue); Stein score optimised (green); and predictor optimised (red) schedules. The predictor optimised schedule identifies a bump along the diffusion path where the reference Gaussian density splits into two modes. In the regions where the score is evaluated (around $\\pm6]$ ), our trained score is accurate compared to the linear schedule score, which fails to match the slope of the true score, resulting in a wider variance density estimate. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "C Experiment Details ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "C.1 1D Density Estimation ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "For all 1D experiments, we train a one spatial dimension model with continuous time encoding via Gaussian Fourier features to embed time values into a higher-dimensional space. The model architecture includes a hidden dimension of 128, five layers, an embedding dimension of 12, and one residual time step. It features a combination of residual blocks, both incorporating linear layers with GELU activation and LayerNorm, tailored to integrate time embeddings. ", "page_idx": 16}, {"type": "text", "text": "C.1.1 Bimodal Example ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We train our model in the form of $f(t)=\\beta_{t}/2$ and $g(t)=\\sqrt{\\beta_{t}}$ using Algorithm 2 with $\\gamma=0.1$ . We use the weight function vt2n $v_{t_{n}}^{2}\\,=\\,(1-\\bar{\\alpha}_{t_{n}})$ , where $\\alpha_{t_{n}}\\,=\\,1\\,-\\,\\beta_{t_{n}}$ and $\\begin{array}{r}{\\bar{\\alpha}_{t_{n}}\\,=\\,\\prod_{i=1}^{n}\\dot{\\alpha}_{t_{i}}}\\end{array}$ . We train our model for 5 thousand iterations using both a fixed linear schedule and o ur optimisation algorithm initialised at the linear schedule. Due to the non-linear dependence during training of the transport-optimised schedule, initialisation in this context plays an important role. We initialise our predictor-optimised schedule with the optimal schedule generated with respect to $\\mathcal{L}_{c}$ without the Jacobian term as a first approximation. We then add the Jacobian term, optimise the schedule, and train for an additional 5 thousand iterations. ", "page_idx": 16}, {"type": "text", "text": "In Figure 5 we see that the linear schedule forms an estimate with greater variance than the true data and the predicted densities of the optimised schedules. ", "page_idx": 16}, {"type": "image", "img_path": "0rl5vWOzRU/tmp/6e5ac9da962355deec89ddeb25ad5d9b0a696789f7a055c6ff4f62f57e8ed784.jpg", "img_caption": ["Figure 6: Comparison of sampling from a mollified Cantor distribution using DDMs with two different schedules: linear (blue) and optimised (green). The optimised schedule enables the DDM to capture eight distinct data modes centered on the mollified Cantor distribution (grey), whereas the linear schedule does not have clear mode separation. The optimised schedule diffusion accurately predicts the score for the mollified Cantor distribution, being near vertical lines interweaving the Cantor set, where the linear schedule fails to adequately approximate the score. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "C.1.2 Mollified Cantor Distribution ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We train our model with $f(t)=\\beta_{t}/2$ and $g(t)=\\sqrt{\\beta_{t}}$ using the online Algorithm 2 with $\\gamma=0.01$ . The weight function is $v_{t_{n}}^{2}=(1-\\bar{\\alpha}_{t_{n}})$ , where $\\alpha_{t_{n}}=1-\\beta_{t_{n}}$ and $\\begin{array}{r}{\\bar{\\alpha}_{t_{n}}=\\prod_{i=1}^{n}\\alpha_{t_{i}}}\\end{array}$ . To capture high-frequency details, we train the one-dimensional model for 150,000 iterat ions using both a fixed linear schedule and our optimisation algorithm initialised at the linear schedule. The difference in sample quality is evident in Figure 1. ", "page_idx": 17}, {"type": "text", "text": "C.2 Pretrained Image Models ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "For sampling pretrained image models, we use the networks and implementation from Karras et al. (2022), https://github.com/NVlabs/edm. We compute the FID using the provided FID script within the codebase with the standard 50, 000 samples using the same fixed seeds $0-49999$ for all schedules. For each image dataset, we use the default sampling strategy included in the codebase by Karras et al. (2022). For unconditional CIFAR10 this is a deterministic 2nd order Heun solver with 18 timesteps, therefore a total of 35 NFE (number of function evaluations) for the underlying denoising network. For both unconditional FFHQ and unconditional AFHQv2 the same deterministic 2nd order Heun solver is used with 40 timesteps $\\left(\\mathrm{NFE}=79\\right)$ ). For class conditional ImageNet, the bespoke stochastic solver from Karras et al. (2022) is used with 256 timesteps $(\\mathrm{NFE}{=}511)$ ). The stochasticity settings are left at their default values for this dataset of $S_{\\mathrm{churn}}\\,=\\,40$ , $S_{\\mathrm{min}}\\,=\\,0.05$ , $S_{\\mathrm{max}}=50$ , $S_{\\mathrm{noise}}=1.003$ . ", "page_idx": 17}, {"type": "text", "text": "To compute the corrector optimised schedule for each dataset, we use Algorithm 1. We use 100 data samples for each dataset when computing $\\mathcal{L}_{c}$ as we find the variation in learned schedule is small between different samples from the dataset. Our initial discretisation schedule used to calculate $\\Lambda(t)$ is LogLinear with 100 steps. We then fit a monotonic spline to the cumulative estimated $\\Lambda(t)$ and invert this function to find $\\varphi^{*}$ function from which we can derive our schedules. This takes on the order of 5 minutes to find the Corrector Optimised Schedule for CIFAR10 on a single RTX 2080Ti GPU. For predictor optimised schedules we repeat the same procedure however also include estimation of the Hessian term. We use 5 samples of $v$ for each image datapoint when using Hutchinson\u2019s trace estimator. It takes 5 GPU hours to compute the Predictor Optimised Schedule for CIFAR10 due to the extra computational cost of computing the second derivatives. ", "page_idx": 17}, {"type": "text", "text": "We compare the corrector optimised and predictor optimised schedules for the 4 image datasets in Figure 8. We find that all of the schedules have the same general shape with increasing step sizes in log space as the generative process approaches clean data. However, the curvature of the schedule varies between datasets which is to be expected as the schedule is determined through the score which will vary depending on the data distribution. We find that, in general, the higher resolution datasets (FFHQ, AFHQv2 and ImageNet) favour shorter steps nearer the start of the generative process at the expense of larger steps at low noise levels near the end of the generative process. ", "page_idx": 17}, {"type": "image", "img_path": "0rl5vWOzRU/tmp/42317d28f2af2a01fea7048874d03b646f48832ae992ce926b9f7e595493ee5a.jpg", "img_caption": ["Figure 7: Evolution of the estimated score for the mollified Cantor distribution Section 4.1 with a Corrector Optimised Schedule. In this case the linear schedule fails to evenly progress the progression of the score, see Figure 6 showing the terminal score estimate in this case. The estimated score exhibits a self-similar nature of interweaving roots around the centers of mass of the mollified Cantor distribution. Identification of these roots amounts to estimated modes in our density estimate, see Figure 1. "], "img_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "0rl5vWOzRU/tmp/2c19d05696ad3fd3347def792e9393633faa35e3595f309547be7f2025f843b8.jpg", "img_caption": ["Figure 8: Corrector optimised and predictor optimised schedules for the 4 image datasets, CIFAR10, FFHQ, AFHQv2 and ImageNet. "], "img_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "0rl5vWOzRU/tmp/0ceeb97f31e893838df3cfbf5f0ebe6ab7ccdf34ca12d619a4effe7516fb458e.jpg", "img_caption": ["Figure 9: Local cost $\\sqrt{\\delta(\\sigma)}$ versus $\\sigma$ for 4 image datasets and using the corrector optimised versus predictor optimised costs. "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "We analyse the local cost as a function of noise level $\\sqrt{\\delta(\\sigma)}$ for the 4 images datasets within Figure 9. This local cost is used as the metric when determining velocities in the space of schedules from $p_{1}$ to $p_{0}$ . ", "page_idx": 19}, {"type": "table", "img_path": "0rl5vWOzRU/tmp/af11298d84c9f4bc9b25a68e066feb531625611289d92f47240d4913f9757fbd.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "Table 3: Comparison of sFID across different amounts of discretisation points for different schedules on CIFAR10. CO stands for our corrector optimised schedule. ", "page_idx": 19}, {"type": "text", "text": "C.3 Online Schedule Optimisation of Images ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "MNIST: For the MNIST experiments, we trained a model with an image size of 32, 32 channels, with a U-Net architecture, with 1 residual block per U-Net resolution, without learning sigma, and ", "page_idx": 19}, {"type": "image", "img_path": "0rl5vWOzRU/tmp/0de3fb404fe4fa2d048cdec2e25d52af0bd954d6bc6d16df214a3b98e3a95fe4.jpg", "img_caption": [], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure 10: Progression of the length and energy Equation (18) over training of MNIST. Both models are trained from initialisation, one with adaptive schedule learning (red) and one without (blue). We can see that the energy and length quantities increase during training. Recall that for a fixed path of scores $t\\mapsto\\nabla\\log p_{t}$ that the length $\\Lambda$ is constant. As we are learning the score, this value is not constant during training. Interestingly, by optimising the schedule during training we observe a larger length value, possibly indicating that the diffusion path learned with the optimised schedule differs greatly from the path learned without. ", "page_idx": 20}, {"type": "image", "img_path": "0rl5vWOzRU/tmp/64559dcdc321ee4c7352b8e151d88397c6cbde831e8c5644e8291147517d3939.jpg", "img_caption": ["Figure 11: Sample progression of MNIST digits for the standard cosine schedule with $\\epsilon=0.008$ (top) against our optimised schedule (bottom). As we can see, the cosine schedule spends more time near the Gaussian reference distribution whereas the optimised schedule quickly determines large scale features and spends more time toward the data distribution. "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "0rl5vWOzRU/tmp/b1d11dcc86430ca4ffdd1a44cf2a5acd9353d78e363d4e1ddc34123a888b2caa.jpg", "img_caption": ["Figure 12: Progression of the length $\\Lambda$ and cost through online training for CIFAR-10. For the larger learning rate, Algorithm 2 seems to garner a larger $\\bar{\\Lambda}$ value at a faster rate that the lower schedule learning rate. For the fixed cosine schedule run, $\\Lambda$ is stable, perhaps because the score estimate has stabilised for the fixed cosine schedule already during the model training burn-in phase. "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "with a dropout rate of 0.3. The diffusion process was configured with 500 diffusion steps. Training was conducted with a learning rate of 1e-4. ", "page_idx": 21}, {"type": "text", "text": "The schedule was also initialised with the Cosine schedule and trained for 60,000 iterations on an NVIDIA 1080 Ti GPU with 12 GB RAM. The batch size for MNIST was set to 128. We trained two models: one with the schedule optimisation and one without. The schedule training rate was set to $\\gamma=0.05$ , as stated in Algorithm 2. Training took approximately 12 hours for either model. ", "page_idx": 21}, {"type": "text", "text": "CIFAR-10: For the CIFAR-10 experiments, we trained a model with an image size of 32, 128 channels, and a U-Net architecture with 3 residual blocks per multiplier resolution (described in codebase Nichol and Dhariwal (2021)), without learning sigma, and with a dropout rate of 0.3. The diffusion process was configured with 1000 diffusion steps and a cosine noise schedule. ", "page_idx": 21}, {"type": "text", "text": "The schedule was initialised with the Cosine schedule and trained for 160,000 iterations on 4 NVIDIA A40 GPUs, each with 48 GB RAM. The batch size was set to 1,536. After training for 160,000 iterations, we trained two models online: one with the corrector schedule optimisation and one without, for an additional 50,000 iterations on a single GPU with a batch size of 384. The burn in phase for training took approximately 50 hours, with the individual schedule optimisations after this taking approximately 24 hours. ", "page_idx": 21}, {"type": "text", "text": "C.4 Licenses ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Codebases: ", "page_idx": 21}, {"type": "text", "text": "\u2022 Improved Denoising Diffusion Probabilistic Models Nichol and Dhariwal (2021): MIT License   \n\u2022 Elucidating the Design Space of Diffusion-Based Generative Models Karras et al. (2022): Attribution-NonCommercial-ShareAlike 4.0 International ", "page_idx": 21}, {"type": "text", "text": "Datasets: ", "page_idx": 21}, {"type": "text", "text": "\u2022 CIFAR-10 Krizhevsky et al. (2009): MIT license \u2022 FFHQ Karras et al. (2018): Creative Commons BY-NC-SA 4.0 license \u2022 AFHQv2 Choi et al. (2020): Creative Commons BY-NC 4.0 license \u2022 ImageNet Deng et al. (2009): Unknown License ", "page_idx": 21}, {"type": "text", "text": "D Acknowledgements of Funding ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "CW acknowledges support from DST Australia. AC acknowledges support from the EPSRC CDT in Modern Statistics and Statistical Machine Learning (EP/S023151/1). SS acknowledges support from the NSERC Postdoctoral Fellow Program. ", "page_idx": 21}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 22}, {"type": "text", "text": "Justification: Our main theoretical and experimental contributions are clearly stated in the abstract and demonstrated in the paper. They reflect the paper\u2019s contributions and scope. ", "page_idx": 22}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We discuss the limitations of our work in Section 5. ", "page_idx": 22}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 22}, {"type": "text", "text": "Justification: All the proofs are proven in the supplementary material. They are duly cross-referenced. ", "page_idx": 22}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We provide detailed descriptions of our experimental procedures in Appendix C and provide the code to run our experiments. ", "page_idx": 22}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We provide the code necessary to run our experiments. ", "page_idx": 22}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We provide all our experiment details in Appendix C. ", "page_idx": 22}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 22}, {"type": "text", "text": "Answer: [No] ", "page_idx": 22}, {"type": "text", "text": "Justification: Our main metric is FID score for which it is standard practice to report it calculated on the first 50,000 images generated from the model. Standard deviations could be bootstrapped from this set but this is not standard practice. Furthermore, the computational cost to sample large image models 50,000 times multiple times is prohibitive for our academic compute cluster. ", "page_idx": 22}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] Justification: We provide details of the compute resources used in Appendix C. ", "page_idx": 23}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 23}, {"type": "text", "text": "Justification: After careful review of the NeurIPS Code of Ethics, it is clear that the research presented in this paper conforms with the Code of Ethics in every respect. ", "page_idx": 23}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: This paper is mostly theoretical and methodological. We do not see immediate societal impact of this work. However, we acknowledge that large scale implementation of our algorithm might suffer from the same societal biases as any other generative models. Indeed it could improve the quality of generative models and hence been used to generate deepfakes for disinformation. ", "page_idx": 23}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] .   \nJustification: The paper poses no such risks. ", "page_idx": 23}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We provide the references and licenses for the codebases and datasets used in our work in Appendix C.4. ", "page_idx": 23}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: This paper does not introduce any new assets. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 23}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] .   \nJustification: The paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 23}]