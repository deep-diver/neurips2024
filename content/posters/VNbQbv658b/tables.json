[{"figure_path": "VNbQbv658b/tables/tables_6_1.jpg", "caption": "Table 1: Objective and subjective evaluation results for monologue and dialogue generation across various systems.", "description": "This table presents a comparison of objective and subjective evaluation metrics for different speech generation systems on both monologue and dialogue datasets.  The objective metrics include Speaker Similarity (SIM), Word Error Rate (WER), Mel Cepstral Distortion (MCD), and Naturalness and Speech Quality Assessment (NISQA). Subjective metrics consist of Comparative Mean Opinion Score (CMOS) for naturalness and overall flow of conversation, and Speaker Mean Opinion Score (SMOS) to evaluate the consistency of the speaker's voice. The systems compared are a phoneme-based baseline, CoVoSingle (a system trained on monologue data), and CoVoMix (a system trained on both monologue and dialogue data). The results demonstrate CoVoMix's superior performance in terms of naturalness, speaker consistency, and overall dialogue flow compared to other methods.", "section": "5.1 Objective and Subjective Metrics"}, {"figure_path": "VNbQbv658b/tables/tables_15_1.jpg", "caption": "Table 1: Objective and subjective evaluation results for monologue and dialogue generation across various systems. The symbol \"\u2020\" is used to indicate that the system performance is significantly different (p<0.01) from CoVoSingle system in terms of CMOS and SMOS scores.", "description": "This table presents a comparison of objective and subjective evaluation metrics for different speech generation systems on both monologue and dialogue tasks.  Objective metrics include speaker similarity (SIM), word error rate (WER), mel cepstral distortion (MCD), and naturalness (NISQA). Subjective metrics include naturalness (CMOS) and speaker similarity (SMOS).  The table compares the performance of CoVoSingle, CoVoMix, and a baseline system, showing the improvements achieved by the proposed CoVoMix model. The statistical significance of the differences in CMOS and SMOS is also indicated.", "section": "5.1 Objective and Subjective Metrics"}, {"figure_path": "VNbQbv658b/tables/tables_16_1.jpg", "caption": "Table 2: Objective evaluation on monologue and dialogue for mono and stereo acoustic model", "description": "This table presents the objective evaluation results for both monologue and dialogue generation tasks using different combinations of text-to-semantic and acoustic models.  It compares the performance of models with single-channel (mono) and dual-channel (stereo) acoustic models. The metrics used include Speaker Similarity (SIM), Word Error Rate (WER), Mel Cepstral Distortion (MCD), and the Naturalness, Intelligibility, and Quality Assessment (NISQA) score. The results show how different model combinations and channel configurations affect the performance on different evaluation metrics.", "section": "4 Experimental Setup"}, {"figure_path": "VNbQbv658b/tables/tables_17_1.jpg", "caption": "Table 4: Objective evaluation on voice conversion for monologue and dialogue generation. The symbol \"+\\\" is used to indicate that the system performance is significantly different (p<0.01) from VoSingle system", "description": "This table presents the objective evaluation results for voice conversion using two different systems: VoSingle and VoMix. The evaluation is performed on both monologue and dialogue datasets. The metrics used for evaluation are SIM (speaker similarity) and MCD (mel cepstral distortion). The results show that VoMix outperforms VoSingle significantly in terms of both MCD and SIM. The table also uses the symbol '+' to indicate that a statistically significant difference (p<0.01) is observed between the performance of VoMix and VoSingle.", "section": "C Extension to Voice Conversion"}, {"figure_path": "VNbQbv658b/tables/tables_17_2.jpg", "caption": "Table 1: Objective and subjective evaluation results for monologue and dialogue generation across various systems.The symbol \"\u2020\" is used to indicate that the system performance is significantly different (p<0.01) from CoVoSingle system in terms of CMOS and SMOS scores.", "description": "This table presents a comparison of objective and subjective evaluation metrics for different speech generation systems on both monologue and dialogue tasks.  Objective metrics include Speaker Similarity (SIM), Word Error Rate (WER), Mel Cepstral Distortion (MCD), and Naturalness, Intelligibility, and Speech Quality (NISQA).  Subjective metrics include Comparative Mean Opinion Score (CMOS) for naturalness and seamlessness, and Similarity Mean Opinion Score (SMOS) for speaker similarity. The table shows that CoVoMix generally outperforms CoVoSingle and a phoneme-based baseline, particularly in terms of naturalness and speaker similarity, highlighting the effectiveness of the proposed approach.", "section": "5 Result and Analysis"}, {"figure_path": "VNbQbv658b/tables/tables_18_1.jpg", "caption": "Table 6: Objective evaluation results for monologue and dialogue generation across various systems with different random seeds", "description": "This table presents the results of objective evaluations for both monologue and dialogue generation across different systems, using three different random seeds for each system to assess the stability and consistency of the results.  The metrics used include Speaker Similarity (SIM), Word Error Rate (WER), Mel Cepstral Distortion (MCD), and Naturalness and Speech Quality (NISQA).  Higher SIM and NISQA values indicate better performance, while lower WER and MCD values indicate better performance.", "section": "5 Result and Analysis"}, {"figure_path": "VNbQbv658b/tables/tables_19_1.jpg", "caption": "Table 1: Objective and subjective evaluation results for monologue and dialogue generation across various systems.", "description": "This table presents a comparison of objective and subjective evaluation metrics for different speech generation systems (CoVoSingle, CoVoMix, and a baseline) across both monologue and dialogue datasets.  Objective metrics include speaker similarity (SIM), word error rate (WER), mel cepstral distortion (MCD), and naturalness score (NISQA). Subjective metrics encompass naturalness (CMOS) and speaker similarity (SMOS), assessed through human evaluations. The table allows for a comprehensive comparison of the performance of the proposed CoVoMix system against a traditional approach and ground truth data, highlighting its strengths and weaknesses across various aspects of speech generation.", "section": "5 Result and Analysis"}, {"figure_path": "VNbQbv658b/tables/tables_19_2.jpg", "caption": "Table 1: Objective and subjective evaluation results for monologue and dialogue generation across various systems.", "description": "This table presents a comparison of objective and subjective evaluation metrics for different speech generation systems.  The systems are evaluated on both monologue and dialogue generation tasks, and the metrics include speaker similarity (SIM), word error rate (WER), mel cepstral distortion (MCD), naturalness score (NISQA), and subjective scores for naturalness (CMOS) and speaker similarity (SMOS). The results provide quantitative and qualitative comparisons across multiple systems, including a baseline model and the proposed CoVoSingle and CoVoMix models.", "section": "5 Result and Analysis"}]