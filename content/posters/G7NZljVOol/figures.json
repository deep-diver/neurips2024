[{"figure_path": "G7NZljVOol/figures/figures_1_1.jpg", "caption": "Figure 1: Diagram comparing the forward/backward flow and update process with TENT [59] and EcoTTA [55], illustrated as representative algorithms for entropy minimization and memory-efficient methods, respectively. The red lock icon indicates the absence of TTA execution.", "description": "This figure compares the computational flow of three different test-time adaptation (TTA) methods: TENT, EcoTTA, and the proposed method.  TENT and EcoTTA, representing entropy minimization and memory-efficient approaches, respectively, show full forward and backward passes through the network for parameter updates. The proposed method, in contrast, only updates parameters in a reconstructed stem layer, significantly reducing computational overhead.  The locked icons highlight the parts of the network not involved in TTA execution in each method.", "section": "1 Introduction"}, {"figure_path": "G7NZljVOol/figures/figures_4_1.jpg", "caption": "Figure 2: Overview of our method including the reconstructed stem layer.  * and  \u2297 denote element-wise multiplication and CONV operation, respectively, while \u03c8l and \u03c8h respectively denote the low and high filters for DWT, described in Appendix B.", "description": "This figure illustrates the architecture of the proposed method's reconstructed stem layer.  The input image undergoes a Discrete Wavelet Transform (DWT) using DEL (Domain Embedding Layer) which decomposes it into multiple frequency domains. These are then processed by a convolutional layer and fed into GCAL (Gaussian Channel Attention Layer).  GCAL calculates channel-wise attention and uncertainty, which is then minimized during training to improve adaptation. Finally, an Inverse Discrete Wavelet Transform (IDWT) reconstructs the output to match the original input shape. The figure details the operations performed within the stem layer, highlighting the DWT, convolution, GCAL, and IDWT operations, as well as element-wise multiplication.", "section": "3 Proposed Method"}, {"figure_path": "G7NZljVOol/figures/figures_6_1.jpg", "caption": "Figure 3: (a) visualizes the proposed ODD process in detail on a given input. (b) shows the variance of uncertainty according to the domain shift of LFC (=LFCLL) and HFC (=HFCLH).", "description": "This figure shows the proposed Omnidirectional Decomposition (ODD) process and the variance of uncertainty of Low Frequency Component (LFC) and High Frequency Component (HFC) according to domain shift.  The left panel (a) illustrates how ODD decomposes the input image into multiple frequency components (LFC_LL, HFC_LH, HFC_HL, HFC_HH) using a two-level Discrete Wavelet Transform (DWT), aiming to extract more diverse features for enhanced domain adaptation. The right panel (b) displays the uncertainty changes in LFC and HFC during Test-Time Adaptation (TTA). The variance of uncertainty (\u0394\u03b3\u03a3) is visualized, showing how sensitive ODD is to changes in the input domain, and demonstrating its ability to maximize data utilization for better adaptation.", "section": "3.3 DEL: Domain Embedding Layer"}, {"figure_path": "G7NZljVOol/figures/figures_7_1.jpg", "caption": "Figure 4: Comparison of memory usage in a single iteration on CIFAR-100-C and ImageNet-C datasets.", "description": "This figure compares the memory usage of various test-time adaptation (TTA) methods on two datasets: CIFAR-100-C and ImageNet-C.  The bar chart shows that the proposed method ('Ours') uses significantly less memory than other state-of-the-art (SOTA) methods, especially those based on entropy minimization or batch normalization statistics adaptation.  The percentage reductions in memory usage compared to the SOTA methods are clearly indicated on the chart.", "section": "4 Experimental Results"}, {"figure_path": "G7NZljVOol/figures/figures_9_1.jpg", "caption": "Figure 6: Comparison of prediction error (%) across increasing TTA iterations on CIFAR-10-C with ResNet-26.", "description": "This figure shows the comparison of prediction error rates (%) across different numbers of TTA iterations on CIFAR-10-C dataset using ResNet-26 as the backbone network.  Two variations of the proposed method are compared: one using both DEL and GCAL (DEL+GCAL), and the other using only GCAL.  A horizontal dashed line indicates the average error rate achieved by the REALM method. The figure demonstrates that the proposed method (DEL+GCAL) consistently achieves lower error rates compared to using GCAL only, and surpasses the performance of REALM after 10 iterations, reaching a 5.7% performance improvement after a full epoch of training.", "section": "4.3 Ablation Studies"}, {"figure_path": "G7NZljVOol/figures/figures_9_2.jpg", "caption": "Figure 7: Assessment of TTA effectiveness for small batch sizes in comparison with entropy minimization baselines on ImageNet-C.", "description": "This figure compares the performance of the proposed TTA method with several other entropy minimization-based methods (TENT, EATA, and SAR) across various batch sizes (1, 2, 4, and 8) on the ImageNet-C dataset.  The y-axis represents the average error rate, and the x-axis represents the batch size.  The results show that the proposed method maintains relatively stable performance even with very small batch sizes (1 and 2), while the other methods show a significant increase in error rate as the batch size decreases. This demonstrates that the proposed method is more robust and efficient in handling small batch sizes, which is important for real-world applications where data may be limited.", "section": "4 Experimental Results"}, {"figure_path": "G7NZljVOol/figures/figures_17_1.jpg", "caption": "Figure 8: Mean error rates (%) by corruption type on ImageNet-C and CIFAR-100-C with increasing TTA iterations in ResNet-50.", "description": "This figure shows the mean error rates for different corruption types (Noise, Blur, Weather, Digital) on ImageNet-C and CIFAR-100-C datasets as the number of TTA iterations increases.  It illustrates the performance of the proposed method over time in handling various types of image corruptions in the two datasets. The x-axis represents the number of iterations and the y-axis represents the mean error rate.  The graphs help visualize the model's adaptation capability during the TTA process and how the performance stabilizes or converges after a certain number of iterations.", "section": "F Appendix: Limitations and Discussions"}]