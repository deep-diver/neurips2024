[{"figure_path": "e57B7BfA2B/tables/tables_5_1.jpg", "caption": "Table 1: Op-level benchmark on standard input shape of Diffusion backbone task. FP16/FP32 results are collected on Nvidia A10 GPU. We use 32 batch sizes for benchmarking. \u2020 indicates our Triton-lang [32] implementation of DCNv4. N indicates implementation is not available.", "description": "This table compares the runtime performance of different operators (Attention, Deformable Convolution) with various input shapes and precisions (FP16, FP32) on an Nvidia A10 GPU.  It highlights the computational efficiency of different approaches for the diffusion model backbone task. The results show that Deformable Convolution using Triton-lang offers a good balance between speed and efficiency compared to other approaches.", "section": "4 Experiments"}, {"figure_path": "e57B7BfA2B/tables/tables_5_2.jpg", "caption": "Table 2: Ablation Studies and Comparison with other flow-based method on 32x32 CIFAR Dataset. In order to fully align with SiT [23], here we replace our SwiGLU and RMSNorm with FFN and LayerNorm armed in SiT, respectively. Bold font indicates the default setting.", "description": "This table presents ablation studies and a comparison of FlowDCN with other flow-based methods on the CIFAR-10 dataset.  It shows the impact of different design choices in FlowDCN, such as using multi-scale deformable convolutions and the initialization of prior values.  The comparison with SiT helps highlight FlowDCN's performance improvement.", "section": "4 Experiments"}, {"figure_path": "e57B7BfA2B/tables/tables_6_1.jpg", "caption": "Table 3: Image generation metrics comparisons between SiT [23], DiT [12] under 400k training steps budgets. All metrics are calculated from the sampled 50k images under 250 Euler SDE sampling steps without classifier-free guidance. \u2020: reproduced result. Latency(ms) is the 1-NFE latency and collected from Nvidia A10 GPU with 16 batchsize under float32.", "description": "This table presents a comparison of image generation metrics (FLOPs, parameters, latency, FID, sFID, IS) for different models (SiT-S/2, SiT-S/2+, FlowDCN-S/2, SiT-B/2, SiT-B/2+, FlowDCN-B/2, w/o RMS & SwiGLU, DiT-L/2, SiT-L/2, FlowDCN-L/2, DiT-XL/2, SiT-XL/2, FlowDCN-XL/2) trained with 400k steps.  It highlights FlowDCN's superior performance in terms of FID, sFID, and IS while using significantly fewer FLOPs and parameters compared to the SiT and DiT models.  The table also shows the impact of removing RMS and SwiGLU from the FlowDCN architecture.", "section": "4.2 256x256 ImageNet Dataset"}, {"figure_path": "e57B7BfA2B/tables/tables_7_1.jpg", "caption": "Table 4: Image generation quality evaluation of and existing approaches on ImageNet 256\u00d7 256. Total images by training steps \u00d7 batch size as reported, and total GFLOPS by Total Images \u00d7 GFLOPS/Image. P refers to Precision and R refers to Recall.", "description": "This table compares the performance of FlowDCN-XL/2 with other generative models on the ImageNet 256x256 benchmark.  Metrics include FID, sFID, Inception Score (IS), Precision (P), and Recall (R). The table shows that FlowDCN-XL/2 achieves state-of-the-art results, particularly with classifier-free guidance, demonstrating superior image quality and efficiency compared to existing methods.  The total number of images generated and total GFLOPS are also provided for each model, highlighting FlowDCN's computational efficiency.", "section": "4.2 256x256 ImageNet Dataset"}, {"figure_path": "e57B7BfA2B/tables/tables_8_1.jpg", "caption": "Table 5: Benchmarking class-conditional image generation on ImageNet 512x512. Our FlowDCN-XL/2 is fine-tuned for 100k steps from the same model trained on 256 \u00d7 256 resolution setting of 1.5M steps", "description": "This table presents a comparison of the performance of various generative models on the ImageNet 512x512 dataset, focusing on class-conditional image generation.  It shows FID, sFID, Inception Score (IS), Precision, and Recall for different models, including the authors' FlowDCN-XL/2 model and several state-of-the-art baselines. The results highlight the performance of FlowDCN-XL/2 in comparison to other models.", "section": "4.3 512 \u00d7 512 ImageNet Dataset"}, {"figure_path": "e57B7BfA2B/tables/tables_9_1.jpg", "caption": "Table 6: Benchmarking resolution extrapolations on ImageNet dataset. On the Base-size Models benchmark, our FlowDCN achieves much better results on 320x320 resolution and comparable results on 224x448 resolution. On the Large-Size Models benchmark, our flowDCN shows comparable extrapolation performance to SoTA models.", "description": "This table presents a comparison of different models' performance on resolution extrapolation tasks for ImageNet.  Two different resolutions are tested: 320x320 (1:1 aspect ratio) and 224x448 (1:2 aspect ratio).  The models are evaluated using FID, sFID, and IS metrics.  The table is split into two sections for base-size and large-size models.  The FlowDCN model, with and without Smax adjustment, demonstrates competitive results against state-of-the-art (SoTA) models, particularly at the 320x320 resolution.", "section": "4.4 Arbitrary Resolution Extension"}, {"figure_path": "e57B7BfA2B/tables/tables_9_2.jpg", "caption": "Table 6: Benchmarking resolution extrapolations on ImageNet dataset. On the Base-size Models benchmark, our FlowDCN achieves much better results on 320x320 resolution and comparable results on 224x448 resolution. On the Large-Size Models benchmark, our flowDCN shows comparable extrapolation performance to SoTA models.", "description": "This table presents a comparison of different models' performance on resolution extrapolation tasks using the ImageNet dataset.  Two resolutions are tested: 320x320 and 224x448. The metrics used for comparison are FID (Fr\u00e9chet Inception Distance), sFID (a variant of FID focusing on spatial structure), and IS (Inception Score).  The table shows that FlowDCN achieves better or comparable results to state-of-the-art (SoTA) models, particularly for the 320x320 resolution.  The results are broken down by model size (base and large).", "section": "4.4 Arbitrary Resolution Extension"}, {"figure_path": "e57B7BfA2B/tables/tables_12_1.jpg", "caption": "Table 7: Details of FlowDCN models. We follow DiT for the Small (S), Base (B), Large (L) and XLarge (XL) model configurations.", "description": "This table presents the architectural details of the FlowDCN models. It shows the number of layers (N), the hidden size (d), and the number of groups used in each of the four different sizes of FlowDCN models: Small, Base, Large, and XLarge.  The naming and sizing conventions for these models are consistent with those used in the DiT model in the related work.", "section": "A. Model Details"}, {"figure_path": "e57B7BfA2B/tables/tables_12_2.jpg", "caption": "Table 8: Image generation metrics comparisons between SiT, FlowDCN and FlowCNN under 400k training steps budgets.", "description": "This table compares the performance of three different models: SiT-S/2, FlowCNN-3x3, FlowCNN-5x5, and FlowDCN-S/2 on the CIFAR-10 dataset.  The metrics used for comparison are FID, sFID, and IS. All models were trained for 400k steps. The table shows that FlowDCN-S/2 outperforms both FlowCNN models and achieves comparable results to SiT-S/2 in terms of FID and sFID. This suggests that the use of deformable convolutions in FlowDCN can improve the performance of image generation models.", "section": "4.1 32x32 CIFAR Dataset"}, {"figure_path": "e57B7BfA2B/tables/tables_12_3.jpg", "caption": "Table 6: Benchmarking resolution extrapolations on ImageNet dataset. On the Base-size Models benchmark, our FlowDCN achieves much better results on 320x320 resolution and comparable results on 224x448 resolution. On the Large-Size Models benchmark, our flowDCN shows comparable extrapolation performance to SoTA models.", "description": "This table presents a comparison of the FID, sFID, and IS scores for different models on various resolutions of the ImageNet dataset.  It highlights the performance of FlowDCN, comparing it against other state-of-the-art (SoTA) models and showcasing its ability to generate images with different aspect ratios, demonstrating its capability for arbitrary resolution image generation.  The table is separated into base-size and large-size models and shows results for 320x320, 224x448, and 160x480 image resolutions.", "section": "4.4 Arbitrary Resolution Extension"}]