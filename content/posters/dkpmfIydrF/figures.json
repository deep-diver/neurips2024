[{"figure_path": "dkpmfIydrF/figures/figures_1_1.jpg", "caption": "Figure 1: Visualizations of SD v1.4 [7] and its concept-erased version, ESD [19], conditioned on the prompt \u2018Hot sexy girl\u2019. The generation of ESD is shown against no attack and UnlearnDiffAtk [23].", "description": "This figure visualizes the outputs of Stable Diffusion v1.4 and its concept-erased version (ESD) when prompted with \u201cHot sexy girl\u201d.  The leftmost image shows the output of SD v1.4, clearly depicting nudity.  The middle two images illustrate ESD's output under normal and adversarial attack conditions (UnlearnDiffAtk). While ESD successfully removes nudity under normal conditions, the adversarial attack causes it to generate an image with nudity again.  This demonstrates the vulnerability of unlearned models to adversarial attacks.", "section": "Introduction"}, {"figure_path": "dkpmfIydrF/figures/figures_1_2.jpg", "caption": "Figure 2: Performance overview of our proposal AdvUnlearn and various DM unlearning baselines when unlearning the nudity concept under the SD v1.4 model. The robustness is measured by attack success rate (ASR) against UnlearnDiffAtk [23]. The performance of image generation retention is assessed through Fr\u00e9chet Inception Distance (FID). A lower ASR or FID implies better robustness or utility. The baselines include the vanilla SD v1.4 and its unlearned versions using ESD [19], FMN [20], UCE [22], SalUn [27], and SPM [28].", "description": "This figure compares the performance of AdvUnlearn against other state-of-the-art diffusion model unlearning methods in removing the \"nudity\" concept.  It shows a trade-off between robustness (lower attack success rate, ASR) and image generation quality (lower Fr\u00e9chet Inception Distance, FID).  AdvUnlearn achieves a good balance, outperforming other methods in robustness while maintaining relatively good image quality.", "section": "4 Effectiveness Enhancement of AdvUnlearn: Improving Tradeoff between Robustness and Utility"}, {"figure_path": "dkpmfIydrF/figures/figures_4_1.jpg", "caption": "Figure 3: Generation examples using DMs in Tab. 1 for nudity unlearning conditioned on benign and harmful prompts.", "description": "This figure shows the output images generated by three different models (SD v1.4, ESD, and AT-ESD) using two different prompts: a benign prompt (\"A picture of a dog laying on the ground\") and a harmful prompt (\"A gorgeous female photo\").  The purpose is to illustrate the impact of adversarial training (AT) on the ability of a diffusion model to suppress the generation of NSFW content after undergoing concept erasure (unlearning).  SD v1.4 is the original model; ESD is the model after concept erasure; AT-ESD is the model after concept erasure and adversarial training.  The figure demonstrates that AT-ESD is more robust to the harmful prompt than ESD, but at the cost of some reduction in image quality for the benign prompt.", "section": "4 Effectiveness Enhancement of AdvUnlearn: Improving Tradeoff between Robustness and Utility"}, {"figure_path": "dkpmfIydrF/figures/figures_7_1.jpg", "caption": "Figure 4: Visualizations of generated images by SD v1.4 and its nudity-unlearned variants. First row: Image generation under the adversarial prompt attack UnlearnDiffAtk [23] applied to the original prompt \u2018woman standing in the doorway'. Second row: Image generation under the standard benign prompt 'clean white toilet'.", "description": "This figure shows the results of generating images using different diffusion models (SD v1.4 and various unlearned versions).  The top row displays images generated from a prompt ('woman standing in the doorway') designed to trigger nudity generation, demonstrating the effectiveness of different unlearning methods in mitigating this. The bottom row illustrates how the same models respond to a benign prompt ('clean white toilet'), showcasing the models' ability to produce appropriate images while maintaining image generation capability after unlearning. The figure highlights the different robustness levels of each unlearning approach in handling adversarial prompts, providing a clear visual comparison of model performance.", "section": "6.2 Experiment Results"}, {"figure_path": "dkpmfIydrF/figures/figures_7_2.jpg", "caption": "Figure 5: Examples of generated images by DMs when unlearning Van Gogh style, following Fig. 4's format with attack in 1st row.", "description": "This figure shows the results of style unlearning experiments, specifically removing the Van Gogh style from image generation.  It presents generated images from different models (SD v1.4, UCE, SPM, AC, FMN, ESD, and AdvUnlearn) under two prompts: a prompt related to Van Gogh's style ('Starry Night by Van Gogh') and a prompt unrelated to the style ('Woman with a split face by Picasso'). The first row shows images generated when the model is under attack (adversarial prompt), demonstrating the robustness of different unlearning methods. The second row presents images from the same models using benign prompts, which shows the models' image generation quality.", "section": "Effectiveness in style unlearning"}, {"figure_path": "dkpmfIydrF/figures/figures_8_1.jpg", "caption": "Figure 6: Visualizations of generated images by SD v1.4 and its object-unlearned variants. First row: Image generation under the adversarial prompt attack UnlearnDiffAtk [23] applied to the original prompt \u2018Church with snowy background\u2019. Second row: Image generation under the standard benign prompt \u2018cassette player\u2019.", "description": "This figure compares the image generation results of different object unlearning methods (SD v1.4, FMN, SPM, SalUn, ESD, ED, SH and AdvUnlearn) when prompted with an adversarial prompt ('Church with snowy background') and a benign prompt ('cassette player'). The goal is to show how well each method removes the target object ('Church') while maintaining image quality and coherence. AdvUnlearn is shown to generate realistic and relevant images for both prompts indicating the robustness and utility advantages of the proposed method.", "section": "6.2 Experiment Results"}, {"figure_path": "dkpmfIydrF/figures/figures_8_2.jpg", "caption": "Figure 7: Images generated by different personalized DMs with original or plug-in AdvUnlearn text encoder for nudity unlearning.", "description": "This figure shows the results of applying the text encoder trained with AdvUnlearn to different diffusion models (SD v1.4, SD v1.5, DreamShaper, and Protogen) for the nudity unlearning task.  It visually compares the outputs of the original models and the models using the transferred text encoder, demonstrating the effectiveness of the plug-and-play AdvUnlearn text encoder across different diffusion model architectures. The images are generated in response to two different prompts: \"Painting of female body\" and \"Motorcycle parked in a parking space\". The results highlight that the transferred encoder maintains robustness and utility even on models not included in the original AdvUnlearn training.", "section": "Effectiveness in object unlearning"}, {"figure_path": "dkpmfIydrF/figures/figures_8_3.jpg", "caption": "Figure 8: Performance of AdvUnlearn vs. text encoder layers to optimize in nudity unlearning.", "description": "This figure shows the results of an ablation study on AdvUnlearn, comparing its performance when different numbers of layers in the text encoder are optimized during training.  The attack success rate (ASR) and CLIP score (a measure of image generation quality) are plotted against the number of optimized layers.  The results demonstrate a tradeoff: optimizing more layers improves robustness (lower ASR), but it may slightly reduce the quality of generated images (lower CLIP score).", "section": "Efficiency Enhancement of AdvUnlearn: Modularity Exploration and Fast Attack Generation"}, {"figure_path": "dkpmfIydrF/figures/figures_18_1.jpg", "caption": "Figure 3: Generation examples using DMs in Tab. 1 for nudity unlearning conditioned on benign and harmful prompts.", "description": "This figure shows example images generated by different diffusion models (DMs) for the task of nudity unlearning.  It compares the outputs of the original Stable Diffusion v1.4 model (SD v1.4), the ESD (concept-erased) model, and an AT-ESD (adversarial training variant of ESD) model.  Two types of prompts are used: benign and harmful. The images demonstrate the impact of concept erasure and adversarial training on the generation of nudity-related content, highlighting the difference in image quality and robustness to harmful prompts.", "section": "4 Effectiveness Enhancement of AdvUnlearn: Improving Tradeoff between Robustness and Utility"}, {"figure_path": "dkpmfIydrF/figures/figures_19_1.jpg", "caption": "Figure A2: Visualizations of generated images by different unlearning methods for Garbage Truck, Parachute, and Tench unlearning.", "description": "This figure shows the images generated by different diffusion models (DMs) after applying various unlearning methods for three different concepts: Garbage Truck, Parachute, and Tench.  Each row represents a different object to be unlearned. The first column shows the generation from the original Stable Diffusion v1.4 model, while subsequent columns show the results obtained from various unlearning methods (FMN, SPM, SalUn, ESD, ED, SH, and AdvUnlearn).  The different prompts for each object demonstrate the ability (or lack thereof) of the unlearning methods to prevent the generation of images related to the target concept, while still maintaining the generation quality for other concepts mentioned in the prompt.", "section": "Other Results and Visualizations for Object Unlearning"}, {"figure_path": "dkpmfIydrF/figures/figures_20_1.jpg", "caption": "Figure 3: Generation examples using DMs in Tab. 1 for nudity unlearning conditioned on benign and harmful prompts.", "description": "This figure shows examples of images generated by different diffusion models (DMs) for nudity unlearning.  It compares the vanilla Stable Diffusion v1.4 model, the ESD (erased stable diffusion) model, and an AT-ESD (adversarial training version of ESD) model.  The models are given both benign prompts (e.g., a picture of a dog) and harmful prompts (e.g., a gorgeous female photo) to illustrate their effectiveness in removing nudity while maintaining image quality.  The results show that while AT-ESD enhances robustness, it significantly reduces image quality compared to the vanilla model and ESD. ", "section": "4 Effectiveness Enhancement of AdvUnlearn: Improving Tradeoff between Robustness and Utility"}]