[{"figure_path": "mYEjc7qGRA/tables/tables_6_1.jpg", "caption": "Table 1: Hyperparameters of LNLN we use on the different datasets", "description": "This table shows the hyperparameters used in the Language-dominated Noise-resistant Learning Network (LNLN) model for three different datasets: MOSI, MOSEI, and SIMS.  The hyperparameters include vector length, vector dimension, batch size, initial learning rate, loss weights (\u03b1, \u03b2, \u03b3, \u03b4), optimizer, number of epochs, usage of warm-up and cosine annealing techniques, early stopping criteria, and the random seed used for reproducibility.  The values for these hyperparameters may be adjusted or optimized for different datasets to achieve best performance.", "section": "4.3 Implementation Details"}, {"figure_path": "mYEjc7qGRA/tables/tables_7_1.jpg", "caption": "Table 2: Robustness comparison of the overall performance on MOSI and MOSEI datasets. Note: The smaller MAE indicates the better performance.", "description": "This table presents a comparison of the performance of several multimodal sentiment analysis (MSA) methods on the MOSI and MOSEI datasets under different levels of data incompleteness (noise).  The comparison includes several metrics: binary classification accuracy (Acc-2), F1 score (F1) for the Acc-2, mean absolute error (MAE), and correlation (Corr).  The table shows both the negative/positive accuracy and negative/non-negative accuracy for the Acc-2 metric. The lower MAE indicates better performance. ", "section": "4 Experiments and Analysis"}, {"figure_path": "mYEjc7qGRA/tables/tables_7_2.jpg", "caption": "Table 3: Robustness comparison of the overall performance on SIMS dataset. Note: The smaller MAE indicates the better performance.", "description": "This table presents a comparison of the performance of several methods on the SIMS dataset under different missing rates.  The metrics used include Acc-3 (three-class accuracy), Acc-2 (two-class accuracy), F1 score, MAE (mean absolute error), and Corr (correlation).  Lower MAE values indicate better performance.", "section": "4.4 Robustness Comparison"}, {"figure_path": "mYEjc7qGRA/tables/tables_8_1.jpg", "caption": "Table 4: Effects of different components. Note: The smaller MAE indicates the better performance.", "description": "This table presents the ablation study results on the MOSI dataset by removing different components of the proposed LNLN model.  It shows the impact on several metrics (Acc-7, Acc-5, Acc-2, F1, MAE, Corr) when removing the Dominant Modality Correction (DMC) module, the Reconstructor, the Dominant Modality based Multimodal Learning (DMML) module, and the noisy data used for training. The results highlight the importance of each component and the use of noisy data in achieving robust performance. ", "section": "4.5 Effects of Different Components"}, {"figure_path": "mYEjc7qGRA/tables/tables_8_2.jpg", "caption": "Table 4: Effects of different components. Note: The smaller MAE indicates the better performance.", "description": "This table presents the ablation study results on the MOSI and SIMS datasets by removing different components of the proposed LNLN model.  The results demonstrate the impact of each component (Dominant Modality Correction (DMC), Reconstructor, and Dominant Modality based Multimodal Learning (DMML) module) on the overall performance, measured by Acc-7, Acc-5, Acc-2, F1 score, MAE, and correlation (Corr). It also shows the effect of removing noisy data from the training set. The table helps to understand the contribution and importance of each component in achieving robustness against incomplete data.", "section": "4.5 Effects of Different Components"}, {"figure_path": "mYEjc7qGRA/tables/tables_9_1.jpg", "caption": "Table 4: Effects of different components. Note: The smaller MAE indicates the better performance.", "description": "This table presents the ablation study results of removing different components from the proposed LNLN model and evaluating its performance on the MOSI and SIMS datasets. The components evaluated include DMC (Dominant Modality Correction) module, Reconstructor, DMML (Dominant Modality based Multimodal Learning) module and the noisy data used for training.  The table shows the effects of removing these individual components on the accuracy (Acc-7, Acc-5, Acc-2), F1 score, MAE (Mean Absolute Error), and correlation (Corr) metrics.  The results illustrate the importance of each component to the overall performance of LNLN, particularly the combined effect of DMC and Reconstructor.", "section": "4.5 Effects of Different Components"}, {"figure_path": "mYEjc7qGRA/tables/tables_12_1.jpg", "caption": "Table 2: Robustness comparison of the overall performance on MOSI and MOSEI datasets. Note: The smaller MAE indicates the better performance.", "description": "This table presents a comparison of the performance of different methods on the MOSI and MOSEI datasets across various noise levels.  The metrics used for comparison include binary classification accuracy (Acc-2), F1-score (F1), mean absolute error (MAE), correlation of predictions with human ratings (Corr), three-class accuracy (Acc-3), and seven-class accuracy (Acc-7).  Lower MAE values indicate better performance. The table highlights the relative improvements of the proposed method (LNLN) compared to other state-of-the-art methods.", "section": "4.4 Robustness Comparison"}, {"figure_path": "mYEjc7qGRA/tables/tables_13_1.jpg", "caption": "Table 2: Robustness comparison of the overall performance on MOSI and MOSEI datasets. Note: The smaller MAE indicates the better performance.", "description": "This table presents a comparison of the performance of various multimodal sentiment analysis (MSA) methods on the MOSI and MOSEI datasets.  The methods are evaluated under different levels of random data missing. The table shows the accuracy (Acc-2, Acc-7), F1 score, mean absolute error (MAE), and correlation (Corr) for each method on both datasets. The \"smaller MAE\" indicates better performance, highlighting the robustness of each approach against noisy data.", "section": "4 Experiments and Analysis"}, {"figure_path": "mYEjc7qGRA/tables/tables_15_1.jpg", "caption": "Table 2: Robustness comparison of the overall performance on MOSI and MOSEI datasets. Note: The smaller MAE indicates the better performance.", "description": "This table presents a comparison of the overall performance of several different methods on the MOSI and MOSEI datasets across various missing data rates. The performance metrics included are Acc-7 (seven-class accuracy), Acc-5 (five-class accuracy), Acc-2 (binary classification accuracy), F1 (F1-score), MAE (mean absolute error), and Corr (correlation).  The table highlights the robustness of each method by showing how well they perform under different noise levels.  The smaller the MAE value, the better the performance.", "section": "4.4 Robustness Comparison"}, {"figure_path": "mYEjc7qGRA/tables/tables_16_1.jpg", "caption": "Table 2: Robustness comparison of the overall performance on MOSI and MOSEI datasets. Note: The smaller MAE indicates the better performance.", "description": "This table presents a comparison of the overall performance of several multimodal sentiment analysis (MSA) methods on the MOSI and MOSEI datasets under different levels of random data missing.  The metrics used to evaluate the model performance are three-class accuracy (Acc-3), two-class accuracy (Acc-2), F1 score (F1), mean absolute error (MAE), and correlation (Corr).  The table demonstrates the robustness of each method by showing the performance under different percentages of missing data, helping to understand how each method deals with incomplete data.", "section": "4.4 Robustness Comparison"}, {"figure_path": "mYEjc7qGRA/tables/tables_21_1.jpg", "caption": "Table 2: Robustness comparison of the overall performance on MOSI and MOSEI datasets. Note: The smaller MAE indicates the better performance.", "description": "This table presents a comparison of the performance of various methods on the MOSI and MOSEI datasets under different missing rate conditions. The performance is evaluated using multiple metrics, including accuracy (Acc-2 and Acc-7), F1 score, MAE, and correlation (Corr).  The results highlight the robustness and competitiveness of each method in handling incomplete data.", "section": "4 Experiments and Analysis"}, {"figure_path": "mYEjc7qGRA/tables/tables_21_2.jpg", "caption": "Table 12: Generalization comparison of the overall performance on SIMS dataset with random modality missing. Note: the parameters used for evaluation are consistent with those used for testing in random data missing. The smaller MAE indicates better performance.", "description": "This table presents a comparison of the overall performance of several methods on the SIMS dataset when random modality missing occurs.  The results shown include accuracy metrics (Acc-5, Acc-3, Acc-2, F1), mean absolute error (MAE), and correlation (Corr). The experiment parameters are consistent with those used in the random data missing scenario.  Lower MAE values indicate better performance.", "section": "4 Experiments and Analysis"}, {"figure_path": "mYEjc7qGRA/tables/tables_22_1.jpg", "caption": "Table 2: Robustness comparison of the overall performance on MOSI and MOSEI datasets. Note: The smaller MAE indicates the better performance.", "description": "This table presents a comparison of the performance of several Multimodal Sentiment Analysis (MSA) methods on two benchmark datasets, MOSI and MOSEI. The comparison focuses on the robustness of the methods under different levels of random data missing (noise).  The metrics used for evaluation include binary and multi-class accuracy (Acc-2, Acc-7), F1 scores, Mean Absolute Error (MAE), and correlation (Corr). The smaller the MAE, the better the performance.", "section": "4 Experiments and Analysis"}, {"figure_path": "mYEjc7qGRA/tables/tables_22_2.jpg", "caption": "Table 2: Robustness comparison of the overall performance on MOSI and MOSEI datasets. Note: The smaller MAE indicates the better performance.", "description": "This table presents a comparison of the performance of different methods on MOSI and MOSEI datasets, considering various metrics such as accuracy, F1 score, and MAE.  The comparison is done under various levels of random data missing, from 0% to 90%, evaluating the robustness of each model.  The results are intended to illustrate the effectiveness of the methods and their ability to handle incomplete data. Lower MAE values are indicative of better performance.", "section": "4 Experiments and Analysis"}, {"figure_path": "mYEjc7qGRA/tables/tables_23_1.jpg", "caption": "Table 2: Robustness comparison of the overall performance on MOSI and MOSEI datasets. Note: The smaller MAE indicates the better performance.", "description": "This table presents a comparison of the overall performance of several methods on the MOSI and MOSEI datasets under various levels of random data missing.  The metrics used for comparison include binary and multi-class accuracy (Acc-2, Acc-3, Acc-7), F1 score, mean absolute error (MAE), and correlation (Corr).  The table highlights the robustness of each model by showing their performance across different levels of data incompleteness (missing rates). The smaller the MAE value, the better the performance. ", "section": "4.4 Robustness Comparison"}]