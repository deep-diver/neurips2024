[{"figure_path": "5GCgNFZSyo/figures/figures_2_1.jpg", "caption": "Figure 1: This function f is sampled from GP(0, k(x, x')), where k(x, x') = exp(-(x \u2013 x')\u00b2), with standard derivation of white noise \u03c3 = 0.05. The dataset contains 2 points, which is marked as black hollow circle. We attempt to search the next point from x0. The left figure shows that UCB bound is much tighter than other two gradient based bounds, and the minimum points of UCB has the best performance. This shows that minimizing UCB in this example can achieve a much better move to lower point than the gradient descent approach. The right figure illustrates UCB across the design space. Here we see that it is small only near the sampled point, and increases as it moves further away, indicating that minimizing UCB can be viewed as local strategy.", "description": "This figure shows a comparison of different acquisition functions for selecting the next point in a Bayesian optimization algorithm. The left panel shows a 1D example where the UCB (Upper Confidence Bound) is much tighter than gradient-based bounds, indicating that minimizing UCB can lead to a better point than using gradient descent. The right panel displays a UCB surface, which shows that UCB is small near the sampled points and increases as the distance from the sampled points increases, thus showing its local nature.", "section": "2 Literature Review"}, {"figure_path": "5GCgNFZSyo/figures/figures_4_1.jpg", "caption": "Figure 1: This function f is sampled from GP(0, k(x, x')), where k(x, x') = exp(-(x \u2013 x')\u00b2), with standard derivation of white noise \u03c3 = 0.05. The dataset contains 2 points, which is marked as black hollow circle. We attempt to search the next point from x0. The left figure shows that UCB bound is much tighter than other two gradient based bounds, and the minimum points of UCB has the best performance. This shows that minimizing UCB in this example can achieve a much better move to lower point than the gradient descent approach. The right figure illustrates UCB across the design space. Here we see that it is small only near the sampled point, and increases as it moves further away, indicating that minimizing UCB can be viewed as local strategy.", "description": "This figure compares UCB with gradient-based bounds (approximated gradient bound and gradient bound) to illustrate the advantage of minimizing UCB for finding the next point in Bayesian optimization. The left panel shows that UCB provides a tighter bound and its minimum point leads to better performance than gradient descent. The right panel shows how UCB varies across the design space, demonstrating its suitability as a local search strategy because it is small only near the sampled point and increases as the distance increases.", "section": "4 The relationship between gradient descent and minimizing UCB"}, {"figure_path": "5GCgNFZSyo/figures/figures_8_1.jpg", "caption": "Figure 2: Progressive optimized reward on high-dimensional synthetic functions. LA-MinUCB demonstrates fast and accurate convergence compared to other methods.", "description": "This figure compares the performance of LA-MinUCB with four other Bayesian Optimization algorithms (MinUCB, MPD, GIBO, and Turbo) on high-dimensional synthetic functions with dimensions of 25, 50, and 100.  The y-axis represents the progressive optimized reward (the best objective function value found so far), and the x-axis represents the number of function evaluations (queries).  The shaded regions around each line represent the standard deviation across multiple trials.  The results show that LA-MinUCB consistently converges faster and achieves a higher reward than the other methods, demonstrating its superior performance in high-dimensional settings.", "section": "8 Experiments"}, {"figure_path": "5GCgNFZSyo/figures/figures_8_2.jpg", "caption": "Figure 3: Progressive optimized reward on the MuJuCo tasks. LA-MinUCB has consistently optimal performance.", "description": "This figure presents the progressive optimized reward on three MuJoCo tasks (CartPole, Swimmer, and Hopper) across multiple queries.  The results demonstrate the performance of LA-MinUCB against other local Bayesian optimization methods (MinUCB, MPD, GIBO, and TurBO).  LA-MinUCB consistently achieves the highest reward, indicating superior performance in finding optimal solutions in these reinforcement learning tasks. Error bars representing variability are included for each algorithm.", "section": "Experiments"}, {"figure_path": "5GCgNFZSyo/figures/figures_25_1.jpg", "caption": "Figure 4: Progressive objective values observed on real-world tasks. LA-MinUCB is competitive against other baselines on all tasks.", "description": "This figure presents the results of applying the LA-MinUCB algorithm and other benchmark algorithms on three real-world tasks: 9D map fitting, 12D cosmological constant, and 200D rover trajectory.  The x-axis represents the number of function evaluations (queries), and the y-axis shows the progressive optimized reward (objective value) achieved by each algorithm.  The shaded regions around each line represent confidence intervals.  The figure demonstrates that LA-MinUCB consistently achieves competitive or superior performance compared to GIBO, MPD, and TurBO across all three tasks, highlighting its effectiveness in real-world scenarios.", "section": "8 Experiments"}, {"figure_path": "5GCgNFZSyo/figures/figures_25_2.jpg", "caption": "Figure 5: Progressive objective values observed on synthetic function. Our methods are much better than traditional UCB methods", "description": "This figure compares the performance of LA-MinUCB, MinUCB, and a traditional UCB method on three synthetic objective functions with 25, 50, and 100 dimensions.  The y-axis represents the current best reward found, and the x-axis represents the number of queries (function evaluations). The shaded areas represent the standard deviation across multiple runs.  The results show that LA-MinUCB and MinUCB significantly outperform the traditional UCB approach, particularly in higher dimensions, converging faster to better solutions.", "section": "8 Experiments"}, {"figure_path": "5GCgNFZSyo/figures/figures_25_3.jpg", "caption": "Figure 6: Progressive objective values observed on synthetic function when D = 25.", "description": "This figure displays the progressive optimized reward on a 25-dimensional synthetic function for different values of beta (\u03b2 = 1, 3, and 5) in both MinUCB and LA-MinUCB algorithms. The shaded area represents the standard deviation across multiple runs. It demonstrates the performance of the algorithms with varying degrees of exploration-exploitation trade-off controlled by the beta parameter.", "section": "8.1 Synthetic Objectives"}, {"figure_path": "5GCgNFZSyo/figures/figures_25_4.jpg", "caption": "Figure 7: Progressive objective values observed on synthetic function when D = 50.", "description": "This figure displays the results of progressive objective values observed on a synthetic function with a dimensionality (D) of 50.  The graph shows the performance of MinUCB and LA-MinUCB algorithms, each tested with different values of the beta (\u03b2) parameter (\u03b2=1, \u03b2=3, \u03b2=5). The beta parameter influences the algorithm's exploration-exploitation balance; smaller betas prioritize exploration, while larger betas favor exploitation. The shaded regions around each line represent the standard deviation across multiple runs of the experiment, indicating the variability in performance. The x-axis represents the number of function evaluations (queries), and the y-axis displays the current best objective value found so far. This allows a visual comparison of the convergence speed and stability of the two algorithms under varying exploration-exploitation strategies.", "section": "8 Experiments"}, {"figure_path": "5GCgNFZSyo/figures/figures_26_1.jpg", "caption": "Figure 8: Progressive objective values observed on synthetic function when D = 100.", "description": "This figure shows the progressive optimized reward on the 100-dimensional synthetic function for MinUCB and LA-MinUCB with different beta values (1, 3, and 5). The shaded area represents the standard deviation.  The results illustrate how the choice of beta affects the convergence speed and final reward for both algorithms.", "section": "8 Experiments"}]