[{"figure_path": "GJ0qIevGjD/tables/tables_6_1.jpg", "caption": "Table 1: The performance comparison to state-of-the-art methods on HIV and PCBA in terms of ROC-AUC (%, \u2191) and Average Precision (%, \u2191). We highlight the best-performing results in boldface. The performance difference with whole dataset training is highlighted with blue and orange, respectively.", "description": "This table presents a comparison of the performance of various data pruning methods (including MolPeg) on the HIV and PCBA datasets.  The performance metrics used are ROC-AUC and Average Precision.  The table highlights the best-performing method for each pruning ratio and shows the performance difference compared to using the whole dataset. This allows for easy comparison of the effectiveness and efficiency of different pruning techniques.", "section": "5.1 Empirical analysis on classification tasks"}, {"figure_path": "GJ0qIevGjD/tables/tables_7_1.jpg", "caption": "Table 2: The performance comparison to state-of-the-art methods on QM9 dataset in terms of MAE (\u2193). We highlight the best- and the second-performing results in boldface and underlined, respectively.", "description": "This table presents a comparison of the performance of MolPeg against other state-of-the-art data pruning methods on the QM9 dataset.  The performance metric used is Mean Absolute Error (MAE), with lower values indicating better performance. The table shows results for different pruning ratios (percentage of data removed) and highlights the best and second-best performing methods for each ratio in bold and underlined text, respectively.  The results are for two different properties in QM9, QM9-U0 and QM9-Zpve.", "section": "5.2 Results on QM9 dataset"}, {"figure_path": "GJ0qIevGjD/tables/tables_8_1.jpg", "caption": "Table 3: Performance with 3D modality on HIV dataset.", "description": "This table presents the performance comparison of different data pruning methods on the HIV dataset using the 3D modality. It shows the ROC-AUC scores for various pruning ratios (60%, 40%, 20%) for Random Pruning and MolPeg, and also includes the performance of training with the whole dataset. The results highlight the effectiveness of MolPeg in achieving superior performance compared to random pruning, even surpassing the full dataset performance at certain pruning ratios.", "section": "5.3 Sensitivity Analysis"}, {"figure_path": "GJ0qIevGjD/tables/tables_14_1.jpg", "caption": "Table 4: Statistics of datasets used in experiments.", "description": "This table presents a summary of the datasets used in the experiments described in the paper.  It shows the dataset name, data type (SMILES or SMILES, 3D), the number of molecules, the average number of atoms and bonds per molecule, the number of tasks (for multi-task datasets), and the average degree of the molecular graphs.  The datasets are categorized into pre-training datasets (used to train the initial model) and finetuning datasets (used to adapt the pre-trained model to specific tasks).", "section": "4.1 Datasets and tasks"}, {"figure_path": "GJ0qIevGjD/tables/tables_18_1.jpg", "caption": "Table 5: The performance comparison on HIV with different pre-taining datasets of varying quality in terms of ROC-AUC (%, \u2191)", "description": "This table presents the results of the robustness evaluation across pretaining datasets.  It compares the performance of various data pruning methods (Hard Random, Forgetting, GraNd, Glister, Soft Random, UCB, InfoBatch, MolPeg) on the HIV dataset, using two pretrained models of varying quality, obtained from the ZINC15 and QM9 datasets.  The results are shown for three different pruning ratios (90%, 70%, 40%). The table also includes the performance of training on the full dataset and training from scratch for comparison.", "section": "G.2 Robustness evaluation of different pretraining datasets"}, {"figure_path": "GJ0qIevGjD/tables/tables_19_1.jpg", "caption": "Table 6: The performance comparison to state-of-the-art methods on MUV in terms of ROC-AUC (%, \u2191).", "description": "This table presents the performance comparison of different data pruning methods on the MUV dataset in terms of ROC-AUC.  It shows the results for both static and dynamic pruning methods at different pruning ratios (90%, 70%, and 40%).  The methods compared include random pruning, forgetting, GraNd-20, Glister, UCB, InfoBatch, and MolPeg.  The table highlights the best-performing results, allowing for a direct comparison of the effectiveness of each method at different data reduction levels.", "section": "5.1 Empirical analysis on classification tasks"}]