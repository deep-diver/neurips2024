[{"figure_path": "fYfliutfHX/figures/figures_1_1.jpg", "caption": "Figure 1: Learning straightened representations. A. Illustration of temporal trajectories, in the space of pixel intensities (left), and in a straightened representation (right). Color indicates digit identity. B. Two-dimensional t-SNE rendering of actual trajectories for the translating digits in our sequential MNIST dataset. Initial (pixel intensity) representation is highly curved and entangled (left). Although the straightening objective is unsupervised (no object labels), the learned representation clearly isolates the trajectories corresponding to different digits (right).", "description": "This figure illustrates the concept of straightening in the context of learning visual representations from sequential data. Panel A shows how a sequence of image frames in pixel space (left) can be mapped to a lower-dimensional embedding space (right), where the trajectories are significantly straighter.  Panel B provides a concrete example using a dataset of translating digits; the t-SNE plots demonstrate how curved and entangled initial trajectories in pixel space become more clearly separated in the straightened representation.", "section": "1 Introduction"}, {"figure_path": "fYfliutfHX/figures/figures_4_1.jpg", "caption": "Figure 2: Straightening and its benefits, evaluated on a network trained on sequential MNIST. A. Three example sequences, illustrating the three geometric transformations. B. Emergence of straightness throughout layers of network computation. C. Accuracy in decoding various (untrained) variables from the network responses (top). Accuracy in predicting/decoding variables at the next time step (bottom). Identitity not considered for prediction as it is constant over the sequence. D. Prediction capabilities of the network. Top: example sequence, with dilating/contracting digit. Middle: reconstructions from simultaneous representation. Bottom: predictions (linear extrapolation) based on the representation at the previous two time steps.", "description": "This figure demonstrates the effectiveness of the straightening objective in learning meaningful representations on the sequential MNIST dataset.  Panel A shows examples of the three geometric transformations (translation, rescaling, rotation) used in the dataset. Panel B illustrates the increase in straightness across the different layers of the network, showing that the straightening objective successfully straightens the representations. Panel C shows the accuracy of decoding various variables from the network's responses, both simultaneously and predictively. Panel D shows the network's prediction capabilities, comparing reconstruction from simultaneous representation and predictions via linear extrapolation, highlighting the accuracy of the latter.", "section": "3 Straightening learns meaningful representations"}, {"figure_path": "fYfliutfHX/figures/figures_6_1.jpg", "caption": "Figure 3: Geometric properties of the straightened representation. Panels A-E show histograms of cosine similarity (normalized dot product) between pairs of difference vectors, zt \u2212 zt\u22121. Insets show example trajectories in each scenario, where color indicates digit identity. A. same digit and transformation type; B. same digit and different transformation; C. different digit and same transformation; D. different digit and transformation; E. all difference vectors vs. digit classifier vectors. F. Average effective dimensionality, measured with participation ratio, of the set of responses zt in each group.", "description": "This figure displays the geometric properties of representations learned by the straightening objective function. Histograms of cosine similarity between successive difference vectors are presented to visualize the parallelism of trajectories for the same digit and transformation, and the orthogonality of trajectories across different digits and transformations.  Example trajectories are shown in insets.  Finally, the effective dimensionality of the responses is quantified by the participation ratio, showing how representations from the same class are more compact under straightening than under invariance.", "section": "The geometry of straight representations"}, {"figure_path": "fYfliutfHX/figures/figures_7_1.jpg", "caption": "Figure 4: Effect of straightening on representational robustness. A. Two example synthetic sequences from on sequential CIFAR-10 dataset. Top: translation and color shift. Bottom: rescaling (contraction) and color shift, last frame randomly grayscaled. B. Emergence of straightness throughout layers of network computation. Top arrows mark the stages of representation directly targeted for straightening (blue) and invariance (orange). C. Example sequences illustrating successes (left) and failures (right) of straightening. Numbers indicate straightness level \u2208 [\u22121, 1]. D. Noise robustness: classification accuracy as a function of the amplitude of additive Gaussian noise injected in the input. E. Adversarial robustness: classification accuracy as a function of attack budget (see text). F. Relative classification accuracy of straightened network compared to invariance-trained network for various degradations. Color indicates the objective with better performance.", "description": "This figure demonstrates the impact of straightening on the robustness of the learned representations. It shows example synthetic sequences (A), the emergence of straightness through network layers (B), examples of successful and failed straightening (C), the impact of Gaussian noise on classification accuracy (D), adversarial attack robustness (E), and finally, a comparison of the relative classification accuracy of the straightened and invariance-trained networks under various degradations (F).", "section": "3 Straightening increases recognition robustness"}, {"figure_path": "fYfliutfHX/figures/figures_8_1.jpg", "caption": "Figure 5: Augmentation of other SSL objectives with a straightening regularizer. A. Straightness of representations learned by four different SSL objectives (gray), and their augmentation with a straightening regularizer (blue). B. CIFAR-10 classification accuracy as a function of adversarial attack budget, for the original and straightening-regularized version, for the same four SSL objectives.", "description": "This figure demonstrates the effect of adding the straightening regularizer to four different self-supervised learning (SSL) objectives. Panel A shows that adding the straightening regularizer increases the straightness of the learned representations for all four SSL objectives. Panel B shows that adding the straightening regularizer improves the adversarial robustness of the learned representations for all four SSL objectives.  The results suggest that straightening is a beneficial regularizer that can improve the performance of various SSL objectives.", "section": "Straightening improves robustness in other SSL models"}, {"figure_path": "fYfliutfHX/figures/figures_12_1.jpg", "caption": "Figure 2: Straightening and its benefits, evaluated on a network trained on sequential MNIST. A. Three example sequences, illustrating the three geometric transformations. B. Emergence of straightness throughout layers of network computation. C. Accuracy in decoding various (untrained) variables from the network responses (top). Accuracy in predicting/decoding variables at the next time step (bottom). Identitity not considered for prediction as it is constant over the sequence. D. Prediction capabilities of the network. Top: example sequence, with dilating/contracting digit. Middle: reconstructions from simultaneous representation. Bottom: predictions (linear extrapolation) based on the representation at the previous two time steps.", "description": "Figure 2 shows the results of the proposed straightening method applied to sequential MNIST dataset. (A) shows example sequences demonstrating three types of transformations: translation, rescaling, and rotation. (B) illustrates the increase in straightness across network layers during training using the proposed objective function, highlighting the effectiveness of the method.  (C) demonstrates the accuracy of decoding various visual attributes (location, size, orientation) from the learned representations. The bottom part of (C) shows the accuracy of predicting future states of these attributes. (D) shows an example sequence (top) along with the simultaneous reconstructions (middle) from its learned representations and predictions based on linear extrapolation from the previous frames (bottom). The figure supports the main claim that the straightening objective leads to better representation that is more predictive and robust.", "section": "3 Straightening learns meaningful representations"}, {"figure_path": "fYfliutfHX/figures/figures_13_1.jpg", "caption": "Figure 5: Augmentation of other SSL objectives with a straightening regularizer. A. Straightness of representations learned by four different SSL objectives (gray), and their augmentation with a straightening regularizer (blue). B. CIFAR-10 classification accuracy as a function of adversarial attack budget, for the original and straightening-regularized version, for the same four SSL objectives.", "description": "This figure shows the impact of adding a straightening regularizer to four different self-supervised learning (SSL) objectives.  Panel A demonstrates that adding the regularizer increases the straightness of the resulting representations. Panel B shows that this added regularization improves the robustness of the resulting models against adversarial attacks, as measured by classification accuracy on the CIFAR-10 dataset.", "section": "Straightening improves robustness in other SSL models"}, {"figure_path": "fYfliutfHX/figures/figures_13_2.jpg", "caption": "Figure 6: A. Example gestures. Some gestures can be classified by a single frame (pause), while others must observe multiple frames to recognize the motion (scroll hand backward, zoom in with fists). B. Gesture recognition performance as a function of noise level.", "description": "Figure 6 shows two subfigures. Subfigure A displays three example gesture sequences from the EgoGesture dataset. These sequences demonstrate different types of gestures, some of which can be easily classified from a single frame (e.g., \"pause\"), while others require observing multiple frames to understand the motion (e.g., \"scroll hand backward\", \"zoom in with fists\"). Subfigure B presents a graph illustrating the robustness of gesture recognition under different levels of Gaussian noise. The graph compares the classification accuracy of models trained with the straightening objective (blue line) against those trained with the invariance objective (orange line). The x-axis represents the standard deviation of added Gaussian noise, while the y-axis shows the classification accuracy. The results indicate that the model trained using the straightening objective outperforms the invariance-trained model in terms of robustness against noise.", "section": "Straightening natural temporal transformations"}]