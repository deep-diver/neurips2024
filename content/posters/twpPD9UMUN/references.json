{"references": [{"fullname_first_author": "Y.-B. Lin", "paper_title": "Vision transformers are parameter-efficient audio-visual learners", "publication_date": "2023-06-01", "reason": "This paper proposes a novel vision transformer architecture for audio-visual learning, which is highly relevant to the current paper's approach and contributes significantly to the state-of-the-art in audio-visual question answering."}, {"fullname_first_author": "G. Li", "paper_title": "Learning to answer questions in dynamic audio-visual scenarios", "publication_date": "2022-06-01", "reason": "This paper introduces the MUSIC-AVQA dataset, which is the foundation for the proposed MUSIC-AVQA-R dataset, and thus provides a crucial context for understanding the improvements presented in the current work."}, {"fullname_first_author": "P. Yang", "paper_title": "AVQA: A dataset for audio-visual question answering on videos", "publication_date": "2022-10-26", "reason": "This paper introduces a new dataset for audio-visual question answering, which is directly compared to and improved upon by the MUSIC-AVQA-R dataset in the current research."}, {"fullname_first_author": "H. Yun", "paper_title": "Pano-AVQA: Grounded audio-visual question answering on 360\u00b0 videos", "publication_date": "2021-06-01", "reason": "This paper introduces another relevant dataset for audio-visual question answering and provides a comparison point to assess the novelty and improvements of the proposed MUSIC-AVQA-R dataset."}, {"fullname_first_author": "Z. Wen", "paper_title": "Debiased visual question answering from feature and sample perspectives", "publication_date": "2021-12-01", "reason": "This paper addresses the issue of bias in visual question answering, providing a theoretical framework and practical techniques that are directly relevant to the methods employed in the current paper to overcome bias in audio-visual question answering."}]}