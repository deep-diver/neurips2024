{"importance": "This paper is crucial for researchers in autonomous driving and real-time perception. It introduces a novel framework, addressing the critical challenge of latency in 3D object detection for streaming perception.  This work paves the way for more responsive and accurate perception systems vital for safe and efficient autonomous vehicles, opening avenues for research in efficient deep learning architectures and real-time perception algorithms.  Its novel fusion method and loss function provide valuable tools for improving the accuracy and efficiency of future systems. ", "summary": "StreamDSGN: a real-time stereo 3D object detection framework significantly boosts streaming perception accuracy by leveraging historical information, a feature-flow fusion method, and a motion consistency loss.", "takeaways": ["StreamDSGN, a novel real-time stereo-based 3D object detection framework designed for streaming perception, significantly improves accuracy.", "The framework incorporates a feature-flow fusion method to address the misalignment issue between features and ground truth in streaming data.", "StreamDSGN uses a motion consistency loss function and a large kernel backbone to enhance accuracy and the handling of long-range spatial contextual features."], "tldr": "Autonomous driving demands real-time perception, promptly reacting to environmental changes.  However, existing stereo-based 3D object detection methods struggle with high computational costs, leading to significant latency and reduced accuracy, especially in the context of 'streaming perception' which considers both accuracy and latency. This misalignment between predictions and real-time changes hinders performance.\nThis paper introduces StreamDSGN, an end-to-end framework directly predicting the next moment's 3D object properties using historical information.  To boost accuracy, StreamDSGN employs three key strategies:  a feature-flow based fusion to solve misalignment, an extra regression loss for object motion consistency, and a large kernel backbone for capturing long-range context.  Extensive testing on the KITTI Tracking dataset showcases a substantial improvement in streaming average precision (up to 4.33%), proving the effectiveness of the proposed solution. ", "affiliation": "Sun Yat-sen University", "categories": {"main_category": "Computer Vision", "sub_category": "Object Detection"}, "podcast_path": "IpHB5RC3za/podcast.wav"}