[{"figure_path": "2dfBpyqh0A/tables/tables_5_1.jpg", "caption": "Table 1: Quantitative comparison on RealEstate10K (re10K) [69] and ACID [26] benchmarks. We evaluate all models with 4, 8, 16 input views and report PSNR as well as the number of Gaussians (K). \u2020 Models accept multi-view inputs, and only preserve Gaussians from two input views for rendering.", "description": "This table presents a quantitative comparison of different novel view synthesis methods (pixelSplat [4], MVSplat [6], and the proposed GGN) on two benchmark datasets, RealEstate10K and ACID.  The comparison is based on Peak Signal-to-Noise Ratio (PSNR) and the number of Gaussians used for rendering novel views.  Results are shown for 4, 8, and 16 input views.  The \u2020 symbol indicates that methods using multiple views only use Gaussians from two views for the final rendering.", "section": "4.1 Multi-view Scene Reconstruction and Synthesis"}, {"figure_path": "2dfBpyqh0A/tables/tables_5_2.jpg", "caption": "Table 2: Novel view synthesis results with two-view inputs. We report the average results of PSNR, SSIM and LPIPS on all test scenes.", "description": "This table presents a comparison of the performance of different novel view synthesis methods using only two input views. The average PSNR, SSIM, and LPIPS scores are reported for each method across all test scenes in the RealEstate10K and ACID datasets.  The metrics evaluate the quality of the synthesized novel views generated from the input views.", "section": "4 Experiments"}, {"figure_path": "2dfBpyqh0A/tables/tables_8_1.jpg", "caption": "Table 4: Cross-dataset performance and efficiency comparisons on RealEstate10K [69] and ACID [26] benchmarks. We assign eight views as reference and test on three target views for each scene.", "description": "This table presents a quantitative comparison of the proposed Gaussian Graph Network (GGN) and two baseline methods (pixelSplat and MVSplat) on cross-dataset generalization tasks.  It shows the performance of models trained on one dataset (either RealEstate10K or ACID) and tested on the other dataset.  The metrics reported include PSNR, SSIM, LPIPS, the number of Gaussians used, and Frames Per Second (FPS).  This demonstrates the generalizability and efficiency of the GGN.", "section": "4.3 Cross Dataset Generalization"}, {"figure_path": "2dfBpyqh0A/tables/tables_8_2.jpg", "caption": "Table 5: Ablation study results of GGN on RealEstate10K [69] benchmarks. Each scene takes eight reference views and renders three novel views.", "description": "This ablation study analyzes the impact of key components within the Gaussian Graph Network (GGN) architecture on the model's performance. By systematically removing components such as the Gaussian Graph linear layer and Gaussian Graph pooling layer, the study isolates the contribution of each component towards the overall performance. The \"Vanilla\" model represents the baseline without any of the proposed GGN components. The results quantitatively demonstrate the importance of each component in achieving better performance. The metrics used are PSNR, SSIM, LPIPS and the number of Gaussians used.", "section": "4.4 Ablations"}, {"figure_path": "2dfBpyqh0A/tables/tables_13_1.jpg", "caption": "Table 1: Quantitative comparison on RealEstate10K (re10K) [69] and ACID [26] benchmarks. We evaluate all models with 4, 8, 16 input views and report PSNR as well as the number of Gaussians (K). \u2020 Models accept multi-view inputs, and only preserve Gaussians from two input views for rendering.", "description": "This table presents a quantitative comparison of different novel view synthesis methods on two benchmark datasets: RealEstate10K and ACID.  The methods are evaluated using 4, 8, and 16 input views, and the results are reported in terms of Peak Signal-to-Noise Ratio (PSNR) and the number of Gaussians used for rendering.  The table highlights the efficiency gains of the proposed Gaussian Graph Network (GGN) method, which achieves comparable or better PSNR with significantly fewer Gaussians.", "section": "4.1 Multi-view Scene Reconstruction and Synthesis"}, {"figure_path": "2dfBpyqh0A/tables/tables_14_1.jpg", "caption": "Table 1: Quantitative comparison on RealEstate10K (re10K) [69] and ACID [26] benchmarks. We evaluate all models with 4, 8, 16 input views and report PSNR as well as the number of Gaussians (K). \u2020 Models accept multi-view inputs, and only preserve Gaussians from two input views for rendering.", "description": "This table presents a quantitative comparison of different novel view synthesis methods on the RealEstate10K and ACID benchmark datasets.  The methods are evaluated using 4, 8, and 16 input views.  The table reports the Peak Signal-to-Noise Ratio (PSNR) and the number of Gaussians used for rendering. Note that methods marked with \u2020 use multiple views as input but only render using Gaussians from two of the input views.", "section": "4.1 Multi-view Scene Reconstruction and Synthesis"}, {"figure_path": "2dfBpyqh0A/tables/tables_14_2.jpg", "caption": "Table 1: Quantitative comparison on RealEstate10K (re10K) [69] and ACID [26] benchmarks. We evaluate all models with 4, 8, 16 input views and report PSNR as well as the number of Gaussians (K). \u2020 Models accept multi-view inputs, and only preserve Gaussians from two input views for rendering.", "description": "This table presents a quantitative comparison of different novel view synthesis methods (pixelSplat, MVSplat, and the proposed GGN) on the RealEstate10K and ACID datasets.  The comparison is based on Peak Signal-to-Noise Ratio (PSNR) and the number of Gaussians used in the models' representations for 4, 8, and 16 input views. Note that for methods that handle multiple views, the results are shown for using only two views for final rendering to ensure a fair comparison.", "section": "4.1 Multi-view Scene Reconstruction and Synthesis"}]