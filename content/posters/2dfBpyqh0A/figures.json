[{"figure_path": "2dfBpyqh0A/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison of previous methods and ours. (a) We visualize the rendering results of various methods and report the number of Gaussians in parentheses. (b) Previous pixel-wise methods can be considered as a degraded case of Gaussian Graphs without edges. (c) We report PSNR as well as the number of Gaussians for pixelSplat [4], MVSplat [6] and GNN under different input settings.", "description": "This figure compares the novel view synthesis results of the proposed Gaussian Graph Network (GGN) with those of existing methods, namely PixelSplat and MVSplat.  Subfigure (a) shows a qualitative comparison of the rendered images, highlighting the improved visual quality of GGN despite using significantly fewer Gaussians.  Subfigure (b) illustrates the conceptual difference between the pixel-wise Gaussian approach of previous methods and the Gaussian Graph representation used in GGN. Subfigure (c) presents a quantitative comparison in terms of Peak Signal-to-Noise Ratio (PSNR) and the number of Gaussians required, demonstrating the superior efficiency and performance of the proposed GGN method across varying numbers of input views.", "section": "1 Introduction"}, {"figure_path": "2dfBpyqh0A/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of Gaussian Graph Network. Given multiple input images, we extract image features and predict the means and features of pixel-aligned Gaussians. Then, we construct a Gaussian Graph to model the relations between different Gaussian nodes. We introduce Gaussian Graph Network to process our Gaussian Graph. The parameter predictor generates Gaussians parameters from the output Gaussian features.", "description": "This figure illustrates the overall framework of the Gaussian Graph Network (GGN).  It begins with multiple input images that are processed by an image encoder to generate feature maps. From these feature maps, a position predictor and feature predictor estimate the means (\u03bc) and features (f) of pixel-aligned Gaussians.  These Gaussians are then organized into a Gaussian Graph, where nodes represent groups of Gaussians and edges represent relationships between them. A Gaussian Graph Network processes this graph to fuse information between Gaussians before a parameter predictor generates the final Gaussian parameters (\u03b1, \u03a3, \u010d).", "section": "3 Method"}, {"figure_path": "2dfBpyqh0A/figures/figures_6_1.jpg", "caption": "Figure 3: Visualization results on RealEstate10K [69] and ACID [26] benchmarks. We evaluate all models with 4, 8, 16 views as input and subsequently test on three target novel views.", "description": "This figure shows a comparison of novel view synthesis results from different methods (PixelSplat, MVSplat, and the proposed GGN method) using 4, 8, and 16 input views.  The ground truth images are also provided for reference. Each row represents a different scene, showcasing the rendered images produced by each method. The results highlight the visual quality and differences in the number of Gaussians used by each approach, with the GGN method demonstrating improved quality with fewer Gaussians.", "section": "4.1 Multi-view Scene Reconstruction and Synthesis"}, {"figure_path": "2dfBpyqh0A/figures/figures_7_1.jpg", "caption": "Figure 4: Efficiency analysis. We report the number of Gaussians (M), rendering frames per second (FPS) and reconstruction PSNR of pixelSplat [4], MVSplat [6] and our GGN.", "description": "This figure analyzes the efficiency of the proposed Gaussian Graph Network (GGN) compared to two existing methods, pixelSplat and MVSplat.  It shows the trade-off between the number of Gaussians used (a measure of model complexity and memory usage), the rendering speed (frames per second, FPS), and the resulting image quality (Peak Signal-to-Noise Ratio, PSNR). The results demonstrate that GGN achieves higher PSNR (better image quality) with fewer Gaussians and faster rendering speed than the other methods.", "section": "4.2 Efficiency Analysis"}, {"figure_path": "2dfBpyqh0A/figures/figures_7_2.jpg", "caption": "Figure 5: Visualization of model performance for cross-dataset generalization on RealEstate10K [69] and ACID [26] benchmarks.", "description": "This figure shows the results of a cross-dataset generalization experiment.  The model was trained on either the RealEstate10K or ACID dataset and then tested on the other dataset. The top row displays results when trained on RealEstate10K and tested on ACID, and the bottom row displays the inverse.  Each column shows the ground truth, PixelSplat, MVSplat and the proposed GGN method. The figure aims to demonstrate the generalization capability of the GGN across different datasets.", "section": "4.3 Cross Dataset Generalization"}, {"figure_path": "2dfBpyqh0A/figures/figures_15_1.jpg", "caption": "Figure 3: Visualization results on RealEstate10K [69] and ACID [26] benchmarks. We evaluate all models with 4, 8, 16 views as input and subsequently test on three target novel views.", "description": "This figure displays a comparison of novel view synthesis results from various methods, including PixelSplat, MVSplat, and the proposed Gaussian Graph Network (GGN).  Each row represents a different scene, showing input views (leftmost), ground truth (second from left), results from PixelSplat, MVSplat, and finally, the results from GGN.  The figure visually demonstrates the superior image quality and efficiency achieved by GGN compared to the baseline methods, particularly as the number of input views increases. The differences highlight GGN's ability to generate more realistic novel views with fewer artifacts, even with limited input data.", "section": "4.1 Multi-view Scene Reconstruction and Synthesis"}, {"figure_path": "2dfBpyqh0A/figures/figures_16_1.jpg", "caption": "Figure 7: Additional visualization results of model performance for cross-dataset generalization on RealEstate10K [69] and ACID [26] benchmarks.", "description": "This figure shows the cross-dataset generalization results of the proposed Gaussian Graph Network (GGN) method.  The model is trained on either the RealEstate10K or ACID dataset and then tested on the other dataset, demonstrating its ability to generalize across different scene types.  The results are compared against the ground truth and two other state-of-the-art methods, pixelSplat and MVSplat, showcasing the superior performance of GGN.", "section": "4.3 Cross Dataset Generalization"}, {"figure_path": "2dfBpyqh0A/figures/figures_16_2.jpg", "caption": "Figure 8: Visualization results of ablation study on RealEstate10K [69] and ACID [26] benchmarks.", "description": "This figure presents an ablation study comparing the performance of the proposed Gaussian Graph Network (GGN) with several variants.  The \"Full Model\" represents the complete GGN.  \"w/o Linear Layer\" shows the results when the linear layers are removed from the GGN. \"w/o Pooling Layer\" omits the pooling layers. Finally, \"Vanilla\" denotes a baseline model without the Gaussian Graph architecture. The visualizations demonstrate the impact of each component of the GGN on the final image quality.", "section": "4.4 Ablations"}, {"figure_path": "2dfBpyqh0A/figures/figures_17_1.jpg", "caption": "Figure 9: Visualization results of large-scale scenes from RealEstate10K and ACID benchmarks.", "description": "This figure shows a comparison of novel view synthesis results on six large-scale scenes from the RealEstate10K and ACID datasets.  For each scene, it displays the input images, the ground truth, and the results from three different methods: PixelSplat, MVSplat, and the authors' proposed GGN (Gaussian Graph Network) method. The visualization demonstrates the ability of each method to generate novel views from multiple input images, and highlights the differences in visual quality between the approaches, particularly with regard to detail preservation and artifact reduction.", "section": "Experiments"}]