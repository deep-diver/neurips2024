[{"figure_path": "Xp8qhdmeb4/tables/tables_4_1.jpg", "caption": "Table 1: Quantitative comparisons of segmentation performance on the validation set of AMOS-CT dataset. * denotes the results with postprocessing.", "description": "This table presents a comparison of the segmentation performance of different methods on the AMOS-CT dataset's validation set.  Metrics include mDice (mean Dice Similarity Coefficient), the number of model parameters (Params), floating point operations (FLOPs) during inference, a performance trade-off score (PT score) that balances accuracy and efficiency, and mNSD (mean Normalized Surface Dice). The methods compared include several state-of-the-art (SOTA) models and the proposed E2ENet model with varying levels of feature sparsity. The * indicates results that included post-processing steps.", "section": "3 Experiments"}, {"figure_path": "Xp8qhdmeb4/tables/tables_5_1.jpg", "caption": "Table 2: 5-fold cross-validation of segmentation performance on the BraTS Challenge training set in the MSD. Note: ED, ET, and NET denote edema, enhancing tumor, and non-enhancing tumor, respectively.", "description": "This table presents the results of a 5-fold cross-validation experiment on the BraTS (Brain Tumor Segmentation) Challenge training set within the Medical Segmentation Decathlon (MSD).  It compares the performance of E2ENet at different sparsity levels (S) against other state-of-the-art methods such as DiNTS, UNet++, and nnUNet. The metrics reported are Dice scores for three tumor regions (edema, enhancing tumor, non-enhancing tumor), the mean Dice score (mDice), the number of model parameters (Params), the number of floating-point operations (FLOPs), and a performance trade-off score (PT score).  The table shows that E2ENet achieves competitive performance while significantly reducing the number of parameters and FLOPs.", "section": "3.1 Comparison with SOTA methods"}, {"figure_path": "Xp8qhdmeb4/tables/tables_5_2.jpg", "caption": "Table 3: Ablation study on the effects of the DSFF mechanism and restricted depth-shift in 3D convolution on the validation set of the AMOS-CT Challenge.", "description": "This table presents the ablation study results on the AMOS-CT dataset validation set to evaluate the impact of the Dynamic Sparse Feature Fusion (DSFF) mechanism and the restricted depth-shift in 3D convolution on the model's performance. It compares different model configurations, including with and without DSFF, with and without depth-shift, and with different depth-shift sizes and kernel sizes. The results are measured using mDice, the number of parameters, FLOPs (floating-point operations), and mNSD (mean normalized surface dice).", "section": "3 Experiments"}, {"figure_path": "Xp8qhdmeb4/tables/tables_6_1.jpg", "caption": "Table 3: Ablation study on the effects of the DSFF mechanism and restricted depth-shift in 3D convolution on the validation set of the AMOS-CT Challenge.", "description": "This table presents the ablation study results on the validation set of the AMOS-CT challenge. It shows the impact of two key components of E2ENet: the Dynamic Sparse Feature Fusion (DSFF) mechanism and the restricted depth-shift in 3D convolution.  The table compares the performance (mDice, Params, FLOPs, mNSD) under different configurations: with/without DSFF, with/without depth-shift, and with different kernel sizes.  This helps understand the contribution of each component to the overall performance and efficiency of the model.", "section": "3.2 Ablation Studies"}, {"figure_path": "Xp8qhdmeb4/tables/tables_6_2.jpg", "caption": "Table 5: Quantitative comparisons of segmentation performance on the validation set of AMOS-CT dataset. * denotes the results with postprocessing.", "description": "This table compares the performance of different segmentation models on the AMOS-CT dataset, including the proposed E2ENet model. It shows the mDice score (a metric for evaluating segmentation accuracy), the number of model parameters (Params), the number of floating point operations (FLOPs) during inference, and the PT score (a composite metric considering accuracy and efficiency).  The results highlight that E2ENet achieves competitive performance while using significantly fewer parameters and FLOPs.", "section": "3.1 Comparison with SOTA methods"}, {"figure_path": "Xp8qhdmeb4/tables/tables_7_1.jpg", "caption": "Table 6: Evaluating the generalizability of E2ENet on the AMOS-MRI dataset. CT \u2192 MRI: pretrained on the CT dataset and fine-tuned on the MRI dataset; MRI: trained solely on the MRI dataset; CT+MRI: trained on both the CT and MRI datasets. Results for all models, except E2ENet and nnUNet (CT \u2192 MRI), are sourced from the AMOS website.", "description": "This table presents a comparison of the segmentation performance of different models on the AMOS-MRI dataset.  Three training strategies are compared: using a model pre-trained on the AMOS-CT dataset and then fine-tuned on the AMOS-MRI dataset; training a model solely on the AMOS-MRI dataset; and training a model on both the AMOS-CT and AMOS-MRI datasets.  The results demonstrate the generalizability of E2ENet and its performance compared to other state-of-the-art methods.", "section": "3.3 Generalizability Analysis"}, {"figure_path": "Xp8qhdmeb4/tables/tables_7_2.jpg", "caption": "Table 1: Quantitative comparisons of segmentation performance on the validation set of AMOS-CT dataset. * denotes the results with postprocessing.", "description": "This table compares the performance of E2ENet with other state-of-the-art methods on the AMOS-CT dataset.  The metrics used for comparison include mDice (mean Dice similarity coefficient), the number of model parameters (Params), floating point operations during inference (FLOPs), the Performance Trade-off score (PT score), and mean normalized surface dice (mNSD).  The table shows that E2ENet achieves competitive performance (mDice) with significantly fewer parameters and FLOPs, demonstrating its efficiency.", "section": "3 Experiments"}, {"figure_path": "Xp8qhdmeb4/tables/tables_8_1.jpg", "caption": "Table 8: A comparison under a similar FLOPs budget on the AMOS-CT challenge in two cases: when nnUNet is scaled down and when E2ENet is scaled up.", "description": "This table compares the performance of E2ENet and nnUNet models under similar FLOPs constraints.  To ensure a fair comparison, a smaller version of nnUNet (nnUNet(-)) and a larger version of E2ENet (E2ENet(+)) were created by adjusting the number of channels and feature scales, respectively.  The table shows that even with a reduction in parameters and FLOPs, E2ENet maintains comparable performance to nnUNet, demonstrating its efficiency in memory and computation.", "section": "3.4 Model Capacity Analysis"}, {"figure_path": "Xp8qhdmeb4/tables/tables_18_1.jpg", "caption": "Table 9: Comparison of inference speeds between E2ENet and nnUNet.", "description": "This table presents a comparison of the inference speed (latency and throughput) of E2ENet and nnUNet using an Intel Xeon Platinum 8360Y CPU with 18 cores.  Patches of images sized 32x32x32 were used as input for the comparison. The results demonstrate that E2ENet shows significant speedups compared to nnUNet.", "section": "3.1 Comparison with SOTA methods"}, {"figure_path": "Xp8qhdmeb4/tables/tables_18_2.jpg", "caption": "Table 1: Quantitative comparisons of segmentation performance on the validation set of AMOS-CT dataset. * denotes the results with postprocessing.", "description": "This table presents a quantitative comparison of the segmentation performance of various state-of-the-art (SOTA) methods on the AMOS-CT dataset's validation set.  The metrics used for comparison include mDice (mean Dice similarity coefficient), Params (model parameters in millions), FLOPs (floating point operations in billions), PT score (performance trade-off score, which combines accuracy and efficiency), and mNSD (mean normalized surface dice).  The asterisk (*) indicates that post-processing was applied to the results.  The table allows readers to compare the accuracy and efficiency of different methods, particularly highlighting E2ENet's performance in relation to others.", "section": "3 Experiments"}, {"figure_path": "Xp8qhdmeb4/tables/tables_19_1.jpg", "caption": "Table 11: Quantitative comparisons of segmentation performance on BTCV test set. Note: Spl: spleen, RKid: right kidney, LKid: left kidney, Gall: gallbladder, Eso: esophagus, Liv: liver, Sto: stomach, Aor: aorta IVC: inferior vena cava, Veins: portal and splenic veins, Pan: pancreas, AG: adrenal gland. The results (class-wise Dice and mDice) for these baselines are from [Hatamizadeh et al., 2022]. + denotes that the training of UNETR+ is without using any extra data outside the challenge. The results of nnUNet+, E2ENet and Hausdorff Distance (HD)\u2193 of UNETR are from the standard leaderboard of BTCV challenge, while the results of nnUNet are from the free leaderboard.", "description": "This table compares the performance of E2ENet against several baselines on the BTCV challenge dataset.  It shows class-wise Dice scores for various organs, as well as overall metrics like mDice, the number of parameters, FLOPS, a performance trade-off score, and Hausdorff distance. Note that some results are taken from the standard leaderboard and others from a free leaderboard, and that one method (UNETR+) was trained without external data, unlike others.", "section": "3.1 Comparison with SOTA methods"}]