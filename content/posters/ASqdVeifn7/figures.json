[{"figure_path": "ASqdVeifn7/figures/figures_1_1.jpg", "caption": "Figure 1: Visualization of test accuracies and total GPU memory costs of vision transformers. 4-bit Shampoo (naive) quantizes the preconditioner, while 4-bit Shampoo (our) quantizes its eigenvector matrix.", "description": "This figure visualizes the performance of different optimizers on two vision transformer models: Swin-Tiny on CIFAR-100 and ViT-Base/32 on ImageNet-1k.  It compares the test accuracy and GPU memory usage of AdamW, AdamW with 32-bit Shampoo, AdamW with a naive 4-bit Shampoo (quantizing the preconditioner), and AdamW with the proposed 4-bit Shampoo (quantizing the eigenvector matrix). The results show that the proposed 4-bit Shampoo achieves comparable accuracy to the 32-bit version while significantly reducing memory consumption.", "section": "1 Introduction"}, {"figure_path": "ASqdVeifn7/figures/figures_4_1.jpg", "caption": "Figure 2: Singular value distributions of PD matrices (real) and their 4-bit compressions (quan) used in Table 1 with R=DT, QM=A. Singular values are shown on a log10 scale.", "description": "This figure visualizes the singular value distributions of two positive definite (PD) matrices, one from real-world data (preconditioner from 32-bit Shampoo) and one synthetic.  It compares the distributions of the original 32-bit matrices to their 4-bit quantized counterparts (using dynamic tree (DT) quantization and quantizing the matrix itself).  The y-axis shows singular values on a logarithmic scale, highlighting how the quantization process affects the smaller singular values more drastically.", "section": "3.1 Quantizing the Eigenvector Matrices"}, {"figure_path": "ASqdVeifn7/figures/figures_4_2.jpg", "caption": "Figure 3: Elementwise mean errors between (VAVT)\u2212s(VAVT)s and identity matrix I. Mean errors are shown on a log10 scale.", "description": "This figure visualizes the element-wise mean errors between the result of applying the power operation (with exponent -s) to a matrix (VAVT) and its s-th power, and the identity matrix.  The graph plots these mean errors on a logarithmic scale (base 10), showing the error's behavior across various number of Bj\u00f6rck orthonormalization iterations (t2). Different lines on the graph represent different values of 's' (-1, -1/4, -1/10, -1/20), showcasing how these values affect the errors during the orthonormalization process.", "section": "3.2 Rectifying the Orthogonality of Eigenvector Matrices"}, {"figure_path": "ASqdVeifn7/figures/figures_7_1.jpg", "caption": "Figure 1: Visualization of test accuracies and total GPU memory costs of vision transformers. 4-bit Shampoo (naive) quantizes the preconditioner, while 4-bit Shampoo (our) quantizes its eigenvector matrix.", "description": "This figure visualizes the test accuracy and GPU memory consumption for vision transformer models.  Two versions of 4-bit Shampoo are compared: a naive approach that quantizes the entire preconditioner, and the authors' proposed method that quantizes only the eigenvector matrix.  The results show the impact of each quantization approach on model performance and memory efficiency, comparing them to the results of training with 32-bit Shampoo and AdamW.", "section": "1 Introduction"}, {"figure_path": "ASqdVeifn7/figures/figures_13_1.jpg", "caption": "Figure 5: Visualization of DT quantization and Linear-2 quantization at b-bit (b = 3, 4) precision.", "description": "This figure shows a comparison of two quantization methods, DT and Linear-2, at both 3-bit and 4-bit precisions.  Each graph plots the quantized value against the index.  The purpose is to visually demonstrate the difference in how these two methods map input values to discrete levels within the limited bit-depth. This directly relates to the quantization error and impact on model performance discussed in the paper, where the Linear-2 method is shown to be superior in many cases.", "section": "C Quantization Mappings"}, {"figure_path": "ASqdVeifn7/figures/figures_15_1.jpg", "caption": "Figure 6: 4-bit quantization errors in f(A) of quantizing U or A at A = UDiag(h(A))UT. We use linear square quantization and orthogonal rectification. The condition number cond(A) = Amax/Amin is around 37235, where Amax and Amin are the maximum and minimum singular values of A respectively. Contraction coefficients are shown on a log2 scale.", "description": "This figure visualizes the impact of quantizing either the eigenvector matrix (U) or the preconditioner matrix (A) on the resulting quantization errors.  The errors are measured using two metrics: normwise relative error and angle error, for both A<sup>-1/4</sup> and A<sup>-1/4</sup> - Diag(diag(A<sup>-1/4</sup>)).  The x-axis represents the contraction coefficient (\u03c4), which modifies the singular value distribution of A. The results demonstrate that quantizing the eigenvector matrix (U) leads to significantly lower quantization errors compared to quantizing the preconditioner matrix (A) itself, particularly for smaller singular values which greatly influence the A<sup>-1/4</sup> computation.  This validates the approach of quantizing U over A in 4-bit Shampoo.", "section": "D Quantization Error Analyses"}, {"figure_path": "ASqdVeifn7/figures/figures_16_1.jpg", "caption": "Figure 1: Visualization of test accuracies and total GPU memory costs of vision transformers. 4-bit Shampoo (naive) quantizes the preconditioner, while 4-bit Shampoo (our) quantizes its eigenvector matrix.", "description": "This figure visualizes the test accuracy and GPU memory consumption for vision transformers using different optimization methods.  Two versions of 4-bit Shampoo are compared: a naive approach that quantizes the preconditioner directly and the proposed method that quantizes the eigenvector matrix.  The results are shown for two different vision transformer models trained on two different datasets (CIFAR-100 and ImageNet-1k).  The figure highlights that the proposed 4-bit Shampoo approach achieves comparable accuracy to the 32-bit Shampoo while significantly reducing memory consumption.", "section": "1 Introduction"}, {"figure_path": "ASqdVeifn7/figures/figures_16_2.jpg", "caption": "Figure 1: Visualization of test accuracies and total GPU memory costs of vision transformers. 4-bit Shampoo (naive) quantizes the preconditioner, while 4-bit Shampoo (our) quantizes its eigenvector matrix.", "description": "The figure visualizes the performance of different optimizers on two vision transformer models: Swin-Tiny on CIFAR-100 and ViT-Base/32 on ImageNet-1k.  It compares the test accuracy and GPU memory usage of AdamW, AdamW+32-bit Shampoo, and two versions of AdamW+4-bit Shampoo.  One 4-bit Shampoo version naively quantizes the preconditioner, while the other (the authors' method) quantizes the eigenvector matrix. The results show that the authors' 4-bit Shampoo achieves comparable accuracy to the 32-bit version while significantly reducing memory consumption.", "section": "1 Introduction"}, {"figure_path": "ASqdVeifn7/figures/figures_24_1.jpg", "caption": "Figure 4: Visualization of test accuracies on the CIFAR-100 and ImageNet-1k datasets.", "description": "This figure visualizes the test accuracy over training time (epochs) for different models and optimizers on the CIFAR-100 and ImageNet-1k datasets.  It compares the performance of standard optimizers (SGDM, AdamW) against their counterparts combined with 32-bit and 4-bit Shampoo. The plots show that the 4-bit Shampoo versions maintain comparable performance to the 32-bit versions, often converging at a similar or slightly slower rate while offering significant memory savings. ", "section": "5 Experiments"}, {"figure_path": "ASqdVeifn7/figures/figures_25_1.jpg", "caption": "Figure 1: Visualization of test accuracies and total GPU memory costs of vision transformers. 4-bit Shampoo (naive) quantizes the preconditioner, while 4-bit Shampoo (our) quantizes its eigenvector matrix.", "description": "This figure visualizes the performance of different optimizers on two vision transformer models: Swin-Tiny on CIFAR-100 and ViT-Base/32 on ImageNet-1k.  It compares the test accuracy and GPU memory usage of AdamW, AdamW + 32-bit Shampoo, AdamW + a naive 4-bit Shampoo (quantizing the preconditioner), and AdamW + the proposed 4-bit Shampoo (quantizing the eigenvector matrix). The results show that the proposed 4-bit Shampoo achieves comparable accuracy to the 32-bit version while significantly reducing memory consumption.", "section": "1 Introduction"}]