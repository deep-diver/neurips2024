[{"figure_path": "motImXq3B1/figures/figures_3_1.jpg", "caption": "Figure 1: Schematic of P2C2Net for learning Navier-Stokes flows. (a), Overall model architecture. (b), Poisson block. (c), learnable PDE block. (d), NN block. (e), Poisson solver. (f), Symbol notations. (g), Conv filter with symmetric constraint.", "description": "This figure shows the architecture of the P2C2Net model for learning Navier-Stokes flows.  It's broken down into several blocks: the overall architecture (a), the Poisson block (b), the learnable PDE block (c), the NN block (d), the Poisson solver (e), symbol notations (f), and a convolution filter with symmetric constraints (g). Each block plays a crucial role in the process of efficiently predicting complex spatiotemporal dynamics, especially on coarse grids. The model uses a combination of classical numerical methods and learnable neural network components to achieve accuracy and efficiency in solving partial differential equations.", "section": "3.2 Network architecture"}, {"figure_path": "motImXq3B1/figures/figures_6_1.jpg", "caption": "Figure 3: An overview of the comparison between our P2C2Net and baseline models, including error distributions (left), error propagation curves (middle), and predicted solutions (right). (a)-(d) show the qualitative results on Burgers, GS, FN, and NS equations, respectively. These PDE systems are trained with grid sizes of 25\u00d725, 32\u00d732, 64\u00d764, and 64\u00d764 accordingly.", "description": "This figure presents a comparison of P2C2Net against several baseline models. The comparison includes four different partial differential equations (PDEs). For each PDE, the figure shows three plots: error distribution, error propagation curves, and snapshots of the predicted solutions. Error distribution shows the range of errors, error propagation shows how errors change over time, and snapshots show the visual representation of the predicted solutions. This figure aims to demonstrate the superiority of P2C2Net in terms of solution accuracy and generalization.", "section": "4.2 Main results"}, {"figure_path": "motImXq3B1/figures/figures_8_1.jpg", "caption": "Figure 4: Energy spectra.", "description": "This figure compares the energy spectra of the proposed P2C2Net model against several baseline models, including FNO, UNet, LI, and PeRCNN, and the ground truth. The x-axis represents the wavenumber k, and the y-axis represents the scaled energy spectrum E(k)k\u2075. The plot shows that the energy spectra of P2C2Net closely matches the ground truth across different wavenumbers.  The inset is a zoomed-in view of the lower wavenumber region to better show the differences among the models.", "section": "4.2 Main results"}, {"figure_path": "motImXq3B1/figures/figures_8_2.jpg", "caption": "Figure 3: An overview of the comparison between our P2C2Net and baseline models, including error distributions (left), error propagation curves (middle), and predicted solutions (right). (a)-(d) show the qualitative results on Burgers, GS, FN, and NS equations, respectively. These PDE systems are trained with grid sizes of 25\u00d725, 32\u00d732, 64\u00d764, and 64\u00d764 accordingly.", "description": "This figure presents a comparison of the proposed P2C2Net model against several baseline models across four different partial differential equation (PDE) systems.  The comparison is shown through visualizations of error distributions, error propagation curves, and example solution snapshots. Four PDE systems are used, each with different levels of complexity,  illustrating the performance of P2C2Net under varying conditions.", "section": "4.2 Main results"}, {"figure_path": "motImXq3B1/figures/figures_9_1.jpg", "caption": "Figure 6: Computational time for comparison.", "description": "This bar chart compares the inference time cost (in seconds) between a numerical solver and the proposed P2C2Net model across three different partial differential equations (PDEs): Gray-Scott (GS), FitzHugh-Nagumo (FN), and Navier-Stokes (NS).  For each PDE, the chart shows the time taken by the numerical solver and P2C2Net, highlighting the significant speedup achieved by P2C2Net. The speedup factors are explicitly indicated for each PDE.  This figure illustrates the computational efficiency gains of the P2C2Net method.", "section": "Conclusion"}, {"figure_path": "motImXq3B1/figures/figures_14_1.jpg", "caption": "Figure S1: The architecture of FNO Model", "description": "The figure illustrates the architecture of the Fourier Neural Operator (FNO) model.  The FNO model consists of three main components: a lift operation (P), a projection operation (Q), and L Fourier layers. The lift operation transforms the input into a higher-dimensional representation.  Each Fourier layer performs a Fast Fourier Transform (FFT), spectral filtering and convolution using R<sub>\u03b8</sub>, and an Inverse Fast Fourier Transform (iFFT), capturing both local and global features. The projection operation maps the output of the final Fourier layer back into the original data space. A linear transformation (W<sup>l</sup>) and activation function (\u03c3) are also included within each Fourier layer. The model is designed to handle inputs and outputs in the form of functions.", "section": "B.1 FNO Model"}, {"figure_path": "motImXq3B1/figures/figures_15_1.jpg", "caption": "Figure 1: Schematic of P2C2Net for learning Navier-Stokes flows. (a), Overall model architecture. (b), Poisson block. (c), learnable PDE block. (d), NN block. (e), Poisson solver. (f), Symbol notations. (g), Conv filter with symmetric constraint.", "description": "This figure shows the architecture of P2C2Net, a physics-encoded correction learning model for efficiently solving spatiotemporal PDE problems. It's composed of four main blocks: a state variable correction block, a learnable PDE block, a Poisson block, and a neural network (NN) block.  The figure details the data flow through these blocks, highlighting the learnable symmetric convolutional filter used for accurate spatial derivative estimation and the RK4 integration scheme for temporal evolution.  Subfigures (a)-(g) break down the overall architecture and individual components.", "section": "3.2 Network architecture"}, {"figure_path": "motImXq3B1/figures/figures_18_1.jpg", "caption": "Figure 3: An overview of the comparison between our P2C2Net and baseline models, including error distributions (left), error propagation curves (middle), and predicted solutions (right). (a)-(d) show the qualitative results on Burgers, GS, FN, and NS equations, respectively. These PDE systems are trained with grid sizes of 25\u00d725, 32\u00d732, 64\u00d764, and 64\u00d764 accordingly.", "description": "This figure compares the performance of P2C2Net against other baseline models across four different PDE systems.  It shows error distributions, error propagation curves, and example predictions for each model on the Burgers, Gray-Scott, FitzHugh-Nagumo, and Navier-Stokes equations. The training grid sizes varied depending on the equation. The results demonstrate P2C2Net's superior performance in terms of accuracy and stability.", "section": "4.2 Main results"}, {"figure_path": "motImXq3B1/figures/figures_21_1.jpg", "caption": "Figure 3: An overview of the comparison between our P2C2Net and baseline models, including error distributions (left), error propagation curves (middle), and predicted solutions (right). (a)-(d) show the qualitative results on Burgers, GS, FN, and NS equations, respectively. These PDE systems are trained with grid sizes of 25\u00d725, 32\u00d732, 64\u00d764, and 64\u00d764 accordingly.", "description": "This figure presents a comparison of P2C2Net against several baseline models on four different PDE systems (Burgers, Gray-Scott, FitzHugh-Nagumo, and Navier-Stokes).  For each PDE, it shows three subfigures: 1) Error Distribution: Illustrates the distribution of prediction errors, revealing the accuracy and robustness of each model. 2) Error Propagation: Plots the error propagation over time, providing insights into the stability and long-term prediction capability of the models. 3) Predicted Solutions: Visualizes the predicted solutions, comparing them qualitatively to the ground truth. The different subfigures (a-d) showcase the performance on varying PDE systems trained on different grid resolutions.", "section": "4.2 Main results"}]