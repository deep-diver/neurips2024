[{"figure_path": "motImXq3B1/tables/tables_5_1.jpg", "caption": "Table 1: Summary of datasets and training implementations. Note that \"\u2192\" denotes the downsampling process from the original resolution (simulation) to the low resolution (training).", "description": "This table summarizes the datasets used in the paper for training and testing the proposed model.  It shows the numerical method used to generate the data (FD for finite difference, FV for finite volume), the spatial and temporal grid resolutions (both original and downsampled for training), the number of training and testing trajectories, and the number of rollout steps for testing.  The datasets cover various complex PDE problems.", "section": "4.1 Setup"}, {"figure_path": "motImXq3B1/tables/tables_6_1.jpg", "caption": "Table 1: Summary of datasets and training implementations. Note that \"\u2192\" denotes the downsampling process from the original resolution (simulation) to the low resolution (training).", "description": "This table summarizes the datasets used in the paper's experiments.  It shows the numerical methods used to generate the data (FD for finite difference, FV for finite volume), the spatial and temporal grid resolutions (before and after downsampling), the number of training and testing trajectories, and the number of rollout steps in each testing trajectory.  The downsampling from higher resolution simulation data to lower resolution training data is indicated by the '\u2192' symbol.", "section": "4.1 Setup"}, {"figure_path": "motImXq3B1/tables/tables_7_1.jpg", "caption": "Table 2: Quantitative results of our model and baselines. For the case of Burgers, GS, and FN, our model inferred the test set's upper time limits of 1.4 s, 2000 s, and 10 s, respectively, as the trajectories of dynamics get stabilized. We take these limits in HCT to facilitate evaluation metrics calculation.", "description": "This table presents a quantitative comparison of the proposed P2C2Net model's performance against several baseline models across different PDE datasets (Burgers, GS, FN, NS).  The metrics used for comparison include RMSE, MAE, MNAD, and HCT (High Correction Time).  The HCT values for Burgers, GS, and FN reflect the point where the dynamics stabilize.  The \"Promotion\" row indicates the percentage improvement achieved by P2C2Net over the best-performing baseline model for each metric.", "section": "4.2 Main results"}, {"figure_path": "motImXq3B1/tables/tables_9_1.jpg", "caption": "Table 3: Results for the ablation study of P2C2Net.", "description": "This table presents a quantitative analysis of the ablation study conducted on the P2C2Net model for the Burgers equation. Five different models were evaluated: Model 1 (replacing symmetric convolutions with regular convolutions), Model 2 (using convolution kernels with finite difference stencils), Model 3 (removing the Correction Block), Model 4 (substituting RK4 integration with first-order Euler methods), and the full P2C2Net architecture.  The performance of each model is assessed using four metrics: RMSE, MAE, MNAD, and HCT. The results clearly demonstrate the importance of the symmetric convolutional filter, the correction block, and the high-order RK4 integration scheme for achieving high accuracy in solving the Burgers equation.", "section": "4.2 Main results"}, {"figure_path": "motImXq3B1/tables/tables_19_1.jpg", "caption": "Table S1: Impact of different kernel sizes.", "description": "This table presents the ablation study results on the impact of different kernel sizes (3x3, 5x5, and 7x7) used in the learnable symmetric convolution filter within the P2C2Net model. The results are evaluated using four metrics: RMSE, MAE, MNAD, and HCT on the Burgers dataset. The 5x5 kernel shows significantly better performance compared to others, highlighting the impact of kernel size selection on the model's accuracy and efficiency.", "section": "4.2 Main results"}, {"figure_path": "motImXq3B1/tables/tables_19_2.jpg", "caption": "Table 1: Summary of datasets and training implementations. Note that \u201c\u2192\u201d denotes the downsampling process from the original resolution (simulation) to the low resolution (training).", "description": "This table summarizes the datasets used in the paper's experiments, including the numerical methods used to generate the data (FD for finite difference, FV for finite volume), the spatial and temporal grid resolutions, the number of training and testing trajectories, and the number of rollout steps for each dataset.  It also shows how the high-resolution simulation data was downsampled to create the lower-resolution training data used in the experiments. The table highlights the varying complexities of the datasets and training setups.", "section": "4.1 Setup"}, {"figure_path": "motImXq3B1/tables/tables_20_1.jpg", "caption": "Table S3: Impact of noise on P<sup>2</sup>C<sup>2</sup>Net performance", "description": "This table shows the impact of adding Gaussian noise to the training data on the performance of the P<sup>2</sup>C<sup>2</sup>Net model. The results are presented in terms of RMSE, MAE, MNAD, and HCT.  The table compares the performance metrics when 1% noise is added, when 0.5% noise is added, and when no noise is added.", "section": "4.2 Main results"}, {"figure_path": "motImXq3B1/tables/tables_20_2.jpg", "caption": "Table S4: Impact of sparser Burgers dataset on P2C2Net performance", "description": "This table presents the results of an ablation study conducted on the Burgers equation to evaluate the impact of reducing the training data size.  It compares the model's performance (RMSE, MAE, MNAD, and HCT) when trained with a reduced dataset (20% reduction) against the performance when trained with the original dataset (5 trajectories with 400 snapshots each). The results demonstrate the robustness of the P2C2Net model even with a significant reduction in training data.", "section": "4.2 Main results"}, {"figure_path": "motImXq3B1/tables/tables_21_1.jpg", "caption": "Table S5: Generalization of P2C2Net over different boundaries on the Burgers example for 10 trajectories.", "description": "This table presents a comparison of the P2C2Net model's performance using two different types of boundary conditions: 'Complex' and 'Periodic'.  For each condition, the table shows the Root Mean Square Error (RMSE), Mean Absolute Error (MAE), Mean Normalized Absolute Difference (MNAD), and High Correction Time (HCT).  The results demonstrate the model's ability to generalize to different boundary conditions, achieving similar levels of accuracy in both cases.", "section": "G.1 Applicability to different BCs"}]