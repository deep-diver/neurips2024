[{"figure_path": "XErWgdxaFU/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of our proposed method. Task embeddings define the task to be performed. For example, in the case of hateful image detection, hate speeches would serve as task embeddings, while in OOD detection, the names of classes from the training distribution would be the task embeddings. Trainable embeddings are the only parameters that are trained in our method, defined in the joint embedding space. During the training phase, only textual data are used, and in the testing phase, these trained parameters are employed to classify images. Detailed explanations are provided in Sections 3.", "description": "This figure illustrates the Hassle-Free Textual Training (HFTT) method.  The training phase uses only textual data and a pre-trained vision-language model (VLM) to train trainable embeddings.  These embeddings are then used in the test phase to classify images based on cosine similarity to task embeddings (which define the specific task, e.g., hateful image detection or OOD detection).", "section": "3 Method"}, {"figure_path": "XErWgdxaFU/figures/figures_2_1.jpg", "caption": "Figure 1: Overview of our proposed method. Task embeddings define the task to be performed. For example, in the case of hateful image detection, hate speeches would serve as task embeddings, while in OOD detection, the names of classes from the training distribution would be the task embeddings. Trainable embeddings are the only parameters that are trained in our method, defined in the joint embedding space. During the training phase, only textual data are used, and in the testing phase, these trained parameters are employed to classify images. Detailed explanations are provided in Sections 3.", "description": "This figure illustrates the proposed Hassle-Free Textual Training (HFTT) method.  It shows the training and testing phases.  In the training phase, only textual data (text corpus) and a text encoder are used to generate task embeddings and trainable embeddings.  The testing phase uses these trained embeddings along with an image encoder to classify images based on cosine similarity.  Different tasks are represented by different task embeddings; for example, hateful image detection uses hate speeches as embeddings while out-of-distribution (OOD) detection uses class names from the training set.", "section": "3 Method"}, {"figure_path": "XErWgdxaFU/figures/figures_7_1.jpg", "caption": "Figure 3: UMAP [35] visualization of the joint embedding space of CLIP. The dispersed, transparent markers represent the OOD data samples used in our experiment (iNaturalist: brown; SUN: grey; Places: pink; Texture: purple; NINCO [3]: red). The trained embeddings (blue stars) are located in a sub-region of the embedding space occupied by OOD data. We trained 2000 embeddings for this plot. It is important to note that these trainable embeddings did not incorporate any information about the OOD data during their training time.", "description": "This UMAP visualization shows the joint embedding space of CLIP.  Different colors represent different OOD datasets.  The blue stars are the trained embeddings from the HFTT method, which are clustered in a region of the embedding space that overlaps with the OOD data, demonstrating that despite not using any visual OOD data during training, the model learned to separate in-distribution and out-of-distribution data.", "section": "4.2 Out-of-Distribution Detection"}]