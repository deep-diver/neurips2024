[{"figure_path": "dB6gwSDXKL/figures/figures_3_1.jpg", "caption": "Figure 1: The ICL output h'N+1 of one softmax attention layer is equivalent to the test prediction \u0177test of its trained dual model f(x) = W(x). The training data and test input can be obtained by linear transformations of demonstration and query tokens, respectively.", "description": "This figure illustrates the equivalence between the in-context learning (ICL) process of a single softmax attention layer and the gradient descent process of its dual model.  The ICL process generates a prediction (h'N+1) for a query token based on example input tokens. This prediction is shown to be equivalent to the test prediction (\u0177test) of a dual model trained on data derived from the example and query tokens.  The figure highlights how the training data for the dual model is created by linear transformations of the input tokens and how backpropagation signals contribute to the final prediction, showing the relationship between ICL and representation learning.", "section": "Connecting ICL with Gradient Descent"}, {"figure_path": "dB6gwSDXKL/figures/figures_5_1.jpg", "caption": "Figure 2: Left Part: The representation learning process for the ICL inference by one attention layer. Remaining Part: Comparison of the ICL Representation Learning Process (Center Left), Contrastive Learning without Negative Samples (Center Right), and Contrastive Kernel Learning (Right).", "description": "The figure compares three representation learning processes. The left part shows how the ICL process in a softmax attention layer can be interpreted as a representation learning problem, where the key and value mappings generate positive sample pairs. The center-left part shows this ICL process aligns with contrastive learning without negative samples. The center-right part shows the ICL process aligns with contrastive kernel learning. ", "section": "Connecting ICL with Gradient Descent"}, {"figure_path": "dB6gwSDXKL/figures/figures_7_1.jpg", "caption": "Figure 3: The equivalence between ICL of one softmax attention layer and gradient descent, along with analysis on different model modifications. Left Part: ||\u0177test - h'T+1||2 as the gradient descent proceeds under setting N = 15; Remaining Part: the performance for regularized models (Center Left), augmented models (Center Right) and negative models (Right) with different settings.", "description": "This figure demonstrates the equivalence between the in-context learning (ICL) process of a single softmax attention layer and the gradient descent process on its dual model. The left panel shows the convergence of the ICL prediction (h'N+1) to the dual model's prediction (\u0177test). The right panel compares the performance of three model modifications: regularized models (adjusting the attention weight norm), augmented models (modifying data input using nonlinear mappings), and negative models (introducing negative samples). The results across different settings are presented.", "section": "Experiments"}, {"figure_path": "dB6gwSDXKL/figures/figures_17_1.jpg", "caption": "Figure 4: The representation learning process for the ICL inference by one Transformer layer.", "description": "This figure illustrates the representation learning process of In-context Learning (ICL) inference through a single Transformer layer from the perspective of representation learning.  The left panel depicts the process showing the key and value mappings by matrices WK and Wv, respectively. The intermediate representation obtained after softmax attention is passed through a feed-forward network (FFN), represented by matrices W1 and W2. The resulting output, h'T+1, is equivalent to the result of a gradient descent step on a dual model.  The right panel shows this process in a higher-dimensional space where the key and value vectors are projected into a higher dimensional space through function \u03d5. The weight matrix W is then trained to minimize the distance between the two projected vectors, approximating the ICL inference process.", "section": "Connecting ICL with Gradient Descent"}, {"figure_path": "dB6gwSDXKL/figures/figures_18_1.jpg", "caption": "Figure 5: Illustrating the ICL inference process of multiple softmax attention layers from the perspective of dual models. The layer-wise process of ICL can be viewed as a gradual gradient descent on the dual model sequence. The datasets used for each gradient descent, including training data and test input, are obtained from the outputs of the previous dual model before and after training.", "description": "This figure illustrates the in-context learning (ICL) inference process through multiple softmax attention layers, showing how it aligns with the gradient descent on a sequence of dual models. Each layer's ICL inference is analogous to one gradient descent step on its corresponding dual model.  The dual models use training data derived from the previous layer's output, making the overall process a sequential gradient descent.", "section": "Connecting ICL with Gradient Descent"}, {"figure_path": "dB6gwSDXKL/figures/figures_26_1.jpg", "caption": "Figure 6: The estimation of the attention matrix by positive random features when varying d<sub>r</sub>", "description": "This figure visualizes how well positive random features can approximate the attention matrix in a Transformer model.  It shows heatmaps of the attention matrix for different values of d<sub>r</sub> (the dimension of the random features). The (e) subfigure presents the exact attention matrix, providing a ground truth for comparison.  The other subfigures show how closely the approximated matrices match the exact attention matrix as the dimension d<sub>r</sub> increases.  This helps to illustrate the quality of approximation.", "section": "4 Attention Modification Inspired by the Representation Learning Lens"}, {"figure_path": "dB6gwSDXKL/figures/figures_26_2.jpg", "caption": "Figure 3: The equivalence between ICL of one softmax attention layer and gradient descent, along with analysis on different model modifications. Left Part: ||\u0177test - h'T+1||2 as the gradient descent proceeds under setting N = 15; Remaining Part: the performance for regularized models (Center Left), augmented models (Center Right) and negative models (Right) with different settings.", "description": "This figure demonstrates the equivalence between the in-context learning (ICL) process of a single softmax attention layer and the gradient descent process on its dual model. The left part shows how the L2 norm of the difference between the ICL output (h'N+1) and the dual model's test prediction (\u0177test) decreases as the gradient descent on the dual model progresses (over 15 steps). The right part compares the performance of three types of modified models (regularized, augmented, and negative) with different parameter settings, illustrating their impact on the ICL process.", "section": "Experiments"}, {"figure_path": "dB6gwSDXKL/figures/figures_27_1.jpg", "caption": "Figure 8: The error of positive random features in estimating the attention and output matrices as dr varies.", "description": "This figure shows two sub-figures. The left sub-figure shows the Mean Squared Error (MSE) and Mean Absolute Error (MAE) in estimating the attention matrix when varying the dimension of random features (dr). The right sub-figure shows the MSE and MAE in estimating the output matrix when varying dr.  Both sub-figures show that as the dimension of random features increases, the approximation performance gradually improves, with both errors reaching a low level in the end.", "section": "4 Attention Modification Inspired by the Representation Learning Lens"}, {"figure_path": "dB6gwSDXKL/figures/figures_27_2.jpg", "caption": "Figure 8: The error of positive random features in estimating the attention and output matrices as dr varies.", "description": "This figure shows two line graphs plotting the Mean Squared Error (MSE) and Mean Absolute Error (MAE) against different values of the dimension of random features (dr).  The errors represent how well the positive random features approximate the attention matrix and the output matrix within the Transformer model's attention mechanism. The results demonstrate that as dr increases, the approximation accuracy improves, with both MSE and MAE decreasing. This finding is important because it shows that the positive random features method, used to simplify the analysis, is effective in approximating the more complex softmax attention.", "section": "4 Attention Modification Inspired by the Representation Learning Lens"}, {"figure_path": "dB6gwSDXKL/figures/figures_27_3.jpg", "caption": "Figure 3: The equivalence between ICL of one softmax attention layer and gradient descent, along with analysis on different model modifications. Left Part: ||\u0177test - h'T+1||2 as the gradient descent proceeds under setting N = 15; Remaining Part: the performance for regularized models (Center Left), augmented models (Center Right) and negative models (Right) with different settings.", "description": "This figure shows the experimental results supporting the paper's claim that the in-context learning (ICL) process in a single softmax attention layer is equivalent to a gradient descent process on its dual model. The left part shows the convergence of the test prediction of the dual model (\u0177test) to the ICL output (h'T+1) across gradient descent steps. The right part compares the performance of different model modifications (regularized, augmented, and negative models) demonstrating how these modifications affect the ICL process and their effectiveness.", "section": "Experiments"}, {"figure_path": "dB6gwSDXKL/figures/figures_27_4.jpg", "caption": "Figure 3: The equivalence between ICL of one softmax attention layer and gradient descent, along with analysis on different model modifications. Left Part: ||\u0177test - hT+1||2 as the gradient descent proceeds under setting N = 15; Remaining Part: the performance for regularized models (Center Left), augmented models (Center Right) and negative models (Right) with different settings.", "description": "This figure shows the results of experiments designed to demonstrate the equivalence between the in-context learning (ICL) process of a softmax attention layer and the gradient descent process of its dual model.  The left panel shows the squared difference between the ICL output and the dual model's prediction (||\u0177test - h'T+1||2) as the gradient descent progresses. The right panel displays the performance of three different model modifications (regularized, augmented, negative) under various hyperparameter settings. Each modification aims to improve the attention mechanism by drawing inspiration from representation learning techniques. This comparison provides evidence supporting the proposed dual model theory and the effectiveness of the modifications.", "section": "Experiments"}, {"figure_path": "dB6gwSDXKL/figures/figures_28_1.jpg", "caption": "Figure 3: The equivalence between ICL of one softmax attention layer and gradient descent, along with analysis on different model modifications. Left Part: ||\u0177test - h'T+1||2 as the gradient descent proceeds under setting N = 15; Remaining Part: the performance for regularized models (Center Left), augmented models (Center Right) and negative models (Right) with different settings.", "description": "This figure demonstrates the equivalence between the in-context learning (ICL) process of a softmax attention layer and the gradient descent process of its dual model. The left part shows the convergence of the L2 norm of the difference between the ICL output and the dual model prediction as the gradient descent progresses. The right part compares the performance of three modified models (regularized, augmented, and negative) with different settings, illustrating the effects of these modifications on the ICL process.", "section": "Experiments"}, {"figure_path": "dB6gwSDXKL/figures/figures_29_1.jpg", "caption": "Figure 3: The equivalence between ICL of one softmax attention layer and gradient descent, along with analysis on different model modifications. Left Part: ||\u0177test - h'T+1||2 as the gradient descent proceeds under setting N = 15; Remaining Part: the performance for regularized models (Center Left), augmented models (Center Right) and negative models (Right) with different settings.", "description": "This figure shows the results of an experiment designed to demonstrate the equivalence between in-context learning (ICL) in a single softmax attention layer and a gradient descent process on its dual model.  The left panel shows how the difference between the ICL output and the prediction from the trained dual model decreases as the number of gradient descent steps increases. The other three panels show how different modifications to the attention mechanism (regularized, augmented, and negative models) impact its performance. Each panel shows curves for various hyperparameter settings for the modifications. This demonstrates that the ICL process can be understood and potentially improved using the lens of representation learning and gradient descent.", "section": "Experiments"}, {"figure_path": "dB6gwSDXKL/figures/figures_29_2.jpg", "caption": "Figure 3: The equivalence between ICL of one softmax attention layer and gradient descent, along with analysis on different model modifications. Left Part: ||\u0177test - h'T+1||2 as the gradient descent proceeds under setting N = 15; Remaining Part: the performance for regularized models (Center Left), augmented models (Center Right) and negative models (Right) with different settings.", "description": "This figure shows the equivalence between the in-context learning (ICL) process of a softmax attention layer and the gradient descent process of its dual model.  The left part shows how the difference between the ICL output (h'N+1) and the dual model's test prediction (\u0177test) decreases as the gradient descent progresses. The right part compares the performance of three model modifications (regularized, augmented, and negative models) under different settings, illustrating the impact of these modifications on the ICL process.", "section": "Experiments"}, {"figure_path": "dB6gwSDXKL/figures/figures_30_1.jpg", "caption": "Figure 3: The equivalence between ICL of one softmax attention layer and gradient descent, along with analysis on different model modifications. Left Part: ||\u0177test - h'T+1||2 as the gradient descent proceeds under setting N = 15; Remaining Part: the performance for regularized models (Center Left), augmented models (Center Right) and negative models (Right) with different settings.", "description": "This figure shows the equivalence between the in-context learning (ICL) process of a single softmax attention layer and the gradient descent process of its dual model. The left part of the figure shows how the difference between the ICL output (h'N+1) and the test prediction of the dual model (\u0177test) decreases as the number of gradient descent steps increases. The right part compares the performance of three different model modifications: regularized models, augmented models, and negative models, under different settings. The results demonstrate the effectiveness of the proposed modifications.", "section": "Experiments"}]