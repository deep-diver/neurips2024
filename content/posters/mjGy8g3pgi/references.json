{"references": [{"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2023", "reason": "This paper introduces the LLaVA model, which is the foundation upon which the current work is built, making it a crucial reference for understanding the context and basis of the research."}, {"fullname_first_author": "Christoph Schuhmann", "paper_title": "Laion-400m: Open dataset of clip-filtered 400 million image-text pairs", "publication_date": "2021", "reason": "This paper provides the LAION-400M dataset, a significant resource utilized for training and evaluation, thus representing a key element of the research methodology."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Improved baselines with visual instruction tuning", "publication_date": "2023", "reason": "This work details the LLaVA-1.5-13B model, a crucial component for YoLLaVA, offering a more detailed and refined architecture compared to the original LLaVA model."}, {"fullname_first_author": "Rinon Gal", "paper_title": "An image is worth one word: Personalizing text-to-image generation using textual inversion", "publication_date": "2022", "reason": "This paper explores the concept of personalizing text-to-image generation, providing valuable insights and related work for the task of personalizing LLMs, which shares a similar goal."}, {"fullname_first_author": "Edward J Hu", "paper_title": "LoRA: Low-rank adaptation of large language models", "publication_date": "2022", "reason": "This paper introduces the LoRA method, which is a parameter-efficient fine-tuning technique that is relevant to the current work's approach of efficiently personalizing LLMs without substantial changes to the pre-trained weights."}]}