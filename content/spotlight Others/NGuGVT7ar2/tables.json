[{"figure_path": "NGuGVT7ar2/tables/tables_5_1.jpg", "caption": "Table 1: Intersection Point Result", "description": "This table presents the accuracy results of different methods on a geometry intersection counting task.  The methods compared include standard prompting, chain-of-thought prompting, self-consistent chain-of-thought prompting with varying sample sizes (k=5, 10, 20), task-specific baselines Inter-GPS and G-LLaVA, and the proposed Vision-Augmented Prompting (VAP) method.  The accuracy is expressed as a percentage, indicating the success rate of each method in correctly determining the number of intersection points in the geometry problems.", "section": "4.1 Task 1: Geometry Intersection Counting"}, {"figure_path": "NGuGVT7ar2/tables/tables_7_1.jpg", "caption": "Table 3: TSP task performance.", "description": "This table presents the performance of different methods on the Traveling Salesman Problem (TSP) with 10 and 20 cities.  It compares traditional TSP solvers (Gurobi, Random, Nearest Neighbor, and Fastest Insertion) against LLM-based approaches (Standard Prompting, Chain-of-Thought, CoT with Self-Consistency, and Vision-Augmented Prompting). The metrics used for comparison are the average path length and the optimality gap (percentage difference from the optimal solution). The results show that VAP outperforms other LLM-based methods, achieving a smaller optimality gap, particularly when the number of cities increases.", "section": "4 Experiments"}, {"figure_path": "NGuGVT7ar2/tables/tables_8_1.jpg", "caption": "Table 4: Performance of Drawing Module.", "description": "This table presents the integrity of images synthesized by the Vision-Augmented Prompting (VAP) framework across four different tasks: Geometry Intersection Counting, Sudoku Puzzle, Time Series Prediction, and Travelling Salesman Problem.  The \"Integrity\" column shows the percentage of successfully generated images that correctly represent the described problem. The \"With Ground Truth Image\" column shows the percentage improvement in accuracy when the ground truth image is used instead of the VAP-generated image.  This demonstrates the impact of image accuracy on the overall performance of the VAP framework.", "section": "4 Experiments"}, {"figure_path": "NGuGVT7ar2/tables/tables_8_2.jpg", "caption": "Table 6: Ablation study results. Each column represents a task and the cell indicates the performance when removing a module in VAP.", "description": "This table presents the results of an ablation study conducted to evaluate the impact of each component (high-level planning, iterative reasoning, and self-alignment) of the Vision-Augmented Prompting (VAP) framework on four different reasoning tasks: Geometry Intersection Counting, Sudoku Puzzle, Time Series Prediction, and Travelling Salesman Problem.  The results show the performance of the full VAP model and the performance when each component is removed.  It helps to understand the contribution of each module to the overall performance of the VAP system.", "section": "5 Ablation Study"}, {"figure_path": "NGuGVT7ar2/tables/tables_17_1.jpg", "caption": "Table 7: Efficiency and Accuracy Comparison", "description": "This table presents a comparison of the time usage and accuracy of various methods across geometry and Sudoku tasks.  It shows that while VAP has a higher time usage than some baselines, it significantly improves accuracy in both tasks.  The table highlights the trade-off between computational cost and accuracy.", "section": "4.4.1 Effiency of VAP"}, {"figure_path": "NGuGVT7ar2/tables/tables_17_2.jpg", "caption": "Table 8: Performance on Geometry Task over Different Foundational Models", "description": "This table compares the accuracy of different reasoning methods (Standard, CoT, CoT-SC, VAP) on a geometry intersection counting task using three different foundational LLMs (GPT-4v, GPT-4, LLaMA 3).  It shows that VAP consistently outperforms other methods across all three LLMs.", "section": "4.4 Task 1: Geometry Intersection Counting"}]