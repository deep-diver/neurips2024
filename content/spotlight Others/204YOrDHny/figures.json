[{"figure_path": "204YOrDHny/figures/figures_1_1.jpg", "caption": "Figure 1: The weight space of a neural network (Eq. 1) overparametrizes the associated function space. This induces families (orange) of weights corresponding to the same functions. Model linearization (left) linearizes these families. In nonlinear models, Gaussian weight distributions (center) do not adapt to the families, while our geometric diffusion (right) captures the associated invariance with a metric (gray ellipses).", "description": "This figure shows how the weight space of a neural network overparametrizes the function space, leading to families of weights corresponding to identical functions.  The left panel illustrates how model linearization addresses this issue by linearizing these families.  The center panel demonstrates how standard Gaussian weight distributions fail to capture this invariance in nonlinear models. Finally, the right panel showcases how the proposed geometric diffusion method effectively accounts for this invariance by adapting its metric to the families of weights.", "section": "3 Reparameterizations of linear functions"}, {"figure_path": "204YOrDHny/figures/figures_1_2.jpg", "caption": "Figure 2: The function space is decomposed into directions of reparameterizations (kernel) and functional change (non-kernel). We improve the posterior fit by concentrating probability mass on directions of functional change.", "description": "This figure shows the decomposition of the function space into two subspaces: the kernel subspace, representing reparameterizations, and the non-kernel subspace, representing functional changes. The Laplace approximation (top left) underfits because it assigns significant probability mass to the kernel subspace. Linearizing the Laplace approximation (top middle) helps to reduce the underfitting. The Laplace diffusion method (top right) further improves the fit by concentrating the probability mass on the non-kernel subspace. The bottom row shows the kernel and non-kernel contributions separately for each of the three methods.", "section": "Reparameterizations of linear functions"}, {"figure_path": "204YOrDHny/figures/figures_3_1.jpg", "caption": "Figure 1: The weight space of a neural network (Eq. 1) overparametrizes the associated function space. This induces families (orange) of weights corresponding to the same functions. Model linearization (left) linearizes these families. In nonlinear models, Gaussian weight distributions (center) do not adapt to the families, while our geometric diffusion (right) captures the associated invariance with a metric (gray ellipses).", "description": "This figure illustrates the concept of reparameterization invariance in the context of neural networks.  The left panel shows that linearizing a neural network collapses families of weights that represent the same function into a single point. The center panel demonstrates that a standard Gaussian distribution over weights fails to capture the redundancy inherent in the overparameterization.  The right panel shows that a novel Riemannian diffusion method proposed in this paper addresses this issue by adapting the distribution over weights to the geometry of the function space, better capturing the equivalence between different sets of weights representing the same function.", "section": "3 Reparameterizations of linear functions"}, {"figure_path": "204YOrDHny/figures/figures_3_2.jpg", "caption": "Figure 4: Underfitting of sampled Laplace is less pronounced when the rank of the GGN is higher for a fixed number of parameters. This is consistent with our hypothesis as a high GGN rank implies a lower dimensional kernel.", "description": "The figure shows the training accuracy for different methods (Laplace Diffusion, Linearised Laplace, and Sampled Laplace) plotted against the rank of the Generalized Gauss-Newton (GGN) matrix.  As the rank of the GGN increases (meaning there are fewer redundant parameters), the underfitting problem observed in Sampled Laplace decreases, while Laplace Diffusion shows consistently high accuracy. This supports the paper's hypothesis that underfitting in Sampled Laplace is due to insufficient handling of reparameterizations, which are linked to the kernel (null space) of the GGN. A higher rank GGN signifies a smaller kernel, leading to less underfitting.", "section": "Underfitting in sampled Laplace"}, {"figure_path": "204YOrDHny/figures/figures_8_1.jpg", "caption": "Figure 5: Benchmark results for Rotated MNIST (similar results for FMNIST and CIFAR are in appendix E.3.2). Sampled Laplace significantly underfits even for non-rotated data. Laplace diffusion consistently outperforms the other methods.", "description": "This figure presents benchmark results for Rotated MNIST, comparing the performance of Laplace Diffusion, Sampled Laplace, and Linearised Laplace.  It shows that Sampled Laplace severely underfits, even without rotation, while Laplace Diffusion consistently outperforms the other methods across various metrics (NLL, ECE, Accuracy).  The results for FMNIST and CIFAR-10 datasets are detailed further in Appendix E.3.2.", "section": "Experiments"}, {"figure_path": "204YOrDHny/figures/figures_19_1.jpg", "caption": "Figure 6: Eigenvalues of the GGN of a Convolutional Neural Network trained on MNIST.", "description": "The figure shows the eigenvalues of the Generalized Gauss-Newton (GGN) matrix for a convolutional neural network trained on the MNIST dataset. The eigenvalues are plotted against their index, demonstrating a rapid decay in magnitude.  This indicates that a significant portion of the GGN's information is concentrated in a small number of principal components, suggesting the possibility of low-rank approximations of the GGN for computational efficiency.", "section": "E.1 Implementation details of the Laplace approximation"}, {"figure_path": "204YOrDHny/figures/figures_21_1.jpg", "caption": "Figure 7: Decomposition of uncertainties of Laplace Approximation for the Gaussian mixture classification.", "description": "This figure shows a comparison of uncertainty estimations from three different Bayesian approximation methods: Sampled Laplace, Linearized Laplace, and Laplace Diffusion. Each method is evaluated based on its full uncertainty, kernel uncertainty, and non-kernel uncertainty.  The results are visualized as contour plots, showing how the different methods capture uncertainty in the input space of a Gaussian mixture classification problem. The black dots represent data points from the Gaussian mixture, and the color gradients illustrate the magnitude of uncertainty. The figure helps to explain how the Laplace approximation methods suffer from an underfitting issue, particularly in the non-kernel direction. The Laplace diffusion method is shown to provide a more accurate representation of uncertainty, particularly by capturing the uncertainty in the non-kernel direction more accurately. This underfitting issue in the other approaches is attributed to their insufficient handling of reparameterizations.", "section": "Experiments"}, {"figure_path": "204YOrDHny/figures/figures_23_1.jpg", "caption": "Figure 1: The weight space of a neural network (Eq. 1) overparametrizes the associated function space. This induces families (orange) of weights corresponding to the same functions. Model linearization (left) linearizes these families. In nonlinear models, Gaussian weight distributions (center) do not adapt to the families, while our geometric diffusion (right) captures the associated invariance with a metric (gray ellipses).", "description": "This figure illustrates how the weight space of a neural network overparameterizes the function space.  In the linear case (left), model linearization effectively linearizes families of weights corresponding to the same function. However, for non-linear models (center, right), the Gaussian weight distributions don't adapt well to these families. The paper's proposed geometric diffusion method (right) addresses this issue by incorporating the geometry of the parameter space, thus achieving reparameterization invariance as depicted by the gray ellipses.", "section": "3 Reparameterizations of linear functions"}, {"figure_path": "204YOrDHny/figures/figures_24_1.jpg", "caption": "Figure 1: The weight space of a neural network (Eq. 1) overparametrizes the associated function space. This induces families (orange) of weights corresponding to the same functions. Model linearization (left) linearizes these families. In nonlinear models, Gaussian weight distributions (center) do not adapt to the families, while our geometric diffusion (right) captures the associated invariance with a metric (gray ellipses).", "description": "This figure illustrates the concept of reparameterization invariance in the context of Bayesian neural networks.  The left panel shows how linearizing a model simplifies the weight space, making different weight settings that represent the same function collapse into single points. The center panel demonstrates how a standard Gaussian distribution in weight space (nonlinear model) fails to capture this invariance, resulting in assigning different posterior densities to different parametrizations of the same function.  The right panel shows how the proposed Riemannian diffusion method correctly adapts to this geometry, exhibiting invariance to reparameterizations, and resulting in a posterior that reflects uncertainty over functions rather than parameters.", "section": "Reparameterizations of linear functions"}]