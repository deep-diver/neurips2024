[{"figure_path": "kMxdV4Blhn/figures/figures_1_1.jpg", "caption": "Figure 1: (a) Visualizing the circles of lp-norms. (b) Manhattan distance based l\u2081-norm measure.", "description": "Figure 1(a) shows a visualization of the unit circles for different lp-norms (l1, l2, l3, and l\u221e).  It illustrates how the shape of the unit circle changes as the value of p changes, reflecting the different ways these norms measure distance. Figure 1(b) provides a visual explanation of the Manhattan distance (l1-norm), showing how it calculates distance along the grid lines rather than the straight-line distance used in the Euclidean norm (l2-norm).  The figures highlight the differences in how these norms treat distances and thus the diverse properties they offer in feature extraction and network training.", "section": "Abstract"}, {"figure_path": "kMxdV4Blhn/figures/figures_3_1.jpg", "caption": "Figure 2: (Left) The distribution of ||G||p,where G is the standard Gaussian vector, p = 1,2,3,\u221e and dim(G) = 9. (Right) The distribution of ||G||p, p = 3,4,5,6,7,8,9,\u221e and dim(G) = 9.", "description": "This figure visualizes the distribution of the lp-norm (||G||p) of a standard Gaussian vector G for different values of p.  The left panel shows the distributions for p=1, 2, 3, and infinity, while the right panel focuses on p=3 to infinity, showing how the distribution changes as p increases.  The dimension of the Gaussian vector G is 9 in both cases. This figure illustrates the impact of different lp-norms on the distribution of data, providing insights into their properties and behavior.", "section": "3.3 Implementation of lp-norm Nets"}, {"figure_path": "kMxdV4Blhn/figures/figures_5_1.jpg", "caption": "Figure 3: The gradient of weight in each layer using two different networks at 1st iteration. Layer I to III represent 3 SetAbstractions modules in l\u2081-PointNet++ and layer IV to V represent fully connected layers. Note that the y-axis is on a logarithmic scale to reflect the magnitude of the values.", "description": "This figure compares the gradient magnitude of weights in each layer of the l\u2081-PointNet++ and the standard PointNet++ at the first iteration. The y-axis is in log scale, and it shows that the gradients from l\u2081-PointNet++ are much smaller than those from PointNet++.  This difference in gradient magnitude is a key motivation for introducing the mixed gradient strategy (MGS) in the paper.", "section": "4.1 MGS: Mixed Gradient Strategy"}]