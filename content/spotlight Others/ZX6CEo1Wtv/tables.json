[{"figure_path": "ZX6CEo1Wtv/tables/tables_6_1.jpg", "caption": "Table 1: Model metrics comparison. DKL for the population spike count histogram and RMSE comparisons. Mean and standard deviation across 5 folds sampled with replacement. sh represents observation models with spike history. Bolded entries represent best-performing values for Poisson and spike-history observation models.", "description": "This table presents a comparison of different model's performance based on several metrics: DKL (Kullback-Leibler divergence) for the population spike count histogram, and RMSE (Root Mean Squared Error) for pairwise correlations, mean inter-spike intervals (isi), and standard deviation of isi.  The comparison includes four models: AutoLFADS (a baseline), LDNS (the proposed method), AutoLFADSsh (AutoLFADS with a spike history-dependent observation model), and LDNSsh (LDNS with a spike history-dependent observation model).  The results are averaged over five folds, each with replacement sampling.  The bold values indicate the best performance for the Poisson and spike-history observation models respectively.", "section": "3.4 Realistic generation of spiking data from a monkey performing reach tasks"}, {"figure_path": "ZX6CEo1Wtv/tables/tables_16_1.jpg", "caption": "Table 2: Training details for autoencoder models on Lorenz, Monkey reach, and Human BCI datasets. We used the AdamW [31] optimizer, whose learning rate was linearly increased over in the initial period and then decayed to 10% of the max value with a cosine schedule. Mean firing rate for Lorenz was 0.3. In all cases, we used K = 5 for the temporal smoothness loss in Eq. 1.", "description": "This table shows the hyperparameters used for training the autoencoder models for three different datasets: Lorenz, Monkey Reach, and Human BCI.  The AdamW optimizer was used with a linearly increasing learning rate that decayed to 10% of its maximum value using a cosine schedule. For the Lorenz dataset, the mean firing rate was 0.3.  In all cases, the temporal smoothness loss (Eq. 1) used K=5.", "section": "Methods"}, {"figure_path": "ZX6CEo1Wtv/tables/tables_17_1.jpg", "caption": "Table 3: Training details for diffusion models on Lorenz, Monkey reach, and Human BCI datasets. We used the same learning rate scheduler as for the autoencoder.", "description": "This table shows the hyperparameters used for training the diffusion models in the LDNS framework.  It provides details on the model architecture (number of latent channels, hidden layer channels, diffusion blocks, and denoising steps) and the training process (maximum learning rate, AdamW weight decay, number of epochs, warmup epochs, and batch size).  The hyperparameters are specific to each dataset: Lorenz, Monkey Reach, and Human BCI.", "section": "3 Experiments and Results"}, {"figure_path": "ZX6CEo1Wtv/tables/tables_19_1.jpg", "caption": "Table 1: Model metrics comparison. DKL for the population spike count histogram and RMSE comparisons. Mean and standard deviation across 5 folds sampled with replacement. sh represents observation models with spike history. Bolded entries represent best-performing values for Poisson and spike-history observation models.", "description": "This table presents the quantitative comparison of different models' performance on the monkey reach task dataset. The models compared are AutoLFADS, LDNS, AutoLFADSsh (AutoLFADS with spike history), and LDNSsh (LDNS with spike history). The metrics used for comparison are DKL (Kullback-Leibler divergence) for population spike count histogram, RMSE (root mean squared error) for pairwise correlations, RMSE for mean inter-spike intervals (isi), and RMSE for standard deviation of isi. The table shows that LDNSsh achieves the best performance across all the metrics.", "section": "3.4 Realistic generation of spiking data from a monkey performing reach tasks"}]