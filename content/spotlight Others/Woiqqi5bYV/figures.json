[{"figure_path": "Woiqqi5bYV/figures/figures_0_1.jpg", "caption": "Figure 1: GradCAM [45] visualizations for the unknown class 'person' across seen and unseen domains of the GMDG baseline with L\u2082 regularization that is trained without and with L-Reg, respectively. Both experiments share the same hyper-parameters, except the latter uses the L-Reg.", "description": "The figure displays GradCAM visualizations, highlighting activated regions in a model trained for visual classification.  It compares the results of a model trained with standard L2 regularization versus one with the proposed L-Reg (logical regularization).  The visualizations are shown for both seen (training) and unseen (testing) domains.  Focus is on the classification of the 'person' class, comparing how salient features (e.g., faces) are detected with and without the use of L-Reg.  The implication is that L-Reg leads to more focused and interpretable attention on relevant features, improving generalization.", "section": "1 Introduction"}, {"figure_path": "Woiqqi5bYV/figures/figures_1_1.jpg", "caption": "Figure 1: GradCAM [45] visualizations for the unknown class 'person' across seen and unseen domains of the GMDG baseline with L\u2082 regularization that is trained without and with L-Reg, respectively. Both experiments share the same hyper-parameters, except the latter uses the L-Reg.", "description": "This figure shows GradCAM visualizations for the 'person' class using the GMDG baseline model with and without L-Reg.  The visualizations highlight which parts of the image the model focuses on to identify the 'person' class in seen and unseen domains.  The key difference shown is that with L-Reg, the model focuses more on facial features, indicating improved interpretability and generalization.", "section": "1 Introduction"}, {"figure_path": "Woiqqi5bYV/figures/figures_2_1.jpg", "caption": "Figure 3: Visualizations of classifiers' weights form models trained using GMDG on PACS dataset without and with L-Reg under mDG+GCD setting, respectively. Both experiments share the same hyper-parameters using Regnety-16g backbone, except the latter uses additional L-Reg.", "description": "The figure visualizes the effects of L-Reg on the classifier's weights in a multi-domain generalization plus generalized category discovery setting using the PACS dataset.  Subfigure (a) shows heatmaps of the classifier weights, revealing a more balanced distribution and fewer extreme values with L-Reg. Subfigure (b) presents the distribution of classifier weight values for each class, demonstrating that L-Reg leads to simpler classifiers with reduced complexity. ", "section": "3 Logical regularization for generalization in image classification"}, {"figure_path": "Woiqqi5bYV/figures/figures_3_1.jpg", "caption": "Figure 4: Visualizations of latent features form models trained using GMDG on PACS dataset without and with L-Reg under mDD+GCD setting using RegNetY-16G backbone, respectively.", "description": "This figure visualizes the distribution of latent features from models trained with and without L-Reg on the PACS dataset under the multi-domain generalization and generalized category discovery setting. It shows that L-Reg leads to a more balanced distribution of features, reducing complexity and improving generalization.", "section": "4 L-Reg under different generalization settings"}, {"figure_path": "Woiqqi5bYV/figures/figures_8_1.jpg", "caption": "Figure 5: GradCAM [45] visualizations for the unknown class 'person' across seen and unseen domains of the GMDG baseline with L\u2082 regularization that is trained without and with L-Reg, respectively. Both experiments share the same hyper-parameters, except the latter uses the L-Reg.", "description": "This figure shows GradCAM visualizations comparing a model trained with L2 regularization only and a model trained with both L2 and L-Reg.  The visualizations highlight the model's attention when classifying the 'person' category across images from both seen and unseen domains. The L-Reg model demonstrates a focus on facial features even when presented with diverse image styles.", "section": "1 Introduction"}, {"figure_path": "Woiqqi5bYV/figures/figures_17_1.jpg", "caption": "Figure 6: Prediction visualizations of MLP with different regularization terms.", "description": "This figure compares the prediction visualizations of a Multilayer Perceptron (MLP) model trained with different regularization techniques. The ground truth (GT) is shown alongside results from a base model, models regularized with L1 and L2, and a model using the proposed L-Reg.  The visualizations highlight the differences in how each regularization method affects the model's ability to learn and generalize from the training data. The visualizations show the model's output across the entire input space and is a contour plot showing the model's prediction values. The differences in the contour plots suggest that L-Reg might lead to better generalization performance than the other methods.", "section": "D One toy example"}, {"figure_path": "Woiqqi5bYV/figures/figures_26_1.jpg", "caption": "Figure 1: GradCAM [45] visualizations for the unknown class 'person' across seen and unseen domains of the GMDG baseline with L\u2082 regularization that is trained without and with L-Reg, respectively. Both experiments share the same hyper-parameters, except the latter uses the L-Reg.", "description": "This figure shows GradCAM visualizations, highlighting the model's attention during classification.  The top row illustrates a model trained without L-Reg (logical reasoning regularization), showcasing ambiguous attention across both seen and unseen domains when classifying a person. The bottom row shows a model trained with L-Reg, demonstrating focused attention on facial features\u2014a key characteristic for identifying a person\u2014regardless of domain.  The comparison highlights L-Reg's ability to improve model interpretability and generalization.", "section": "1 Introduction"}, {"figure_path": "Woiqqi5bYV/figures/figures_27_1.jpg", "caption": "Figure 8: GradCAM visualizations: Baseline is GMDG. The used dataset is PACS. The model is trained under uDG+GCD setting with and without L-Reg, respectively. It can be seen that for the known class 'elephant,' the model trained with L-Reg extracts the shape of long noses, teeth, and big ears for classification across all seen and unseen domains. The compromise of the known sets can be seen in the sketch domain, where those features are not significant.", "description": "This figure shows GradCAM visualizations for the known class 'elephant' using GMDG with and without L-Reg. The results demonstrate that L-Reg improves generalization across seen and unseen domains by focusing on salient features (long noses, teeth, and big ears). However, it also highlights a limitation where this approach may compromise performance in domains with less distinctive features (e.g., sketch).", "section": "4 L-Reg under different generalization settings"}, {"figure_path": "Woiqqi5bYV/figures/figures_28_1.jpg", "caption": "Figure 9: GradCAM visualizations: Baseline is GMDG. The used dataset is PACS. The model is trained under uDG+GCD setting with and without L-Reg, respectively. It can be seen that for the known class 'giraffe,' the model trained with L-Reg extracts the feature of the long necks for classifying across all seen and unseen domains.", "description": "This figure shows GradCAM visualizations for the classification of giraffes in the PACS dataset. The model was trained using the GMDG method, both with and without L-Reg. The visualizations highlight the areas of the images that are most important for classification.  In the model trained with L-Reg, the visualizations clearly focus on the long necks of the giraffes, regardless of whether the images are from the seen or unseen domains. This illustrates the model's improved ability to generalize to unseen data when using L-Reg.", "section": "4 L-Reg under different generalization settings"}, {"figure_path": "Woiqqi5bYV/figures/figures_29_1.jpg", "caption": "Figure 1: GradCAM [45] visualizations for the unknown class 'person' across seen and unseen domains of the GMDG baseline with L\u2082 regularization that is trained without and with L-Reg, respectively. Both experiments share the same hyper-parameters, except the latter uses the L-Reg.", "description": "The figure shows GradCAM visualizations for the 'person' class in seen and unseen domains.  The visualizations compare models trained with and without the proposed Logical Reasoning Regularization (L-Reg).  The goal is to illustrate how L-Reg improves the model's ability to identify salient features (such as faces) for classifying the 'person' class, even in unseen domains, leading to better generalization.", "section": "1 Introduction"}, {"figure_path": "Woiqqi5bYV/figures/figures_30_1.jpg", "caption": "Figure 1: GradCAM [45] visualizations for the unknown class 'person' across seen and unseen domains of the GMDG baseline with L\u2082 regularization that is trained without and with L-Reg, respectively. Both experiments share the same hyper-parameters, except the latter uses the L-Reg.", "description": "This figure uses GradCAM to visualize the features used by a model for classifying the 'person' class.  It shows visualizations for images from both seen and unseen domains. The left column shows the model trained with only L2 regularization; the right column shows the model trained with both L2 and the proposed L-Reg. The visualization highlights the difference in attention: the L-Reg model focuses more on salient features like faces, showcasing improved interpretability and generalization.", "section": "1 Introduction"}, {"figure_path": "Woiqqi5bYV/figures/figures_31_1.jpg", "caption": "Figure 5: GradCAM [45] visualizations for the unknown class 'person' across seen and unseen domains of the GMDG baseline with L\u2082 regularization that is trained without and with L-Reg, respectively. Both experiments share the same hyper-parameters, except the latter uses the L-Reg.", "description": "This figure shows GradCAM visualizations, highlighting the model's attention areas when classifying images. The visualizations are separated into two groups: images trained without L-Reg and images trained with L-Reg. Each group shows a comparison across four different domains (art painting, photo, sketch, and cartoon). The visualizations reveal that images with L-Reg consistently focuses on human faces as salient features, improving the model's interpretability and generalization to unseen data, such as images from unseen domains or novel classes. ", "section": "1 Introduction"}]