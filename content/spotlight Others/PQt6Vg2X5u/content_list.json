[{"type": "text", "text": "Recursive PAC-Bayes: A Frequentist Approach to Sequential Prior Updates with No Information Loss ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yi-Shan Wu Yijie Zhang University of South Denmark University of Copenhagen & Novo Nordisk A/S yswu@imada.sdu.dk yizh@di.ku.dk ", "page_idx": 0}, {"type": "text", "text": "Badr-Eddine Ch\u00e9rief-Abdellatif CNRS, LPSM, Sorbonne Universit\u00e9, Universit\u00e9 Paris Cit\u00e9 badr-eddine.cherief-abdellatif@cnrs.fr ", "page_idx": 0}, {"type": "text", "text": "Yevgeny Seldin University of Copenhagen seldin@di.ku.dk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "PAC-Bayesian analysis is a frequentist framework for incorporating prior knowledge into learning. It was inspired by Bayesian learning, which allows sequential data processing and naturally turns posteriors from one processing step into priors for the next. However, despite two and a half decades of research, the ability to update priors sequentially without losing confidence information along the way remained elusive for PAC-Bayes. While PAC-Bayes allows construction of datainformed priors, the final confidence intervals depend only on the number of points that were not used for the construction of the prior, whereas confidence information in the prior, which is related to the number of points used to construct the prior, is lost. This limits the possibility and benefti of sequential prior updates, because the final bounds depend only on the size of the final batch. ", "page_idx": 0}, {"type": "text", "text": "We present a novel and, in retrospect, surprisingly simple and powerful PACBayesian procedure that allows sequential prior updates with no information loss. The procedure is based on a novel decomposition of the expected loss of randomized classifiers. The decomposition rewrites the loss of the posterior as an excess loss relative to a downscaled loss of the prior plus the downscaled loss of the prior, which is bounded recursively. As a side result, we also present a generalization of the split-kl and PAC-Bayes-split-kl inequalities to discrete random variables, which we use for bounding the excess losses, and which can be of independent interest. In empirical evaluation the new procedure significantly outperforms state-of-the-art. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "PAC-Bayesian analysis was born from an attempt to derive frequentist generalization guarantees for Bayesian-style prediction rules (Shawe-Taylor and Williamson, 1997, McAllester, 1998). The motivation was to provide a way to incorporate prior knowledge into the frequentist analysis of generalization. PAC-Bayesian bounds provide high-probability generalization guarantees for randomized classifiers. A randomized classifier is defined by a distribution $\\rho$ on a set of prediction rules $\\mathcal{H}$ , which is used to sample a prediction rule each time a prediction is to be made. Bayesian posterior is an example of a randomized classifier, whereas PAC-Bayesian bounds hold generally for all randomized classifiers. Prior knowledge is encoded through a prior distribution $\\pi$ on $\\mathcal{H}$ , and the complexity of a posterior distribution $\\rho$ is measured by the Kullback-Leibler (KL) divergence from the prior, $\\operatorname{KL}({\\bar{\\rho}}\\|\\pi)$ . PAC-Bayesian generalization guarantees are optimized by posterior distributions $\\rho$ that optimize a trade-off between empirical data fit and divergence from the prior in the $\\mathrm{KL}$ sense. ", "page_idx": 0}, {"type": "text", "text": "Selection of a \u201cgood\u201d prior plays an important role in the PAC-Bayesian bounds. If one manages to foresee which prediction rules are likely to produce low prediction error and allocate a higher prior mass for them, then the bounds are tighter, because the posterior only needs to make a small deviation from the prior. But if the prior mass on well-performing prediction rules is small, the bounds are loose. A major technique to design good priors is to use part of the data to estimate a good prior and the rest of the data to compute a PAC-Bayes bound. It is known as data-dependent or data-informed priors (Ambroladze et al., 2007). However, all existing approaches to data-informed priors have three major disadvantages. The first is that the bounds are computed on \u201cthe rest of the data\u201d that were not used in construction of the prior. Thus, the sample size in the bounds is only a fraction of the total sample size. Therefore, empirically data-informed priors are not always helpful. In many cases starting with an uninformed prior and using all the data to compute the posterior and the bound turns to be superior to sacrificing part of the data for prior construction (Ambroladze et al., 2007, Mhammedi et al., 2019). The second disadvantage is that all the confidence information about the prior is lost in the process. In particular, a prior trained on a few data points is treated in the same way as a prior trained on a lot of data. And a third related disadvantage is that sequential data processing provides no benefti, because the bounds only depend on the size of the last chunk and all the confidence information from processing earlier chunks is lost in the process. ", "page_idx": 1}, {"type": "text", "text": "Our main contribution is a new (and simple) way of decomposing the loss of a randomized classifier defined by the posterior. We write it as an excess loss relative to a downscaled loss of the randomized classifier defined by the prior plus the downscaled loss of the randomized classifier defined by the prior. The excess loss can be bounded using PAC-Bayes-Empirical-Bernstein-style inequalities (Tolstikhin and Seldin, 2013, Mhammedi et al., 2019, Wu et al., 2021, Wu and Seldin, 2022), whereas the loss of the randomized classifier defined by the prior can be bounded recursively. The recursive bound can both use the data used for construction of the prior and \u201cthe rest of the data\u201d, and thereby preserves confidence information on the prior. Our contribution stands out relative to all prior work on PAC-Bayes, and in fact all prior work on frequentist generalization bounds, because it makes sequential data processing and sequential prior updates meaningful and beneficial. ", "page_idx": 1}, {"type": "text", "text": "We note that while several recent papers experimented with sequential posterior updates by using martingale-style analysis, in all these works the prior remained fixed and only the posterior was changing (Chugg et al., 2023, Biggs and Guedj, 2023, Rodr\u00edguez-G\u00e1lvez et al., 2024). The work on sequential posterior updates is orthogonal to our contribution and can be combined with it. Namely, it is possible to apply sequential posterior updates in-between sequential prior updates. Another line of work used tools from online learning to derive PAC-Bayesian bounds (Jang et al., 2023), and in this context Haddouche and Guedj (2023) have used sequential prior updates, but their bounds hold for a uniform aggregation of sequentially constructed posteriors, which is different from standard posteriors studied in our work. The confidence bounds in their work come primarily from aggregation rather than confidence in individual posteriors in the sequence (the denominator of their bounds depends on the number of aggregated posteriors). The need to construct and maintain a large number of posteriors has a negative impact on the computational efficiency. Our work is the first one allowing sequential prior updates without loss of confidence information. ", "page_idx": 1}, {"type": "text", "text": "An additional side contribution of independent interest is a generalization of the split-kl and PACBayes-split-kl inequalities of Wu and Seldin (2022) from ternary to general discrete random variables. It is based on a novel representation of discrete random variables as a superposition of Bernoulli random variables. ", "page_idx": 1}, {"type": "text", "text": "The paper is organized in the following way. In Section 2 we briefly survey the evolution of datainformed priors in PAC-Bayes and present our main idea behind Recursive PAC-Bayes; in Section 3 we present our generalization of the split-kl and PAC-Bayes-split-kl inequalities, which are later used to bound the excess losses; in Section 4 we present the Recursive PAC-Bayes bound; in Section 5 we present an empirical evaluation; and in Section 6 we conclude with a discussion. ", "page_idx": 1}, {"type": "text", "text": "2 The evolution of data-informed priors and the idea of Recursive PAC-Bayes ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In this section we briefly survey the evolution of data-informed priors, and then present our construction of Recursive PAC-Bayes. We consider the standard classification setting, with $\\mathcal{X}$ being a sample space, $\\boldsymbol{\\wp}$ a label space, $\\mathcal{H}$ a set of prediction rules $h:\\,\\mathcal{X}\\,\\rightarrow\\,\\mathcal{Y}$ , and $\\ell(h(X),Y)\\;=$ $\\mathbb{1}(h(\\bar{X})\\neq\\mathbf{\\bar{\\}}Y)$ the zero-one loss function, where $\\mathbb{1}(\\cdot)$ denotes the indicator function. We let $\\mathcal{D}$ denote a distribution on $\\mathcal X\\times\\mathcal Y$ and ${\\cal S}=\\{(X_{1},Y_{1}),\\ldots,(X_{n},Y_{n})\\}$ an i.i.d. sample from $\\mathcal{D}$ . Let $L(h)=\\mathbb{E}_{(X,Y)\\sim{\\mathcal{D}}}[\\ell(h(X),Y)]$ be the expected and $\\begin{array}{r}{\\hat{L}(h,S)=\\frac{1}{n}\\sum_{i=1}^{n}\\ell(h(X_{i}),Y_{i})}\\end{array}$ the empirical loss. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Let $\\rho$ be a distribution on $\\mathcal{H}$ . A randomized classifier associated with $\\rho$ samples a prediction rule $h$ according to $\\rho$ for each sample $X\\in\\mathcal{X}$ , and applies it to make a prediction $h(X)$ . The expected loss of such randomized classifier, which we call $\\rho$ , is $\\mathbb{E}_{h\\sim\\rho}[L(h)]$ and the empirical loss is $\\mathbb{E}_{h\\sim\\rho}[\\hat{L}(h,S)]$ . For brevity we use $\\mathbb{E}_{\\rho}[\\cdot]$ to denote $\\mathbb{E}_{h\\sim\\rho}[\\cdot]$ . ", "page_idx": 2}, {"type": "text", "text": "We use $\\operatorname{KL}(\\rho||\\pi)$ to denote the Kullback-Leibler divergence between two probability distributions, $\\rho$ and $\\pi$ (Cover and Thomas, 2006). For $p$ ${\\boldsymbol{p}},{\\boldsymbol{q}}\\in[0,1]$ we further use $\\mathrm{kl}(p\\|q)=\\mathrm{KL}((1\\!-\\!p,p)\\|(1\\!-\\!q,q))$ to denote the Kullback-Leibler divergence between two Bernoulli distributions with biases $p$ and $q$ . ", "page_idx": 2}, {"type": "text", "text": "The goal of PAC-Bayes is to bound $\\mathbb{E}_{\\rho}[L(h)]$ . Below we present how the bounds on $\\mathbb{E}_{\\rho}[L(h)]$ have evolved. In Appendix A we also provide a graphical illustration of the evolution. ", "page_idx": 2}, {"type": "text", "text": "Uninformed priors Early work on PAC-Bayes used uninformed priors (McAllester, 1998). An uniformed prior $\\pi$ is a distribution on $\\mathcal{H}$ that is independent of the data $S$ . A classical, and still one of the tightest bounds, is the following. ", "page_idx": 2}, {"type": "text", "text": "Theorem 1 (PAC-Bayes-kl Inequality, Seeger, 2002, Maurer, 2004). For any probability distribution $\\pi$ on $\\mathcal{H}$ that is independent of $S$ and any $\\delta\\in(0,1)$ : ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{P}\\bigg(\\exists\\rho\\in\\mathcal{P}:\\operatorname{kl}\\Big(\\mathbb{E}_{\\rho}[\\hat{L}(h,S)]\\Big\\|\\mathbb{E}_{\\rho}\\left[L(h)\\right]\\Big)\\geq\\frac{\\operatorname{KL}(\\rho\\|\\pi)+\\ln(2\\sqrt{n}/\\delta)}{n}\\bigg)\\leq\\delta,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mathcal{P}$ is the set of all probability distributions on $\\mathcal{H}$ , including those dependent on $S$ . ", "page_idx": 2}, {"type": "text", "text": "A posterior $\\rho$ that minimizes $\\mathbb{E}_{\\rho}[L(h)]$ has to balance between allocating higher mass to prediction rules $h$ with small $\\hat{L}(h,S)$ and staying close to $\\pi$ in the $\\operatorname{KL}(\\rho||\\pi)$ sense. Since $\\pi$ has to be independent of $S$ , typical uninformed priors aim \u201cto leave maximal options open\u201d for $\\rho$ by staying close to uniform. ", "page_idx": 2}, {"type": "text", "text": "Data-informed priors Ambroladze et al. (2007) proposed to split the data $S$ into two disjoint sets, $S=S_{1}\\cup S_{2}$ , and use $S_{1}$ to construct a data-informed prior $\\pi$ and compute a bound on $\\mathbb{E}_{\\rho}[L(h)]$ using $\\pi$ and $S_{2}$ . Since in this approach $\\pi$ is independent of $S_{2}$ , Theorem 1 can be applied. The advantage is that $\\pi$ can use $S_{1}$ to give higher mass to promising classifiers, thus relaxing the regularization pressure $\\operatorname{KL}(\\rho||\\pi)$ and making it easier for $\\rho$ to allocate even higher mass to well-performing classifiers (those with small $\\hat{L}(h,S_{2}))$ . The disadvantage is that the sample size in the bound (the $n$ in the denominator) decreases from the size of $S$ to the size of $S_{2}$ . Indeed, Ambroladze et al. observed that the sacrifice of $S_{1}$ for prior construction does not always pay off. ", "page_idx": 2}, {"type": "text", "text": "Data-informed priors $^+$ excess loss Mhammedi et al. (2019) observed that if we have already sacrificed $S_{1}$ for the construction of $\\pi$ , we could also use it to construct a reference prediction rule $h^{*}$ , typically an Empirical Risk Minimizer (ERM) on $S_{1}$ . They then employed the decomposition ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}[L(h)]=\\mathbb{E}_{\\rho}[L(h)-L(h^{*})]+L(h^{*})\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "and used $S_{2}$ to give a PAC-Bayesian bound on $\\mathbb{E}_{\\rho}[L(h)-L(h^{*})]$ and a single-hypothesis bound on $L(h^{*})$ . The quantity $\\mathbb{E}_{\\rho}[L(h)-L(h^{*})]$ is known as excess loss. The advantage of this approach is that when $L(h^{*})$ is a good approximation of $\\mathbb{E}_{\\rho}[L(h)]$ , the excess loss has lower variance than the plain loss $\\mathbb{E}_{\\rho}[\\dot{L}(h)]$ and, therefore, is more efficient to bound, whereas the single-hypothesis bound on $L(h^{*})$ does not involve the $\\operatorname{KL}(\\rho||\\pi)$ term. Therefore, it is generally beneficial to use excess losses in combination with data-informed priors. However, as with the previous approach, sacrificing $S_{1}$ to learn $\\pi$ and $h^{*}$ means that the denominator in the bounds ( $\\ln$ in Theorem 1) reduces to the size of $S_{2}$ , and it does not always pay off. (We note that the excess loss is not binary and not in the $[0,1]$ interval, and in order to exploit small variance it is actually necessary to apply a PAC-Bayes-Empirical-Bernstein-style inequality (Tolstikhin and Seldin, 2013, Mhammedi et al., 2019, Wu et al., 2021) or the PAC-Bayes-split-kl inequality (Wu and Seldin, 2022) rather than Theorem 1, but the point about reduced sample size still applies.) ", "page_idx": 2}, {"type": "text", "text": "Recursive PAC-Bayes (new) We introduce the following decomposition of the loss ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\rho}[L(h)]=\\mathbb{E}_{\\rho}[L(h)-\\gamma\\mathbb{E}_{\\pi}[L(h^{\\prime})]]+\\gamma\\mathbb{E}_{\\pi}[L(h^{\\prime})].}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "As before, we decompose $S$ into two disjoint sets $S\\,=\\,S_{1}\\cup S_{2}$ . We make the following major observations: ", "page_idx": 3}, {"type": "text", "text": "\u2022 The quantity $\\mathbb{E}_{\\pi}[L(h^{\\prime})]$ on the right is \u201cof the same kind\u201d as $\\mathbb{E}_{\\rho}[L(h)]$ on the left. \u2022 We can take an uninformed prior $\\pi_{0}$ and apply Theorem 1 (or any other suitable PAC-Bayes bound) to bound $\\mathbb{E}_{\\pi}[L(h^{\\prime})]$ . (The KL term in the bound on $\\mathbb{E}_{\\pi}[L(h^{\\prime})]$ will be $\\mathrm{KL}(\\pi\\|\\pi_{0})$ .) ", "page_idx": 3}, {"type": "text", "text": "\u2022 We can restrict $\\pi$ to depend only on $S_{1}$ , but still use all the data $S$ in calculation of the PACBayes bound on $\\mathbb{E}_{\\pi}[L(h^{\\prime})]$ , because $\\pi$ is a posterior relative to $\\pi_{0}$ , and a posterior is allowed to depend on all the data, and in particular on any subset of the data. Therefore, the empirical loss $\\mathbb{E}_{\\pi}[\\widehat{L}(h^{\\prime},S)]$ can be computed on all the data $S$ , and the denominator of the bound in Theorem 1 can be the size of $S$ , and not the size of $S_{2}$ . This is what we call preservation of confidence information on $\\pi$ , because all the data $S$ are used to construct a confidence bound on $\\mathbb{E}_{\\pi}[L(h^{\\prime})]$ , and not just $S_{2}$ . This is in contrast to the bound on $L(h^{*})$ in the approach of Mhammedi et al. (2019), which only allows to use $S_{2}$ for bounding $L(h^{*})$ . Note that while we use all the data $S$ in calculation of the bound, we only use $S_{1}$ and $\\mathbb{E}_{\\pi}[\\hat{L}(h^{\\prime},S_{1})]$ in the construction of $\\pi$ . Nevertheless, we can still use the knowledge that we will have $n$ samples when we reach the estimation phase, i.e., when constructing $\\pi$ we can leave the denominator of the bound at $n$ , allowing more aggressive deviation from $\\pi_{0}$ . ", "page_idx": 3}, {"type": "text", "text": "\u2022 If we restrict $\\pi$ to depend only on $S_{1}$ , then it is a valid prior for estimation of any posterior quantity $\\mathbb{E}_{\\rho}[\\cdot]$ based on $S_{2}$ . Thus, if we also restrict $\\gamma$ to depend only on $S_{1}$ , we can use any PACBayes-Empirical-Bernstein-style inequality or the PAC-Bayes-split-kl inequality to estimate the excess loss $\\mathbb{E}_{\\rho}[L(h)-\\gamma\\mathbb{E}_{\\pi}[L(h^{\\prime})]]$ based on $S_{2}$ , i.e., based on $\\overline{{\\mathbb{E}_{\\rho}[\\hat{L}(h,S_{2})-\\gamma\\mathbb{E}_{\\pi}[\\hat{L}(h^{\\prime},S_{2})]]}}$ . If $\\gamma\\mathbb{E}_{\\pi}[L(h^{\\prime})]$ is a good approximation of $\\mathbb{E}_{\\rho}[L(h)]$ and $\\mathbb{E}_{\\rho}[L(h)]$ is not close to zero, then the excess loss $\\ddot{\\mathbb{E}_{\\rho}}[L(h)-\\gamma\\mathbb{E}_{\\pi}[L(h^{\\prime})]]$ is more efficient to bound than the plain loss $\\mathbb{E}_{\\rho}[L(h)]$ . \u2022 In general, since $\\mathbb{E}_{\\rho}[L(h)]$ is expected to improve on $\\mathbb{E}_{\\pi}[L(h^{\\prime})]$ , it is natural to set $\\gamma\\,<\\,1$ . However, $\\gamma$ is not allowed to depend on $S_{2}$ , because otherwise $\\hat{L}(h,S_{2})\\textrm{--}\\gamma\\mathbb{E}_{\\pi}[\\hat{L}(h^{\\prime},S_{2})]$ becomes a biased estimate of $L(h)-\\gamma\\mathbb{E}_{\\pi}[L(h^{\\prime})]$ . We discuss the choice of $\\gamma$ in more detail when we present the bound and the experiments. \u2022 Biggs and Guedj (2023) have proposed a sequential martingale-style evaluation of a martingale version of $\\mathbb{E}_{\\rho}[L(h)-L(h^{*})]$ and $L(h^{*})$ in the approach of Mhammedi et al., but it has not been shown to yield significant improvements yet. The same \u201cmartingalization\u201d can be directly applied to our decomposition, but to keep things simple we stay with the basic decomposition. \u2022 Finally, we note that we can split $S_{1}$ further and apply (1) recursively to bound $\\mathbb{E}_{\\pi}[L(h^{\\prime})]$ . ", "page_idx": 3}, {"type": "text", "text": "To set notation for recursive decomposition, we use $\\pi_{0},\\pi_{1},\\ldots,\\pi_{T}$ to denote a sequence of distributions on $\\mathcal{H}$ , where $\\pi_{0}$ is an uninformed prior and $\\pi_{T}=\\rho$ is the final posterior. We use $\\gamma_{2},\\dots,\\gamma_{T}$ to denote a sequence of coefficients. For $t\\geq2$ we then have the recursive decomposition ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\pi_{t}}[L(h)]=\\mathbb{E}_{\\pi_{t}}[L(h)-\\gamma_{t}\\mathbb{E}_{\\pi_{t-1}}[L(h)]]+\\gamma_{t}\\mathbb{E}_{\\pi_{t-1}}[L(h)].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "To construct $\\pi_{1},...,\\pi_{T}$ we split the data $S$ into $T$ non-overlapping subsets, $S=S_{1}\\cup\\cdot\\cdot\\cdot\\cup S_{T}$ . We restrict $\\pi_{t}$ to depend on $\\begin{array}{r}{U_{t}^{\\mathrm{train}}=\\bigcup_{s=1}^{t}S_{s}}\\end{array}$ only, and we use $\\begin{array}{r}{U_{t}^{\\mathrm{val}}=\\bigcup_{s=t}^{T}S_{s}}\\end{array}$ to estimate (recursively) $\\mathbb{E}_{\\pi_{t}}[L(h)]$ (see Figure 1 in Appendix A). Note that $S_{t}$ is used both for construction of $\\pi_{t}$ and for estimation of $\\mathbb{E}_{\\pi_{t}}[L(h)]$ (it is both in $U_{t}^{\\mathrm{train}}$ and $U_{t}^{\\mathrm{val}}$ ), resulting in efficient use of the data. It is possible to use any standard PAC-Bayes bound, e.g., Theorem 1, to bound $\\mathbb{E}_{\\pi_{1}}[L(h)]$ , and any PAC-Bayes-Empirical-Bernstein-style bound or the PAC-Bayes-split-kl bound to bound the excess losses $\\ddot{\\mathbb{E}_{\\pi_{t}}}[L(h)-\\gamma_{t}\\mathbb{E}_{\\pi_{t-1}}[L(h)]]$ . The excess losses take more than three values, so in the next section we present a generalization of the PAC-Bayes-split-kl inequality to general discrete random variables, which may be of independent interest. The Recursive PAC-Bayes bound is presented in Section 4. ", "page_idx": 3}, {"type": "text", "text": "3 Split-kl and PAC-Bayes-split-kl inequalities for discrete random variables ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The kl inequality is one of the tightest concentration of measure inequalities for binary random variables. Letting $\\mathrm{kl}^{-1,+}(\\hat{p},\\varepsilon):=\\operatorname*{max}\\left\\{p:p\\in[0,1]\\right.$ and $\\mathrm{kl}(\\hat{p}\\|p)\\leq\\varepsilon\\}$ denote the upper inverse of kl and $\\mathrm{kl}^{-1,-}(\\hat{p},\\varepsilon):=\\operatorname*{min}\\left\\{p:p\\in[0,1]\\right.$ and $\\mathrm{kl}(\\hat{p}\\|p)\\leq\\varepsilon\\}$ the lower inverse, it states the following. ", "page_idx": 3}, {"type": "text", "text": "Theorem 2 (kl Inequality (Langford, 2005, Foong et al., 2021, 2022)). Let $Z_{1},\\cdot\\cdot\\cdot,Z_{n}$ be independent random variables bounded in the $[0,1]$ interval and with E $[Z_{i}]=p$ for all i. Let $\\begin{array}{r}{\\hat{p}=\\frac{1}{n}\\sum_{i=1}^{n}Z_{i}}\\end{array}$ be the empirical mean. Then, for any $\\bar{\\boldsymbol{\\delta}}\\in\\bar{(0,1)}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{P}\\bigg(p\\geq\\mathrm{kl}^{-1,+}\\left(\\hat{p},\\frac{1}{n}\\ln\\frac{1}{\\delta}\\right)\\bigg)\\leq\\delta\\qquad;\\qquad\\mathbb{P}\\bigg(p\\leq\\mathrm{kl}^{-1,-}\\left(\\hat{p},\\frac{1}{n}\\ln\\frac{1}{\\delta}\\right)\\bigg)\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "While the $\\mathrm{kl}$ inequality is tight for binary random variables, it is loose for random variables taking more than two values due to its inability to exploit small variance. To address this shortcoming $\\mathrm{Wu}$ and Seldin (2022) have presented the split-kl and PAC-Bayes-split-kl inequalities for ternary random variables. Ternary random variables naturally appear in a variety of applications, including analysis of excess losses, certain ways of analysing majority votes, and in learning with abstention. The bound of Wu and Seldin is based on decomposition of a ternary random variable into a pair of binary random variables and application of the kl inequality to each of them. Their decomposition yields a tight bound in the binary and ternary case, but loose otherwise. The same decomposition was used by Biggs and Guedj (2023) to derive a slight variation of the inequality, with the same limitations. We present a novel decomposition of discrete random variables into a superposition of binary random variables. Unlike the decomposition of Wu and Seldin, which only applies in the ternary case, our decomposition applies to general discrete random variables. By combining it with $\\mathrm{kl}$ bounds for the binary elements we obtain a tight bound. The decomposition is presented formally below and illustrated graphically in Figure 2 in Appendix A. ", "page_idx": 4}, {"type": "text", "text": "3.1 Split-kl inequality ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Let $Z\\;\\in\\;\\{b_{0},\\ldots,b_{K}\\}$ be a $(K+1)$ -valued random variable with $b_{0}\\;<\\;b_{1}\\;<\\;\\cdot\\cdot\\;<\\;b_{K}$ . For $j\\in\\{1,\\ldots,K\\}$ define $Z_{|j}=\\mathbb{1}(Z\\geq b_{j})$ and $\\alpha_{j}=b_{j}-b_{j-1}$ . Then $\\begin{array}{r}{Z=b_{0}+\\sum_{j=1}^{K}\\alpha_{j}Z_{|j}}\\end{array}$ . For a sequence $Z_{1},\\ldots,Z_{n}$ of $(K+1)$ -valued random variables with the same support, let $Z_{i\\mid j}\\;=\\;$ $\\mathbb{1}(Z_{i}\\geq b_{j})$ denote the elements of binary decomposition of $Z_{i}$ . ", "page_idx": 4}, {"type": "text", "text": "Theorem 3 (Split-kl inequality for discrete random variables). Let $Z_{1},\\ldots,Z_{n}$ be i.i.d. random variables taking values in $\\{b_{0},\\dot{\\mathbf{\\eta}}.\\dot{\\mathbf{\\eta}}.\\mathbf{\\eta},b_{K}\\}\\ w i t h\\mathbb{E}\\left[Z_{i}\\right]=p$ for all $i$ . Let $\\begin{array}{r}{\\hat{p}_{|j}=\\frac{1}{n}\\sum_{i=1}^{n}Z_{i|j}}\\end{array}$ . Then for any $\\delta\\in(0,1)$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(p\\geq b_{0}+\\sum_{j=1}^{K}\\alpha_{j}\\,\\mathrm{kl}^{-1,+}\\left(\\hat{p}_{|j},\\frac{1}{n}\\ln\\frac{K}{\\delta}\\right)\\right)\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Proof. Let $p_{|j}=\\mathbb{E}\\left[\\hat{p}_{|j}\\right]$ , then $\\begin{array}{r}{p=b_{0}+\\sum_{j=1}^{K}\\alpha_{j}p_{|j}}\\end{array}$ and ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(p\\geq b_{0}+\\sum_{j=1}^{K}\\alpha_{j}\\,\\mathrm{kl}^{-1,+}\\left(\\hat{p}_{|j},\\frac{1}{n}\\ln\\frac{K}{\\delta}\\right)\\right)\\leq\\mathbb{P}\\bigg(\\exists j:p_{|j}\\geq\\mathrm{kl}^{-1,+}\\left(\\hat{p}_{|j},\\frac{1}{n}\\ln\\frac{K}{\\delta}\\right)\\bigg)\\leq\\delta,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where the first inequality is by the decomposition of $p$ and the second inequality is by the union bound and Theorem 2. \u53e3 ", "page_idx": 4}, {"type": "text", "text": "3.2 PAC-Bayes-Split-kl inequality ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Let $f:\\mathcal{H}\\times\\mathcal{Z}\\to\\{b_{0},\\dotsc,b_{K}\\}$ be a $(K+1)$ -valued loss function. (To connect it to the earlier examples, in the binary prediction case we would have $\\mathcal{Z}=\\mathcal{X}\\times\\mathcal{Y}$ with elements $Z=(X,Y)$ and $\\bar{f}(h,Z)=\\ell(h(X\\bar{)},\\bar{Y})$ , but we will need a more general space $\\mathcal{Z}$ later.) For $j\\in\\{1,\\ldots,K\\}$ let $f_{|j}(\\cdot,\\cdot)=\\mathbb{1}(f(\\cdot,\\cdot)\\geq b_{j})$ . Let $\\mathcal{D}_{Z}$ be an unknown distribution on $\\mathcal{Z}$ . For $h\\in\\mathcal H$ let $F(h)=$ $\\mathbb{E}_{\\cal D_{Z}}[f(h,Z)]$ and $F_{|j}(h)=\\mathbb{E}_{\\mathcal{D}_{Z}}[f_{|j}(h,Z)]$ . Let $S=\\{Z_{1},\\ldots,Z_{n}\\}$ be an i.i.d. sample according to $\\mathcal{D}_{Z}$ and $\\begin{array}{r}{\\hat{F}_{|j}(h,S)=\\frac{1}{n}\\sum_{i=1}^{n}f_{|j}(h,Z_{i})}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "Theorem 4 (PAC-Bayes-Split-kl Inequality). For any distribution $\\pi$ on $\\mathcal{H}$ that is independent of $S$ and any $\\delta\\in(0,1)$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Bigg(\\exists\\rho\\in\\mathcal{P}:\\mathbb{E}_{\\rho}[F(h)]\\geq b_{0}+\\sum_{j=1}^{K}\\alpha_{j}\\,\\mathrm{kl}^{-1,+}\\left(\\mathbb{E}_{\\rho}[\\hat{F}_{|j}(h,S)],\\frac{\\mathrm{KL}(\\rho\\|\\pi)+\\ln\\frac{2K\\sqrt{n}}{\\delta}}{n}\\right)\\Bigg)\\leq\\delta,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathcal{P}$ is the set of all possible probability distributions on $\\mathcal{H}$ that can depend on $S$ . ", "page_idx": 4}, {"type": "text", "text": "Proof. We have $\\begin{array}{r}{f(\\cdot,\\cdot)=b_{0}+\\sum_{j=1}^{K}\\alpha_{j}f_{|j}(\\cdot,\\cdot)}\\end{array}$ and $\\begin{array}{r}{F(h)=b_{0}+\\sum_{j=1}^{K}{\\alpha}_{j}F_{|j}(h)}\\end{array}$ . Therefore, ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\mathbb{P}\\Bigg(\\exists\\rho\\in\\mathcal{P}:\\mathbb{E}_{\\rho}[F(h)]\\geq b_{0}+\\displaystyle\\sum_{j=1}^{K}\\alpha_{j}\\,\\mathrm{kl}^{-1,+}\\left(\\mathbb{E}_{\\rho}[\\hat{F}_{\\vert j}(h,S)],\\frac{\\mathrm{KL}(\\rho\\|\\pi)+\\ln\\frac{2K\\sqrt{n}}{\\delta}}{n}\\right)\\Bigg)}\\\\ {\\leq\\mathbb{P}\\Bigg(\\exists\\rho\\in\\mathcal{P}\\mathrm{~and~}\\exists j:\\mathbb{E}_{\\rho}[F_{\\vert j}(h)]\\geq\\mathrm{kl}^{-1,+}\\left(\\mathbb{E}_{\\rho}[\\hat{F}_{\\vert j}(h,S)],\\frac{\\mathrm{KL}(\\rho\\|\\pi)+\\ln\\frac{2K\\sqrt{n}}{\\delta}}{n}\\right)\\Bigg)\\leq\\delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the first inequality is by the decomposition of $F$ and the second inequality is by the union bound and application of Theorem 1 to $F_{\\mid j}$ (note that $f_{\\vert j}$ is a zero-one loss function). ", "page_idx": 5}, {"type": "text", "text": "4 Recursive PAC-Bayes bound ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Now we derive a Recursive PAC-Bayes bound based on the loss decomposition in equation (2). We aim to bound $\\mathbb{E}_{\\pi_{t}}[L(h)-\\gamma_{t}\\mathbb{E}_{\\pi_{t-1}}[\\dot{L}(h^{\\prime})]]$ , which we denote by ", "page_idx": 5}, {"type": "equation", "text": "$$\nF_{\\gamma_{t},\\pi_{t-1}}(h)=L(h)-\\gamma_{t}\\mathbb{E}_{\\pi_{t-1}}[L(h^{\\prime})]=\\mathbb{E}_{\\mathcal{D}\\times\\pi_{t-1}}[\\ell(h(X),Y)-\\gamma_{t}\\ell(h^{\\prime}(X),Y)],\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\mathcal{D}\\times\\pi_{t-1}$ is a product distribution on $\\mathcal{X}\\times\\mathcal{Y}\\times\\mathcal{H}$ and $h^{\\prime}\\in\\mathcal{H}$ is sampled according to $\\pi_{t-1}$ . We further define ", "page_idx": 5}, {"type": "equation", "text": "$$\nf_{\\gamma_{t}}(h,(X,Y,h^{\\prime}))=\\ell(h(X),Y)-\\gamma_{t}\\ell(h^{\\prime}(X),Y)\\in\\left\\{-\\gamma_{t},0,1-\\gamma_{t},1\\right\\},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "then $F_{\\gamma_{t},\\pi_{t-1}}(h)=\\mathbb{E}_{\\mathcal{D}\\times\\pi_{t-1}}[f_{\\gamma_{t}}(h,(X,Y,h^{\\prime}))]$ . In order to apply Theorem 4, we represent $f_{\\gamma_{t}}$ as a superposition of binary functions. For this purpose we let $\\left\\{b_{t|0},b_{t|1},b_{t|2},b_{t|3}\\right\\}=\\left\\{-\\gamma_{t},0,1-\\gamma_{t},1\\right\\}$ and define $\\begin{array}{r l r}{f_{\\gamma_{t}|j}(h,(X,Y,h^{\\prime}))}&{=}&{\\mathbb{1}\\big(f_{\\gamma_{t}}(h,(X,Y,h^{\\prime}))\\stackrel{}{\\geq}b_{t|j}\\big)}\\end{array}$ . We let $\\begin{array}{r l}{F_{\\gamma_{t},\\pi_{t-1}|j}(h)}&{{}=}\\end{array}$ $\\mathbb{E}_{\\mathcal{D}\\times\\pi_{t-1}}[f_{\\gamma_{t}|j}(h,(X,Y,h^{\\prime}))]$ , then $\\begin{array}{r}{F_{\\gamma_{t},\\pi_{t-1}}(h)=-\\gamma_{t}+\\sum_{j=1}^{3}(b_{t|j}-b_{t|j-1})F_{\\gamma_{t},\\pi_{t-1}|j}(h).}\\end{array}$ . ", "page_idx": 5}, {"type": "text", "text": "Now we construct an empirical estimate of $F_{\\gamma_{t},\\pi_{t-1}|j}(h)$ . We first let $\\hat{\\pi}_{t-1}=\\left\\{h_{1}^{\\pi_{t-1}},h_{2}^{\\pi_{t-1}},\\cdot\\cdot\\cdot\\right\\}$ be a sequence of prediction rules sampled independently according to $\\pi_{t-1}$ . We define $U_{t}^{\\mathrm{val}}\\circ\\hat{\\pi}_{t-1}=$ $\\left\\{\\left({\\bar{X_{i}}},Y_{i},h_{i}^{\\pi_{t}-\\bar{1}}\\right):\\left(X_{i},Y_{i}\\right)\\in U_{t}^{\\mathrm{val}}\\right\\}$ . In words, for every sample $(X_{i},Y_{i})\\ \\in\\ U_{t}^{\\mathrm{val}}$ we sample a prediction rule $h_{i}^{\\pi_{t-1}}$ according to $\\pi_{t-1}$ and put the triplet $(X_{i},Y_{i},h_{i}^{\\pi_{t-1}})$ in $U_{t}^{\\mathrm{val}}\\circ\\,\\hat{\\pi}_{t-1}$ . The triplets $(X_{i},Y_{i},h_{i}^{\\pi_{t-1}})$ correspond to the random variables $Z$ in Theorem 4. We note that $|U_{t}^{\\mathrm{val}}|~=~|U_{t}^{\\mathrm{val}}\\circ\\hat{\\pi}_{t-1}|$ , and we let $n_{t}^{\\mathrm{val}}~=~|U_{t}^{\\mathrm{val}}|$ . We define the empirical estimate of $F_{\\gamma_{t},\\pi_{t-1}|j}(h)$ as $\\begin{array}{r}{\\hat{F}_{\\gamma_{t}|j}(h,U_{t}^{\\mathrm{val}}\\circ\\hat{\\pi}_{t-1})\\,=\\,\\frac{1}{n_{t}^{\\mathrm{val}}}\\sum_{(X,Y,h^{\\prime})\\in U_{t}^{\\mathrm{val}}\\circ\\hat{\\pi}_{t-1}}f_{\\gamma_{t}|j}(h,(X,Y,h^{\\prime}))}\\end{array}$ $\\mathbb{E}_{\\mathcal{D}\\times\\pi_{t-1}}[\\hat{F}_{\\gamma_{t}|j}(h,U_{t}^{\\mathrm{val}}\\circ\\hat{\\pi}_{t-1})]\\ =\\ F_{\\gamma_{t},\\pi_{t-1}|j}(h)$ , therefore, we can use Theorem 4 to bound $\\mathbb{E}_{\\pi_{t}}[F_{\\gamma_{t},\\pi_{t-1}}(h)]$ using its empirical estimates. We are now ready to state the bound. ", "page_idx": 5}, {"type": "text", "text": "Theorem 5 (Recursive PAC-Bayes Bound). Let $S=S_{1}\\cup\\cdot\\cdot\\cdot\\cup S_{T}$ be an i.i.d. sample split in an arbitrary way into $T$ non-overlapping subsamples, and let $\\begin{array}{r}{U_{t}^{\\mathrm{train}}=\\bigcup_{s=1}^{t}S_{s}}\\end{array}$ and $\\begin{array}{r}{U_{t}^{\\mathrm{{ical}}}=\\bigcup_{s=t}^{T}S_{s}}\\end{array}$ . Let $n_{t}^{\\mathrm{val}}=|U_{t}^{\\mathrm{val}}|$ . Let $\\pi_{0}^{*},\\pi_{1}^{*},\\ldots,\\pi_{T}^{*}$ be a sequence of distributions  on $\\mathcal{H}$ , where $\\pi_{t}^{*}$ is al lowed to depend on $U_{t}^{\\mathrm{train}}$ , but not the rest of the data. Let $\\gamma_{2},\\dots,\\gamma_{T}$ be a sequence of coefficients, where $\\gamma_{t}$ is allowed to depend on $U_{t-1}^{\\mathrm{train}}$ , but not the rest of the data. For $t\\in\\{1,\\ldots,T\\}$ let $\\mathcal{P}_{t}$ be a set of distributions on $\\mathcal{H}$ , which are allowed to depend on $U_{t}^{\\mathrm{train}}$ . Then for any $\\delta\\in(0,1)$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\exists t\\in\\{1,\\dots,T\\}\\ a n d\\,\\pi_{t}\\in\\mathcal{P}_{t}:\\mathbb{E}_{\\pi_{t}}[L(h)]\\geq\\mathrm{B}_{t}(\\pi_{t}))\\leq\\delta,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\operatorname{B}_{t}(\\pi_{t})$ is a PAC-Bayes bound on $\\mathbb{E}_{\\pi_{t}}[L(h)]$ defined recursively as follows. For $t=1$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{B}_{1}(\\pi_{1})=\\mathrm{kl}^{-1,+}\\left(\\mathbb{E}_{\\pi_{1}}[\\hat{L}(h,S)],\\frac{\\mathrm{KL}(\\pi_{1}\\|\\pi_{0}^{*})+\\ln\\frac{2T\\sqrt{n}}{\\delta}}{n}\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "For $t\\geq2$ we let $\\mathcal{E}_{t}(\\pi_{t},\\gamma_{t})$ denote a PAC-Bayes bound on $\\mathbb{E}_{\\pi_{t}}[L(h)-\\gamma_{t}\\mathbb{E}_{\\pi_{t-1}^{*}}[L(h^{\\prime})]]$ given by ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\dot{\\tau}(\\pi_{t},\\gamma_{t})=-\\gamma_{t}+\\sum_{j=1}^{3}(b_{t|j}-b_{t|j-1})\\,\\mathrm{k}\\mathrm{l}^{-1,+}\\,\\left(\\mathbb{E}_{\\pi_{t}}\\left[\\hat{F}_{\\gamma_{t|j}}(h,U_{t}^{\\mathrm{val}}\\circ\\hat{\\pi}_{t-1}^{*})\\right],\\frac{\\mathrm{KL}(\\pi_{t}\\|\\pi_{t-1}^{*})+\\ln\\frac{6T\\sqrt{n_{t}^{*}}}{\\delta}-1}{n_{t}^{\\mathrm{val}}}\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "and then ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{B}_{t}(\\pi_{t})=\\mathcal{E}_{t}(\\pi_{t},\\gamma_{t})+\\gamma_{t}\\,\\mathrm{B}_{t-1}(\\pi_{t-1}^{*}).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Proof. By Theorem 1 we have $\\begin{array}{r}{\\mathbb{P}(\\exists\\pi_{1}\\in\\mathcal{P}_{1}:\\mathbb{E}_{\\pi_{1}}[L(h)]\\ge B_{1}(\\pi_{1}))\\le\\frac{\\delta}{T}}\\end{array}$ . Further, by Theorem 4 for $t\\,\\in\\,\\{2,\\ldots,T\\}$ we have $\\begin{array}{r}{\\mathbb{P}\\Big(\\exists\\pi_{t}\\in\\mathcal{P}_{t}:\\mathbb{E}_{\\pi_{t}}[L(h)-\\gamma_{t}\\mathbb{E}_{\\pi_{t-1}^{*}}[L(h^{\\prime})]]\\geq\\mathcal{E}_{t}(\\pi_{t},\\gamma_{t})\\Big)\\,\\le\\,\\frac{\\delta}{T}}\\end{array}$ . The theorem follows by a union bound and the recursive decomposition of the loss (2). \u53e3 ", "page_idx": 6}, {"type": "text", "text": "Discussion ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "\u2022 Note that $\\pi_{1}^{*},\\dots,\\pi_{T}^{*}$ can be constructed sequentially, but $\\pi_{t}^{*}$ can only be constructed based on the data in $U_{t}^{\\mathrm{train}}$ , meaning that in the construction of $\\pi_{t}^{*}$ we can only rely on $\\mathbb{E}_{\\pi_{t}}\\left[\\hat{F}_{\\gamma_{t}|j}(h,S_{t}\\circ\\hat{\\pi}_{t-1})\\right]$ , but not on $\\mathbb{E}_{\\pi_{t}}\\left[\\hat{F}_{\\gamma_{t}|j}(h,U_{t}^{\\mathrm{val}}\\circ\\hat{\\pi}_{t-1})\\right]$ . Also note that $S_{t}$ is part of both $U_{t}^{\\mathrm{train}}$ and $U_{t}^{\\mathrm{val}}$ (see Figure 1 in Appendix A for a graphical illustration). In other words, when we evaluate the bounds we can use additional data. And even though the additional data can only be used in the evaluation stage, we can still use the knowledge that we will get more data for evaluation when we construct $\\pi_{t}^{*}$ . For example, we can take ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\pi_{1}^{*}=\\arg\\operatorname*{min}_{\\pi}\\operatorname{kl}^{-1,+}\\left(\\mathbb{E}_{\\pi}[\\hat{L}(h,S_{1})],\\frac{\\mathrm{KL}(\\pi\\|\\pi_{0}^{*})+\\ln\\frac{2T\\sqrt{n}}{\\delta}}{n}\\right)\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "and for $t\\geq2$ ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\pi_{t}^{*}=\\arg\\operatorname*{min}_{\\pi}\\sum_{j=1}^{3}(b_{t|j}-b_{t|j-1})\\operatorname{kl}^{-1,+}\\left(\\mathbb{E}_{\\pi}\\left[\\hat{F}_{\\gamma_{t}|j}(h,S_{t}\\circ\\hat{\\pi}_{t-1}^{*})\\right],\\frac{\\mathrm{KL}(\\pi\\|\\pi_{t-1}^{*})+\\ln\\frac{6T\\sqrt{n_{t}^{*1}}}{\\delta}}{n_{t}^{\\mathrm{val}}}\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The empirical losses above are calculated on $S_{t}$ corresponding to $\\pi_{t}^{*}$ , but the sample sizes $n_{t}^{\\mathrm{val}}$ correspond to the size of the validation set $U_{t}^{\\mathrm{val}}$ rather than the size of $S_{t}$ . This allows to be more aggressive in deviating with $\\pi_{t}^{*}$ from $\\pi_{t-1}^{*}$ by sustaining larger $\\mathrm{KL}(\\pi_{t}^{*}||\\pi_{t-1}^{*})$ terms. ", "page_idx": 6}, {"type": "text", "text": "\u2022 Similarly, $\\gamma_{2},\\dots,\\gamma_{T}$ can also be constructed sequentially, as long as $\\gamma_{t}$ only depends on $U_{t-1}^{\\mathrm{trair}}$ (otherwise $\\hat{F}_{\\gamma_{t}|j}(h,S_{t}\\circ\\hat{\\pi}_{t-1}^{*})$ becomes a biased estimate of $F_{\\gamma_{t},\\pi_{t-1}^{*}|j}(h))$ . ", "page_idx": 6}, {"type": "text", "text": "\u2022 We naturally want to have improvement over recursion steps, meaning $\\mathrm{B}_{t}(\\pi_{t}^{*})<\\mathrm{B}_{t-1}(\\pi_{t-1}^{*})$ . Plugging this into (3), we obtain $\\mathcal{E}(\\pi_{t}^{*},\\gamma_{t})+\\gamma_{t}B_{t-1}(\\pi_{t-1}^{*})<B_{t-1}(\\pi_{t-1}^{*})$ , which implies that we want $\\gamma_{t}$ to be sufficiently small to satisfy $\\begin{array}{r}{\\gamma_{t}<1-\\frac{\\mathcal{E}_{t}\\left(\\pi_{t}^{*},\\gamma_{t}\\right)}{B_{t-1}\\left(\\pi_{t-1}^{*}\\right)}}\\end{array}$ BEtt\u2212(1\u03c0(t \u03c0,t\u2217\u03b3\u2212t)1). At the same time, \u03b3t should be non-negative. Therefore, improvement over recursion steps can only be maintained as long as $\\mathcal{E}_{t}(\\pi_{t}^{*},\\gamma_{t})<B_{t-1}(\\pi_{t-1}^{*})$ . We note that $\\gamma_{t}\\operatorname{B}_{t-1}(\\pi_{t-1}^{*})$ term in (3) is linearly increasing in $\\gamma_{t}$ , whereas $\\mathcal{E}(\\pi_{t}^{*},\\gamma_{t})$ is decreasing in $\\gamma_{t}$ . The value of $\\gamma_{t}$ that minimizes the trade-off depends on the data. Even though it is not allowed to use $U_{t}^{\\mathrm{val}}$ for tuning $\\gamma_{t}$ , it is possible to take a grid of values of $\\gamma_{t}$ and a union bound over the grid, and then select the best value from the grid based the value of the bound evaluated on $U_{t}^{\\mathrm{val}}$ . ", "page_idx": 6}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we provide an empirical comparison of our Recursive PAC-Bayes (RPB) procedure to the following prior work: i) Uninformed priors (Uninformed), (Dziugaite and Roy, 2017); ii) Datainformed priors (Informed) (Ambroladze et al., 2007, P\u00e9rez-Ortiz et al., 2021); iii) Data-informed prior $^+$ excess loss (Informed $^+$ Excess) (Mhammedi et al., 2019, Wu and Seldin, 2022). All the experiments were run on a laptop. The source code for replicating the experiments is available at Github1. ", "page_idx": 6}, {"type": "text", "text": "We start with describing the details of the optimization procedure, and then present the results. ", "page_idx": 6}, {"type": "text", "text": "5.1 Details of the optimization and evaluation procedure ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We constructed $\\pi_{1}^{*},\\dots,\\pi_{T}^{*}$ sequentially using the optimization objective, (4) for $\\pi_{1}^{*}$ and (5) for $\\pi_{2}^{*}$ to $\\pi_{T}^{*}$ , and computed the bound using the recursive procedure in Theorem 5. There are a few technical details concerning convexity of the optimization procedure and infinite size of the set of prediction rules $\\mathcal{H}$ that we address next. ", "page_idx": 6}, {"type": "text", "text": "1https://github.com/pyijiezhang/rpb ", "page_idx": 6}, {"type": "text", "text": "5.1.1 Convexification of the loss functions ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The functions $f_{\\gamma_{t}|j}(h,(X,Y,h^{\\prime}))$ defined in Section 4 are non-convex and non-differentiable: $f_{\\gamma_{t}|j}(h,(X,Y,h^{\\prime}))=\\mathbb{1}\\big(f_{\\gamma_{t}}(h,(X,Y,h^{\\prime}))\\ge b_{t|j}\\big)=\\mathbb{1}\\big(\\ell(h(X),Y)-\\gamma_{t}\\ell(h^{\\prime}(X),Y)\\ge b_{t|j}\\big)$ . In order to facilitate optimization, we approximate the external indicator function $\\mathbb{1}(z\\geq z_{0})$ by a sigmoid function $\\omega(z;c_{1},z_{0})=(1+\\exp(c_{1}(z-z_{0})))^{-1}$ with a fixed parameter $c_{1}>0$ specified in Appendix B.3. ", "page_idx": 7}, {"type": "text", "text": "Furthermore, since the zero-one loss $\\ell(h(X),Y)$ is also non-differentiable, we adopt the cross-entropy loss, as in most modern training procedures (P\u00e9rez-Ortiz et al., 2021). Specifically, for a $k$ -class classification problem, let $h:\\bar{\\mathcal{X}}\\,\\bar{\\to}\\,\\mathbb{R}^{k}$ represent the function implemented by the neural network, assigning each class a real value. Let $u=h(X)$ be the assignment, with $u_{i}$ being the $i$ -th value of the vector. To convert this real-valued vector into a probability distribution over classes, we apply the softmax function $\\sigma:\\mathbb{R}^{k}\\rightarrow\\Delta^{k-1}$ , where $\\begin{array}{r}{\\sigma(u)_{i}\\stackrel{}{=}\\exp(c_{2}\\stackrel{.}{u}_{i})/\\sum_{j}\\exp(c_{2}u_{j})}\\end{array}$ for some $c_{2}>0$ for each entry. The cross-entropy loss $\\ell^{\\mathrm{ce}}:\\mathbb{R}^{k}\\times[k]\\rightarrow\\mathbb{R}$ is defined by $\\ell^{\\mathrm{{ce}}}(u,Y)=-\\log(\\sigma(u)_{Y})$ . However, since this loss is unbounded, whereas the PAC-Bayes-kl bound requires losses within $[0,1]$ , we enforce a $[0,1]$ -valued cross-entropy loss by mixing the output distribution with a uniform distribution $\\sigma(u)$ , i.e., $\\bar{\\tilde{\\sigma}}(u)_{i}=(1-p_{\\operatorname*{min}})\\sigma(u)_{i}+p_{\\operatorname*{min}}/k$ for all $i\\in[k]$ and for some $p_{\\operatorname*{min}}>0$ , and then rescaling it to $[0,1]$ by taking $\\tilde{\\ell}^{\\mathrm{ce}}(u,Y)=-\\log(\\tilde{\\sigma}(u)_{Y})/\\log(k/p_{\\operatorname*{min}}).$ . ", "page_idx": 7}, {"type": "text", "text": "We emphasize that in the evaluation of the bound (using Theorem 5), we directly compute the zero-one loss and the $f_{\\gamma_{t}|j}$ functions without employing the approximations. ", "page_idx": 7}, {"type": "text", "text": "5.1.2 Relaxation of the PAC-Bayes-kl bound ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The PAC-Bayes-kl bound is often criticized for being unfriendly to optimization (Rodr\u00edguez-G\u00e1lvez et al., 2024). Therefore, several relaxations have been proposed, including the PAC-Bayes-classic bound (McAllester, 1999), the PAC-Bayes- $\\cdot\\lambda$ bound (Thiemann et al., 2017), and the PAC-Bayesquadratic bound (Rivasplata et al., 2019, P\u00e9rez-Ortiz et al., 2021), among others. In our optimization we have adopted the bound of McAllester (1999) instead of the kl-based bounds in Equation (5). ", "page_idx": 7}, {"type": "text", "text": "We again emphasize that in the evaluation of the bound we used the kl-based bounds in Theorem 5. ", "page_idx": 7}, {"type": "text", "text": "5.1.3 Estimation of $\\mathbb{E}_{\\pi}[\\cdot]$ ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Due to the infinite size of $\\mathcal{H}$ and lack of a closed-form expression for $\\mathbb{E}_{\\pi_{1}}[\\hat{L}(h,S)]$ and $\\mathbb{E}_{\\pi_{t}}[\\hat{F}_{\\gamma_{t}|j}(h,U_{t}^{\\mathrm{val}}\\circ\\hat{\\pi}_{t-1}^{*})]$ appearing in Theorem 5, we approximate them by sampling (P\u00e9rezOrtiz et al., 2021). For optimization, we sample one classifier for each mini-batch during stochastic gradient descent. For evaluation, we sample one classifier for each data in the corresponding evaluation dataset. Due to approximation of the empirical quantities the final bound in Theorem 5 requires an additional concentration bound. (We note that the extra bound is only required for computation of the final bound, but not for optimization of $\\hat{\\pi}_{t}^{*}$ .) Specifically, let $\\hat{\\pi}_{t}^{*}=\\{h_{1}^{\\bar{\\pi}_{1}},h_{2}^{\\pi_{t}},\\ldots,h_{m}^{\\bar{\\pi_{t}}}\\}$ be $m$ prediction rules sampled independently according to $\\pi_{t}$ . Then for any function $f(h)$ taking values in $[0,1]$ (which is the case for $\\hat{L}(h,S)$ and $\\hat{F}_{\\gamma_{t}|j}(h,U_{t}^{\\mathrm{val}}\\circ\\hat{\\pi}_{t-1}^{*}))$ and $\\delta^{\\prime}\\in(0,1)$ we have ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Bigg(\\mathbb{E}_{\\pi_{t}^{*}}[f(h)]\\geq\\mathrm{kl}^{-1,+}\\left(\\frac{1}{m}\\sum_{i=1}^{m}f(h_{i}^{\\pi_{t}^{*}}),\\frac{1}{m}\\log\\frac{1}{\\delta^{\\prime}}\\right)\\Bigg)\\leq\\delta^{\\prime}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "It is worth noting that $\\mathbb{E}_{\\pi_{t}^{*}}\\left[f(h)\\right]$ is evaluated for a fixed $\\pi_{t}^{*}$ , meaning that there is no selection involved, and therefore no $\\mathrm{\\tilde{KL}}$ term appears in the bound above. We, of course, take a union bound over all the quantities being estimated. ", "page_idx": 7}, {"type": "text", "text": "5.2 Experimental results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We evaluated our approach and compared it to prior work using multi-class classification tasks on MNIST (LeCun and Cortes, 2010) and Fashion MNIST (Xiao et al., 2017) datasets, both with 60000 training data. The experimental setup was based on the work of Dziugaite and Roy (2017) and P\u00e9rez-Ortiz et al. (2021). Similar to them we used Gaussian distributions for all the priors and posteriors, modeled by probabilistic neural networks. Technical details are provided in B. ", "page_idx": 7}, {"type": "text", "text": "The empirical evaluation is presented in Table 1. For the Uninformed approach, we trained and evaluated the bound using the entire training dataset directly. For the other two baseline methods, Informed and Informed $^+$ Excess Loss, we used half of the training data to train the informed prior and an ERM $h^{*}$ for the excess loss, and the other half to learn the posterior. For our Recursive PAC-Bayes, we chose $\\gamma_{t}=1/2$ for all $t$ , and conducted experiments with $T=2,4,6,8$ to study the impact of recursion depth. (Each value of $T$ corresponded to a separate run of the algorithm and a separate evaluation of the bound, i.e., they should not be seen as successive refinements.) We applied a geometric data split. Specifically, for $T\\,=\\,2$ the split was (30000, 30000) points; for $T=4$ , it was (7500, 7500, 15000, 30000); for $T=6$ it was (1875, 1875, 3750, 7500, 15000, 30000); and for $T=8$ , it was (469, 469, 937, 1875, 3750, 7500, 15000, 30000). This approach allowed the early recursion steps, which had fewer data points, to efficiently learn the prior, while preserving enough data for fine-tuning in the later steps. Note that with this approach the value of $\\bar{n_{t}^{\\mathrm{val}}}=|\\bar{U_{t}^{\\mathrm{val}}}|=\\bar{\\sum_{s=t}^{T}|S_{s}|}$ , which is in the denominator of the bounds in Theorem 5, is at least $\\begin{array}{l}{{\\frac{n}{2}}}\\end{array}$ . ", "page_idx": 8}, {"type": "table", "img_path": "PQt6Vg2X5u/tmp/828133177e63439fa93420d5f94a1ceae9eccf45909b423c041546ea7f768b02.jpg", "table_caption": ["Table 1: Comparison of the classification loss of the final posterior $\\rho$ on the entire training data, $\\mathbb{E}_{\\rho}[\\hat{L}(h,S)]$ (Train 0-1), and on the testing data, $\\mathbb{E}_{\\rho}[\\hat{L}(h,S^{\\mathrm{test}})]$ (Test 0-1), and the corresponding bounds for each method on MNIST and Fashion MNIST. We report the mean and one standard deviation over 5 repetitions. \u201cUnif.\u201d abbreviates the Uniform approach, \u201cInf.\u201d the Informed, \u201cInf. $^+$ Ex.\u201d the Informed $^+$ Excess Loss, and \u201cRPB\u201d the Recursive PAC-Bayes. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Table 1 shows that even with only $T=2$ , which corresponds to the data split used in the Informed and the Informed $^+$ Excess Loss approaches, RPB achieves better test performance than prior work. As the recursion deepens, further improvements in both the test error and the bound are observed. We note that while the bound for $T=2$ is looser compared to the Informed $^+$ Excess Loss method, deeper recursion yields bounds that are tighter. Overall, deep recursion provides substantial improvements in the bound and the test error relative to prior work. ", "page_idx": 8}, {"type": "text", "text": "Tables 2 and 3 provide a glimpse into the training progress of RPB with $T=8$ by showing the evolution of the key quantities along the recursive process. Similar tables for other values of $T$ are provided in Appendix B.4, along with training details for other methods. The tables show an impressive reduction of the KL term and significant improvement of the bound as the recursion proceeds, demonstrating effectiveness of the approach. ", "page_idx": 8}, {"type": "table", "img_path": "PQt6Vg2X5u/tmp/bac96ed4847cf53a69c225b7afc4dcaebacb7e527090fd2d7cb1e436a10db5da.jpg", "table_caption": ["Table 2: Insight into the training process of the Recursive PAC-Bayes for $T=8$ on MNIST. The table shows the evolution of $\\mathcal{E}_{t}(\\pi_{t}^{*},\\gamma_{t})$ , $B_{t}(\\pi_{t}^{*})$ , and other quantities as the training progresses with $t$ . We define $\\begin{array}{r}{\\hat{F}_{\\gamma_{t}}(h,U_{t}^{\\mathrm{val}}\\circ\\hat{\\pi}_{t-1})=-\\gamma_{t}+\\sum_{j=1}^{3}(b_{t|j}-b_{t|j-1})\\hat{F}_{\\gamma_{t}|j}(h,U_{t}^{\\mathrm{val}}\\circ\\hat{\\pi}_{t-1}).}\\end{array}$ "], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "PQt6Vg2X5u/tmp/e4c17176f05c3a9e4be3a338b7134eff1b5933485cc9ea643829158619b4920d.jpg", "table_caption": ["Table 3: Insight into the training process of the Recursive PAC-Bayes for $T=8$ on Fashion MNIST. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "6 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We have presented the first PAC-Bayesian bound that supports sequential prior updates and preserves confidence information on the prior. The work closes a long-standing gap between Bayesian and Frequentist learning by making sequential data processing and sequential updates of prior knowledge meaningful and beneficial in the frequentist framework, as it has always been in the Bayesian framework. We have shown that apart from theoretical beauty the approach is highly beneficial in practice. ", "page_idx": 9}, {"type": "text", "text": "The Recursive PAC-Bayes framework is extremely rich and powerful, and leads to numerous directions for future research, some of which we briefly sketch next. ", "page_idx": 9}, {"type": "text", "text": "\u2022 The decomposition in (2) applies to any loss function, including unbounded losses. It would be interesting to find additional applications to it.   \n\u2022 While we have restricted ourselves to the zero-one loss function to illustrate the use of PACBayes-split-kl, the results can be directly generalized to any bounded loss function by replacing PAC-Bayes-split-kl with PAC-Bayes-Empirical-Bernstein or PAC-Bayes-Unexpected-Bernstein, and deriving the corresponding analogue of Theorem 5 (which is straightforward).   \n\u2022 We have shown that the bound works well with geometric split of the data, but there are many other ways to split the data which could be studied.   \n\u2022 There is also a lot of space for experimentation with optimization of $\\gamma_{t}$ .   \n\u2022 It would be interesting to study how the bound will perform in sequential learning settings, where the data arrives sequentially, and thus the partition is dictated externally.   \n\u2022 There are many interesting research directions from the computational perspective. We note that for base models with linear computational complexity (e.g., neural networks) the overhead of recursion is relatively small and optimization time of Recursive PAC-Bayes is comparable to processing all data at once or in two chunks (as in data-dependent priors). For base models with superlinear computational complexity (e.g., kernel SVMs) sequential training of several small models in the recursion may actually be cheaper than training a big model based on all the data. Moreover, since the bound in Theorem 5 holds for any sequence of distributions $\\pi_{0}^{*}$ $\\tau_{0}^{*},\\pi_{1}^{*},\\ldots,\\pi_{T}^{*}$ , the optimization in equation (5) is allowed to be approximate. Considering that the improvement of the bounds and the test loss relative to prior work was very significant, there is space to look at the trade-off between statistical power and computational complexity. Namely, it may potentially be possible to relax the approximation of arg min in equation (5) to gain computational speed-up at the cost of only a small compromise on the bounds and test losses.   \n\u2022 We note that it is possible to start the recursion at $\\pi_{0}$ . Namely, it is possible to use, for example, Theorem 2 to bound $\\mathbb{E}_{\\pi_{0}}[L(h)]$ using all the data, and apply the recursive decomposition (2) starting from $\\pi_{1}$ . Whether this would yield an advantage relative to starting the recursion at $\\pi_{1}$ , as we did, remains to be studied. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "YW acknowledges support from the Novo Nordisk Foundation, grant number NNF21OC0070621. YZ acknowledge Ph.D. funding from Novo Nordisk A/S. BECA acknowledges funding from the ANR grant project BACKUP ANR-23-CE40-0018-01. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Amiran Ambroladze, Emilio Parrado-Hern\u00e1ndez, and John Shawe-Taylor. Tighter PAC-Bayes bounds. In Advances in Neural Information Processing Systems (NeurIPS), 2007.   \nFelix Biggs and Benjamin Guedj. Tighter PAC-Bayes generalisation bounds by leveraging example difficulty. In Proceedings on the International Conference on Artificial Intelligence and Statistics (AISTATS), 2023.   \nBen Chugg, Hongjian Wang, and Aaditya Ramdas. A unified recipe for deriving (time-uniform) PAC-Bayes bounds. Journal of Machine Learning Research, 24(372), 2023.   \nThomas M. Cover and Joy A. Thomas. Elements of Information Theory. Wiley Series in Telecommunications and Signal Processing, 2nd edition, 2006.   \nGintare Karolina Dziugaite and Daniel M. Roy. Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data. In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), 2017.   \nAndrew Foong, Wessel Bruinsma, David Burt, and Richard Turner. How tight can pac-bayes be in the small data regime? In Advances in Neural Information Processing Systems (NeurIPS), 2021.   \nAndrew Y. K. Foong, Wessel P. Bruinsma, and David R. Burt. A note on the chernoff bound for random variables in the unit interval. arXiv preprint arXiv.2205.07880, 2022.   \nMaxime Haddouche and Benjamin Guedj. PAC-Bayes generalisation bounds for heavy-tailed losses through supermartingales. Transactions on Machine Learning Research Journal, 2023.   \nKyoungseok Jang, Kwang-Sung Jun, Ilja Kuzborskij, and Francesco Orabona. Tighter PAC-Bayes bounds through coin-betting. In Proceedings of the Conference on Learning Theory (COLT), 2023.   \nJohn Langford. Tutorial on practical prediction theory for classification. Journal of Machine Learning Research, 6, 2005.   \nYann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010. URL http://yann. lecun.com/exdb/mnist/.   \nAndreas Maurer. A note on the PAC-Bayesian theorem. arXiv preprint cs/0411099, 2004.   \nDavid McAllester. Some PAC-Bayesian theorems. In Proceedings of the Conference on Learning Theory (COLT), 1998.   \nDavid McAllester. Some PAC-Bayesian theorems. Machine Learning, 37, 1999.   \nZakaria Mhammedi, Peter Gr\u00fcnwald, and Benjamin Guedj. PAC-Bayes un-expected Bernstein inequality. In Advances in Neural Information Processing Systems (NeurIPS), 2019.   \nMar\u00eda P\u00e9rez-Ortiz, Omar Rivasplata, John Shawe-Taylor, and Csaba Szepesv\u00e1ri. Tighter risk certificates for neural networks. Journal of Machine Learning Research, 2021.   \nOmar Rivasplata, Vikram M Tankasali, and Csaba Szepesvari. Pac-bayes with backprop. arXiv preprint arXiv:1908.07380, 2019.   \nBorja Rodr\u00edguez-G\u00e1lvez, Ragnar Thobaben, and Mikael Skoglund. More PAC-Bayes bounds: From bounded losses, to losses with general tail behaviors, to anytime validity. Journal of Machine Learning Research, 25(110), 2024.   \nMatthias Seeger. PAC-Bayesian generalization error bounds for Gaussian process classification. Journal of Machine Learning Research, 3, 2002.   \nJohn Shawe-Taylor and Robert C. Williamson. A PAC analysis of a Bayesian estimator. In Proceedings of the Conference on Learning Theory (COLT), 1997.   \nNiklas Thiemann, Christian Igel, Olivier Wintenberger, and Yevgeny Seldin. A strongly quasiconvex PAC-Bayesian bound. In Proceedings of the International Conference on Algorithmic Learning Theory (ALT), 2017.   \nIlya Tolstikhin and Yevgeny Seldin. PAC-Bayes-Empirical-Bernstein inequality. In Advances in Neural Information Processing Systems (NeurIPS), 2013.   \nYi-Shan Wu and Yevgeny Seldin. Split-kl and PAC-Bayes-split-kl inequalities for ternary random variables. In Advances in Neural Information Processing Systems (NeurIPS), 2022.   \nYi-Shan Wu, Andres Masegosa, Stephan Sloth Lorenzen, Christian Igel, and Yevgeny Seldin. Chebyshev-cantelli pac-bayes-bennett inequality for the weighted majority vote. In Advances in Neural Information Processing Systems (NeurIPS), 2021.   \nHan Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-MNIST: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Illustrations ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "In this appendix we provide graphical illustrations of the basic concepts presented in the paper. ", "page_idx": 12}, {"type": "table", "img_path": "PQt6Vg2X5u/tmp/913ab23b96026a0840ea1a92664f4595c7aa48afa93f771fbd097016df017d24.jpg", "table_caption": [], "table_footnote": [], "page_idx": 12}, {"type": "image", "img_path": "PQt6Vg2X5u/tmp/8a2e0ae4ad0a3b74e33cb8a3cfc4de925b3d6d18f78702688d4df02c7f0c9b04.jpg", "img_caption": [], "img_footnote": [], "page_idx": 13}, {"type": "text", "text": "Figure 2: Decomposition of a discrete random variable into a superposition of binary random variables. The figure illustrates a decomposition of a discrete random variable $Z$ with domain of four values $b_{0}\\,<\\,b_{1}\\,<\\,b_{2}\\,<\\,b_{3}$ into a superposition of three binary random variables, $Z=$ $\\begin{array}{r}{b_{0}+\\sum_{j=1}^{3}\\alpha_{j}Z_{|j}}\\end{array}$ . A way to think about the decomposition is to compare it to a progress bar. In the illustration $Z$ takes value $b_{2}$ , and so the random variables $Z_{|1}$ and $Z_{\\parallel2}$ corresponding to the first two segments \u201clight up\u201d (take value 1), whereas the random variable $Z_{|3}$ corresponding to the last segment remains \u201cturned off\u201d (takes value 0). The value of $Z$ equals the sum of the lengths $\\alpha_{j}$ of the \u201clighted up\u201d segments. ", "page_idx": 13}, {"type": "text", "text": "B Experimental details ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we provide the details of the datasets in Appendix B.1, our neural network architectures in Appendix B.2, and other details in Appendix B.3. We provide further statistics for all the methods on both datasets in Appendix B.4. ", "page_idx": 13}, {"type": "text", "text": "B.1 Datasets ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We perform our evaluation on two datasets, MNIST (LeCun and Cortes, 2010) and Fashion MNIST (Xiao et al., 2017). We will introduce these two datasets in the following. ", "page_idx": 13}, {"type": "text", "text": "B.1.1 MNIST ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The MNIST (Modified National Institute of Standards and Technology) dataset is one of the most renowned and widely used datasets in the field of machine learning, particularly for training and testing in the domain of image processing and computer vision. It consists of a large collection of handwritten digit images, spanning the numbers 0 through 9. ", "page_idx": 13}, {"type": "text", "text": "The MNIST dataset comprises a total of 70,000 grayscale images of handwritten digits, where the training set has 60,000 images and the test set has 10,000 images. Each image in the dataset is $28\\mathrm{x}28$ pixels, resulting in a total of 784 pixels per image. The images are in grayscale, with pixel values ranging from 0 (black) to 255 (white). Each image is associated with a label from 0 to 9, indicating the digit that the image represents. The images are typically stored in a single flattened array of 784 elements, although they can also be represented in a $28\\mathrm{x}28$ matrix format. ", "page_idx": 13}, {"type": "text", "text": "B.1.2 Fashion MNIST ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The Fashion MNIST dataset is a contemporary alternative to the traditional MNIST dataset, created to provide a more challenging benchmark for machine learning algorithms. It consists of images of various clothing items and accessories, offering a more complex and varied dataset for image classification tasks. ", "page_idx": 13}, {"type": "text", "text": "The Fashion MNIST dataset contains a total of 70,000 grayscale images, where the training set has 60,000 images and the test set has 10,000 images. Each image in the dataset is $28\\mathrm{x}28$ pixels, resulting in a total of 784 pixels per image. The images are in grayscale, with pixel values ranging from 0 (black) to 255 (white). Each image is associated with one of 10 categories, representing different types of fashion items. The categories are: 1. T-shirt/top 2. Trouser 3. Pullover 4. Dress 5. Coat 6. Sandal 7. Shirt 8. Sneaker 9. Bag 10. Ankle boot. Similar to MNIST, the images are stored in a single flattened array of 784 elements but can also be represented in a $28\\mathrm{x}28$ matrix format. ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "B.2 Neural network architectures ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "For all methods, we adopt a family of factorized Gaussian distributions to model both priors and posteriors, characterized by the form $\\boldsymbol{\\pi}=\\mathcal{N}(w,\\sigma\\mathbf{I})$ where $w\\in\\mathbb{R}^{d}$ denotes the mean vector, and $\\sigma$ represents the scalar variance. We use feedforward neural networks for the MNIST dataset (LeCun and Cortes, 2010), while using convolutional neural networks for the Fashion MNIST dataset (Xiao et al., 2017). ", "page_idx": 14}, {"type": "text", "text": "Both our feedforward neural network and convolutional neural network are probabilistic, and each layer has a factorized (i.e. mean-field) Gaussian distribution. ", "page_idx": 14}, {"type": "text", "text": "Our feedforward neural network has the following architecture: ", "page_idx": 14}, {"type": "text", "text": "1. Input layer. Input size: $28\\times28$ (flattened to 784 features).   \n2. Probabilistic linear layer 1. Input features: 784, output features: 600, activation: ReLU.   \n3. Probabilistic linear layer 2. Input features: 600, output features: 600, activation: ReLU.   \n4. Probabilistic linear layer 3. Input features: 600, output features: 600, activation: ReLU.   \n5. Probabilistic linear layer 4. Input features: 600, output features: 10, activation: Softmax. ", "page_idx": 14}, {"type": "text", "text": "Our convolutional neural network has the following architecture: ", "page_idx": 14}, {"type": "text", "text": "1. Input layer. Input size: $1\\times28\\times28$ .   \n2. Probabilistic convolutional layer 1. Input channels: 1, output channels: 32, kernel size: 3x3, activation: ReLU.   \n3. Probabilistic convolutional layer 2. Input channels: 32, output channels: 64, kernel size: 3x3, activation: ReLU.   \n4. Max pooling layer. Pooling size: $2\\mathtt{x}2$ .   \n5. Flattening layer. Flattens the output from the previous layers into a single vector.   \n6. Probabilistic linear layer 1. Input features: 9216, output features: 128, activation: ReLU.   \n7. Probabilistic linear layer 2 (output layer). Input features: 128, output features: 10, activation: Softmax. ", "page_idx": 14}, {"type": "text", "text": "B.3 Other details in the experiments ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "General for all methods The methods in comparisons are trained and evaluated using the procedure described in Section 2 and visually illustrated in Figure 1. We will provide some further details for each method later in the following. For all methods in comparison, we apply the optimization and evaluation method described in Section 5.1. For the approximation described in Section 5.1.1, we set the parameters $c_{1}=c_{2}=5$ . The lower bound for the prediction $p_{\\mathrm{min}}=1e\\mathrm{~-~}5$ . The $\\delta$ in our bound and all the other methods is selected to be $\\delta=0.025$ . As mentioned in Section 5.1.2, we use the PAC-Bayes-classic bound by McAllester in replacement of PAC-Bayes-kl when doing optimization. Note that for all methods, we also have to estimate the empirical loss of the posterior $\\mathbb{E}_{\\pi}[\\cdot]$ described in Section 5.1.3. We also allocate the budget for the union bound for the estimation such that these estimations in the bound are controlled with probability at least $1-\\delta^{\\prime}$ , where we chose $\\delta^{\\prime}=0.01$ . Therefore, the ultimate bounds for all methods hold with probability at least $1-\\delta-\\delta^{\\prime}$ . Note that we do not consider such bounds during optimization but only when estimating the bounds. ", "page_idx": 14}, {"type": "text", "text": "For all methods, we adopt a family of factorized Gaussian distributions to model both priors and posteriors of all the learnable parameters of the classifiers, characterized by the form $\\boldsymbol{\\pi}=\\bar{\\mathcal{N}}(\\boldsymbol{w},\\sigma\\mathbf{I})$ where $w\\in\\mathbb{R}^{d}$ denotes the mean vector, and $\\sigma$ represents the scalar variance. For all methods, we initialize an uninformed prior $\\pi_{0}\\,=\\,\\mathcal{N}(w_{0},\\sigma_{0}\\mathbf{I})$ that is independent of data, where the mean is randomly initialized, and the variance $\\sigma_{0}$ is initialized to 0.03 (P\u00e9rez-Ortiz et al., 2021). ", "page_idx": 14}, {"type": "text", "text": "In the training process of all methods in our experiments, we set the batch size to 250, the number of training epochs to 200, and use stochastic gradient descent with a learning rate of 0.005 and a momentum of 0.95. ", "page_idx": 15}, {"type": "text", "text": "Uninformed priors We take $\\pi_{0}$ defined above as the uninformed prior. We then learn the posterior $\\rho$ from the prior using the entire training dataset $S$ , applying a PAC-Bayes bound. We evaluate the bound using, again, the entire training dataset $S$ . ", "page_idx": 15}, {"type": "text", "text": "Data-informed priors We start with the same $\\pi_{0}$ as the uninformed prior. We train the informed prior $\\pi_{1}$ using $S_{1}$ with $|S_{1}|=|S|/2$ by minimizing a PAC-Bayes bound. The posterior $\\rho$ is then learned using the informed prior $\\pi_{1}$ and the subset $S_{2}$ with $|\\bar{S_{2}}|=|S|/2$ , again by minimizing a PAC-Bayes bound. The bound is evaluated using $S_{2}$ . ", "page_idx": 15}, {"type": "text", "text": "Data-informed priors $^{+}$ excess loss We train the informed prior $\\pi_{1}$ and the reference classifier $h^{*}$ using $S_{1}$ that contains half of the training dataset. $\\pi_{1}$ is obtained by minimizing a PAC-Bayes bound with the uninformed prior $\\pi_{0}$ , while the reference classifier $h^{*}$ is obtained by an empirical risk minimizer (ERM). The posterior $\\rho$ is obtained by minimizing a PAC-Bayes bound on the excess loss between $\\rho$ and $h^{*}$ . The prior used in the bound for both training and evaluation is the data-informed prior $\\pi_{1}$ . Therefore, the data for both training and evaluation of $\\rho$ must be the other half of data $S_{2}$ . ", "page_idx": 15}, {"type": "text", "text": "B.4 Further results for the experiments ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we report some more statistics for all methods. ", "page_idx": 15}, {"type": "text", "text": "For all methods, to calculate the classification loss of $\\rho$ on the testing data, $\\mathbb{E}_{\\rho}[\\hat{L}(h,S^{\\mathrm{test}})]$ (Test 0-1), we sample one classifier for each data. The train 0-1 loss for all methods is computed on the entire training dataset $S$ , while the test 0-1 loss for all methods is computed on the test dataset $S_{\\mathrm{test}}$ . ", "page_idx": 15}, {"type": "text", "text": "B.4.1 Recursive PAC-Bayes ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We report the additional results of Recursive PAC-Bayes on MNIST with $T=2$ in Table 4, $T=4$ in Table 5, and $T=6$ in Table 6. We report Recursive PAC-Bayes on Fashion MNIST with $T=2$ in Table 7, $T=4$ in Table 8, and $T=6$ in Table 9. ", "page_idx": 15}, {"type": "table", "img_path": "PQt6Vg2X5u/tmp/194abf6b294498de360ae03f61341a527663b073e680e2e526c39056ae10230a.jpg", "table_caption": ["Table 4: Insight into the training process of the Recursive PAC-Bayes for $T=2$ on MNIST. "], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "PQt6Vg2X5u/tmp/43924a3a641af775cfafea5edda54fb5d213c693dc32b4b7c328b5d31a5f0a09.jpg", "table_caption": ["Table 5: Insight into the training process of the Recursive PAC-Bayes for $T=4$ on MNIST. "], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "PQt6Vg2X5u/tmp/e4fc775c8d2068c3ca9fc68fed1f570b55cab2892117b2a3c09a4325c992fc4c.jpg", "table_caption": ["Table 6: Insight into the training process of the Recursive PAC-Bayes for $T=6$ on MNIST. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "Table 7: Insight into the training process of the Recursive PAC-Bayes for $T=2$ on Fashion MNIST. ", "page_idx": 16}, {"type": "table", "img_path": "PQt6Vg2X5u/tmp/61fa256b565f1fce38688665b4b7cd082c56ceb62ffc5e819ba3fc6b249b3c72.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "table", "img_path": "PQt6Vg2X5u/tmp/7e8752817a98f5f6431abad8e6c947122b59c71783a2d50b8063b8be2da3d176.jpg", "table_caption": ["Table 8: Insight into the training process of the Recursive PAC-Bayes for $T=4$ on Fashion MNIST. "], "table_footnote": [], "page_idx": 16}, {"type": "table", "img_path": "PQt6Vg2X5u/tmp/d742c611bd4ec7757cb013bc4b16ef6145435955e7c4011e92cdd23d21123045.jpg", "table_caption": ["Table 9: Insight into the training process of the Recursive PAC-Bayes for $T=6$ on Fashion MNIST. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "B.4.2 Uninformed priors ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We report the additional results of uninformed priors (McAllester, 1998) on MNIST and Fashion MNIST in Table 10. As described earlier in Section 2, Section 5, and Section B.3, we evaluate the bound using the entire training set. ", "page_idx": 16}, {"type": "text", "text": "Table 10: Further details to compute the bound for the uninformed prior approach on MNIST and Fashion MNIST. ", "page_idx": 16}, {"type": "table", "img_path": "PQt6Vg2X5u/tmp/808957085bba530345141c81d8a61e12de8aba7d73039dd241983d0c5d5200d5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "B.4.3 Data-informed priors ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We report the additional results of data-informed priors (Ambroladze et al., 2007) on MNIST and Fashion MNIST in Table 11. As described earlier in Section 2, Section 5, and Section B.3, we evaluate the bound using $S_{2}$ that is independent of the data-informed prior $\\pi_{1}$ . ", "page_idx": 16}, {"type": "text", "text": "Table 11: Further details to compute the bound for the data-informed prior on MNIST and Fashion MNIST. ", "page_idx": 16}, {"type": "text", "text": "$\\mathbb{E}_{\\rho}[\\hat{L}(h,S_{2})]$ KL|(S\u03c1\u2225|\u03c00) Bound Test 0-1 MNIST .376 (8e-4) 8e-4 (9e-6) .408 (9e-4) .371 (6e-3) F-MNIST .412 (1e-3) 4e-4 (7e-6) .440 (1e-3) .413 (6e-3) ", "page_idx": 16}, {"type": "text", "text": "B.4.4 Data-informed priors $^+$ excess loss ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We report the additional results of data-informed priors $^+$ excess loss (Mhammedi et al., 2019) on MNIST and Fashion MNIST in Table 12 and 13. As described earlier in Section 2, Section 5, and Section B.3, we evaluate the bound using $S_{2}$ that is independent of the data-informed prior $\\pi_{1}$ and the reference prediction rule $h^{*}$ . The bound is composed of two parts: a bound on the excess loss of $\\rho$ with respect to $h^{*}$ (Excess bound) and a single hypothesis bound on $h^{*}$ $h^{*}$ bound). We report the two components of the bound in Table 12. We provide further details to compute these bounds from the losses of their corresponding quantities in Table 13. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "Table 12: Details to compute the bound for the data-informed prior and excess loss on MNIST and Fashion MNIST. The table shows the bound on the excess loss of $\\rho$ with respect to $h^{*}$ (Excess bound) and a single hypothesis bound on $h^{*}$ ( $h^{*}$ bound). ", "page_idx": 17}, {"type": "table", "img_path": "PQt6Vg2X5u/tmp/f5921d94a941beb9a2194d712e074345dcbd8fcfe5fb54d9e02a3c1ea4141157.jpg", "table_caption": [], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "Table 13: Further details to compute the bound for the data-informed prior and excess loss on MNIST and Fashion MNIST. The table shows the empirical excess loss $\\mathbb{E}_{\\rho}[\\hat{\\Delta}(h,h^{*},S_{2})]$ , where we define $\\Delta(h,h^{*},S_{2})=\\hat{L}(h,S_{2})-\\hat{L}(h^{*},S_{2})$ , and its bound (Excess Bound). It also shows the empirical loss of the reference prediction rule $\\hat{L}(h^{*},S_{2})$ and its bound. The computation of such bound does not involve the KL term. ", "page_idx": 17}, {"type": "text", "text": "$\\mathbb{E}_{\\rho}[\\hat{\\Delta}(h,h^{*},S_{2})]$ $\\frac{\\mathrm{KL}(\\rho\\|\\pi_{1})}{|S_{2}|}$ Ex. Bound $\\hat{L}(h^{*},S_{2})$ $h^{*}$ Bound Bound MNIST -0.011 (3e-3) .035 (5e-4) .162 (1e-3) .026 (4e-4) .029 (4e-4) .192 (2e-3) F-MNIST .104 (6e-3) .018 (5e-4) .196 (5e-3) .112 (1e-3) .145 (1e-3) .342 (6e-3) ", "page_idx": 17}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We tried to write an abstract and an introduction that reflected the rest of the paper as accurately as possible. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 18}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Justification: We have tried to be as honest as possible in setting the framework of this theoretical work and have explicitly mentioned the limiting assumptions of the paper, e.g. i.i.d. data. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 18}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We have clearly stated the assumptions made in the paper, and our theoretical results are accompanied by detailed proofs. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 19}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The datasets are available online and we have tried to provide as much detail as possible to make our experiments transparent and reproducible. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 19}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: The code has been uploaded, the datasets are open source. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so No is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 20}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: We have introduced many different notations to accurately specify the different data splits and parameters used in our framework, and have tried to detail the optimization procedure to make our results as understandable as possible. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 20}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: We provided for each experiment the corresponding standard deviations over different runs of the experiments. Please refer to the tables in the paper for more details. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 20}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 21}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: As mentioned in the paper, all the experiments were run on a personal laptop. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 21}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We have not violated any of the points in the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 21}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: This is a theoretical paper with no specific societal impact. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 21}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 22}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 22}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: The open source datasets we used in the paper were properly cited, namely MNIST (LeCun and Cortes, 2010) and Fashion MNIST (Xiao et al., 2017). ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: We have not released any new assets. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 23}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: Our paper did not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 23}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: Our paper did not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}]