[{"figure_path": "WukSyFSzDt/figures/figures_2_1.jpg", "caption": "Figure 1: Comparison of S-DANE and ACC-S-DANE with DANE for solving a convex quadratic minimization problem. All three methods use GD as the local solver. S-DANE has improved local computation efficiency than DANE while ACC-S-DANE further improves the communication complexity. Finally, the adaptive variants can leverage local dissimilarities to achieve better performance. (The definitions of local smoothness and dissimilarity can be found in Section 6.)", "description": "This figure compares three algorithms (S-DANE, ACC-S-DANE, and DANE) on a convex quadratic minimization problem using gradient descent as the local solver.  It highlights the improved local computation efficiency of S-DANE over DANE and the further communication complexity improvement of ACC-S-DANE.  The adaptive variants of the algorithms are also shown to leverage local dissimilarities for enhanced performance.", "section": "Numerical Experiments"}, {"figure_path": "WukSyFSzDt/figures/figures_9_1.jpg", "caption": "Figure 2: Comparisons of different algorithms for solving the polyhedron feasibility problem.", "description": "This figure compares several algorithms for solving a strongly convex polyhedron feasibility problem, including S-DANE, ACC-S-DANE, GD, DANE-GD, Scaffold, FedProx-GD, and AccGradSliding.  Different settings are shown, varying the number of total clients (n) and the number of clients sampled per round (s). The vertical axis represents the objective function value (f(x) - f*), while the horizontal axis represents the number of communication rounds. The figure demonstrates the superior performance of S-DANE and ACC-S-DANE, particularly in settings with limited client participation (smaller s values).", "section": "Numerical Experiments"}, {"figure_path": "WukSyFSzDt/figures/figures_9_2.jpg", "caption": "Figure 1: Comparison of S-DANE and ACC-S-DANE with DANE for solving a convex quadratic minimization problem. All three methods use GD as the local solver. S-DANE has improved local computation efficiency than DANE while ACC-S-DANE further improves the communication complexity. Finally, the adaptive variants can leverage local dissimilarities to achieve better performance. (The definitions of local smoothness and dissimilarity can be found in Section 6.)", "description": "The figure compares the performance of three algorithms (S-DANE, ACC-S-DANE, and DANE) in solving a convex quadratic minimization problem.  All use gradient descent as the local solver.  The plots illustrate the convergence speed in terms of communication rounds and the number of local gradient calls. S-DANE shows improved local efficiency over DANE, while ACC-S-DANE further improves communication complexity.  The adaptive versions of the algorithms demonstrate the advantage of leveraging local dissimilarities for better performance.", "section": "Numerical Experiments"}, {"figure_path": "WukSyFSzDt/figures/figures_9_3.jpg", "caption": "Figure 1: Comparison of S-DANE and ACC-S-DANE with DANE for solving a convex quadratic minimization problem. All three methods use GD as the local solver. S-DANE has improved local computation efficiency than DANE while ACC-S-DANE further improves the communication complexity. Finally, the adaptive variants can leverage local dissimilarities to achieve better performance. (The definitions of local smoothness and dissimilarity can be found in Section 6.)", "description": "This figure compares the performance of three algorithms (S-DANE, ACC-S-DANE, and DANE) on a convex quadratic minimization problem.  All use gradient descent (GD) as the local solver.  The results show that S-DANE improves local computation efficiency over DANE, and ACC-S-DANE further enhances communication complexity.  The adaptive versions of the algorithms demonstrate the ability to use local dissimilarity for better performance.", "section": "Numerical Experiments"}, {"figure_path": "WukSyFSzDt/figures/figures_30_1.jpg", "caption": "Figure 1: Comparison of S-DANE and ACC-S-DANE with DANE for solving a convex quadratic minimization problem. All three methods use GD as the local solver. S-DANE has improved local computation efficiency than DANE while ACC-S-DANE further improves the communication complexity. Finally, the adaptive variants can leverage local dissimilarities to achieve better performance. (The definitions of local smoothness and dissimilarity can be found in Section 6.)", "description": "This figure compares the performance of three algorithms (DANE, S-DANE, and ACC-S-DANE) on a convex quadratic minimization problem.  All algorithms use gradient descent as the local solver.  The plots show that S-DANE achieves the same communication complexity as DANE but with improved local computation efficiency.  ACC-S-DANE improves upon both communication complexity and local computation efficiency.  Furthermore, adaptive versions of these algorithms demonstrate even better performance by leveraging local dissimilarities.", "section": "Numerical Experiments"}]