{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational model for multimodal contrastive learning, which is central to the current work's data selection methods."}, {"fullname_first_author": "Samir Yitzhak Gadre", "paper_title": "DataComp: In search of the next generation of multimodal datasets", "publication_date": "2023-04-14", "reason": "This paper introduces the DataComp benchmark, which is the primary evaluation metric used to assess the effectiveness of the proposed data selection methods."}, {"fullname_first_author": "Alex Fang", "paper_title": "Data filtering networks", "publication_date": "2023-09-17", "reason": "This paper introduces the DFN model, a state-of-the-art method for data selection that is compared against and combined with the proposed methods in this paper."}, {"fullname_first_author": "Wonjae Kim", "paper_title": "Hype: Hyperbolic entailment filtering for underspecified images and texts", "publication_date": "2024-04-17", "reason": "This paper introduces the HYPE model, another state-of-the-art data selection method, which is compared against and combined with the proposed methods."}, {"fullname_first_author": "Christoph Schuhmann", "paper_title": "LAION-5B: An open large-scale dataset for training next generation image-text models", "publication_date": "2022-12-01", "reason": "This paper introduces the LAION-5B dataset, a large-scale multimodal dataset used in the training of many CLIP-style models and is relevant to the discussion of data quality."}]}