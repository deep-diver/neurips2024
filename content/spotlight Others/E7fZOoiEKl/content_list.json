[{"type": "text", "text": "FuseFL: One-Shot Federated Learning through the Lens of Causality with Progressive Model Fusion ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zhenheng Tang\u2020\u2217 Yonggang Zhang\u2020 Peijie Dong\u266f Yiu-ming Cheung Amelie Chi Zhou\u2020 Bo Han\u2020 Xiaowen Chu\u266f, \u00a7 ", "page_idx": 0}, {"type": "text", "text": "\u2020 Department of Computer Science, Hong Kong Baptist University \u266fDSA Thrust, The Hong Kong University of Science and Technology (Guangzhou) {zhtang, ygzhang, ymc, amelieczhou, bhanml}@comp.hkbu.edu.hk {pdong212, xwchu}@connect.hkust-gz.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "One-shot Federated Learning (OFL) significantly reduces communication costs in FL by aggregating trained models only once. However, the performance of advanced OFL methods is far behind the normal FL. In this work, we provide a causal view to find that this performance drop of OFL methods comes from the isolation problem, which means that locally isolatedly trained models in OFL may easily fit to spurious correlations due to data heterogeneity. From the causal perspective, we observe that the spurious fitting can be alleviated by augmenting intermediate features from other clients. Built upon our observation, we propose a novel learning approach to endow OFL with superb performance and low communication and storage costs, termed as FuseFL. Specifically, FuseFL decomposes neural networks into several blocks and progressively trains and fuses each block following a bottom-up manner for feature augmentation, introducing no additional communication costs. Comprehensive experiments demonstrate that FuseFL outperforms existing OFL and ensemble FL by a significant margin. We conduct comprehensive experiments to show that FuseFL supports high scalability of clients, heterogeneous model training, and low memory costs. Our work is the first attempt using causality to analyze and alleviate data heterogeneity of OFL2. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Federated learning (FL) [96; 67] has become a popular paradigm that enables collaborative model training without sharing private datasets from clients. Two typical characteristics of FL limit its performance: (1) FL normally has non-IID (Independently and Identically Distributed) data, also called data heterogeneity [67], which causes unstable slow convergence [68; 146; 124; 135] and poor model performance [157; 94; 134; 162; 150]; (2) The extremely low bandwidth, e.g. $1\\sim10$ MB/s of FL in Internet environments [67; 133; 129; 128; 132; 129], leads to high communication time of a large neural network. For example, communicating once ResNet-50 [51] with 25.56M parameters (102.24MB) or GPT-3 [14] with 175B parameters (700GB) will consume around 102.24 seconds or 194 hours, respectively. Current FL methods alleviate this problem by skipping the gradient synchronization of traditional distributed training to save communication costs [96; 67]. But the required hundreds or thousands of communication rounds still make the communication time unacceptable. ", "page_idx": 0}, {"type": "text", "text": "To reduce the communication costs at extreme, one-shot FL (OFL) [159; 38; 81; 164; 25; 23] only communicates the local trained model once. Thus, the communication cost is the model size $S$ for each client, less than FedAvg-style algorithms for hundreds or thousands of times. However, averaging for only once cannot guarantee the convergence of FedAvg. Thus, the direct idea is to aggregate client models on the server and conduct inference as ensemble learning does. Some advanced works also consider better model averaging [63; 112; 90; 6], neurons matching [5; 141], selective ensemble learning [26; 52; 143], model distillation [81; 164; 25; 23]. These methods may be impractical due to the requirements of additional datasets with privacy concerns, and the extra large storage or computation costs. Most importantly, there still exists a large performance gap between OFL and the normal FL or the ensemble learning. This motivates the following question: ", "page_idx": 1}, {"type": "text", "text": "How to improve FL performance under extremely low communication costs with almost no extra computational and storage costs? ", "page_idx": 1}, {"type": "text", "text": "In this work, we provide a causal view [109; 110; 3; 119] to analyze the performance drop of OFL. We firstly construct a causal graph to model the data generation process in FL, where the spurious features build up the data heterogeneity between clients, and invariant features of the same class remain constant in each client (domain) [3; 119; 22; 151; 161]. Then, we show the performance drop comes from the isolation problem, which means that locally isolatedly trained models in OFL may easily fti to spurious correlations like adversarial shortcuts [40; 35; 53], instead of learning invariant features [3; 119], causing a performance drop of OFL on the test dataset. Consider a real-world example, Alice takes photos of birds in the forests, while Bob near the sea. Now, the isolated models will mistakenly identify birds according to the forests or the sea [53; 35]. Based on the causal graph, we intuitively and empirically show that such spurious ftiting can be alleviated by augmenting intermediate features from other clients (Section 3). ", "page_idx": 1}, {"type": "text", "text": "Built upon this observation, we propose a simple yet effective learning approach to realizing OFL with superb performance and extremely low communication and storage costs, termed as FuseFL, which builds up the global model through bottom-up training and fusion to improve OFL performance (Section 4). Specifically, we split the whole model into multiple blocks 3 (The \u201cblock\u201d means a single or some continuous layers in a DNN.). For each block, clients first train and share their local blocks with others; then, these trained local blocks are assembled together, and the features outputted from these blocks are fused together and fed into the next local blocks. This process is repeated until the whole model is trained. Through this bottom-up training-and-fusion method, local models can learn better feature extractors that learn more invariant features from other clients to avoid the isolation problem. To avoid the large storage cost, given the number of \u221aclients $M$ , we assign each local client with a small model with reduced hidden dimension with ratio $\\sqrt{M}$ , to ensure the final learned global model has the same size $S$ as the original model. ", "page_idx": 1}, {"type": "text", "text": "Our main contributions can be summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We provide a causal view to understand the gap between multi-round FL and OFL, showing that augmenting intermediate features from other clients contributes helps improve OFL. As far as we know, this is the first work using causality to analyze the data heterogeneity of OFL. \u2022 To leverage causality to improve OFL, we design FuseFL, which decomposes models into several modules and transmits one module for feature augmentation at each communication round. \u2022 We conduct comprehensive experiments to show how FuseFL significantly promotes the performance of OFL without no additional communication and computation cost. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminary ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 Federated Learning ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In $\\mathrm{FL}$ , a set of clients $\\mathcal{M}\\,=\\,\\{m|m\\in1,2,...,M\\}$ have their own dataset $\\mathcal{D}_{m}$ . Given $C$ classes indexed by $\\left[C\\right]$ , a sample in $\\mathcal{D}_{m}$ is denoted by $(x,\\dot{y})\\in\\mathcal{X}\\times[C]$ , where $x$ is the input in the space $\\mathcal{X}$ and $y$ is its corresponding label. These clients cooperatively learn a model $F(\\theta,x)^{\\large\\!\\!}:\\lambda\\rightarrow\\mathbb{R}^{C}$ that is ", "page_idx": 1}, {"type": "text", "text": "parameterized as $\\theta\\in\\ensuremath{\\mathbb{R}}^{d}$ . Formally, the global optimization problem can be formulated as [96]: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta}L(\\theta)\\triangleq\\sum_{m=1}^{M}p_{m}L_{m}(\\theta)=\\sum_{m=1}^{M}p_{m}\\mathbb{E}_{(x,y)\\sim\\mathcal{D}_{m}}\\ell(F;x,y),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where the local objective function of mth-client $\\ell(F;x,y)\\,\\triangleq\\,C E({\\hat{y}},y)$ with ${\\hat{y}}\\,\\triangleq\\,F(\\theta;x)$ , $C E$ denotes the cross-entropy loss, $p_{m}\\,>\\,0$ and $\\textstyle\\sum_{m=1}^{M}p_{m}\\,=\\,1$ . Usually, $p_{m}\\,\\triangleq\\,n_{m}/N$ , where $n_{m}$ denotes the number of samples on client $m$ $\\left(n_{m}=|D_{m}|\\right)$ and $\\begin{array}{r}{N=\\sum_{m=1}^{M}n_{m}}\\end{array}$ . ", "page_idx": 2}, {"type": "text", "text": "The classic FL algorithm is FedAvg [96]. In each communication round $t$ , the central server randomly samples a part of clients $S^{t}\\subseteq{\\bar{\\mathcal{M}}}$ and broadcasts the model $\\theta^{t}$ to all selected clients, and then each $m$ -th client performs multiple local updates. After local training, all selected clients send the optimized $\\theta_{m,E}^{t}$ to the server, and the server aggregates and averages local models to obtain a global model. Such a multi-round communication introduces large communication costs [67]. ", "page_idx": 2}, {"type": "text", "text": "2.2 Ensembled FL ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The FedAvg requires multiple communication rounds $T$ for convergence [146; 83], which might be extremely large [67]. Given the model size $S$ , FedAvg-style FL methods introduce communication costs as $T\\times S$ . As shown in Table 1, the current lowest communication cost of FL is reduced as $S$ in OFL, making FL possibly deployable in low communication bandwidth scenarios [133; 129]. Thus, we analyze what causes the performance drop of OFL and how to improve it. As the performance of average-based and model distillation OFL methods is upper bounded by ensemble learning [159; 38; 81; 164; 23], we mainly focus on analyzing ensemble learning and differentiating FuseFL from it. The output of the ensemble learning can be formalized as: $\\begin{array}{r}{F_{\\mathrm{ens}}(x)\\triangleq\\frac{1}{M}\\sum_{m\\in\\mathcal{M}}F_{m}^{\\mathrm{loc}}(\\theta_{m};x)}\\end{array}$ , in which the local model $F_{m}^{\\mathrm{loc}}$ parameterized with $\\theta_{m}$ is isolatedly trained with minimizing empirical risk minimization (ERM) objective [152; 3; 22] function $\\ell(F({\\boldsymbol{\\dot{\\theta}}},x),y),(x,y)\\sim{\\mathcal{D}}_{m}$ by SGD. ", "page_idx": 2}, {"type": "text", "text": "3 Federated Learning: A Causal View ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 The Sequential Structure of Neural Networks ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "A neural network can be decomposed into the sequential module-wise structure as shown in Figure 1. Formally, it can be defined as: ", "page_idx": 2}, {"type": "equation", "text": "$$\nF=\\Lambda\\circ H^{K}\\circ H^{K-1}\\circ\\cdot\\cdot\\cdot\\circ H^{1},\\operatorname{for}1\\leq k\\leq K,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\Lambda$ is the final classifier, and $H_{k}$ is the module that may consist of single or multiple blocks. The $\\Lambda$ and each $H_{k}$ are parameterized by $\\theta^{\\Lambda}\\in\\mathbb{R}^{d_{\\Lambda}}$ and $\\theta^{k}\\in\\mathbb{R}^{d_{k}}$ . The $\\bar{H}^{i}\\circ H^{j}(\\cdot)$ means $H^{i}(H^{j}(\\cdot))$ . Thus, the parameter $\\theta$ of $F$ are concatenated by the $\\theta^{\\Lambda}$ and $\\{\\theta^{k}|k\\in1,2,\\cdot\\cdot\\cdot K\\}$ , and $\\begin{array}{r}{d_{\\Lambda}+\\sum_{k=1}^{K}d_{k}=d}\\end{array}$ . ", "page_idx": 2}, {"type": "text", "text": "As Figure 1 illustrates, each module $H^{k}$ receives the output of module $H^{k-1}$ , and the final classifier receives the output of the final hidden module $H^{K}$ and makes predictions $\\hat{y}\\;=\\;f(x)$ on the input $x$ . We call the output from each module, $\\mathring{h^{k}}=H^{k}(h^{k-1})$ and $\\dot{h^{1}}=H^{1}(x)$ , as the feature for simplicity. ", "page_idx": 2}, {"type": "image", "img_path": "E7fZOoiEKl/tmp/191bd395a7232c6d5ffd9c1926403b6790a788e5bf0f10d07f070bb4c79b8a71.jpg", "img_caption": [], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "Figure 1: Structure Equation Model [109] of FL. ", "page_idx": 2}, {"type": "text", "text": "3.2 Structure Equation Model of FL ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Inspired from the analysis of out-of-distribution (OOD) generalization [3] through the lens of mutual information [122; 2] and structure equation model (SEM) in causality [110; 3; 119; 161], we define the data generation SEM of FL as shown in Figure 1. For local training dataset $\\mathcal{D}_{m}$ at client $m$ , the SEM is $\\bar{Y}_{m}\\to R_{m}^{\\mathrm{inv}}\\to X_{m}\\leftarrow R_{m}^{\\mathrm{spu}}$ , where $R_{m}^{\\mathrm{inv}}$ and $R_{m}^{\\mathrm{spu}}$ are invariant and spurious features, $Y_{m}$ and $X_{m}$ are label and input data respectively. Here, the dataset $\\mathcal{D}_{m}$ is a subset of the whole dataset $\\mathcal{D}$ . The $R_{m}^{\\mathrm{spu}}$ is actually the nuisance at a global level (respect to $Y$ ), being independent of $Y$ , but dependent on $X_{m}$ . ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Non-IID data and causality. For a groundtruth label $Y$ , its corresponding invariant features $R_{m}^{\\mathrm{inv}}$ do not change across clients [3; 119; 22; 151]. However, the spurious features $R_{m}^{\\mathrm{spu}}$ are other factors that occasionally exist in data and do not have a relationship to $Y$ , which means that the heterogeneous features of data (non-iid) with the same class come from the spurious features $R_{m}^{\\mathrm{spu}}$ (concept shift [67]). For example, in photos of birds in the forests or the sea, pixels of birds are $R_{m}^{\\mathrm{inv}}$ while the forests and the sea are $R_{m}^{\\mathrm{spu}}$ . Considering the test dataset includes all client data distribution and even OOD data, the $Y_{\\mathrm{test}}$ is largely dependent on $R_{\\mathrm{test}}^{\\mathrm{inv}}$ : $P(Y_{\\mathrm{test}}|X_{\\mathrm{test}},R_{\\mathrm{test}}^{\\mathrm{inv}})\\gg P(Y_{\\mathrm{test}}|X_{\\mathrm{test}},R_{\\mathrm{test}}^{\\mathrm{spu}})^{4}$ . ", "page_idx": 3}, {"type": "text", "text": "Non-IID scenarios. This SEM model considers the label shift $(p_{i}(y)\\neq p_{j}(y))$ and concept shift $(p_{i}(x|y)\\neq p_{j}(x|y))$ scenarios [67; 80], or both of them appear simultaneously. When the support5 $y_{m}$ of $Y_{m}$ is different or partly overlapped between clients $m=1,...,M$ , this would be the severe non-IID scenario [155]. And it is obvious that spurious features $R_{m}^{\\mathrm{spu}}$ relate to the concept shift. ", "page_idx": 3}, {"type": "text", "text": "Spurious fitting. By conducting isolated local training on local dataset $\\mathcal{D}_{m}$ at client $m$ , the model $\\bar{F_{m}^{\\mathrm{loc}}}$ is prone to learn to predict $Y_{m}$ based on spurious features $R_{m}^{\\mathrm{spu}}$ , i.e. low distance $d_{\\mathrm{loc},m}^{\\mathrm{spu}}=$ $d(P(Y_{m}|X_{m},R_{m}^{\\mathrm{spu}}),P(F_{m}^{\\mathrm{loc}}|X_{m},R_{m}^{\\mathrm{spu}}))$ but high distance $d(P(Y_{m}|X_{m},R_{m}^{\\mathrm{inv}}),P(F_{m}^{\\mathrm{loc}}|X_{m},R_{m}^{\\mathrm{inv}}))$ in which the distance $d$ could be $C E$ loss or $K L$ divergence. The reason for the spurious fitting by isolated training is that the invariant features $R_{i\\ne m}^{\\mathrm{inv}}$ from other clients are not observed by client $m$ , while the $R_{m}^{\\mathrm{spu}}$ frequently appears in the local dataset $\\mathcal{D}_{m}$ like the adversarial attacks or shortcuts [40; 35; 53]. This guarantees low error on the training dataset $\\mathcal{D}_{m}$ , because it has much less data than $\\ensuremath{\\mathcal{D}}_{\\mathrm{test}}$ and $\\mathcal{D}_{1,...,M}$ , thus introducing high probability $P(Y_{m}|X_{m},R_{m}^{\\mathrm{spu}})$ . However, on test dataset $\\mathcal{D}_{\\mathrm{test}}$ , the low $d_{\\mathrm{loc},m}^{\\mathrm{spu}}$ of model $F_{m}^{\\mathrm{loc}}$ but high $d_{\\mathrm{loc},m}^{\\mathrm{inv}}$ of model $F_{m}^{\\mathrm{loc}}$ leads to high test error. Dmioffdeerles ntto  ffrinodm t hisooslea tceodm trmaoinni fnega,t uFreeds,A ivngc lauldlienvgi atmeos rte $R_{1,\\ldots,M}^{\\mathrm{inv}}$ eamnd  brye mmouvlitinpgl $R_{1,...,M}^{\\mathrm{spu}}$ .of averaging ", "page_idx": 3}, {"type": "text", "text": "Feature augmentation. Through the above analysis, the key to improve OFL performance is to endow OFL with the ability of training to see invariant features across all clients. It has been found that training on noised datasets with SGD to optimize ERM can still result in some feature representations consisting of both spurious and invariant features; exploiting the invariant features is the key to helping improve OOD performance [158; 3; 8]. In light of this, we introduce augmenting features by fusing client models block by block. Concisely speaking, in FuseFL, each local model can conduct local training with the view from other clients $\\bar{H_{i\\neq m}}(\\bar{X_{m}})$ , which helps filter out $R_{m}^{\\mathrm{spu}}$ but retain $R_{m}^{\\mathrm{inv}}$ , as other clients cannot see $R_{m}^{\\mathrm{spu}}$ in their dataset $\\mathscr{D}_{i\\neq m}$ . This method can be seen as a kind of invariant feature augmentation [22]. The details of FuseFL are shown in Section 4. ", "page_idx": 3}, {"type": "text", "text": "3.3 Mutual Information ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The goal of $\\mathrm{FL}$ is to obtain a model that performs well on all client datasets [67]. Thus, here we consider the random variable $X,Y$ sampled from the global dataset $\\mathcal{D}$ . In this section, we also write $H^{k}$ as the features that output from $H^{k^{\\ast}}(H^{k-1}\\cdot\\cdot\\cdot(H^{\\breve{1}}(X)))$ for simplicity. ", "page_idx": 3}, {"type": "text", "text": "Given the probabilistic graph model $(R^{\\mathrm{spu}},Y)\\,\\to\\,X\\,\\to\\,H^{1}\\,\\to\\,\\cdots\\,\\to\\,H^{k}\\,\\to\\,F(X)$ (Eq. 1), where $R^{\\mathrm{inv}}$ are ignored for simplicity, the MI between $Y$ and subsequent transformations $H^{k}$ on $X$ satisfies a decreasing trend: $I(\\dot{X};Y)\\,\\ge\\,I(H^{1};Y)\\,\\ge\\,\\cdots\\,\\ge\\,I(\\bar{H}^{K};Y)$ ; the MI between $X$ and subsequent transformations on $X$ satisfies a decreasing trend: Ent $r o p y(X)\\ge I(H^{1};X)\\ge$ $\\cdots\\ge I(\\bar{H^{K}};X)$ [122]. If $I(H^{K};R^{\\mathrm{spu}})\\,=\\,0$ and $H^{K}$ can predict labels, $\\dot{H}^{K}$ is called invariant features so that the final classifier will not overfit to spurious correlations between $R^{\\mathrm{spu}}$ and $Y$ . The previous works [122] show that achieving the following minimal sufficient statistic provides good ", "page_idx": 3}, {"type": "text", "text": "generalization: ", "page_idx": 4}, {"type": "text", "text": "Lemma 3.1 (Invariance and minimality [2]). Given spurious feature $R^{s p u}$ for the label $Y$ , and probabilistic graph model $(R^{s p u},Y)\\to X\\to H(X)$ , then, ", "page_idx": 4}, {"type": "equation", "text": "$$\nI(H(X);R^{s p u})\\leq I(H(X);X)-I(X;Y).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "There is a nuisance $R^{s p u}$ such that equality holds up to a residual $\\epsilon$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\nI(H(X);R^{s p u})=I(H(X);X)-I(X;Y)-\\epsilon,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\epsilon\\triangleq I(H(X);Y|R^{s p u})-I(X;Y)$ . The sufficient statistic $H(X)$ (satisfying Eq. 3) is invariant to $R^{s p u}$ if and only if it is minimal (satisfying Eq. 2). ", "page_idx": 4}, {"type": "text", "text": "Remark 3.1. Based on Lemma 3.1, we can study how $I(H(X);X)$ and $I((H);Y)$ changes to study to what degree the $H(X)$ contains spurious features. ", "page_idx": 4}, {"type": "image", "img_path": "E7fZOoiEKl/tmp/3b8c7034c41075d4c806f6b858ca9849cdc88a6686c74106f1f46e4ced1cf03e.jpg", "img_caption": ["Figure 2: Estimated MI and separability of trained models with non-IID datasets. "], "img_footnote": [], "page_idx": 4}, {"type": "image", "img_path": "E7fZOoiEKl/tmp/d400d60bbd4b38f9746d4ee3b46b0ed0957bb38d739ba8afccb8041a4e264a02.jpg", "img_caption": ["Figure 3: Estimated MI and separability of trained models with non-IID backdoored datasets. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Empirical study. We empirically estimate the MI $I(H_{\\mathrm{loc}}^{k},X)$ and $I(H_{\\mathrm{loc}}^{k},Y)$ of isolated local trained features, and the $I(H_{\\mathrm{fus}}^{k},X)$ and $I(H_{\\mathrm{fus}}^{k},Y)$ of augmented features. As the deep neural networks (DNNs) show layer-wise feature enhancements [7], we also measure the linear separability [7; 101] of features $H_{\\mathrm{loc}}^{k}$ and $H_{\\mathrm{fus}}^{k}$ to see how they change. Details of MI estimation and linear separability are shown in Appendix D.3 and D.4. The experiments are conducted by training ResNet-18 with CIFAR-10 [74] partitioned across $M\\,=\\,5$ clients. Figure 2 shows the local features $H_{\\mathrm{loc}}^{k}$ have significantly higher $I(H^{k},X)$ but lower $I(H^{k},Y)$ than augmented features $H_{\\mathrm{fus}}^{k}$ . With the increased non-IID degree (lower $a$ ), the $I(H^{k},Y)$ decreased further, demonstrating that the local feature $H_{\\mathrm{loc}}^{k}$ fits on a more anti-causal relationship between $R_{m}^{\\mathrm{spu}}$ and $Y_{m}$ . The fused high-level features show better linear separability. And $H_{\\mathrm{fus}}^{k}$ is more robust to $R_{m}^{\\mathrm{spu}}$ . ", "page_idx": 4}, {"type": "text", "text": "Except for the natural spurious features that exist in CIFAR-10, we also study the effect of spurious features by handcraft. Specifically, we inject backdoored data samples [10; 97] of 1 out of 5 clients as $\\mathcal{D}_{1}^{\\mathrm{back}}$ , in which the images have handcrafted textures generated according to the labels as a strong anti-causal relation. Details of backdoored datasets are introduced in Appendix D.5. Figure 3 shows that the backdoor features lead to information loss in $X$ . And the backdoored data samples further aggravate the information loss of label $Y$ . The isolated local trained features retain significantly less $\\bar{I(H^{k},Y)}$ than augmented features. ", "page_idx": 4}, {"type": "image", "img_path": "E7fZOoiEKl/tmp/f112e53b76ed4e2d244207fe12832c3b181ead7e94f6872c140e260dbdfd5f1f.jpg", "img_caption": ["Figure 4: (a) Initially, all layers are isolated training. Note that the layer here does not only mean one or Conv layer, but generally refers to a neural network block that can consist of multiple layers. (b) Then, all first blocks (L1) of different clients are communicated, shared and frozen among clients. Then, the adaptors are added behind the fused block, to fuse features outputted from the concatenated local blocks. (c) Train the third blocks (L3) follow the similar process in (b). (d) inference process of FuseFL. The larger squares represent the original training block in local models. The smaller squares are adaptors that fuse features from previous modules together, which are $1\\times1$ Conv kernels or simple average operations with little or no memory costs. Note that (a) also represents local training in ensemble FL, where different clients train models on local datasets. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "4 FuseFL: Progressive FL Model Fusion ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Motivated by analysis in Section 3, we propose augmenting local intermediate features $H_{m}^{1,\\ldots,K}$ on client $m$ , which helps reduce ftiting to a spurious correlation between $Y_{m}$ and $R_{m}^{\\mathrm{spu}}$ . However, direct fusing features together to make predictions faces the following problems. ", "page_idx": 5}, {"type": "text", "text": "Altered feature distribution. During local training, the local subsequent model $\\Gamma_{m}^{k+1}\\ \\triangleq\\ \\Lambda_{m}\\circ$ $H_{m}^{K}\\cdots\\circ H_{m}^{k+1}$ after block $k$ on client $m$ is trained based on local features $H_{m}^{k}$ . After feature fusion, changed local features lead to feature drifts [75; 134]. ", "page_idx": 5}, {"type": "text", "text": "Mismatched semantics. Each local feature $H_{m}^{k}$ has totally different distributions, scales, or even dimensions; thus, directly averaging may cause useful features to be overwhelmed or confused by noisy features. ", "page_idx": 5}, {"type": "text", "text": "4.1 Train, Fuse, Freeze, and Re-Train ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "As Figure 4 and Algorithm 1 (Appendix 1) show, the main loop of FuseFL including training, fusing, and freezing, which is repeated for all $K$ split blocks following a progressive manner. Note that for $H_{m}^{1}$ , there is no layer fusion, which is isolatedly trained. ", "page_idx": 5}, {"type": "text", "text": "Fuse. After each local training step, clients share their $H_{m}^{k}$ with other clients, and fuse them following Eq. 4. An adaptor A is stitched before Hkm+1(Section 4.2). Then the local model becomes as F fku,sm following Eq. 5. ", "page_idx": 5}, {"type": "text", "text": "Freeze and re-train. To address the altered feature distribution problem $(A(H_{\\mathrm{fus}}^{k}(x))\\to H_{m}^{k}(x))$ , for each step $k$ on client $m$ , the subsequent layers $\\Gamma_{m}^{k+1}$ will be trained again based on $\\mathcal{D}_{m}$ . Thus, the $\\Gamma_{m}^{k+1}$ can learn from all low-level features of all clients. Note that we do not need to train each block $k$ with the same epochs in isolated training, because the DNNs naturally follow the layer-wise convergence [113; 48]. ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{H_{\\mathrm{fus}}^{k}(x)=\\left[H_{1}^{k}(x),...,H_{M}^{k}(x)\\right].}\\\\ &{\\quad F_{\\mathrm{fus}}^{k,m}=\\Lambda_{m}\\circ H_{m}^{K}\\circ...\\circ H_{m}^{k+1}\\circ H_{\\mathrm{fus}}^{k}\\circ...\\circ H_{\\mathrm{fus}}^{1}.}\\\\ &{\\quad F_{\\mathrm{fus}}=\\Lambda\\circ H_{\\mathrm{fus}}^{K}\\circ H_{\\mathrm{fus}}^{K-1}\\circ...\\circ H_{\\mathrm{fus}}^{1}.}\\\\ &{\\quad A_{\\mathrm{avg}}=\\mathsf{A v e r a g e}(H_{\\mathrm{fus}}^{k}(x)).}\\\\ &{\\quad A_{\\mathrm{conv}}=\\mathsf{C o n v}(\\mathsf{C o n c a t}(H_{\\mathrm{fus}}^{k}(x))).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "By freezing fused blocks and retraining high-level models, the another benefti is to enforce the SGD to use previous features from other clients to continue tuning the high-level model. The previous local trained high-level models may overfit on shortcut features from the noisy data. This insight is also utilized in defensing adversarial attacks [139; 107]. ", "page_idx": 6}, {"type": "text", "text": "4.2 Feature Adaptation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "To address the mismatched semantics problem, the intuitive approach is to preserve the original feature structures through the concatenation of all features to the next block. However, this leads to new problems: (1) requiring modification of subsequent modules; (2) feature size explosion of subsequent blocks by $O\\bar{(}M^{K}\\bar{)}$ . To address these two problems, we introduce an adaptor stitched before local modules $(k>1)$ ), and training together with $\\Gamma_{m}^{k}$ . As an initial trial to operationalize FuseFL, we utilize conv1 $_{\\times1}$ as the adapter as Eq. 8. We also verify the use of average as an adapter (Eq. 7) in experiments (Section 6). ", "page_idx": 6}, {"type": "text", "text": "4.3 Benefits of FuseFL Design ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Mitigating fitting on spurious correlations. During the local training on datasets with spurious features, the final learned representations with ERM still contain some invariant features [3; 22]. Thus, some work proposes to finetune the classifier based on data samples with invariant features to let the classifier make predictions based on invariant features [70; 61; 106]. Similar to this motivation, we hope to incorporate other client modules as auxiliary feature extractors to generate more invariant features of local data during training subsequent layers. Figure 1 describes the mechanism that using coltiheenrt sl eclas $H_{i\\neq m}(X_{m})$ hine ltph etior  fdilattears eot idouursi nfeg altoucraels $R_{m}^{\\mathrm{spu}}$ i,n bg,u to rneltya iinn $R_{m}^{\\mathrm{inv}}$ .n t Afes aottuhreesr $\\{i\\neq m\\}$ $R_{m}^{\\mathrm{spu}}$ $\\mathscr{D}_{i\\neq m}$ can pass through $H_{i\\neq m}(X_{m})$ . This method can be seen as the invariant feature augmentation [22]. ", "page_idx": 6}, {"type": "text", "text": "Saving storage and communication costs than ensemble FL. Similar to ensemble learning, directly collecting and fusing local models together will enlarge the total model size from $S$ to $S\\times M$ . Note that FuseFL actually builds up a global model with blocks fused together, with the hidden dimensions (channels) enlarged from $n_{s}\\rightarrow n_{s}\\times M$ . Thus, intuitively, we can reduce the hidden dimension of the local model $n_{f}$ to reduce the memory requirements. Interestingly, with a scaling ratio $\\gamma$ , when scaling all local linear or convolutional layers, each matrix should be scaled on both input and output dimension as $n_{f}=\\gamma n_{s}$ . The ratio of memory costs between FuseFL and the \u221aoriginal single model is $r_{m}=M\\times n_{s}^{2}/(\\gamma n_{s})^{2}$ . To obtain $r_{m}=1$ , we obtain the scaling ratio $\\gamma=\\sqrt{M}$ , which means that FuseFL can keep sim\u221ailar memory requirements with the original model size $S$ with reducing hidden dimensions as ratio $\\sqrt{M}$ , demonstrating good theoretical scalability to the $M$ . We will verify this in experiments (Section 6.2). ", "page_idx": 6}, {"type": "text", "text": "Privacy concerns. FuseFL only shares layers between clients, which aligns with other classic and advanced FL methods in all directions mentioned in Section 5. ", "page_idx": 6}, {"type": "text", "text": "Support of heterogeneous models. The block in FuseFL does not mean a single linear or convolution layer, but a general module that can consist of any DNN, thus supporting FL with heterogeneous models (see experiments 6.2). The adaptor can be designed to transform features of different shapes to align with the input of the next local block. ", "page_idx": 6}, {"type": "text", "text": "Layer-wise training to reduce training epochs. Because each communication round means multiple local training epochs. To keep the total training epochs the same as the one-shot FedAVG (represented as $E$ ), we assign the local training epochs of the FuseFL as $E/K$ . Thus, the number of total training epochs of FuseFL is the same as other OFL methods. The core insight of this design can be referred to as the progressive freezing during training DNNs [113]. ", "page_idx": 6}, {"type": "text", "text": "5 Related Works ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "5.1 Data Heterogeneity in FL ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The notorious non-IID data distribution in FL severely harms the convergence rate and model performance of FL. The model regularization proposes to add a penalty of distances between local and global models [117; 1]. Feature calibration aligns feature representations of different clients in similar spaces [29; 134; 60; 135]. FedMA [141] exploits a layer-wise communication and averaging methods, in which the aggregation is conducted on fine-grained layer. Thus, its linear dependence of computation and communication on the network\u2019s depth, is not suitable for deeper models, which introduces large computation costs in re-training and more com", "page_idx": 7}, {"type": "table", "img_path": "E7fZOoiEKl/tmp/967257263a3543bca6dd6611252fd128605fc008b3810910394c1f5eeff9360a.jpg", "table_caption": ["Table 1: Demystifying different FL algorithms. $T$ represents communication rounds, $S$ the model size, $M$ the number of clients. The \u201cCentralized\u201d means training the model with all datasets aggregated with SGD. \u201cComm.\u201d means communication. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "munication rounds [19; 58]. Unlike FedMA, FuseFL introduces block-wise communication and aggregation with much less communication rounds and computation costs. Furthermore, due to the matching and averaging aggregation, FedMA only supports linear or Conv layers, which severely limits its practical usage. By viewing the separated block as a black box and concatenating output features, FuseFL can successfully support merging any kind of neural layer. Some works on fairness analysis in FL also relate to this work in perspective of local and global characteristics [42; 32]. ", "page_idx": 7}, {"type": "text", "text": "5.2 One-shot FL ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "One-shot FL [159; 38; 81; 164; 25] reduces communication costs from $T\\times S$ to $S$ by communicating with only one round. Average-based methods focus on better averaging client models, like Fisher information [63; 112], bayesian optimization [90; 6] or matching neurons [5; 141]. However, the nonlinear structure of DNNs makes it difficult to obtain a comparable global model through averaging. Ensemble-based methods make prediction based on all or selected client models [26; 52; 143], but requires additional datasets with privacy concerns. And they have low scalability of the number of clients due to the storage of client models. Model distillation uses the public [81] or synthesized datasets [164; 25] to distill a new model based on ensemble models [38; 81]. These methods may be impractical in data-sensitive scenarios, such as medical and education, or continuous learning scenarios [28; 27]. Furthermore, there exists a large performance gap between these methods and the ensemble learning. ", "page_idx": 7}, {"type": "text", "text": "Due to the limited space, we leave the detailed reviews in Table 8 and Appendix C. Table 1 concisely demystifies different FL methods in terms of communication cost, storage cost, model performance, and whether supporting model heterogeneity or requiring extra data. ", "page_idx": 7}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "6.1 Experiment Setup ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Federated Datasets and Models. In order to validate the efficacy of FuseFL, we conduct comprehensive experiments with commonly used datasets in FL, including MNIST [77], CIFAR-10 [73], FMNIST [147], SVHN [100], CIFAR-100 [73] and Tiny-Imagenet [76]. For studying the non-IID problem in FL, we partitioned the datasets through a widely-used non-IID partition method, namely Latent Dirichlet Sampling [56; 67; 114; 80], in which the coefficient $a$ represents the non-IID degree. Lower $a$ generates more non-IID datasets, and vice versa. Consistent with established practices in the field [159; 114; 93; 80], each dataset was divided with three distinct degrees of non-IID with $a\\in\\{0.1,0.3,0.5\\}$ . If there is no additional explanation, the non-IID degree $a$ is set to 0.5 by default. ", "page_idx": 7}, {"type": "text", "text": "Following other classic and advanced FL works studying non-IID problems and communicationefficient FL [125; 52; 93; 159], we train ResNet-18 [51] on all datasets in main experiments. And we reduce and increase the number of layers as ResNet-10 and ResNet-26 to verify the effect of FuseFL in model-heterogeneity FL. The number of clients is set as $M=5$ by default. Moreover, we study the scalability of our methods with different $M\\in\\{5,10,20,50\\}$ . ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "We use SGD optimizer with momentum coefficient as 0.9, and the batch size is 128. The number of local training epochs $E=200$ . We search learning rates in $\\left\\lbrace0.0001,0.001,0.01,0.1\\right\\rbrace$ and report the best results. The detailed hyper-parameters of different settings are shown in Table 9 of Appendix D. ", "page_idx": 8}, {"type": "text", "text": "Table 2: Accuracy of different methods across $\\alpha=\\{0.1,0.3,0.5\\}$ on different datasets. Ensemble means ensemble learning with local trained models, which is an upper bound of all previous methods but impractical in FL due to the large memory costs and the weak scalability of clients. Thus, we highlight the best results in bold font except Ensemble. ", "page_idx": 8}, {"type": "table", "img_path": "E7fZOoiEKl/tmp/522b4abffbf6bf50302607a1de7ab6e36659c9ac4789a4bd6a62c4ca0dc65873.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Baselines. Except the classic baseline FedAvg [96] and advanced OFL method DENSE [159], we apply two prevailing data-free KD methods DAFL [18] and ADI [153] into OFL. We choose FedDF [88] as its high efficiency in few-round FL. We conduct ensemble FL as it is the upper bound across ensemble-and-distillation based methods, yet impractical in real-world scenarios. The communication round for all baseline methods is only 1. For our method FuseFL, the number of communication rounds is equal to the number of splitted blocks $K$ . However, the actual communication cost is as same as one-shot FL. Because FuseFL only communicates a part of the model. After all rounds, the total communication cost is $S M$ , where $S$ is the model size, $M$ the number of clients. ", "page_idx": 8}, {"type": "text", "text": "6.2 Experimental Results ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Main Results. Table 2 shows that FuseFL generally outperforms all other baselines except for ensemble FL. All ensemble-and-distillation baselines have lower performance than ensemble FL. Nevertheless, by the insights from causality (Section 3) and our innovative design (Section 4), FuseFL can significantly outperform ensemble FL for almost all cases except for CIFAR-100 with $a=0.3,0.5$ and Tiny-Imagenet. We suppose the reason is that CIFAR-100 and Tiny-Imagenet has much more data divergence between different classes, thus the overlap between $R_{m}^{\\mathrm{inv}}$ is much less than other datasets. Recall that the beneftis of FuseFL come from fusing sub models training on other clients, thus filtering out $R_{m}^{\\mathrm{spu}}$ and collecting $R_{m}^{\\mathrm{inv}}$ of the same class to improve the generalization performance. The large data divergence in CIFAR-100 and Tiny-Imagenet limits beneftis of FuseFL. ", "page_idx": 8}, {"type": "text", "text": "Table 3: Accuracy with FuseFL withTable 4: Memory Occupation. For different number $\\mathrm{conv}1\\!\\times\\!1$ or averaging to support heteroge-of clients, the number of basic channels in ResNetneous model design on CIFAR-10. 18 of FuseFL is set as 32, 20, 14, 9 with $M\\_{\\Sigma}$ $\\{5,10,20,50\\}$ , respectively. Other OFLs refer to Fe", "page_idx": 8}, {"type": "table", "img_path": "E7fZOoiEKl/tmp/683c1771568c78af284bcf3b813f8ae1f9f2cb549be7e7d2275fe45b7709ae26.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Support of heterogeneous model design. Table 3 shows training heterogeneous model using FuseFL. In all $M=5$ clients, 2 clients train ResNet-10 and other 2 clients train ResNet-26, the left 1 client trains ResNet-18. We set $K=4$ for FuseFL. Results show that training with heterogeneous models has similar or even better results than homogeneous models, demonstrating that FuseFL supports training heterogeneous model well. This will be very useful in heterogeneous computation environments. ", "page_idx": 8}, {"type": "table", "img_path": "E7fZOoiEKl/tmp/6895ccfd12ee5d748d48f354be0884e3982fab16021bc6aabaf038b0774843c7.jpg", "table_caption": ["Table 5: Accuracy of different methods across $M=\\{5,10,20,50\\}.$ "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Memory occupation. Table 4 shows the memory occupation with varying number of clients and split modules. Results show that FuseFL requires similar memory with the single model when $K=2$ , while the ensemble FL requires the $S\\times M$ storage cost. And using averaging as feature fusion method can further reduce the memory cost. Table 12 shows that the FuseFL with $K=2$ or FuseFL with averaging has comparable or better performance than other variants of FuseFL. ", "page_idx": 9}, {"type": "text", "text": "Table 6: Local and global accuracy of 5 local client models. $\\mathrm{BD_{0}}$ and $\\mathrm{BD_{1}}$ represent two clients trained on backdoored datasets. $\\mathrm{{Normal}_{\\mathrm{{0}}}}$ , $\\mathrm{{Normal}_{1}}$ , and Normal2 represent three clients trained on clean datasets. ", "page_idx": 9}, {"type": "table", "img_path": "E7fZOoiEKl/tmp/3c5f4131e0264bd9052eb64fc6c8a4751a516af5a8df2ff82fe1ff6909d83fe7.jpg", "table_caption": [], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Scalability of the number of clients. We em", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "pirically prove that the memory occupation increases a little along with the increased $M$ (Table 4), and keeping performance outperforms than baselines (Table 5). ", "page_idx": 9}, {"type": "text", "text": "Influence on local models of backdoored datasets. As shown in Section 3, the backdoored features lead to information loss in $X$ . Here we further show how the FL performance is influenced by the backdoored features. Table 6 shows that the backdoored (BD) clients fti on the handcrafted spurious features, thus having lower global accuracy than normal clients. ", "page_idx": 9}, {"type": "text", "text": "Test accuracy on backdoored datasets. Table 7 provides the test accuracy of different methods training with backdoored CIFAR-10. The test dataset is the original clean test set. We test different numbers of backdoored clients $M_{b d}=$ ", "page_idx": 9}, {"type": "table", "img_path": "E7fZOoiEKl/tmp/df16b8c398439d9c5a2c5b3b637f66f9f4a0827c89c0b885b35a41bc55c82f6e.jpg", "table_caption": ["Table 7: Comparing accuracy on backdoored CIFAR-10. "], "table_footnote": ["$1,2$ out of a total of 5 clients, to see how the degree of the backdoor influences training. Results show FuseFL outperforms ensemble FL in all cases. demonstrating that FuseFL can defend better against the backdoor samples than ensemble FL. "], "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this work, we draw inspiration from the causality and the information bottleneck to analyze the cause of low performance of ensemble FL and OFL. Specifically, the local isolatedly trained models are easily to fit spurious features, as local clients cannot learn more invariant features and remove spurious features from other datasets. Built upon this insight, we provide a novel approach FuseFL to augment features by fusing client layers in a bottom-up manner, thus mitigating the spurious fitting and encourage learning of invariant features. FuseFL achieves OFL with extremely low communication costs with significantly higher performance than current OFL and ensemble FL methods. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work was partially supported by National Natural Science Foundation of China under Grant No. 62272122, the Guangzhou Municipal Joint Funding Project with Universities and Enterprises under Grant No. 2024A03J0616, the Hong Kong RIF grant under Grant No. R6021-20, and Hong Kong CRF grants under Grant No. C2004-21G and C7004-22G. BH was supported by NSFC General Program No. 62376235, Guangdong Basic and Applied Basic Research Foundation Nos. 2022A1515011652 and 2024A1515012399, HKBU Faculty Niche Research Areas No. RC-FNRA-IG/22-23/SCI/04, and HKBU CSD Departmental Incentive Scheme. YGZ and YMC were supported in part by the NSFC / Research Grants Council (RGC) Joint Research Scheme under the grant: N-HKBU214/21, the General Research Fund of RGC under the grants: 12201321, 12202622, 12201323, the RGC Senior Research Fellow Scheme under the grant: SRFS2324-2S02, and the Initiation Grant for Faculty Niche Research Areas of Hong Kong Baptist University under the grant: RC-FNRA-IG/23-24/SCI/02. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] D. A. E. Acar, Y. Zhao, R. Matas, M. Mattina, P. Whatmough, and V. Saligrama. Federated learning based on dynamic regularization. In International Conference on Learning Representations, 2021.   \n[2] A. Achille and S. Soatto. Emergence of invariance and disentanglement in deep representations. The Journal of Machine Learning Research, 2018.   \n[3] K. Ahuja, E. Caballero, D. Zhang, J.-C. Gagnon-Audet, Y. Bengio, I. Mitliagkas, and I. Rish. Invariance principle meets information bottleneck for out-of-distribution generalization. Advances in Neural Information Processing Systems, 34:3438\u20133450, 2021. [4] K. Ahuja, J. Wang, A. Dhurandhar, K. Shanmugam, and K. R. Varshney. Empirical or invariant risk minimization? a sample complexity perspective. In International Conference on Learning Representations, 2020.   \n[5] S. Ainsworth, J. Hayase, and S. Srinivasa. Git re-basin: Merging models modulo permutation symmetries. In The Eleventh International Conference on Learning Representations, 2022.   \n[6] M. Al-Shedivat, J. Gillenwater, E. Xing, and A. Rostamizadeh. Federated learning via posterior averaging: A new perspective and practical algorithms. In International Conference on Learning Representations, 2020.   \n[7] G. Alain and Y. Bengio. Understanding intermediate layers using linear classifier probes. arXiv preprint arXiv:1610.01644, 2016.   \n[8] M. Arjovsky, L. Bottou, I. Gulrajani, and D. Lopez-Paz. Invariant risk minimization. arXiv preprint arXiv:1907.02893, 2019. [9] S. Babakniya, S. Kundu, S. Prakash, Y. Niu, and S. Avestimehr. Federated sparse training: Lottery aware model compression for resource constrained edge. In Workshop on Federated Learning: Recent Advances and New Challenges (in Conjunction with NeurIPS 2022), 2022.   \n[10] E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, and V. Shmatikov. How to backdoor federated learning. In International Conference on Artificial Intelligence and Statistics, pages 2938\u20132948, 2020.   \n[11] M. I. Belghazi, A. Baratin, S. Rajeshwar, S. Ozair, Y. Bengio, A. Courville, and D. Hjelm. Mutual information neural estimation. In International conference on machine learning, pages 531\u2013540. PMLR, 2018.   \n[12] S. Bibikar, H. Vikalo, Z. Wang, and X. Chen. Federated dynamic sparse training: Computing less, communicating less, yet learning better. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 6080\u20136088, 2022.   \n[13] I. Bistritz, A. Mann, and N. Bambos. Distributed distillation for on-device learning. Advances in Neural Information Processing Systems, 33:22593\u201322604, 2020.   \n[14] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901, 2020.   \n[15] K. Cai, X. Lei, J. Wei, and X. Xiao. Data synthesis via differentially private markov random fields. Proc. VLDB Endow., 14(11):2190\u20132202, jul 2021.   \n[16] H. Chang, V. Shejwalkar, R. Shokri, and A. Houmansadr. Cronus: Robust and heterogeneous collaborative learning with black-box knowledge transfer. arXiv preprint arXiv:1912.11279, 2019.   \n[17] A. Chatalic, V. Schellekens, F. Houssiau, Y. A. de Montjoye, L. Jacques, and R. Gribonval. Compressive learning with privacy guarantees. Information and Inference: A Journal of the IMA, 05 2021. iaab005.   \n[18] H. Chen, Y. Wang, C. Xu, Z. Yang, C. Liu, B. Shi, C. Xu, C. Xu, and Q. Tian. Data-free learning of student networks. In Proceedings of the IEEE/CVF international conference on computer vision, pages 3514\u20133522, 2019.   \n[19] H.-Y. Chen and W.-L. Chao. Fedbe: Making bayesian model ensemble applicable to federated learning. In NeurIPS, 2020.   \n[20] H.-Y. Chen and W.-L. Chao. On bridging generic and personalized federated learning for image classification. In International Conference on Learning Representations, 2021.   \n[21] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton. A simple framework for contrastive learning of visual representations. In ICML, 2020.   \n[22] Y. Chen, W. Huang, K. Zhou, Y. Bian, B. Han, and J. Cheng. Understanding and improving feature learning for out-of-distribution generalization. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[23] R. Dai, Y. Zhang, A. Li, T. Liu, X. Yang, and B. Han. Enhancing one-shot federated learning through data and ensemble co-boosting. In The Twelfth International Conference on Learning Representations, 2024.   \n[24] Y. Dai, Z. Chen, J. Li, S. Heinecke, L. Sun, and R. Xu. Tackling data heterogeneity in federated learning with class prototypes. In Proceedings of the AAAI Conference on Artificial Intelligence, 2023.   \n[25] D. K. Dennis, T. Li, and V. Smith. Heterogeneity for the win: One-shot federated clustering. In International Conference on Machine Learning, 2021.   \n[26] Y. Diao, Q. Li, and B. He. Towards addressing label skews in one-shot federated learning. In The Eleventh International Conference on Learning Representations, 2023.   \n[27] J. Dong, H. Li, Y. Cong, G. Sun, Y. Zhang, and L. Van Gool. No one left behind: Real-world federated class-incremental learning. IEEE Transactions on Pattern Analysis and Machine Intelligence, 46(4):2054\u20132070, 2024.   \n[28] J. Dong, L. Wang, Z. Fang, G. Sun, S. Xu, X. Wang, and Q. Zhu. Federated class-incremental learning. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2022.   \n[29] X. Dong, S. Q. Zhang, A. Li, and H. Kung. Spherefed: Hyperspherical federated learning. In European Conference on Computer Vision, 2022.   \n[30] R. Dorfman, S. Vargaftik, Y. Ben-Itzhak, and K. Y. Levy. Docofl: downlink compression for cross-device federated learning. In Proceedings of the 40th International Conference on Machine Learning, 2023.   \n[31] S. Dou, E. Zhou, Y. Liu, S. Gao, W. Shen, L. Xiong, Y. Zhou, X. Wang, Z. Xi, X. Fan, S. Pu, J. Zhu, R. Zheng, T. Gui, Q. Zhang, and X. Huang. LoRAMoE: Alleviating world knowledge forgetting in large language models via MoE-style plugin. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Aug. 2024.   \n[32] Y. H. Ezzeldin, S. Yan, C. He, E. Ferrara, and A. S. Avestimehr. Fairfed: Enabling group fairness in federated learning. In Proceedings of the AAAI conference on artificial intelligence, pages 7494\u20137502, 2023.   \n[33] J. Frankle and M. Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural networks. arXiv preprint arXiv:1803.03635, 2018.   \n[34] J. Frankle, G. K. Dziugaite, D. Roy, and M. Carbin. Linear mode connectivity and the lottery ticket hypothesis. In Proceedings of the 37th International Conference on Machine Learning, pages 3259\u20133269, 2020.   \n[35] R. Geirhos, J.-H. Jacobsen, C. Michaelis, R. Zemel, W. Brendel, M. Bethge, and F. A. Wichmann. Shortcut learning in deep neural networks. Nature Machine Intelligence, 2(11):665\u2013 673, 2020.   \n[36] R. Geirhos, P. Rubisch, C. Michaelis, M. Bethge, F. A. Wichmann, and W. Brendel. Imagenettrained cnns are biased towards texture; increasing shape bias improves accuracy and robustness. In International Conference on Learning Representations, 2018.   \n[37] J. Goetz and A. Tewari. Federated learning via synthetic data. arXiv preprint arXiv:2008.04489, 2020.   \n[38] N. Guha, A. Talwalkar, and V. Smith. One-shot federated learning. arXiv preprint arXiv:1902.11175, 2019.   \n[39] I. Gulrajani and D. Lopez-Paz. In search of lost domain generalization. In International Conference on Learning Representations, 2020.   \n[40] C. Guo, M. Rana, M. Cisse, and L. van der Maaten. Countering adversarial images using input transformations. In ICLR, 2020.   \n[41] K. Gupta, M. Fournarakis, M. Reisser, C. Louizos, and M. Nagel. Quantization robust federated learning for efficient inference on heterogeneous devices. Transactions on Machine Learning Research, 2023.   \n[42] F. Hamman and S. Dutta. Demystifying local & global fairness trade-offs in federated learning using partial information decomposition. In The Twelfth International Conference on Learning Representations, 2024.   \n[43] W. Hao, M. El-Khamy, J. Lee, J. Zhang, K. J. Liang, C. Chen, and L. C. Duke. Towards fair federated learning with zero-shot data augmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3310\u20133319, 2021.   \n[44] M. Hardt, K. Ligett, and F. Mcsherry. A simple and practical algorithm for differentially private data release. In F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems, volume 25. Curran Associates, Inc., 2012.   \n[45] M. Hardt and G. N. Rothblum. A multiplicative weights mechanism for privacy-preserving data analysis. In 2010 IEEE 51st Annual Symposium on Foundations of Computer Science, pages 61\u201370, 2010.   \n[46] C. He, M. Annavaram, and S. Avestimehr. Group knowledge transfer: Federated learning of large cnns at the edge. In Advances in Neural Information Processing Systems 34, 2020.   \n[47] C. He, S. Li, J. So, M. Zhang, H. Wang, X. Wang, P. Vepakomma, A. Singh, H. Qiu, L. Shen, P. Zhao, Y. Kang, Y. Liu, R. Raskar, Q. Yang, M. Annavaram, and S. Avestimehr. Fedml: A research library and benchmark for federated machine learning. arXiv preprint arXiv:2007.13518, 2020.   \n[48] C. He, S. Li, M. Soltanolkotabi, and S. Avestimehr. Pipetransformer: Automated elastic pipelining for distributed training of large-scale models. In Proceedings of the 38th International Conference on Machine Learning, pages 4150\u20134159. PMLR, 18\u201324 Jul 2021.   \n[49] C. He, A. D. Shah, Z. Tang, D. F. N. Sivashunmugam, K. Bhogaraju, M. Shimpi, L. Shen, X. Chu, M. Soltanolkotabi, and S. Avestimehr. Fedcv: A federated learning framework for diverse computer vision tasks. arXiv preprint arXiv:2111.11066, 2021.   \n[50] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick. Momentum contrast for unsupervised visual representation learning. In CVPR, 2020.   \n[51] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013 778, 2016.   \n[52] C. E. Heinbaugh, E. Luz-Ricca, and H. Shao. Data-free one-shot federated learning under very high statistical heterogeneity. In The Eleventh International Conference on Learning Representations, 2023.   \n[53] D. Hendrycks, K. Zhao, S. Basart, J. Steinhardt, and D. Song. Natural adversarial examples. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15262\u201315271, 2021.   \n[54] R. D. Hjelm, A. Fedorov, S. Lavoie-Marchildon, K. Grewal, P. Bachman, A. Trischler, and Y. Bengio. Learning deep representations by mutual information estimation and maximization. In ICLR, 2019.   \n[55] C.-H. Ho and N. Nvasconcelos. Contrastive learning with adversarial examples. Advances in Neural Information Processing Systems, 33:17081\u201317093, 2020.   \n[56] T. Hsu, H. Qi, and M. Brown. Measuring the effects of non-identical data distribution for federated visual classification. ArXiv, abs/1909.06335, 2019.   \n[57] T.-M. H. Hsu, H. Qi, and M. Brown. Federated visual classification with real-world data distribution. In A. Vedaldi, H. Bischof, T. Brox, and J.-M. Frahm, editors, Computer Vision \u2013 ECCV 2020, pages 76\u201392, Cham, 2020. Springer International Publishing.   \n[58] S. Hu, Q. Li, and B. He. Communication-efficient generalized neuron matching for federated learning. In Proceedings of the 52nd International Conference on Parallel Processing, ICPP \u201923, page 254\u2013263, New York, NY, USA, 2023. Association for Computing Machinery.   \n[59] C. Huang, Q. Liu, B. Y. Lin, C. Du, T. Pang, and M. Lin. Lorahub: Efficient cross-task generalization via dynamic loRA composition, 2024.   \n[60] W. Huang, M. Ye, Z. Shi, H. Li, and B. Du. Rethinking federated learning with domain shift: A prototype view. In 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023.   \n[61] P. Izmailov, P. Kirichenko, N. Gruver, and A. G. Wilson. On feature learning in the presence of spurious correlations. Advances in Neural Information Processing Systems, 35:38516\u201338532, 2022.   \n[62] E. Jeong, S. Oh, H. Kim, J. Park, M. Bennis, and S.-L. Kim. Communication-efficient ondevice machine learning: Federated distillation and augmentation under non-iid private data. arXiv preprint arXiv:1811.11479, 2018.   \n[63] D. Jhunjhunwala, S. Wang, and G. Joshi. Towards a theoretical and practical understanding of one-shot federated learning with fisher information. In Federated Learning and Analytics in Practice: Algorithms, Systems, Applications, and Opportunities, 2023.   \n[64] Y. Jiang, S. Wang, V. Valls, B. J. Ko, W.-H. Lee, K. K. Leung, and L. Tassiulas. Model pruning enables efficient federated learning on edge devices. IEEE Transactions on Neural Networks and Learning Systems, 2022.   \n[65] X. Jin, X. Ren, D. Preotiuc-Pietro, and P. Cheng. Dataless knowledge fusion by merging weights of language models. In The Eleventh International Conference on Learning Representations, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "[66] N. Johnson, J. P. Near, and D. Song. Towards practical differential privacy for sql queries. Proceedings of the VLDB Endowment, 11(5):526\u2013539, 2018. ", "page_idx": 14}, {"type": "text", "text": "[67] P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji, K. Bonawitz, Z. Charles, G. Cormode, R. Cummings, R. G. L. D\u2019Oliveira, H. Eichner, S. E. Rouayheb, D. Evans, J. Gardner, Z. Garrett, A. Gasc\u00f3n, B. Ghazi, P. B. Gibbons, M. Gruteser, Z. Harchaoui, C. He, L. He, Z. Huo, B. Hutchinson, J. Hsu, M. Jaggi, T. Javidi, G. Joshi, M. Khodak, J. Kone\u02c7cn\u00fd, A. Korolova, F. Koushanfar, S. Koyejo, T. Lepoint, Y. Liu, P. Mittal, M. Mohri, R. Nock, A. \u00d6zg\u00fcr, R. Pagh, M. Raykova, H. Qi, D. Ramage, R. Raskar, D. Song, W. Song, S. U. Stich, Z. Sun, A. T. Suresh, F. Tram\u00e8r, P. Vepakomma, J. Wang, L. Xiong, Z. Xu, Q. Yang, F. X. Yu, H. Yu, and S. Zhao. Advances and open problems in federated learning, 2021.   \n[68] S. P. Karimireddy, S. Kale, M. Mohri, S. J. Reddi, S. U. Stich, and A. T. Suresh. Scaffold: Stochastic controlled averaging for federated learning. arXiv preprint arXiv:1910.06378, 2019.   \n[69] H. Kim, Y. Kwak, M. Jung, J. Shin, Y. Kim, and C. Kim. Protofl: Unsupervised federated learning via prototypical distillation. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), October 2023.   \n[70] P. Kirichenko, P. Izmailov, and A. G. Wilson. Last layer re-training is sufficient for robustness to spurious correlations. In The Eleventh International Conference on Learning Representations, 2023.   \n[71] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska, D. Hassabis, C. Clopath, D. Kumaran, and R. Hadsell. Overcoming catastrophic forgetting in neural networks. Proceedings of the National Academy of Sciences, 2017.   \n[72] J. Konec\u02c7n\u00fd, H. Brendan McMahan, F. X. Yu, P. Richt\u00e1rik, A. Theertha Suresh, and D. Bacon. Federated Learning: Strategies for Improving Communication Efficiency. arXiv e-prints, 2016.   \n[73] A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. Master\u2019s thesis, 2009.   \n[74] A. Krizhevsky, V. Nair, and G. Hinton. Cifar-10 (canadian institute for advanced research). URL http://www.cs.toronto.edu/kriz/cifar.html, 2010.   \n[75] A. Kumar, A. Raghunathan, R. M. Jones, T. Ma, and P. Liang. Fine-tuning can distort pretrained features and underperform out-of-distribution. In International Conference on Learning Representations, 2022.   \n[76] Y. Le and X. Yang. Tiny imagenet visual recognition challenge. CS 231N, 7(7):3, 2015.   \n[77] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 1998.   \n[78] A. Li, J. Sun, B. Wang, L. Duan, S. Li, Y. Chen, and H. Li. Lotteryfl: Empower edge intelligence with personalized and communication-efficient federated learning. In 2021 IEEE/ACM Symposium on Edge Computing (SEC), pages 68\u201379, 2021.   \n[79] D. Li and J. Wang. Fedmd: Heterogenous federated learning via model distillation. arXiv preprint arXiv:1910.03581, 2019.   \n[80] Q. Li, Y. Diao, Q. Chen, and B. He. Federated learning on non-iid data silos: An experimental study, 2021.   \n[81] Q. Li, B. He, and D. Song. Practical one-shot federated learning for cross-silo setting. arXiv preprint arXiv:2010.01017, 2020.   \n[82] Q. Li, B. He, and D. Song. Model-contrastive federated learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10713\u201310722, 2021.   \n[83] X. Li, K. Huang, W. Yang, S. Wang, and Z. Zhang. On the convergence of fedavg on non-iid data. In International Conference on Learning Representations, 2020.   \n[84] X. Li, Z. Zhou, J. Zhu, J. Yao, T. Liu, and B. Han. Deepinception: Hypnotize large language model to be jailbreaker. arXiv preprint arXiv:2311.03191, 2023.   \n[85] Y. Li, B. Luo, Q. Wang, N. Chen, X. Liu, and B. He. A reflective llm-based agent to guide zero-shot cryptocurrency trading. arXiv preprint arXiv:2407.09546, 2024.   \n[86] Z. Li, X. Shang, R. He, T. Lin, and C. Wu. No fear of classifier biases: Neural collapse inspired federated learning with synthetic and fixed classifier. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 5319\u20135329, October 2023.   \n[87] P. P. Liang, T. Liu, L. Ziyin, N. B. Allen, R. P. Auerbach, D. Brent, R. Salakhutdinov, and L.-P. Morency. Think locally, act globally: Federated learning with local and global representations. arXiv preprint arXiv:2001.01523, 2020.   \n[88] T. Lin, L. Kong, S. U. Stich, and M. Jaggi. Ensemble distillation for robust model fusion in federated learning. In NeurIPS, 2020.   \n[89] J. Liu, Z. Shen, Y. He, X. Zhang, R. Xu, H. Yu, and P. Cui. Towards out-of-distribution generalization: A survey. arXiv preprint arXiv:2108.13624, 2021.   \n[90] L. Liu, X. Jiang, F. Zheng, H. Chen, G.-J. Qi, H. Huang, and L. Shao. A bayesian federated learning framework with online laplace approximation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023.   \n[91] Y. Long, B. Wang, Z. Yang, B. Kailkhura, A. Zhang, C. Gunter, and B. Li. G-pate: Scalable differentially private data generator via private aggregation of teacher discriminators. Advances in Neural Information Processing Systems, 34, 2021.   \n[92] B. Luo, Z. Zhang, Q. Wang, A. Ke, S. Lu, and B. He. Ai-powered fraud detection in decentralized finance: A project life cycle perspective. arXiv preprint arXiv:2308.15992, 2023.   \n[93] M. Luo, F. Chen, D. Hu, Y. Zhang, J. Liang, and J. Feng. No fear of heterogeneity: Classifier calibration for federated learning with non-IID data. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan, editors, Advances in Neural Information Processing Systems, 2021.   \n[94] Z. Luo, Y. Wang, Z. Wang, Z. Sun, and T. Tan. Disentangled federated learning for tackling attributes skew via invariant aggregation and diversity transferring. In K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, and S. Sabato, editors, Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pages 14527\u201314541. PMLR, 17\u201323 Jul 2022.   \n[95] M. S. Matena and C. A. Raffel. Merging models with fisher-weighted averaging. Advances in Neural Information Processing Systems, 35:17703\u201317716, 2022.   \n[96] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial Intelligence and Statistics, pages 1273\u20131282, 2017.   \n[97] L. Melis, C. Song, E. De Cristofaro, and V. Shmatikov. Exploiting unintended feature leakage in collaborative learning. In 2019 IEEE Symposium on Security and Privacy $(S P)$ , pages 691\u2013706. IEEE, 2019.   \n[98] V. Mugunthan, E. Lin, V. Gokul, C. Lau, L. Kagal, and S. Pieper. Fedltn: Federated learning for sparse and personalized lottery ticket networks. In European Conference on Computer Vision, pages 69\u201385. Springer, 2022.   \n[99] M. Naseer, S. Khan, M. Hayat, F. S. Khan, and F. Porikli. A self-supervised approach for adversarial robustness. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 262\u2013271, 2020.   \n[100] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y. Ng. Reading digits in natural images with unsupervised feature learning. In NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011, 2011.   \n[101] B. Neyshabur, S. Bhojanapalli, D. Mcallester, and N. Srebro. Exploring generalization in deep learning. In Advances in Neural Information Processing Systems, 2017.   \n[102] B. Neyshabur, H. Sedghi, and C. Zhang. What is being transferred in transfer learning? Advances in neural information processing systems, 2020.   \n[103] J. Nguyen, K. Malik, M. Sanjabi, and M. Rabbat. Where to begin? exploring the impact of pre-training and initialization in federated learning. arXiv preprint arXiv:2206.15387, 2022.   \n[104] N.-H. Nguyen, T.-A. Nguyen, T. Nguyen, V. T. Hoang, D. D. Le, and K.-S. Wong. Towards efficient communication federated recommendation system via low-rank training. arXiv preprint arXiv:2401.03748, 2024.   \n[105] A. v. d. Oord, Y. Li, and O. Vinyals. Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748, 2018.   \n[106] M. Pagliardini, M. Jaggi, F. Fleuret, and S. P. Karimireddy. Agree to disagree: Diversity through disagreement for better transferability. In The Eleventh International Conference on Learning Representations, 2023.   \n[107] N. Papernot and P. McDaniel. Deep k-nearest neighbors: Towards confident, interpretable and robust deep learning. arXiv preprint arXiv:1803.04765, 2018.   \n[108] Y. Park, D.-J. Han, D.-Y. Kim, J. Seo, and J. Moon. Few-round learning for federated learning. Advances in Neural Information Processing Systems, 34:28612\u201328622, 2021.   \n[109] J. Pearl. Causality. Cambridge university press, 2009.   \n[110] J. Peters, D. Janzing, and B. Sch\u00f6lkopf. Elements of causal inference: foundations and learning algorithms. The MIT Press, 2017.   \n[111] X. Qiu, J. Fernandez-Marques, P. P. Gusmao, Y. Gao, T. Parcollet, and N. D. Lane. ZeroFL: Efficient on-device training for federated learning with local sparsity. In International Conference on Learning Representations, 2022.   \n[112] Z. Qu, X. Li, R. Duan, Y. Liu, B. Tang, and Z. Lu. Generalized federated learning via sharpness aware minimization. In International Conference on Machine Learning, pages 18250\u201318280. PMLR, 2022.   \n[113] M. Raghu, J. Gilmer, J. Yosinski, and J. Sohl-Dickstein. Svcca: singular vector canonical correlation analysis for deep learning dynamics and interpretability. In Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS\u201917, 2017.   \n[114] S. J. Reddi, Z. Charles, M. Zaheer, Z. Garrett, K. Rush, J. Kone\u02c7cn\u00fd, S. Kumar, and H. B. McMahan. Adaptive federated optimization. In International Conference on Learning Representations, 2021.   \n[115] A. Reisizadeh, A. Mokhtari, H. Hassani, A. Jadbabaie, and R. Pedarsani. Fedpaq: A communication-efficient federated learning method with periodic averaging and quantization. In International Conference on Artificial Intelligence and Statistics, pages 2021\u20132031. PMLR, 2020.   \n[116] S. Sagawa, A. Raghunathan, P. W. Koh, and P. Liang. An investigation of why overparameterization exacerbates spurious correlations. In International Conference on Machine Learning, pages 8346\u20138356. PMLR, 2020.   \n[117] A. K. Sahu, T. Li, M. Sanjabi, M. Zaheer, A. Talwalkar, and V. Smith. On the convergence of federated optimization in heterogeneous networks. ArXiv, abs/1812.06127, 2018.   \n[118] A. M. Saxe, Y. Bansal, J. Dapello, M. Advani, A. Kolchinsky, B. D. Tracey, and D. D. Cox. On the information bottleneck theory of deep learning. Journal of Statistical Mechanics: Theory and Experiment, 2019(12):124020, 2019.   \n[119] B. Sch\u00f6lkopf, F. Locatello, S. Bauer, N. R. Ke, N. Kalchbrenner, A. Goyal, and Y. Bengio. Toward causal representation learning. Proceedings of the IEEE, 109(5):612\u2013634, 2021.   \n[120] V. Sehwag, S. Mahloujifar, T. Handina, S. Dai, C. Xiang, M. Chiang, and P. Mittal. Improving adversarial robustness using proxy distributions. arXiv preprint arXiv:2104.09425, 2021.   \n[121] M. Shin, C. Hwang, J. Kim, J. Park, M. Bennis, and S.-L. Kim. Xor mixup: Privacy-preserving data augmentation for one-shot federated learning. arXiv preprint arXiv:2006.05148, 2020.   \n[122] R. Shwartz-Ziv and N. Tishby. Opening the black box of deep neural networks via information. arXiv preprint arXiv:1703.00810, 2017.   \n[123] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. Dropout: A simple way to prevent neural networks from overftiting. J. Mach. Learn. Res., 15(1):1929\u20131958, jan 2014.   \n[124] Y. Sun, L. Shen, S. Chen, L. Ding, and D. Tao. Dynamic regularized sharpness aware minimization in federated learning: Approaching global consistency and smooth landscape. In Proceedings of the 40th International Conference on Machine Learning, 2023.   \n[125] Y. Sun, L. Shen, T. Huang, L. Ding, and D. Tao. Fedspeed: Larger local interval, less communication round, and higher generalization accuracy. In The Eleventh International Conference on Learning Representations, 2023.   \n[126] A. Z. Tan, H. Yu, L. Cui, and Q. Yang. Towards personalized federated learning. IEEE Transactions on Neural Networks and Learning Systems, pages 1\u201317, 2022.   \n[127] Z. Tang, X. Chu, R. Y. Ran, S. Lee, S. Shi, Y. Zhang, Y. Wang, A. Q. Liang, S. Avestimehr, and C. He. Fedml parrot: A scalable federated learning system via heterogeneity-aware scheduling on sequential and hierarchical training. arXiv preprint arXiv:2303.01778, 2023.   \n[128] Z. Tang, J. Huang, R. Yan, Y. Wang, Z. Tang, S. Shi, A. C. Zhou, and X. Chu. Bandwidth-aware and overlap-weighted compression for communication-efficient federated learning. In 53rd International Conference on Parallel Processing, Gotland, Sweden, 12\u201315 August 2024.   \n[129] Z. Tang, X. Kang, Y. Yin, X. Pan, Y. Wang, X. He, Q. Wang, R. Zeng, K. Zhao, S. Shi, A. C. Zhou, B. Li, B. He, and X. Chu. Fusionllm: A decentralized llm training system on geo-distributed gpus with adaptive compression, 2024.   \n[130] Z. Tang, S. Shi, and X. Chu. Communication-efficient decentralized learning with sparsification and adaptive peer selection. In 2020 IEEE 40th International Conference on Distributed Computing Systems (ICDCS), pages 1207\u20131208. IEEE, 2020.   \n[131] Z. Tang, S. Shi, X. Chu, W. Wang, and B. Li. Communication-efficient distributed deep learning: A comprehensive survey. arXiv preprint arXiv:2003.06307, 2020.   \n[132] Z. Tang, S. Shi, B. Li, and X. Chu. Gossipfl: A decentralized federated learning framework with sparsified and adaptive communication. IEEE Transactions on Parallel and Distributed Systems, pages 1\u201313, 2022.   \n[133] Z. Tang, Y. Wang, X. He, L. Zhang, X. Pan, Q. Wang, R. Zeng, K. Zhao, S. Shi, B. He, et al. Fusionai: Decentralized training and deploying llms with massive consumer-level gpus. The 32nd International Joint Conference on Artificial Intelligence, Symposium on Large Language Models (LLM@IJCAI 2023), 2023.   \n[134] Z. Tang, Y. Zhang, S. Shi, X. He, B. Han, and X. Chu. Virtual homogeneity learning: Defending against data heterogeneity in federated learning. In K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, and S. Sabato, editors, Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pages 21111\u201321132. PMLR, 17\u201323 Jul 2022.   \n[135] Z. Tang, Y. Zhang, S. Shi, X. Tian, T. Liu, B. Han, and X. Chu. Fedimpro: Measuring and improving client update in federated learning. In The Twelfth International Conference on Learning Representations, 2024.   \n[136] C. Thapa, M. A. P. Chamikara, S. Camtepe, and L. Sun. Splitfed: When federated learning meets split learning. arXiv preprint arXiv:2004.12088, 2020.   \n[137] Y. Tian, C. Sun, B. Poole, D. Krishnan, C. Schmid, and P. Isola. What makes for good views for contrastive learning. arXiv preprint arXiv:2005.10243, 2020.   \n[138] N. Tishby, F. C. Pereira, and W. Bialek. The information bottleneck method. In Proc. of the 37-th Annual Allerton Conference on Communication, Control and Computing, pages 368\u2013377, 1999.   \n[139] F. Utrera, E. Kravitz, N. B. Erichson, R. Khanna, and M. W. Mahoney. Adversarially-trained deep nets transfer better: Illustration on image classification. In International Conference on Learning Representations, 2020.   \n[140] B. Vivek and R. V. Babu. Single-step adversarial training with dropout scheduling. In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 947\u2013956. IEEE, 2020.   \n[141] H. Wang, M. Yurochkin, Y. Sun, D. Papailiopoulos, and Y. Khazaeni. Federated learning with matched averaging. In International Conference on Learning Representations, 2020.   \n[142] J. Wang, Q. Liu, H. Liang, G. Joshi, and H. V. Poor. Tackling the objective inconsistency problem in heterogeneous federated optimization. In arXiv preprint arXiv:2007.07481, 2020.   \n[143] N. Wang, W. Feng, yuchen deng, M. Duan, F. Liu, and S.-K. Ng. Data-free diversity-based ensemble selection for one-shot federated learning. Transactions on Machine Learning Research, 2023.   \n[144] Q. Wang, Z. Zhang, Z. Liu, S. Lu, B. Luo, and B. He. Ex-graph: A pioneering dataset bridging ethereum and x. In The Twelfth International Conference on Learning Representations, 2024.   \n[145] Y. Wang, Z. Ni, S. Song, L. Yang, and G. Huang. Revisiting locally supervised learning: an alternative to end-to-end training. In International Conference on Learning Representations, 2020.   \n[146] B. E. Woodworth, K. K. Patel, and N. Srebro. Minibatch vs local sgd for heterogeneous distributed learning. Advances in Neural Information Processing Systems, 33:6281\u20136292, 2020.   \n[147] H. Xiao, K. Rasul, and R. Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.   \n[148] P. Yadav, D. Tam, L. Choshen, C. Raffel, and M. Bansal. TIES-merging: Resolving interference when merging models. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[149] K. Yang, T. Zhou, Y. Zhang, X. Tian, and D. Tao. Class-disentanglement and applications in adversarial detection and defense. In NeurIPS, 2021.   \n[150] Z. Yang, Y. Zhang, Y. Zheng, X. Tian, H. Peng, T. Liu, and B. Han. Fedfed: Feature distillation against data heterogeneity in federated learning. Advances in Neural Information Processing Systems, 36, 2024.   \n[151] H. Ye, C. Xie, T. Cai, R. Li, Z. Li, and L. Wang. Towards a theoretical framework of outof-distribution generalization. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan, editors, Advances in Neural Information Processing Systems, 2021.   \n[152] M. Yi, L. Hou, J. Sun, L. Shang, X. Jiang, Q. Liu, and Z. Ma. Improved ood generalization via adversarial training and pretraing. In M. Meila and T. Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 11987\u201311997. PMLR, 18\u201324 Jul 2021.   \n[153] H. Yin, P. Molchanov, J. M. Alvarez, Z. Li, A. Mallya, D. Hoiem, N. K. Jha, and J. Kautz. Dreaming to distill: Data-free knowledge transfer via deepinversion. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8715\u20138724, 2020.   \n[154] T. Yoon, S. Shin, S. J. Hwang, and E. Yang. Fedmix: Approximation of mixup under mean augmented federated learning. In International Conference on Learning Representations, 2021.   \n[155] F. Yu, A. S. Rawat, A. Menon, and S. Kumar. Federated learning with only positive labels. In International Conference on Machine Learning, 2020.   \n[156] B. Yuan, Y. He, J. Q. Davis, T. Zhang, T. Dao, B. Chen, P. Liang, C. Re, and C. Zhang. Decentralized training of foundation models in heterogeneous environments. In NeurIPS, 2022.   \n[157] H. Yuan, W. R. Morningstar, L. Ning, and K. Singhal. What do we mean by generalization in federated learning? In International Conference on Learning Representations, 2022.   \n[158] D. Zhang, K. Ahuja, Y. Xu, Y. Wang, and A. Courville. Can subnetwork structure be the key to out-of-distribution generalization? In International Conference on Machine Learning, pages 12356\u201312367. PMLR, 2021.   \n[159] J. Zhang, C. Chen, B. Li, L. Lyu, S. Wu, S. Ding, C. Shen, and C. Wu. Dense: Data-free one-shot federated learning. Advances in Neural Information Processing Systems, 35, 2022.   \n[160] J. Zhang, Z. Li, B. Li, J. Xu, S. Wu, S. Ding, and C. Wu. Federated learning with label distribution skew via logits calibration. In Proceedings of the 39th International Conference on Machine Learning. PMLR, 2022.   \n[161] Y. Zhang, M. Gong, T. Liu, G. Niu, X. Tian, B. Han, B. Sch\u00f6lkopf, and K. Zhang. Adversarial robustness through the lens of causality. In International Conference on Learning Representations, 2021.   \n[162] Y. Zhang, Z. Yang, X. Tian, N. Wang, T. Liu, and B. Han. Robust training of federated models with extremely label deficiency. In The Twelfth International Conference on Learning Representations, 2024.   \n[163] Y. Zhao, M. Li, L. Lai, N. Suda, D. Civin, and V. Chandra. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582, 2018.   \n[164] Y. Zhou, G. Pu, X. Ma, X. Li, and D. Wu. Distilled one-shot federated learning. arXiv preprint arXiv:2009.07999, 2020.   \n[165] Z. Zhou, R. Tao, J. Zhu, Y. Luo, Z. Wang, and B. Han. Can large language models reason robustly with noisy rationales? In ICLR 2024 Workshop on Reliable and Responsible Foundation Models. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "Appendix / supplemental material ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "A Details of Algorithm ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Details of our algorithm is shown in Algorithm 1. ", "page_idx": 20}, {"type": "text", "text": "Algorithm 1 FL with FuseFL   \nInput: The number of split modules $K$ ; Initialized local modules $H_{m}^{1},...,H_{m}^{K}$ and classifier $\\Lambda_{m}$ .   \nOutput: The fused model $F_{\\mathrm{fus}}$ (Eq. 6). 1: # Train and fuse 2: for module $k=1,\\cdots\\,,K$ do 3: for each client $m\\in\\mathcal{M}$ in parallel do do 4: $\\theta_{m}^{k}\\gets\\mathtt{C l i e n t T r a i n}(k)$ ; 5: end for 6: Fuse $H_{\\mathrm{fus}}^{k}\\gets(H_{1}^{k},...,H_{M}^{k})$ as Eq. 4; 7: for each client $m\\in\\mathcal{M}$ in parallel do do 8: ClientAdapt $(k,H_{\\mathrm{fus}}^{k})$ ; 9: end for   \n10: end for   \n11: # Calibrate classifier   \n12: Averaging and calibrating final classifier $\\Lambda$ using CCVR [93] with object $\\ell(\\boldsymbol{F}_{\\mathrm{fus}};x,y)$ (Eq. 6);   \n13: Return Ffus.   \n14:   \n15: ClientTrain $(k)$ :   \n16: Build $\\boldsymbol{F}_{\\mathrm{fus}}^{k,m}$ follows Eq. 5;   \n17: Freeze ${\\widehat{H}}_{m}^{k-1},...,H_{m}^{1}$ ;   \n18: for each local iteration $j=0,\\cdots\\,,E$ do   \n19: $\\theta_{m,j+1}\\gets\\theta_{m,j}-\\eta_{k,j}\\nabla_{\\theta}\\ell(F_{\\mathrm{fus}}^{k,m};x,y),x,y\\sim\\mathcal{D}_{m};$   \n20: end for   \n21: Return $H_{m}^{k}$ parameterized with $\\theta_{m,E}^{k}$ ;   \n22:   \n23: ClientAdapt $(k,H_{\\mathrm{fus}}^{k})$ :   \n24: Build adaptor $A_{m}^{k+1}$ following $\\mathrm{Eq}\\,7$ or 8;   \n25: Stitch $H_{m}^{k+1}\\triangleq H_{m}^{k+1}\\circ A_{m}^{k+1}$ ;   \n26: ", "page_idx": 20}, {"type": "text", "text": "B Broader Impact ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "This work provides a novel OFL approach, aiming at advancing the field of federated learning. There are many potential societal consequences of our work. For instance, our work can extremely reduce the communication cost of FL, reducing energy consumption. Under the low-bandwidth communication environments like Internet with $1\\!\\sim10\\,\\mathrm{MB/s}$ [133; 156; 129], this method provides possibility to train super large models like large language models with low communication time. Furthermore, to the best of our knowledge, this is the first work that understands FL from the view of causality. There exist a large space for future works to study along this direction. ", "page_idx": 20}, {"type": "text", "text": "FuseFL can further inspire more research and applications in the communication-constrained scenarios, like extremely low communication bandwidth, and training large language models (LLM) in FL [129; 84; 165]. We will try to extend FuseFL into training LLMs or MoE in FL scenarios with its low communication costs. ", "page_idx": 20}, {"type": "text", "text": "To deploy transformer-based frameworks like current LLMs with the core idea of FuseFL in one-shot FL, we envision two methods here. ", "page_idx": 20}, {"type": "text", "text": "\u2022 Concat-and-freeze. Similar to training ResNet in FuseFL, we can block-wisely train and collect the transformer blocks together for each round; during local training, the output features of all transformer blocks are concatenated to feed into the subsequent layers. Due to the large resource consumption of pretraining, we do not evaluate this idea here. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "\u2022 Averaging-and-freeze LoRA. Here, we consider the finetuning scenarios with LoRA [59]. LoRA blocks can be seen as additional matrix mapping applied on the local Q V attentions and MLP layers. The output is the original feature plus the LoRA output. To use LoRA in FuseFL, we can follow the MoE style [31] or the averaging style [59]. Specifically, we consider averaging LoRAs on different clients together, then averaging and freezing all LoRAs in each transformer block to freeze the obtained aggregated features in each communication round. ", "page_idx": 21}, {"type": "text", "text": "C More related works ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We provide the comprehensive introduction of the related works in this section. The data heterogeneity problem in FL is introduced in Section C.1, and the communication compression in FL is introduced in Section C.3. Further, by seeing local datasets from other clients as the OOD datasets with respect to the isolated locally trained models, we review some methods in OOD generalization (Section C.5 and mutual information (Section C.4) to build a connection between them and FL with extremely low communication costs. We demystify our work from current works in Table 8, which is a detailed version of Table 1. ", "page_idx": 21}, {"type": "text", "text": "Table 8: Demystifying different FL algorithms. $T$ represents communication rounds, $S$ the model size, $M$ the number of clients. Practically, in communication-compression FL, the minimal sparsification ratio $Q_{\\mathrm{Spar}}$ is 0.1, the quantization ratio $Q_{\\mathrm{Quant}}$ is 0.125 ( $32\\rightarrow4\\mathrm{{bits})}$ ), and the low rank ratio $Q_{\\mathrm{LowR}}$ is 0.1, otherwise the convergence is difficult to achieve and significantly harming model performance. The \u201cCentralized\u201d means training the model with all datasets aggregated with SGD. Due to the data heterogeneity, the performance usually is: Centralized $\\geq$ FedAvg \u2265Ensemble. ", "page_idx": 21}, {"type": "table", "img_path": "E7fZOoiEKl/tmp/a293f6f9c841bf5de458cb081bb10702ecd0d33bb85881a7bf566532bb6cc15d.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "C.1 Data Heterogeneity in FL ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The Non-IID data distribution is the notorious problem in FL, which severely harms the convergence rate and model performance of FL. The sharp Non-IID data makes local clients learn much different weights [68; 146], resulting in heterogeneous feature [160; 134] and classifiers [93]. Current methods that address Non-IID data problems include following typical directions. ", "page_idx": 21}, {"type": "text", "text": "Some works design new FL optimizers to stabilize and accelerate convergence [114; 125]. Personalized FL aims to optimize different client models by learning knowledge from other clients and adapting to their own datasets [126; 88]. Distinguished from these works, how to alleviate data heterogeneity within extremely low communication costs is a new challenging problem, as clients have little possibility of communicating information with other clients. ", "page_idx": 21}, {"type": "text", "text": "Model regularization. This direction proposes to add a penalty of distances between local trained models and the server model. FedProx [117] directly uses the L2 distance between local models to the server model to constrain the local models not moving too far. SCAFFOLD [68] utilizes the historical local updates to correct update directions of local clients during local training. FedDyn [1] dynamically updates the objective functions to ensure the local optima between devices are asymptotically consistent. FedIR [57] claims that applying important weight to the client\u2019s local objectives helps to obtain an unbiased estimator of the global loss objective function. ", "page_idx": 21}, {"type": "text", "text": "Feature calibration. Some works focuses on align feature representations of different clients in similar spaces [82; 29; 134; 60]. MOON [82] adds the contrastive loss to between local and global models to learn a similar representation between clients, in which the global model acts as an intermediate agent to communicate between clients. It is found the local features of the same data largely shift between client models during local training [134]. To address this problem, virtual homogeneous learning [134] proposes to use a homogeneous dataset which can contain completely no information of original datasets, to calibrate the feature representations between clients. This technique improves the generalization performance and convergence speed of federated learning. SphereFed [29] adds constraints on learned representations of input data to be in a unit hypersphere shared by clients. Besides, SphereFed discovers that the non-overlapped feature distributions for the same class lead to weaker consistency of the local learning targets from another perspective. The prototype [60] methods propose to utilize a pre-defined vector of each class in the representation space, then align client feature representations with such prototype, which is also called virtual feature transfer learning [134]. FedImpro [135] estimates and share the feature distribution to alleviate the gradient diversity and enhance high-level model training. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "Classifier calibration. Due to the shifted features between clients, the classifier is usually trained with bias. And the final obtained classifier with FedAvg is normally prone to some specical classes. CCVR [93] is the first work to transmit the statistics of logits and label information of data samples to calibrate the classifier. In SphereFed [29], the classifier is fiexed with weights spanning the unit hypersphere, and calibrated by a mean squared loss. Some works also calibrate the classifier during or after training [24; 86; 69]. ", "page_idx": 22}, {"type": "text", "text": "Optimization schemes. From the optimization perspective, some methods regard local updates at clients as pseudo gradients [114] and design new FL optimizers to stabilize and accelerate convergence. FedNova [142] normalizes the local updates to reduce the inconsistency between the local and global optimization objective functions. FedAvgM [56] exploits the history updates of server model to avoid the overfits on the selected clients in each round. FedOpt [114] generalizes the centralized optimizers into FL scenario, and proposes FedAdaGrad, FedYogi, FedAdam. FedSpeed [125] utilizes a correction term on local updates to reduce the biases during training. FedSpeed also merges the stochastic gradient with a perturbation computed from an extra gradient ascent step in the neighborhood, to reduce the gradient heterogeneity. ", "page_idx": 22}, {"type": "text", "text": "Data&Feature sharing. The phenomenon of client drift primarily originates from data heterogeneity. To address this issue, researchers have discovered that sharing a subset of private data can markedly enhance convergence speed and generalization capability, as highlighted in [163]. However, this approach entails a compromise on the privacy of client data. ", "page_idx": 22}, {"type": "text", "text": "Consequently, to simultaneously mitigate data heterogeneity and uphold data privacy, a range of studies [45; 44; 17; 66; 85; 15] have proposed the addition of noise to data. This method allows for the sharing of data while providing a certain level of privacy protection. Alternatively, other research efforts concentrate on disseminating synthetic data portions [62; 91; 37; 43] or data statistics [121; 154], as opposed to raw data, in order to alleviate data heterogeneity. FedDF [88] employs external data and engages in knowledge distillation based on these data to facilitate the transfer of model knowledge between the server and clients. The fundamental concept of FedDF involves fine-tuning the aggregated model through knowledge distillation using newly shared data. ", "page_idx": 22}, {"type": "text", "text": "Additionally, to address feature shift, certain methodologies advocate for the sharing of features to enhance the convergence rate. Cronus [16] suggests the sharing of logits as a means to counteract poisoning attacks. CCVR [93] transmits the statistical data of logits to calibrate the final layer of federated models. CCVR [93] also shares parameters representative of local feature distribution. Importantly, this approach does not necessitate sharing the count of different labels with the server, thereby preserving the privacy of clients\u2019 label distribution. Furthermore, our method serves as a framework to leverage shared features in reducing gradient dissimilarity. The feature estimator employed need not be confined to the Gaussian distribution of local features; alternative estimators or even features from additional datasets, rather than private ones, may be utilized. In this direction, VHL [134] only requires to share the pure noise dataset, which can have completely no related information of the local private datasets, largely reducing the requirements of the shared datasets and can be exploited in practical scenarios. ", "page_idx": 22}, {"type": "text", "text": "Personalized FL. Personalized Federated Learning (PFL) aims to enable clients to optimize distinct personal models that can absorb knowledge from other clients and tailor it to their individual datasets, as detailed in [126]. The process of knowledge transfer in personalization primarily involves the introduction of personalized parameters [87; 136; 78], or the employment of knowledge distillation [46; 88; 79; 13] utilizing shared local features or supplementary datasets. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "However, due to the tendency of personalized federated models to prioritize optimizing local objective functions, they often do not achieve generic performance (as evaluated on a global test dataset) that is on par with conventional Federated Learning (FL) methodologies [20]. Given our primary objective of learning an enhanced generic model, we have chosen not to include comparisons and improve performance of personalized FL algorithms in our work. While achieving extremely low communication costs in PFL can be an interesting future work. ", "page_idx": 23}, {"type": "text", "text": "C.2 One-shot FL ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Current FL methods with communication costs of only one model size are referred as one-shot FL, different one-shot learning, the \u201cone-shot\u201d here means one communicating round [159; 38; 81; 164; 25]. Thus, the communication cost is limited as the model size $\\mathcal{M}$ for each client, less than FedAvg-style algorithms for $R$ times. While there are works that introduce additional communication costs to improve the performance of one-shot FL. Existing one-shot FL works can be categorized into average-based [63], ensemble-based [143] or model distillation based [52; 26], ", "page_idx": 23}, {"type": "text", "text": "Average-based methods include the basic baseline, one-shot FedAvg, which shows a severely bad performance, and some other advanced average methods [95; 65; 148]. FedFisher [63] proposes to utilize fisher information to avoid harming knowledge of local models when averaging on the server. Note that the similar methodology of using fisher information is also utilized to enhance the FedAvg [112] or bayesian FL [90; 6], which belongs to multi-round FL. All of them aims to avoid forgetting local learned knowledge like the classical exploitation of fisher information in continual learning [71]. Matching permutations between the weights of different models [5; 141] is another advanced method for model averaging. Linear mode connectivity [34; 102; 5] helps to explain to the part of the success of model averaging. However, due to the highly non-linear structure of deep neural networks, it is extremely difficult to find a method to directly average local clients through one round to obtain a perfect server model. Therefore, one-shot average method usually fails to achieve a good performance. ", "page_idx": 23}, {"type": "text", "text": "Ensemble-based methods are based on ensemble learning [38]. Intuitively, the server aggregates multiple local client models. Then, the direct way of deploying these models is to average outputed logits of them and make predictions [143]. Some methods propose to find a better model selection method to select local models that might be more familiar with the given inputs [143]. Some methods utilize prototype data [26] or generated datasets [52] to conduct better model selection in ensemble learning. ", "page_idx": 23}, {"type": "text", "text": "Model distillation methods are built upon the ensemble models [38; 81]. The core motivation is that the ensemble models occupy too much storage and require much extra computation costs. Thus [81] involved a public dataset for training. As a replacement of using global data, [164] transmits the distilled local datasets to server for model distillation. [25] clusters clients and communicates the mean data of each cluster. These methods require extra datasets, which may be impractical in some data-sensitive scenarios like medical and education data. And the large storage costs still exist when many clients upload their models for ensemble learning. ", "page_idx": 23}, {"type": "text", "text": "Note that there is also some work [108] that proposes to find a good initial model of FL in few communication rounds. Thus the convergence rate of FedAvg can be accelerated by this good initialization [103; 49]. The objective of this work is different from one-shot FL or ours. ", "page_idx": 23}, {"type": "text", "text": "C.3 Communication compressed FL ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Different from one-shot FL which reduces the communication frequency, communication compression methods aim to reduce the communication size in each round. Typical communication-compression methods [131] include sparsification [12; 64; 130; 132], quantization [115; 41] and low-rank decomposition [104; 72]. ", "page_idx": 23}, {"type": "text", "text": "Sparsification. Studies in [30; 12; 111; 132] have introduced a significant level of sparsity in the local model training stage, effectively reducing the number of parameters that need to be transmitted. The works represented in [33] have put forth the Lottery Ticket Hypothesis, suggesting the existence of trainable sub-networks within over-parameterized networks that can be independently trained without accuracy loss. Inspired by this concept, LotteryFL [78] and FedLTN [98] aim to identify and exchange these personalized lottery ticket networks between the server and clients. Moreover, Hetero-FLASH [9] employs adaptive sparsity, with objectives extending beyond identifying the optimal sub-network, to fully leveraging clients\u2019 resources. In contrast to focusing on personalized Federated Learning (FL), this paper primarily considers generic FL, where all clients share the same model structure. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "Quantization. Orthogonally to Sparsification, quantization emerges as an additional pivotal strategy to alleviate the communication bottleneck in Federated Learning. This method represents model updates with fewer bits than the conventional 32 or 64 bits, thus reducing numerical precision. FedPAQ [115] adopts periodic averaging of low-bit representations of local model updates to minimize both the frequency of communication and the overhead per round. Advancements in this realm have been furthered by [41], which introduces a variant of Quantization-Aware Training (QAT) robust to multiple bit-widths, eliminating the necessity for retraining in the FL context. ", "page_idx": 24}, {"type": "text", "text": "Low-rank decomposition. Concurrently, research in [104; 72] has utilized a low-rank decomposition of matrices to cultivate sparse models. Specifically, the weights of local trained models are decomposed into smaller matrices. Then these smaller matrices are communicated to the server for recovering the original weights. ", "page_idx": 24}, {"type": "text", "text": "While these methods also reduce the communication costs, they are far from reducing costs at an extremely low level of the one-shot FL and ours. Because these methods still require many even more communication rounds than FedAvg to achieve training convergence. ", "page_idx": 24}, {"type": "text", "text": "C.4 Mutual Information ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "The mutual information (MI) has garnered increasing attention in recent years with its explanation of how deep neural networks learn intermediate representations of the raw data. The Information Bottleneck (IB) principle [122; 118; 138] provides insights into the training dynamics of deep neural networks. Specifically, the neural network reduces the mutual information between raw data and representations layer by layer, while maximizing the mutual information between labels and representations. [2] introduces the nuisance variable into the mutual information, and proposes that mutual information between representation and the nuisance should be as less as possible. And it is proved that the empirical risk minimization (ERM) with stochastic gradient descent (SGD) has implicitly achieved the IB principle [2]. Some methods in unsupervised learning exploit maximization of mutual information [105; 137; 54] to enhance the feature representation. The contrastive learning [21; 50] maximizes the mutual information across varying views of the same input. ", "page_idx": 24}, {"type": "text", "text": "C.5 Out-of-Distribution Generalization ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Out-of-Distribution (OOD) generalization refers to the model performance on the unseen data distribution, which is called OOD data [89; 22; 3]. The spurious features widely exist in the realworld datasets, like the textures, shapes, colors of objects [53; 36; 35; 144; 92]. Classification with original labels with these properties often leads overftiting on these variables instead of learning the real mapping relationship $X\\rightarrow Y$ . It is found that the out-of-distribution generalization performance of a model learned by ERM [22; 151] is connected with the spurious features. It is found that the over-parameterization, increasing model size well beyond the point of zero training error, may hurt the test error on some data samples, while it improving the average test error on all data samples [116]. These aggravated test errors are called worst-group error [89]. ", "page_idx": 24}, {"type": "text", "text": "Invariant risk minimization (IRM) [8; 3] is proposed to address inheriting spurious correlations in trained models. It is shown that exploiting invariant causal relationships between datasets gathered from multiple environments rather than relying on varying spurious relationships appearing in isolated local datasets, help to improve the robustness of the learned predictors. [158] proposes that there exists a sub-network hidden in the full neural network that is unbiased functional (not focusing on spurious correlation), thus achieving better OOD performance. ", "page_idx": 24}, {"type": "text", "text": "However, some studies show that there is no clear winner between ERM and IRM when covariate shift happens [4], and ERM is still the state-of-the-art on many problems of OOD generalization [39]. ", "page_idx": 24}, {"type": "text", "text": "The colored MNIST (CMNIST) is also called anti-causal CMNIST proposed by [8; 4] is often used to study the OOD performance of different training methods. In our work, we directly add different geometry shapes with random colors on local clients as the spurious features (also called adversarial samples [149; 120; 55]) to explore how isolated local training and our algorithm are influenced by them. ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "It is proven that the self-supervised or unsupervised training with contrastive learning [55; 99] can help reduce the overfitting on spurious features. And dropout [123] also helps learning spurious relationships between label and the spurious features [140]. ", "page_idx": 25}, {"type": "text", "text": "D Details of Experiment Configuration ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "D.1 Hyper Parameters ", "text_level": 1, "page_idx": 25}, {"type": "table", "img_path": "E7fZOoiEKl/tmp/43d8f0c25437ab4f065224aba13951da553e5de054d4d9c563c89f17d23a5a63.jpg", "table_caption": ["Table 9: Learning rate of all experiments. "], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "The learning rate configuration has been listed in Table 9. We report the best results and their learning rates (searched in $\\left\\lbrace0.0001,0.001,0.01,0.1\\right\\rbrace$ ). During local updating, the optimizer is SGD with 0.9 momentum following most FL baselines [] ", "page_idx": 25}, {"type": "text", "text": "D.2 Hardware and software ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "The FedAvg baseline is conducted based on the standard commonly used FL library FedML [47; 127]. While other OFL baselines are implemented following [159]. All experiments are conducted based on NVIDIA 2080 Ti or NVIDIA V100 GPU for several hours. Users just need one single GPU to run these experiments. ", "page_idx": 25}, {"type": "text", "text": "D.3 Mutual Information Estimation ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Due to the extremely high dimension of intermediate features, MI estimation is very difficult [11]. Simple neural networks may fail to accurately estimate MI. Thus, we follow [145], to use the reconstruction error from $^h$ to $\\textbf{\\em x}$ to estimate the $I(h,x)$ , and the classification error to estimate $I(\\pmb{h},y)$ . The details are provided as follows. ", "page_idx": 25}, {"type": "text", "text": "Estimating $I(h,x)$ . Assume that $\\mathcal{R}(\\pmb{x}|h)$ denotes the expected error for reconstructing $\\textbf{\\em x}$ from $^h$ . It has been widely known that $\\mathcal{R}(\\boldsymbol{x}|h)$ follows $I(h,x)={\\bar{H}}(x)-H(x|h)\\geq H(x)-{\\bar{\\pi}}(x|h)$ , where $H(x)$ denotes the marginal entropy of $\\textbf{\\em x}$ , as a constant [54]. We estimate $I(h,x)$ by training a decoder parameterized by $w$ to reconstruct the original image $x$ , namely $I(h,x)\\approx\\operatorname*{max}_{w}[H(x)-\\mathcal{R}_{w}(x|h)]$ . For estimating $I(h,x)$ , the decoders are multiple up-sampling convolutional layers following [145]. ", "page_idx": 25}, {"type": "text", "text": "Estimating $I(h,y)$ . Since I(h, y) = $I(y)-H(y|h)\\,=\\,H(y)\\,-\\,\\mathbb{E}(h,y)[-\\log\\,p(y|h)]$ , we can directly train an auxiliary classifier $q\\psi(y|h)$ with parameters $\\psi$ to approximate $p(y|h)$ , such that we have $I(h,y)\\approx\\operatorname*{max}\\psi H(y)-\\mathbb{E}h[\\sum_{y}-p(y|h)\\mathrm{log~}q_{\\psi}(y|h)]$ . To summarize, given the split features $H^{k}$ at layer $k$ , we freeze previous layers that with index $i\\leq k$ , and train a new inserted linear layer as classifier as to estimate $I(h,y)$ . For estimating $I(h,x)$ , the decoder follows [145]. ", "page_idx": 25}, {"type": "text", "text": "D.4 Linear Separability ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Following [7; 101], for each layer $k$ to be examined, we stitch and train a linear classifier $M L P_{k}$ following it, while freezing previous layers. Thus, the linear separability of feature $H^{k}$ is shown by the classification error of $M L P_{k}$ . The MLP is trained by 10 epochs. ", "page_idx": 25}, {"type": "text", "text": "D.5 Backdoored Datasets ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Figure 5 shows the original images and the backdoored images of CIFAR-10. The shapes are added on images according to label indexes but with random colors. By training on backdoored images, the local model is easily to fit on the shapes instead of original images. Each shape occupies $10\\times10$ image size. Table 7 provides the test accuracy of different methods training with backdoored CIFAR10, showing that the performance is severely harmed by the backdoored datasets. While FuseFL is not severely affected by the backdoor. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "image", "img_path": "E7fZOoiEKl/tmp/575fa51eef44a9fa96621de46226dece2b91938b5dcc5a6ad301e476c95b2ae6.jpg", "img_caption": ["Figure 5: Each row is a class of original (upper) and backdoored (lower) images of CIFAR-10. The shapes are added on images according to label indexes. "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "E More Results ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "To validate the effect of FuseFL when training heterogeneous models with more clients, we further conduct experiments with $M=10$ and compare results with $M=5$ as shown in Table 10. Results show that the FuseFL well supports training heterogeneous models, of which the performance is still comparable with Ensemble FL, but requires much less storage cost than Ensemble. ", "page_idx": 26}, {"type": "text", "text": "E.1 Heterogeneous Model with Different Number of Clients ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Table 10 shows how number of clients influences the performance of FuseFL with average or conv1 $\\times1$ as adapter. Results show that with increased $M=10$ , FuseFL still provide benefits to training heterogeneous model. ", "page_idx": 26}, {"type": "text", "text": "Table 10: Accuracy with FuseFL with conv1 $_{\\times1}$ or averaging to support heterogeneous model design on CIFAR-10 with different number of clients. ", "page_idx": 26}, {"type": "table", "img_path": "E7fZOoiEKl/tmp/18c386e9ad96508234695a6531337f1211d08a921c96d0344529377210078c58.jpg", "table_caption": [], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "E.2 Comparisons with FedMA ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "FedMA [141] does not support training ResNet-18 and aggregating multi-layers blocks. Thus, we compare it with FedAvg and our methods on training VGG-9 on CIFAR-10. For FedAvg, we run it for 10 communication rounds. For ensemble FL methods, the training epoch is set as 200 and communication with only one round. For fair comparison, to keep the same computation burden, we divide the 200 epochs to each communication round in FuseFL and FedMA. Thus, FedMA, FuseFL and Ensemble FL have the same communication costs and $10\\times$ less than FedAvg. Note that the FuseFL can have different $K$ to decide its communication rounds, while FedMA has a fixed number of communication rounds, i.e. the number of layers in VGG-9. Thus, the total computation and communication costs of different baselines are same except for FedAvg. Results in Table 11 shows that FuseFL successfully outperforms other methods. Note that to achieve the comparable performance to hundreds-of-rounds FedAvg, the FedMA actually requires communicating multiple model size. UNder the limited communication constraints, the matching and averaging ways in FedMA show inferior performance than the feature concatenation and merging as used in FuseFL. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "table", "img_path": "E7fZOoiEKl/tmp/fcfeee62cfdcb6d6f31bc2cfb978bf7ecb0eaef7fbeb015801371c8fc9e5a3fc.jpg", "table_caption": ["Table 11: Comparing accuracy on CIFAR-10 with FedMA. "], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "E.3 Different Feature Fusion Methods ", "text_level": 1, "page_idx": 27}, {"type": "table", "img_path": "E7fZOoiEKl/tmp/04858a5c0a7b3df856ccde0e3dc733269724428c62ce4aaf0ca6a6629b7c9b73.jpg", "table_caption": ["Table 12: Accuracy with FuseFL with conv1 $\\times1$ or averaging as adapters of different non-IID degree on CIFAR-10. "], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "We verify the effect of using $\\mathrm{conv}1\\!\\times\\!1$ or simply averaging features as feature fusion in Table 12. Results shows that using conv1 $\\times1$ is generally better than averaging. With the decreased non-IID degree, the gap between conv1 $\\times1$ and averaging is smaller, demonstrating that more similar features require less feature adaptation through learning a mapping i.e. training a conv1 $\\times1$ . ", "page_idx": 27}, {"type": "text", "text": "E.4 Communication Cost Comparison ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "We provide the detailed communication costs of different methods in Table 13. The Other OFLs refer to advanced OFL method including DENSE [159], data-free KD methods DAFL [18] and ADI [153]. Table 13 shows that FuseFL does not increase the communication costs, while largely improving the model performance. ", "page_idx": 27}, {"type": "text", "text": "E.5 Higher Heterogeneity and More Baselines ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Table 14 provides more results of the higher heterogeneity ( $a=0.05)$ ) and more baselines including DENSE [159] and CoBoosting [23]. Results show that the CoBoosting can improve the performance than other baseline methods but fail to outperform FuseFL. ", "page_idx": 27}, {"type": "text", "text": "Both CoBoosting [23] and FEDCVAE-KD [52] focus on exploiting knowledge distillation methods to improve the performance of global models, while our method focuses on how to aggregate models together. Thus, the knowledge distillation is orthogonal with our method and may be utilized to enhance FuseFL. For example, one can consider running FuseFL first to obtain a fused global model. Then, this model can be used to conduct knowledge distillation to guide local model training with the FuseFL once again. ", "page_idx": 27}, {"type": "table", "img_path": "E7fZOoiEKl/tmp/fed06fd9efc90f1279d4d2f819ad538bc6667146e76e9635f89cb0dc57bb3711.jpg", "table_caption": ["Table 13: Communication costs. For different number of clients, the number of basic channels in ResNet-18 of FuseFL is set as 32, 20, 14, 9 with $M\\in\\{5,10,20,50\\}$ , respectively. "], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "table", "img_path": "E7fZOoiEKl/tmp/c3d35be67110ab5c7b02ccdc34fc1200d5ca35ade48f2c54b76db2948e069934.jpg", "table_caption": ["Table 14: Results of higher data heterogeneiry $(a=0.05)$ . "], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "F Limitation ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Finding invariant features. With our analysis in Section 3, it will be useful to choose the invariant features $R_{m}^{\\mathrm{inv}}$ during local training for client $n$ . Currently, under the communication and privacy constrains, it is further difficult to identify which features are spurious. We left this as the future work to explore. We do not explore and exploit this technique in this paper, as it is orthogonal to our core innovation technique, augmenting features by layer-wise model fusion. Nevertheless, by manually crafting spurious correlations by adding backdoored data samples into local dataset, we empirically prove FuseFL can effectively avoid the influences of spurious features. ", "page_idx": 28}, {"type": "text", "text": "Limited feature adaptation. In this work, as an initial trial, we only explore using averaging and conv1 $\\times1$ as the feature adaptation. Further methods can consider exploring better feature adaptation methods like using non-linear models. ", "page_idx": 28}, {"type": "text", "text": "Security issues. In this work, we do not explicitly consider the security issue. However, the vulnerability to attacks of FuseFL will not be higher than previous multi-round FedAvg, which requires many more communication rounds to achieve the same model performance as FuseFL. For example, FedAvg may require more than 100 rounds to achieve $70\\%$ test accuracy as FuseFL with $2\\sim4$ rounds, which introduces more communicated information and a higher possibility of attacks. And FuseFL has the same communication size with other OFL methods. ", "page_idx": 28}, {"type": "text", "text": "However, while the size of the communication does not increase, FuseFL increases the number of communication rounds compared to other OFL methods. There are some possible mitigations to address the security issues: ", "page_idx": 28}, {"type": "text", "text": "\u2022 Adversarial attacks. Some malicious clients might upload adversarial modules or backdoored modules that are used to misguide the aggregated model to generate incorrect or handcrafted predictions. For these attacks, the possible solution is to detect and reject such malicious uploading also through the lens of causality. Specifically, some images with the invariant features can be fed into the uploaded modules to see whether the output feature can be used to correctly classify images;   \n\u2022 Model inversion or Membership attack. Some malicious clients or the server may consider to conduct model inversion or membership attack to obtain the raw data of clients, thus threatening the user privacy. In this case, the learned module can be protected with differential privacy to enhance its security. ", "page_idx": 29}, {"type": "text", "text": "Multiple communication rounds. To enable concatenating local modules together and training based on aggregated features from these modules, multiple communication rounds are required in FuseFL. In this sense, FuseFL belongs to the few-shot FL. However, the communication cost of FuseFL is as same as other OFL methods, which is the main claim in the introduction (extremely low communication costs). ", "page_idx": 29}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: The main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 30}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: The limitations have been discussed in Section F. The communication cost and storage costs are compared in Table 4 and 13. The scalability on datasets and clients, computation efficiency, and whether supporting personalized model design have been discussed in Experiment Section 6. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 30}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: We build the causal graph without giving the theorem. The proof of Lemma 3.1 comes from [2] ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 31}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We have provided the experiment setting, specific baselines (Section 6), hyperparameters (Section D), the algorithm details (Algorithm A, hardware and software details (Section D.2). We have provided our open-sourced code link. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in ", "page_idx": 31}, {"type": "text", "text": "some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 32}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: We have provided our open-sourced code link. The library has provided the experiment and code instructions. And the datasets are public datasets as listed in Section 6, which can be downloaded online, or using Pytorch. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 32}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: We have provided the experiment setting, specific baselines, optimizers(Section 6), hyper-parameters (Section D), the algorithm details (Algorithm A, hardware and software details (Section D.2). ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 32}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 32}, {"type": "text", "text": "Answer: [No] ", "page_idx": 32}, {"type": "text", "text": "Justification: We do not report the error bars in our experiments. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that the paper does not include experiments. ", "page_idx": 32}, {"type": "text", "text": "\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 33}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: We have provided the experiment setting (Section 6) and hardware and software details (Section D.2). ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 33}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: This work does not incorporate any ethic concerns of NeurIPS. The datasets and models are commonly used in the community, and the method does not incorporate potential concerns. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 33}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: We have discussed the broader impact in Section B. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 34}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This paper poses no such risks. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 34}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: The datasets and baselines, used libraries are properly credited. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets. \u2022 The authors should cite the original paper that produced the code package or dataset. \u2022 The authors should state which version of the asset is used and, if possible, include a URL. ", "page_idx": 34}, {"type": "text", "text": "\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 35}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: The datasets and baselines, used libraries are well documented and cited. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 35}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 35}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 35}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 36}]