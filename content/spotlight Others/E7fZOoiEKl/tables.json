[{"figure_path": "E7fZOoiEKl/tables/tables_7_1.jpg", "caption": "Table 1: Demystifying different FL algorithms. T represents communication rounds, S the model size, M the number of clients. The \u201cCentralized\u201d means training the model with all datasets aggregated with SGD. \u201cComm.\u201d means communication.", "description": "This table compares different federated learning (FL) algorithms based on their communication cost, storage cost, ability to handle model heterogeneity, and whether they require extra data.  It shows that FedAvg has high communication costs, while one-shot methods like FuseFL significantly reduce this cost, but with trade-offs in terms of model heterogeneity support and extra data requirements.", "section": "5 Related Works"}, {"figure_path": "E7fZOoiEKl/tables/tables_8_1.jpg", "caption": "Table 2: Accuracy of different methods across \u03b1 = {0.1, 0.3, 0.5} on different datasets. Ensemble means ensemble learning with local trained models, which is an upper bound of all previous methods but impractical in FL due to the large memory costs and the weak scalability of clients. Thus, we highlight the best results in bold font except Ensemble.", "description": "This table presents the accuracy results of various federated learning (FL) methods across three different non-IID data distributions (\u03b1 = 0.1, 0.3, 0.5) and six datasets (MNIST, FMNIST, CIFAR-10, SVHN, CIFAR-100, Tiny-Imagenet).  The methods compared include FedAvg, FedDF, Fed-DAFL, Fed-ADI, DENSE, and the proposed FuseFL with different numbers of modules (K).  The \"Ensemble\" row represents the upper bound achievable by combining local models, although this is impractical due to high memory and scalability issues.  The table highlights the best-performing methods for each dataset and non-IID setting.", "section": "6.2 Experimental Results"}, {"figure_path": "E7fZOoiEKl/tables/tables_8_2.jpg", "caption": "Table 2: Accuracy of different methods across \u03b1 = {0.1, 0.3, 0.5} on different datasets. Ensemble means ensemble learning with local trained models, which is an upper bound of all previous methods but impractical in FL due to the large memory costs and the weak scalability of clients. Thus, we highlight the best results in bold font except Ensemble.", "description": "This table presents the accuracy of various federated learning (FL) methods across different datasets (MNIST, FMNIST, CIFAR-10, SVHN, CIFAR-100, Tiny-Imagenet) and non-IID data distribution levels (\u03b1 = 0.1, 0.3, 0.5).  The methods compared include FedAvg, FedDF, Fed-DAFL, Fed-ADI, DENSE, and FuseFL (with different numbers of modules K).  Ensemble represents a baseline method that uses all local models for prediction. The table highlights the best performance achieved for each setting, excluding the ensemble method (which is impractical due to high memory and scalability issues).  The results demonstrate the superior performance of FuseFL compared to other one-shot FL methods.", "section": "6.1 Experiment Setup"}, {"figure_path": "E7fZOoiEKl/tables/tables_9_1.jpg", "caption": "Table 2: Accuracy of different methods across \u03b1 = {0.1, 0.3, 0.5} on different datasets. Ensemble means ensemble learning with local trained models, which is an upper bound of all previous methods but impractical in FL due to the large memory costs and the weak scalability of clients. Thus, we highlight the best results in bold font except Ensemble.", "description": "This table presents the accuracy results of various federated learning (FL) methods on different datasets with varying degrees of non-IID data (represented by \u03b1).  The methods compared include FedAvg, FedDF, Fed-DAFL, Fed-ADI, DENSE, Ensemble, and FuseFL (with different numbers of modules, K). The Ensemble method serves as an upper bound for the other methods, but its high memory cost and scalability issues make it impractical for real-world FL scenarios.  The table highlights the best-performing method for each dataset and \u03b1 value, excluding the Ensemble method.", "section": "6.1 Experiment Setup"}, {"figure_path": "E7fZOoiEKl/tables/tables_9_2.jpg", "caption": "Table 6: Local and global accuracy of 5 local client models. BD0 and BD1 represent two clients trained on backdoored datasets. Normal0, Normal1, and Normal2 represent three clients trained on clean datasets.", "description": "This table presents the local and global accuracy results for 5 clients in a federated learning experiment. Two clients (BD0 and BD1) were trained on datasets with backdoor attacks, whereas three clients (Normal0, Normal1, and Normal2) were trained on clean datasets.  The \"Local Acc.\" column indicates the accuracy achieved by each client on their own local dataset, demonstrating that the models trained on the backdoored datasets achieved almost perfect accuracy. However, the \"Global Acc.\" column, which represents the accuracy obtained when all the models are aggregated on the server, shows a significant performance gap between clients trained on clean datasets and those trained on backdoored datasets.  This indicates the negative impact of backdoor attacks on the overall federated learning model.", "section": "6.2 Experimental Results"}, {"figure_path": "E7fZOoiEKl/tables/tables_9_3.jpg", "caption": "Table 7: Comparing accuracy on backdoored CIFAR-10.", "description": "This table presents the test accuracy of different methods on backdoored CIFAR-10 datasets. The test dataset is clean, and the number of backdoored clients (Mbd) varies between 1 and 2. The results show how the backdoored data influences the performance of different methods under varying non-IID degrees (\u03b1).", "section": "6.2 Experimental Results"}, {"figure_path": "E7fZOoiEKl/tables/tables_21_1.jpg", "caption": "Table 1: Demystifying different FL algorithms. T represents communication rounds, S the model size, M the number of clients. The \u201cCentralized\u201d means training the model with all datasets aggregated with SGD. \u201cComm.\u201d means communication.", "description": "This table compares different federated learning (FL) algorithms across several key characteristics: communication cost, storage cost, performance upper bound, support for model heterogeneity, and requirement for external data.  It highlights the trade-offs between communication efficiency, model performance, and data requirements of various FL approaches.", "section": "Related Works"}, {"figure_path": "E7fZOoiEKl/tables/tables_25_1.jpg", "caption": "Table 2: Accuracy of different methods across \u03b1 = {0.1, 0.3, 0.5} on different datasets. Ensemble means ensemble learning with local trained models, which is an upper bound of all previous methods but impractical in FL due to the large memory costs and the weak scalability of clients. Thus, we highlight the best results in bold font except Ensemble.", "description": "This table shows the accuracy of various federated learning methods across three different levels of data heterogeneity (\u03b1 = 0.1, 0.3, 0.5) and six different datasets (MNIST, FMNIST, CIFAR-10, SVHN, CIFAR-100, Tiny-Imagenet). The methods compared include FedAvg, FedDF, Fed-DAFL, Fed-ADI, DENSE, and the proposed FuseFL with different numbers of modules (K=2, 4, 8).  Ensemble learning is also included as an upper bound, although it's impractical for real-world federated learning due to its high memory cost and scalability issues. The best results for each setting are highlighted in bold, excluding the Ensemble results.", "section": "6.1 Experiment Setup"}, {"figure_path": "E7fZOoiEKl/tables/tables_26_1.jpg", "caption": "Table 10: Accuracy with FuseFL with conv1x1 or averaging to support heterogeneous model design on CIFAR-10 with different number of clients.", "description": "This table compares the performance of different model fusion methods (FuseFL with conv1x1, FuseFL with averaging, FuseFL with conv1x1 and heterogeneous models, FuseFL with averaging and heterogeneous models) on CIFAR-10 dataset with varying number of clients (M=5, M=10).  The \"Ensemble\" row provides a benchmark representing the upper bound performance achievable through ensembling local models.", "section": "E.1 Heterogeneous Model with Different Number of Clients"}, {"figure_path": "E7fZOoiEKl/tables/tables_27_1.jpg", "caption": "Table 11: Comparing accuracy on CIFAR-10 with FedMA.", "description": "This table compares the accuracy of various federated learning algorithms, including FedAvg, FedMA, Ensemble, and FuseFL with different numbers of blocks (K), on the CIFAR-10 dataset.  The comparison is made for three different levels of non-IID data distribution (\u03b1 = 0.1, 0.3, 0.5). The table highlights the performance of FuseFL in achieving comparable or better accuracy than other methods, especially when considering the constraint of only one communication round. It shows that FuseFL generally outperforms the other methods under one-shot communication constraints.", "section": "6.2 Experimental Results"}, {"figure_path": "E7fZOoiEKl/tables/tables_27_2.jpg", "caption": "Table 2: Accuracy of different methods across \u03b1 = {0.1, 0.3, 0.5} on different datasets. Ensemble means ensemble learning with local trained models, which is an upper bound of all previous methods but impractical in FL due to the large memory costs and the weak scalability of clients. Thus, we highlight the best results in bold font except Ensemble.", "description": "This table presents the accuracy results of different federated learning methods (FedAvg, FedDF, Fed-DAFL, Fed-ADI, DENSE, Ensemble, and FuseFL) on various datasets (MNIST, FMNIST, CIFAR-10, SVHN, CIFAR-100, Tiny-Imagenet) under different non-IID data distribution levels (\u03b1 = 0.1, 0.3, 0.5).  The Ensemble method serves as an upper bound, highlighting the performance limitations of other one-shot federated learning methods.  FuseFL's best results are bolded, demonstrating its superior performance compared to other methods except the computationally expensive Ensemble method.", "section": "6.2 Experimental Results"}, {"figure_path": "E7fZOoiEKl/tables/tables_28_1.jpg", "caption": "Table 1: Demystifying different FL algorithms. T represents communication rounds, S the model size, M the number of clients. The \u201cCentralized\u201d means training the model with all datasets aggregated with SGD. \u201cComm.\u201d means communication.", "description": "This table compares several federated learning (FL) algorithms based on their communication costs, storage costs, and support for model heterogeneity.  It highlights the communication and storage cost savings of one-shot FL and the proposed FuseFL method while showing their performance in comparison with multi-round FL methods and ensemble methods. The table also notes whether the methods require additional data for training.", "section": "Related Works"}, {"figure_path": "E7fZOoiEKl/tables/tables_28_2.jpg", "caption": "Table 14: Results of higher data heterogeneiry (a = 0.05).", "description": "This table presents the accuracy results of different federated learning methods on various datasets (MNIST, FMNIST, SVHN, CIFAR-10, CIFAR-100) under a higher degree of data heterogeneity (\u03b1 = 0.05).  It compares the performance of FuseFL with several baseline methods including FedAvg, FedDF, Fed-ADI, Fed-DAFL, DENSE, and CoBoosting.  The results demonstrate the accuracy of each method across these datasets.  The purpose is to show that FuseFL performs well even under significant data heterogeneity.", "section": "6.2 Experimental Results"}]