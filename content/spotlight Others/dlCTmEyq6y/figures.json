[{"figure_path": "dlCTmEyq6y/figures/figures_2_1.jpg", "caption": "Figure 1: Semi-supervised classification and support recovery regions. The red and green regions follow from previous works. Contributions of our work include identification of the orange and the blue regions.", "description": "This figure shows different regions in the (\u03b3, \u03b2) plane, where \u03b3 represents the number of unlabeled samples and \u03b2 represents the number of labeled samples. The red region shows where classification and feature selection are impossible. The green region shows where support estimation is computationally feasible using only unlabeled data. The orange region shows where accurate classification and feature selection are computationally hard. The blue region shows where it is possible to construct an accurate SSL classifier in polynomial time. The white region is where the feasibility of classification and feature selection are unknown. The x-axis represents the amount of unlabeled data and the y-axis represents the amount of labeled data.", "section": "Semi-Supervised Learning Scheme"}, {"figure_path": "dlCTmEyq6y/figures/figures_9_1.jpg", "caption": "Figure 2: Empirical simulation results. (Left) Support recovery, (Right) Classification error.", "description": "This figure shows the results of empirical simulations comparing several semi-supervised learning (SSL), supervised learning (SL), and unsupervised learning (UL) algorithms on a sparse high-dimensional Gaussian classification task.  The left panel displays the support recovery accuracy, showing the fraction of correctly identified features for each method as the number of unlabeled samples (n) increases. The right panel displays the classification error rate of the different methods, where lower error rates indicate better performance.  The results highlight the benefits of combining labeled and unlabeled data for accurate classification in high-dimensional sparse settings.  LSPCA and LS2PCA, the proposed SSL methods, consistently show superior performance to SL and UL techniques.", "section": "Simulation Results"}, {"figure_path": "dlCTmEyq6y/figures/figures_9_2.jpg", "caption": "Figure 3: Empirical simulation results. (Left) Support recovery, (Right) Classification error.", "description": "The figure shows empirical results comparing the performance of several semi-supervised learning algorithms for sparse Gaussian classification in high dimensions.  The left panel displays the support recovery accuracy (the fraction of correctly identified features) of different algorithms as the number of labeled samples (L) increases, while keeping the number of unlabeled samples fixed. The right panel shows the corresponding classification error rates. The algorithms compared include LSPCA (proposed), LS2PCA (an improved variant of LSPCA), a self-training algorithm, LSDF, and a top-k labeled data-only method. The results demonstrate the superiority of the proposed LSPCA and LS2PCA algorithms over supervised, unsupervised and other SSL approaches, highlighting the provable benefits of combining labeled and unlabeled data in this setting.", "section": "Simulation Results"}]