[{"figure_path": "7uqVfZW6Mo/figures/figures_1_1.jpg", "caption": "Figure 1: Prior arts only consider a small fraction of potential activations in diffusion models. As a result, more advanced diffusion architecture fails to achieve better performance (SDXL v.s. SDv1.5). In contrast, we consider a broader range of candidate activations. To facilitate the quantitative comparison, we first make a comprehensive and generalizable analysis to qualitatively filter out many candidates in advance. On top of this, our method achieves superior performance (75.2 PCK@0.1).", "description": "This figure compares the approach of previous studies and the proposed approach of this paper for selecting discriminative features from diffusion models.  Previous studies only considered a limited set of activations (inter-module activations), leading to suboptimal performance with advanced models like SDXL.  In contrast, this paper considers a much wider range of activations, including those from ViT modules, and uses qualitative filtering to reduce the search space before quantitative comparison. This improved approach resulted in superior performance (75.2 PCK@0.1). The figure visually shows examples of activations considered in each approach.", "section": "1 Introduction"}, {"figure_path": "7uqVfZW6Mo/figures/figures_3_1.jpg", "caption": "Figure 2: U-Net architecture (upper) and the ViT module (lower), taking SDXL as an example.", "description": "This figure illustrates the architecture of a U-Net used in diffusion models, specifically highlighting the SDXL model as an example.  The upper part shows the overall U-Net structure, divided into three main stages: down-stage, mid-stage, and up-stage.  Each stage involves multiple resolution modules, which in turn contain ResModules (convolutional ResNet structures), ViT Modules, and down/up samplers.  The lower part focuses on a single ViT module, showing its internal structure composed of several basic blocks. Each basic block consists of self-attention, cross-attention (in modern versions), and feed-forward layers. The figure uses color-coding to differentiate between different components and illustrates the flow of activations through the network.", "section": "3 Preliminaries: Architecture of Diffusion U-Nets"}, {"figure_path": "7uqVfZW6Mo/figures/figures_4_1.jpg", "caption": "Figure 3: We highlight three properties of diffusion U-Nets that are distinct from existing knowledge about other models: (a) Asymmetric diffusion noises. (b) In-resolution granularity changes. (c) Locality without positional embeddings: pixels within the orange circle resemble nearby background pixels more than distant pixels on the horse's neck that are semantically closer.", "description": "This figure highlights three key properties of diffusion U-Nets that differentiate them from traditional U-Nets or Vision Transformers (ViTs).  It visually demonstrates these properties through activation visualizations:\n\n(a) **Asymmetric Diffusion Noises:** Diffusion models introduce noise at various frequencies during training; this figure shows that this noise is not uniformly distributed across the network, being more pronounced in the downsampling stages and less in the upsampling stages. \n(b) **In-Resolution Granularity Changes:**  Traditional U-Nets have a gradual change in granularity across resolutions.  Diffusion U-Nets, however, show a significant granularity change *within* a single resolution. This is visually shown as the activations evolving from coarse to fine granularity within a single resolution.\n(c) **Locality without Positional Embeddings:**  ViTs typically use positional embeddings to maintain spatial information.  However, the diffusion U-Net's ViT modules exhibit a form of locality despite the absence of positional embeddings, where nearby pixels are more similar than semantically close, distant pixels. This is highlighted with an orange circle around a region of pixels that have more resemblance to surrounding background pixels than to semantically similar pixels further away.", "section": "4 Distinct Properties of Diffusion U-Nets"}, {"figure_path": "7uqVfZW6Mo/figures/figures_6_1.jpg", "caption": "Figure 1: Prior arts only consider a small fraction of potential activations in diffusion models. As a result, more advanced diffusion architecture fails to achieve better performance (SDXL v.s. SDv1.5). In contrast, we consider a broader range of candidate activations. To facilitate the quantitative comparison, we first make a comprehensive and generalizable analysis to qualitatively filter out many candidates in advance. On top of this, our method achieves superior performance (75.2 PCK@0.1).", "description": "This figure compares the activation selection methods in previous studies and the proposed method in the paper. The left side shows that previous studies only considered a small fraction of potential activations from diffusion models, which resulted in suboptimal performance for more advanced architectures such as SDXL. The right side illustrates that the proposed method considers a broader range of activations, qualitatively filters them, and achieves superior performance, as shown by the higher PCK@0.1 value.", "section": "1 Introduction"}, {"figure_path": "7uqVfZW6Mo/figures/figures_15_1.jpg", "caption": "Figure 3: We highlight three properties of diffusion U-Nets that are distinct from existing knowledge about other models: (a) Asymmetric diffusion noises. (b) In-resolution granularity changes. (c) Locality without positional embeddings: pixels within the orange circle resemble nearby background pixels more than distant pixels on the horse's neck that are semantically closer.", "description": "This figure highlights three key properties of diffusion U-Nets that differentiate them from traditional U-Nets and Vision Transformers (ViTs).  It visually demonstrates these properties using activation visualizations from a diffusion model applied to an image of a horse. (a) Asymmetric Diffusion Noises: Shows that diffusion noises impact both high and low-frequency signals asymmetrically during the forward and reverse passes of the diffusion process. (b) In-Resolution Granularity Changes: Illustrates that within a single resolution, the granularity of information changes significantly, unlike traditional U-Nets. (c) Locality without Positional Embeddings: Demonstrates that even without positional embeddings, there's a degree of locality in self-attention mechanisms, where nearby pixels in the feature space are more similar than semantically related but spatially distant pixels.", "section": "4 Distinct Properties of Diffusion U-Nets"}, {"figure_path": "7uqVfZW6Mo/figures/figures_15_2.jpg", "caption": "Figure 3: We highlight three properties of diffusion U-Nets that are distinct from existing knowledge about other models: (a) Asymmetric diffusion noises. (b) In-resolution granularity changes. (c) Locality without positional embeddings: pixels within the orange circle resemble nearby background pixels more than distant pixels on the horse's neck that are semantically closer.", "description": "This figure highlights three key properties of diffusion U-Nets that differentiate them from traditional U-Nets and Vision Transformers.  It visually demonstrates these properties using activation visualizations from different stages of a diffusion U-Net.  Specifically: (a) shows how diffusion noise affects activations asymmetrically across the down- and up-sampling stages, (b) shows in-resolution granularity changes within each resolution level of the U-Net, and (c) illustrates how locality is preserved in self-attention query and key activations even without positional embeddings.", "section": "4 Distinct Properties of Diffusion U-Nets"}, {"figure_path": "7uqVfZW6Mo/figures/figures_16_1.jpg", "caption": "Figure 7: Visualization of SDXL activations on a simple indoor scene.", "description": "This figure visualizes the activations of the Stable Diffusion XL (SDXL) model on a simple indoor scene. It highlights three key properties of diffusion U-Nets that distinguish them from traditional U-Nets and Vision Transformers (ViTs): asymmetric diffusion noise, in-resolution granularity changes, and locality without positional embeddings.  The visualization shows how these properties manifest across the down-stage, mid-stage, and up-stage of the U-Net architecture. Specifically, it demonstrates that diffusion noise is significant in the down-stage, less so in the mid-stage, and only partially reappears in the later half of the up-stage. It also shows how granularity changes within a single resolution and the persistence of locality within self-attention despite the absence of positional embeddings.", "section": "4 Distinct Properties of Diffusion U-Nets"}, {"figure_path": "7uqVfZW6Mo/figures/figures_16_2.jpg", "caption": "Figure 3: We highlight three properties of diffusion U-Nets that are distinct from existing knowledge about other models: (a) Asymmetric diffusion noises. (b) In-resolution granularity changes. (c) Locality without positional embeddings: pixels within the orange circle resemble nearby background pixels more than distant pixels on the horse's neck that are semantically closer.", "description": "This figure highlights three key properties of diffusion U-Nets that differentiate them from traditional U-Nets and Vision Transformers (ViTs).  It visually demonstrates these properties through activation visualizations at different levels of the network:\n\n(a) **Asymmetric Diffusion Noises:** Shows how diffusion noise, introduced during the diffusion process, affects both high and low-frequency components asymmetrically across the different stages (down-sampling, middle, up-sampling) of the U-Net. \n(b) **In-Resolution Granularity Changes:** Illustrates how within a single resolution, the granularity of information changes, unlike traditional U-Nets where this change is primarily assumed to occur across different resolutions.\n(c) **Locality without Positional Embeddings:** Demonstrates the presence of locality in self-attention mechanisms even without explicit positional embeddings. This shows how activations related to the same semantic concept cluster together spatially, even without positional information.", "section": "4 Distinct Properties of Diffusion U-Nets"}, {"figure_path": "7uqVfZW6Mo/figures/figures_17_1.jpg", "caption": "Figure 3: We highlight three properties of diffusion U-Nets that are distinct from existing knowledge about other models: (a) Asymmetric diffusion noises. (b) In-resolution granularity changes. (c) Locality without positional embeddings: pixels within the orange circle resemble nearby background pixels more than distant pixels on the horse's neck that are semantically closer.", "description": "This figure highlights three key properties of diffusion U-Nets that differentiate them from traditional U-Nets and Vision Transformers (ViTs).  (a) shows that diffusion noises, introduced by the diffusion process, affect both high and low-frequency signals asymmetrically across the down-stage and up-stage of the U-Net. (b) illustrates in-resolution granularity changes, demonstrating that the information granularity varies within a single resolution, due to the increased size of each resolution in modern diffusion U-Nets.  Finally, (c) shows locality without positional embeddings, where pixels within a localized region share similar features despite being semantically distant compared to those farther away.", "section": "4 Distinct Properties of Diffusion U-Nets"}, {"figure_path": "7uqVfZW6Mo/figures/figures_17_2.jpg", "caption": "Figure 11: Visualization of SDXL activations on a complex indoor scene.", "description": "This figure visualizes the activations of the Stable Diffusion XL (SDXL) model on a complex indoor scene. It highlights the three distinct properties of diffusion U-Nets: asymmetric diffusion noises, in-resolution granularity changes, and locality without positional embeddings. The visualization shows how these properties manifest in different stages (down-stage, mid-stage, up-stage) and resolutions of the U-Net architecture.  Each level displays a series of activation maps, illustrating the changes in noise levels, granularity, and locality across the network.", "section": "A Additional Visualization for Distinct Properties of Diffusion U-Nets"}, {"figure_path": "7uqVfZW6Mo/figures/figures_18_1.jpg", "caption": "Figure 3: We highlight three properties of diffusion U-Nets that are distinct from existing knowledge about other models: (a) Asymmetric diffusion noises. (b) In-resolution granularity changes. (c) Locality without positional embeddings: pixels within the orange circle resemble nearby background pixels more than distant pixels on the horse's neck that are semantically closer.", "description": "This figure highlights three key properties of diffusion U-Nets that differentiate them from traditional U-Nets and Vision Transformers (ViTs).  It visually demonstrates these properties using activation visualizations from a Stable Diffusion XL (SDXL) model.  Specifically:\n\n(a) **Asymmetric Diffusion Noises:** Shows that diffusion noise affects both high and low-frequency signals asymmetrically throughout the U-Net's processing stages (down-sampling, mid-stage, up-sampling).  The noise is more prevalent in earlier stages and decreases in the early part of the up-sampling process, only to reappear later.\n(b) **In-Resolution Granularity Changes:** Illustrates that within each resolution level, there are variations in granularity, indicating a change in the level of detail of information extracted at different layers or stages within a resolution.\n(c) **Locality without Positional Embeddings:** Demonstrates that even without explicit positional embeddings, there's still a form of locality within the self-attention mechanism.  Nearby pixels share more similar features than semantically related but spatially distant pixels.", "section": "4 Distinct Properties of Diffusion U-Nets"}, {"figure_path": "7uqVfZW6Mo/figures/figures_18_2.jpg", "caption": "Figure 3: We highlight three properties of diffusion U-Nets that are distinct from existing knowledge about other models: (a) Asymmetric diffusion noises. (b) In-resolution granularity changes. (c) Locality without positional embeddings: pixels within the orange circle resemble nearby background pixels more than distant pixels on the horse's neck that are semantically closer.", "description": "This figure highlights three key properties of diffusion U-Nets that differentiate them from traditional U-Nets and Vision Transformers (ViTs).  It shows visualizations demonstrating:\n(a) **Asymmetric Diffusion Noises:** Diffusion models introduce noise at all frequencies, but this noise's effect is not symmetric across the network's down-sampling and up-sampling stages. Noise is more significant in the down-sampling stages.\n(b) **In-Resolution Granularity Changes:** Unlike traditional U-Nets that focus on granularity change across different resolutions, diffusion U-Nets display significant granularity changes within a single resolution, which is important for feature selection.\n(c) **Locality without Positional Embeddings:** Even without positional embeddings, the self-attention mechanism in ViTs within diffusion U-Nets exhibits locality, meaning that activations show similarity to spatially close pixels rather than semantically similar but distantly located pixels. The orange circle highlights this effect, where activations in that region resemble background activations more than distant pixels.", "section": "4 Distinct Properties of Diffusion U-Nets"}, {"figure_path": "7uqVfZW6Mo/figures/figures_19_1.jpg", "caption": "Figure 3: We highlight three properties of diffusion U-Nets that are distinct from existing knowledge about other models: (a) Asymmetric diffusion noises. (b) In-resolution granularity changes. (c) Locality without positional embeddings: pixels within the orange circle resemble nearby background pixels more than distant pixels on the horse's neck that are semantically closer.", "description": "This figure highlights three key properties of diffusion U-Nets that differentiate them from traditional U-Nets or Vision Transformers (ViTs).  It visually demonstrates these properties across different stages (down-stage, mid-stage, up-stage) of a diffusion U-Net's architecture.  Specifically:\n\n(a) **Asymmetric Diffusion Noises:** Diffusion models introduce noise, and this noise impacts both high and low-frequency signals unevenly across the network's stages.  The asymmetry means the effect of this noise isn't uniform as the model processes an image.\n(b) **In-Resolution Granularity Changes:** Unlike traditional U-Nets, diffusion U-Nets exhibit significant granularity changes *within* a single resolution, altering the quality of features extracted from different levels of the same resolution. This is due to the \"fatter\" structure of the networks (fewer resolutions, more feature channels).\n(c) **Locality Without Positional Embeddings:** While lacking conventional positional embeddings, self-attention mechanisms in ViT modules within diffusion U-Nets still demonstrate locality.  This means that activations respond more strongly to nearby pixels in space than semantically similar but distant pixels.", "section": "4 Distinct Properties of Diffusion U-Nets"}, {"figure_path": "7uqVfZW6Mo/figures/figures_19_2.jpg", "caption": "Figure 3: We highlight three properties of diffusion U-Nets that are distinct from existing knowledge about other models: (a) Asymmetric diffusion noises. (b) In-resolution granularity changes. (c) Locality without positional embeddings: pixels within the orange circle resemble nearby background pixels more than distant pixels on the horse's neck that are semantically closer.", "description": "This figure highlights three key properties of diffusion U-Nets that differentiate them from traditional U-Nets and Vision Transformers (ViTs).  It visually demonstrates these properties using activation visualizations from a diffusion model. \n(a) **Asymmetric Diffusion Noises**: Shows that diffusion-induced noise affects both high and low-frequency signals asymmetrically across the down- and up-sampling stages of the U-Net.\n(b) **In-Resolution Granularity Changes**: Illustrates that within a single resolution, the granularity (level of detail) of the activations changes significantly, unlike traditional U-Nets.\n(c) **Locality without Positional Embeddings**:  Highlights the existence of locality (nearby pixels are more similar) in self-attention mechanisms even without explicit positional embeddings, which differs from standard ViTs.", "section": "4 Distinct Properties of Diffusion U-Nets"}, {"figure_path": "7uqVfZW6Mo/figures/figures_20_1.jpg", "caption": "Figure 1: Prior arts only consider a small fraction of potential activations in diffusion models. As a result, more advanced diffusion architecture fails to achieve better performance (SDXL v.s. SDv1.5). In contrast, we consider a broader range of candidate activations. To facilitate the quantitative comparison, we first make a comprehensive and generalizable analysis to qualitatively filter out many candidates in advance. On top of this, our method achieves superior performance (75.2 PCK@0.1).", "description": "The figure shows a comparison of previous studies and the proposed method for selecting activations in diffusion models. Previous studies only considered a small fraction of potential activations, leading to suboptimal performance in advanced models like SDXL.  The authors' method considers a broader range of activations and uses qualitative filtering to reduce the number of candidates before quantitative comparison, resulting in superior performance.", "section": "1 Introduction"}, {"figure_path": "7uqVfZW6Mo/figures/figures_28_1.jpg", "caption": "Figure 3: We highlight three properties of diffusion U-Nets that are distinct from existing knowledge about other models: (a) Asymmetric diffusion noises. (b) In-resolution granularity changes. (c) Locality without positional embeddings: pixels within the orange circle resemble nearby background pixels more than distant pixels on the horse's neck that are semantically closer.", "description": "This figure highlights three key properties of diffusion U-Nets that differentiate them from traditional U-Nets and Vision Transformers (ViTs).  Panel (a) shows that diffusion models introduce \"diffusion noise\" that impacts both high and low-frequency signals asymmetrically during the denoising process. Panel (b) demonstrates that in-resolution granularity changes are significant in diffusion U-Nets due to their design with fewer but wider resolutions compared to traditional U-Nets. Finally, panel (c) illustrates that, despite lacking positional embeddings (common in ViTs), there is still a notion of locality where a pixel's representation is more similar to nearby pixels than semantically-related distant pixels.", "section": "4 Distinct Properties of Diffusion U-Nets"}, {"figure_path": "7uqVfZW6Mo/figures/figures_28_2.jpg", "caption": "Figure 17: This visualization shows the granularity change across all inter-module activations of one resolution. At the end, the activations start to contain some slight noises, which is a sign of over-refinement.", "description": "This figure shows how the granularity of the activations changes from coarse to fine as the network processes the input.  The progression is visualized across multiple inter-module activation outputs from a single resolution layer within the U-Net.  At the very end, the appearance of slight noise in the activations suggests that the refinement process has gone too far, indicating a potential point of diminishing returns in terms of extracting useful features.", "section": "E.2 Detailed In-Resolution Granularity Change"}, {"figure_path": "7uqVfZW6Mo/figures/figures_29_1.jpg", "caption": "Figure 1: Prior arts only consider a small fraction of potential activations in diffusion models. As a result, more advanced diffusion architecture fails to achieve better performance (SDXL v.s. SDv1.5). In contrast, we consider a broader range of candidate activations. To facilitate the quantitative comparison, we first make a comprehensive and generalizable analysis to qualitatively filter out many candidates in advance. On top of this, our method achieves superior performance (75.2 PCK@0.1).", "description": "The figure compares two approaches to selecting activation features from diffusion models for discriminative tasks.  Previous studies only considered a limited subset of activations, resulting in lower performance for more advanced models like SDXL. The proposed method considers a wider range of activations and employs qualitative filtering to reduce the number of candidates for a quantitative comparison. This approach leads to significantly improved performance.", "section": "1 Introduction"}]