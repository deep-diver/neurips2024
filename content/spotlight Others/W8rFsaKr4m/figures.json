[{"figure_path": "W8rFsaKr4m/figures/figures_2_1.jpg", "caption": "Figure 1: Comparison of different propagation strategies for multi-modal tasks. For visual tasks, the previous strategies (a) are based on fixed patterns, while our method can adaptively generate the propagation topology according to input features. For textual tasks, compared to previous methods (c), our approach (d) can break the inherent constraints of text sequences, facilitating the effective transmission of long-range information.", "description": "This figure compares different propagation strategies for visual and textual tasks.  Previous visual SSMs (a) use raster, continuous, or local scanning, resulting in spatial discontinuities and limiting information flow.  In contrast, MambaTreeV (b) dynamically generates a tree topology based on input features, enabling better long-range interactions. Similarly, previous textual SSMs (c) are limited by sequence constraints, while MambaTreeL (d) creates a tree topology to improve long-range dependency modeling in text.", "section": "3 Method"}, {"figure_path": "W8rFsaKr4m/figures/figures_3_1.jpg", "caption": "Figure 2: Illustration of Tree State Space Model. With an image feature map x, we perform Tree Scanning Algorithm (TSA) to construct a 4-connected graph with edge weights measured by dissimilarity between pixels. Then, we obtain an MST with vertices set \u03a9 through a pruning algorithm and perform the state transition for each vertex in this topology (detailed in Sec. 3.2). Red arrows describe the propagation source of vertex i.", "description": "This figure illustrates the architecture of the proposed Tree State Space Model (TSSM).  It starts with an input feature map (x), which undergoes a 4-connected graph construction based on pixel dissimilarity.  This graph is then pruned to form a minimum spanning tree (MST). A tree scanning algorithm (TSA) processes this MST, performing state transitions for each vertex. The state transition parameters (A, B, C, D) are dynamically generated.  The red arrows highlight the feature propagation direction.  The overall process combines spatial and semantic information for improved feature representation, moving beyond limitations of previous linear sequences.", "section": "3 Method"}, {"figure_path": "W8rFsaKr4m/figures/figures_4_1.jpg", "caption": "Figure 3: Overview of MambaTreeV. LN means LayerNorm and FFN is a feed-forward network in the basic block. S2 and P1 denote stride of 2 and padding size of 1 in convolution, respectively.", "description": "This figure provides a detailed architecture overview of the MambaTreeV model, which is designed for visual tasks.  It illustrates the stem, four stages of basic blocks, downsampling layers, and the head. Each stage employs basic blocks incorporating a tree state space model, layer normalization (LN), and feed-forward networks (FFN). The stem performs initial feature extraction from the input image, and downsampling layers reduce the spatial dimensions at each stage. The head is responsible for generating final predictions for downstream tasks such as classification, detection, and segmentation.", "section": "3.3 Application for Vision and Language"}, {"figure_path": "W8rFsaKr4m/figures/figures_7_1.jpg", "caption": "Figure 1: Comparison of different propagation strategies for multi-modal tasks. For visual tasks, the previous strategies (a) are based on fixed patterns, while our method can adaptively generate the propagation topology according to input features. For textual tasks, compared to previous methods (c), our approach (d) can break the inherent constraints of text sequences, facilitating the effective transmission of long-range information.", "description": "This figure compares different propagation strategies for visual and textual tasks.  It shows that previous methods used fixed patterns (raster, continuous, local scan) for propagating features in visual SSMs, leading to spatial discontinuities and inefficient information flow.  In contrast, the proposed MambaTree dynamically generates a tree topology based on input features, breaking sequence constraints for improved long-range dependency modeling. For text, previous approaches were constrained by the inherent sequential nature of text, while MambaTree's tree topology facilitates more effective long-range interactions.", "section": "1 Introduction"}, {"figure_path": "W8rFsaKr4m/figures/figures_14_1.jpg", "caption": "Figure 5: Classification performance comparison among SSM-based vision foundation models.", "description": "This figure compares the performance of various SSM (State Space Model)-based vision models on ImageNet-1K dataset.  It plots Top-1 Accuracy against FLOPs (floating-point operations per second). Different colors represent different models (MambaTreeV, PlainMamba, VMamba, ViM, LocalMamba), and different shapes within each color represent different model scales. The size of each shape is proportional to the number of model parameters. The figure visually demonstrates the trade-off between computational efficiency and accuracy for different SSM-based approaches.", "section": "A.1 Image Classification"}, {"figure_path": "W8rFsaKr4m/figures/figures_17_1.jpg", "caption": "Figure 1: Comparison of different propagation strategies for multi-modal tasks. For visual tasks, the previous strategies (a) are based on fixed patterns, while our method can adaptively generate the propagation topology according to input features. For textual tasks, compared to previous methods (c), our approach (d) can break the inherent constraints of text sequences, facilitating the effective transmission of long-range information.", "description": "This figure compares different feature propagation strategies in state-space models for both visual and textual data.  It shows that previous methods used fixed patterns (raster, continuous, local scans) for visual data, leading to spatial discontinuities and hindering information flow.  For textual data, previous methods were limited by the sequential nature of text. In contrast, the proposed MambaTree method dynamically generates a tree topology based on input features (visual or textual), breaking these limitations and improving long-range dependency modeling.", "section": "3 Method"}]