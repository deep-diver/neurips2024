{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces the foundational Denoising Diffusion Probabilistic Models (DDPMs), a core technology that underpins the image and video generation methods in StoryDiffusion."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper presents a significant improvement in image generation quality and resolution that StoryDiffusion builds upon for generating high-quality images."}, {"fullname_first_author": "Aditya Ramesh", "paper_title": "Hierarchical text-conditional image generation with CLIP latents", "publication_date": "2022-01-01", "reason": "This paper introduces a method that leverages CLIP's image-text understanding capabilities, directly influencing StoryDiffusion's approach to text-to-image generation."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Imagen video: High definition video generation with diffusion models", "publication_date": "2022-12-01", "reason": "This paper is crucial to StoryDiffusion because it adapts diffusion models for high-quality video generation, a key element of StoryDiffusion's capabilities."}, {"fullname_first_author": "Xinyuan Chen", "paper_title": "SEINE: Short-to-long video diffusion model for generative transition and prediction", "publication_date": "2023-01-01", "reason": "This paper proposes a state-of-the-art method for generating video transitions, directly relevant to StoryDiffusion's video generation module."}]}