[{"figure_path": "vBlzen37i0/figures/figures_8_1.jpg", "caption": "Figure 1: Elliptic diffusion equation. Average relative L(X; Y)-norm error versus m for different DNNs approximating the solution operator for the elliptic diffusion equation (B.9). The first two plots use the affine coefficient a1,d (B.1) with d = 4, 8, respectively. The rest use the log-transformed coefficient a2,d (B.2).", "description": "This figure shows the performance of different DNN architectures in approximating the solution operator of the parametric elliptic diffusion equation.  The error is measured using the average relative L(X;Y)-norm and plotted against the number of training samples (m). The results are shown for both affine and log-transformed diffusion coefficients, with different parametric dimensions (d = 4 and d = 8).  Each line represents a different DNN architecture, showing how the error decreases as the number of training samples increases.", "section": "Numerical experiments"}, {"figure_path": "vBlzen37i0/figures/figures_8_2.jpg", "caption": "Figure 2: NSB equations. Average relative L(X; Y)-norm error versus m for different DNNs approximating the velocity field u of the NSB problem in (B.14). See Fig. 7 for results for the pressure component p. The diffusion coefficients a1,d, a2,d and d = 4, 8 are as in Fig. 1.", "description": "This figure shows the average relative L(X;Y)-norm error for different deep neural network (DNN) architectures in approximating the velocity field (u) of the parametric Navier-Stokes-Brinkman (NSB) equations.  The results are shown for different numbers of training samples (m) and for both affine and log-transformed diffusion coefficients. The plot includes error bars to show variability and a reference line indicating a rate of m\u207b\u00b9.  A similar figure (Figure 7) shows the same results, but for the pressure component (p).", "section": "Numerical experiments"}, {"figure_path": "vBlzen37i0/figures/figures_9_1.jpg", "caption": "Figure 3: Boussinesq equation. Average relative L(X; Y)-norm error versus m for different DNNs approximating the temperature of the Boussinesq problem in (B.16) (see Fig. 9 for u and p). The diffusion coefficients a1,d, a2,d and d = 4, 8 are as in Fig. 1. In this example, we also consider an additional parametric dependence in the tensor K = K(x) describing the thermal conductivity of the fluid. See \u00a7B.5 and (B.17).", "description": "This figure compares the performance of different DNN architectures on approximating the temperature field (\u03c6) of the Boussinesq equation. It shows the average relative L2 error versus the number of training samples (m) for various DNNs with different activation functions (ELU, ReLU, tanh) and sizes (4x40, 10x100).  The results are shown for both affine and log-transformed diffusion coefficients and two parametric dimensions (d=4 and d=8).  An additional parametric dependence in the thermal conductivity tensor (K) is also considered in this example.", "section": "Numerical experiments"}, {"figure_path": "vBlzen37i0/figures/figures_21_1.jpg", "caption": "Figure 4: The domain \u03a9 and FE mesh for the parametric diffusion equation.", "description": "This figure shows the domain (\u03a9) and the finite element mesh used in the numerical experiments for the parametric elliptic diffusion equation. The domain is a unit square, and the mesh is a regular triangulation consisting of triangles.", "section": "B Description of the parametric PDEs used in the numerical experiments and their discretization"}, {"figure_path": "vBlzen37i0/figures/figures_21_2.jpg", "caption": "Figure 5: The solution u(x) of the parametric Poisson problem in (B.9) for a given parameter x = (1,0,0,0) with affine coefficient a1,d and d = 4, using a total of K = 2622 DoF. The left plot shows the solution given by the FEM solver. The right plot show the ELU 4 \u00d7 40 DNN approximation after 60, 000 epochs of training with m = 500 sample points for training.", "description": "This figure compares the solution of the parametric Poisson equation (B.9) generated by the FEM solver and the ELU 4x40 DNN approximation.  The left plot shows the solution from the FEM solver, while the right plot shows the DNN approximation after 60,000 training epochs with 500 training samples. Both plots illustrate the solution u(x) for a specific parameter set (1,0,0,0), using an affine coefficient (a1,d) and a parametric dimension d=4. The total degrees of freedom used in the FEM discretization is 2622.", "section": "Numerical experiments"}, {"figure_path": "vBlzen37i0/figures/figures_23_1.jpg", "caption": "Figure 5: The solution u(x) of the parametric Poisson problem in (B.9) for a given parameter x = (1,0,0,0) with affine coefficient a1,d and d = 4, using a total of K = 2622 DoF. The left plot shows the solution given by the FEM solver. The right plot show the ELU 4 \u00d7 40 DNN approximation after 60, 000 epochs of training with m = 500 sample points for training.", "description": "This figure compares the solution of the parametric Poisson problem (B.9) obtained using a Finite Element Method (FEM) solver against the solution obtained using an ELU 4x40 Deep Neural Network (DNN).  The DNN was trained on 500 sample points. The figure displays both solutions for a specific parameter set (x = (1,0,0,0)). The left panel shows the FEM solution, while the right panel shows the DNN approximation. This visualization helps assess the accuracy of the DNN in approximating the FEM solution for the given problem.", "section": "Numerical experiments"}, {"figure_path": "vBlzen37i0/figures/figures_24_1.jpg", "caption": "Figure 2: NSB equations. Average relative L(X; Y)-norm error versus m for different DNNs approximating the velocity field u of the NSB problem in (B.14). See Fig. 7 for results for the pressure component p. The diffusion coefficients a1,d, a2,d and d = 4, 8 are as in Fig. 1.", "description": "This figure compares the average relative L(X;Y)-norm error for different DNN architectures (4x40 and 10x100 with ReLU, ELU, and tanh activations) applied to the parametric Navier-Stokes-Brinkman (NSB) equations.  The error is plotted against the number of training samples (m). Two parametric dimensions (d=4 and d=8) and two diffusion coefficients (affine and log-transformed) are considered. The results show that ELU and tanh DNNs generally outperform ReLU architectures.  A separate figure (Figure 7) provides corresponding results for the pressure component (p).", "section": "Numerical experiments"}, {"figure_path": "vBlzen37i0/figures/figures_26_1.jpg", "caption": "Figure 1: Elliptic diffusion equation. Average relative L\u00b2(X; Y )-norm error versus m for different DNNs approximating the solution operator for the elliptic diffusion equation (B.9). The first two plots use the affine coefficient a1,d (B.1) with d = 4, 8, respectively. The rest use the log-transformed coefficient a2,d (B.2).", "description": "This figure compares the average relative L2 error versus the number of training samples (m) for different DNN architectures in solving the parametric elliptic diffusion equation.  It showcases the performance of various DNNs (with different activation functions and sizes) using both affine and log-transformed diffusion coefficients with varying parametric dimensions (d=4 and d=8).  The results illustrate the impact of DNN architecture and coefficient type on the learning outcome.", "section": "Numerical experiments"}, {"figure_path": "vBlzen37i0/figures/figures_26_2.jpg", "caption": "Figure 3: Boussinesq equation. Average relative L\u00b2(X; Y)-norm error versus m for different DNNs approximating the temperature of the Boussinesq problem in (B.16) (see Fig. 9 for u and p). The diffusion coefficients a\u2081,d, a\u2082,d and d = 4, 8 are as in Fig. 1. In this example, we also consider an additional parametric dependence in the tensor K = K(a) describing the thermal conductivity of the fluid. See \u00a7B.5 and (B.17).", "description": "The figure shows the average relative L\u00b2(X;Y) error versus the number of training samples (m) for different DNN architectures (ELU, ReLU, tanh) in approximating the temperature component of the solution of a parametric Boussinesq equation.  Two parametric dimensions (d = 4, 8) and two types of diffusion coefficients (affine and log-transformed) are considered.  The results demonstrate the performance of the different DNN architectures and the effect of increasing the number of training samples on the error, providing insights into the convergence rates.", "section": "Numerical experiments"}]