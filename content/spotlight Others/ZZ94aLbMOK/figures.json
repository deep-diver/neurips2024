[{"figure_path": "ZZ94aLbMOK/figures/figures_2_1.jpg", "caption": "Figure 1: A. Overview of the proposed architecture (right) and its relation to CNNs (left) and RNNs (middle). B. Various dynamical regimes exhibited by randomly-initialized CordsNets. C. Aligned neural trajectories between a CordsNet and a low-rank RNN trained on a perceptual decision-making task (left), as well as between a CordsNet and a sparse RNN trained on a multi-sensory decision-making task (right). D. Example of a CordsNet trained to perform a memory-pro delayed response task by storing a circular variable in memory using a ring attractor.", "description": "This figure provides a visual overview of the proposed CordsNet architecture and its relationship to traditional CNNs and RNNs.  Panel A shows a comparison of the three architectures. Panel B illustrates the various dynamic regimes that CordsNet can exhibit, including stable, oscillatory, and chaotic patterns of neural activity. Panels C and D demonstrate the ability of CordsNet to produce similar dynamical results to other RNN architectures and to successfully perform the memory-pro delayed response task, respectively.", "section": "Model architecture"}, {"figure_path": "ZZ94aLbMOK/figures/figures_4_1.jpg", "caption": "Figure 2: A. Architecture of CordsNet-R4. B. Proposed initialization method. A feedforward CNN is first trained (top). The parameters are then used to initialize and train linear RNNs (middle). Non-linearity is then introduced by annealing (bottom). C. Multiply-accumulate operations (MACs) of 79 CNN models (green/grey) and CordsNet (purple) plotted against parameter counts. D. Validation accuracy of our models trained on ImageNet using the aforementioned three steps (dashed lines), compared to training CordsNet (purple circles) and fully-connected RNNs (green circles) directly.", "description": "This figure shows the architecture of CordsNet-R4, a hybrid model that combines convolutional and recurrent neural network features. It also details the proposed three-step initialization method, comparing the computational cost (MACs) of CordsNet with other CNN models and illustrating the validation accuracy on ImageNet.", "section": "Training and results"}, {"figure_path": "ZZ94aLbMOK/figures/figures_6_1.jpg", "caption": "Figure 3: A. Evolution of a single interpretable feature map over time in the first layer of a feedforward CNN (middle) and CordsNet-R8 (bottom). B. Neural activity and softmax output of a feedforward CNN (green), discrete-time CNN (red), and CordsNet-R8 (purple) in response to various stimuli sequences. C. Mean-squared deviation from noiseless activations of the output layer across 50000 noisy images. D. ImageNet validation accuracies over 5 noise levels.", "description": "This figure demonstrates the temporal dynamics of CordsNet compared to other CNN architectures. Panel A shows how a single feature map evolves over time in CordsNet, highlighting its continuous-time nature. Panel B compares the neural activity and softmax output of CordsNet, a feedforward CNN, and a discrete-time CNN under different stimulus sequences.  C shows the robustness of CordsNet to noise by measuring the mean-squared error between its noisy and noiseless activations. Finally, panel D shows the validation accuracy of CordsNet on ImageNet across various noise levels, demonstrating its superior robustness to noise compared to traditional CNNs.", "section": "Model analysis"}, {"figure_path": "ZZ94aLbMOK/figures/figures_7_1.jpg", "caption": "Figure 4: A. Arnoldi iteration [63] applied to a convolutional recurrent weight matrix. B. Model activations in CordsNet-R4 trained to classify images in time intervals [140 ms, 200 ms] (purple) and [240 ms, 300 ms] (green), along with their top 100 eigenvalues (right). C. Neural trajectories in the final layer of CordsNet-R8 projected onto two dimensions when presented with 3 different images.", "description": "This figure demonstrates the analysis of CordsNet from a dynamical systems perspective. Panel A shows the application of Arnoldi iteration to analyze the convolutional recurrent weight matrix. Panel B shows model activations and eigenvalues for CordsNet-R4 trained to classify images at different time intervals, highlighting the different dynamical characteristics exhibited depending on the training time. Panel C visualizes neural trajectories from the final layer of CordsNet-R8, projected onto two dimensions, for three different images, showcasing the model's ability to perform autonomous inference.", "section": "Model analysis"}, {"figure_path": "ZZ94aLbMOK/figures/figures_8_1.jpg", "caption": "Figure 5: A multi-area model consisting of CordsNet-R8 connected to a fully-connected RNN trained on various cognitive tasks in neuroscience. A. Numerical quantification task where monkeys are required to remember the number of visual features on the screen. B. Discrimination task where monkeys must discern whether an image is predominantly cat or dog. C. Delayed-response task where monkeys have to saccade to the location of a previously shown stimulus. D. Evidence integration task where monkeys are required to tell if random dots are moving left or right.", "description": "This figure demonstrates the application of CordsNet as a front-end for a multi-area model performing complex cognitive tasks.  Four different tasks are shown: a numerical quantification task, a categorical discrimination task, an oculomotor delayed-response task, and a perceptual decision-making task. Each panel shows example inputs, the expected output, and neural activity plots demonstrating the model's performance on each task. The tasks use actual stimuli from monkey experiments rather than abstract representations, showcasing the model's capacity to handle naturalistic visual inputs.", "section": "5 Applications"}, {"figure_path": "ZZ94aLbMOK/figures/figures_9_1.jpg", "caption": "Figure 6: A. Framework of Brain-Score (Vision). B. Normalized CordsNet-R8 activity in the last two layers compared with experimentally-recorded [68] normalized activity in visual areas V4 and IT. C. Similarity metrics between CordsNet model activations and neural data (dark purple) and temporally-shuffled neural data (light purple). (paired t-test, ** p < 10-4, *** p<10-7)", "description": "This figure demonstrates the ability of the CordsNet model to predict the temporal dynamics of neural activity in the visual cortex. Panel A illustrates the experimental setup, showing the flow of visual information from V1 to IT and how CordsNet's activity is compared to neural recordings. Panel B displays the time courses of CordsNet's activity compared with real neural recordings in V4 and IT, showing that the model replicates the pattern of activity. Finally, panel C quantitatively assesses the similarity between the model and the experimental data using correlation metrics and shows statistically significant similarity.", "section": "6 Discussion and conclusion"}, {"figure_path": "ZZ94aLbMOK/figures/figures_15_1.jpg", "caption": "Figure S1: A. Examples of convolutional kernels, their resultant flattened weight matrices as described in equation (2) and their distribution of singular values. B. Gaussian-initialized CordsNets exhibiting an oscillatory regime (left) and a chaotic regime (right). In each regime, we plot the population trajectory of the space of the first two principal components (left), the cumulative variance explained and participation ratio (middle) and activity autocorrelation (right).", "description": "This figure demonstrates the dynamical characteristics of CordsNets by showing the distribution of singular values for different kernel sizes (A) and analyzing the activity patterns in the oscillatory and chaotic regimes (B). In the oscillatory regime, activity shows a periodic pattern in low-dimensional space, whereas in the chaotic regime, the activity is aperiodic and unpredictable.", "section": "B Analysis of dynamical characteristics"}, {"figure_path": "ZZ94aLbMOK/figures/figures_17_1.jpg", "caption": "Figure 2: A. Architecture of CordsNet-R4. B. Proposed initialization method. A feedforward CNN is first trained (top). The parameters are then used to initialize and train linear RNNs (middle). Non-linearity is then introduced by annealing (bottom). C. Multiply-accumulate operations (MACs) of 79 CNN models (green/grey) and CordsNet (purple) plotted against parameter counts. D. Validation accuracy of our models trained on ImageNet using the aforementioned three steps (dashed lines), compared to training CordsNet (purple circles) and fully-connected RNNs (green circles) directly.", "description": "This figure shows the architecture of CordsNet-R4, a hybrid model that combines convolutional and recurrent neural network components. It also details the proposed initialization method, which involves training a feedforward CNN, initializing linear RNNs with its parameters, and then introducing non-linearity through annealing.  The figure further compares the computational efficiency of CordsNet with other CNNs based on MACs and parameter counts. Finally, it contrasts the ImageNet validation accuracy of CordsNet trained using this method with that of directly trained CordsNets and fully-connected RNNs.", "section": "Training and results"}, {"figure_path": "ZZ94aLbMOK/figures/figures_18_1.jpg", "caption": "Figure S3: Evolution of neural activity across time in CordsNets trained to perform a memory-pro delayed-response task [20]. During the delay epoch, neural activity converges to different fixed/slow points depending on the stimulus that was presented in the previous epoch. Depending on the type of stimulus presented, the trained networks may exhibit ring (left), line (middle) or point attractors (right) during the delay epoch. In the response epoch, neural activity rotates to the output axis and approximately preserves the same geometry [20].", "description": "This figure demonstrates the different types of attractor dynamics exhibited by CordsNets during a memory-pro delayed-response task. Depending on the stimulus, the network's activity converges to a ring, line, or point attractor during the delay period, and then rotates towards the output during the response period, preserving the attractor's geometry.", "section": "B.4 Attractor formation"}, {"figure_path": "ZZ94aLbMOK/figures/figures_21_1.jpg", "caption": "Figure 3: A. Evolution of a single interpretable feature map over time in the first layer of a feedforward CNN (middle) and CordsNet-R8 (bottom). B. Neural activity and softmax output of a feedforward CNN (green), discrete-time CNN (red), and CordsNet-R8 (purple) in response to various stimuli sequences. C. Mean-squared deviation from noiseless activations of the output layer across 50000 noisy images. D. ImageNet validation accuracies over 5 noise levels.", "description": "This figure demonstrates the temporal dynamics of CordsNet compared to other CNN architectures. (A) shows an example of a feature map evolving over time in CordsNet-R8. (B) compares the neural activity and softmax output of different CNN architectures under various stimulus sequences, highlighting CordsNet's ability to maintain accurate classifications across time. (C) and (D) illustrate CordsNet's robustness to noise, showing its resilience in noisy image classification tasks compared to traditional CNNs.", "section": "4 Model analysis"}]