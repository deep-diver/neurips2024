[{"figure_path": "JDAQwysFOc/tables/tables_1_1.jpg", "caption": "Table 1: Schematic illustration of RUM. All 4-step unbiased random walks from the 2-degree carbon atom in the (hydrogen-omitted) chemical graph of propylene oxide, a key precursor for manufacturing polyurethane. The arrows indicate the direction of the walks and numbers the order in which each node is visited. The semantic (w) and topological (wu) representations of each walk are shown.", "description": "This table provides a schematic illustration of the RUM (Random Walk with Unifying Memory) neural network. It showcases all possible 4-step unbiased random walks originating from a 2-degree carbon atom within the propylene oxide molecule.  Each walk is visually represented, showing the path taken and the order of node visits.  The table also shows the semantic (features of nodes visited) and topological (order of unique nodes visited) representations associated with each walk, highlighting how RUM combines these aspects for node embeddings.", "section": "Architecture: combining topologic and semantic trajectories of walks"}, {"figure_path": "JDAQwysFOc/tables/tables_7_1.jpg", "caption": "Table 2: Node classification test set accuracy \u2191 and standard deviation.", "description": "This table presents the test set accuracy and standard deviation for node classification task on several benchmark datasets.  The results are shown for various Graph Neural Network (GNN) models, including GCN, GAT, GraphSAGE, MoNet, GCNII, PairNorm, GraphCON, and the proposed RUM model.  The datasets include Cora, CiteSeer, PubMed, Coauthor CS, Computer, and Photo.  The upward-pointing arrow (\u2191) indicates that higher values are better.", "section": "5 Experiments"}, {"figure_path": "JDAQwysFOc/tables/tables_7_2.jpg", "caption": "Table 3: Binary graph classification test set accuracy \u2191.", "description": "This table presents the results of binary graph classification experiments using various graph neural network models, including RUM.  The accuracy is reported for several benchmark datasets (IMDB-B, MUTAG, PROTEINS, PTC, NCI1), comparing the performance of RUM against several other state-of-the-art methods. Higher accuracy indicates better performance.", "section": "Experiments"}, {"figure_path": "JDAQwysFOc/tables/tables_7_3.jpg", "caption": "Table 4: Node classification test set accuracy \u2191 and standard deviation on heterophilic [52] datasets.", "description": "This table presents the results of node classification experiments on three heterophilic datasets: Texas, Wisconsin, and Cornell.  The results compare the performance of various Graph Neural Network (GNN) architectures, including GCN, GAT, GCNII, Geom-GCN, PairNorm, GPS, Graphomer, and the proposed RUM model.  Heterophilic datasets are challenging because of the presence of conflicting labels in the neighborhoods of nodes. The table shows the test accuracy and standard deviation for each model, indicating the relative performance and stability of different GNNs on these difficult datasets. RUM achieves the highest accuracy in two of three datasets and is comparable to the best-performing model on the remaining dataset.", "section": "5 Experiments"}, {"figure_path": "JDAQwysFOc/tables/tables_7_4.jpg", "caption": "Table 5: Graph regression RMSE \u2193 compared with the best model studied in two large-scale benchmark studies on OGB [55] and Molecu-leNet [54] datasets.", "description": "This table presents a comparison of the root mean squared error (RMSE) achieved by the RUM model and other state-of-the-art models on three graph regression tasks from the OGB and MoleculeNet benchmark datasets. Lower RMSE indicates better performance.  The results show that RUM achieves competitive performance compared to the best models on these tasks.", "section": "Experiments"}, {"figure_path": "JDAQwysFOc/tables/tables_16_1.jpg", "caption": "Table 6: Ablation study. Cora [47] test set accuracy \u2191 with in the architecture deleted.", "description": "This table presents the results of an ablation study conducted on the Cora dataset to evaluate the impact of different components of the RUM architecture on the model's performance.  The test set accuracy is reported for several variations, where either the topological representation (Wu), the semantic representation (Wx), the self-supervised regularization loss (Lself), or the consistency regularization loss (Lconsistency) have been removed from the RUM model. This allows for a quantitative analysis of each component's contribution to the overall performance.", "section": "5 Experiments"}, {"figure_path": "JDAQwysFOc/tables/tables_16_2.jpg", "caption": "Table 2: Node classification test set accuracy \u2191 and standard deviation.", "description": "The table presents the test set accuracy and standard deviation for node classification on several benchmark datasets using various graph neural network models, including GCN, GAT, GraphSAGE, MoNet, GCNII, PairNorm, GraphCON, and RUM.  The results show RUM achieves competitive or superior performance compared to other models.", "section": "5 Experiments"}, {"figure_path": "JDAQwysFOc/tables/tables_17_1.jpg", "caption": "Table 7: Graph classification accuracy \u2191 on CSL [60] synthetic dataset for graph isomorphism test.", "description": "This table presents the results of a graph isomorphism test using various Graph Neural Networks (GNNs) on the Circular Skip Link (CSL) dataset.  The CSL dataset is specifically designed to be challenging for GNNs. The table shows that while most GNNs fail to perform better than a random baseline, indicating a failure to discriminate between the non-isomorphic graphs within this dataset, RUM, and 3WLGNN achieve significantly higher accuracy. This highlights RUM's ability to discriminate between non-isomorphic graphs, a capability beyond most standard convolutional GNNs.", "section": "5 Experiments"}, {"figure_path": "JDAQwysFOc/tables/tables_17_2.jpg", "caption": "Table 8: Node classification accuracy and efficiency on OGB-PRODUCTS [55]", "description": "This table presents a comparison of the performance of several graph neural network (GNN) models, including RUM, on the OGB-PRODUCTS dataset, a large-scale benchmark dataset for graph classification.  The metrics reported include accuracy, memory usage (in MB), and throughput (iterations per second). The table shows that RUM achieves comparable accuracy to other state-of-the-art GNNs while demonstrating significant improvements in memory efficiency and throughput.", "section": "Real-world benchmark performance"}, {"figure_path": "JDAQwysFOc/tables/tables_17_3.jpg", "caption": "Table 9: Node classification test accuracy \u2191 and standard deviation with 60:20:20 random splits.", "description": "This table presents a comparison of the test set accuracy achieved by various graph neural network models on node classification tasks, specifically on the Cora and Photo datasets.  The accuracy is reported with standard deviation to show the variability. The table includes several state-of-the-art GNN models along with RUM (Random Walk with Unifying Memory) for comparison, highlighting RUM's competitive performance.", "section": "5 Experiments"}]