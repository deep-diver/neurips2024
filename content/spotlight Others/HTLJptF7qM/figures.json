[{"figure_path": "HTLJptF7qM/figures/figures_5_1.jpg", "caption": "Figure 1: An illustration of outliers and nominal data items w.r.t. range(W\u00b9): (left) when M = 1, e \u2208 range(W\u00b9), (right) while M > 1, it is highly likely that e\u2209 range(W\u00b9). In addition, the measure \u03ba(e) is larger for outliers that are farther from range(W\u00b9).", "description": "This figure illustrates the core idea of the paper, which is to utilize multiple annotators to distinguish outliers (instance-dependent noise) from normal data points by creating a low-dimensional subspace. When only one annotator is used (M=1), outliers are likely to reside in the subspace spanned by the nominal data, making it hard to identify them. However, when multiple annotators are employed (M>1), the probability of outliers residing outside of the subspace increases, thus making it easier to distinguish outliers from nominal data. The outlier impact score \u03ba(e) is also introduced to quantify how far an outlier is from the subspace. ", "section": "3 Proposed Approach"}, {"figure_path": "HTLJptF7qM/figures/figures_9_1.jpg", "caption": "Figure 2: Histogram of the learned outlier indicator values sn = \u03a3M=1 ||em||2 over all training images in the CIFAR-10N dataset (left), and examples with low (middle) and high (right) sn's\u2014see more examples in Appendix H.", "description": "This figure shows a histogram of outlier indicator values (sn) calculated for each training image in the CIFAR-10N dataset using the proposed COINNet method. The histogram helps to visualize the distribution of these values.  The middle and right panels show example images with low and high sn values, respectively, illustrating the types of images that the model identifies as outliers or non-outliers.  The images with high sn values tend to exhibit more instance-dependent confusion characteristics, such as background noise and blurring, than those with low sn values.", "section": "5.2 Experiments Using Real Annotations"}, {"figure_path": "HTLJptF7qM/figures/figures_9_2.jpg", "caption": "Figure 3: Some examples from ImageNet-15N with low (top) and high (bottom) sn's", "description": "This figure shows some example images from the ImageNet-15N dataset that are classified by COINNet with low outlier scores (top row) and high outlier scores (bottom row). The images with lower scores are visually easier to recognize than those with higher scores. The images with high sn scores show more instance-dependent confusion characteristics (such as background noise and blurring) compared to those in the middle.", "section": "Experiments Using Real Annotations"}, {"figure_path": "HTLJptF7qM/figures/figures_27_1.jpg", "caption": "Figure 4: Performance of COINNet on CIFAR-10 with synthetic labels against different number of annotators; left: \u03c4 = 0.2, \u03b7 = 0.1, right: \u03c4 = 0.4, \u03b7 = 0.1.", "description": "This figure shows the performance of the COINNet model on the CIFAR-10 dataset using synthetic labels with varying numbers of annotators (M). The left panel shows the results for a noise rate (\u03c4) of 0.2 and a sparsity parameter (\u03b7) of 0.1, while the right panel presents the results for \u03c4 = 0.4 and \u03b7 = 0.1.  The graph plots both the outlier detection rate and the accuracy for each value of M.  It illustrates how the model's performance improves with more annotators, suggesting the benefit of crowdsourcing in dealing with noisy and outlier data.", "section": "H.1 Experiments with Synthetic Annotators"}, {"figure_path": "HTLJptF7qM/figures/figures_29_1.jpg", "caption": "Figure 2: Histogram of the learned outlier indicator values sn = \u2211M=1 ||em||2 over all training images in the CIFAR-10N dataset (left), and examples with low (middle) and high (right) sn's\u2014see more examples in Appendix H.", "description": "This figure visualizes the distribution of outlier indicator scores (sn) calculated for each image in the CIFAR-10N dataset during training.  The left panel shows a histogram of these scores, illustrating their distribution across the dataset. The middle and right panels display example images with low and high sn scores, respectively.  Images with higher sn scores are more likely to exhibit the characteristics of outliers which implies instance-dependent confusion (e.g., noisy backgrounds, blurriness, etc.). Appendix H contains additional examples.", "section": "5.2 Experiments Using Real Annotations"}, {"figure_path": "HTLJptF7qM/figures/figures_30_1.jpg", "caption": "Figure 2: Histogram of the learned outlier indicator values sn = \u2211M=1 ||e(m)||2 over all training images in the CIFAR-10N dataset (left), and examples with low (middle) and high (right) sn's\u2014see more examples in Appendix H.", "description": "The figure shows a histogram of the outlier indicator values (sn) calculated for each image in the CIFAR-10N dataset during training. The outlier indicator, sn, is a measure of how much the instance-dependent confusion matrix deviates from the instance-independent confusion matrix for each data point.  The histogram shows the distribution of sn values across all training images, indicating the proportion of data points that are considered outliers (high sn values).  The middle and right sections of the figure display example images with low and high sn values, respectively, illustrating the visual characteristics of inliers and outliers.  Further examples are available in the Appendix.", "section": "Experiments Using Real Annotations"}]