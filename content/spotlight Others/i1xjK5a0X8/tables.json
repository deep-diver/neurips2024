[{"figure_path": "i1xjK5a0X8/tables/tables_2_1.jpg", "caption": "Table 1: Comparisons between our PCP-MAE and existing Single/Cross-Modal MAE-based methods in terms of method features, pre-training efficiency, and performance on standard SSL benchmarks.", "description": "This table compares PCP-MAE with other single and cross-modal masked autoencoder methods for point cloud self-supervised learning.  It provides a quantitative comparison across several key aspects:  whether masked centers are leaked to the decoder, the type of model (single or cross-modal), whether a pre-trained model was used, the number of parameters, GFLOPS (a measure of computational cost), pre-training time, and finally the performance on the ScanObjectNN and ModelNet40 benchmarks.  This allows for a comprehensive evaluation of PCP-MAE's efficiency and effectiveness relative to existing state-of-the-art approaches.", "section": "2 Related Work"}, {"figure_path": "i1xjK5a0X8/tables/tables_6_1.jpg", "caption": "Table 1: Comparisons between our PCP-MAE and existing Single/Cross-Modal MAE-based methods in terms of method features, pre-training efficiency, and performance on standard SSL benchmarks.", "description": "This table compares PCP-MAE with other single and cross-modal masked autoencoder (MAE) methods for point cloud self-supervised learning.  It provides a quantitative comparison across several factors: the type of method (single or cross-modal), whether masked center information is leaked, the number of model parameters, the computational cost (GFLOPS), the pre-training time, and finally the performance on standard benchmarks (ScanObjectNN and ModelNet40).  This allows for a comprehensive evaluation of PCP-MAE's efficiency and effectiveness compared to existing state-of-the-art methods.", "section": "2 Related Work"}, {"figure_path": "i1xjK5a0X8/tables/tables_7_1.jpg", "caption": "Table 3: Few-shot classification results on ModelNet40. We perform ten separate trials for each experimental setting and the mean accuracy (%) and standard deviation are reported.", "description": "This table presents the results of few-shot learning experiments conducted on the ModelNet40 dataset.  The experiments involved different numbers of classes ('ways') and examples per class ('shots').  For each setting, ten independent trials were run, and the table shows the mean accuracy and standard deviation across these trials.  The results highlight the model's performance in low-data scenarios.", "section": "4 Experiments"}, {"figure_path": "i1xjK5a0X8/tables/tables_8_1.jpg", "caption": "Table 4: Segmentation Results on ShapeNetPart and S3DIS Area 5: Mean intersection over union for all classes Cls.mIoU (%) and all instances Inst.mIoU (%) for Part Segmentation; Mean accuracy mAcc (%) and IoU mIoU (%) for Semantic Segmentation.", "description": "This table presents a comparison of different methods for 3D point cloud segmentation on two datasets: ShapeNetPart and S3DIS Area 5.  For each method, it reports the Mean Intersection over Union (mIoU) for both part and instance segmentation on ShapeNetPart, and the Mean Accuracy (mAcc) and mIoU for semantic segmentation on S3DIS Area 5.  The results show the performance of various self-supervised and supervised learning methods.", "section": "4 Experiments"}, {"figure_path": "i1xjK5a0X8/tables/tables_8_2.jpg", "caption": "Table 1: Comparisons between our PCP-MAE and existing Single/Cross-Modal MAE-based methods in terms of method features, pre-training efficiency, and performance on standard SSL benchmarks.", "description": "This table compares PCP-MAE against other single and cross-modal masked autoencoder (MAE)-based methods for point cloud self-supervised learning (SSL).  It presents a comprehensive overview of the methods, considering factors such as whether masked centers are leaked to the decoder, the modality (single or cross-modal), the number of parameters, the computational cost (GFLOPS), pre-training time, and the performance across three standard SSL benchmarks on the ScanObjectNN dataset (OBJ-BG, OBJ-ONLY, PB-T50-RS) and ModelNet40. This allows readers to readily compare the efficiency and effectiveness of PCP-MAE to existing state-of-the-art approaches.", "section": "2 Related Work"}, {"figure_path": "i1xjK5a0X8/tables/tables_13_1.jpg", "caption": "Table 8: Training details for pretraining and downstream fine-tuning.", "description": "This table details the hyperparameters, optimization settings, and data augmentation techniques used during both the pre-training and downstream fine-tuning phases of the PCP-MAE model.  It specifies settings for different datasets (ShapeNet, ScanObjectNN, ModelNet, ShapeNetPart, and S3DIS), providing a comprehensive overview of the experimental setup.  The information includes the optimizer used (AdamW), learning rates, weight decay values, learning rate scheduling methods, training epochs, warm-up epochs, batch size, drop path rate, number of points used, number of point patches, point patch size, data augmentation strategies applied and GPU devices used.", "section": "4 Experiments"}, {"figure_path": "i1xjK5a0X8/tables/tables_13_2.jpg", "caption": "Table 9: Different Loss functions. The accuracy (%) on three variants of ScanObjectNN is reported. The default setting is marked in blue.", "description": "This table presents the results of experiments comparing different loss functions used in the PCP-MAE model for 3D object classification on the ScanObjectNN dataset.  Three variants of the dataset (OBJ_BG, OBJ_ONLY, and PB_T50_RS) are evaluated, and the accuracy for each is reported. The \u21132 distance loss function is shown to achieve the best overall results.", "section": "4 Experiments"}, {"figure_path": "i1xjK5a0X8/tables/tables_14_1.jpg", "caption": "Table 10: Effects of pre-training augmentations. The accuracy (%) on three variants of ScanObjectNN is reported. The default setting is marked in blue.", "description": "This table presents the results of an ablation study on the impact of different data augmentation techniques used during the pre-training phase of the PCP-MAE model.  The accuracy of the model is evaluated on three variants of the ScanObjectNN dataset (OBJ_BG, OBJ_ONLY, PB_T50_RS).  The table shows that combining Scale&Translate and Rotation augmentations yields the best performance.", "section": "4 Experiments"}, {"figure_path": "i1xjK5a0X8/tables/tables_15_1.jpg", "caption": "Table 11: Performance comparison of Point-MAE with different augmentations. The star (*) marks the setting used by the original Point-MAE [24], the dagger (\u2020) by peer SOTA methods such as Point-FEMAE [48] and ReCon [27], and the double dagger (\u2020) by us.", "description": "This table compares the performance of Point-MAE under different data augmentation strategies (Scale&Translate, Rotation, and Scale&Translate+Rotation) during both pre-training and fine-tuning stages.  The results are presented for three variants of the ScanObjectNN dataset (OBJ-BG, OBJ-ONLY, and PB-T50-RS).  The table highlights the impact of augmentation choices on the overall model accuracy, showing that combining Scale&Translate and Rotation provides the best results in this specific experiment.", "section": "4 Experiments"}, {"figure_path": "i1xjK5a0X8/tables/tables_15_2.jpg", "caption": "Table 12: The performance of previous SOTA methods using our explored augmentation.", "description": "This table compares the performance of two state-of-the-art (SOTA) methods, Point-FEMAE and ReCon, using the data augmentation strategy proposed in the paper.  It shows the accuracy of each method on three different variants of the ScanObjectNN dataset (OBJ-BG, OBJ-ONLY, and PB-T50-RS). The results demonstrate that the proposed augmentation strategy affects the performance of these SOTA methods and yields slightly lower accuracy when compared to their original performance with their original augmentations.", "section": "4.2 Fine-tuning on downstream tasks"}, {"figure_path": "i1xjK5a0X8/tables/tables_15_3.jpg", "caption": "Table 13: Number of transformer layers in the projector. The accuracy (%) on three variants of ScanObjectNN is reported. The default setting is marked in blue.", "description": "This table shows the impact of varying the number of transformer layers within the projector module of the PCP-MAE model on the accuracy of 3D object classification. The results are presented for three different variants of the ScanObjectNN dataset: OBJ_BG, OBJ_ONLY, and PB_T50_RS.  The default configuration (marked in blue) uses zero layers. Increasing the depth of the projector generally does not improve performance, indicating that simple prediction is sufficient.", "section": "4.3 Ablation studies"}, {"figure_path": "i1xjK5a0X8/tables/tables_16_1.jpg", "caption": "Table 14: Ablation on shared parameters between the encoder and PCM. The accuracy (%) on three variants of ScanObjectNN is reported. The default setting is marked in blue.", "description": "This ablation study analyzes the impact of sharing parameters between the encoder and the Predicting Center Module (PCM) on the model's performance.  The table presents accuracy results for three variants of the ScanObjectNN dataset (OBJ_BG, OBJ_ONLY, PB_T50_RS). The \"shared\" row shows the results when the encoder and PCM share parameters, while the \"non-shared\" row shows the results when they do not.  The default setting (in blue) demonstrates superior performance with shared parameters, highlighting their beneficial impact on model accuracy.", "section": "4.3 Ablation studies"}]