[{"figure_path": "uSKzEaj9zJ/tables/tables_6_1.jpg", "caption": "Table 1: Test errors and the number of trainable parameters for the radial kernel problem, where bold numbers highlight the best methods. The small operator errors and large kernel errors of discrete-NAO highlight the ill-posedness of the inverse problem. NAO overcomes the ill-posedness and yields resolution-invariant estimators.", "description": "The table presents the results of experiments on radial kernel learning. It compares the performance of the proposed Nonlocal Attention Operator (NAO) against several baseline methods (Discrete-NAO, Softmax-NAO, AFNO, NAO-u, Autoencoder) in terms of operator and kernel test errors.  The results are shown for different configurations, varying the token size (dk) and data resolution. The bold numbers indicate the best performance for each configuration. The table highlights that NAO is superior in handling the ill-posed nature of the inverse problem and provides resolution-invariant estimators, unlike the baseline methods.", "section": "5.1 Radial kernel learning"}, {"figure_path": "uSKzEaj9zJ/tables/tables_8_1.jpg", "caption": "Table 2: Test errors and the number of trainable parameters in solution operator learning.", "description": "This table shows the performance of two models, Discrete-NAO and NAO, on two different tasks in solution operator learning: linear operator (g \u2192 p) and nonlinear operator (b \u2192 p). The results are presented for two different cases with varying numbers of samples and trainable parameters. The performance is measured by the test error, which is the percentage of error between the predicted and actual values.  The table demonstrates that NAO performs better or comparably to Discrete-NAO in both tasks and cases, with fewer trainable parameters.", "section": "5.2 Solution operator learning"}, {"figure_path": "uSKzEaj9zJ/tables/tables_9_1.jpg", "caption": "Table 3: Test errors and the number of trainable parameters in heterogeneous material learning.", "description": "This table shows the results of applying NAO and Discrete-NAO to the heterogeneous material learning problem.  Two cases are presented, one with fewer samples and smaller token size, and the other with more samples and larger token size.  The table compares the ID (in-distribution) and OOD (out-of-distribution) test errors for both models, highlighting the performance differences between NAO and its discrete counterpart.", "section": "5.3 Heterogeneous material learning"}, {"figure_path": "uSKzEaj9zJ/tables/tables_21_1.jpg", "caption": "Table 1: Test errors and the number of trainable parameters for the radial kernel problem, where bold numbers highlight the best methods. The small operator errors and large kernel errors of discrete-NAO highlight the ill-posedness of the inverse problem. NAO overcomes the ill-posedness and yields resolution-invariant estimators.", "description": "This table presents the results of experiments on radial kernel learning using different models (Discrete-NAO, Softmax-NAO, NAO, NAO-u, Autoencoder).  It shows the test errors (operator and kernel) and the number of trainable parameters for each model under various conditions (different values of dk and data resolution). The results highlight the superior performance of NAO in addressing the ill-posed nature of the inverse problem and its ability to provide resolution-invariant estimators.", "section": "5.1 Radial kernel learning"}]