{"references": [{"fullname_first_author": "Max Bain", "paper_title": "Frozen in time: A joint video and image encoder for end-to-end retrieval", "publication_date": "2021", "reason": "This paper is foundational for video retrieval, which is relevant to the task of text-to-video generation."}, {"fullname_first_author": "Tim Brooks", "paper_title": "Sora: Creating video from text", "publication_date": "2024", "reason": "Sora is a state-of-the-art text-to-video generation model, and its architecture and training methods are directly relevant to the proposed approach."}, {"fullname_first_author": "Rinon Gal", "paper_title": "An image is worth one word: Personalizing text-to-image generation using textual inversion", "publication_date": "2022", "reason": "This paper introduces textual inversion, a technique for customizing text-to-image models, which is a key component of the proposed method."}, {"fullname_first_author": "Nataniel Ruiz", "paper_title": "DreamBooth: Fine tuning text-to-image diffusion models for subject-driven generation", "publication_date": "2023", "reason": "DreamBooth is a popular method for customizing text-to-image models, and its ideas are adapted to the video domain in this work."}, {"fullname_first_author": "Yuming Jiang", "paper_title": "Videobooth: Diffusion-based video generation with image prompts", "publication_date": "2024", "reason": "This paper proposes a method for generating videos from images, which serves as a baseline for the proposed motion-aware approach."}]}