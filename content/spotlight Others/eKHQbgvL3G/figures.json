[{"figure_path": "eKHQbgvL3G/figures/figures_1_1.jpg", "caption": "Figure 1: The workflow of TrackIME. Our framework enhances point tracking by pruning the search space, along the instance trajectory in video frames. To estimate the instance trajectory, our framework utilizes the point tracking results for a group of points (blue lines) on top of the object instance predicted by segmentation model (e.g., SAM [1]) and aggregate their individual trajectories.", "description": "The figure illustrates the two-step process of TrackIME.  Step 1 shows instance trajectory estimation through trajectory aggregation. A query point is identified, a segmentation model determines semantic neighbors, and an individual point tracker follows the trajectories of these neighbors. Step 2 shows TrackIME itself, where the pruned input frames (along the instance trajectory) are used in point tracking to generate the final tracking result. This method enhances point tracking by focusing only on relevant regions.", "section": "1 Introduction"}, {"figure_path": "eKHQbgvL3G/figures/figures_8_1.jpg", "caption": "Figure 2: Demonstration of the video instance segmentation results by our TrackIME framework. Given the query points in the reference frame, our framework can produce the video instance segmentation masks at quality by performing the weighted aggregation of the mask associated each query point, based on the visibility values.", "description": "This figure demonstrates the video instance segmentation results produced by TrackIME. It shows how the framework generates high-quality segmentation masks by aggregating masks associated with individual query points, using their visibility values as weights. The example shows three different video sequences with their masks generated at different time frames(t=0, t=10, t=20, t=30).", "section": "4.2 Video Object Segmentation"}, {"figure_path": "eKHQbgvL3G/figures/figures_18_1.jpg", "caption": "Figure 3: Demonstration of the progressive inference by TrackIME framework.", "description": "This figure demonstrates the progressive inference process in the TrackIME framework.  It shows how the search space for point tracking is progressively pruned using instance motion estimation and segmentation.  The top row illustrates the process for one query point, with the sampling of semantic neighbors and their tracking results.  The bottom row shows a second example of progressive inference.  In both examples, TrackIME starts with a broad search area centered around the query point (red circle), and gradually narrows this area over subsequent frames (orange boxes) by utilizing improved trajectory estimation from the instance mask. The final frame displays a significantly reduced search region.", "section": "2.2 TrackIME: Enhanced Video Point Tracking via Instance Motion Estimation"}]