[{"figure_path": "xymhWyiZOp/tables/tables_4_1.jpg", "caption": "Table 5: Protocols adopted for training anchored models across different datasets and architectures. While we adopt standard training recipes for training our models, we note that anchoring can serve as a generic wrapper that can be applied on top of any other existing recipe.", "description": "This table details the training hyperparameters used for different datasets and model architectures.  It shows that standard training recipes were used, but anchoring was applied on top of them. This highlights the flexibility of anchoring, which can be combined with existing methods.", "section": "A.3 Additional Details on Training Protocols"}, {"figure_path": "xymhWyiZOp/tables/tables_6_1.jpg", "caption": "Table 1: Generalization performance of CNNs trained on CIFAR10/100. We report the ID test and the OOD (CIFAR10 -C/C, CIFAR100 - C/C) accuracies of standard and anchored CNNs to evaluate generalization (\u2191). Note, we provide the difference (\u25b3) between the proposed and the standard model in each case with blue.", "description": "This table presents a comparison of the generalization performance of Convolutional Neural Networks (CNNs) trained on CIFAR10 and CIFAR100 datasets using standard training, vanilla anchoring, and the proposed anchored training method.  The evaluation includes in-distribution (ID) accuracy and out-of-distribution (OOD) accuracy on CIFAR10-C, CIFAR100-C, CIFAR10-C, and CIFAR100-C datasets. The table highlights the improvement achieved by the proposed method compared to standard training and vanilla anchoring across different corruption severities.", "section": "4.1 Generalization to Covariate Shifts and Synthetic Corruptions"}, {"figure_path": "xymhWyiZOp/tables/tables_6_2.jpg", "caption": "Table 2: Generalization performance of different transformer architectures trained on ImageNet-1K. We report the ID test and OOD (corruptions and covariate shifts) generalization performance of standard and anchored vision transformers using the top1 accuracy. For calibration performance, we report the mean and standard deviation of the Smoothed ECE (\u2193) metric across all ImageNet OOD datasets. Note, we provide the difference (\u25b3) between the proposed and the standard model in each case with blue.", "description": "This table presents a comparison of the generalization performance between standard and anchored transformer models on the ImageNet-1K dataset.  It includes in-distribution (ID) and out-of-distribution (OOD) accuracy results across various datasets, measuring robustness to different types of image corruptions and covariate shifts. The table also shows calibration performance using the Smoothed ECE metric.", "section": "4.1 Generalization to Covariate Shifts and Synthetic Corruptions"}, {"figure_path": "xymhWyiZOp/tables/tables_7_1.jpg", "caption": "Table 3: Anomaly rejection and calibration performance of transformers trained on ImageNet-1K. We compare the anomaly rejection performance against standard training using common vision OOD benchmarks (Textures, Places365, and iSUN datasets) and the more recent NINCO dataset. For evaluation, we consider the AUROC (\u2191) metric. Moreover, we also provide Smoothed ECE scores (\u2193) (mean, std) across different Imagenet corruption benchmarks. We highlight the best performing model in each case with blue.", "description": "This table presents the results of anomaly rejection and calibration performance evaluation on various vision models trained on ImageNet-1K.  It compares the performance of standard training against a proposed method, using metrics such as AUROC for anomaly detection and Smoothed ECE for calibration. The models are tested on several benchmark datasets, including common Vision OOD benchmarks and the NINCO dataset.  The best-performing model for each metric is highlighted.", "section": "4.2 Assessing Safety of Anchored Models"}, {"figure_path": "xymhWyiZOp/tables/tables_8_1.jpg", "caption": "Table 2: Generalization performance of different transformer architectures trained on ImageNet-1K. We report the ID test and OOD (corruptions and covariate shifts) generalization performance of standard and anchored vision transformers using the top1 accuracy. For calibration performance, we report the mean and standard deviation of the Smoothed ECE (\u2193) metric across all ImageNet OOD datasets. Note, we provide the difference (\u25b3) between the proposed and the standard model in each case with blue.", "description": "This table presents a comparison of the generalization performance between standard and anchored transformer models on ImageNet-1K. It includes in-distribution (ID) and out-of-distribution (OOD) accuracy using top-1 accuracy, and calibration performance using Smoothed ECE.  The models used are different transformer architectures (SWINv2-T, SWINv2-S, ViT-B16, SWINv2-B).  The differences between proposed (anchored with reference masking) and standard models are highlighted.", "section": "4.1 Generalization to Covariate Shifts and Synthetic Corruptions"}, {"figure_path": "xymhWyiZOp/tables/tables_13_1.jpg", "caption": "Table 4: Impact of \u03b1 on anchored training. As we gradually increase \u03b1, there is a risk of over-regularization which can lead to severe underfits. Note, we consider R = D in this study.", "description": "This table shows the impact of the hyperparameter \u03b1 (which controls the frequency of the regularization applied to anchored training) on the model's performance.  As \u03b1 increases, there's a greater risk of over-regularization, leading to underfitting. The table displays the in-distribution (ID) test accuracy and out-of-distribution (OOD) accuracy for different values of \u03b1, demonstrating the optimal range for \u03b1 to balance regularization and performance.  The reference set R is set to the entire training dataset (D) for this experiment.", "section": "A.1 How does the choice of \u03b1 impact training?"}, {"figure_path": "xymhWyiZOp/tables/tables_14_1.jpg", "caption": "Table 5: Protocols adopted for training anchored models across different datasets and architectures. While we adopt standard training recipes for training our models, we note that anchoring can serve as a generic wrapper that can be applied on top of any other existing recipe.", "description": "This table summarizes the training protocols used for different models and datasets in the paper. It shows that while standard training recipes were used, anchoring was applied on top of them.  The table includes the model, dataset, training recipes, and the number of epochs for both non-anchored and anchored training, as well as the optimizer used.", "section": "A.3 Additional Details on Training Protocols"}, {"figure_path": "xymhWyiZOp/tables/tables_15_1.jpg", "caption": "Table 2: Generalization performance of different transformer architectures trained on ImageNet-1K. We report the ID test and OOD (corruptions and covariate shifts) generalization performance of standard and anchored vision transformers using the top1 accuracy. For calibration performance, we report the mean and standard deviation of the Smoothed ECE (\u2193) metric across all ImageNet OOD datasets. Note, we provide the difference (\u25b3) between the proposed and the standard model in each case with blue.", "description": "This table presents a comparison of the generalization performance between standard and anchored training methods for various transformer architectures on the ImageNet-1K dataset.  It includes in-distribution (ID) accuracy, out-of-distribution (OOD) accuracy across different corruption benchmarks, and calibration metrics (Smoothed ECE).  The difference in performance between the proposed and standard models is highlighted.", "section": "4.1 Generalization to Covariate Shifts and Synthetic Corruptions"}, {"figure_path": "xymhWyiZOp/tables/tables_15_2.jpg", "caption": "Table 1: Generalization performance of CNNs trained on CIFAR10/100. We report the ID test and the OOD (CIFAR10 -C/C, CIFAR100 - C/C) accuracies of standard and anchored CNNs to evaluate generalization (\u2191). Note, we provide the difference (\u25b3) between the proposed and the standard model in each case with blue.", "description": "This table presents a comparison of the generalization performance of Convolutional Neural Networks (CNNs) trained using standard methods and the proposed anchored training method.  The performance is evaluated on both in-distribution (ID) and out-of-distribution (OOD) datasets, using CIFAR-10 and CIFAR-100, and their corrupted versions. The table shows ID accuracy and OOD accuracy across different corruption severities, highlighting the improvement achieved by the proposed method. The '\u0394' column indicates the difference in performance between the proposed method and the standard method.", "section": "4.1 Generalization to Covariate Shifts and Synthetic Corruptions"}]