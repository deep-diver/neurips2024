[{"figure_path": "FFW6rPz48Z/figures/figures_6_1.jpg", "caption": "Figure 1: Test loss contributions DIL, CMTL, NNT across three sample size regimes. Test risk exhibits decreasing, increasing, or convex shapes based on the regime. \u03bb* from theory are marked.", "description": "This figure shows the breakdown of the test loss into three components: the independent learning term (DIL), the cross-term (CMTL) representing multi-task learning, and the noise term (NNT) representing negative transfer.  The plots illustrate how these components interact for three different sample size regimes (n/d = 0.5, 1.5, and 2.5).  The test risk curve, shown in black, exhibits different behaviors depending on the sample size regime: monotonically decreasing, monotonically increasing, or convex.  The optimal lambda values (\u03bb*) predicted by the theory are also marked on the plots with red dashed lines, highlighting their consistency with the test risk curves.", "section": "Main Theoretical Results"}, {"figure_path": "FFW6rPz48Z/figures/figures_6_2.jpg", "caption": "Figure 2: Empirical and theoretical train and test MSE as functions of the parameter \u03bb for different values of \u03b1. The smooth curves represent the theoretical predictions, while the corresponding curves with the same color show the empirical results, highlighting that the empirical observations indeed match the theoretical predictions.", "description": "This figure compares the empirical and theoretical mean squared error (MSE) for both training and testing data across various values of the regularization parameter \u03bb and different levels of task similarity (\u03b1). The smooth curves represent the theoretical MSE calculated using the proposed random matrix theory-based framework, while the corresponding curves with the same color show the empirical MSE obtained from experiments. The close alignment between the theoretical and empirical results confirms the accuracy of the proposed framework, particularly in estimating the optimal value of \u03bb.", "section": "4 Main Theoretical Results"}, {"figure_path": "FFW6rPz48Z/figures/figures_7_1.jpg", "caption": "Figure 3: Theoretical vs Empirical MSE as function of regularization parameter \u03bb. Close fit between the theoretical and the empirical predictions which underscores the robustness of the theory in light of varying assumptions as well as the accuracy of the suggested estimates. We consider the first two channels as the the two tasks and d = 144. 95 samples are used for the training and 42 samples are used for the test.", "description": "This figure compares the theoretical and empirical Mean Squared Errors (MSE) for training and testing data across a range of regularization parameter (lambda) values.  The close agreement between the theoretical predictions and empirical results validates the accuracy of the theoretical model developed in the paper. The experiment uses the first two channels of a dataset as two separate tasks, with 144 features (d=144), 95 samples for training, and 42 for testing.", "section": "5 Hyperparameter Optimization in Practice"}, {"figure_path": "FFW6rPz48Z/figures/figures_27_1.jpg", "caption": "Figure 4: Results of our optimization method on different datasets and horizons averaged across 3 different seeds for each gamma and lambda values for the PatchTST baseline", "description": "This figure shows the results of applying the proposed optimization method to the PatchTST baseline model on three different datasets (ETTh1, ETTh2, and Weather) and four different forecasting horizons (96, 192, 336, and 720).  Each subplot represents a different dataset and horizon. The x-axis represents the lambda values, and the y-axis represents the average Mean Squared Error (MSE). Multiple lines are plotted within each subplot, each corresponding to different gamma values. The plots illustrate how the optimal lambda value changes across various datasets, horizons, and gamma values, highlighting the effectiveness of the proposed method in finding optimal hyperparameters.", "section": "G.4 Additional Experiments"}, {"figure_path": "FFW6rPz48Z/figures/figures_28_1.jpg", "caption": "Figure 4: Results of our optimization method on different datasets and horizons averaged across 3 different seeds for each gamma and lambda values for the PatchTST baseline", "description": "This figure shows the results of the proposed optimization method applied to the PatchTST baseline model on three different datasets (ETTh1, ETTh2, and Weather) and four different forecasting horizons (96, 192, 336, and 720).  Each subfigure represents a dataset and horizon, showcasing the average mean squared error (MSE) across three different random seeds, with varying values of gamma (\u03b3) and lambda (\u03bb). The plot illustrates the impact of these hyperparameters on the model's performance, allowing for the identification of optimal values that minimize error for each specific scenario.", "section": "G.4 Additional Experiments"}, {"figure_path": "FFW6rPz48Z/figures/figures_29_1.jpg", "caption": "Figure 4: Results of our optimization method on different datasets and horizons averaged across 3 different seeds for each gamma and lambda values for the PatchTST baseline", "description": "This figure visualizes the results of applying the proposed optimization method to the PatchTST baseline model. It shows the average MSE achieved across three different random seeds for various combinations of gamma (\u03b3) and lambda (\u03bb) hyperparameters.  The results are presented separately for three datasets (ETTh1, ETTh2, Weather) and four forecast horizons (96, 192, 336, 720). Each plot allows for a comparison of performance across different values of \u03b3 and \u03bb, aiding in the identification of optimal hyperparameter settings for each scenario.", "section": "G.4 Additional Experiments"}]