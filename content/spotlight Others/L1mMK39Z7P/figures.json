[{"figure_path": "L1mMK39Z7P/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of the ACES algorithm. ACES iteratively generates a diverse set of challenging programming puzzles. First, a target cell corresponding to a combination of programming skills is sampled from a puzzle archive (1), and puzzles from filled neighboring cells - prioritized by difficulty - are selected as examples and given to a puzzle generating LLM. It generates a new puzzle with the desired skill combination that an LLM solver tries to solve 50 times (2). If never solved, the puzzle is discarded. An LLM describes the skills needed to solve the puzzle (3) and the puzzle, along with its computed difficulty score, is added to the puzzle archive.", "description": "This figure illustrates the ACES (Autotelic CodE Search) algorithm's iterative process for generating diverse and challenging programming puzzles.  It starts by sampling a target skill combination from a puzzle archive.  Then, it uses a large language model (LLM) as a puzzle generator, providing it with similar puzzles as examples. The generated puzzle is then tested by an LLM solver 50 times to assess its difficulty.  If solvable (at least once), another LLM labels it with the required skills. The puzzle, its difficulty, and skills are then added to the archive, feeding into the next iteration.  This iterative process aims to create a diverse and challenging set of puzzles.", "section": "3 Methods"}, {"figure_path": "L1mMK39Z7P/figures/figures_3_1.jpg", "caption": "Figure 3: ACES generates more diverse and more difficult problems. Diversity (first row): semantic diversity (a), embedding diversity with the codet5p model (b) and the deepseek-coder-1.3b model (c). Fitness (second row): average fitness of valid puzzle generated over the last 160 generation attempts (d), QD-score (e) and distributions of fitness values over whole archives (f). ACES variants outperform baselines in terms of diversity, fitness and QD score (aggregated measure).", "description": "This figure compares the performance of ACES and its variants against other baselines in terms of both diversity and difficulty of generated programming puzzles. The top row shows the diversity across different metrics: semantic diversity (number of unique skill combinations), embedding diversity using two different embedding models (codet5p and deepseek-coder-1.3b). The bottom row shows the fitness (difficulty) metrics: average fitness over the last 160 generations, QD-score (a quality-diversity measure), and the overall distribution of fitness values across all generated puzzles.  The results consistently demonstrate that ACES and its variants generate more diverse and more challenging puzzles than the baselines.", "section": "4 Results"}, {"figure_path": "L1mMK39Z7P/figures/figures_6_1.jpg", "caption": "Figure 3: ACES generates more diverse and more difficult problems. Diversity (first row): semantic diversity (a), embedding diversity with the codet5p model (b) and the deepseek-coder-1.3b model (c). Fitness (second row): average fitness of valid puzzle generated over the last 160 generation attempts (d), QD-score (e) and distributions of fitness values over whole archives (f). ACES variants outperform baselines in terms of diversity, fitness and QD score (aggregated measure).", "description": "This figure presents a comprehensive comparison of ACES and other baselines across multiple metrics. The top row displays diversity metrics, starting with semantic diversity (a), which measures the unique combinations of programming skills used across the generated puzzles.  It then shows embedding diversity using two different models: codet5p (b) and deepseek-coder-1.3b (c). The bottom row focuses on the fitness (difficulty) of the puzzles. (d) shows the average fitness of valid puzzles generated in the last 160 generations, (e) shows the quality-diversity score (a combined metric of diversity and quality), and (f) presents distributions of fitness values across all generated archives. The results demonstrate that ACES variants outperform the baselines in terms of both diversity and difficulty.", "section": "4 Results"}, {"figure_path": "L1mMK39Z7P/figures/figures_8_1.jpg", "caption": "Figure 3: ACES generates more diverse and more difficult problems. Diversity (first row): semantic diversity (a), embedding diversity with the codet5p model (b) and the deepseek-coder-1.3b model (c). Fitness (second row): average fitness of valid puzzle generated over the last 160 generation attempts (d), QD-score (e) and distributions of fitness values over whole archives (f). ACES variants outperform baselines in terms of diversity, fitness and QD score (aggregated measure).", "description": "This figure displays the results of the experiments comparing ACES with other baselines in terms of diversity and difficulty of the generated puzzles.  The first row shows the diversity of generated puzzles in terms of semantic diversity, embedding diversity using two different models (codet5p and deepseek-coder-1.3b). The second row shows the average fitness (difficulty) of the puzzles, the quality-diversity score, and the distribution of fitness values in the archives. The results show that ACES variants consistently outperform other baselines across all metrics.", "section": "4 Results"}, {"figure_path": "L1mMK39Z7P/figures/figures_15_1.jpg", "caption": "Figure 3: ACES generates more diverse and more difficult problems. Diversity (first row): semantic diversity (a), embedding diversity with the codet5p model (b) and the deepseek-coder-1.3b model (c). Fitness (second row): average fitness of valid puzzle generated over the last 160 generation attempts (d), QD-score (e) and distributions of fitness values over whole archives (f). ACES variants outperform baselines in terms of diversity, fitness and QD score (aggregated measure).", "description": "This figure compares the performance of ACES against other baselines in terms of diversity and difficulty of generated puzzles.  The top row shows three different diversity metrics: semantic diversity, embedding diversity using codet5p, and embedding diversity using deepseek-coder-1.3b.  The bottom row shows three different fitness metrics: average fitness, QD-score, and distributions of fitness values. The results demonstrate that ACES consistently outperforms other methods across all metrics, indicating its superior ability to generate diverse and challenging puzzles.", "section": "4 Results"}, {"figure_path": "L1mMK39Z7P/figures/figures_16_1.jpg", "caption": "Figure 3: ACES generates more diverse and more difficult problems. Diversity (first row): semantic diversity (a), embedding diversity with the codet5p model (b) and the deepseek-coder-1.3b model (c). Fitness (second row): average fitness of valid puzzle generated over the last 160 generation attempts (d), QD-score (e) and distributions of fitness values over whole archives (f). ACES variants outperform baselines in terms of diversity, fitness and QD score (aggregated measure).", "description": "This figure compares the performance of ACES against several baseline methods across various metrics related to diversity and difficulty of generated programming puzzles.  The top row shows diversity metrics: (a) counts unique skill combinations, (b) uses codet5p embeddings, and (c) uses deepseek-coder-1.3b embeddings. The bottom row shows difficulty metrics: (d) average fitness (difficulty) over the last 160 generated puzzles, (e) Quality Diversity score (a combined diversity and difficulty measure), and (f) distributions of puzzle fitness across the whole generated dataset.  The results demonstrate that ACES produces more diverse and more challenging puzzles compared to the baseline methods.", "section": "4 Results"}, {"figure_path": "L1mMK39Z7P/figures/figures_17_1.jpg", "caption": "Figure 3: ACES generates more diverse and more difficult problems. Diversity (first row): semantic diversity (a), embedding diversity with the codet5p model (b) and the deepseek-coder-1.3b model (c). Fitness (second row): average fitness of valid puzzle generated over the last 160 generation attempts (d), QD-score (e) and distributions of fitness values over whole archives (f). ACES variants outperform baselines in terms of diversity, fitness and QD score (aggregated measure).", "description": "This figure presents a comparison of ACES and its variants against several baselines (ELM, ELM-CVT, StaticGen) in terms of diversity and difficulty of generated programming puzzles.  The top row shows diversity metrics: semantic diversity (number of unique skill combinations), embedding diversity using two different embedding models (codet5p and deepseek-coder-1.3b). The bottom row displays fitness metrics: average fitness (difficulty), Quality Diversity (QD) score (a combined measure of diversity and difficulty), and distributions of fitness scores across all generated puzzles.  The results demonstrate that ACES variants significantly outperform the baselines in all aspects, generating puzzles that are both more diverse and more challenging.", "section": "4 Results"}, {"figure_path": "L1mMK39Z7P/figures/figures_18_1.jpg", "caption": "Figure 3: ACES generates more diverse and more difficult problems. Diversity (first row): semantic diversity (a), embedding diversity with the codet5p model (b) and the deepseek-coder-1.3b model (c). Fitness (second row): average fitness of valid puzzle generated over the last 160 generation attempts (d), QD-score (e) and distributions of fitness values over whole archives (f). ACES variants outperform baselines in terms of diversity, fitness and QD score (aggregated measure).", "description": "This figure shows a comparison of ACES and several baseline methods across various metrics related to diversity and difficulty of generated programming puzzles. The first row displays the diversity of generated puzzles, comparing semantic diversity (number of unique skill combinations), and embedding diversity using two different embedding models (codet5p and deepseek-coder-1.3b). The second row focuses on the difficulty (fitness) of the generated puzzles, presenting average fitness, Quality-Diversity (QD) score, and the distributions of fitness scores across all generated puzzles. In all metrics, ACES variants outperform baseline methods, demonstrating their superior ability to produce more diverse and challenging programming puzzles.", "section": "4 Results"}, {"figure_path": "L1mMK39Z7P/figures/figures_19_1.jpg", "caption": "Figure 3: ACES generates more diverse and more difficult problems. Diversity (first row): semantic diversity (a), embedding diversity with the codet5p model (b) and the deepseek-coder-1.3b model (c). Fitness (second row): average fitness of valid puzzle generated over the last 160 generation attempts (d), QD-score (e) and distributions of fitness values over whole archives (f). ACES variants outperform baselines in terms of diversity, fitness and QD score (aggregated measure).", "description": "This figure compares the performance of ACES against several baseline methods across multiple metrics. The top row shows diversity metrics: semantic diversity (number of unique skill combinations), and embedding diversity (using two different embedding models). The bottom row shows fitness metrics: average fitness (difficulty), quality diversity score (QD-score, a combined measure of diversity and difficulty), and distributions of fitness scores across the generated puzzles. The results demonstrate that ACES generates more diverse and more challenging puzzles than baselines methods.", "section": "4 Results"}, {"figure_path": "L1mMK39Z7P/figures/figures_20_1.jpg", "caption": "Figure 3: ACES generates more diverse and more difficult problems. Diversity (first row): semantic diversity (a), embedding diversity with the codet5p model (b) and the deepseek-coder-1.3b model (c). Fitness (second row): average fitness of valid puzzle generated over the last 160 generation attempts (d), QD-score (e) and distributions of fitness values over whole archives (f). ACES variants outperform baselines in terms of diversity, fitness and QD score (aggregated measure).", "description": "This figure compares the performance of ACES and its variants against several baselines in terms of puzzle diversity and difficulty. The first row shows diversity metrics across different methods: semantic diversity (the number of unique skill combinations), embedding diversity (using codet5p and deepseek-coder-1.3b models), showing ACES variants generate more diverse puzzles than baseline methods. The second row illustrates the fitness (difficulty) of generated puzzles: average fitness (difficulty score), quality-diversity score, and the fitness distribution across the archives. Again, ACES variants demonstrate superior performance, producing more challenging and diverse puzzles.", "section": "4 Results"}, {"figure_path": "L1mMK39Z7P/figures/figures_23_1.jpg", "caption": "Figure 5: (b) Quality-Diversity (QD) score updated figure with ACES-ELM using state-of-the-art open weight LLM (Llama-3-405B and Mistral Large 2)", "description": "The figure shows the evolution of the quality-diversity (QD) score over the number of puzzles generated for different algorithms.  ACES-ELM consistently outperforms other methods, demonstrating its superior ability to generate diverse and high-quality puzzles. The inclusion of larger LLMs (Llama-405B and Mistral Large-2) in the ACES-ELM algorithm further enhances its performance, showcasing the scalability of the method. The shaded regions represent the standard deviation across multiple runs, indicating the algorithm's robustness.", "section": "4 Results"}, {"figure_path": "L1mMK39Z7P/figures/figures_23_2.jpg", "caption": "Figure 6: (e) Evolution of Puzzle Difficulty Distribution generated by ACES: Decile Analysis of Generated Puzzles over generations.", "description": "This figure shows the distribution of puzzle difficulties over 40 generations of the ACES algorithm.  The y-axis represents the number of puzzles, and the x-axis represents the generation number. The area chart displays the distribution of puzzles across ten difficulty deciles (0-10, 10-20,..., 90-100). The chart visualizes how the difficulty distribution of generated puzzles changes over time during the ACES algorithm's iterative process. This allows for an analysis of whether the algorithm successfully generates more challenging puzzles across generations.", "section": "4.3 ACES generates more diverse and challenging problems than existing approaches"}, {"figure_path": "L1mMK39Z7P/figures/figures_24_1.jpg", "caption": "Figure 3: ACES generates more diverse and more difficult problems. Diversity (first row): semantic diversity (a), embedding diversity with the codet5p model (b) and the deepseek-coder-1.3b model (c). Fitness (second row): average fitness of valid puzzle generated over the last 160 generation attempts (d), QD-score (e) and distributions of fitness values over whole archives (f). ACES variants outperform baselines in terms of diversity, fitness and QD score (aggregated measure).", "description": "This figure demonstrates the superior performance of ACES (Autotelic CodE Search) and its variant ACES-ELM compared to other baselines (ELM, ELM-CVT, StaticGen) in generating diverse and challenging programming puzzles.  The top row shows the diversity metrics across different methods: semantic diversity (number of unique skill combinations), and embedding diversity using two different embedding models (codet5p and deepseek-coder-1.3b). The bottom row displays fitness metrics: average fitness, quality-diversity (QD) score, and the distribution of fitness values across all generated puzzles.  In all aspects, ACES and ACES-ELM outperform the baselines.", "section": "4 Results"}, {"figure_path": "L1mMK39Z7P/figures/figures_25_1.jpg", "caption": "Figure 3: ACES generates more diverse and more difficult problems. Diversity (first row): semantic diversity (a), embedding diversity with the codet5p model (b) and the deepseek-coder-1.3b model (c). Fitness (second row): average fitness of valid puzzle generated over the last 160 generation attempts (d), QD-score (e) and distributions of fitness values over whole archives (f). ACES variants outperform baselines in terms of diversity, fitness and QD score (aggregated measure).", "description": "This figure compares the performance of ACES against several baseline methods in generating programming puzzles.  The top row shows the diversity of generated puzzles across different metrics: semantic diversity (number of unique skill combinations), and embedding diversity in two different embedding spaces (codet5p and deepseek-coder-1.3b). The bottom row shows the quality of generated puzzles, measured by average fitness (difficulty), quality diversity score (QD-score), and the distribution of fitness values across the entire set of generated puzzles.  The results demonstrate that ACES and its variants significantly outperform the baselines in terms of both the diversity and the difficulty of the generated puzzles.", "section": "4 Results"}, {"figure_path": "L1mMK39Z7P/figures/figures_26_1.jpg", "caption": "Figure 9: Evolution of the difficulty score from puzzles used as a few-shot example to generated puzzles based on those previous puzzles.", "description": "This figure displays the correlation between the difficulty scores of puzzles used as few-shot examples and the difficulty scores of the puzzles generated based on those examples, for different algorithms (ACES-ELM, ACES, ELM, ELM-CVT, and RandomGen). Each plot shows a scatter plot with a linear regression line. The R-squared value (R2) for each regression line indicates the goodness of fit, showing how well the linear model explains the variance in the data.  The x-axis represents the difficulty score of the original puzzles, and the y-axis represents the difficulty score of the newly generated puzzles.  The diagonal line represents a perfect correlation (x=y). Deviations from the diagonal line suggest that the algorithms don't perfectly preserve difficulty when generating new puzzles from old ones. The R2 values suggest that the degree of correlation varies across the algorithms, with some showing a stronger relationship between original and generated puzzle difficulties than others.", "section": "4.3 ACES generates more diverse and challenging problems than existing approaches"}, {"figure_path": "L1mMK39Z7P/figures/figures_27_1.jpg", "caption": "Figure 10: Distance to target skills over time.", "description": "The figure shows the evolution of the distance to target skills over time for two different algorithms: ACES-ELM and ACES. The x-axis represents the number of puzzles generated, and the y-axis represents the distance to the target skills. The shaded area represents the standard deviation. The figure shows that both algorithms are able to reduce the distance to the target skills over time, but ACES-ELM is able to reduce the distance more quickly than ACES. This suggests that ACES-ELM is a more efficient algorithm for generating diverse and challenging programming puzzles.", "section": "3.3 ACES: Autotelic CodE Search"}, {"figure_path": "L1mMK39Z7P/figures/figures_28_1.jpg", "caption": "Figure 3: ACES generates more diverse and more difficult problems. Diversity (first row): semantic diversity (a), embedding diversity with the codet5p model (b) and the deepseek-coder-1.3b model (c). Fitness (second row): average fitness of valid puzzle generated over the last 160 generation attempts (d), QD-score (e) and distributions of fitness values over whole archives (f). ACES variants outperform baselines in terms of diversity, fitness and QD score (aggregated measure).", "description": "This figure compares the performance of ACES and several baseline methods across various metrics related to diversity and difficulty of generated programming puzzles.  The top row shows different measures of diversity: semantic diversity (number of unique skill combinations), and embedding diversity (using two different embedding models). The bottom row shows metrics related to difficulty: average fitness (a measure of difficulty inversely related to success rate), Quality Diversity score (a combined measure of diversity and difficulty), and distributions of fitness scores.  The results indicate that ACES consistently outperforms baseline methods in both diversity and difficulty.", "section": "4 Results"}]