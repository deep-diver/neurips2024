[{"figure_path": "mHtOyh5taj/tables/tables_7_1.jpg", "caption": "Table 1: Performance comparison in terms of median SRCC and PLCC on six IQA datasets. The methods are jointly trained with a mixture of six datasets are represented in italics.", "description": "This table presents the performance comparison of various image quality assessment (IQA) methods across six benchmark datasets, using two common metrics: Spearman's rank correlation coefficient (SRCC) and Pearson linear correlation coefficient (PLCC). The methods are categorized into several types, including opinion-unaware models, learning-to-regress models, learning-to-rank models, and large multimodal model (LMM)-based models. The datasets are categorized into those with synthetic distortions and those with real-world distortions. The table highlights Compare2Score's superior performance across various datasets and distortion types.", "section": "4.2 Main Results"}, {"figure_path": "mHtOyh5taj/tables/tables_7_2.jpg", "caption": "Table 2: SRCC results on the three IQA datasets under the cross-dataset setup. The methods are jointly trained with a mixture of six datasets are represented in italics.", "description": "This table presents the Spearman Rank Correlation Coefficients (SRCC) achieved by different image quality assessment (IQA) models on three unseen IQA datasets (TID2013, SPAQ, and AGIQA-3K).  The models were pre-trained on a combination of six other IQA datasets.  The table shows the cross-dataset generalization ability of the models, indicating how well they perform on datasets with different distortion types and characteristics than those seen during training.  Higher SRCC values represent better performance.", "section": "4.2 Main Results"}, {"figure_path": "mHtOyh5taj/tables/tables_7_3.jpg", "caption": "Table 3: SRCC results of probability matrix and count matrix on four IQA datasets. Prob. stands for probability.", "description": "This table compares the performance of using a probability matrix versus a count matrix for image quality assessment.  The comparison is done using the Spearman Rank Correlation Coefficient (SRCC) across four different image quality assessment (IQA) datasets.  The probability matrix approach is shown to significantly improve performance compared to the traditional count matrix approach. ", "section": "4.2 Main Results"}, {"figure_path": "mHtOyh5taj/tables/tables_8_1.jpg", "caption": "Table 4: Performance comparison in terms of prediction accuracy on six IQA datasets. The best results are highlighted in boldface.", "description": "This table presents a comparison of the prediction accuracy achieved by Compare2Score and several other models across six different image quality assessment (IQA) datasets.  The datasets vary in terms of the types of image distortions included (synthetic and real-world distortions).  The accuracy metric likely represents a correlation coefficient (e.g., Pearson or Spearman) measuring the agreement between the model's predictions and human judgments.  The best performing model for each dataset is shown in boldface.  The table demonstrates Compare2Score's superior performance compared to other LMM models.", "section": "4.2 Main Results"}, {"figure_path": "mHtOyh5taj/tables/tables_8_2.jpg", "caption": "Table 5: SRCC results for Compare2Score using anchor images from KonIQ-10k [7], KADID-10k [26], and AGIQA-3K [61].", "description": "This table presents the Spearman's rank correlation coefficient (SRCC) results for the Compare2Score model.  The results show the model's performance on six different image quality assessment (IQA) datasets (LIVE, CSIQ, KADID-10k, BID, CLIVE, and KonIQ-10k).  Importantly, the anchor images used for comparison were sourced from three different datasets (KonIQ-10k, KADID-10k, and AGIQA-3K) to evaluate the model's robustness and generalization capabilities across various IQA datasets and distortion types.", "section": "4.2 Main Results"}, {"figure_path": "mHtOyh5taj/tables/tables_9_1.jpg", "caption": "Table 6: SRCC results of the different anchor selection schemes on KonIQ-10k [7] dataset.", "description": "This table shows the impact of different anchor image selection methods on the performance of the Compare2Score model.  It compares the SRCC (Spearman Rank Correlation Coefficient) scores achieved using three different methods: random selection, maximum variance selection, and the proposed minimum variance selection method.  The results are presented for six different IQA (Image Quality Assessment) datasets: LIVE [53], CSIQ [24], KADID-10k [26], BID [25], CLIVE [54], and KonIQ-10k [7].  The table demonstrates the effectiveness of the proposed minimum variance anchor selection method compared to the other two approaches.", "section": "4.3 Ablation Studies"}, {"figure_path": "mHtOyh5taj/tables/tables_15_1.jpg", "caption": "Table 7: Overview of the baseline open-sourced LMMs compared with the proposed Compare2Score. MLP stands for the multilayer perceptron. MAM is the modality-adaptive module.", "description": "This table compares different Large Multimodal Models (LMMs) used in the paper.  It shows the visual model, visual-language alignment method, and language model used in each model.  The models compared are several existing open-source models and the proposed Compare2Score model.  The table highlights the architectural differences in the models, showing the components that process visual information, how visual and textual information are combined, and which language model generates the final output.", "section": "A.3 More Details on Competing LMMs"}]