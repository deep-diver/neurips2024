[{"figure_path": "cqfE9eYMdP/figures/figures_1_1.jpg", "caption": "Figure 1: The variation in tolerance for NeurKItt compared to GMRES, where each line represents an experiment under a solving method and a specific preconditioning. Notably, the NeurKItt substantially enhances the efficiency of solving the linear systems, with a reduction in the number of iterations by up to a factor of 16 and achieving a speed-up of up to 5.5 times.", "description": "This figure compares the performance of NeurKItt and GMRES in solving linear systems across various preconditioning techniques.  Each line shows the convergence of one method with a particular preconditioner. NeurKItt demonstrates significantly faster convergence than GMRES in terms of both time (left panel) and number of iterations (right panel), achieving speedups of up to 5.5x and 16.1x, respectively. This highlights NeurKItt's ability to accelerate the solving process.", "section": "1 Introduction"}, {"figure_path": "cqfE9eYMdP/figures/figures_4_1.jpg", "caption": "Figure 2: Algorithm Flow Diagram: (a) Finding solution x for given matrices A and b. (b) Traditional Algorithm: Krylov iterations from a random initial vector. (c1) NeurKItt Subspace Prediction Module: Utilizing a neural operator for estimating the invariant subspace of matrix A. (c2) NeurKItt Acceleration Module: Using the predicted invariant subspace of the matrix to guide the iteration, thereby accelerating the Krylov iteration process.", "description": "This figure illustrates the workflow of the proposed NeurKItt algorithm compared to traditional Krylov subspace iteration methods.  Panel (a) shows the problem setup: finding the solution vector x for a given matrix A and vector b.  Panel (b) illustrates the traditional Krylov subspace method, starting from a random initial vector and iteratively expanding the subspace to approximate the solution.  Panel (c1) depicts the NeurKItt subspace prediction module, which uses a neural operator to predict the invariant subspace of the matrix A. Panel (c2) shows how the predicted subspace (from c1) is used to guide the Krylov subspace iteration in the acceleration module, resulting in a faster convergence to the solution.", "section": "4 Method"}, {"figure_path": "cqfE9eYMdP/figures/figures_8_1.jpg", "caption": "Figure 1: The variation in tolerance for NeurKItt compared to GMRES, where each line represents an experiment under a solving method and a specific preconditioning. Notably, the NeurKItt substantially enhances the efficiency of solving the linear systems, with a reduction in the number of iterations by up to a factor of 16 and achieving a speed-up of up to 5.5 times.", "description": "This figure compares the performance of NeurKItt against GMRES for solving linear systems.  It shows the convergence (tolerance) over time (left) and the average number of iterations (right) for both methods across various preconditioning techniques (Jacobi, BJacobi, SOR, ASM, ICC, ILU).  NeurKItt demonstrates significantly faster convergence, requiring fewer iterations and less time to achieve the same tolerance.", "section": "1 Introduction"}, {"figure_path": "cqfE9eYMdP/figures/figures_19_1.jpg", "caption": "Figure 1: The variation in tolerance for NeurKItt compared to GMRES, where each line represents an experiment under a solving method and a specific preconditioning. Notably, the NeurKItt substantially enhances the efficiency of solving the linear systems, with a reduction in the number of iterations by up to a factor of 16 and achieving a speed-up of up to 5.5 times.", "description": "This figure compares the performance of NeurKItt and GMRES in solving linear systems.  The y-axis shows the 2-norm of the residual error (tolerance), and the x-axis shows either the computation time in seconds (left) or the number of iterations (right).  Multiple lines represent different preconditioning techniques used with each solver.  The results demonstrate that NeurKItt significantly reduces both the time and the number of iterations required to achieve a given level of accuracy, showing improvements of up to 5.5x and 16.1x respectively.", "section": "1 Introduction"}, {"figure_path": "cqfE9eYMdP/figures/figures_20_1.jpg", "caption": "Figure 1: The variation in tolerance for NeurKItt compared to GMRES, where each line represents an experiment under a solving method and a specific preconditioning. Notably, the NeurKItt substantially enhances the efficiency of solving the linear systems, with a reduction in the number of iterations by up to a factor of 16 and achieving a speed-up of up to 5.5 times.", "description": "This figure compares the performance of the proposed Neural Krylov Iteration (NeurKItt) method against the Generalized Minimal Residual (GMRES) method for solving linear systems.  It shows how the tolerance (2-norm) decreases over time (in seconds) and the number of iterations for various preconditioning techniques (None, Jacobi, BJacobi, SOR, ASM, ICC, ILU).  The results demonstrate that NeurKItt significantly outperforms GMRES in both speed and iteration count, achieving up to a 5.5x speedup in time and a 16.1x speedup in iterations.", "section": "1 Introduction"}]