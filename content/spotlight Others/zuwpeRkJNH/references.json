{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning Transferable Visual Models From Natural Language Supervision", "publication_date": "2021-07-18", "reason": "This paper introduces CLIP, a foundational model for multi-modal learning that is heavily referenced and adapted in the current work."}, {"fullname_first_author": "Aaron van den Oord", "paper_title": "Representation learning with contrastive predictive coding", "publication_date": "2018-07-18", "reason": "This paper introduces contrastive learning, a crucial technique used for training multi-modal models, forming a basis for the methods in this paper."}, {"fullname_first_author": "Kun Yuan", "paper_title": "Learning Multi-modal Representations By Watching Hundreds of Surgical Video Lectures", "publication_date": "2023-07-18", "reason": "This paper introduces the SVL dataset used for pretraining in the current work, providing the foundation data for the presented approach."}, {"fullname_first_author": "Kaiming He", "paper_title": "Momentum Contrast for Unsupervised Visual Representation Learning", "publication_date": "2020-06-01", "reason": "This paper introduces MoCo, a highly influential self-supervised learning method for visual representation learning that is directly compared against in the current work."}, {"fullname_first_author": "Antoine Miech", "paper_title": "Howto100M: Learning a text-video embedding by watching hundred million narrated video clips", "publication_date": "2019-10-01", "reason": "This paper introduces a large-scale video-language dataset and a contrastive learning approach for video-text embedding, offering a comparison point for the current method."}]}