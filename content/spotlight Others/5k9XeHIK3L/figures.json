[{"figure_path": "5k9XeHIK3L/figures/figures_0_1.jpg", "caption": "Figure 1: Designers can efficiently generate parametric CAD models from text prompts. The prompts can vary from abstract shape descriptions to detailed parametric instructions.", "description": "This figure illustrates the core concept of Text2CAD, showing how a user can generate a 3D model using only text prompts describing the desired shapes.  Three different prompts\u2014abstract, intermediate, and detailed\u2014are given as examples, demonstrating the system's ability to create CAD models from various levels of description. It emphasizes that Text2CAD handles design instructions for all levels of user expertise.", "section": "1 Introduction"}, {"figure_path": "5k9XeHIK3L/figures/figures_3_1.jpg", "caption": "Figure 2: Text2CAD Data Annotation Pipeline: Our data annotation pipeline generates multi-level text prompts describing the construction workflow of a CAD model with varying complexities. We use a two-stage method - (Stage 1) Shape description generation using VLM (Stage 2) Multi-Level textual annotation generation using LLM.", "description": "This figure illustrates the two-stage data annotation pipeline used in the Text2CAD project.  The first stage utilizes a Vision Language Model (VLM) to generate abstract shape descriptions from multi-view images of the 3D CAD models. These descriptions capture the overall structure of the model. The second stage employs a Large Language Model (LLM) to produce multi-level natural language instructions (NLIs) based on the shape descriptions and detailed CAD construction information. These instructions are categorized into four levels of complexity: abstract, beginner, intermediate, and expert, making them suitable for users of varying CAD skill levels.", "section": "3 Text2CAD Data Annotation"}, {"figure_path": "5k9XeHIK3L/figures/figures_5_1.jpg", "caption": "Figure 3: Network architecture: Text2CAD Transformer takes as input a text prompt T and a CAD subsequence C<sub>1:t-1</sub> of length t - 1. The text embedding T<sub>adapt</sub> is extracted from T using a pretrained BeRT Encoder ([8]) followed by a trainable Adaptive layer. The resulting embedding T<sub>adapt</sub> and the CAD sequence embedding F<sup>t-1</sup><sub>1</sub> is passed through L decoder blocks to generate the full CAD sequence in auto-regressive way.", "description": "This figure illustrates the architecture of the Text2CAD Transformer, a deep learning model designed to generate parametric CAD models from text prompts.  It shows how the model processes text input (T) and an existing CAD sequence (C<sub>1:t-1</sub>) using a BERT encoder, an adaptive layer, and multiple transformer decoder blocks to produce a complete CAD sequence (C<sub>2:t</sub>). The figure highlights the different components of the model, including the embedding layers, attention mechanisms, and feedforward networks, illustrating the autoregressive generation process step-by-step. The final output is a reconstructed 3D CAD model.", "section": "4 Text2CAD Transformer"}, {"figure_path": "5k9XeHIK3L/figures/figures_6_1.jpg", "caption": "Figure 4: Parametric CAD model generation by Text2CAD transformer using different text prompts. Our text prompts follow a certain structure highlighting the different design aspects of CAD construction workflow (shown in different colors). Abstract (L0) and Beginner (L1) level prompts contain shape descriptions (teal color) whereas Intermediate (L2) and Expert (L3) level prompts are more parametric and contain design details for sketch and extrusion (yellow and red).", "description": "This figure shows the CAD models generated by the Text2CAD model using different levels of text prompts.  The prompts are color-coded to represent the level of detail: teal for abstract and beginner levels, yellow for intermediate, and red for expert. The figure demonstrates how the model generates more detailed and parametric CAD models from more detailed prompts.", "section": "Experiment"}, {"figure_path": "5k9XeHIK3L/figures/figures_7_1.jpg", "caption": "Figure 4: Parametric CAD model generation by Text2CAD transformer using different text prompts. Our text prompts follow a certain structure highlighting the different design aspects of CAD construction workflow (shown in different colors). Abstract (L0) and Beginner (L1) level prompts contain shape descriptions (teal color) whereas Intermediate (L2) and Expert (L3) level prompts are more parametric and contain design details for sketch and extrusion (yellow and red).", "description": "This figure shows the different CAD models generated by using different levels of text prompts (abstract, beginner, intermediate, and expert). Each level of prompt is color-coded to easily distinguish the type of description used in the prompt, and the resulting CAD model demonstrates the complexity of the model based on the prompt's detail level.", "section": "5 Experiment"}, {"figure_path": "5k9XeHIK3L/figures/figures_8_1.jpg", "caption": "Figure 4: Parametric CAD model generation by Text2CAD transformer using different text prompts. Our text prompts follow a certain structure highlighting the different design aspects of CAD construction workflow (shown in different colors). Abstract (L0) and Beginner (L1) level prompts contain shape descriptions (teal color) whereas Intermediate (L2) and Expert (L3) level prompts are more parametric and contain design details for sketch and extrusion (yellow and red).", "description": "This figure shows how the Text2CAD model generates CAD models from different levels of text prompts.  The prompts range from abstract shape descriptions to detailed parametric instructions. The figure showcases the impact of prompt detail on the generated CAD model, illustrating the model's ability to handle varying levels of user expertise.", "section": "Experiment"}, {"figure_path": "5k9XeHIK3L/figures/figures_9_1.jpg", "caption": "Figure 7: Visual examples of 3D CAD model generation using varied prompts. (1) Three different prompts yielding the same ring-like model, some without explicitly mentioning \u2018ring\u2019. (2) Three diverse prompts resulting in same star-shaped model, each emphasizing different star characteristics.", "description": "This figure shows two examples to demonstrate the robustness of the Text2CAD model to different prompt styles.  The first example shows three different prompts that all successfully generate the same ring-like CAD model.  These prompts vary in descriptive detail, with one prompt being highly abstract while others provide more specific details of the shape's features. The second example demonstrates that three prompts, each employing different wording and emphasis on specific star features, all yield the same star-shaped CAD model.  This illustrates the model's ability to handle diverse phrasing and contextual clues in natural language design instructions.", "section": "Prompt Diversity"}, {"figure_path": "5k9XeHIK3L/figures/figures_15_1.jpg", "caption": "Figure 2: Text2CAD Data Annotation Pipeline: Our data annotation pipeline generates multi-level text prompts describing the construction workflow of a CAD model with varying complexities. We use a two-stage method - (Stage 1) Shape description generation using VLM (Stage 2) Multi-Level textual annotation generation using LLM.", "description": "This figure illustrates the two-stage data annotation pipeline used in the Text2CAD project.  Stage 1 employs a Vision Language Model (VLM) to generate abstract shape descriptions from multi-view images of CAD models.  These descriptions are then used in Stage 2, which leverages a Large Language Model (LLM) to produce multi-level textual instructions detailing the CAD construction process. These instructions range from abstract descriptions to detailed parametric instructions, catering to various user skill levels.", "section": "3 Text2CAD Data Annotation"}, {"figure_path": "5k9XeHIK3L/figures/figures_16_1.jpg", "caption": "Figure 3: Network architecture: Text2CAD Transformer takes as input a text prompt T and a CAD subsequence C1:t\u22121 of length t \u2212 1. The text embedding Tadapt is extracted from T using a pretrained BeRT Encoder ([8]) followed by a trainable Adaptive layer. The resulting embedding Tadapt and the CAD sequence embedding F\u22121t\u22121 is passed through L decoder blocks to generate the full CAD sequence in auto-regressive way.", "description": "This figure illustrates the architecture of the Text2CAD Transformer model.  The model takes as input a text prompt and a partial CAD sequence. It uses a pre-trained BERT encoder and an adaptive layer to process the text, creating a text embedding.  This embedding is then integrated with the partial CAD sequence embedding using a transformer decoder with layer-wise cross-attention mechanisms. The decoder generates the complete CAD sequence autoregressively.", "section": "4 Text2CAD Transformer"}, {"figure_path": "5k9XeHIK3L/figures/figures_17_1.jpg", "caption": "Figure 10: F1 score calculation for CAD sequence evaluation as proposed in [19].", "description": "This figure illustrates the F1 score calculation method for evaluating CAD sequences, as proposed in reference [19]. It shows a comparison between ground truth sketches and predicted sketches, detailing the process of loop matching and primitive matching to arrive at the final F1 score.  The steps include matching loops within each sketch, creating a cost matrix for primitives (lines, arcs, circles) within the matched loops, and applying the Hungarian algorithm to find the best matches. Finally, precision, recall, and the F1 score are calculated.", "section": "5 Experiment"}, {"figure_path": "5k9XeHIK3L/figures/figures_18_1.jpg", "caption": "Figure 4: Parametric CAD model generation by Text2CAD transformer using different text prompts. Our text prompts follow a certain structure highlighting the different design aspects of CAD construction workflow (shown in different colors). Abstract (L0) and Beginner (L1) level prompts contain shape descriptions (teal color) whereas Intermediate (L2) and Expert (L3) level prompts are more parametric and contain design details for sketch and extrusion (yellow and red).", "description": "This figure shows examples of CAD models generated by the Text2CAD model using different levels of textual prompts.  The prompts vary in complexity from abstract shape descriptions to highly detailed, parametric instructions.  The color-coding of the prompts highlights the different types of information provided (shape description, simple sketch details, extrusion details). The figure demonstrates how the model's output changes depending on the level of detail in the prompt, highlighting the model's ability to generate CAD models from various levels of user input.", "section": "Experiment"}, {"figure_path": "5k9XeHIK3L/figures/figures_19_1.jpg", "caption": "Figure 3: Network architecture: Text2CAD Transformer takes as input a text prompt T and a CAD subsequence C1:t\u22121 of length t \u2212 1. The text embedding Tadapt is extracted from T using a pretrained BeRT Encoder ([8]) followed by a trainable Adaptive layer. The resulting embedding Tadapt and the CAD sequence embedding F\u22121t\u22121 is passed through L decoder blocks to generate the full CAD sequence in auto-regressive way.", "description": "This figure illustrates the architecture of the Text2CAD Transformer model.  It shows how the model processes text prompts and existing CAD sequences to generate a complete parametric CAD model. The process starts with a pre-trained BERT encoder to process the text prompt, followed by an adaptive layer to refine the embedding.  This refined text embedding and the existing CAD sequence are then fed into multiple transformer decoder blocks which produce a sequence representing the steps for creating a CAD model. The output of the decoder is a full CAD sequence, allowing autoregressive generation of the model.", "section": "4 Text2CAD Transformer"}, {"figure_path": "5k9XeHIK3L/figures/figures_20_1.jpg", "caption": "Figure 3: Network architecture: Text2CAD Transformer takes as input a text prompt T and a CAD subsequence C1:t\u22121 of length t \u2212 1. The text embedding Tadapt is extracted from T using a pretrained BeRT Encoder ([8]) followed by a trainable Adaptive layer. The resulting embedding Tadapt and the CAD sequence embedding F\u22121t\u22121 is passed through L decoder blocks to generate the full CAD sequence in auto-regressive way.", "description": "This figure illustrates the architecture of the Text2CAD Transformer, a deep learning model designed to generate parametric CAD models from text descriptions.  The model takes as input a text prompt and a sequence of previously generated CAD tokens. It processes the text prompt using a pre-trained BERT encoder and an adaptive layer to create a contextual text embedding. This embedding, combined with the existing CAD sequence embedding, is fed into multiple transformer decoder blocks.  These blocks generate the next CAD tokens in an auto-regressive manner, sequentially building up the complete CAD model description. ", "section": "4 Text2CAD Transformer"}]