[{"figure_path": "dA7hUm4css/figures/figures_4_1.jpg", "caption": "Figure 1: An illustration of the dual properties with 128 responses drawn from the Alpaca-7b-reproduced model operating over 1000 prompts from the PKU-SafeRLHF-30K dataset. (Left) The empirical distribution of the safety scores. (Middle) The dual landscape with respect to varying margin b. (Right) The convergence of PGD with a constant step size of one and initialization \u03bb(0) = 1.", "description": "This figure demonstrates three key properties related to the dual function in the paper's proposed method. The left panel shows the distribution of safety scores from the Alpaca-7b model, illustrating the data used. The middle panel displays the dual loss function across different margin values (b), highlighting its convex nature. The right panel shows the convergence of the projected gradient descent (PGD) algorithm used for optimization, demonstrating its efficiency.", "section": "3 Dualization of constrained alignment"}, {"figure_path": "dA7hUm4css/figures/figures_7_1.jpg", "caption": "Figure 2: Visualization of MOCAN. (Left) Dual optimization predicts the safety improvement of practically aligned LMs. (Middle & Right) The safety/helpfulness score distribution before and after alignment (\u03bb = 0.75).", "description": "This figure visualizes the results of the MOCAN algorithm. The left panel shows how well dual optimization predicts the safety improvement achieved by practically aligning language models. The middle and right panels show the distributions of safety and helpfulness scores before and after alignment using MOCAN with a specific dual variable (\u03bb = 0.75).  The comparison highlights the impact of MOCAN on improving both safety and helpfulness.", "section": "5 Computational experiments"}, {"figure_path": "dA7hUm4css/figures/figures_8_1.jpg", "caption": "Figure 3: Trade-off in improving helpfulness and safety of aligned LMs. (Left) Improvement of helpfulness score versus safety score of MOCAN-aligned LMs under model-based evaluation. (Middle & Right) Helpfulness win rate versus safety win rate of MOCAN-aligned LMs and PECAN-aligned LMs with \u03b2 = 0.1, respectively, under GPT-based evaluation.", "description": "This figure demonstrates the trade-off between helpfulness and safety improvements achieved by the MOCAN and PECAN models.  The left panel shows the model-based evaluation (using proxy reward and safety models), illustrating how increasing safety often comes at the cost of reduced helpfulness. The middle and right panels present GPT-based evaluations (using GPT-4-turbo as an evaluator), comparing the win rates of the aligned LMs against a supervised fine-tuning baseline (SFT) for both helpfulness and safety, with \u03b2 set to 0.1.", "section": "5.2 Experimental results"}, {"figure_path": "dA7hUm4css/figures/figures_9_1.jpg", "caption": "Figure 1: An illustration of the dual properties with 128 responses drawn from the Alpaca-7b-reproduced model operating over 1000 prompts from the PKU-SafeRLHF-30K dataset. (Left) The empirical distribution of the safety scores. (Middle) The dual landscape with respect to varying margin b. (Right) The convergence of PGD with a constant step size of one and initialization \u03bb(0) = 1.", "description": "This figure illustrates three key properties of the dual function used in the CAN algorithm.  The left panel shows the empirical distribution of safety scores from a dataset.  The middle panel displays the dual loss landscape for various safety margins, demonstrating the convexity and smoothness of the dual function. The right panel visualizes the convergence of the projected gradient descent (PGD) algorithm used to find the optimal dual variable, showcasing its efficiency and rapid convergence.", "section": "3 Dualization of constrained alignment"}, {"figure_path": "dA7hUm4css/figures/figures_27_1.jpg", "caption": "Figure 1: An illustration of the dual properties with 128 responses drawn from the Alpaca-7b-reproduced model operating over 1000 prompts from the PKU-SafeRLHF-30K dataset. (Left) The empirical distribution of the safety scores. (Middle) The dual landscape with respect to varying margin b. (Right) The convergence of PGD with a constant step size of one and initialization \u03bb(0) = 1.", "description": "This figure demonstrates several properties of the dual function (D(\u03bb)) used in the CAN algorithm.  The left panel shows the distribution of safety scores from a language model. The middle panel displays how the dual function's shape changes as the margin (b) in the safety constraint is varied.  The right panel illustrates the convergence of the projected gradient descent (PGD) algorithm used to find the optimal dual variable (\u03bb*).", "section": "3 Dualization of constrained alignment"}, {"figure_path": "dA7hUm4css/figures/figures_28_1.jpg", "caption": "Figure 1: An illustration of the dual properties with 128 responses drawn from the Alpaca-7b-reproduced model operating over 1000 prompts from the PKU-SafeRLHF-30K dataset. (Left) The empirical distribution of the safety scores. (Middle) The dual landscape with respect to varying margin b. (Right) The convergence of PGD with a constant step size of one and initialization \u03bb(0) = 1.", "description": "This figure illustrates key properties of the dual function (D(\u03bb)) used in the CAN algorithm.  The left panel shows the empirical distribution of safety scores from a model, highlighting the data's characteristics. The middle panel displays the dual function's landscape for different margin values (b), demonstrating its convexity. Finally, the right panel illustrates the convergence of the projected gradient descent (PGD) algorithm used to minimize D(\u03bb), showing its efficiency in finding the optimal dual variable.", "section": "3 Dualization of constrained alignment"}]