[{"figure_path": "6ZBHIEtdP4/tables/tables_1_1.jpg", "caption": "Table 1: Comparison of similarities and differences between PiSSA and LoRA. In this table, bold highlights the model's primary component, while underline denotes the residual component.", "description": "This table compares and contrasts the forward pass, initialization, gradient calculation, and overall comparison of PiSSA and LoRA.  It highlights key differences in how each method handles weight updates and initialization, showing that PiSSA updates principal components while freezing residual components, leading to faster convergence and potentially better performance compared to LoRA.", "section": "Comparison of similarities and differences between PiSSA and LoRA"}, {"figure_path": "6ZBHIEtdP4/tables/tables_6_1.jpg", "caption": "Table 2: Comparison of PiSSA and LoRA on NLG tasks, with results averaged over three runs and reported with standard deviations.", "description": "This table presents a comparison of the performance of PiSSA and LoRA on various natural language generation (NLG) tasks.  Three different large language models (LLaMA-2-7B, Mistral-7B, and Gemma-7B) were fine-tuned using both methods, and the results (averaged over three runs) are reported with standard deviations for each task. The tasks include GSM8K, MATH, HumanEval, MBPP, and MT-Bench, providing a comprehensive evaluation across different benchmarks and model types.", "section": "5.1 Evaluating the Performance of PiSSA on both NLG and NLU Tasks"}, {"figure_path": "6ZBHIEtdP4/tables/tables_6_2.jpg", "caption": "Table 3: Comparison of PiSSA and LoRA on NLU tasks. LoRAG and LoRAK denote LoRA with Gaussian and Kaiming initialization for B, respectively. Results for full fine-tuning, BitFit [15], HAdapter [30], PAdapter [36], LoRAG [11] and AdaLoRA are from AdaLoRA [58], averaged over five runs. Remaining methods are averaged over three runs, with details in Appendix L.", "description": "This table compares the performance of PiSSA and LoRA on eleven natural language understanding (NLU) tasks using the GLUE benchmark.  It shows the accuracy achieved by various methods, including full fine-tuning, BitFit, HAdapter, PAdapter, LoRA (with Gaussian and Kaiming initialization), DORA, and AdaLoRA. The table highlights PiSSA's consistent performance improvement compared to LoRA across different tasks.  Details about the experimental setup and statistical analysis can be found in Appendix L.", "section": "5.1 Evaluating the Performance of PiSSA on both NLG and NLU Tasks"}, {"figure_path": "6ZBHIEtdP4/tables/tables_7_1.jpg", "caption": "Table 4: The quantization error reduction ratio of QLoRA, LoftQ, and PiSSA across different layers.", "description": "This table compares the quantization error reduction ratios achieved by three different methods (QLoRA, LoftQ, and PiSSA) across various layers of different language models.  The error reduction ratio is calculated as (1 - ||W-(nf4(W)+AB)||*) \u00d7 100%, where ||.||* denotes the nuclear norm. A higher ratio signifies a greater reduction in quantization error, indicating a more effective method. The table shows that PiSSA consistently outperforms the other two methods across different model sizes and various layers, demonstrating its advantage in reducing quantization error.", "section": "5.3 Conducting 4-bit Quantization Experiments"}, {"figure_path": "6ZBHIEtdP4/tables/tables_16_1.jpg", "caption": "Table 5: GSM8K accuracy for LORA and PiSSA when combined with LoRA improvement methods.", "description": "This table compares the performance of different methods on the GSM8K benchmark.  It shows the accuracy achieved by the vanilla LORA and PiSSA models, and also the accuracy when these models are enhanced with three LoRA improvement methods (DORA, AdaLoRA). The results demonstrate that PiSSA consistently outperforms LORA, and that incorporating LoRA improvements further enhances the performance of both methods.", "section": "A Enhancing PiSSA with LoRA Improvement Methods"}, {"figure_path": "6ZBHIEtdP4/tables/tables_17_1.jpg", "caption": "Table 3: Comparison of PiSSA and LoRA on NLU tasks. LoRAG and LoRAK denote LoRA with Gaussian and Kaiming initialization for B, respectively. Results for full fine-tuning, BitFit [15], HAdapter [30], PAdapter [36], LoRAG [11] and AdaLoRA are from AdaLoRA [58], averaged over five runs. Remaining methods are averaged over three runs, with details in Appendix L.", "description": "This table compares the performance of PiSSA and LoRA on eleven natural language understanding (NLU) tasks from the GLUE benchmark.  It shows the accuracy of different models (including various parameter-efficient fine-tuning methods) for each task and their overall performance.  The results highlight the consistent improvement of PiSSA over LoRA across the NLU tasks.", "section": "5.1 Evaluating the Performance of PiSSA on both NLG and NLU Tasks"}, {"figure_path": "6ZBHIEtdP4/tables/tables_18_1.jpg", "caption": "Table 2: Comparison of PiSSA and LoRA on NLG tasks, with results averaged over three runs and reported with standard deviations.", "description": "This table presents a comparison of the performance of PiSSA and LoRA on several Natural Language Generation (NLG) tasks.  The models were evaluated on various metrics such as GSM8K, MATH, HumanEval, MBPP and MT-Bench across four different models: LLaMA 2-7B, Mistral-7B, Gemma-7B.  The results are averages of three runs and include standard deviations to show variability.  The table highlights the consistent superior performance of PiSSA compared to LoRA.", "section": "5.1 Evaluating the Performance of PiSSA on both NLG and NLU Tasks"}, {"figure_path": "6ZBHIEtdP4/tables/tables_19_1.jpg", "caption": "Table 2: Comparison of PiSSA and LoRA on NLG tasks, with results averaged over three runs and reported with standard deviations.", "description": "This table presents a comparison of the performance of PiSSA and LoRA on various Natural Language Generation (NLG) tasks.  The results are averaged over three runs and include standard deviations to indicate the variability in the results.  The table shows that PiSSA consistently outperforms LoRA across a variety of models and tasks, highlighting the effectiveness of PiSSA as a parameter-efficient fine-tuning method.", "section": "5.1 Evaluating the Performance of PiSSA on both NLG and NLU Tasks"}, {"figure_path": "6ZBHIEtdP4/tables/tables_22_1.jpg", "caption": "Table 2: Comparison of PiSSA and LoRA on NLG tasks, with results averaged over three runs and reported with standard deviations.", "description": "This table presents a comparison of the performance of PiSSA and LoRA on various Natural Language Generation (NLG) tasks.  It shows the accuracy achieved by full fine-tuning, LoRA with Gaussian initialization, LoRA with Kaiming initialization, and PiSSA across multiple models (LLaMA-2-7B, Mistral-7B, Gemma-7B) and several NLG benchmarks (GSM8K, MATH, HumanEval, MBPP, MT-Bench).  Standard deviations are included to show the variability in the results.", "section": "5.1 Evaluating the Performance of PiSSA on both NLG and NLU Tasks"}, {"figure_path": "6ZBHIEtdP4/tables/tables_27_1.jpg", "caption": "Table 3: Comparison of PiSSA and LoRA on NLU tasks. LoRAG and LoRAK denote LoRA with Gaussian and Kaiming initialization for B, respectively. Results for full fine-tuning, BitFit [15], HAdapter [30], PAdapter [36], LoRAG [11] and AdaLoRA are from AdaLoRA [58], averaged over five runs. Remaining methods are averaged over three runs, with details in Appendix L.", "description": "This table compares the performance of PiSSA and LoRA on eleven different natural language understanding (NLU) tasks.  It shows various model parameters, the results for each model on each task (with metrics like accuracy), and indicates the methods used for initialization.  Results from five runs for full fine-tuning, BitFit, HAdapter, PAdapter, LoRAG and AdaLoRA are included, while PiSSA and LoRA results are based on three runs.  Details about these results can be found in Appendix L. The table highlights the differences in performance between PiSSA and LoRA and other state-of-the-art models.", "section": "5.1 Evaluating the Performance of PiSSA on both NLG and NLU Tasks"}, {"figure_path": "6ZBHIEtdP4/tables/tables_28_1.jpg", "caption": "Table 3: Comparison of PiSSA and LoRA on NLU tasks. LoRAG and LoRAK denote LoRA with Gaussian and Kaiming initialization for B, respectively. Results for full fine-tuning, BitFit [15], HAdapter [30], PAdapter [36], LoRAG [11] and AdaLoRA are from AdaLoRA [58], averaged over five runs. Remaining methods are averaged over three runs, with details in Appendix L.", "description": "This table compares the performance of PiSSA and LoRA on eleven different natural language understanding (NLU) tasks using the GLUE benchmark.  It shows the accuracy achieved by various methods, including full fine-tuning, BitFit, HAdapter, PAdapter, LoRA (with Gaussian and Kaiming initialization), AdaLoRA, and PiSSA.  The table highlights the performance gains achieved by PiSSA compared to other methods, demonstrating its effectiveness in NLU tasks.  The table also shows the model parameters used and includes references to relevant papers and appendices for more detail.", "section": "5.1 Evaluating the Performance of PiSSA on both NLG and NLU Tasks"}]