[{"figure_path": "YgJPQW0lkO/figures/figures_1_1.jpg", "caption": "Figure 1: Graph Uncertainty for claim-level uncertainty estimation. We first sample several responses from LLMs (a) and decompose each response into atomic claims (b) following Sec. 4.1. The key components are the construction of a bipartite graph that captures the relations between responses and claims (c) and the use of graph centrality metrics to estimate the uncertainty of each claim. We simplify the pipeline and prompt for presentation, see Appx. F for details.", "description": "This figure illustrates the Graph Uncertainty framework for claim-level uncertainty estimation.  It begins with sampling multiple responses from a large language model (LLM) given a prompt (a). Each response is then decomposed into individual claims (b).  A bipartite graph is constructed, linking claims to the responses that support them (c). Finally, graph centrality metrics (degree, eigenvalue, PageRank, closeness, etc.) are used to estimate the uncertainty of each claim (d). Claims with high uncertainty are marked with an 'X', while those with low uncertainty are marked with a checkmark.  This framework provides a more granular way to assess uncertainty compared to methods that only focus on overall response uncertainty.", "section": "4 Claim-Level Uncertainty Estimation with Semantic Entailment Graphs"}, {"figure_path": "YgJPQW0lkO/figures/figures_4_1.jpg", "caption": "Figure 2: Our uncertainty-aware decoding framework. Based on our claim-wise uncertainty estimates obtained from Fig. 1, we keep low-uncertainty claims above a certain confidence threshold and use LLMs to synthesize them into a coherent response. Varying the threshold enables us to balance factuality and informativeness.", "description": "This figure illustrates the uncertainty-aware decoding framework.  It takes as input a set of claims with associated uncertainty scores (obtained from the graph uncertainty method shown in Figure 1). Claims with uncertainty scores below a threshold are selected.  An LLM then synthesizes these selected claims into a coherent paragraph. The threshold parameter controls the trade-off between factuality (fewer false claims) and informativeness (more claims included in the final output).", "section": "5 Uncertainty-Aware Decoding"}, {"figure_path": "YgJPQW0lkO/figures/figures_7_1.jpg", "caption": "Figure 3: UAD with better claim-level uncertainty estimates demonstrates a better trade-off between factuality and informativeness of the generated responses. We compare UAD across different thresholds & and two non-uncertainty decoding baselines. We assume that random noise is applied to break ties for each uncertainty method, resulting in a horizontal line extending from the leftmost dot to the left. The shaded confidence interval is obtained by bootstrapping with a confidence level of 95%.", "description": "The figure shows the precision of claims (y-axis) plotted against the number of true claims (x-axis) for different methods including greedy decoding, CoVe, and several variants of Uncertainty-Aware Decoding (UAD).  Different UAD variants use different uncertainty estimation methods to filter claims before generating the response.  The graph illustrates the trade-off between factuality (precision of claims) and informativeness (number of true claims).  UAD methods, particularly those employing the closeness centrality metric, show a better trade-off compared to non-UAD baselines. The shaded regions represent confidence intervals.", "section": "6.2 Uncertainty-Aware Decoding"}, {"figure_path": "YgJPQW0lkO/figures/figures_8_1.jpg", "caption": "Figure 4: Ablation study: (a) The false claims have a greater average distance to other claims compared to true ones, indicating the effectiveness of the closeness centrality metric. (b) Performance improves consistently as we increase the number of responses |RN| used to construct the claim node set C in our uncertainty estimation method. While all evaluations are conducted on the same fixed set of claims, varying RN alters the graph structure used to estimate these claims\u2019 uncertainty values.", "description": "This figure presents the results of an ablation study to analyze the effectiveness of closeness centrality for uncertainty estimation. Subfigure (a) shows that false claims have a greater average distance to other claims in the semantic graph compared to true claims, demonstrating the effectiveness of the closeness centrality metric.  Subfigure (b) demonstrates that increasing the number of responses used to construct the claim node set consistently improves performance, highlighting the impact of the graph structure on uncertainty estimation.  The results show that closeness centrality is effective at discriminating between true and false claims because of the relationships between nodes within the graph.  More connections indicate higher centrality and a higher likelihood of factual accuracy.", "section": "6.3 Ablation Study"}, {"figure_path": "YgJPQW0lkO/figures/figures_8_2.jpg", "caption": "Figure 4: Ablation study: (a) The false claims have a greater average distance to other claims compared to true ones, indicating the effectiveness of the closeness centrality metric. (b) Performance improves consistently as we increase the number of responses |RN| used to construct the claim node set C in our uncertainty estimation method. While all evaluations are conducted on the same fixed set of claims, varying RN alters the graph structure used to estimate these claims\u2019 uncertainty values.", "description": "This figure presents an ablation study to analyze the effectiveness of closeness centrality in discriminating between true and false claims and how the performance changes with the number of responses used to construct the claim node set.  The left subplot (a) shows that false claims have a greater average distance to other claims than true claims in the semantic graph, supporting the use of closeness centrality. The right subplot (b) demonstrates that increasing the number of responses consistently improves performance in uncertainty estimation, highlighting the benefit of using more granular graph information.", "section": "6.3 Ablation Study"}, {"figure_path": "YgJPQW0lkO/figures/figures_17_1.jpg", "caption": "Figure 5a: AUROC curves for the GPT-3.5 model with |R| = 10 on the FActScore dataset. Our method using closeness centrality (CC) outperforms the baselines.", "description": "This figure shows the AUROC curves for different uncertainty estimation methods on the FactScore dataset using the GPT-3.5 model with 10 response samples.  The closeness centrality (CC) method significantly outperforms baseline methods such as post-hoc verbalized confidence (PH-VC), self-consistency (SC), and self-consistency combined with verbalized confidence (SC+VC), demonstrating its superior ability to distinguish between true and false claims.", "section": "6.1 Uncertainty Estimation"}, {"figure_path": "YgJPQW0lkO/figures/figures_17_2.jpg", "caption": "Figure 3: UAD with better claim-level uncertainty estimates demonstrates a better trade-off between factuality and informativeness of the generated responses. We compare UAD across different thresholds & and two non-uncertainty decoding baselines. We assume that random noise is applied to break ties for each uncertainty method, resulting in a horizontal line extending from the leftmost dot to the left. The shaded confidence interval is obtained by bootstrapping with a confidence level of 95%.", "description": "This figure shows the results of the Uncertainty-Aware Decoding (UAD) method compared to other baselines (greedy decoding and CoVe). The x-axis represents the number of true claims, while the y-axis represents the precision of claims (factuality). Each curve represents a different threshold for filtering claims based on uncertainty scores. The results show that UAD with closeness centrality consistently outperforms other methods, achieving a better trade-off between factuality and informativeness.", "section": "6.2 Uncertainty-Aware Decoding"}, {"figure_path": "YgJPQW0lkO/figures/figures_17_3.jpg", "caption": "Figure 3: UAD with better claim-level uncertainty estimates demonstrates a better trade-off between factuality and informativeness of the generated responses. We compare UAD across different thresholds & and two non-uncertainty decoding baselines. We assume that random noise is applied to break ties for each uncertainty method, resulting in a horizontal line extending from the leftmost dot to the left. The shaded confidence interval is obtained by bootstrapping with a confidence level of 95%.", "description": "This figure compares different decoding methods for evaluating the trade-off between the factuality and informativeness of the generated responses. The x-axis represents the informativeness (number of true claims), and the y-axis represents the factuality (precision of claims). The plot shows the Pareto frontier, illustrating the best possible trade-offs between factuality and informativeness. UAD (Uncertainty-Aware Decoding) methods consistently achieve a better trade-off than greedy decoding and CoVe baselines, demonstrating the effectiveness of incorporating uncertainty estimates into the decoding process.", "section": "6.2 Uncertainty-Aware Decoding"}, {"figure_path": "YgJPQW0lkO/figures/figures_18_1.jpg", "caption": "Figure 3: UAD with better claim-level uncertainty estimates demonstrates a better trade-off between factuality and informativeness of the generated responses. We compare UAD across different thresholds & and two non-uncertainty decoding baselines. We assume that random noise is applied to break ties for each uncertainty method, resulting in a horizontal line extending from the leftmost dot to the left. The shaded confidence interval is obtained by bootstrapping with a confidence level of 95%.", "description": "This figure shows the results of the Uncertainty-Aware Decoding (UAD) method.  It compares the performance of UAD using different uncertainty estimation methods (Self-Consistency with greedy decoding, Self-Consistency with multi-sample decoding, Self-Consistency + In-line Verbalized Confidence with multi-sample decoding, and Closeness Centrality with multi-sample decoding) against greedy decoding and CoVe baselines. The x-axis represents the number of true claims, and the y-axis represents the precision of the claims. The figure demonstrates that UAD with better claim-level uncertainty estimation achieves a better balance between factuality and informativeness.", "section": "Uncertainty-Aware Decoding"}]