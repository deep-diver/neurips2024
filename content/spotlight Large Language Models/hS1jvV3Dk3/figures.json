[{"figure_path": "hS1jvV3Dk3/figures/figures_3_1.jpg", "caption": "Figure 7: The estimated accuracy distribution of prompts generated by Vicuna-13B or ChatGPT on various instruction induction tasks, where the vertical dotted line indicates the mean performance.", "description": "This figure shows the distribution of validation accuracies for prompts generated by two different large language models, Vicuna-13B and ChatGPT.  It demonstrates that ChatGPT tends to generate prompts with higher accuracy and a larger mean accuracy than Vicuna-13B.  The x-axis represents validation accuracy, and the y-axis represents the probability density. The vertical dotted lines represent the mean accuracy for each model.", "section": "3.2 Essence of Input Domain"}, {"figure_path": "hS1jvV3Dk3/figures/figures_3_2.jpg", "caption": "Figure 4: The function surfaces using the last token (Vicuna-13B) or SBERT embedding.", "description": "This figure visualizes the accuracy landscape (function surface) for prompt optimization using two different embedding methods: the last token embedding from the Vicuna-13B model and the SBERT embedding.  The visualizations aim to illustrate how the choice of embedding impacts the distribution of well-performing local optima in the prompt optimization process.  Different embeddings lead to varying numbers of well-performing local optima, highlighting the importance of input domain selection in efficient prompt optimization.", "section": "3.2 Essence of Input Domain"}, {"figure_path": "hS1jvV3Dk3/figures/figures_7_1.jpg", "caption": "Figure 5: Comparison of the query efficiency between ZOPO and baselines. The first and second rows show the test and validation accuracies.", "description": "This figure compares the query efficiency of ZOPO against several baseline methods (APE, InstructZero, INSTINCT, EvoPrompt, PB, and OPRO) across three different tasks (taxonomy_animal, cause_and_effect, and informal_to_formal). The top row shows test accuracy, while the bottom row shows validation accuracy.  The x-axis represents the number of queries, and the y-axis represents accuracy.  The figure demonstrates that ZOPO generally achieves better performance with the same number of queries compared with other baseline methods and yields superior performance upon convergence. The plot also reveals that ZOPO achieves lower validation accuracy but higher test accuracy on the taxonomy_animal task compared to INSTINCT, suggesting better generalization for ZOPO.", "section": "5 Experiments"}, {"figure_path": "hS1jvV3Dk3/figures/figures_15_1.jpg", "caption": "Figure 1: The performance profile for different methods on 20 tasks. A higher p(\u03c4) is better. More details in Sec. 5.", "description": "This figure shows the performance profile of several prompt optimization methods on 20 different instruction induction tasks. The performance profile is a plot showing the cumulative distribution function (CDF) of the performance of each method.  The x-axis represents the performance level (\u03c4) and the y-axis shows the proportion of tasks for which the method achieves at least that performance level (p(\u03c4)). A method that is consistently better than other methods will have a curve that is higher and further to the right. The figure indicates that ZOPO outperforms other methods across a range of performance levels.", "section": "5 Experiments"}, {"figure_path": "hS1jvV3Dk3/figures/figures_16_1.jpg", "caption": "Figure 1: The performance profile for different methods on 20 tasks. A higher p(\u03c4) is better. More details in Sec. 5.", "description": "This figure shows the performance profile curves for various prompt optimization methods on 20 different tasks.  The performance profile, denoted as p(\u03c4), indicates the probability that a given method achieves a performance within a factor of \u03c4 of the best observed performance across all methods tested on the task. A higher p(\u03c4) value at any given \u03c4 signifies better performance.  The curve for ZOPO (the proposed method) dominates others, indicating better performance overall.  Section 5 provides further details on the methodology and the results.", "section": "5 Experiments"}, {"figure_path": "hS1jvV3Dk3/figures/figures_17_1.jpg", "caption": "Figure 1: The performance profile for different methods on 20 tasks. A higher p(\u03c4) is better. More details in Sec. 5.", "description": "This figure shows the performance profile of different prompt optimization methods across 20 tasks. The performance profile is a cumulative distribution function (CDF) that plots the proportion of tasks for which a given method achieves a performance within a certain distance (\u03c4) from the best-performing method for each task. A higher p(\u03c4) indicates superior performance across more tasks.  Section 5 provides further details.", "section": "5 Experiments"}, {"figure_path": "hS1jvV3Dk3/figures/figures_18_1.jpg", "caption": "Figure 6: The validation accuracy of 300 randomly sampled prompts with the last token representation on various tasks.", "description": "This figure visualizes the performance of 300 randomly selected prompts on various tasks. Each prompt's embedding (using the last token representation) is reduced to two dimensions using t-SNE for better visualization. The color of each point represents its validation accuracy, demonstrating the prevalence of well-performing local optima in the prompt optimization landscape, supporting Insight I in the paper.", "section": "3 Empirical Study on Prompt Optimization"}, {"figure_path": "hS1jvV3Dk3/figures/figures_18_2.jpg", "caption": "Figure 7: The estimated accuracy distribution of prompts generated by Vicuna-13B or ChatGPT on various instruction induction tasks, where the vertical dotted line indicates the mean performance.", "description": "This figure displays the distribution of validation accuracies achieved by prompts generated using two different large language models: Vicuna-13B and ChatGPT.  The x-axis represents the validation accuracy, while the y-axis shows the probability density.  Each subplot corresponds to a different instruction induction task. The vertical dotted lines in each subplot indicate the mean validation accuracy for that task. This visualization helps to understand the variability in performance across different prompts generated by each model and across different tasks.  The comparison between Vicuna-13B and ChatGPT highlights differences in their ability to generate high-performing prompts.", "section": "3.2 Essence of Input Domain"}, {"figure_path": "hS1jvV3Dk3/figures/figures_19_1.jpg", "caption": "Figure 8: The function surfaces on various tasks using the last token embedding from Vicuna-13B as the representation for prompt candidates that are generated by Vicuna-13B, with contour plots shown below.", "description": "This figure visualizes the accuracy landscape (function surface) for different prompt optimization tasks.  The x and y axes represent the two dimensions of the reduced prompt embedding (Vicuna-13B last token embedding reduced to 2D using t-SNE), and the color intensity represents the validation accuracy. The contour plots at the bottom provide additional visualization of the accuracy landscape. This figure illustrates that the complexity of the target function varies among tasks, with some having many good local optima and others having fewer.  The existence of numerous good local optima supports the paper's focus on localized zeroth-order optimization.", "section": "3.2 Essence of Input Domain"}, {"figure_path": "hS1jvV3Dk3/figures/figures_21_1.jpg", "caption": "Figure 1: The performance profile for different methods on 20 tasks. A higher p(\u03c4) is better. More details in Sec. 5.", "description": "This figure shows the performance profile of different prompt optimization methods on 20 instruction induction tasks.  The performance profile plots the cumulative distribution function (CDF) of the performance of each method relative to the best performing method across all tasks. A higher p(\u03c4) indicates better performance, meaning that the method achieves a higher accuracy within a given distance (\u03c4) from the optimal accuracy.  The figure highlights the superior performance of the proposed ZOPOGPT method compared to several baselines (APE, InstructZero, INSTINCT, EvoPrompt, PB, OPRO).", "section": "5 Experiments"}, {"figure_path": "hS1jvV3Dk3/figures/figures_21_2.jpg", "caption": "Figure 5: Comparison of the query efficiency between ZOPO and baselines. The first and second rows show the test and validation accuracies.", "description": "This figure compares the query efficiency of ZOPO against several other baseline methods across different query budget scales.  The top row shows the test accuracy, while the bottom row displays the validation accuracy.  It illustrates that ZOPO generally achieves better performance with the same number of queries compared to other methods, and it shows superior performance upon convergence.  Noteworthy is that ZOPO achieves lower validation accuracy but higher test accuracy on the \\texttt{taxonomy_animal} task than INSTINCT, suggesting potentially better generalization.", "section": "5 Experiments"}, {"figure_path": "hS1jvV3Dk3/figures/figures_24_1.jpg", "caption": "Figure 1: The performance profile for different methods on 20 tasks. A higher p(\u03c4) is better. More details in Sec. 5.", "description": "The figure shows the performance profile of different prompt optimization methods across 20 tasks, comparing their efficiency in achieving high accuracy within a given query budget.  The x-axis (\u03c4) represents the performance gap from the best-performing method, and the y-axis (\u03c1(\u03c4)) indicates the proportion of tasks for which a method achieves a performance within \u03c4 of the optimum. A higher curve shows better performance.  Section 5 provides more detailed analysis of these results.", "section": "5 Experiments"}]