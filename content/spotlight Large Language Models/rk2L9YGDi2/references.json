{"references": [{"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper is foundational to the field of large language models, introducing the concept of few-shot learning which is crucial to the development of many LLMs."}, {"fullname_first_author": "Aakanksha Chowdhery", "paper_title": "PaLM: Scaling language modeling with pathways", "publication_date": "2022-04-01", "reason": "This paper introduces Pathways Language Model (PaLM), a highly influential model that demonstrates the power of scaling language models to unprecedented size and performance."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "publication_date": "2023-07-18", "reason": "This paper introduces Llama 2, a significant advancement in open-source LLMs which has become a widely used benchmark for evaluating LLM performance."}, {"fullname_first_author": "Xupeng Miao", "paper_title": "Specinfer: Accelerating generative llm serving with speculative inference and token tree verification", "publication_date": "2023-05-01", "reason": "This paper introduces SpecInfer, a key prior work in speculative decoding which SEQUOIA builds upon and improves, making it a crucial reference for understanding the context of SEQUOIA's contributions."}, {"fullname_first_author": "Yaniv Leviathan", "paper_title": "Fast inference from transformers via speculative decoding", "publication_date": "2023-07-01", "reason": "This paper introduces the foundational concept of speculative decoding for accelerating LLM inference, which is the primary focus of SEQUOIA's improvements."}]}