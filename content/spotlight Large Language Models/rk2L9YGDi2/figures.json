[{"figure_path": "rk2L9YGDi2/figures/figures_1_1.jpg", "caption": "Figure 1: SEQUOIA is a scalable method for speculative decoding. Left: SEQUOIA tree construction algorithm is able to generate trees whose average number of generated tokens (after verification) continues to grow with the tree size while existing tree structures asymptote. This allows SEQUOIA to perform much better than existing methods in very memory-bound regimes like offloading. Right: A visualization to contrast SEQUOIA tree structure with other common handcrafted ones.", "description": "The figure demonstrates the scalability of the SEQUOIA speculative decoding algorithm. The left panel shows that the average number of generated tokens after verification in SEQUOIA trees continues to grow with the tree size, unlike existing methods which asymptote. This improved scalability is particularly beneficial in memory-constrained environments like offloading. The right panel provides a visual comparison of the SEQUOIA tree structure with other common handcrafted structures, highlighting SEQUOIA's ability to generate significantly larger and more efficient trees.", "section": "3 SEQUOIA"}, {"figure_path": "rk2L9YGDi2/figures/figures_3_1.jpg", "caption": "Figure 1: SEQUOIA is a scalable method for speculative decoding. Left: SEQUOIA tree construction algorithm is able to generate trees whose average number of generated tokens (after verification) continues to grow with the tree size while existing tree structures asymptote. This allows SEQUOIA to perform much better than existing methods in very memory-bound regimes like offloading. Right: A visualization to contrast SEQUOIA tree structure with other common handcrafted ones.", "description": "The figure on the left shows the average number of generated tokens after verification for different tree construction methods. SEQUOIA's performance continues to grow with the tree size, while other methods such as the use of k independent sequences or binary trees reach a plateau.  This demonstrates SEQUOIA's scalability, particularly beneficial in memory-constrained settings like offloading. The figure on the right provides a visual comparison of SEQUOIA's tree structure with other common structures, highlighting its unique topology.", "section": "1 Introduction"}, {"figure_path": "rk2L9YGDi2/figures/figures_5_1.jpg", "caption": "Figure 3: Rejection rate vs. number speculated tokens: We plot the average rejection rate (1 \u2013 acceptance_rate) for the different verification algorithms, as a function of the number of speculated tokens k. Across temperature settings ({0.2,0.6,1.0}, left to right), the SEQUOIA verification algorithm attains the lowest rejection rates, and consistently has a power-law acceptance rate (Definition 3.5).", "description": "This figure compares the rejection rates of four different verification algorithms (SEQUOIA, SpecInfer, SpecTr, and Top-k Sampling) across three different temperature settings (0.2, 0.6, and 1.0). The x-axis represents the number of speculated tokens, and the y-axis represents the average rejection rate. The figure shows that SEQUOIA consistently achieves the lowest rejection rates across all temperature settings and exhibits a power-law acceptance rate. This indicates that SEQUOIA's sampling and verification strategy is robust and effective at various temperatures.", "section": "3.2 Tree sampling and verification"}, {"figure_path": "rk2L9YGDi2/figures/figures_8_1.jpg", "caption": "Figure 1: SEQUOIA is a scalable method for speculative decoding. Left: SEQUOIA tree construction algorithm is able to generate trees whose average number of generated tokens (after verification) continues to grow with the tree size while existing tree structures asymptote. This allows SEQUOIA to perform much better than existing methods in very memory-bound regimes like offloading. Right: A visualization to contrast SEQUOIA tree structure with other common handcrafted ones.", "description": "This figure compares SEQUOIA's tree construction algorithm with existing methods for speculative decoding.  The left side shows that SEQUOIA generates trees with an average number of verified tokens that increases with tree size, unlike existing methods which plateau. This scalability is particularly advantageous in memory-constrained environments like offloading. The right side visually contrasts SEQUOIA's tree structure with simpler structures used by other methods, highlighting the key difference in topology that leads to SEQUOIA's improved performance.", "section": "3 SEQUOIA"}, {"figure_path": "rk2L9YGDi2/figures/figures_15_1.jpg", "caption": "Figure 1: SEQUOIA is a scalable method for speculative decoding. Left: SEQUOIA tree construction algorithm is able to generate trees whose average number of generated tokens (after verification) continues to grow with the tree size while existing tree structures asymptote. This allows SEQUOIA to perform much better than existing methods in very memory-bound regimes like offloading. Right: A visualization to contrast SEQUOIA tree structure with other common handcrafted ones.", "description": "The figure demonstrates the scalability of the SEQUOIA algorithm for speculative decoding. The left panel shows that the average number of generated tokens after verification in SEQUOIA trees continues to increase with the size of the tree, unlike existing methods.  This scalability is particularly beneficial in memory-constrained environments such as offloading. The right panel visually compares the SEQUOIA tree structure with other common tree structures.", "section": "3 SEQUOIA"}, {"figure_path": "rk2L9YGDi2/figures/figures_25_1.jpg", "caption": "Figure 1: SEQUOIA is a scalable method for speculative decoding. Left: SEQUOIA tree construction algorithm is able to generate trees whose average number of generated tokens (after verification) continues to grow with the tree size while existing tree structures asymptote. This allows SEQUOIA to perform much better than existing methods in very memory-bound regimes like offloading. Right: A visualization to contrast SEQUOIA tree structure with other common handcrafted ones.", "description": "The figure shows that SEQUOIA's tree construction algorithm outperforms other methods by generating trees whose average number of verified tokens grows with the tree size, unlike existing methods that asymptote. This scalability advantage is particularly beneficial in memory-constrained environments such as offloading.  The right side visually compares SEQUOIA's tree structure to other common structures, highlighting its unique ability to grow unboundedly with tree size.", "section": "3 SEQUOIA"}, {"figure_path": "rk2L9YGDi2/figures/figures_26_1.jpg", "caption": "Figure 4: Left: We compare the number of tokens generated on average by SEQUOIA trees vs. k independent sequences, where we use SEQUOIA sampling and verification for both tree structures. Right: We compare the speedups attained by the SEQUOIA sampling and verification algorithm relative to SpecInfer and top-k sampling, across various temperatures, holding the tree structure fixed.", "description": "This figure demonstrates two key aspects of the SEQUOIA algorithm. The left panel shows the scalability of SEQUOIA's tree construction method by comparing the average number of generated tokens for SEQUOIA trees versus k independent sequences of tokens (with the same sampling and verification methods). It highlights that SEQUOIA trees generate more tokens as their size increases, unlike other methods that reach a plateau. The right panel showcases the robustness of the SEQUOIA sampling and verification algorithm across different temperature settings, comparing its performance against SpecInfer and top-k sampling methods. It indicates that SEQUOIA consistently achieves higher speedups across various temperatures.", "section": "4.2 Ablations"}, {"figure_path": "rk2L9YGDi2/figures/figures_26_2.jpg", "caption": "Figure 8: Forward pass times for different model/hardware combinations as a function of the number of tokens n being processed. We use these values to choose the optimal tree. a higher ratio of bandwidth (between GPU HBM and SRAM) to FLOPS, because it is less memory bound).", "description": "This figure shows the forward pass time (in seconds) for different large language models (LLMs) and hardware configurations (A100 and L40 GPUs) as a function of the input length (number of tokens).  The plot helps in determining the optimal tree size for SEQUOIA's speculative decoding algorithm by considering the tradeoff between the time spent on the draft model and the time for verification on the target model. It highlights the importance of hardware-aware optimization.  As the input length increases, the forward pass time increases, particularly significantly for larger models and less memory-bound hardware. This is because the I/O cost of processing tokens becomes more significant with larger input lengths. The lines show that the growth rate is hardware dependent.", "section": "4.1 End-to-end Results"}]