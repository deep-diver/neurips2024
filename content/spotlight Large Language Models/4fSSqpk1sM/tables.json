[{"figure_path": "4fSSqpk1sM/tables/tables_4_1.jpg", "caption": "Table 1: Summary of our main results (described in Section 3).", "description": "This table summarizes the key findings of the paper regarding compute-optimal scaling laws for large language models.  It compares the scaling law exponent (a) obtained in this research with those reported by Hoffmann et al. [25] and Kaplan et al. [30], across different experiments and datasets.  The R\u00b2 values indicate the goodness of fit for the power-law models, and the p* range shows the span of optimal token-to-parameter ratios observed.", "section": "Main results: settling the scaling law discrepancy"}, {"figure_path": "4fSSqpk1sM/tables/tables_16_1.jpg", "caption": "Table 2: Model architectures and different parameter counts, in millions. The column N gives our definition of models size, Nexact is the exact number of trainable parameters in the model, Neff is the effective size which also accounts for the cost of attention operatoins, and NKaplan does not count parameters in the model's head. See Appendix B for precise definitions and discussion.", "description": "This table shows the model architectures used in the experiments, along with different ways to count the number of parameters in each model.  N represents the number of parameters in all the linear layers (excluding embeddings, but including the head). Nexact counts all trainable parameters. Neff accounts for the computational cost of attention operations. Finally, NKaplan excludes parameters from the model's head, as was done in the work by Kaplan et al. Appendix B provides a more detailed explanation of these variations and their implications.", "section": "2 Preliminaries and experiment design"}, {"figure_path": "4fSSqpk1sM/tables/tables_17_1.jpg", "caption": "Table 2: Model architectures and different parameter counts, in millions. The column N gives our definition of models size, Nexact is the exact number of trainable parameters in the model, Neff is the effective size which also accounts for the cost of attention operatoins, and NKaplan does not count parameters in the model's head. See Appendix B for precise definitions and discussion.", "description": "This table shows the different ways to calculate the number of parameters of the language models used in the experiments.  It compares four different metrics for parameter count:\n\n* **N:** The number of parameters in all linear layers (excluding embeddings but including the final linear layer). This is the primary definition used in the paper for the model size.\n* **Nexact:** The exact number of trainable parameters in the model.\n* **Neff:**  An effective model size that also accounts for the computational cost of attention operations. \n* **NKaplan:** The parameter count that does not include the parameters in the model's head (final linear layer). This method is used by Kaplan et al. [30]\n\nThe table lists these counts for several model architectures that vary in depth and width. It provides the percentage differences between N and Nexact, N and Neff to demonstrate the magnitude of variations among the different parameter counting methods. More details on the different model size definitions and their implications are discussed in Appendix B.", "section": "2 Preliminaries and experiment design"}, {"figure_path": "4fSSqpk1sM/tables/tables_17_2.jpg", "caption": "Table 2: Model architectures and different parameter counts, in millions. The column N gives our definition of models size, Nexact is the exact number of trainable parameters in the model, Neff is the effective size which also accounts for the cost of attention operatoins, and NKaplan does not count parameters in the model's head. See Appendix B for precise definitions and discussion.", "description": "This table presents the model architectures used in the experiments, along with various measures of model size.  The column 'N' represents the primary model size definition used in the paper, based on the number of parameters in the linear layers (excluding embeddings but including the head). 'Nexact' gives the precise count of trainable parameters, 'Neff' includes the computational cost of attention operations, and 'NKaplan' excludes the parameters in the final (head) layer. Appendix B provides further details on these different definitions of model size and their implications for the results.", "section": "2 Preliminaries and experiment design"}, {"figure_path": "4fSSqpk1sM/tables/tables_23_1.jpg", "caption": "Table 2: Model architectures and different parameter counts, in millions. The column N gives our definition of models size, Nexact is the exact number of trainable parameters in the model, Neff is the effective size which also accounts for the cost of attention operatoins, and NKaplan does not count parameters in the model's head. See Appendix B for precise definitions and discussion.", "description": "This table shows the different ways to count the number of parameters of the model and their effect on the final results.  It compares four different metrics for measuring model size: N (the method used in the main paper), Nexact (the exact number of trainable parameters), Neff (the effective model size that accounts for both linear and attention layers), and NKaplan (the model size used by Kaplan et al. [30], that excludes embedding parameters and the model's head). The table also shows the percentage difference between N and Nexact, N and Neff, and N and NKaplan.  Appendix B provides a more detailed explanation of these metrics and their impact on the FLOP computation.", "section": "Preliminaries and experiment design"}, {"figure_path": "4fSSqpk1sM/tables/tables_23_2.jpg", "caption": "Table 2: Model architectures and different parameter counts, in millions. The column N gives our definition of models size, Nexact is the exact number of trainable parameters in the model, Neff is the effective size which also accounts for the cost of attention operatoins, and NKaplan does not count parameters in the model's head. See Appendix B for precise definitions and discussion.", "description": "This table presents the different model architectures used in the experiments, along with various ways to calculate the number of parameters.  N is the primary measure of model size used in the paper, excluding embedding layers, but including the final output layer (the head).  Nexact includes all trainable parameters. Neff accounts for the computational cost of the attention mechanism. NKaplan excludes parameters in the head. The table shows how these values vary across different model sizes and depths and also indicates the relative percentage difference between N and these alternative metrics.", "section": "2 Preliminaries and experiment design"}, {"figure_path": "4fSSqpk1sM/tables/tables_26_1.jpg", "caption": "Table 2: Model architectures and different parameter counts, in millions. The column N gives our definition of models size, Nexact is the exact number of trainable parameters in the model, Neff is the effective size which also accounts for the cost of attention operatoins, and NKaplan does not count parameters in the model's head. See Appendix B for precise definitions and discussion.", "description": "This table presents a comparison of different ways to measure the size of language models.  It lists model architectures with varying depths and widths, and shows the number of parameters using three different methods:  N (the authors' definition of model size), Nexact (the exact number of trainable parameters), and NKaplan (which excludes parameters in the final layer). The table highlights the differences between these methods and explains their implications for computing the model's computational cost. Appendix B provides further details on how these different methods of measuring model size are defined and why the authors chose their preferred definition (N).", "section": "2 Preliminaries and experiment design"}]