[{"figure_path": "eezCLKwx6T/tables/tables_16_1.jpg", "caption": "Table 5: Partially observable navigation task results. The table shows the average solved rate and standard deviation over five independent runs, and each run is evaluated by 100 independent episodes for each test environment. All methods train the agent using LSTM-based PPO and evaluated after 250M environmental steps.", "description": "This table presents the zero-shot performance results of different reinforcement learning algorithms on twelve unseen test environments in a partially observable navigation task.  The results are averages over five independent runs, each consisting of 100 independent episodes per environment.  All algorithms used LSTM-based Proximal Policy Optimization (PPO) and were evaluated after 250 million environmental steps. The table provides a detailed comparison across different algorithms (DR, PAIRED, PLR+, ACCEL, ADD without guidance, and ADD) and their performance on each environment, allowing for a comprehensive evaluation of zero-shot generalization capabilities.", "section": "C.1 Partially Observable Navigation Task"}, {"figure_path": "eezCLKwx6T/tables/tables_17_1.jpg", "caption": "Table 1: Domain of the environment parameter for the 2D bipedal locomotion task.", "description": "This table shows the range of values for each of the eight environment parameters used in the 2D bipedal locomotion task.  These parameters control the difficulty of the terrain the robot must navigate. The parameters are: Stump Height, Stair Height, Pit Gap, Stair Steps, and Roughness.", "section": "B.2 2D Bipedal Locomotion Task"}, {"figure_path": "eezCLKwx6T/tables/tables_18_1.jpg", "caption": "Table 2: Hyperparameters used for training the RL agent in each task", "description": "This table lists the hyperparameters used for training the reinforcement learning (RL) agent in two different tasks: Minigrid and BipedalWalker.  The hyperparameters cover various aspects of the Proximal Policy Optimization (PPO) algorithm, such as the discount factor (\u03b3), the generalized advantage estimation (GAE) parameter (\u03bbGAE), rollout length, number of epochs, and more.  Differences between the two tasks are highlighted, reflecting the need for task-specific optimization strategies.", "section": "B.3 Hyperparameters"}, {"figure_path": "eezCLKwx6T/tables/tables_18_2.jpg", "caption": "Table 3: Hyperparameters used for training the diffusion-based environment generator", "description": "This table lists the hyperparameters used to train the diffusion-based environment generator for both the Minigrid and BipedalWalker tasks.  It includes parameters for the DDPM timestep, network architecture (UNet for Minigrid, MLP for BipedalWalker), hidden dimension, batch size, dropout rate, AdamW optimizer parameters (learning rate, weight decay, beta1, beta2), EMA rate, and the total number of training steps.", "section": "B.3 Hyperparameters"}, {"figure_path": "eezCLKwx6T/tables/tables_19_1.jpg", "caption": "Table 4: Hyperparameters used for the regret guidance and training the environment critic", "description": "This table lists the hyperparameters used in the regret-guided diffusion model and environment critic training for both the Minigrid and BipedalWalker tasks.  The hyperparameters control various aspects of the training process, including the number of denoising steps, the number of bins in the return distribution, the strength of the regret guidance, the risk level for CVaR, and the batch size and number of epochs used for training the environment critic.", "section": "B.3 Hyperparameters"}, {"figure_path": "eezCLKwx6T/tables/tables_20_1.jpg", "caption": "Table 5: Partially observable navigation task results. The table shows the average solved rate and standard deviation over five independent runs, and each run is evaluated by 100 independent episodes for each test environment. All methods train the agent using LSTM-based PPO and evaluated after 250M environmental steps.", "description": "This table presents the zero-shot generalization performance of different reinforcement learning algorithms on 12 unseen test environments in a partially observable navigation task.  The results, averaged over five independent runs with 100 episodes each, show the mean solved rate and standard deviation for each algorithm (DR, PAIRED, PLR+, ACCEL, ADD w/o guidance, and ADD).  It highlights the superior performance of ADD compared to the baselines.", "section": "C.1 Partially Observable Navigation Task"}, {"figure_path": "eezCLKwx6T/tables/tables_22_1.jpg", "caption": "Table 6: 2D bipedal locomotion task results. The table shows the average return and standard deviation over five independent runs, and each run is evaluated by 100 independent trials on each test environment. All methods train the agent using PPO and evaluated after two billion environmental steps.", "description": "This table presents the average return and standard deviation achieved by different reinforcement learning algorithms on six test environments in a 2D bipedal locomotion task. The algorithms are compared against a domain randomization baseline.  Each algorithm's performance is evaluated over five independent runs, with each run consisting of 100 trials on each test environment. All agents were trained using the Proximal Policy Optimization (PPO) algorithm for 2 billion environmental steps.", "section": "C.2 2D Bipedal Locomotion Task"}, {"figure_path": "eezCLKwx6T/tables/tables_25_1.jpg", "caption": "Table 7: Ablation study on the entropy regularization term. The table shows the zero-shot generalization performance in the partially observable navigation task in accordance to the entropy coefficient \u03c9. We measure the average success rate over five independent seeds.", "description": "This table presents the results of an ablation study conducted to evaluate the impact of the entropy regularization term (\u03c9) on the performance of the proposed ADD algorithm in the partially observable navigation task.  Different values of \u03c9 were tested, and the mean success rate (averaged across five independent seeds) was calculated for each. The table shows how the performance changes as the value of \u03c9 increases.", "section": "C.3 Ablation Study"}]