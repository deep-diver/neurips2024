[{"figure_path": "8KPyJm4gt5/tables/tables_4_1.jpg", "caption": "Table 1: Summary of upper bounds for deterministic experts; lower bounds are more nuanced, and discussed in Section 2.2. Each cell denotes the regret of a policy learned with log-loss behavior cloning (LogLossBC), which is optimal in each setting. Here, \u03a0 is the policy class, R is the reward range, H is the horizon, and n is the number of expert trajectories. In the dense-reward setting, we set R = H.", "description": "This table summarizes upper bounds on the regret of LogLossBC for deterministic expert policies, categorized by parameter sharing (yes/no) and reward density (sparse/dense).  It highlights that under parameter sharing, the horizon dependence can be linear (dense rewards) or independent (sparse rewards).  Without parameter sharing, quadratic dependence on the horizon is generally unavoidable, emphasizing the benefits of parameter sharing for efficient offline imitation learning.", "section": "Deterministic policies: Closing the gap between offline and online IL"}, {"figure_path": "8KPyJm4gt5/tables/tables_17_1.jpg", "caption": "Table 2: Summary of upper bounds for stochastic experts (Corollary 3.1). Each cell denotes the expected regret of a policy learned with LogLossBC; lower bounds are more nuanced and discussed in Section 3. Here \u03a0 is the policy class, R is the cumulative reward range, H is the horizon, n is the number of expert trajectories, \u03c3\u00b2 is the variance of the expert policy, and \u03bc\u0303 is the signed recoverability parameter; see Section 3 for definitions.", "description": "This table summarizes the upper bounds on the expected regret for stochastic experts when using the LogLossBC algorithm. It breaks down the bounds based on different reward settings (sparse and dense) and levels of recoverability (\u03bc\u0303-recoverable).  The table highlights the dependence of regret on the horizon (H), the number of expert trajectories (n), and other factors like policy class complexity (\u03a0) and reward range (R). Note that the lower bounds are more complex and described in the corresponding section of the paper.", "section": "Horizon-Independent Analysis of Log-Loss Behavior Cloning"}]