[{"figure_path": "PGOuBHYdbr/figures/figures_8_1.jpg", "caption": "(a) Average regret over time (b) Average final regret as a function of m", "description": "The figure shows two plots: (a) displays the average cumulative regret over time for four algorithms (B-CTS-Jeffreys, B-CTS-Uniform, ESCB, and BG-CTS) in a combinatorial bandit problem with a time horizon of T = 2 \u00d7 104 and m = 50. The plot includes error bars representing two standard deviations. (b) displays the average final regret as a function of the number of items (m) for the same four algorithms, with a time horizon of T = 1 \u00d7 104 and m varying from 5 to 65. The plot illustrates the polynomial relationship between regret and m for BG-CTS and ESCB, while B-CTS-Jeffreys and B-CTS-Uniform show exponential growth.", "section": "Numerical experiments"}, {"figure_path": "PGOuBHYdbr/figures/figures_8_2.jpg", "caption": "Figure 1(b): Average final regret as a function of m", "description": "The figure shows the average final regret of four algorithms (B-CTS-Jeffreys, B-CTS-Uniform, ESCB, and BG-CTS) as a function of the number of arms (m).  The x-axis represents the number of arms (m), ranging from approximately 5 to 65. The y-axis represents the average final regret on a logarithmic scale. The plot reveals that the regret of B-CTS-Jeffreys and B-CTS-Uniform increases exponentially with m, while ESCB and BG-CTS exhibit much lower regret, demonstrating the effectiveness of these algorithms when the number of arms increases.", "section": "Numerical experiments"}, {"figure_path": "PGOuBHYdbr/figures/figures_14_1.jpg", "caption": "Figure 2: Diagram of the proof of the main result", "description": "This figure is a flowchart that illustrates the main steps of the proof for the regret upper bound of the BG-CTS algorithm. It breaks down the proof into different events and lemmas, showing how the probability of each event and the corresponding regret are bounded.  The flowchart starts by considering a clean run, which happens with high probability, and then analyses the regret based on whether the algorithm sampled the optimal action enough times, and how much the Thompson samples deviate from the expected rewards. The diagram visually depicts the logical flow of the proof and how different parts contribute to the overall regret bound.", "section": "5 Regret Analysis"}]