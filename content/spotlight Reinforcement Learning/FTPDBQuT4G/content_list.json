[{"type": "text", "text": "Generalized Linear Bandits with Limited Adaptivity ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Ayush Sawarni\u2217 Stanford University ayushsaw@stanford.edu ", "page_idx": 0}, {"type": "text", "text": "Nirjhar Das\u2020 Indian Institute of Science Bangalore nirjhardas@iisc.ac.in ", "page_idx": 0}, {"type": "text", "text": "Siddharth Barman Indian Institute of Science Bangalore barman@iisc.ac.in ", "page_idx": 0}, {"type": "text", "text": "Gaurav Sinha Microsoft Research India gauravsinha@microsoft.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study the generalized linear contextual bandit problem within the constraints of limited adaptivity. In this paper, we present two algorithms, B-GLinCB and RS-GLinCB, that address, respectively, two prevalent limited adaptivity settings. Given a budget $M$ on the number of policy updates, in the first setting, the algorithm needs to decide upfront $M$ rounds at which it will update its policy, while in the second setting it can adaptively perform $M$ policy updates during its c\u221aourse. For the first setting, we design an algorithm B-GLinCB, that incurs $\\tilde{O}(\\sqrt{T})$ regret when $M=\\Omega\\,(\\log\\log T)$ and the arm feature vectors are generated stochastically. For the second setting, we design an algorith\u221am RS-GLinCB that updates its policy $\\tilde{O}(\\log^{2}T)$ times and achieves a regret of $\\tilde{O}(\\sqrt{T})$ even when the arm feature vectors are adversarially generated. Notably, in these bounds, we manage to eliminate the dependence on a key instance dependent parameter $\\kappa$ , that captures non-linearity of the underlying reward model. Our novel approach for removing this dependence for generalized linear contextual bandits might be of independent interest. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Contextual Bandits (CB) is an archetypal framework that models sequential decision making in time-varying environments. In this framework, the algorithm (decision maker) is presented, in each round, with a set of arms (represented as $d$ -dimensional feature vectors), and it needs to decide which arm to play. Once an arm is played, a reward corresponding to the played arm is accrued. The regret of the round is defined as the difference between the maximum reward possible in that round and the reward of the played arm. The goal is to design a policy for selecting arms that minimizes cumulative regret (referred to as the regret of the algorithm) over a specified number of rounds, $T$ . In the last few decades, much progress has been made in designing algorithms for special classes of reward models, e.g. linear model [3, 4, 1, 16], logistic model [6, 2, 7, 28] and generalized linear models [8, 19]. ", "page_idx": 0}, {"type": "text", "text": "However, despite this progress, there is a key challenge that prevents deployment of CB algorithms in the real world. Practical situations often allow for very limited adaptivity, i.e., do not allow CB algorithms to update their policy at all rounds. For example, in clinical trials [10], each trial involves administering medical treatments to a cohort of patients, with medical outcomes observed and collected for the entire cohort at the conclusion of the trial. This data is then used to design the treatment for the next phase of the trial. Similarly, in online advertising [25] and recommendations [18], updating the policy after every iteration during deployment is often infeasible due to infrastructural constraints. A recent line of work [23, 22, 11, 12, 21, 9, 26] tries to address this limitation by developing algorithms that try to minimize cumulative regret while ensuring that only a limited number of policy updates occur. Across these works, two settings (called M1 and M2 from here onwards) of limited adaptivity have been popular. Both M1, M2 provide a budget $M$ to the algorithm, determining the number of times it can update its policy. In M1 [23, 13], the algorithm is required to decide upfront a sub-sequence of $M$ rounds where policy updates will occur. While in M2 [1, 23]), the algorithm is allowed to adaptively decide (during its course) when to update its policy. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Limited adaptivity algorithms were recently proposed for the CB problem with linear reward models under the M1 setting [23, 11], and optimal regret guarantees were obtained when the arm feature vectors were stochastically generated. Similarly, in their seminal work on linear bandits, [1] developed algorithms for the M2 setting and proved optimal regret guarantees with no restrictions on the arm vectors. While these results provide tight regret guarantees for linear reward models, extending them to generalized linear models is quite a challenge. Straightforward extensions lead to sub-optimal regret with a significantly worse dependence on an instance dependent parameter $\\kappa$ (See Section 2 for definition) that captures non-linearity of the problem instance. In fact, to the best of our knowledge, developing optimal algorithms for the CB problem with generalized linear reward models under the limited adaptivity settings M1, M2, is an open research question. This is the main focus of our work. We make the following contributions. ", "page_idx": 1}, {"type": "text", "text": "1.1 Our Contributions ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "\u2022 We propose B-GLinCB, an algorithm that solves the CB problem for bounded (almost surely) generalized linear reward models (Definition 2.1) under the M1 setting of limited adaptivity. We prove that, when the arm fe\u221aature vectors are generated stochastically, the regret of B-GLinCB at the end of $T$ rounds is $\\tilde{O}(\\sqrt{T})$ , when $M\\,=\\,\\Omega(\\log\\log T)$ . When $M\\,=\\,O(\\log\\log T)$ , we prove an $\\tilde{O}({T^{2}}^{M-1}/({2^{M}}\\!-\\!2))$ regret guarantee. While the algorithm bears a slight resemblance to the one in [23], direct utilization of their key techniques (distributional optimal design) results in a regret guarantee that scales linearly with the instance dependent non-linearity $\\kappa$ . On the other hand, the leading terms in our regret guarantee for B-GLinCB have no dependence on $\\kappa$ . To achieve this, we make novel modifications to the key technique of distributional optimal design in [23]. Along with this, the rounds for policy updates are also chosen more carefully (in a $\\kappa$ dependent fashion), leading to a stronger regret guarantee. ", "page_idx": 1}, {"type": "text", "text": "\u2022 We propose RS-GLinCB, an algorithm that solves the CB problem for bounded (almost surely) generalized linear reward models (Definition 2.1) under the M2 setting of limited adaptivity. RS-GLinCB builds on a similar algorithm in [1] by adding a novel context-dependent criterion for determini\u221ang if a policy update is needed. This new criterion allows us to prove optimal regret guarantee $(\\tilde{O}(\\sqrt{T}))$ with only $O(\\log^{2}T)$ updates to the policy. It is quite crucial for the generalized linear reward settings since, without it, the resultant regret guarantees have a linear dependence \u221aon $\\kappa$ . ", "page_idx": 1}, {"type": "text", "text": "\u2022 Our work also resolves a conjecture in [17] by proving an optimal $(\\tilde{O}(\\sqrt{T}))$ regret guarantee (for the CB problem with logistic reward model) that does not depend polynomially on $S$ (the known upper bound on the size of the model parameters, i.e. $\\lVert\\theta^{\\star}\\rVert\\leq S$ , See Section 2) 3. RS-GLinCB is, to our knowledge, the first CB algorithm for generalized linear reward models that is both computationally efficient (amortized ${\\cal O}(\\log T)$ computation per round) and incurs optimal regret. We also perform experiments in Section 5 that validate its superiority both in terms of regret and computational efficiency in comparison to other baseline algorithms proposed in [14] and [6]. ", "page_idx": 1}, {"type": "text", "text": "1.2 Important Remarks on Contributions and Comparison with Prior Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Remark 1.1 ( $\\kappa$ -independence). For both B-GLinCB and RS-GLinCB, our regret guarantees are free of $\\kappa$ (in their leading term), an instance-dependent parameter that can be exponential in the size of the unknown parameter vector, i.e., $\\lVert\\theta^{\\star}\\rVert$ (See Section 2 for definition). Our contribution in this regard is two-fold. Not only do we prove $\\kappa$ -independent regret guarantees under the limited adaptivity constraint, we also characterize a broad class of generalized linear reward models for which a $\\kappa$ -independent regret guarantee can be achieved. Specifically, our results imply that the CB problem with generalized linear reward models originally proposed in [8] and subsequently studied in literature [19, 14, 24] admits a $\\kappa$ -independent regret. ", "page_idx": 1}, {"type": "text", "text": "Remark 1.2 (Computational efficiency). Efforts to reduce the total time complexity to be linear in $T$ have been active in the CB literature with generealized linear rewards models. For e.g., [14] recently devised computationally efficient algorithms but they suffer from regret dependence on $\\kappa$ . Optimal $\\kappa$ -independent) guarantees were recently achieved for logistic reward models [6, 2], and the algorithms were subsequently made computationally efficient in [7, 28]. However, the techniques involved rely heavily on the structure of the logistic model and do not easily extend to more general models. To the best of our knowledge, ours is the first work that achieves optimal $\\kappa$ -independent regret guarantees for bounded generalized linear reward models while remaining computationally efficient4. ", "page_idx": 2}, {"type": "text", "text": "Remark 1.3 (Self Concordance of bounded GLMs). In order to prove $\\kappa$ -independent regret guarantees, we prove a key result about self concordance of bounded (almost surely) generalized linear models (Definition 2.1) in Lemma 2.2. This result was postulated in [8] for GLMs (with the same definition as ours), but no proof was provided. While [6, 7] partially tackled this issue for logistic reward models5, in our work, we prove self concordance for much more general generalized linear models. ", "page_idx": 2}, {"type": "text", "text": "2 Notations and Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Notations: A policy $\\pi$ is a function that maps any given arm set $\\mathcal{X}$ to a probability distribution over the same set, i.e., $\\dot{\\pi}(\\boldsymbol{\\mathcal{X}})\\in\\Delta(\\boldsymbol{\\mathcal{X}})$ , where $\\Delta(\\mathcal{X})$ is the probability simplex supported on $\\mathcal{X}$ . We will denote mat\u221arices in bold upper case (e.g. M). $\\|x\\|$ denotes the $\\ell_{2}$ norm of vector $x$ . We write $\\|{\\boldsymbol{x}}\\|_{\\mathbf{M}}$ to denote $\\sqrt{x^{\\top}\\mathbf{M}x}$ for a positive semi-definite matrix $\\mathbf{M}$ and vector $x$ . For any two real numbers $a$ and $b$ , we denote by $a\\wedge b$ the minimum of $a$ and $b$ . Throughout, $\\widetilde O(\\cdot)$ denotes big-O notation but suppresses log factors in all relevant parameters. For $m,n\\in\\mathbb{N}$ w ith $m<n$ , we denote the set $\\{1,\\ldots,n\\}$ by $[n]$ and $\\{m,\\ldots,n\\}$ by $[m,n]$ . ", "page_idx": 2}, {"type": "text", "text": "Definition 2.1 (GLM). A Generalized Linear Model or GLM with parameter vector $\\theta^{\\star}\\in\\mathbb{R}^{d}$ is a real valued random variable $r$ that belongs to the exponential family with density function ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{P}(r\\mid x)=\\exp\\left(r\\cdot\\left\\langle x,\\theta^{*}\\right\\rangle-b\\left(\\left\\langle x,\\theta^{*}\\right\\rangle\\right)+c\\left(r\\right)\\right)\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Function $b$ (called the log-partition function) is assumed to be twice differentiable and $\\dot{b}$ is assumed to be monotone. Further, we assume that $r\\in[0,R]$ almost surely for some known $R\\in\\mathbb{R}$ . ", "page_idx": 2}, {"type": "text", "text": "Important properties of GLMs such as $\\mathbb{E}[r\\mid x]=\\dot{b}(\\langle x,\\theta^{\\star}\\rangle)$ and variance $\\mathbb{V}[r\\mid x]=\\ddot{b}(\\langle x,\\theta^{\\star}\\rangle)$ are detailed in Appendix C. We define the link function $\\mu$ as $\\bar{\\mu}\\,\\big(\\langle x,\\theta^{*}\\rangle\\big):=\\mathbb{E}[\\bar{r}\\mid x]$ . Thus, $\\mu$ is also monotone. We now present a key Lemma on GLMs (see Appendix $\\mathbf{C}$ for details) that enable us to achieve optimal regret guarantees for our algorithms designed in Sections 3 and 4. ", "page_idx": 2}, {"type": "text", "text": "Lemma 2.2 (Self-Concordance of GLMs). For any GLM supported on $[0,R]$ almost surely, the link function $\\mu(\\cdot)$ satisfies $|\\ddot{\\mu}(z)|\\leq R\\dot{\\mu}(z)$ , for all $z\\in\\mathbb R$ . ", "page_idx": 2}, {"type": "text", "text": "Next we describe the two CB problems with GLM rewards that we address in this paper. Let $T\\in\\mathbb N$ be the total number of rounds. At round $t\\in[T]$ , we receive an arm set $\\mathcal{X}_{t}\\subset\\mathbb{R}^{d}$ , with number of arms $K=|\\mathcal{X}_{t}|$ and must select an arm $x_{t}\\in\\mathscr{X}_{t}$ . Following this, we receive a reward $r_{t}$ sampled from the GLM distribution $\\mathbb{P}(r|x_{t})$ with unknown $\\theta^{*}$ . ", "page_idx": 2}, {"type": "text", "text": "Problem 1: In this problem we assume that at each round $t$ , the set of arms $\\mathcal{X}_{t}\\subset\\mathbb{R}^{d}$ is drawn from an unknown distribution $\\mathcal{D}$ . Further, we assume the constraints of limited adaptivity setting M1, i.e., the algorithm is given a budget $M\\in\\mathbb{N}$ and needs to decide upfront the $M$ rounds at which it will update its policy. Let supp $(\\mathcal{D})$ denote the support of distribution $\\mathcal{D}$ . We want to design an algorithm that minimizes the expected cumulative regret given as ", "page_idx": 2}, {"type": "equation", "text": "$$\n{\\bf R}_{T}=\\mathbb{E}\\,\\big[\\sum_{t=1}^{T}\\operatorname*{max}_{x\\in\\mathcal{X}_{t}}\\mu\\left(\\langle x,\\theta^{*}\\rangle\\right)\\;-\\;\\sum_{t=1}^{T}\\mu\\left(\\langle x_{t},\\theta^{*}\\rangle\\right)\\big]\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Here, the expectation is taken over the randomness of the algorithm, the distribution of rewards $r_{t}$ , and the distribution of the arm set $\\mathcal{D}$ . ", "page_idx": 3}, {"type": "text", "text": "Problem 2: In this problem we do not make any assumptions on the arm feature vectors, i.e., the arm vectors can be adversarially chosen. However, we assume the constraints of limited adaptivity setting M2, i.e., the algorithm is given a budget $M\\in\\mathbb{N}$ and needs to adaptively decide the $M$ rounds at which it will update its policy (during its course). We want to design an algorithm that minimizes the cumulative regret given as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{R}_{T}=\\sum_{t=1}^{T}\\operatorname*{max}_{x\\in\\mathcal{X}_{t}}\\mu\\left(\\langle x,\\theta^{*}\\rangle\\right)\\ -\\ \\sum_{t=1}^{T}\\mu\\left(\\langle x_{t},\\theta^{*}\\rangle\\right)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "2.1 Instance Dependent Non-Linearity Parameters ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "As in prior works [6, 7], we define instance dependent parameters that capture non-linearity of the underlying instance and critically impact our algorithm design. The performance of Algorithm 1 (B-GLinCB) that solves Problem 1, can be quantified using three such parameters that are defined using the derivative of the link function ${\\dot{\\mu}}(\\cdot)$ . Specifically, for any arm set $\\mathcal{X}$ , write optimal arm $x^{*}=\\arg\\operatorname*{max}_{x\\in\\mathcal{X}}\\mu\\left(\\langle x,\\theta^{*}\\rangle\\right)$ and define, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\kappa:=\\operatorname*{max}_{\\boldsymbol x\\in\\mathrm{supp}(\\mathcal{D})}\\operatorname*{max}_{\\boldsymbol x\\in\\mathcal{X}}\\,\\frac{1}{\\dot{\\mu}\\left(\\langle\\boldsymbol x,\\boldsymbol{\\theta}^{*}\\rangle\\right)},\\quad\\frac{1}{\\kappa^{*}}:=\\operatorname*{max}_{\\boldsymbol x\\in\\mathrm{supp}(\\mathcal{D})}\\,\\dot{\\mu}\\left(\\langle\\boldsymbol x^{*},\\boldsymbol{\\theta}^{*}\\rangle\\right),\\quad\\frac{1}{\\hat{\\kappa}}:=\\operatorname*{l}_{\\boldsymbol x\\sim\\mathcal{D}}\\left[\\dot{\\mu}\\left(\\langle\\boldsymbol x^{*},\\boldsymbol{\\theta}^{*}\\rangle\\right)\\right]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Remark 2.3. These quantities feature prominently in our regret analysis of Algorithm 1. In particular, the dominant term in our regret bound scales as $O(\\sqrt{T/\\kappa^{*}})$ . We also note that $\\widehat{\\kappa}\\geq\\kappa^{*}$ ; in fact, for specific distributions $\\mathcal{D}$ , the gap between them can be significant. Hence, we also provide a regret upper bound of $O(\\sqrt{T/\\widehat{\\kappa}})$ . In this latter case, however, we incur a worse dependence on $d$ . Section 3 provides a quantified form of this trade-off. ", "page_idx": 3}, {"type": "text", "text": "Algorithm 2 (RS-GLinCB) that solves Problem 2, requires another such non-linearity parameter $\\kappa^{6}$ , defined as, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\kappa:=\\operatorname*{max}_{x\\in\\cup_{t=1}^{T}\\mathcal{X}_{t}}\\frac{1}{\\dot{\\mu}\\left(\\left<x,\\theta^{*}\\right>\\right)}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We note that, here, $\\kappa$ is defined considering the parameter vector $\\theta^{*}$ in contrast to prior work on logistic bandits [7], where its definition involved a maximization over all vectors $\\theta$ with $\\|\\theta\\|\\leq S$ (known upper bound of $\\lVert\\theta^{\\star}\\rVert_{,}$ ). Hence, our definition of $\\kappa$ is potentially much smaller and can lead to lower regret, compared to prior works. Standard to the CB literature with GLM rewards, we will assume that tight upper bounds on these parameters is known to the algorithms. ", "page_idx": 3}, {"type": "text", "text": "Assumption 2.4. We make the following additional assumptions which are standard for the CB problem with linear or GLM reward models. ", "page_idx": 3}, {"type": "text", "text": "\u2022 For every round $t\\in[T]$ , and each arm $x\\in\\mathcal{X}_{t}$ , $\\|x\\|\\leq1$ . ", "page_idx": 3}, {"type": "text", "text": "\u2022 Let $\\theta^{*}$ be the unknown parameter of the GLM reward, then $\\lVert\\theta^{*}\\rVert\\leq S$ for a known constant $S$ . ", "page_idx": 3}, {"type": "text", "text": "2.2 Optimal Design Policies ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "G-optimal Design Given an arm set $\\mathcal{X}$ , the G-OPTIMAL DESIGN policy $\\pi_{G}$ is the solution of the following optimization problem: $\\begin{array}{r}{\\arg\\operatorname*{min}_{\\lambda\\in\\Delta(\\mathcal{X})}\\operatorname*{max}_{x\\in\\mathcal{X}}\\left||x|\\right|_{\\mathbf{U}(\\lambda)^{-1}}^{2}}\\end{array}$ , where $\\mathbf{U}(\\lambda)=\\mathbb{E}_{x\\sim\\lambda}[x x^{\\mathsf{T}}]$ . Now consider the following optimization problem, also known as the D-optimal design problem: $\\begin{array}{r}{\\operatorname*{max}_{\\lambda\\in\\Delta(\\mathcal{X})}\\log\\mathsf{D e t}(\\mathbf{U}(\\lambda))}\\end{array}$ . This is a concave maximization problem as opposed to the G-optimal design which is non-convex. We have the following equivalence theorem due to Kiefer and Wolfowitz [15]: ", "page_idx": 3}, {"type": "text", "text": "Lemma 2.5 (Keifer-Wolfowitz). Let $\\mathcal{X}\\subset\\mathbb{R}^{d}$ be any set of arms and $\\mathbf{W}_{G}$ be the expected design matrix, defined as $\\mathbf{W}_{G}:=\\mathbb{E}_{x\\sim\\pi_{G}(x)}\\left[x x^{\\mathsf{T}}\\right]$ , with $\\pi_{G}(\\mathcal{X})$ as the solution to the $D$ -optimal design problem. Then, $\\pi_{G}(\\mathcal{X})$ also solves the $G$ -optimal design problem, and for all $x\\in\\mathcal{X}$ , $\\|\\boldsymbol{x}\\|_{\\mathbf{W}_{G}^{-1}}^{2}\\leq d.$ . ", "page_idx": 3}, {"type": "text", "text": "Distributional optimal design Notably, the upper bound on $\\|\\boldsymbol x\\|_{\\mathbf{W}_{G}^{-1}}$ specified in Lemma 2.5 holds only for the arms $x$ in $\\mathcal{X}$ . When the arm set $\\mathbf{\\boldsymbol{\\mathcal{X}}}_{t}$ varies from round to round, securing a guarantee analogous to Lemma 2.5 is generally challenging. Nonetheless, when the arm sets $\\mathbf{\\mathcal{X}}_{t}$ are drawn from a distribution, it is possible to extend the guarantee, albeit with a worse dependence on $d$ ; see Section A.5 in Appendix A. Improving this dependence motivates the need of studying DISTRIBUTIONAL OPTIMAL DESIGN and towards this we utilize the results of [23]. ", "page_idx": 4}, {"type": "text", "text": "The distributional design policy is defined using a collection of tuples $\\mathcal{M}=\\{(p_{i},\\mathbf{M}_{i}):p_{1},\\ldots,p_{n}\\geq$ 0 and $\\textstyle\\sum_{i}p_{i}=1\\}$ , wherein each $\\mathbf{M}_{i}$ is a $d\\times d$ positive semi-definite matrix and $n\\leq4d\\log d$ . The collec tion $\\mathcal{M}$ is detailed next. Let softmax\u03b1 $\\left(\\left[\\boldsymbol{s}_{1},\\ldots,\\boldsymbol{s}_{k}\\right]\\right)$ denote the probability distribution where the $i^{t h}$ element is sampled with probability $\\frac{s_{i}^{\\alpha}}{\\sum_{j=1}^{k}s_{j}^{\\alpha}}$ . For a specific $\\mathcal{M}=\\{(p_{i},\\mathbf{M}_{i})\\}_{i=1}^{n}$ , and each $i\\;\\in\\;[n]$ write $\\pi_{\\mathbf{M}_{i}}\\left(\\boldsymbol{\\mathcal{X}}\\right)\\,=\\,\\mathrm{softmax}_{\\boldsymbol{\\alpha}}\\bigl(\\bigl\\{\\left\\|\\boldsymbol{x}\\right\\|_{\\mathbf{M}_{i}}^{2}:\\,\\boldsymbol{x}\\,\\in\\,\\boldsymbol{\\mathcal{X}}\\bigr\\}$ ). Finally, with $\\pi_{G}$ as the G-OPTIMAL DESIGN policy (Section 2.2), we define the DISTRIBUTIONAL OPTIMAL DESIGN policy $\\pi$ as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\pi\\left(\\boldsymbol{\\mathcal{X}}\\right)=\\left\\{\\pi_{G}\\left(\\boldsymbol{\\mathcal{X}}\\right)\\quad\\begin{array}{l}{\\mathrm{with\\;probability\\;1/2}}\\\\ {\\mathrm{with\\;probability\\;}p_{i}/2}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Given a collection of arm sets $\\{\\mathcal{X}_{1},\\...\\,,\\mathcal{X}_{s}\\}$ (called core set) sampled from the distribution $\\mathcal{D}$ , we utilize Algorithm 2 of [23] to find the collection $\\mathcal{M}$ ; see Algorithm 4 of [23]. Overall, the computed $\\mathcal{M}$ induces a policy $\\pi$ that upholds the following guarantee. ", "page_idx": 4}, {"type": "text", "text": "Lemma 2.6 (Theorem 5, [23]). Let \u03c0 be the DISTRIBUTIONAL OPTIMAL DESIGN policy that has been learnt from s independent samples $\\mathcal{X}_{1},\\ldots\\mathcal{X}_{s}\\sim\\mathcal{D}$ . Also, let W denote the expected design matrix, $\\mathbf{W}\\stackrel{\\cdot}{=}\\mathbb{E}_{\\mathcal{X}\\sim\\mathcal{D}}\\left[\\mathbb{E}_{\\boldsymbol{x}\\sim\\pi(\\mathcal{X})}\\left[\\boldsymbol{x}\\boldsymbol{x}^{\\intercal}\\mid\\mathcal{X}\\right]\\right]$ . Then, ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left\\{\\underset{x\\sim\\mathcal{D}}{\\mathbb{E}}\\left[\\underset{x\\in\\mathcal{X}}{\\operatorname*{max}}\\;\\|x\\|_{\\mathbf{W}^{-1}}\\right]\\leq O\\left(\\sqrt{d\\log d}\\right)\\right\\}\\geq1-\\exp\\left(O\\left(d^{4}\\log^{2}d\\right)-s d^{-12}\\cdot2^{-16}\\right).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "3 B-GLinCB ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we present B-GLinCB (Algorithm 1) that solves Problem 1 described in Section 2, which enforces constraints of limited adaptivity setting M1. Given limited adaptivity budget $M\\in\\mathbb{N}$ , our algorithm first computes the batch length for each of the $M$ batches (i.e., rounds where the policy remains constant). We build upon the batch length construction in [9]; however, the first batch is chosen to be $\\kappa$ dependent which crucially helps in removing $\\kappa$ from the leading term in the regret. 7 ", "page_idx": 4}, {"type": "text", "text": "Batch Lengths: For each batch $k\\in[M]$ , let $\\mathcal{T}_{k}$ denote all the consecutive rounds within the $k^{t h}$ batch. We will refer to the first batch $\\mathcal{T}_{1}$ as the warm-up batch. The batch lengths $\\tau_{k}:=|\\mathcal{T}_{k}|$ , $k\\in[M]$ are calculated as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\tau_{1}:=\\left(\\frac{\\sqrt{\\kappa}\\;e^{3S}d^{2}\\gamma^{2}}{S}\\alpha\\right)^{2/3},\\;\\;\\;\\tau_{2}:=\\alpha,\\;\\;\\;\\tau_{k}:=\\alpha\\sqrt{\\tau_{k-1}},\\;\\mathrm{for}\\;k\\in[3,M]\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\gamma:=30R S\\sqrt{d\\log T}\\,^{8}$ and \u03b1 = T2(1\u22122\u2212M+1) if $M\\leq\\log\\log T$ and $\\alpha=2\\sqrt{T}$ otherwise. ", "page_idx": 4}, {"type": "text", "text": "During the warm-up batch (Lines 2, 3), the algorithm follows the G-OPTIMAL DESIGN policy, $\\pi_{G}$ . At the end of the warm-up batch (Line 4), the algorithm computes the Maximum Likelihood Estimate (MLE), $\\widehat{\\theta}_{w}$ , of $\\theta^{*9}$ , and design matrix $\\begin{array}{r}{\\mathbf{V}:=\\sum_{t\\in\\mathcal{T}_{1}}x_{t}x_{t}^{\\mathsf{T}}+\\lambda\\mathbf{I}}\\end{array}$ , with parameter $\\lambda=20R d\\log T$ . ", "page_idx": 4}, {"type": "text", "text": "Now, for each batch $k\\geq2$ and every round $t\\in T_{k}$ , the algorithm updates $\\scriptstyle{\\mathcal{X}}_{t}$ by eliminating arms from it using the confidence bounds (see Equation (7)) computed in the previous batches (Line 10). The algorithm next computes $\\widetilde{\\mathcal{X}}_{t}$ , a scaled version of $\\scriptstyle{\\mathcal{X}}_{t}$ , as follows, with $\\beta(x)$ is same as in (5), ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\widetilde{\\mathcal{X}}_{t}:=\\left\\{\\sqrt{\\dot{\\mu}(\\langle x,\\widehat{\\theta}_{w}\\rangle)/\\beta(x)}\\quad x:\\ \\mathrm{for\\,all}\\ x\\in\\mathcal{X}_{t}\\right\\}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Finally, we use the distributional optimal design policy $\\pi_{k}$ , on the scaled arm set $\\widetilde{\\mathcal X}_{t}$ , to sample the next arm (Line 11). At the end of every batch, we equally divide the batch $\\mathcal{T}_{k}$ into two sets $\\boldsymbol{\\mathcal{A}}$ ", "page_idx": 4}, {"type": "text", "text": "Algorithm 1 B-GLinCB: Batched Generalized Linear Bandits Algorithm ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Input: Number of batches $M$ and horizon of play $T$ .   \n1: Initialize batches $\\mathcal{T}_{1},\\dots,\\mathcal{T}_{M}$ , as defined in equation (3), and set $\\lambda:=20R d\\log T$ .   \n2: for rounds $t\\in\\mathcal T_{1}$ do   \n3: Observe arm set $\\mathbf{\\mathcal{X}}_{t}$ , sample arm $x_{t}\\sim\\pi_{G}(\\mathcal{X}_{t})$ , and observe reward $r_{t}$ .   \n4: Compute $\\begin{array}{r}{\\widehat{\\theta}_{w}=\\arg\\operatorname*{min}_{\\theta}\\sum_{s\\in\\mathcal{T}_{1}}\\ell(\\theta,x_{s},r_{s})}\\end{array}$ and matrix $\\begin{array}{r}{\\mathbf{V}=\\lambda\\mathbf{I}+\\sum_{t\\in\\mathcal{T}_{1}}x_{t}x_{t}^{\\mathsf{T}}}\\end{array}$ .   \n5: Initialize policy $\\pi_{1}$ as G-OPTIMAL DESIGN.   \n6: for batches $k=2$ to $M$ do   \n7: for each round $t\\in T_{k}$ do   \n8: Observe arm set $\\textstyle{\\mathcal{X}}_{t}$ .   \n9: for $j=1$ to $k-1$ do   \n10: Update arm set $\\mathcal{X}_{t}\\gets\\mathcal{X}_{t}\\setminus\\{x\\in\\mathcal{X}_{t}:U C B_{j}(x)<\\operatorname*{max}_{y\\in\\mathcal{X}_{t}}L C B_{j}(y)\\}.$ .   \n11: Scale $\\textstyle{\\mathcal{X}}_{t}$ , as in (4), to obtain $\\widetilde{\\boldsymbol{\\mathcal{X}}_{t}}.$ ., then sample $x_{t}\\sim\\pi_{k-1}\\left(\\widetilde{\\lambda_{t}}\\right)$ .   \n12: Equally divide $\\tau_{k}$ into two sets $\\boldsymbol{\\mathcal{A}}$ and $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ .   \n13: $\\begin{array}{r}{\\mathbf{H}_{k}=\\lambda\\mathbf{I}+\\sum_{t\\in\\mathcal{A}}\\frac{\\dot{\\mu}\\left(\\langle x,\\widehat{\\theta}_{w}\\rangle\\right)}{\\beta(x_{t})}x_{t}x_{t}^{\\sf T}}\\end{array}$ , and $\\begin{array}{r}{\\widehat{\\theta}_{k}=\\arg\\operatorname*{min}_{\\theta}\\sum_{s\\in\\mathcal{A}}\\ell(\\theta,x_{s},r_{s})}\\end{array}$ .   \n14: Compute DISTRIBUTIONAL OPTIMAL DESIGN policy $\\pi_{k}$ using the arm sets $\\{\\mathcal X_{t}\\}_{t\\in B}$ ", "page_idx": 5}, {"type": "text", "text": "and $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ . We use samples from $\\boldsymbol{\\mathcal{A}}$ to compute the estimator $\\widehat{\\theta}_{k}$ and the scaled design matrix $\\mathbf{H}_{k}$ . The rounds in $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ are used to compute $\\pi_{k+1}$ , the distributional o ptimal design policy for the next batch. It is important to note, while the policy $\\pi_{k}$ is utilized in each round (Line 11) to draw arms, it is updated (to $\\pi_{k+1}$ ) only at the end of the batch. Hence, conforming to setting M1, the algorithm updates the selection policy at $M$ rounds that were decided upfront. ", "page_idx": 5}, {"type": "text", "text": "Confidence Bounds: The scaled design matrix ${\\mathbf{H}}_{k}$ , an estimator of the Hessian, is computed at the end of each batch $k\\in2,\\dots,M$ (Line 13): ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbf{H}_{k}=\\sum_{t\\in A}\\left(\\dot{\\mu}(\\langle x_{t},\\widehat{\\theta}_{w}\\rangle)/\\beta(x_{t})\\right)x_{t}x_{t}^{\\mathsf{T}}+\\lambda\\mathbf{I},\\quad\\mathrm{where}\\quad\\beta(x)=\\exp\\left(R\\operatorname*{min}\\left\\{2S,\\gamma\\sqrt{\\kappa}\\left\\|x\\right\\|_{\\mathbf{V}^{-1}}\\right\\}\\right)\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\boldsymbol{\\mathcal{A}}$ is the first half of $\\mathcal{T}_{k}$ . Using this, we define the upper and lower confidence bounds $(U C B_{k}$ and $L C B_{k}$ ) computed at the end of batch $\\mathcal{T}_{k}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{U C B_{k}(x):=\\left\\{\\left\\langle x,\\widehat{\\theta}_{w}\\right\\rangle+\\gamma\\sqrt{\\kappa}\\left\\|x\\right\\|_{\\mathbf{V}^{-1}}\\right.\\ \\ k=1}\\\\ &{\\left.\\qquad\\qquad\\right\\rangle\\left\\langle x,\\widehat{\\theta}_{k}\\right\\rangle+\\gamma\\left\\|x\\right\\|_{\\mathbf{H}_{k}^{-1}}\\ \\ \\qquad k>1}\\\\ &{L C B_{k}(x):=\\left\\{\\left\\langle x,\\widehat{\\theta}_{w}\\right\\rangle-\\gamma\\sqrt{\\kappa}\\left\\|x\\right\\|_{\\mathbf{V}^{-1}}\\right.\\ \\ k=1}\\\\ &{\\left.\\qquad\\qquad\\right\\rangle\\left\\langle x,\\widehat{\\theta}_{k}\\right\\rangle-\\gamma\\left\\|x\\right\\|_{\\mathbf{H}_{k}^{-1}}\\qquad k>1}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Remark 3.1. The confidence bounds employed by the algorithm exhibit a significant distinction between the first batch and subsequent batches. While the first batch\u2019s bounds are influenced by the parameter $\\kappa$ , subsequent batches utilize $\\kappa$ -independent bounds. This difference arises from the use of the standard design matrix $\\mathbf{V}$ in the first batch and a scaled design matrix $\\mathbf{H}_{k}$ (equation 5) in later batches, leveraging the self-concordance property of GLM rewards to achieve $\\kappa$ -independence. Notably, the first batch\u2019s confidence bounds influence the scaling factor $\\beta(x)$ in later batches, creating a trade-off (addressed in the regret analysis in Appendix A) where an inaccurate estimate of $\\widehat{\\theta}_{w}$ can exponentially increase the scaling factor and confidence bounds. ", "page_idx": 5}, {"type": "text", "text": "In Theorem 3.2 and Corollary 3.3, we present our regret guarantee for B-GLinCB. Detailed proofs for both are provided in Appendix A. The computational efficiency of B-GLinCB is discussed in Appendix D. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.2. Algorithm $I\\ (B\\!-\\!G L\\,i n C B)$ incurs regret $\\mathbf{R}_{T}\\leq\\left(\\mathbf{R}_{1}+\\mathbf{R}_{2}\\right)\\log\\log T$ , where ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{R}_{1}=O\\left(R S d\\left(\\sqrt{\\frac{d}{\\widehat{\\kappa}}}\\wedge\\sqrt{\\frac{1}{\\kappa^{*}}}\\right)T^{\\frac{1}{2\\left(1-2^{1-M}\\right)}}\\log T\\right)\\,a n d}\\\\ &{\\mathsf{R}_{2}=O\\left(\\kappa^{1/3}d^{2}e^{2S}(R S\\log T)^{2/3}T^{\\frac{1}{3\\left(1-2^{1-M}\\right)}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "1: Initialize: $\\mathbf{V}=\\mathbf{H}_{1}=\\lambda\\mathbf{I}$ , $\\mathcal{T}_{o}=\\emptyset$ , $\\tau=1$ $=1,\\lambda:=d\\log(T/\\delta)/R^{2}$ and $\\begin{array}{r}{\\gamma:=25R S\\sqrt{d\\log\\left(\\frac{T}{\\delta}\\right)}}\\end{array}$ .   \n2: for rounds $t=1,\\dots,T$ do   \n3: Observe arm set $\\mathbf{\\mathcal{X}}_{t}$ .   \n4: if $\\mathrm{max}_{x\\in\\mathcal{X}_{t}}\\|x\\|_{\\mathbf{V}^{-1}}^{2}\\geq1/(\\gamma^{2}\\kappa R^{2})$ then // Switching Criterion I   \n5: Select $x_{t}=\\arg\\operatorname*{max}_{x\\in\\mathcal{X}_{t}}\\|x\\|_{\\mathbf{V}^{-1}}$ and observe reward $r_{t}$ .   \n6: Update $\\mathcal{T}_{o}\\gets\\mathcal{T}_{o}\\cup\\{t\\}$ , $\\dot{\\mathbf V}\\gets\\mathbf V+x_{t}x_{t}^{\\mathsf{T}}$ and $\\mathbf{H}_{t+1}\\leftarrow\\mathbf{H}_{t}$ .   \n7: Compute $\\begin{array}{r}{\\widehat{\\theta}_{o}=\\arg\\operatorname*{min}_{\\theta}\\sum_{s\\in\\mathcal{T}_{o}}\\ell(\\theta,x_{s},r_{s})+\\frac{\\lambda}{2}\\left\\|\\theta\\right\\|_{2}^{2}}\\end{array}$ .   \n8: else   \n9: if $\\operatorname*{det}(\\mathbf{H}_{t})>2\\operatorname*{det}(\\mathbf{H}_{\\tau})$ then // Switching Criterion II   \n10: Set $\\tau=t$ and $\\begin{array}{r}{\\widetilde{\\theta}\\leftarrow\\arg\\operatorname*{min}_{\\theta}\\sum_{s\\in[t-1]\\backslash\\mathcal{T}_{o}}\\ell(\\theta,x_{s},r_{s})+\\frac{\\lambda}{2}\\left\\|\\theta\\right\\|_{2}^{2}}\\end{array}$ and   \n11: $\\widehat{\\theta}_{\\tau}\\leftarrow\\mathtt{P r o j e c t}(\\widetilde{\\theta})$ .   \n12: Update $\\begin{array}{r}{\\mathcal{X}_{t}\\gets\\mathcal{X}_{t}\\setminus\\{x\\in\\mathcal{X}_{t}:U C B_{o}(x)<\\operatorname*{max}_{z\\in\\mathcal{X}_{t}}L C B_{o}(z)\\}.}\\end{array}$   \n13: Select $x_{t}=\\arg\\operatorname*{max}_{x\\in\\mathcal{X}_{t}}U C B(x,\\mathbf{H}_{\\tau},\\widehat{\\theta}_{\\tau})$ and observe reward $r_{t}$ .   \n14: Update Ht+1 \u2190Ht +\u00b5\u02d9(\u27e8xte,\u03b8 o\u27e9)x . ", "page_idx": 6}, {"type": "text", "text": "Corollary 3.3. When the number of batches $M\\geq\\log\\log T$ , Algorithm $^{\\,l}$ achieves a regret bound of ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathtt{R}_{T}\\leq\\widetilde{O}\\left(\\left(\\sqrt{\\frac{d}{\\widehat{\\kappa}}}\\wedge\\sqrt{\\frac{1}{\\kappa^{*}}}\\right)d R S\\sqrt{T}+d^{2}e^{2S}(S^{2}R^{2}\\kappa T)^{1/3}\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Remark 3.4. Scaling the arm set (as in (4)) for optimal design is a crucial aspect of our algorithm, allowing us to obtain tight estimates of $\\dot{\\mu}\\left(\\left\\langle x,\\theta^{*}\\right\\rangle\\right)$ (see Lemma A.10). This result relies on multiple novel ideas and techniques, including self-concordance for GLMs, matrix concentration, Bernsteintype concentration for the canonical exponential family (Lemma A.1), and application of distributional optimal design on scaled arm set. ", "page_idx": 6}, {"type": "text", "text": "Remark 3.5. The $\\kappa$ -dependent batch construction is a crucial feature of our algorithm, enabling effective estimation of $\\dot{\\mu}\\langle\\theta,x\\rangle$ at the end of the first batch. Since the first batch \u221aincurs regret linear in its length, achieving a $\\kappa$ -independent guarantee requires the first batch to be $o(\\sqrt{T})$ . We demonstrate that choosing $\\tau_{1}=O(T^{{\\frac{1}{3}}})$ is sufficient for this purpose (see Appendix A). ", "page_idx": 6}, {"type": "text", "text": "4 RS-GLinCB ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section we present RS-GLinCB (Algorithm 2) that solves Problem 2 described in Section 2, which enforces constraints of limited adaptivity setting M2. This algorithm incorporates a novel switching criterion (Line 4), extending the determinant-doubling approach of [1]. Additionally, we introduce an arm-elimination step (Line 12) to obtain tighter regret guarantees. Throughout this section, we set $\\lambda=d\\log(T/\\delta)/R^{2}$ and $\\gamma=25R S\\sqrt{d\\log\\left(T/\\delta\\right)}$ . ", "page_idx": 6}, {"type": "text", "text": "At round $t$ , on receiving an arm set $\\scriptstyle{\\mathcal{X}}_{t}$ , RS-GLinCB first checks the Switching Criterion I (Line 4). This criterion checks whether for any arm $x\\in\\mathcal{X}_{t}$ the quantity $\\Vert x\\Vert_{\\mathbf{V}-1}$ is greater than a carefully chosen $\\kappa$ -dependent threshold. Here $\\mathbf{V}$ is the design matrix corresponding to all arms that have been played in the rounds in $\\mathcal{T}_{o}$ ( $:=$ the set of rounds preceding round $t$ , where Switching Criterion I was triggered). Under this criterion the arm that maximizes $\\Vert x\\Vert_{\\mathbf{V}-1}$ is played (call this arm $x_{t}$ ) and the corresponding reward is obtained. Subsequently in Line 6, the set $\\mathcal{T}_{o}$ is updated to include $t$ ; the design matrix $\\mathbf{V}$ is updated as $\\mathbf{V}\\gets\\mathbf{V}+\\bar{x_{t}}x_{t}^{\\top}$ ; and the scaled design matrix $\\mathbf{H}_{t+1}$ is set to $\\mathbf{H}_{t}$ . The MLE is computed (Line 7) based on the data in the rounds in $\\mathcal{T}_{o}$ to obtain $\\widehat{\\theta}_{o}$ . ", "page_idx": 6}, {"type": "text", "text": "When Switching Criterion I is not triggered, the algorithm first checks (Line 9) the Switching Criterion II, that is whether the determinant of the scaled design matrix $\\mathbf{H}_{t}$ has become more than double of that of $\\mathbf{H}_{\\tau}$ (where $\\tau$ is the last round before $t$ when Switching Criterion $\\mathrm{II}$ was triggered). If Switching Criterion $\\mathrm{II}$ is triggered at round $t$ , then in Line 10, the algorithm sets $\\tau\\gets t$ and recomputes the MLE over all the past rounds except those in $\\mathcal{T}_{o}$ to obtain\u03b8 . Then\u03b8  is projected into an ellipsoid around $\\widehat{\\theta}_{o}$ to obtain the estimate $\\widehat{\\theta}_{\\tau}$ via the following optimization problem10, ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta}\\left\\|\\sum_{s\\in\\mathcal{T}_{o}}\\left(\\mu\\left(\\langle x_{s},\\theta\\rangle\\right)-\\mu(\\langle x_{s},\\widetilde{\\theta}\\rangle)\\right)x_{s}\\right\\|_{\\mathbf{H}(\\theta)}\\mathrm{s.t.}\\ \\left\\|\\theta-\\widehat{\\theta}_{o}\\right\\|_{\\mathbf{V}}\\leq\\gamma\\sqrt{\\kappa}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Here $\\begin{array}{r}{\\mathbf{H}(\\theta)\\;:=\\;\\sum_{s\\in{\\mathcal{T}}_{o}}\\dot{\\mu}\\left(\\langle x_{s},\\theta\\rangle\\right)x_{s}x_{s}^{\\mathsf{T}}}\\end{array}$ . After checking Switching Criterion $\\mathrm{II}$ , the algorithm performs an arm elimination step (Line 12) based on the parameter estimate $\\widehat{\\theta}_{o}$ as follows: for every arm $x\\ \\in\\ \\mathcal{X}_{t}$ , we compute $U C B_{o}(x)~=~\\langle x,\\widehat{\\theta}_{o}\\rangle\\ +\\,\\gamma\\sqrt{\\kappa}\\,\\|x\\|_{\\mathbf{V}^{-1}}$ and $L C B_{o}(x)~=~$ $\\langle x,\\widehat{\\theta_{o}}\\rangle\\,-\\,\\gamma\\sqrt{\\kappa}\\,\\|x\\|_{\\mathbf{V}^{-1}}{^1}\\mathrm{11}$ . Then, $\\mathbf{\\mathcal{X}}_{t}$ is updated by eliminating from it the arms with $U C B_{o}(\\cdot)$ less than the highest $L C B_{o}(\\cdot)$ . For arms in the reduced arm set $\\scriptstyle{\\mathcal{X}}_{t}$ , RS-GLinCB computes the index $U C B(x,\\mathbf{H}_{\\tau},\\widehat{\\theta}_{\\tau})\\,:=\\,\\langle x,\\widehat{\\theta}_{\\tau}\\rangle+150\\left\\|x\\right\\|_{\\mathbf{H}_{\\tau}^{-1}}\\sqrt{d\\log\\left(T/\\delta\\right)}$ , and plays the arm $x_{t}$ with the highest index (Line 13). After observing the subsequent reward $r_{t}$ , the algorithm updates the scaled design matrix $\\mathbf{H}_{t}$ (Line 14) as follows: $\\mathbf{H}_{t+1}\\leftarrow\\mathbf{H}_{t}+(\\dot{\\mu}(\\langle x_{t},\\widehat{\\theta}_{o}\\rangle)/e)x_{t}x_{t}^{\\intercal}$ . With this, the round $t$ ends and the algorithm moves to the next round. Next, in Lemma 4.1 and Theorem 4.2 we present the guarantees on number of policy updates and regret, respectively, for RS-GLinCB. Detailed proofs for both are provided in Appendix B. ", "page_idx": 7}, {"type": "text", "text": "Lemma 4.1. RS-GLinCB (Algorithm 2), during its entire execution, updates its policy at most $O(R^{4}S^{2}\\;\\kappa d^{2}\\;\\log^{2}(T/\\delta))$ times. ", "page_idx": 7}, {"type": "text", "text": "Theorem 4.2. Given $\\delta\\in(0,1)$ , with probability $\\geq1-\\delta$ , the regret of RS-GLinCB (Algorithm 2) satisfies $\\begin{array}{r}{\\mathrm{R}_{T}=O\\big(d\\sqrt{\\sum_{t\\in[T]}\\dot{\\mu}\\left(\\langle x_{t}^{*},\\theta^{*}\\rangle\\right)}\\log\\left(R T/\\delta\\right)+\\ \\kappa d^{2}R^{5}S^{2}\\log^{2}\\left(T/\\delta\\right)\\big).}\\end{array}$ ", "page_idx": 7}, {"type": "text", "text": "Remark 4.3. Switching Criterion I is essential in delivering tight regret guarantees in the non-linear setting. Unlike existing literature [7], which relies on warm-up rounds based on observed rewards (hence heavily dependent on reward models), RS-GLinCB presents a context-dependent criterion that implicitly checks whether the estimate $\\dot{\\mu}(\\langle x,\\widehat{\\theta}_{o}\\rangle)$ is within a constant factor of $\\dot{\\mu}\\left(\\left\\langle x,\\theta^{*}\\right\\rangle\\right)$ (see Lemmas B.3 and B.4). We show that the number  of times Switching Criterion I is triggered is only $O(\\kappa d^{2}\\log^{2}(T))$ (see Lemma B.11), hence incurring a small regret in these rounds. ", "page_idx": 7}, {"type": "text", "text": "Remark 4.4. Unlike [1], our determinant-doubling Switching Criterion II uses the scaled design matrix $\\mathbf{H}_{t}$ instead of the unscaled version (similar to $\\mathbf{V}$ ). The matrix $\\mathbf{H}_{t}$ , estimating the Hessian of the log-loss, is crucial for achieving optimal regret. This modification is crucial in extending algorithms satisfying limited adaptivity setting M2 for the CB problem with a linear reward model to more general GLM reward models. ", "page_idx": 7}, {"type": "text", "text": "Remark 4.5. The feasible set for the optimization stated in 8 is an ellipsoid around $\\widehat{\\theta}_{o}$ , which contains $\\theta^{*}$ with high probability. Deviating from existing literature on GLM Bandits  which projects the estimate into the ball set of rad\u221aius $S$ $(\\{\\theta:\\|\\theta\\|\\leq S\\})$ ), our projection step leads to tighter regret guarantees; notably, the leading $\\sqrt{T}$ term is free of parameters $S$ (and $R$ ).\u221a This resolves the conjecture made in [17] regarding the possibility of obtaining $S$ -free regret in the $\\sqrt{T}$ term in logistic bandits. Remark 4.6. The regret guarantee of the logistic bandit algorithms in [2, 17] have a second-order term that is minimum of an arm-geometry dependent quantity (see Theorem 3 of [17]) and a $\\kappa$ - dependent term similar to our regret guarantee. Although our analysis is not able to accommodate this arm-geometry dependent quantity, we underscore that our algorithm is computationally efficient while the above works are not. In fact, to the best of our knowledge, the other known efficient algorithms for logistic bandits [7, 28] also do not achieve the arm-geometry dependent regret term. It can be interesting to design an efficient algorithm that is able to achieve the same guarantees in the second-order regret term as in [2, 17]. ", "page_idx": 7}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We tested the practicality of our algorithm RS-GLinCB against various baselines for logistic and generalized linear bandits. For these experiments, we adjusted the warm-up threshold constant in RS-GLinCB to 0.01 and used data from both warm-up and non-warm-up rounds to estimate\u03b8. ", "page_idx": 7}, {"type": "image", "img_path": "FTPDBQuT4G/tmp/f51fdd15ceedeac18e8e8ca071ff70c7c058ce42a33e4c5e32c5b9b5bc612daa.jpg", "img_caption": ["Figure 1: Top: Cumulative Regret vs. number of rounds for Logistic (left) and Probit (right) reward models. Bottom: (left) Execution times of ECOLog and RS-GLinCB for different values of $\\kappa$ (low $\\kappa=9.3$ and high $\\kappa=141.6)$ for Logistic rewards. (right) Execution times of GLOC and RS-GLinCB for different values of $\\kappa$ (low $\\kappa=17.6$ and high $\\kappa=202.3)$ Probit rewards. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "These modifications do not affect the overall efficiency as $\\widetilde{\\theta}$ is calculated only $O(\\log(T))$ times. The experiment code is available at https://github.com /nirjhar-das/GLBandit_Limited_ Adaptivity. ", "page_idx": 8}, {"type": "text", "text": "Logistic. We compared RS-GLinCB against ECOLog [7] and GLOC [14], the only algorithms with overall time complexity $\\tilde{O}(T)$ for this setting. The dimension was set to $d=5$ , number of arms per round to $K=20$ , and $\\theta^{*}$ was sampled from a $d$ -dimensional sphere of radius $S=5$ . Arms were sampled uniformly from the $d$ -dimensional unit ball. We ran simulations for $T=20,000$ rounds, repeating them 10 times. RS-GLinCB showed the smallest regret with a flattened regret curve, as seen in Fig. 1 (top-left). ", "page_idx": 8}, {"type": "text", "text": "Probit. For the probit reward model, we compared RS-GLinCB against GLOC and GLM-UCB [8]. The dimension was set to $d=5$ and number of arms per round to $K\\,=\\,20$ . $\\theta^{*}$ was sampled from a $d$ -dimensional sphere of radius $S\\,=\\,3$ . Arm features were generated similarly as in the logistic bandit simulation. We ran simulations for $T=5$ , 000 rounds, repeating them 10 times. RS-GLinCB outperformed both baselines, as shown in Fig. 1 (top-right). ", "page_idx": 8}, {"type": "text", "text": "Comparing Execution Times. We compared the execution times of RS-GLinCB and ECOLog. We created two logistic bandit instances with $d\\,=\\,5$ and $K\\,=\\,20$ , and different $\\kappa$ values. We ran both algorithms for $T=20$ , 000 rounds, repeating each run 20 times. For low $\\kappa$ , RS-GLinCB took about one-fifth of the time of ECOLog, and for high $\\kappa$ , slightly more than one-third, as seen in Fig. 1 (left-bottom). This demonstrates that RS-GLinCB has a significantly lower computational overhead compared to ECOLog. We also compared the execution times of RS-GLinCB and GLOC under the probit reward model, creating two bandit instances with $d=5$ and $K=20$ , but with differing $\\kappa$ . We ran both algorithms for $T=20,000$ rounds, repeating each run 20 times. The result is shown in Fig. 1 (bottom-right). We observe that for low $\\kappa$ , RS-GLinCB takes less than half time of GLOC while for high $\\kappa$ , it takes about two-third time of GLOC. A more detailed discussion of these experiments is provided in Appendix D. ", "page_idx": 8}, {"type": "text", "text": "6 Conclusion and Future Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The Contextual Bandit problem with GLM rewards is a ubiquitous framework for studying online decision-making with non-linear rewards. We study this problem with a focus on limited adaptivity. In particular, we design algorithms B-GLinCB and RS-GLinCB that obtain optimal regret guarantees for two prevalant limited adaptivity settings M1 and M2 respectively. A key feature of our guarantees are that their leading terms are independent of a instance dependent parameter $\\kappa$ that captures nonlinearity. To the best of our knowledge, our paper provides the first algorithm for CB algorithms for GLM rewards under limited adaptivity (and otherwise) that achieves $\\kappa$ -independent regret. The regret guarantee of RS-GLinCB, not only aligns with the best-known guarantees for Logistic Bandits but enhances them by removing the dependence on $S$ (upper bound on $\\lVert\\theta^{*}\\rVert)$ in the leading term of the regret and therefore resolves a conjecture in [17]. The batch learning algorithm B-GLinCB, for $M=\\Omega(\\log{(\\log{T})})$ , achieves a regret of $\\widetilde{O}\\left(d R S\\left(\\sqrt{d/\\widehat{\\kappa}}\\wedge\\sqrt{1/\\kappa^{*}}\\right)\\sqrt{T}\\right)$ . We believe that the dependence on $d$ along with the $\\widehat{\\kappa}$ term is not tight and improving the dependence is a relevant direction for future work. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Siddharth Barman gratefully acknowledges the support of the Walmart Center for Tech Excellence (CSR WMGT-23-0001) and a SERB Core research grant (CRG/2021/006165). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Yasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, and Csaba Szepesv\u00e1ri. Improved algorithms for linear stochastic bandits. Advances in neural information processing systems, 24, 2011.   \n[2] Marc Abeille, Louis Faury, and Cl\u00e9ment Calauz\u00e8nes. Instance-wise minimax-optimal algorithms for logistic bandits. In International Conference on Artificial Intelligence and Statistics, pages 3691\u20133699. PMLR, 2021.   \n[3] Peter Auer. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine Learning Research, 3(Nov):397\u2013422, 2002.   \n[4] Wei Chu, Lihong Li, Lev Reyzin, and Robert Schapire. Contextual bandits with linear payoff functions. In Geoffrey Gordon, David Dunson, and Miroslav Dud\u00edk, editors, Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, volume 15 of Proceedings of Machine Learning Research, pages 208\u2013214, Fort Lauderdale, FL, USA, 11\u201313 Apr 2011. PMLR.   \n[5] Louis Faury. Variance-sensitive confidence intervals for parametric and offilne bandits. Theses, Institut Polytechnique de Paris, Oct 2021.   \n[6] Louis Faury, Marc Abeille, Cl\u00e9ment Calauz\u00e8nes, and Olivier Fercoq. Improved optimistic algorithms for logistic bandits. In International Conference on Machine Learning, pages 3052\u20133060. PMLR, 2020.   \n[7] Louis Faury, Marc Abeille, Kwang-Sung Jun, and Cl\u00e9ment Calauz\u00e8nes. Jointly efficient and optimal algorithms for logistic bandits. In International Conference on Artificial Intelligence and Statistics, pages 546\u2013580. PMLR, 2022.   \n[8] Sarah Filippi, Olivier Cappe, Aur\u00e9lien Garivier, and Csaba Szepesv\u00e1ri. Parametric bandits: The generalized linear case. Advances in neural information processing systems, 23, 2010.   \n[9] Zijun Gao, Yanjun Han, Zhimei Ren, and Zhengqing Zhou. Batched multi-armed bandits problem. Advances in Neural Information Processing Systems, 32, 2019.   \n[10] International Stroke Trial Collaborative Group et al. The international stroke trial (ist): a randomised trial of aspirin, subcutaneous heparin, both, or neither among 19 435 patients with acute ischaemic stroke. The Lancet, 349(9065):1569\u20131581, 1997.   \n[11] Yanjun Han, Zhengqing Zhou, Zhengyuan Zhou, Jose Blanchet, Peter W Glynn, and Yinyu Ye. Sequential batch learning in finite-action linear contextual bandits. arXiv preprint arXiv:2004.06321, 2020.   \n[12] Osama Hanna, Lin Yang, and Christina Fragouli. Learning from distributed users in contextual linear bandits without sharing the context. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022.   \n[13] Osama Hanna, Lin Yang, and Christina Fragouli. Efficient batched algorithm for contextual linear bandits with large action space via soft elimination. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[14] Kwang-Sung Jun, Aniruddha Bhargava, Robert Nowak, and Rebecca Willett. Scalable generalized linear bandits: Online computation and hashing. Advances in Neural Information Processing Systems, 30, 2017.   \n[15] Jack Kiefer and Jacob Wolfowitz. The equivalence of two extremum problems. Canadian Journal of Mathematics, 12:363\u2013366, 1960.   \n[16] Tor Lattimore and Csaba Szepesv\u00e1ri. Bandit Algorithms. Cambridge University Press, 2020.   \n[17] Junghyun Lee, Se-Young Yun, and Kwang-Sung Jun. Improved regret bounds of (multinomial) logistic bandits via regret-to-confidence-set conversion. In Proceedings of The 27th International Conference on Artificial Intelligence and Statistics, pages 4474\u20134482. PMLR, 02\u201304 May 2024.   \n[18] Lihong Li, Wei Chu, John Langford, and Robert E Schapire. A contextual-bandit approach to personalized news article recommendation. In Proceedings of the 19th international conference on World wide web, pages 661\u2013670, 2010.   \n[19] Lihong Li, Yu Lu, and Dengyong Zhou. Provably optimal algorithms for generalized linear contextual bandits. In International Conference on Machine Learning, pages 2071\u20132080. PMLR, 2017.   \n[20] Blake Mason, Kwang-Sung Jun, and Lalit Jain. An experimental design approach for regret minimization in logistic bandits. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 7736\u20137743, 2022.   \n[21] Vianney Perchet, Philippe Rigollet, Sylvain Chassang, and Erik Snowberg. Batched bandit problems. In Peter Gr\u00fcnwald, Elad Hazan, and Satyen Kale, editors, Proceedings of The 28th Conference on Learning Theory, volume 40 of Proceedings of Machine Learning Research, pages 1456\u20131456, Paris, France, 03\u201306 Jul 2015. PMLR.   \n[22] Zhimei Ren and Zhengyuan Zhou. Dynamic batch learning in high-dimensional sparse linear contextual bandits. Management Science, 70(2):1315\u20131342, 2024.   \n[23] Yufei Ruan, Jiaqi Yang, and Yuan Zhou. Linear bandits with limited adaptivity and learning distributional optimal design. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages 74\u201387, 2021.   \n[24] Yoan Russac, Olivier Capp\u2019e, and Aur\u00e9lien Garivier. Algorithms for non-stationary generalized linear bandits. ArXiv, abs/2003.10113, 2020.   \n[25] Eric M Schwartz, Eric T Bradlow, and Peter S Fader. Customer acquisition via display advertising using multi-armed bandit experiments. Marketing Science, 36(4):500\u2013522, 2017.   \n[26] David Simchi-Levi and Yunzong Xu. Bypassing the monster: A faster and simpler optimal algorithm for contextual bandits under realizability. Mathematics of Operations Research, 47(3):1904\u20131931, 2022.   \n[27] Joel A Tropp et al. An introduction to matrix concentration inequalities. Foundations and Trends\u00ae in Machine Learning, 8(1-2):1\u2013230, 2015.   \n[28] Yu-Jie Zhang and Masashi Sugiyama. Online (multinomial) logistic bandit: Improved regret and constant computation cost. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "Generalized Linear Bandits with Limited Adaptivity Appendix ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "Table of Contents ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "Introduction 1   \n1.1 Our Contributions . 2   \n1.2 Important Remarks on Contributions and Comparison with Prior Work 2   \nNotations and Preliminaries 3   \n2.1 Instance Dependent Non-Linearity Parameters . . 4   \n2.2 Optimal Design Policies 4 ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "3 B-GLinCB 5 ", "page_idx": 11}, {"type": "text", "text": "4 RS-GLinCB ", "page_idx": 11}, {"type": "text", "text": "5 Experiments 8 ", "page_idx": 11}, {"type": "text", "text": "6 Conclusion and Future Work 10 ", "page_idx": 11}, {"type": "text", "text": "Regret Analysis of B-GLinCB 13   \nA.1 Additional Notation 13   \nA.2 Concentration Inequalities and Confidence Intervals 13   \nA.3 Preliminary Lemmas 16   \nA.4 Proof of Theorem 3.2 19   \nA.5 Optimal Design Guarantees . 20   \nB Regret Analysis of RS-GLinCB 21   \nB.1 Confidence Sets for Switching Criterion I rounds 22   \nB.2 Confidence Sets for non-Switching Criterion I rounds 23   \nB.3 Bounding the instantaneous regret 25   \nB.4 Proof of Theorem 4.2 26   \nB.5 Bounding number of policy updates: Proof of Lemma 4.1 . 27   \nB.6 Some Useful Lemmas 27 ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "C Useful Properties of GLMs 28 ", "page_idx": 11}, {"type": "text", "text": "D Computational Cost 31 ", "page_idx": 11}, {"type": "text", "text": "E Projection 32   \nE.1 Convex Relaxation 33 ", "page_idx": 11}, {"type": "text", "text": "A Regret Analysis of B-GLinCB ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A.1 Additional Notation ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "We write c to denote absolute constant(s) that appears throughout our analysis. Our analysis also utilizes the following function ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\gamma(\\lambda)=24R S\\left(\\sqrt{\\log{(T)}+d}+\\frac{R\\left(\\log{(T)}+d\\right)}{\\sqrt{\\lambda}}\\right)+2S\\sqrt{\\lambda}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Note that $\\gamma(\\lambda)$ is a \u2018parameterized\u2019 version of $\\gamma$ (which was defined in section 3). In our proof, we present the arguments using this parameterized version. A direct minimization of the above expression in terms of $\\lambda$ would not suffice since we need $\\lambda$ to be sufficiently large for certain matrix concentration lemmas to hold (see Section A.5). However, later we show that setting $\\lambda$ equal to $\\mathbf{c}R d\\log T$ leads to the desired bounds. ", "page_idx": 12}, {"type": "text", "text": "We use $\\widetilde{x}$ to denote the scaled versions of the arms (see Line 11 of the algorithm); in particular, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\widetilde{x}:=\\sqrt{\\frac{\\dot{\\mu}\\left(\\langle x,\\widehat{\\theta}_{w}\\rangle\\right)}{\\beta(x)}}x\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Furthermore, to capture the non-linearity of the problem, we introduce the term $\\phi(\\lambda)$ : ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\phi(\\lambda):=\\frac{\\sqrt{\\kappa}\\;e^{3S}\\;\\gamma(\\lambda)^{2}}{S}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Recall that the scaled data matrix ${\\bf{H}}_{k}$ (for each batch $k$ ) was computed using $\\widehat{\\theta}_{w}$ as follows ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathbf{H}_{k}=\\sum_{t\\in\\mathcal{T}_{k}}\\frac{\\dot{\\mu}\\left(\\langle x_{j},\\widehat{\\theta}_{w}\\rangle\\right)}{\\beta(x_{t})}x_{t}x_{t}^{\\sf T}+\\lambda\\mathbf{I}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Following the definition of $\\mathbf{H}_{k}$ and using the true vector $\\theta^{*}$ we define ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathbf{H}_{k}^{*}=\\sum_{t\\in\\mathcal{T}_{k}}\\dot{\\mu}\\left(\\langle x_{t},\\theta^{*}\\rangle\\right)x_{t}x_{t}^{\\mathsf{T}}+\\lambda\\mathbf{I}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "We will show that ${\\mathbf{H}}_{k}$ as an estimator of $\\mathbf{H}_{k}^{*}$ certain desirable properties (see Lemma A.5). Furthermore, we assume that the MLE estimator $\\theta^{*}$ obtained by minimizing the log-loss objective always satisfies $\\left\\|{\\widehat{\\theta}}\\right\\|\\leq S$ . In case, that\u2019s not true, one can use the non-convex projection described in Appendix E. The projected vector satisfies the same guarantees as described in the subsequent lemmas up to a multiplicative factor of 2. Hence, the assumption $\\left\\|{\\widehat{\\theta}}\\right\\|\\leq S$ is non-limiting. ", "page_idx": 12}, {"type": "text", "text": "A.2 Concentration Inequalities and Confidence Intervals ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Lemma A.1 (Bernstein\u2019s Inequality). Let $X_{1},\\ldots,X_{n}$ be a sequence of independent random variables with $\\left|X_{t}-\\mathbb{E}\\left[X_{t}\\right]\\right|\\leq\\bar{b}$ . Also, let sum $\\begin{array}{r}{S:=\\sum_{t=1}^{n}\\left(X_{t}\\^{\\cdot}-\\mathbb{E}\\left[X_{t}\\right]\\right)}\\end{array}$ and $\\begin{array}{r}{v\\,:=\\,\\sum_{t=1}^{m}V a r[X_{t}]}\\end{array}$ . Then, for any $\\delta\\in[0,1]$ , we have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left\\{S\\geq\\sqrt{2v\\log\\frac{1}{\\delta}}+\\frac{2b}{3}\\log\\frac{1}{\\delta}\\right\\}\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Lemma A.2. Let $\\mathcal{X}=\\{x_{1},x_{2},\\ldots,x_{s}\\}\\in\\mathbb{R}^{d}$ be a set of vectors with $\\|x_{t}\\|\\leq1$ , for all $t\\,\\in\\,[s]$ , and let scalar $\\lambda\\geq0$ . Also, let $r_{1},r_{2},\\dots,r_{s}\\in[0,R]$ be independent random variables distributed by the canonical exponential family; in particular, $\\mathbb{E}\\left[r_{s}\\right]=\\mu\\left(\\left\\langle x_{s},\\theta^{*}\\right\\rangle\\right)$ for $\\theta^{*}\\in\\mathbb{R}^{d}$ . Further, let $\\begin{array}{r}{\\widehat{\\theta}=\\arg\\operatorname*{min}_{\\theta}\\sum_{s=1}^{t}\\ell(\\theta,x_{s},r_{s})}\\end{array}$ be the maximum likelihood estimator of $\\theta^{*}$ and let matrix ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathbf{H}^{*}=\\sum_{j=1}^{s}{\\dot{\\mu}}\\left(\\langle x_{j},\\theta^{*}\\rangle\\right)x_{j}x_{j}^{\\mathsf{T}}+\\lambda\\mathbf{I}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Then, with probability at least than $\\textstyle1-{\\frac{1}{T^{2}}}$ , the following inequality holds ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\left\\|\\theta^{*}-\\widehat{\\theta}\\right\\|_{\\mathbf{H}^{*}}\\leq24R S\\left(\\sqrt{\\log{(T)}+d}+\\frac{R\\left(\\log{(T)}+d\\right)}{\\sqrt{\\lambda}}\\right)+2S\\sqrt{\\lambda}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Proof. We first define the following quantities ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\alpha(x,\\theta^{*},\\widehat{\\theta}):=\\displaystyle\\int_{v=1}^{1}\\dot{\\mu}\\left(\\langle x,\\theta^{*}\\rangle+v\\langle x,\\left(\\widehat{\\theta}-\\theta^{*}\\right)\\rangle\\right)d v}&\\\\ &{\\qquad\\quad\\textbf{G}:=\\displaystyle\\sum_{j=1}^{s}\\alpha(x,\\theta^{*},\\widehat{\\theta})x_{j}x_{j}^{\\mathsf{T}}+\\displaystyle\\frac{\\lambda}{1+2R S}\\mathbf{I}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Using Lemma C.2 we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbf{G}\\succeq\\frac{1}{1+2R S}\\,\\mathbf{H}^{*}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Hence we write ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\theta^{*}-\\hat{\\theta}\\Big\\rVert_{\\mathbf{H}^{*}}\\le\\sqrt{(1+2R S)}\\left\\lVert\\theta^{*}-\\hat{\\theta}\\right\\rVert_{\\mathbf{G}}}\\\\ &{=\\sqrt{1+2R S}\\left\\lVert\\left(\\theta^{*}-\\hat{\\theta}\\right)\\mathbf{G}\\right\\rVert_{\\mathbf{G}^{-1}}}\\\\ &{=\\sqrt{1+2R S}\\left\\lVert\\displaystyle\\sum_{j=1}^{s}\\left(\\langle\\theta^{*},x_{j}\\rangle-\\langle\\hat{\\theta},x_{j}\\rangle\\right)\\alpha(x,\\theta^{*},\\hat{\\theta})x_{j}+\\frac{\\lambda}{1+2R S}\\left(\\theta^{*}-\\hat{\\theta}\\right)\\right\\rVert_{\\mathbf{G}^{-1}}}\\\\ &{\\le\\sqrt{1+2R S}\\left\\lVert\\displaystyle\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-\\mu\\left(\\langle\\hat{\\theta},x_{j}\\rangle\\right)\\right)x_{j}\\right\\rVert_{\\mathbf{G}^{-1}}+\\frac{\\lambda}{\\sqrt{1+2R S}}\\left\\lVert\\theta^{*}-\\hat{\\theta}\\right\\rVert_{\\mathbf{G}^{-1}}}\\\\ &{\\le\\sqrt{1+2R S}\\left\\lVert\\displaystyle\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-\\mu\\left(\\langle\\hat{\\theta},x_{j}\\rangle\\right)\\right)x_{j}\\right\\rVert_{\\mathbf{G}^{-1}}+2S\\sqrt{\\lambda}}\\\\ &{\\le\\sqrt{1+2R S}\\left\\lVert\\displaystyle\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-\\mu\\left(\\langle\\hat{\\theta},x_{j}\\rangle\\right)\\right)x_{j}\\right\\rVert_{\\mathbf{G}^{-1}}+2S\\sqrt{\\lambda}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "equation", "text": "$$\n\\leq3R S\\left\\|\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-\\mu\\left(\\langle\\widehat{\\theta},x_{j}\\rangle\\right)\\right)x_{j}\\right\\|_{\\mathbf{H}^{*}^{-1}}+2S\\sqrt{\\lambda}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Now by the optimality condition on $\\widehat{\\theta}$ we have $\\begin{array}{r}{\\sum_{j=1}^{s}\\mu\\left(\\langle x_{j},\\widehat\\theta\\rangle\\right)x_{j}=\\sum_{j=1}^{s}r_{j}x_{j}}\\end{array}$ (see equation (3) [8]). Hence, we write ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-\\mu\\left(\\langle\\widehat{\\theta},x_{j}\\rangle\\right)\\right)x_{j}\\right\\|_{\\mathbf{H}^{*}-1}=\\left\\|\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-r_{j}\\right)x_{j}\\right\\|_{\\mathbf{H}^{*}-1}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Let $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ denote the unit ball in $\\mathbb{R}^{d}$ . We can write ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-r_{j}\\right)x_{j}\\right\\|_{\\mathbf{H}^{*}-1}=\\operatorname*{max}_{y\\in B}\\langle y,\\mathbf{H}^{*}{}^{-1/2}\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-r_{j}\\right)x_{j}\\rangle\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We construct an $\\varepsilon$ -net for the unit ball, denoted as $\\mathcal{C}_{\\varepsilon}$ . For any $y\\ \\in\\ B$ , we define $y_{\\varepsilon}\\quad:=$ arg $\\operatorname*{min}_{b\\in C_{\\varepsilon}}\\left\\|b-y\\right\\|_{2}$ . We can now write ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\left\\|\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-r_{j}\\right)x_{j}\\right\\|_{\\mathbf{H}^{s-1}}}}\\\\ &{=\\operatorname*{max}_{y\\in\\cal B}\\langle y-y_{\\varepsilon},\\mathbf{H}^{*-1/2}\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-r_{j}\\right)x_{j}\\rangle+\\langle y_{\\varepsilon},\\mathbf{H}^{*-1/2}\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-r_{j}\\right)x_{j}\\rangle}\\\\ &{\\leq\\|y-y_{\\varepsilon}\\|_{2}\\left\\|\\displaystyle\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-r_{j}\\right)x_{j}\\right\\|_{\\mathbf{H}^{s-1}}+\\langle y_{\\varepsilon},\\mathbf{H}^{*-1/2}\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-r_{j}\\right)x_{j}\\rangle}\\\\ &{\\leq\\varepsilon\\left\\|\\displaystyle\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-r_{j}\\right)x_{j}\\right\\|_{\\mathbf{H}^{s-1}}+\\langle y_{\\varepsilon},\\mathbf{H}^{*-1/2}\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-r_{j}\\right)x_{j}\\rangle}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Rearranging, we obtain ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-r_{j}\\right)x_{j}\\right\\|_{\\mathbf{H}^{*}}\\leq\\frac{1}{1-\\varepsilon}\\langle y_{\\varepsilon},\\mathbf{H}^{*}}^{-1/2}\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-r_{j}\\right)x_{j}\\rangle\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Next, we use Lemma A.3 (stated below) with $\\delta=T^{2}|\\mathcal{C}_{\\varepsilon}|$ and union bound over all vectors in $\\mathcal{C}_{\\varepsilon}$ . We also observe that $\\begin{array}{r}{|\\mathcal{C}_{\\varepsilon}|\\leq\\left(\\frac{2}{\\varepsilon}\\right)^{d}}\\end{array}$ . Substituting $\\epsilon=1/2$ and using Lemma A.3, we obtain that the following holds with probability greater than $\\textstyle1-{\\frac{1}{T^{2}}}$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{j=1}^{s}\\left(\\mu\\left(\\left\\langle\\theta^{*},x_{j}\\right\\rangle\\right)-r_{j}\\right)x_{j}\\right\\|_{\\mathbf{H}^{*-1}}\\leq3\\sqrt{\\log\\left(T^{2}|\\mathcal{C}_{\\varepsilon}|\\right)}+\\frac{4R}{3\\sqrt{\\lambda}}\\log\\left(T^{2}|\\mathcal{C}_{\\varepsilon}|\\right)\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Substituting in equations (13), we get the desired inequality in the lemma statement. ", "page_idx": 14}, {"type": "text", "text": "Lemma A.3. Let y be a fixed vector with $\\|y\\|\\leq1$ . Then, with the notation stated in Lemma A.2, the following inequality holds with probability at least $1-\\delta$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\sum_{j=1}^{s}\\left(\\mu\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)-r_{j}\\right)y^{\\top}\\mathbf{H}^{*}^{-1/2}x_{j}\\leq\\sqrt{2\\log\\frac{1}{\\delta}}+\\frac{2R}{3\\sqrt{\\lambda}}\\log\\frac{1}{\\delta}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Proof. Let us denote the $j^{t h}$ term of the sum as $Z_{j}$ . Note that each random variable $Z_{j}$ has variance $\\mathrm{Var}(Z_{j})=\\dot{\\mu}\\left(\\langle x_{j},\\theta^{*}\\rangle\\right)\\left(y^{\\mathsf{T}}\\mathbf{H}^{*\\,-1/2}x_{j}\\right)^{2}$ . Hence, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{j=1}^{s}\\operatorname{Var}(Z_{j})=\\displaystyle\\sum_{j=1}^{s}\\dot{\\mu}\\left(\\langle\\theta^{*},x_{j}\\rangle\\right)\\left(y^{\\top}\\mathbf{H}^{*\\,-1/2}x_{j}\\right)^{2}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=y^{\\top}y\\leq1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Moreover, each $Z_{j}$ is at most $\\textstyle{\\frac{R}{\\sqrt{\\lambda}}}$ (since $\\|x_{j}\\|\\leq1,\\mathbf{H}^{*}\\succeq\\lambda\\mathbf{I}$ and $r\\in[0,R])$ . Now applying Lemma A.1, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left\\{\\sum_{j=1}^{s}Z_{j}\\geq\\sqrt{2\\log\\frac{1}{\\delta}}+\\frac{2R}{3\\sqrt{\\lambda}}\\log\\frac{1}{\\delta}\\right\\}\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Corollary A.4. Let $x_{1},x_{2},\\ldots,x_{\\tau}$ be the sequence of arms pulled during the warm-up batch and let $\\widehat{\\theta}_{w}$ be the estimator of $\\theta^{*}$ computed at the end of the batch. Then, for any vector $x$ and $\\lambda\\geq0$ the following bound holds with probability greater than $\\textstyle1-{\\frac{1}{T^{2}}}$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n|\\langle x,\\theta^{*}-\\widehat{\\theta}_{w}\\rangle|\\leq\\sqrt{\\kappa}\\,\\|x\\|_{\\mathbf{V}^{-1}}\\,\\gamma(\\lambda).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. This result is derived directly from Lemma A.2 and the definition of (see ). By applying the lemma, we obtain ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\lvert\\langle x,\\theta^{*}-\\widehat{\\theta}_{w}\\rangle\\rvert\\leq\\lVert x\\rVert_{{\\mathbf{H}^{*}}^{*1}}\\left\\lVert\\theta^{*}-\\widehat{\\theta}_{w}\\right\\rVert_{{\\mathbf{H}^{*}}}\\leq\\lVert x\\rVert_{{\\mathbf{H}^{*-1}}}\\,\\gamma(\\lambda)}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Considering the definition of $\\kappa$ , we have\u221a $\\begin{array}{r}{\\dot{\\mu}\\left(\\langle\\mathbf{x},\\theta^{*}\\rangle\\right)\\geq\\frac{1}{\\kappa}}\\end{array}$ . This implies that $\\begin{array}{r}{\\mathbf{H}^{*}\\succeq\\frac{1}{\\kappa}\\mathbf{V}^{12}}\\end{array}$ which in turn leads to the inequality $\\|x\\|_{\\mathbf{H}^{*}^{-1}}\\leq\\sqrt{\\kappa}\\,\\|x\\|_{\\mathbf{V}^{-1}}$ . \u53e3 ", "page_idx": 15}, {"type": "text", "text": "A.3 Preliminary Lemmas ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Lemma A.5. For each batch $k\\geq2$ and the scaled data matrix ${\\bf{H}}_{k}$ computed at the end of batch, the following bound holds with probability at least $\\textstyle1-{\\frac{1}{T^{2}}}$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbf{H}_{k}\\preceq\\mathbf{H}_{k}^{*}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. If the event stated in Lemma A.4 holds, ", "page_idx": 15}, {"type": "text", "text": "From Lemma C.2, we apply the multiplicative bound on $\\dot{\\mu}$ to obtain ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\dot{\\mu}\\left(\\langle x,\\widehat{\\theta}_{w}\\rangle\\right)\\leq\\dot{\\mu}\\left(\\langle x,\\theta^{*}\\rangle\\right)\\exp\\left(R|\\langle x,\\widehat{\\theta}_{w}-\\theta^{*}\\rangle|\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Via Lemma A.4 we have $|\\langle x,\\widehat{\\theta}_{w}\\rangle\\;-\\;\\langle x,\\theta^{*}\\rangle|\\;\\leq\\;\\sqrt{\\kappa}\\,\\|x\\|_{\\mathbf{V}^{-1}}\\,\\gamma(\\lambda)$ . Additionally, given that $\\left\\|{\\widehat{\\theta}}\\right\\|,\\left\\|\\theta^{*}\\right\\|\\leq S$ and $\\|x\\|\\leq1$ we also have $|\\langle x,\\widehat{\\theta}_{w}\\rangle-\\langle x,\\theta^{*}\\rangle|\\leq2S$ . Hence, we write ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\dot{\\mu}\\left(\\langle x,\\widehat{\\theta}_{w}\\rangle\\right)\\leq\\dot{\\mu}\\left(\\langle x,\\theta^{*}\\rangle\\right)\\exp\\left(R\\operatorname*{min}\\{\\sqrt{\\kappa}\\left\\|x\\right\\|_{\\mathbf{V}^{-1}}\\gamma(\\lambda),2S\\}\\right)}\\\\ &{\\qquad\\qquad\\leq\\dot{\\mu}\\left(\\langle x,\\theta^{*}\\rangle\\right)\\beta(x)}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Substituting these results into the definitions of ${\\bf{H}}_{k}$ and $\\mathbf{H}_{k}^{*}$ proves the lemma statement. ", "page_idx": 15}, {"type": "text", "text": "Claim A.6. The Algorithm $^{\\,l}$ runs for at most $\\log\\log T$ batches. ", "page_idx": 15}, {"type": "text", "text": "Proof. When $M\\leq\\log\\log T$ then th\u221ae claim trivially holds. When $M\\geq\\log\\log T+1$ , we define the length of the second batch, $\\tau_{2}$ , as $2\\sqrt{T}$ . The length of the $M^{t h}$ batch is ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tau_{M}=(2\\sqrt{T})^{\\sum_{k=1}^{M-1}\\frac{1}{2^{k-1}}}}\\\\ &{\\ \\ \\ \\ \\geq2T\\,T^{\\frac{-1}{2^{M-1}}}}\\\\ &{\\ \\ \\ \\ \\ \\geq2T\\,T^{\\frac{-1}{2^{\\log\\log T}}}}\\\\ &{\\ \\ \\ \\ \\geq T.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "equation", "text": "$$\n(M\\geq\\log\\log T+1)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Corollary A.7. Let $\\widehat{\\theta}_{k}$ be the estimator of $\\theta^{*}$ calculated at the end of the $k^{t h}$ batch. Then for any vector x the followin g holds with probability greater than 1 \u2212log Tl o2g T for every batch $k>=2$ . ", "page_idx": 15}, {"type": "equation", "text": "$$\n|\\langle x,\\theta^{*}-\\widehat{\\theta}\\rangle|\\leq\\|x\\|_{\\mathbf{H}_{k}^{-1}}\\,\\gamma(\\lambda)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. This result is a direct consequence of Lemma A.2 and the definition of $\\gamma(\\lambda)$ (see 9). According to the lemma, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lvert\\langle x,\\theta^{*}-\\widehat{\\theta}_{w}\\rangle\\rvert\\leq\\lVert x\\rVert_{\\mathbf{H}_{k}^{*}-1}\\left\\lVert\\theta^{*}-\\widehat{\\theta}_{w}\\right\\rVert_{\\mathbf{H}_{k}^{*}}}&{}\\\\ {\\leq\\lVert x\\rVert_{\\mathbf{H}_{k}^{*}-1}\\,\\gamma(\\lambda)}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Using Lemma A.5, we can further bound $\\|x\\|_{\\mathbf{H}_{k}^{*}^{}^{-1}}\\,\\le\\,\\|x\\|_{\\mathbf{H}_{k}^{}^{-1}}$ . Finally, a union bound over all batches and considering the fact that there are at most $\\log\\log T$ batches (Claim A.6) we establish the corollary\u2019s claim. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "Claim A.8. For any $x\\in[0,M]$ the following holds ", "page_idx": 16}, {"type": "equation", "text": "$$\ne^{x}\\leq\\left(e^{M}-1\\right)\\frac{x}{M}+1.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. The claim follows from the convexity of $e^{x}$ . ", "page_idx": 16}, {"type": "text", "text": "Lemma A.9. Let $x\\in\\mathscr{X}$ be the selected in any round of batch $k\\geq2$ in the algorithm, and let $x^{*}$ be the optimal arm in the arm set $\\mathcal{X}$ , i.e., $x^{*}=\\arg\\operatorname*{max}_{x\\in}\\mathcal{X}$ . With probability greater than $1-{\\frac{\\log\\log T}{T^{2}}}$ the following inequality holds", "page_idx": 16}, {"type": "equation", "text": "$$\n\\iota\\left(\\langle x^{*},\\theta^{*}\\rangle\\right)-\\mu\\left(\\langle x,\\theta^{*}\\rangle\\right)\\leq6\\phi(\\lambda)\\sum_{y\\in\\{x,x^{*}\\}}\\left\\|y\\right\\|_{\\mathbf{V}^{-1}}\\left\\|\\tilde{y}\\right\\|_{\\mathbf{H}_{k-1}}+2\\gamma(\\lambda)\\sqrt{\\dot{\\mu}\\left(\\langle x^{*},\\theta^{*}\\rangle\\right)}\\left(\\left\\|\\tilde{x}^{*}\\right\\|_{\\mathbf{H}_{k-1}}+\\left\\|\\tilde{x}\\right\\|_{\\mathbf{H}_{k-1}}\\right)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. We begin by applying Taylor\u2019s theorem, which yields the following for some $z\\ \\in$ $[\\langle x^{*},\\theta^{*}\\rangle,\\langle x,\\theta^{*}\\rangle]$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mu\\left(\\left\\langle x^{*},\\theta^{*}\\right\\rangle\\right)-\\mu\\left(\\left\\langle x,\\theta^{*}\\right\\rangle\\right)}\\\\ &{=\\dot{\\mu}\\left(z\\right)\\left\\vert\\left\\langle x,\\theta^{*}\\right\\rangle-\\left\\langle x,\\theta^{*}\\right\\rangle\\right\\vert}\\\\ &{=\\dot{\\mu}\\left(z\\right)\\left\\vert\\left\\langle x^{*},\\theta^{*}\\right\\rangle-\\left\\langle x^{*},\\hat{\\theta}_{k-1}\\right\\rangle+\\langle x^{*},\\hat{\\theta}_{k-1}\\right\\rangle-\\langle x,\\hat{\\theta}_{k-1}\\right\\rangle+\\langle x,\\hat{\\theta}_{k-1}\\rangle-\\langle x,\\theta^{*}\\rangle\\right\\vert}\\\\ &{\\le\\dot{\\mu}\\left(z\\right)\\left(\\left\\vert x^{*},\\theta^{*}\\right\\rangle-\\langle x^{*},\\hat{\\theta}_{k-1}\\right\\rangle\\right\\vert+\\left\\vert\\left\\langle x^{*},\\hat{\\theta}_{k-1}\\right\\rangle-\\langle x,\\hat{\\theta}_{k-1}\\right\\rangle\\right\\vert+\\left\\vert\\alpha,\\hat{\\theta}_{k-1}\\right\\rangle-\\langle x,\\theta^{*}\\rangle\\right\\vert\\right)}\\\\ &{\\le2\\dot{\\mu}\\left(z\\right)\\left(\\left\\Vert x^{*}\\right\\Vert_{\\mathbf{H}_{k-1}}\\gamma(\\lambda)+\\left\\Vert x\\right\\Vert_{\\mathbf{H}_{k-1}}\\gamma(\\lambda)\\right)}\\\\ &{\\le2\\dot{\\mu}\\left(z\\right)\\gamma(\\lambda)\\left(\\sqrt{\\frac{\\beta\\left(x^{*}\\right)}{\\mu\\left(\\left\\langle x^{*},\\hat{\\theta}_{\\infty}\\right\\rangle\\right)}}\\left\\Vert\\tilde{x}^{*}\\right\\Vert_{\\mathbf{H}_{k-1}}+\\sqrt{\\frac{\\beta\\left(x\\right)}{\\mu\\left(\\left\\langle x,\\hat{\\theta}_{\\infty}\\right\\rangle\\right)}}\\left\\Vert\\tilde{x}\\right\\Vert_{\\mathbf{H}_{k-1}}\\right)}\\\\ &{\\le2\\dot{\\gamma}(\\lambda)\\sqrt{\\mu(z)}\\sqrt{\\frac{\\beta\\left(z\\right)\\beta\\left(x^{*}\\right)}{\\mu\\left(\\left\\langle x^{*},\\hat{\\theta}_{\\infty}\\right\\rangle\\right)}}\\left\\Vert\\tilde{x}^{*}\\right\\Vert_{\\mathbf{H}_{k-1}}+2\\sqrt{\\dot{\\mu}\\left(z\\right)\\gamma}(\\lambda)\\sqrt{\\frac{\\beta\\left(z\\right)\\beta\\left(x\\right)}{\\mu\\left(\\left\\langle x,\\hat{\\theta}_{\\infty}\\right\\rangle\\right)}}\\left\\Vert\\tilde{x}\\right\\Vert_{\\mathbf{H}_{k-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We now invoke Lemmas C.2 and A.4 to obtain ", "page_idx": 17}, {"type": "text", "text": "(by stated assumptions and Lemma C.2) ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\exp\\left(\\operatorname*{min}\\left\\{S,\\frac{|\\langle x,\\theta^{*}\\rangle-\\langle x,\\widehat{\\theta}_{w}\\rangle|+|\\langle x,\\theta^{*}\\rangle-z|}{2}\\right\\}\\right)\\sqrt{\\beta(x)}}\\\\ &{\\leq\\exp\\left(\\operatorname*{min}\\left\\{S,\\frac{|\\langle x,\\theta^{*}\\rangle-\\langle x,\\widehat{\\theta}_{w}\\rangle|+|\\langle x,\\theta^{*}\\rangle-\\langle x^{*},\\theta^{*}\\rangle|}{2}\\right\\}\\right)\\sqrt{\\beta(x)}}\\\\ &{\\leq\\exp\\left(\\operatorname*{min}\\left\\{S,\\frac{3\\sqrt{\\kappa}\\,\\|x\\|_{\\mathbf{V}^{-1}}\\,\\gamma\\,(\\lambda)+2\\sqrt{\\kappa}\\,\\|x^{*}\\|_{\\mathbf{V}^{-1}}\\,\\gamma\\,(\\lambda)}{2}\\right\\}\\right)\\sqrt{\\beta(x)}}\\\\ &{\\leq\\exp\\left(\\operatorname*{min}\\left\\{S,\\frac{3\\sqrt{\\kappa}\\,\\|x\\|_{\\mathbf{V}^{-1}}\\,\\gamma\\,(\\lambda)+2\\sqrt{\\kappa}\\,\\|x^{*}\\|_{\\mathbf{V}^{-1}}\\,\\gamma\\,(\\lambda)}{2}\\right\\}\\right)\\sqrt{\\beta(x)}}\\\\ &{\\leq\\exp\\left(\\operatorname*{min}\\left\\{2S,2\\sqrt{\\kappa}\\,\\|x\\|_{\\mathbf{V}^{-1}}\\,\\gamma\\,(\\lambda)+\\sqrt{\\kappa}\\,\\|x^{*}\\|_{\\mathbf{V}^{-1}}\\,\\gamma\\,(\\lambda)\\right\\}\\right)\\Big)\\enspace\\mathrm{.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Similarly, we also have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\sqrt{\\dot{\\mu}\\left(z\\right)}\\leq\\sqrt{\\dot{\\mu}\\left(\\left\\langle x^{*},\\theta^{*}\\right\\rangle\\right)}\\exp\\left(\\operatorname*{min}\\left\\lbrace S,\\sqrt{\\kappa}\\left\\Vert x\\right\\Vert_{\\mathbf{V}^{-1}}\\gamma\\left(\\lambda\\right)+\\sqrt{\\kappa}\\left\\Vert x^{*}\\right\\Vert_{\\mathbf{V}^{-1}}\\gamma\\left(\\lambda\\right)\\right\\rbrace\\right).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Further, we can simplify each term in equation (15) as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sqrt{\\dot{\\mu}(z)}\\left(\\sqrt{\\frac{\\dot{\\mu}(z)\\beta(x^{*})}{\\dot{\\beta}\\left(\\left\\langle z^{*},\\hat{\\theta}_{w}\\right\\rangle\\right)}}\\left\\|\\tilde{x}^{*}\\right\\|_{\\mathbf{H}_{k-1}}\\right)}\\\\ &{\\leq2\\sqrt{\\dot{\\mu}(\\left\\langle x^{*},\\hat{\\theta}^{*}\\right\\rangle)}\\left(\\left\\|\\tilde{x}^{*}\\right\\|_{\\mathbf{H}_{k-1}}\\exp\\left(\\operatorname*{min}\\left\\{3S,3\\sqrt{\\kappa}\\gamma\\left(\\boldsymbol\\lambda\\right)\\left(\\left\\|x\\right\\|_{\\mathbf{V}^{-1}}+\\left\\|\\mathbf{z}^{*}\\right\\|_{\\mathbf{V}^{-1}}\\right)\\right\\}\\right)\\right)}\\\\ &{\\leq6\\frac{\\sqrt{\\dot{\\mu}(\\left\\langle x^{*},\\hat{\\theta}^{*}\\right\\rangle)\\kappa}\\,e^{3S\\gamma}(\\lambda)^{2}}{S}\\left(\\left\\|x^{*}\\right\\|_{\\mathbf{V}^{-1}}+\\left\\|x\\right\\|_{\\mathbf{V}^{-1}}\\right)\\left\\|\\tilde{x}^{*}\\right\\|_{\\mathbf{H}_{k-1}}+2\\gamma(\\lambda)\\sqrt{\\dot{\\mu}(\\left\\langle x^{*},\\hat{\\theta}^{*}\\right\\rangle)}\\left\\|\\tilde{x}^{*}\\right\\|_{\\mathbf{H}_{k-1}}}\\\\ &{\\leq6\\frac{\\sqrt{\\dot{\\mu}(\\left\\langle x^{*},\\hat{\\theta}^{*}\\right\\rangle)\\kappa}\\,e^{3S\\gamma}(\\lambda)^{2}}{S}\\left(\\left\\|x^{*}\\right\\|_{\\mathbf{V}^{-1}}+\\left\\|x\\right\\|_{\\mathbf{V}^{-1}}\\right)\\left\\|\\tilde{x}^{*}\\right\\|_{\\mathbf{H}_{k-1}}}\\\\ &{\\qquad+2\\gamma(\\lambda)\\sqrt{\\dot{\\mu}(\\left\\langle x^{*},\\hat{\\theta}^{*}\\right\\rangle)}\\left\\|\\tilde{x}^{*}\\right\\|_{\\mathbf{H}_{k-1}}}\\\\ &{\\leq6\\sqrt{\\dot{\\mu}(\\left\\langle x^{*},\\hat{\\theta}^{*}\\right\\rangle)}\\phi(\\left\\|x^{*}\\right\\|_{\\mathbf{V}^{-1}}+\\left\\|x\\right\\|_{\\mathbf{V}^{-1}})\\left\\|\\tilde{x}^{*}\\right\\|_{\\mathbf{H}_{k-1}}+2\\gamma(\\lambda)\\sqrt{\\dot{\\mu}(\\left\\langle x^{*},\\hat{\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Finally, we substitute the above bound in (15) to obtain ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\mu\\left(\\langle x^{*},\\theta^{*}\\rangle\\right)-\\mu\\left(\\langle x,\\theta^{*}\\rangle\\right)|\\leq6\\sqrt{\\mu\\left(\\langle x^{*},\\theta^{*}\\rangle\\right)}\\phi(\\lambda)\\left(\\|x^{*}\\|_{\\mathbf{V}^{-1}}+\\|x\\|_{\\mathbf{V}^{-1}}\\right)\\left(\\|\\tilde{x}^{*}\\|_{\\mathbf{H}_{k-1}}+\\|\\tilde{x}\\|_{\\mathbf{H}_{k-1}}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\ 2\\sqrt{\\mu\\left(\\langle x^{*},\\theta^{*}\\rangle\\right)}\\left(\\|\\tilde{x}^{*}\\|_{\\mathbf{H}_{k-1}}+\\|\\tilde{x}\\|_{\\mathbf{H}_{k-1}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "For Phase $k$ , the distribution of the remaining arms after the elimination step ( $\\chi$ in line 10 of the Algorithm 1) is represented as $\\mathcal{D}_{k}$ . ", "page_idx": 17}, {"type": "text", "text": "Lemma A.10. During any round in batch $k$ of Algorithm 1, and for an absolute constant c, we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\left|\\mu\\left(\\langle x^{*},\\theta^{*}\\rangle\\right)-\\mu\\left(\\langle x,\\theta^{*}\\rangle\\right)\\right|\\right]\\leq c\\left(\\frac{\\phi(\\lambda)d^{2}}{\\sqrt{\\tau_{1}\\;\\tau_{k-1}}}+\\frac{\\gamma(\\lambda)}{\\sqrt{\\tau_{k-1}}}\\left(\\frac{d}{\\sqrt{\\hat{\\kappa}}}\\wedge\\sqrt{\\frac{d\\log d}{\\kappa^{*}}}\\right)\\right)\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. The proof here invokes Lemma A.9. We begin by noting that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{x\\underset{y\\in\\mathbb{Z}^{\\star}}{\\mathbb{E}}\\underset{y\\in\\{x,x^{\\star}\\}}{\\sum}\\|y\\|_{\\mathbf{v}-1}\\leq4\\,\\underset{x^{\\star}\\geq P_{k}}{\\mathbb{E}}\\left[\\frac{\\operatorname*{max}}{x\\in\\mathcal{X}}\\left\\|x\\right\\|_{\\mathbf{v}-1}\\underset{x\\in\\mathcal{X}}{\\operatorname*{max}}\\left\\|\\tilde{x}\\right\\|_{\\mathbf{H}_{k-1}^{-1}}\\right]}\\\\ &{\\qquad\\qquad\\leq4\\sqrt{\\underset{x\\in\\mathcal{Y}_{h}}{\\mathbb{E}}\\left[\\underset{x\\in\\mathcal{X}}{\\operatorname*{max}}\\left\\|x\\right\\|_{\\mathbf{v}-1}^{2}\\right]}\\underset{x\\in\\mathcal{Y}_{h}}{\\mathbb{E}}\\left[\\underset{\\mathrm{tament~infity}}{\\operatorname*{max}}\\right]}\\\\ &{\\qquad\\qquad\\leq4\\sqrt{\\underset{x\\in\\mathcal{Y}_{h}}{\\mathbb{E}}\\left[\\underset{y\\in\\mathcal{X}}{\\operatorname*{max}}\\left\\|x\\right\\|_{\\mathbf{v}-1}^{2}\\right]}\\underset{x\\in\\mathcal{Y}_{h-1}}{\\mathbb{E}}\\left[\\underset{\\mathrm{tament~infity}}{\\operatorname*{max}}\\right]}\\\\ &{\\qquad\\qquad\\leq c\\left(\\sqrt{\\underset{\\tau\\leq P}{\\mathbb{E}}\\left[\\underset{\\tau\\leq P}{\\operatorname*{max}}\\left\\|x\\right\\|_{\\mathbf{v}-1}^{2}\\right]}\\underset{x\\in\\mathcal{Y}_{h-1}}{\\mathbb{E}}\\left[\\underset{\\mathrm{tament~infity}}{\\operatorname*{max}}\\right]\\right)}\\\\ &{\\qquad\\qquad\\leq c\\left(\\sqrt{\\underset{\\tau\\leq1}{\\mathbb{H}}^{2}\\cdot\\frac{d^{2}}{\\tau_{k-1}}}\\right)\\qquad\\qquad\\qquad\\mathrm{(using~Lemma~A.17)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We also have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{x\\sim\\mathcal{D}_{k}}{\\mathbb{E}}\\left[\\sqrt{\\dot{\\mu}\\left(\\left\\langle x^{*},\\theta^{*}\\right\\rangle\\right)}\\left(\\left\\lVert\\tilde{x}^{*}\\right\\rVert_{{\\mathbf{H}_{k-1}}}+\\left\\lVert\\tilde{x}\\right\\rVert_{{\\mathbf{H}_{k-1}}}\\right)\\right]}\\\\ &{\\leq2\\underset{x\\sim\\mathcal{D}_{k}}{\\mathbb{E}}\\left[\\sqrt{\\dot{\\mu}\\left(\\left\\langle x^{*},\\theta^{*}\\right\\rangle\\right)}\\underset{x\\in\\mathcal{X}}{\\operatorname*{max}}\\left\\lVert x\\right\\rVert_{{\\mathbf{H}_{k-1}^{-1}}}\\right]}\\\\ &{\\leq2\\operatorname*{min}\\left\\{\\sqrt{\\kappa^{*}}_{\\chi\\sim\\mathcal{D}_{k}}\\left[\\underset{x\\in\\mathcal{X}}{\\operatorname*{max}}\\left\\lVert x\\right\\rVert_{{\\mathbf{H}_{k-1}^{-1}}}\\right],\\sqrt{\\underset{x\\sim\\mathcal{D}_{k}}{\\mathbb{E}}\\left[\\dot{\\mu}\\left(\\left\\langle x^{*},\\theta^{*}\\right\\rangle\\right)\\right]_{\\mathcal{X}\\sim\\mathcal{D}_{k}}\\left[\\left\\lVert x\\right\\rVert_{{\\mathbf{H}_{k-1}^{-1}}}^{2}\\right]\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\leq c\\left(\\sqrt{\\frac{d\\log d}{\\kappa^{*}\\tau_{k-1}}}\\wedge\\sqrt{\\frac{d^{2}}{\\widehat{\\kappa}\\tau_{k-1}}}\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Substituting the above bounds in Lemma A.9 we obtained the stated inequality. This completes the proof. \u53e3 ", "page_idx": 18}, {"type": "text", "text": "A.4 Proof of Theorem 3.2 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We trivially upper bound the regret incurred during the warm-up batch as $\\tau_{1}R$ ; recall that $R$ denotes the upper bound on the rewards and $\\tau_{1}$ denotes the length of the first (warm-up) batch; see equation (5)). ", "page_idx": 18}, {"type": "text", "text": "For each batch $k$ and an absolute constant $c$ , Lemma A.10 gives us ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\left[\\displaystyle\\sum_{t\\in\\mathcal{T}_{k}}\\mu\\left(\\langle x_{t}^{*},\\theta^{*}\\rangle\\right)-\\mu\\left(\\langle x_{t},\\theta^{*}\\rangle\\right)\\right]\\leq\\tau_{k}\\cdot c\\left(\\frac{\\phi(\\lambda)d^{2}}{\\sqrt{\\tau_{1}\\tau_{k-1}}}+\\frac{\\gamma(\\lambda)}{\\sqrt{\\tau_{k-1}}}\\left(\\frac{d}{\\sqrt{\\hat{\\kappa}}}\\wedge\\sqrt{\\frac{d\\log d}{\\kappa^{*}}}\\right)\\right)}&{{}}\\\\ {\\leq c\\left(\\frac{\\phi(\\lambda)d^{2}}{\\sqrt{\\tau_{1}}}\\alpha+\\left(\\frac{d}{\\sqrt{\\hat{\\kappa}}}\\wedge\\sqrt{\\frac{d\\log d}{\\kappa^{*}}}\\right)\\gamma(\\lambda)\\alpha\\right)}&{{}(\\mathrm{vial}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Since there are at most $\\log\\log T$ batches, we can upper bound the regret as ", "page_idx": 18}, {"type": "equation", "text": "$$\nR_{T}\\leq c\\left(\\tau_{1}R+\\frac{\\phi(\\lambda)d^{2}}{\\sqrt{\\tau_{1}}}\\alpha+\\left(\\frac{d}{\\sqrt{\\hat{\\kappa}}}\\wedge\\sqrt{\\frac{d\\log d}{\\kappa^{*}}}\\right)\\gamma(\\lambda)\\alpha\\right)\\log\\log(T)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Setting $\\begin{array}{r}{\\tau_{1}=\\left(\\frac{\\phi(\\lambda)d^{2}\\alpha}{R}\\right)^{2/3}}\\end{array}$ we get ", "page_idx": 18}, {"type": "equation", "text": "$$\nR_{T}\\leq O\\left(\\left(\\frac{\\phi(\\lambda)d^{2}\\alpha}{R}\\right)^{2/3}+\\left(\\frac{d}{\\sqrt{\\hat{\\kappa}}}\\wedge\\sqrt{\\frac{d\\log d}{\\kappa^{*}}}\\right)\\gamma(\\lambda)\\alpha\\right)\\log\\log(T)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Now with the choice of $\\lambda=20d R\\log T$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\gamma(\\lambda)\\leq\\gamma\\quad\\mathrm{~where~}\\gamma=30R S\\sqrt{d\\log T}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Substituting \u03b1 = T2(1\u22122\u2212M) and \u03d5(\u03bb) = \u03ba eS3S \u03b32 we get ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathfrak{L}_{T}\\le O\\left(\\left(\\sqrt{\\kappa}d^{3}\\,e^{3S}\\,R S T^{\\frac{1}{2(1-2^{-M})}}\\log T\\right)^{2/3}+\\left(\\frac{d}{\\sqrt{\\kappa}}\\wedge\\sqrt{\\frac{d\\log d}{\\kappa^{*}}}\\right)R S T^{\\frac{1}{2(1-2^{-M})}}\\sqrt{d\\log T}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "A.5 Optimal Design Guarantees ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In this section, we study the optimal design policies utilized in different batches of the algorithm. Specifically, $\\pi_{G}$ denotes the G-OPTIMAL DESIGN policy applied during the warm-up batch, while $\\pi_{k}$ refers to the DISTRIBUTIONAL OPTIMAL DESIGN policy calculated at the end of batch $k$ ( and used in the $(k+1)^{t h}$ batch). Recall that the distribution of the remaining arms after the elimination step ( $\\mathcal{X}$ in line 10 of the Algorithm) is represented as $\\mathcal{D}_{k}$ . We define expected design matrices for each policy: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{W}_{G}:=\\underset{x\\sim\\mathcal{D}}{\\mathbb{E}}\\left[\\underset{x\\sim\\pi_{G}(\\boldsymbol{x})}{\\mathbb{E}}\\left[x\\boldsymbol{x}^{\\mathsf{T}}|\\boldsymbol{\\mathcal{X}}\\right]\\right]}\\\\ {\\mathbf{W}_{k}:=\\underset{x\\sim\\mathcal{D}_{k}}{\\mathbb{E}}\\left[\\underset{x\\sim\\pi_{k}(\\boldsymbol{x})}{\\mathbb{E}}\\left[\\widetilde{x}\\widetilde{\\boldsymbol{x}}^{\\mathsf{T}}|\\boldsymbol{\\mathcal{X}}\\right]\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Recall, for all batches starting from the second batch $(k\\ \\geq\\ 2)$ , we employ the scaled arm set, denoted as $\\widetilde{\\chi}$ , for learning and action selection under the DISTRIBUTIONAL OPTIMAL DESIGN policy. However, during the initial warm-up batch, we utilize the original, unscaled arm set. ", "page_idx": 19}, {"type": "text", "text": "Claim A.11. The following holds for any positive semidefinite matrix A and any batch $k$ - ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\underset{\\mathcal{X}\\sim\\mathcal{D}_{k}}{\\mathbb{E}}\\operatorname*{max}_{x\\in\\mathcal{X}}\\left\\|x\\right\\|_{A}\\leq\\underset{\\mathcal{X}\\sim\\mathcal{D}_{j}}{\\mathbb{E}}\\operatorname*{max}_{x\\in\\mathcal{X}}\\left\\|x\\right\\|_{A}\\quad\\forall j\\in[k-1].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "This is due to the fact that the set of surviving arms in batch $k$ is always a smaller set than the previous batches. ", "page_idx": 19}, {"type": "text", "text": "Lemma A.12 (Lemma 4 [23]). The expected data matrix $\\mathbf{W}_{G}$ satisfies. We have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\underset{\\chi\\sim\\mathcal{D}}{\\mathbb{E}}\\left[\\underset{x\\in\\mathcal{X}}{\\mathrm{max}}\\;\\|x\\|_{\\mathbf{W}_{G}^{-1}}^{2}\\right]\\leq d^{2}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Lemma A.13 (Theorem 5 [23]). Let the DISTRIBUTIONAL OPTIMAL DESIGN $\\pi$ which has been learnt from s independent samples $\\mathcal{X}_{1},...\\,\\mathcal{X}_{s}\\,\\sim\\,\\mathcal{D}$ and let W denote the expected data matrix, $\\mathbf{W}=\\overset{*}{\\mathbb{E}}_{\\mathcal{X}\\sim\\mathcal{D}}\\left[\\mathbb{E}_{x\\sim\\mathcal{\\hat{\\pi}}(\\mathcal{X})}\\left[x x^{\\mathsf{T}}|\\mathcal{X}\\right]\\right]$ . We have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left\\{\\underset{x\\sim\\mathcal{D}}{\\mathbb{E}}\\left[\\underset{x\\in\\mathcal{X}}{\\operatorname*{max}}\\;\\|x\\|_{\\mathbf{W}^{-1}}\\right]\\leq O\\left(\\sqrt{d\\log d}\\right)\\right\\}\\geq1-\\exp\\left(O\\left(d^{4}\\log^{2}d\\right)-s d^{-12}\\cdot2^{-16}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Lemma A.14. Under the notation of Lemma A.13, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\underset{\\chi\\sim\\mathcal{D}}{\\mathbb{E}}\\left[\\underset{x\\in\\mathcal{X}}{\\operatorname*{max}}\\;\\|x\\|_{\\mathbf{W}^{-1}}^{2}\\right]\\leq2d^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. Recall that the DISTRIBUTIONAL OPTIMAL DESIGN policy samples according to the $\\pi_{G}$ policy with half probability. Hence, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbf{W}=\\underset{x\\sim\\mathcal{D}_{k}}{\\mathbb{E}}\\left[\\underset{x\\sim\\pi(x)}{\\mathbb{E}}\\left[x x^{\\mathsf{T}}|\\boldsymbol{\\mathcal{X}}\\right]\\right]\\succeq\\underset{x\\sim\\mathcal{D}_{k}}{\\mathbb{E}}\\left[\\frac{1}{2}\\underset{x\\sim\\pi\\alpha(\\boldsymbol{\\mathcal{X}})}{\\mathbb{E}}\\left[x x^{\\mathsf{T}}|\\boldsymbol{\\mathcal{X}}\\right]\\right]=\\frac{1}{2}\\mathbf{W}_{G}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\underset{x\\sim\\mathcal{D}}{\\mathbb{E}}\\left[\\underset{x\\in\\mathcal{X}}{\\operatorname*{max}}~\\|x\\|_{\\mathbf{W}^{-1}}^{2}\\right]\\le2\\underset{x\\sim\\mathcal{D}}{\\mathbb{E}}\\left[\\underset{x\\in\\mathcal{X}}{\\operatorname*{max}}~\\|x\\|_{\\mathbf{W}^{-1}}^{2}\\right]\\le2d^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Lemma A.15 (Matrix Chernoff [27, 23]). Let $x_{1},x_{3},\\ldots,x_{n}\\sim{\\cal D}$ be vectors, with $\\|\\boldsymbol{x}_{t}\\|\\leq1$ , then we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left\\{3\\varepsilon n\\mathbf{I}+\\sum_{i=1}^{n}x_{i}x_{i}^{\\top}\\succeq\\frac{n}{8}\\mathbf{\\Sigma}_{x\\sim\\mathcal{D}}^{\\mathbb{E}}\\left[x x^{\\top}\\right]\\right\\}\\geq1-2d\\exp\\left(\\frac{-\\varepsilon n}{8}\\right)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Corollary A.16. In Algorithm 1 the warm-up matrix $\\mathbf{V}$ , with $\\lambda\\geq16\\log\\left(T d\\right)$ , satisfies the following with probability greater than $\\textstyle1-{\\frac{1}{T^{2}}}$ . ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbf{V}\\succeq\\frac{\\tau_{1}}{8}\\underset{x\\sim\\mathcal{D}}{\\mathbb{E}}\\underset{x\\sim\\pi_{G}(\\mathcal{X})}{\\mathbb{E}}\\,x x^{\\mathsf{T}}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Similarly $\\mathbf{H}_{k}$ , with $\\lambda\\,\\geq\\,6\\log\\left(T d\\right)$ satisfies the following for each batch $k\\geq2$ with probability greater than $\\textstyle1-{\\frac{1}{T^{2}}}$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbf{H}_{k}\\succeq\\frac{\\tau_{k}}{8}\\underset{\\boldsymbol{x}\\sim\\mathcal{D}_{k}}{\\mathbb{E}}\\underset{\\boldsymbol{x}\\sim\\pi_{G}(\\boldsymbol{x})}{\\mathbb{E}}\\pi\\widetilde{\\boldsymbol{x}}^{\\mathsf{T}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. The results for both $\\mathbf{V}$ and ${\\mathbf{H}}_{k}$ are obtained directly by applying Lemma A.15 with $\\begin{array}{r}{\\varepsilon=\\frac{\\log(T)}{\\tau_{1}}}\\end{array}$ and $\\begin{array}{r}{\\varepsilon=\\frac{\\log(T)}{\\tau_{k}}}\\end{array}$ , respectively. \u53e3 ", "page_idx": 20}, {"type": "text", "text": "We note that the analysis of [23] gives an optimal guarantee (in expectation) on $\\|{\\boldsymbol{x}}\\|_{\\mathbf{V}}$ , but not on $\\|{\\boldsymbol{x}}\\|_{\\mathbf{V}}^{2}$ . We obtain such a bound here and use it in the analysis. ", "page_idx": 20}, {"type": "text", "text": "Lemma A.17. The following holds with probability greater than $\\textstyle1-{\\frac{1}{T^{2}}}$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{x\\sim\\mathcal{D}}{\\mathbb{E}}\\operatorname*{max}_{x\\in\\mathcal{X}}\\left\\|x\\right\\|_{\\mathbf{V}^{-1}}^{2}\\leq O\\left(\\frac{d^{2}}{\\tau_{1}}\\right)}&{}\\\\ {\\underset{x\\sim\\mathcal{D}_{k}}{\\mathbb{E}}\\operatorname*{max}_{x\\in\\mathcal{X}}\\left\\|\\widetilde{x}\\right\\|_{\\mathbf{H}^{-1}}^{2}\\leq O\\left(\\frac{d^{2}}{\\tau_{k}}\\right)}&{\\forall k\\in\\left[M\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We also have that for sufficiently large $T\\gtrsim O\\left(d^{32}(\\log2T)^{2}\\right)$ , the following holds with probability greater than $1-{\\frac{\\log\\log T}{T}}$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\underset{\\chi\\sim\\mathcal{D}_{k}}{\\mathbb{E}}\\operatorname*{max}_{x\\in\\mathcal{X}}\\|\\widetilde{x}\\|_{\\mathbf{H}_{k}^{-1}}\\leq O\\left(\\sqrt{\\frac{d}{\\tau_{k}}}\\right)\\quad\\forall k\\in[M]\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. First, we note from Corollary A.16 that the following holds with high probability ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\|x\\|_{\\mathbf{V}^{-1}}\\leq\\frac{8}{\\tau_{1}}\\,\\|x\\|_{\\mathbf{W}_{G}^{-1}}}\\\\ {\\displaystyle\\|\\widetilde{x}\\|_{\\mathbf{H}_{k}^{-1}}\\geq\\frac{8}{\\tau_{1}}\\,\\|\\widetilde{x}\\|_{\\mathbf{W}_{k}^{-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We obtain the first to inequalities, (18) an\u221ad (19), by a direct use of Corollary A.16. For (20) we note that for every phase we have at least $O({\\sqrt{T}})$ samples for learning the DISTRIBUTIONAL OPTIMAL DESIGN policy (for any M). Since, $T\\,\\geq\\,d^{32}\\log2T^{2}$ the event stated in Lemma A.13 holds with probability greater than 1 \u2212T1 2 . \u53e3 ", "page_idx": 20}, {"type": "text", "text": "B Regret Analysis of RS-GLinCB ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Recall $\\mathcal{T}_{o}$ denotes the set of rounds when switching criterion I is satisfied. We write $\\tau_{o}$ to denote the size of the set $\\tau_{o}=|\\mathcal{T}_{o}|$ . We define the following (scaled) data matrix ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbf{H}_{w}^{*}=\\sum_{s\\in\\mathcal{T}_{o}}\\dot{\\mu}\\left(\\left\\langle x_{s},\\theta^{*}\\right\\rangle\\right)x_{s}x_{s}^{\\intercal}+\\lambda\\mathbf{I}\\;.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We will specify the regularizer $\\lambda$ later. We also define ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\gamma:=\\mathbf{c}.R S\\sqrt{d\\log\\frac{T}{\\delta}}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Below, we state the main concentration bound used in the proof. ", "page_idx": 20}, {"type": "text", "text": "Lemma B.1 (Theorem 1 of [6]). Let $\\{\\mathcal{F}_{t}\\}_{t=1}^{\\infty}$ be a flitration. Let $\\{x_{t}\\}_{t=1}^{\\infty}$ be a stochastic process in $B_{1}(d)$ such that $x_{t}$ is $\\mathcal{F}_{t}$ measurable. Let $\\{\\eta_{t}\\}_{t=1}^{\\infty}$ be a martingale difference sequence such that $\\eta_{t}$ is $\\mathcal{F}_{t}$ measurable. Furthermore, assume we have $|\\eta_{t}|\\leq1$ almost surely, and denote $\\sigma_{t}^{2}=\\mathbb{V}[\\eta_{t}|\\mathcal{F}_{t}]$ . Let $\\lambda>0$ and for any $t\\geq1$ define: ", "page_idx": 21}, {"type": "equation", "text": "$$\nS_{t}=\\sum_{s=1}^{t-1}\\eta_{s}x_{s}\\qquad\\quad{\\bf H}_{t}=\\sum_{s=1}^{t-1}\\sigma_{s}^{2}x_{s}x_{s}^{\\top}+\\lambda{\\bf I}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Then, for any $\\delta\\in(0,1]$ , ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\exists t\\geq1:\\lVert S_{t}\\rVert_{{\\mathbf H}_{t}^{-1}}\\geq\\frac{\\sqrt{\\lambda}}{2}+\\frac{2}{\\sqrt{\\lambda}}\\log\\left(\\frac{\\operatorname*{det}({\\mathbf H}_{t})^{\\frac{1}{2}}}{\\lambda^{d/2}\\delta}\\right)+\\frac{2}{\\sqrt{\\lambda}}d\\log(2)\\right]\\leq\\delta\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "B.1 Confidence Sets for Switching Criterion I rounds ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Lemma B.2. At any round $t,$ , let $\\widehat{\\theta}_{o}$ be the maximum likelihood estimate calculated using set of rewards observed in the rounds $\\mathcal{T}_{o}$ . With probability at least $1-\\delta$ we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\|\\widehat{\\theta}_{o}-\\theta^{*}\\|_{\\mathbf{H}_{w}^{*}}\\leq\\gamma.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. Let us define the matrix $\\begin{array}{r}{\\mathbf{G}_{w}=\\sum_{s\\in\\mathcal{T}_{o}}\\alpha(x,\\theta^{*},\\widehat{\\theta}_{o})x_{s}x_{s}^{\\sf T}+\\lambda\\mathbf{I}}\\end{array}$ . First, we note that by selfconcordance property of $\\mu$ (Lemma C.2), $\\begin{array}{r}{\\mathbf{G}_{w}\\,\\succeq\\,\\frac{1}{1+2R S}\\mathbf{H}_{w}^{*}}\\end{array}$ . Hence, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left\\lVert\\widehat{\\theta}_{o}-\\theta^{*}\\right\\rVert_{\\mathbf{H}_{\\infty}^{*}}\\leq\\sqrt{1+2R S}\\left\\lVert\\widehat{\\theta}_{o}-\\theta^{*}\\right\\rVert_{\\mathbf{G}_{\\infty}^{*}}}&{}\\\\ {=\\sqrt{1+2R S}\\left\\lVert\\mathbf{G}_{v}\\left(\\widehat{\\theta}_{o}-\\theta^{*}\\right)\\right\\rVert_{\\mathbf{G}_{\\infty}^{*}}}&{}\\\\ {=\\sqrt{1+2R S}\\left\\lVert\\sum_{s\\in\\mathcal{T}_{o}}\\left(\\widehat{\\theta}_{o},x_{s}\\right)-\\left\\langle\\theta^{*},x_{s}\\right\\rangle\\right)\\alpha(x_{s},\\widehat{\\theta}_{o},\\theta^{*})x_{s}+\\widehat{\\lambda}\\widehat{\\theta}_{o}-\\lambda_{t}\\theta^{*}\\right\\rVert_{\\mathbf{G}_{\\infty}^{*1}}}\\\\ {=\\sqrt{1+2R S}\\left\\lVert\\sum_{s\\in\\mathcal{T}_{o}}\\left(\\mu\\left(\\widehat{\\theta}_{o},x_{s}\\right)\\right)-\\mu\\left(\\left\\langle\\theta^{*},x_{s}\\right\\rangle\\right)x_{s}+\\widehat{\\lambda}\\widehat{\\theta}_{o}-\\lambda_{t}\\theta^{*}\\right\\rVert_{\\mathbf{G}_{\\infty}^{*1}}}\\\\ &{\\qquad+\\left(1+2R S\\right)\\left\\lVert\\sum_{s\\in\\mathcal{T}_{o}}\\left(\\mu\\left(\\widehat{\\theta}_{o},x_{s}\\right)\\right)-\\mu\\left(\\left\\langle\\theta^{*},x_{s}\\right\\rangle\\right)x_{s}+\\widehat{\\lambda}\\widehat{\\theta}_{o}-\\lambda_{t}\\theta^{*}\\right\\rVert_{\\mathbf{G}_{\\infty}^{*1}}}\\\\ {\\leq\\left(1+2R S\\right)\\left\\lVert\\sum_{s\\in\\mathcal{T}_{o}}\\left(\\mu\\left(\\widehat{\\theta}_{o},x_{s}\\right)\\right)-\\mu\\left(\\left\\langle\\theta^{*},x_{s}\\right\\rangle\\right)\\right\\rVert_{s}}&{\\leq\\widehat{\\lambda}\\widehat{\\theta}_{o}-\\lambda_{s}\\theta^{*}\\right\\rVert_{\\mathbf{H}_{\\infty}^{*1}}}\\\\ {\\qquad+\\left(\\mathbb{G}_{u}\\left\\lVert\\Sigma_{v}\\right\\rVert_{\\mathbf{G}_{o}}+\\mu\\left(\\widehat{\\theta}_{o},x_{s}\\right)\\right)-\\mu\\left(\\left\\langle\\theta^{*},x_{s}\\right\\rangle\\right)x_{s}+\\widehat{\\lambda}\\widehat{\\theta}_{o}-\\lambda_{t}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Since $\\widehat{\\theta}_{o}$ is the maximum likelihood estimate, by optimality condition, we have the following relation: $\\begin{array}{r}{\\sum_{s\\in\\mathcal{T}_{o}}\\mu\\left(\\langle x_{s},\\widehat{\\theta}_{o}\\rangle\\right)x_{s}+\\lambda\\widehat{\\theta}_{o}=\\sum_{s\\in\\mathcal{T}_{o}}r_{s}x_{s}}\\end{array}$ . Substituting this above, we get ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\left\\lVert\\widehat{\\theta}_{o}-\\theta^{*}\\right\\rVert_{\\mathbf{H}_{w}^{*}}\\leq\\left(1+2R S\\right)\\left\\lVert\\sum_{s\\in\\mathcal{T}_{o}}\\left(r_{s}-\\mu\\left(\\left\\langle\\theta^{*},x_{s}\\right\\rangle\\right)\\right)x_{s}-\\lambda\\theta^{*}\\right\\rVert_{\\mathbf{H}_{w}^{s-1}}}\\\\ &{\\qquad\\qquad\\leq\\left(1+2R S\\right)\\left\\lVert\\sum_{s\\in\\mathcal{T}_{o}}\\left(r_{s}-\\mu\\left(\\left\\langle\\theta^{*},x_{s}\\right\\rangle\\right)\\right)x_{s}\\right\\rVert_{\\mathbf{H}_{w}^{*-1}}+\\lambda\\left\\lVert\\theta^{*}\\right\\rVert_{\\mathbf{H}_{w}^{*-1}}}\\\\ &{\\leq\\left(1+2R S\\right)\\left\\lVert\\sum_{s\\in\\mathcal{T}_{o}}\\eta_{s}x_{s}\\right\\rVert_{\\mathbf{H}_{w}^{*-1}}+S\\sqrt{\\lambda}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\eta_{s}:=(r_{s}-\\mu\\left(\\left<\\theta^{*},x_{s}\\right>\\right))$ . ", "page_idx": 21}, {"type": "text", "text": "We will now apply Lemma B.1 \u03b7s scaled by R. First note that    s\u2208To \u03b7sxs  (H\u2217)\u22121 = $\\begin{array}{r}{\\Big\\|\\sum_{s\\in\\mathcal{T}_{o}}\\frac{\\eta_{s}}{R}\\boldsymbol{x}_{s}\\Big\\|_{(R^{2}\\mathbf{H}_{w}^{*})^{-1}}}\\end{array}$ which, in turn ensures that the noise variable is upper bounded by 1. ", "page_idx": 21}, {"type": "text", "text": "Applying B.1 we get ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{\\theta}_{o}-\\theta^{*}\\|_{\\mathbf{H}_{w}^{*}}\\leq S\\sqrt{R^{2}\\lambda}}\\\\ &{\\qquad\\quad+\\left(1+2R S\\right)\\left(\\frac{\\sqrt{R^{2}\\lambda}}{2}+\\frac{2d}{\\sqrt{R^{2}\\lambda}}\\log\\left(1+\\frac{\\tau_{o}}{R^{2}\\lambda d}\\right)+\\frac{2}{\\sqrt{R^{2}\\lambda}}\\log\\left(\\frac{1}{\\delta}\\right)+\\frac{2}{\\sqrt{R^{2}\\lambda}}d\\log(2)\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Simplifying constants and setting\u221aR2\u03bb = c d log(T) + log(1/\u03b4), we have   \u03b8 o \u2212\u03b8\u2217   H\u2217 \u2264 $\\mathbf{c}R S\\sqrt{d\\log(T/\\delta)+\\log(1/\\delta)}\\leq\\mathbf{c}R S\\sqrt{d\\log\\left(T/\\delta\\right)}.$ \u53e3 ", "page_idx": 22}, {"type": "text", "text": "B.2 Confidence Sets for non-Switching Criterion I rounds ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We define $\\mathcal{E}_{w}$ be the event defined in Lemma B.2, that is, $\\mathcal{E}_{w}=\\{\\|\\widehat{\\theta}_{o}-\\theta^{*}\\|_{\\mathbf{H}_{w}^{*}}\\leq\\gamma\\}$ . ", "page_idx": 22}, {"type": "text", "text": "Lemma B.3. If in round $t$ the switching criteria $I$ is not satisfied and the event $\\mathcal{E}_{w}$ holds, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n|\\langle x,\\widehat{\\theta}_{o}-\\theta^{*}\\rangle|\\leq\\frac{1}{R}\\quad\\,f o r\\,a l l\\,x\\in\\mathcal{X}_{t}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\vert\\langle x,\\widehat{\\theta}_{o}-\\theta^{*}\\rangle\\vert\\leq\\Vert x\\Vert_{\\mathbf{H}_{w}^{*-1}}\\cdot\\Vert\\widehat{\\theta}_{o}-\\theta^{*}\\Vert_{\\mathbf{H}_{w}^{*}}}&{}\\\\ {\\leq\\Vert x\\Vert_{\\mathbf{H}_{w}^{*-1}}\\gamma}&{}\\\\ {\\leq\\gamma\\sqrt{\\kappa}\\Vert x\\Vert_{\\mathbf{V}_{w}^{-1}}}&{}\\\\ {\\leq\\gamma\\sqrt{\\kappa}\\frac{1}{\\sqrt{R^{2}\\kappa\\gamma^{2}}}}&{}\\\\ {\\leq\\frac{1}{R}}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "equation", "text": "$$\n(\\mathbf{V}_{w}\\preceq\\kappa\\mathbf{H}_{w}^{*})\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "(warm-up criteria is not satisfied) ", "page_idx": 22}, {"type": "text", "text": "Recall that $\\mathbf{H}_{t}$ is defined in line 14 of Algorithm 2. Further, we define ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbf{H}_{t}^{*}=\\sum_{s\\in[t-1]\\backslash\\mathcal{T}_{o}}\\dot{\\mu}\\left(\\langle x_{s},\\theta^{*}\\rangle\\right)x_{s}x_{s}^{\\sf T}+\\lambda\\mathbf{I}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Corollary B.4. Under event $\\mathcal{E}_{w}$ , $\\mathbf{H}_{t}\\preceq\\mathbf{H}_{t}^{*}\\preceq e^{2}\\mathbf{H}_{t}$ ", "page_idx": 22}, {"type": "text", "text": "Proof. For a given $s\\in[t-1]\\ensuremath{\\,\\backslash\\,}\\mathcal{T}_{o}$ , let $\\widehat{\\theta}_{o}^{s}$ denote the value of $\\widehat{\\theta}_{o}$ in that round. Then, for all $x\\in\\mathcal{X}_{s}$ , by Lemma C.2, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\dot{\\mu}\\left(\\langle x,\\widehat{\\theta}_{o}^{s}\\rangle\\right)\\exp(-R|\\langle x,\\widehat{\\theta}_{o}^{s}-\\theta^{*}\\rangle|)\\leq\\dot{\\mu}\\left(\\langle x,\\theta^{*}\\rangle\\right)\\leq\\dot{\\mu}\\left(\\langle x,\\widehat{\\theta}_{o}^{s}\\rangle\\right)\\exp(R|\\langle x,\\widehat{\\theta}_{o}^{s}-\\theta^{*}\\rangle|)}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Applying lemma B.3, gives $e^{-1}\\dot{\\mu}\\left(\\langle x,\\widehat{\\theta}_{o}^{s}\\rangle\\right)\\leq\\dot{\\mu}\\left(\\langle x,\\theta^{*}\\rangle\\right)\\leq e^{1}\\dot{\\mu}\\left(\\langle x,\\widehat{\\theta}_{o}^{s}\\rangle\\right)$ . Thus, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbf{H}_{t}=\\sum_{s\\in[t-1]\\backslash\\mathcal{T}_{o}}e^{-1}\\dot{\\mu}\\left(\\langle x_{s},\\widehat{\\theta}_{o}^{s}\\rangle\\right)x_{s}x_{s}^{\\intercal}+\\lambda\\mathbf{I}\\preceq\\sum_{s\\in[t-1]\\backslash\\mathcal{T}_{o}}\\dot{\\mu}\\left(\\langle x_{s},\\theta^{*}\\rangle\\right)x_{s}x_{s}^{\\intercal}+\\lambda\\mathbf{I}=\\mathbf{H}_{t}^{*}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "equation", "text": "$\\begin{array}{r}{\\mathbf{H}_{t}^{*}\\preceq\\sum_{s\\in[t-1]\\setminus T_{o}}e^{2}\\frac{\\dot{\\mu}\\left(\\langle x_{s},\\widehat{\\theta}_{o}^{s}\\rangle\\right)}{e}x_{s}x_{s}^{\\sf T}+e^{2}\\lambda\\mathbf{I}=e^{2}\\mathbf{H}_{t}.}\\end{array}$ ", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Recall that $\\tau$ is the round when the Switching Criterion II (Line 9) is satisfied. Now we define the following quantities: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{g_{\\tau}(\\theta)=\\displaystyle\\sum_{s\\in[\\tau-1]\\backslash T_{o}}\\mu\\left(\\langle x_{s},\\theta\\rangle\\right)x_{s}+\\lambda_{\\tau}\\theta}\\\\ &{\\mathbf{H}_{\\tau}(\\theta)=\\displaystyle\\sum_{s\\in[\\tau-1]\\backslash T_{o}}\\hat{\\mu}\\left(\\langle x_{s},\\theta\\rangle\\right)x_{s}x_{s}^{\\top}+\\lambda\\mathbf{I}}\\\\ &{\\qquad\\ominus=\\left\\lbrace\\theta:\\left\\|\\theta-\\widehat{\\theta}_{o}\\right\\|_{\\mathbf{v}}\\le\\gamma\\sqrt{\\kappa}\\right\\rbrace}\\\\ &{\\qquad\\hat{\\theta}=\\displaystyle\\underset{\\theta\\in\\mathbb{R}^{d}}{\\operatorname*{arg\\,min}}\\,\\sum_{s\\in[t-1]\\backslash T_{o}}\\ell(\\theta,x_{s},r_{s})}\\\\ &{\\qquad\\beta:=\\mathbf{c}\\sqrt{d\\log(T/\\delta)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Moreover, recall the following definition $\\widehat{\\theta}_{\\tau}$ : ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\widehat{\\theta}_{\\tau}=\\arg\\operatorname*{min}_{\\theta\\in\\Theta}\\left\\|g_{\\tau}(\\theta)-g_{\\tau}(\\widetilde{\\theta})\\right\\|_{\\mathbf{H}_{\\tau}(\\theta)^{-1}}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Lemma B.5. Under event $\\mathcal{E}_{w},\\left\\|\\widehat{\\theta}_{\\tau}-\\theta^{*}\\right\\|_{\\mathbf{V}}\\leq2\\gamma\\sqrt{\\kappa}$ ", "page_idx": 23}, {"type": "text", "text": "Proof. First, we observe from Lemma B.2 that $\\left\\lVert\\widehat{\\theta}_{o}-\\theta^{*}\\right\\rVert_{\\mathbf{H}_{w}^{*}}\\leq\\gamma$ . Using $\\mathbf{V}\\preceq\\kappa\\mathbf{H}_{w}^{*}$ , we can write $\\left\\|{\\widehat{\\theta}}_{o}-\\theta^{*}\\right\\|_{\\mathbf{v}}\\leq\\gamma{\\sqrt{\\kappa}}$ . This implies that $\\theta^{*}\\in\\Theta$ . Now, $\\widehat{\\theta}_{\\tau}\\in\\Theta$ by virtue of being a feasible solution to the optimization in (21). Thus, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\widehat{\\theta}_{\\tau}-\\theta^{*}\\right\\|_{\\mathbf{V}}=\\left\\|\\widehat{\\theta}_{\\tau}-\\widehat{\\theta}_{o}+\\widehat{\\theta}_{o}-\\theta^{*}\\right\\|_{\\mathbf{V}}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\leq\\left\\|\\widehat{\\theta}_{\\tau}-\\widehat{\\theta}_{o}\\right\\|_{\\mathbf{V}}+\\left\\|\\widehat{\\theta}_{o}-\\theta^{*}\\right\\|_{\\mathbf{V}}}\\\\ &{\\quad\\quad\\quad\\quad\\leq2\\gamma\\sqrt{\\kappa}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Lemma B.6. Let $\\delta\\in(0,1)$ . Then, under event $\\mathcal{E}_{w}$ , with probability $1-\\delta,\\left\\lVert\\widehat{\\theta}_{\\tau}-\\theta^{*}\\right\\rVert_{\\mathbf{H}_{\\tau}^{*}}\\leq\\beta.$ . ", "page_idx": 23}, {"type": "text", "text": "Proof. We have for all rounds $s\\in[\\tau-1]\\backslash\\mathcal{T}_{o}$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\left\\langle x_{s},\\theta^{*}-\\widehat{\\theta}_{\\tau}\\right\\rangle\\right|\\leq\\left\\|x_{s}\\right\\|_{\\mathbf{V}^{-1}}\\left\\|\\theta^{*}-\\widehat{\\theta}_{\\tau}\\right\\|_{\\mathbf{V}}}\\\\ &{\\qquad\\qquad\\leq\\left\\|x_{s}\\right\\|_{\\mathbf{V}^{-1}}2\\gamma\\sqrt{\\kappa}}\\\\ &{\\qquad\\qquad\\leq2\\gamma\\sqrt{\\kappa}\\displaystyle\\frac{1}{R\\gamma\\sqrt{\\kappa}}}\\\\ &{\\qquad\\qquad=\\displaystyle\\frac{2}{R}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "(warm up criterion not satisfied) ", "page_idx": 23}, {"type": "text", "text": "Also note that $\\theta^{*}\\in\\Theta$ . Hence, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\left\\|\\widehat{\\theta}_{\\tau}-\\theta^{*}\\right\\|_{\\mathbf{H}_{\\tau}^{*}}\\leq2(1+2)\\left\\|g_{\\tau}(\\theta^{*})-\\sum_{s\\in[\\tau-1]}r_{s}x_{s}\\right\\|_{\\mathbf{H}^{*}-1}}}\\\\ &{\\leq6\\mathbf{c}\\sqrt{d\\log(T/\\delta)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Let the event in lemma B.6 be denoted by $\\mathcal{E}_{\\tau}$ , or in other words, $\\mathcal{E}_{\\tau}=\\{\\|\\widehat{\\theta}_{\\tau}-\\theta^{*}\\|_{\\mathbf{H}_{\\tau}^{*}}\\leq\\beta\\}$ . ", "page_idx": 23}, {"type": "text", "text": "B.3 Bounding the instantaneous regret ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In this subsection, we will only consider rounds $t\\in[T]$ which does not satisfy Switching Criterion I. Let $x_{t}\\in\\mathcal X_{t}$ be the played arm defined via line 13 Algorithm 2. Further, let $x_{t}^{*}\\in\\mathcal{X}_{t}$ be the best available arm in that round. ", "page_idx": 24}, {"type": "text", "text": "Corollary B.7. Under the event $\\mathcal{E}_{\\tau}$ , for all $x\\in\\mathcal{X}_{t}$ , we have, $|\\langle x,\\widehat{\\theta}_{\\tau}-\\theta^{*}\\rangle|\\leq\\beta\\|x\\|_{\\mathbf{H}_{\\tau}^{-1}}$ . ", "page_idx": 24}, {"type": "text", "text": "Proof. ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\langle x,\\widehat{\\theta}_{\\tau}-\\theta^{*}\\rangle|\\leq\\|x\\|_{\\mathbf H_{\\tau}^{*-1}}\\cdot\\|\\widehat{\\theta}_{\\tau}-\\theta^{*}\\|_{\\mathbf H_{\\tau}^{*}}}\\\\ &{\\leq\\beta\\|x\\|_{\\mathbf H_{\\tau}^{*-1}}}\\\\ &{\\leq\\beta\\|x\\|_{\\mathbf H_{\\tau}^{-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Lemma B.8. Under event $\\mathcal{E}_{\\tau}$ $,\\left\\langle x_{t}^{*}-x_{t},\\theta^{*}\\right\\rangle\\leq2\\sqrt{2}\\beta\\left\\lVert x_{t}\\right\\rVert_{\\mathbf{H}_{t}^{*-1}}$ . ", "page_idx": 24}, {"type": "text", "text": "Proof. ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\left\\langle x_{t}^{*},\\theta^{*}\\right\\rangle-\\left\\langle x_{t},\\theta^{*}\\right\\rangle\\leq\\left(\\left\\langle x_{t}^{*},\\widehat{\\theta}_{\\tau}\\right\\rangle+\\beta\\left\\Vert x_{t}^{*}\\right\\Vert_{\\mathbf H_{t}^{*-1}}\\right)-\\left(\\left\\langle x_{t},\\widehat{\\theta}_{\\tau}\\right\\rangle-\\beta\\left\\Vert x_{t}\\right\\Vert_{\\mathbf H_{t}^{*-1}}\\right)}&{\\left(\\mathrm{by~Corollary~B.7}\\right)}\\\\ &{\\leq\\left(\\left\\langle x_{t},\\widehat{\\theta}_{\\tau}\\right\\rangle+\\beta\\left\\Vert x_{t}\\right\\Vert_{\\mathbf H_{\\tau}^{*-1}}\\right)-\\left(\\left\\langle x_{t},\\widehat{\\theta}_{\\tau}\\right\\rangle-\\beta\\left\\Vert x_{t}\\right\\Vert_{\\mathbf H_{\\tau}^{*-1}}\\right)}&\\\\ &{\\qquad\\qquad\\qquad=2\\beta\\left\\Vert x_{t}\\right\\Vert_{\\mathbf H_{\\tau}^{*-1}}}&\\\\ &{\\leq2\\sqrt{2}\\beta\\left\\Vert x_{t}\\right\\Vert_{\\mathbf H_{t}^{*-1}}}&{\\left(\\mathrm{Lemma~B.13,~}\\frac{\\operatorname*{det}\\left\\Vert\\mathbf H_{\\tau}^{*-1}\\right\\rangle}{\\operatorname*{det}\\left\\langle\\mathbf H_{\\tau}^{*-1}\\right\\rangle}=\\frac{\\operatorname*{det}\\left\\Vert\\mathbf H_{t}\\right\\Vert}{\\operatorname*{det}\\left\\langle\\mathbf H_{\\tau}\\right\\rangle}\\right)\\leq2}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Lemma B.9. The arm set $\\ensuremath{\\mathcal{X}}_{t}^{\\prime}$ obtained after eliminating arms from $\\textstyle{\\mathcal{X}}_{t}$ (line $^{12}$ Algorithm 2), under event $\\mathcal{E}_{w}$ , satisfies: (a) $x_{t}^{*}\\in\\mathcal{X}_{t}$ , (b) $\\left<x_{t}^{*}-x_{t},\\theta^{*}\\right>\\leq\\frac{4}{R}$ ", "page_idx": 24}, {"type": "text", "text": "Proof. Suppose $x^{\\prime}=\\arg\\operatorname*{max}_{x\\in\\mathcal{X}_{t}}L C B_{o}(x)$ . Now, we have, for all $x\\in\\mathcal{X}_{t}$ , ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\left\\langle x,\\widehat{\\theta}_{o}-\\theta^{*}\\right\\rangle\\right|\\leq\\left\\lVert x\\right\\rVert_{\\mathbf{H}_{w}^{*-1}}\\left\\lVert\\widehat{\\theta}_{o}-\\theta^{*}\\right\\rVert_{\\mathbf{H}_{w}^{*}}}\\\\ &{\\qquad\\qquad\\leq\\gamma\\left\\lVert x\\right\\rVert_{\\mathbf{H}_{w}^{*-1}}}\\\\ &{\\qquad\\qquad\\leq\\gamma\\sqrt{\\kappa}\\left\\lVert x\\right\\rVert_{\\mathbf{V}^{-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Thus, $\\begin{array}{r}{U C B_{o}(x_{t}^{*})=\\langle x_{t}^{*},\\widehat{\\theta}_{o}\\rangle+\\gamma\\sqrt{\\kappa}\\left\\|x_{t}^{*}\\right\\|_{\\mathbf{V}^{-1}}\\geq\\langle x_{t}^{*},\\theta^{*}\\rangle\\geq\\langle x^{\\prime},\\theta^{*}\\rangle\\geq\\langle x^{\\prime},\\widehat{\\theta}_{o}\\rangle-\\gamma\\sqrt{\\kappa}\\left\\|x^{\\prime}\\right\\|_{\\mathbf{V}^{-1}}=0}\\end{array}$ $L C B_{o}(x^{\\prime})$ , where the se cond inequality is due to optimality of $\\boldsymbol{x}_{t}^{*}$ . Henc e, $\\boldsymbol{x}_{t}^{*}$ is not eliminated, implying $\\bar{x}_{t}^{*}\\in\\mathcal{X}_{t}^{\\prime}$ . This completes the proof of (a). ", "page_idx": 24}, {"type": "text", "text": "Since $x_{t}$ is also in $\\ensuremath{\\mathcal{X}}_{t}^{\\prime}$ (by definition), ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{U C B_{o}(x_{t})=\\langle x_{t},\\widehat{\\theta}_{o}\\rangle+\\gamma\\sqrt{\\kappa}\\left\\|x_{t}\\right\\|_{\\mathbf{V}^{-1}}\\geq\\langle x^{\\prime},\\widehat{\\theta}_{o}\\rangle-\\gamma\\sqrt{\\kappa}\\left\\|x^{\\prime}\\right\\|_{\\mathbf{V}^{-1}}}&{}\\\\ {\\geq\\langle x_{t}^{*},\\widehat{\\theta}_{o}\\rangle-\\gamma\\sqrt{\\kappa}\\left\\|x_{t}^{*}\\right\\|_{\\mathbf{V}^{-1}}}&{\\ (x^{\\prime}\\operatorname{has}\\operatorname*{max}L C B_{o}(\\cdot))}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Ag\u221aain, using the fact that $\\begin{array}{r l r}{\\langle x_{t}^{*},\\widehat{\\theta}_{o}\\rangle\\!}&{{}\\ge}&{\\!\\langle x_{t}^{*},\\theta^{*}\\rangle\\;-\\;\\gamma\\sqrt{\\kappa}\\,\\|x_{t}^{*}\\|_{\\mathbf{V}^{-1}}}\\end{array}$ and $\\langle x_{t},\\widehat{\\theta}_{o}\\rangle\\;\\;\\leq\\;\\;\\langle x_{t},\\theta^{*}\\rangle\\;+$ $\\gamma\\sqrt{\\kappa}\\,\\|x_{t}\\|_{\\mathbf{V}^{-1}}$ , we obtain, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\langle x_{t},\\theta^{*}\\rangle+2\\gamma\\sqrt{\\kappa}\\left\\|x_{t}\\right\\|_{\\mathbf{V}^{-1}}\\geq\\langle x_{t}^{*},\\theta^{*}\\rangle-2\\gamma\\sqrt{\\kappa}\\left\\|x_{t}^{*}\\right\\|_{\\mathbf{V}^{-1}}}\\\\ {\\mathrm{which~gives~us,~}~~\\langle x_{t}^{*}-x_{t},\\theta^{*}\\rangle\\leq2\\gamma\\sqrt{\\kappa}\\left\\|x_{t}\\right\\|_{\\mathbf{V}^{-1}}+2\\gamma\\sqrt{\\kappa}\\left\\|x_{t}^{*}\\right\\|_{\\mathbf{V}^{-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Finally, since Switching Criterion I is not satisfied in this round, \u2225x\u2225V\u22121 < R\u03b31\u221a\u03ba for all $x\\in\\mathcal{X}_{t}$ . Plugging this above, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\langle x_{t}^{*}-x_{t},\\theta^{*}\\rangle\\leq\\frac{4}{R}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "B.4 Proof of Theorem 4.2 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In this subsection, we complete the proof of the regret bound of RS-GLinCB(Algorithm 2). We first restate Theoreom 4.2 and then prove it. For every round $t\\in[T]$ , we use $x_{t}\\in\\mathcal X_{t}$ to denote the arm played by the algorithm and $\\boldsymbol{x}_{t}^{*}$ to denote the best available arm in that round. ", "page_idx": 25}, {"type": "text", "text": "Theorem B.10 (Theorem 4.2). Given $\\delta\\in(0,1)$ , with probability $\\geq1-\\delta$ , the regret of RS-GLinCB (Algorithm 2) satisfies $\\begin{array}{r}{\\mathbf{R}_{T}=O\\big(d\\sqrt{\\sum_{t\\in[T]}\\dot{\\mu}\\left(\\langle x_{t}^{*},\\theta^{*}\\rangle\\right)}\\log\\left(R T/\\delta\\right)+\\,\\kappa d^{2}R^{5}S^{2}\\log^{2}\\left(T/\\delta\\right)\\big)}\\end{array}$ . ", "page_idx": 25}, {"type": "text", "text": "Proof. Firstly, we will assume throughout the proof that $\\mathcal{E}_{w}\\cap\\mathcal{E}_{\\tau}$ holds, which happens with probability at least $1-\\delta$ . Thus, regret of Algorithm 2 is upper bounded as: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbf{R}_{T}=\\sum_{t\\in[T]}\\mu\\left(\\langle x_{t}^{*},\\theta^{*}\\rangle\\right)-\\mu\\left(\\langle x_{t},\\theta^{*}\\rangle\\right)}}\\\\ &{\\leq R\\tau_{o}+\\displaystyle\\sum_{t\\in[T]\\backslash T_{o}}\\mu\\left(\\langle x_{t}^{*},\\theta^{*}\\rangle\\right)-\\mu\\left(\\langle x_{t},\\theta^{*}\\rangle\\right)}&{\\mathrm{(Upper~bound~of~}R\\mathrm{~for~rounds~in~}\\mathcal{T}_{o})}\\\\ &{\\leq\\mathbf{c}R^{3}\\kappa\\gamma^{2}\\log(T/\\delta)+\\displaystyle\\sum_{t\\in[T]\\backslash T_{o}}\\dot{\\mu}(z)\\langle x_{t}^{*}-x_{t},\\theta^{*}\\rangle}\\\\ &{\\leq\\mathrm{).}}&{\\mathrm{(some~}z\\in[\\langle x_{t},\\theta^{*}\\rangle,\\langle x_{t}^{*},\\theta^{*}\\rangle];\\mathrm{lemma~B.}1]}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Now, let $\\begin{array}{r}{R_{1}(T)\\,=\\,\\sum_{t\\in[T]\\backslash\\mathcal{T}_{o}}\\dot{\\mu}(z)\\langle x_{t}^{*}-x_{t},\\theta^{*}\\rangle}\\end{array}$ . Hereon, we will slightly abuse notation $\\mathbf{H}_{\\tau}$ to denote the $\\mathbf{H}_{\\tau}$ matrix last updated before time $t$ for each time step $t\\in[T]$ . This will be clear from the context as we will only use $\\mathbf{H}_{\\tau}$ term-wise. With this, we upper bound $\\bar{R}_{1}(T)$ as follows: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{1}(\\tau)\\leq\\operatorname*{limsup}_{\\varepsilon\\leq0}\\ \\operatorname*{limsup}_{\\varepsilon\\leq0}}\\\\ &{\\quad\\leq\\operatorname*{limsup}_{\\varepsilon\\leq0}\\sum_{\\tau\\leq t\\leq1}^{\\infty}\\ \\varepsilon(\\varepsilon^{(1/2)}\\varepsilon(\\log(1\\rho_{\\varepsilon}))\\varepsilon(\\log(1\\rho_{\\varepsilon}-\\frac{1}{\\alpha}\\log(1))))}\\\\ &{\\quad\\leq2\\varepsilon^{(1/2)}\\frac{\\sqrt{6}}{1-\\rho}\\left(\\varepsilon^{(1/2)}\\varepsilon(\\log(1\\rho_{\\varepsilon}))\\right)}\\\\ &{\\quad\\leq2\\varepsilon^{(1/2)}\\frac{\\sqrt{6}}{\\rho}\\left(\\varepsilon^{(1/2)}\\varepsilon(\\log(1\\rho_{\\varepsilon}))\\varepsilon^{\\alpha}-\\varepsilon^{(1/2)}\\right)\\varepsilon(\\log(1\\rho_{\\varepsilon}))}\\\\ &{\\quad\\leq2\\varepsilon^{(1/2)}\\frac{\\sqrt{6}}{\\rho}\\frac{\\sqrt{6}}{\\rho}\\left(\\varepsilon^{(1/2)}\\varepsilon^{(1/2)}\\left(\\sqrt{6}\\left(\\varepsilon^{(1/2)}\\right)\\varepsilon(\\log(1\\rho_{\\varepsilon})-\\rho_{\\varepsilon})\\right)\\varepsilon(\\log(1\\right))}\\\\ &{\\quad\\leq32\\varepsilon^{(1/2)}\\frac{\\sqrt{6}}{\\rho}\\frac{\\sqrt{6}}{\\rho}\\left(\\varepsilon^{(1/2)}\\varepsilon^{(1/2)}\\right)\\varepsilon(\\log(1\\rho_{\\varepsilon}))\\varepsilon^{\\alpha}-\\varepsilon^{(1/2)}\\varepsilon(\\log(1\\rho_{\\varepsilon}))}\\\\ &{\\quad=2\\varepsilon^{(1/2)}\\varepsilon\\frac{\\sqrt{6}}{\\rho}\\left(\\varepsilon^{(1/2)}\\varepsilon^{(1/2)}\\sqrt{6}\\left(\\varepsilon^{(1/2)}\\varepsilon^{(1/2)}\\right)\\left\\{16}\\right\\}\\varepsilon^{\\alpha}}\\\\ &{\\quad=2\\varepsilon^{(1/2)}\\frac{\\sqrt{6}}{\\rho}\\frac{\\sqrt{6}}{\\rho}\\left(\\varepsilon^{(1/2)}\\varepsilon^{(1/2)}\\left(1\\rho_{\\varepsilon}\\log^{(1)}\\right)\\right)}\\\\ &{\\quad=2\\varepsilon^{(1/2)}\\frac{\\sqrt{6}}{\\rho}\\frac{\\sqrt{6}}{\\rho}\\left(\\varepsilon^{(1/2)}\\varepsilon^{(1/2)}\\right)\\varepsilon\\frac{\\sqrt{6}}{\\rho}\\left(\\varepsilon^{(1 \n$$$\\|\\tilde{x}_{t}\\|_{2}\\leq R)$ ", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Putting things back, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbf{R}_{T}\\leq\\mathbf{c}d\\log(R T/\\delta)\\sqrt{\\sum_{t\\in[T]\\backslash T_{o}}\\dot{\\mu}\\left(\\langle x_{t}^{*},\\theta^{*}\\rangle\\right)}+\\mathbf{c}R^{5}S^{2}\\kappa\\log(T/\\delta)^{2}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "B.5 Bounding number of policy updates: Proof of Lemma 4.1 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "We first obtain a bound on the number of rounds when Switching Criterion I is satisfied. Then we restate Lemma 4.1 and present its proof. Here, we use $\\mathcal{T}_{o}$ to denote the collection of all rounds till $T$ for which Switching Criterion I is satisfied. ", "page_idx": 26}, {"type": "text", "text": "Lemma B.11. Algorithm 2, during its entire execution, satisfies the Switching Criterion I at most $2d R^{2}\\kappa\\gamma^{2}\\log\\left(T/\\bar{\\delta}\\right)$ times. ", "page_idx": 26}, {"type": "text", "text": "Proof. Recall that Switching Criterion I (Line 4) is satisfied, when $\\|x\\|_{\\mathbf{V}^{-1}}^{2}>1/(R^{2}\\kappa\\gamma^{2})$ for some $x\\,\\in\\,{\\mathcal{X}}_{t}$ . Let ${\\mathbf{V}}_{m}$ be the sequence of $\\mathbf{V}$ matrices (line 6 of Algorithm 2) for $m\\,\\in\\,\\tau_{o}$ . That is, $\\begin{array}{r}{\\mathbf{V}_{1}=\\lambda\\mathbf{I},\\mathbf{V}_{m}=\\sum_{s\\in[m-1]\\cap\\mathcal{T}_{o}}x_{s}x_{s}^{\\mathsf{T}}+\\lambda\\mathbf{I}.}\\end{array}$ . In these rounds, by Line 5 of Algorithm 2, we have that the arm played $x_{t}$ is such that $\\overset{\\cdot}{\\boldsymbol{x}}_{t}=\\arg\\operatorname*{max}_{\\boldsymbol{x}\\in\\mathcal{X}_{t}}\\left\\|\\boldsymbol{x}\\right\\|_{\\mathbf{V}_{t}^{-1}}$ . Therefore, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{t\\in\\mathcal{T}_{o}}\\|x_{t}\\|_{\\mathbf{V}_{t}^{-1}}^{2}\\geq\\frac{\\tau_{o}}{R^{2}\\kappa\\gamma^{2}}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Furthermore, by the Elliptic Potential Lemma (Lemma B.12) we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{t\\in\\mathcal{T}_{o}}\\left\\|x_{t}\\right\\|_{\\mathbf{V}_{t}^{-1}}^{2}\\leq2d\\log\\left(1+\\frac{\\tau_{o}}{\\lambda d}\\right)\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Combining (23) and (22) we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\tau_{o}\\le2d R^{2}\\kappa\\gamma^{2}\\log\\left(1+\\frac{\\tau_{o}}{\\lambda d}\\right)\\le2d R^{2}\\kappa\\gamma^{2}\\log\\left(T\\right)\\le2d R^{2}\\kappa\\gamma^{2}\\log\\left(T/\\delta\\right)\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Lemma (4.1). Algorithm 2, during its entire execution, updates its policy at most $O(R^{4}S^{2}\\;\\kappa d^{2}\\;\\log^{2}(\\bar{T}/\\delta))$ times. ", "page_idx": 26}, {"type": "text", "text": "Proof. Note that in Algorithm 2, policy changes happen only in the warm-up rounds and when the determinant of $\\mathbf{H}_{t}$ doubles in the main round. Thus, total number of policy switches is upper bounded by the number of warm-up rounds and the number of times $\\operatorname*{det}(\\mathbf{H}_{t})$ doubles. The first quantity is bounded by Lemma B.11 while the second quantity is bounded by Lemma B.15. Thus in total, the number of policy changes in Algorithm A is upper bounded by $2d\\bar{R^{2}}\\kappa\\gamma^{2}\\log(T/\\delta)+\\mathbf{c}d\\log(T)$ . ", "page_idx": 26}, {"type": "text", "text": "B.6 Some Useful Lemmas ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Lemma B.12 (Elliptic Potential Lemma (Lemma 10 [1])). Let $x_{1},x_{2},\\ldots{x_{t}}$ be a sequence of vectors in $\\mathbb{R}^{d}$ and let $\\|\\boldsymbol{x}_{s}\\|_{2}\\leq L$ for all $s\\in[t]$ . Further, let $\\begin{array}{r}{\\mathbf{V}_{s}=\\sum_{m=1}^{s-1}x_{m}x_{m}^{\\sf T}+\\lambda\\mathbf{I}}\\end{array}$ . Suppose $\\lambda\\geq L^{2}$ Then, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{s=1}^{t}\\|x_{s}\\|_{\\mathbf{V}_{s}^{-1}}^{2}\\leq2d\\log\\left(1+\\frac{L^{2}t}{\\lambda d}\\right)\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Lemma B.13 (Lemma 12 of [1]). Let $A\\succeq B\\succ0.$ . Then ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{x\\neq0}{\\frac{x^{\\mathsf{T}}A x}{x^{\\mathsf{T}}B x}}\\leq{\\frac{\\operatorname*{det}(A)}{\\operatorname*{det}(B)}}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Lemma B.14 (Lemma 10 of [1]). Let $\\{x_{s}\\}_{s=1}^{t}$ be a set of vectors. Define the sequence $\\{\\mathbf{V}_{s}\\}_{s=1}^{t}$ as $\\mathbf{V}_{1}=\\lambda\\mathbf{I}_{\\mathbf{\\Omega}}$ , $\\mathbf{V}_{s+1}=\\mathbf{V}_{s}+x_{s}x_{s}^{\\sf T}$ for $s\\in[t-1]$ . Further, let $\\|x_{s}\\|_{2}\\leq L\\,\\forall\\,s\\in[t]$ . Then, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\operatorname*{det}(\\mathbf{V}_{t})\\leq\\left(\\lambda+t L^{2}/d\\right)^{d}\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Lemma B.15. Let $\\{x_{s}\\}_{s=1}^{t}$ be a set of vectors. Define the sequence $\\{\\mathbf{V}_{s}\\}_{s=1}^{t}$ as $\\mathbf{V}_{1}=\\lambda\\mathbf{I}_{*}$ , $\\mathbf{V}_{s+1}=$ $\\mathbf{V}_{s}+x_{s}x_{s}^{\\top}$ for $s\\in[t-1]$ . Further, let $\\|x_{s}\\|_{2}\\leq L\\,\\forall\\,s\\in[t]$ . Define the set $\\left\\{1=\\tau_{1},\\tau_{2}\\ldots\\tau_{m}=t\\right\\}$ such that: $\\operatorname*{det}(\\mathbf{V}_{\\tau_{i+1}})\\geq2\\operatorname*{det}(\\mathbf{V}_{\\tau_{i}})$ but $\\operatorname*{det}(\\mathbf{V}_{\\tau_{i+1}-1})<2\\operatorname*{det}(\\mathbf{V}_{\\tau_{i}})$ for $i\\in\\{2,\\ldots m-1\\}$ . Then, the number of time doubling happens,i.e. $m$ is at most $O(d\\log(t))$ . ", "page_idx": 27}, {"type": "text", "text": "Proof. By Lemma B.14, $\\operatorname*{det}(\\mathbf{V}_{t})\\leq\\left(\\lambda+t L^{2}/d\\right)^{d}$ . But we have that from definition of $\\tau_{i}$ \u2019s ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{det}(\\mathbf{V}_{t})\\geq\\operatorname*{det}(\\mathbf{V}_{\\tau_{m-1}})}\\\\ &{\\qquad\\qquad\\geq2\\operatorname*{det}(\\mathbf{V}_{\\tau_{m-2}})}\\\\ &{\\qquad\\qquad\\vdots}\\\\ &{\\qquad\\qquad\\geq2^{m-2}\\operatorname*{det}(\\mathbf{V}_{\\tau_{1}})}\\\\ &{\\qquad=2^{m-2}\\operatorname*{det}(\\mathbf{V}_{1})}\\\\ &{\\qquad=2^{m-2}\\lambda^{d}}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "equation", "text": "$$\n(\\mathbf{V}_{1}=\\lambda\\mathbf{I})\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Thus, $2^{m-2}\\lambda^{d}\\leq\\left(\\lambda+t L^{2}/d\\right)^{d}$ which implies that ", "page_idx": 27}, {"type": "equation", "text": "$$\n2^{m-2}\\leq\\left(1+\\frac{t L^{2}}{\\lambda d}\\right)^{d}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Hence, $m\\leq O(d\\log(t))$ . ", "page_idx": 27}, {"type": "text", "text": "C Useful Properties of GLMs ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Recall that a Generalized Linear Model is characterized by a canonical exponential family, i.e., the random variable $r$ has density function $p_{z}\\left(r\\right)\\,=\\,\\exp\\left(r z-b\\left(z\\right)+c\\left(\\bar{r^{}}\\right)\\right)$ , with parameter $z$ , log-partition function $b(\\cdot)$ , and a function $c$ . Further, $\\dot{b}(z)=\\mu(z)$ is also called the link function. ", "page_idx": 27}, {"type": "text", "text": "Hereon, we will assume that the random variable has a bounded non-negative support, i.e., $r\\in[0,R]$ almost surely. Now, we state the following key Lemmas on GLMs ", "page_idx": 27}, {"type": "text", "text": "Lemma C.1 (Self-Concordance for GLMs). For distributions in the exponential family the function $\\mu(\\cdot)$ satisfies that for all $z\\in\\mathbb{R}$ , $|\\ddot{\\mu}(z)|\\leq R\\dot{\\mu}(z)$ . ", "page_idx": 27}, {"type": "text", "text": "Proof. Indeed, ", "page_idx": 27}, {"type": "text", "text": "(Jensen\u2019s inequality) ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\widecheck{b}(z)|=|\\mathbb{E}[(r-\\mathbb{E}[r])^{3}]|}\\\\ &{\\qquad\\leq\\mathbb{E}\\left[|(r-\\mathbb{E}[r])^{3}|\\right]}\\\\ &{\\qquad=\\mathbb{E}\\left[|r-\\mathbb{E}[r]|\\cdot(r-\\mathbb{E}[r])^{2}\\right]}\\\\ &{\\qquad\\leq\\mathbb{E}[R(r-\\mathbb{E}[r])^{2}]}\\\\ &{\\qquad=R\\mathbb{E}[(r-\\mathbb{E}[r])^{2}]}\\\\ &{\\qquad=R\\ddot{b}(z)}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "equation", "text": "$$\n(r,\\mathbb{E}[r]\\in[0,R])\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "As a consequence, we have the following simple modification of the self-concordance results of [6]. Lemma C.2. For an exponential distribution with log-partition function $b(\\cdot)$ , for all $z_{1},z_{2}\\in\\mathbb{R}_{}$ , letting $\\mu(z):=\\dot{b}(z),$ , following holds: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\displaystyle\\alpha(z_{1},z_{2}):=\\int_{v=0}^{1}\\dot{\\mu}\\left(z_{1}+v\\left(z_{2}-z_{1}\\right)\\right)\\geq\\displaystyle\\frac{\\dot{\\mu}\\left(z\\right)}{1+R|z_{1}-z_{2}|}\\quad\\!f o r\\,z\\in\\{z_{1},z_{2}\\}}}\\\\ {{\\displaystyle\\frac{\\dot{\\mu}(z_{2})}{e^{R|z_{2}-z_{1}|}}\\leq\\dot{\\mu}\\left(z_{1}\\right)\\leq e^{R|z_{2}-z_{1}|}\\dot{\\mu}\\left(z_{2}\\right)}}\\\\ {{\\displaystyle\\tilde{\\alpha}(z_{1},z_{2}):=\\int_{v=0}^{1}(1-v)\\dot{\\mu}\\left(z_{1}+v(z_{2}-z_{1})\\right)d v\\geq\\displaystyle\\frac{\\dot{\\mu}(z_{1})}{2+R|z_{1}-z_{2}|}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Proof. Without loss of generality, assume that $z_{2}~\\geq~z_{1}$ . Note that by property of integration $\\begin{array}{r}{\\int_{a}^{b}f(x)d x=\\int_{b}^{a}f(b+a-x)d x,\\alpha(z_{1},z_{2})=\\alpha(z_{2},z_{1})}\\end{array}$ . Now, by proposition C.1, and the fact that $\\ddot{\\mu}(z)=\\ddot{b}\\left(z\\right)$ , we have for any $v\\in\\mathbb R$ and $z\\geq z_{1}$ , ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{-R\\dot{\\mu}(v)\\leq\\ddot{\\mu}(v)\\leq R\\dot{\\mu}(v)}}\\\\ {{-R\\leq\\displaystyle\\frac{\\ddot{\\mu}(v)}{\\dot{\\mu}(v)}\\leq R}}\\\\ {{-R\\int_{z}^{z_{1}}d v\\leq\\displaystyle\\int_{z}^{z_{1}}\\frac{\\ddot{\\mu}(v)}{\\dot{\\mu}(v)}d v\\leq R\\int_{z}^{z_{1}}d v}}\\\\ {{-R(z-z_{1})\\leq\\log\\left(\\frac{\\dot{\\mu}(z)}{\\dot{\\mu}(z_{1})}\\right)\\leq R(z-z_{1})}}\\\\ {{\\dot{\\mu}(z_{1})\\exp(-R(z-z_{1}))\\leq\\dot{\\mu}(z_{1})\\leq\\dot{\\mu}(z_{1})\\exp(R(z-z_{1}))}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Putting $z=z_{2}$ establishes 26. To show 25, we further set $z=z_{1}+u(z_{2}-z_{1})$ for $u\\in[0,1]$ , (note that $z\\geq z_{1}$ ) and integrate on $u$ , ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\dot{\\mu}(z_{1})\\displaystyle\\int_{0}^{1}\\exp(-R u(z_{2}-z_{1}))d u\\leq\\displaystyle\\int_{0}^{1}\\dot{\\mu}(z_{1}+u(z_{2}-z_{1}))d u\\leq\\displaystyle\\int_{0}^{1}\\exp(R u(z_{2}-z_{1}))d u}\\\\ {\\mathrm{es}}&{\\dot{\\mu}(z_{1})\\displaystyle\\frac{1-\\exp(-R(z_{2}-z_{1}))}{R(z_{2}-z_{1})}\\leq\\alpha(z_{1},z_{2})\\leq\\dot{\\mu}(z_{1})\\displaystyle\\frac{\\exp(R(z_{2}-z_{1}))-1}{R(z_{2}-z_{1})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Next, we use the fact that for $x>0$ , $e^{-x}\\leq(1+x)^{-1}$ which on rearranging gives $(1-e^{-x})/x\\geq$ $1/(1+x)$ . Applying this inequality to the LHS above finishes the proof. Note that similar exercise can be repeated with $z_{2}\\leq z_{1}$ to get the same result for $z_{2}$ . ", "page_idx": 28}, {"type": "text", "text": "For 27, we have, by application of 26, $\\dot{\\mu}(z_{1}+v(z_{2}-z_{1}))\\geq\\dot{\\mu}(z_{1})\\exp(R|v(z_{2}-z_{1})|)$ . Therefore, ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\alpha}(z_{1},z_{2})=\\displaystyle\\int_{v=0}^{1}(1-v)\\dot{\\mu}\\left(z_{1}+v(z_{2}-z_{1})\\right)d v}\\\\ &{\\qquad\\qquad\\geq\\displaystyle\\int_{v=0}^{1}(1-v)\\dot{\\mu}(z_{1})\\exp(-R|v(z_{1}-z_{2})|)d v}\\\\ &{\\qquad=\\dot{\\mu}(z_{1})\\displaystyle\\int_{v=0}^{1}(1-v)\\exp(-R v|(z_{1}-z_{2})|)d v}\\\\ &{\\qquad=\\dot{\\mu}(z_{1})\\left(\\frac{1}{R|z_{1}-z_{2}|}+\\frac{\\exp(-R|z_{1}-z_{2}|)-1}{R^{2}|z_{1}-z_{2}|^{2}}\\right)}\\\\ &{\\qquad\\geq\\dot{\\mu}(z_{1})\\cdot\\frac{1}{2+R|z_{1}-z_{2}|}}\\end{array}\\quad\\mathrm{(Lemma~10)}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Next we state some nice properties of the GLM family that is the key in deriving Lemma C.1. ", "page_idx": 28}, {"type": "text", "text": "Lemma C.3 (Properties of GLMs). For any random variable r that is distributed by a canonical exponential family, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{l}{I.\\ \\mathbb{E}\\left[r\\right]=\\mu\\left(z\\right)=\\dot{b}\\left(z\\right)}\\\\ {\\mathrm{~2.~}\\ \\mathbb{V}[r]=\\mathbb{E}\\left[\\left(r-\\mathbb{E}\\left[r\\right]\\right)^{2}\\right]=\\dot{\\mu}\\left(z\\right)=\\ddot{b}\\left(z\\right)}\\\\ {\\mathrm{~3.~}\\ \\mathbb{E}\\left[\\left(r-\\mathbb{E}[r]\\right)^{3}\\right]=\\dddot{b}\\left(z\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof. 1. Indeed, since $p_{z}(r)$ is a probability distribution, $\\begin{array}{r}{\\int_{r}p_{z}(r)d r\\;=\\;1}\\end{array}$ which in turn implies that $\\begin{array}{r}{b(z)=\\log\\left(\\int_{r}\\exp(r z+c(r))d r\\right)}\\end{array}$ . Thus, taking derivative, ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle{\\dot{b}}(z)=\\frac{1}{\\int_{r}\\exp(r z+c(r))d r}\\int_{r}\\frac{\\partial}{\\partial z}\\exp(r z+c(r))d r}\\\\ {\\displaystyle~~~~~=\\exp(-b(z))\\int_{r}r\\exp(r z+c(r))d r}\\\\ {\\displaystyle~~~~~=\\int_{r}r\\exp(r z-b(z)+c(r))d r=\\mathbb{E}[r]}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "2. Let $\\begin{array}{r}{f(z):=\\int_{r}r\\exp(r z+c(r))d r}\\end{array}$ . Thus, $\\dot{b}(z)=\\exp(-b(z))f(z)$ . Taking derivative on both sides, ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\ddot{b}(z)=-\\dot{b}(z)\\exp(-b(z))f(z)+\\exp(-b(z))\\dot{f}(z)}\\\\ {\\displaystyle}\\\\ {\\displaystyle}\\\\ {\\displaystyle}\\\\ {\\displaystyle}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "3. Again let $\\begin{array}{r}{f(z):=\\int_{r}r^{2}\\exp(r z\\!+\\!c(r))d r}\\end{array}$ . Thus, $\\ddot{b}(z)=-\\dot{b}(z)^{2}\\!+\\!\\exp(-b(z))f(z)$ . Taking derivative on both sides, ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\ddot{b}^{*}(z)=-2\\dot{b}(z)\\ddot{b}(z)-\\dot{b}(z)\\exp(-b(z))f(z)+\\exp(-b(z))\\dot{f}(z)}\\\\ {\\displaystyle\\qquad=-2\\dot{b}(z)\\ddot{b}(z)-\\dot{b}(z)\\,\\mathbb{E}[r^{2}]+\\int_{r}r^{3}\\exp(r z-b(z)+c(r))d r}\\\\ {\\displaystyle\\qquad=-2\\,\\mathbb{E}[r]\\mathbb{V}[r]-\\mathbb{E}[r]\\,\\mathbb{E}[r^{2}]+\\mathbb{E}[r^{3}]}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Now, let us expand $\\mathbb{E}[(r-\\mathbb{E}[r])^{3}]$ . ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[(r-\\mathbb{E}[r])^{3}]=\\mathbb{E}[r^{3}-3r^{2}\\,\\mathbb{E}[r]+3r\\,\\mathbb{E}[r]^{2}-\\mathbb{E}[r]^{3}]}\\\\ &{\\qquad\\qquad\\qquad=\\mathbb{E}[r^{3}]-3\\,\\mathbb{E}[r]\\,\\mathbb{E}[r^{2}]+3\\,\\mathbb{E}[r]^{3}-\\mathbb{E}[r]^{3}}\\\\ &{\\qquad\\qquad\\quad=\\mathbb{E}[r^{3}]-\\mathbb{E}[r]\\,\\mathbb{E}[r^{2}]-2\\,\\mathbb{E}[r]\\,\\bigl(-\\mathbb{E}[r^{2}]+\\mathbb{E}[r]^{2}\\bigr)}\\\\ &{\\qquad\\qquad\\quad=\\mathbb{E}[r^{3}]-\\mathbb{E}[r]\\,\\mathbb{E}[r^{2}]-2\\,\\mathbb{E}[r]\\mathbb{V}[r]}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Corollary C.4. For all exponential family, $b(\\cdot)$ is a convex function. ", "page_idx": 29}, {"type": "text", "text": "Proof. Indeed, note that $\\ddot{b}(z)=\\mathbb{V}[r]$ which is always non-negative. Thus, $\\ddot{b}(z)\\geq0$ implying that $b(\\cdot)$ is convex. ", "page_idx": 29}, {"type": "text", "text": "Remark C.5. In [5] Section 1.4.1, the author claims that if the GLM parameter $z$ lies in a bounded set, then the GLM is self-concordant, i.e., $|\\ddot{\\mu}(z)|\\,\\leq\\,a\\dot{\\mu}(z)$ , for some appropriate constant $a$ over this bounded set.\u221a Thereafter the author notes that the techniques developed in [5] guarantees $\\kappa$ -free regret rates (in $\\sqrt{T}$ term) for such GLMs (i.e., all GLMs with bounded parameter). However, the claim regarding self-concordance of GLMs is not true in general. There are classes of GLMs whose parameters may be restricted in a bounded set, but for them no constant $a$ exists. One such example is tIfh e weex palolnoewn lt od ilsiter iibnu ttihoen .s eTth ufnocrt isoon $\\mu$ fporo seixtipvoen ,n ttihael nd iswtrei bhuatvioe i vsterni catls $\\mu(z)\\bar{=}-\\frac{1}{z}$ . $z$ $(-c,0)$ $c$ $\\mu(z)$ (satisfying our assumption on monotonicity of $\\mu$ , thus a valid example). However, for this GLM, ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\dot{\\mu}(z)=\\frac{1}{z^{2}}\\qquad\\ddot{\\mu}(z)=-\\frac{2}{z^{3}}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Note that $\\ddot{\\mu}(z)$ is positive for the assumed support of $z$ . Suppose this GLM is self-concordant, then we must have some positive constant $a$ such that ", "page_idx": 30}, {"type": "equation", "text": "$$\n|\\ddot{\\mu}(z)|=-\\frac{2}{z^{3}}\\leq a\\dot{\\mu}(z)=a\\frac{1}{z^{2}}\\;.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Simplifying, we obtain the following relation: ", "page_idx": 30}, {"type": "equation", "text": "$$\n-{\\frac{2}{z}}\\leq a\\;.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "However, since $z\\in(-c,0)$ , we have $\\begin{array}{r}{\\operatorname*{lim}_{z\\to0}-\\frac{2}{z}\\to\\infty}\\end{array}$ . Hence, no constant $a$ is possible. By this counterexample it can be seen that bounded parameter set is not enough to guarantee self-concordance of GLMs. In this work, we give a characterization of self-concordance of GLMs with bounded support of the random variable. It will be interesting to understand a complete characterization of self-concordance of GLMs. ", "page_idx": 30}, {"type": "text", "text": "D Computational Cost ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Consider a log-loss minimization oracle that returns the unconstrained MLE for a given GLM class with a computational complexity of $C_{o p t}\\cdot n$ , when the log-loss is computed over $n$ data points. Let the maximum number of arms available every round be $K$ . Furher, let the computational cost of an oracle that solves the non-convex optimization 8 be $N C_{o p t}$ . ", "page_idx": 30}, {"type": "text", "text": "Computational Cost of B-GLinCB: In the B-GLinCB algorithm, we employ the log-loss oracle at the end of each batch. The estimator $\\widehat{\\theta}$ calculated at the end of a batch of length $\\tau$ incurs a computational cost of $C_{o p t}\\tau$ . Furthermore, this oracle is invoked for a maximum of $M\\leq\\log\\log T$ batches. Additionally, the computation of the distributional optimal design at the end of each batch is efficient in $d\\,(\\mathrm{poly}(d))$ . Moreover, in every round, the algorithm solves the $D/G-$ Optimal Design problem (requiring $O(d\\log d)$ computation) and runs elimination based on prior (at most $\\log\\log T)$ phases. Hence, the amortized cost per round of B-GLinCB is $O(K\\log\\log T+d\\log d+C_{o p t})$ . ", "page_idx": 30}, {"type": "text", "text": "Computational Cost of RS-GLinCB: In the RS-GLinCB algorithm, the estimator $\\widehat{\\theta}_{w}$ is computed during each warmup round. Additionally, during non-warmup rounds, the estimator\u03b8  is computed a maximum of $O(\\log(T))$ times. These computations involve utilizing both the log-loss oracle and the non-convex projection oracle. Furthermore, in each non-warmup round, the algorithm executes an elimination step. This yields an amortized time complexity of $O(C_{o p t}\\log T+N C_{o p t}\\log^{2}(T)+K)$ per round. ", "page_idx": 30}, {"type": "text", "text": "Performance in Practice: As evident from Fig. 1, RS-GLinCB has much better computational performance in practice. We ran all the experiments on an Azure Data Science VM equipped with AMD EPYC 7V13 64-Core Processor (clock speed of $2.45\\ \\mathrm{GHz}$ ) and Linux Ubuntu $20.04~\\mathrm{LTS}$ operating system. It was ensured that no other application processes were running while we tested the performance. We implemented and tested our code in Python, and measured the execution times using time.time() command. We allowed no operations for 10 seconds after every run to let the CPU temperature come back to normal, in case the execution heats up the CPU, thereby causing subsequent runs to slow down. ", "page_idx": 30}, {"type": "text", "text": "Comparison with ECOLog [7] shows that execution time for RS-GLinCB is significantly smaller. We posit that this is because RS-GLinCB solves a large convex optimization problem but less frequently, resulting into smaller overhead at the implementation level, while ECOLog solves a smaller convex optimization problem, but does so every round. On an implementation level, this translates into more function calls and computation. Further, we observe that with increasing $\\kappa$ , the execution time of RS-GLinCB increases, which is in accordance with Lemma 4.1 that quantifies the number of policy switches as an increasing function of $\\kappa$ . ", "page_idx": 30}, {"type": "text", "text": "While comparing with GLOC [14], we observe that RS-GLinCB performs better than GLOC in both high and low $\\kappa$ regimes. Since GLOC runs an online convex optimization (online Newton step) algorithm to generate its confidence sets, the time taken by GLOC is nearly constant with changing $\\kappa$ . On the other hand, in accordance with Lemma 4.1, the computational cost of RS-GLinCB increases with $\\kappa$ . However, after a few initial rounds, when neither of the switching criteria are triggered, RS-GLinCB does not need to solve any computationally intensive optimization problem, hence these rounds execute very fast. In practice, with typical data distribution, RS-GLinCB reaches this stage much before what the worst-case guarantees show, hence we see it perform better than GLOC. ", "page_idx": 30}, {"type": "text", "text": "E Projection ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "We describe the projection step used in Algorithms 1 and 2. We present arguments similar to the ones made in Appendix B.3 of [6]. We write ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathbf{H}(\\boldsymbol{\\theta})=\\sum_{s=1}^{t}\\dot{\\mu}\\left(\\langle\\boldsymbol{\\theta},\\boldsymbol{x}_{s}\\rangle\\right)\\boldsymbol{x}_{s}\\boldsymbol{x}_{s}^{\\sf T}+\\lambda\\mathbf{I}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Recall, $\\mathbf{H}^{*}=\\mathbf{H}(\\theta^{*})$ . Let $\\widehat{\\theta}$ be the MLE estimator of $\\theta^{*}$ calculated after the sequence arm pulls $x_{1},x_{2},\\ldots,x_{t}$ . Let $r_{1},r_{2},\\ldots,r_{t}$ be the corresponding observed rewards. We project\u03b8 to a set $\\Theta$ by solving the following optimization problem ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\widetilde{\\theta}:=\\underset{\\theta\\in\\Theta}{\\arg\\operatorname*{min}}\\left\\|\\sum_{s=1}^{t}(\\mu\\left(\\langle x_{s},\\theta\\rangle\\right)-\\mu\\left(\\langle x_{s},\\widehat{\\theta}\\rangle\\right))x_{s}\\right\\|_{\\mathbf{H}(\\theta)^{-1}}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Lemma E.1. Using the notations described above, if $\\theta^{*}\\in\\Theta$ and $\\begin{array}{r}{\\operatorname*{max}_{i\\in[t]}|\\langle x_{i},\\widetilde{\\theta}-\\theta^{*}\\rangle|\\leq c/R,}\\end{array}$ , then we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\left\\Vert\\widetilde{\\theta}-\\theta^{*}\\right\\Vert_{\\mathbf{H}(\\theta^{*})}\\leq2(1+c)\\left\\Vert\\sum_{s=1}^{t}(\\mu\\left(\\langle x_{s},\\theta^{*}\\rangle\\right)-r_{s})x_{s}\\right\\Vert_{\\mathbf{H}(\\theta^{*})^{-1}}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. First, we note that by self-concordance property of $\\mu$ (lemma C.2), for any $s\\in[t]$ , ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l}&{\\alpha(x_{s},\\widetilde{\\theta},\\theta^{*})\\geq\\displaystyle\\frac{\\dot{\\mu}\\left(\\langle x_{s},\\theta^{*}\\rangle\\right)}{1+R|\\langle x_{s},\\widetilde{\\theta}-\\theta^{*}\\rangle|}}\\\\ &{\\qquad\\qquad\\geq\\displaystyle\\frac{\\dot{\\mu}\\left(\\langle x_{s},\\theta^{*}\\rangle\\right)}{1+R(c/R)}}&&{\\qquad\\qquad(\\operatorname*{max}_{i\\in[s]}|\\langle x_{s},\\widetilde{\\theta}-\\theta^{*}\\rangle|\\leq c/R)}\\\\ &{\\qquad\\qquad=\\displaystyle\\frac{\\dot{\\mu}\\left(\\langle x_{s},\\theta^{*}\\rangle\\right)}{1+c}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Similarly, we have $\\begin{array}{r}{\\alpha(x_{s},\\widetilde{\\theta},\\theta^{*})\\geq\\frac{\\dot{\\mu}\\left(\\langle x_{s},\\widetilde{\\theta}\\rangle\\right)}{1+c}}\\end{array}$ ", "page_idx": 31}, {"type": "text", "text": "Let us define the matrix $\\begin{array}{r}{\\mathbf{G}=\\sum_{s\\in[t]}\\alpha(x,\\widetilde{\\theta},\\theta^{*})x_{s}x_{s}^{\\intercal}}\\end{array}$ . Using the above fact, we obtain the relation: $\\begin{array}{r}{\\mathbf{G}\\succeq\\frac{1}{1+c}\\mathbf{H}^{*}}\\end{array}$ and $\\begin{array}{r}{\\mathbf{G}\\succeq\\frac{1}{1+c}\\mathbf{H}(\\widetilde{\\theta})}\\end{array}$ . Also define the vector $\\begin{array}{r}{g(\\theta)=\\sum_{s\\in[t]}\\mu\\left(\\langle\\theta,x_{s}\\rangle\\right)x_{s}}\\end{array}$ . Now, ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\tilde{\\theta}-\\theta^{*}\\right\\|_{\\mathbf{H}^{*}}\\leq\\sqrt{1+c}\\left\\|\\tilde{\\theta}-\\theta^{*}\\right\\|_{\\mathbf{G}}}&{\\quad{\\mathrm{(H}^{*}\\preceq(\\sqrt{1+c})\\mathbf{G})}}\\\\ &{\\qquad\\qquad=\\sqrt{1+c}\\left\\|\\mathbf{G}\\left(\\tilde{\\theta}-\\theta^{*}\\right)\\right\\|_{\\mathbf{G}^{-1}}}\\\\ &{\\qquad\\qquad=\\sqrt{1+c}\\left\\|\\sum_{s\\in[t]}\\left(\\alpha(x_{s},\\tilde{\\theta},\\theta^{*})\\widetilde{\\theta}-\\theta^{*},x_{s}\\right)x_{s}\\right\\|_{\\mathbf{G}^{-1}}}\\\\ &{\\qquad\\qquad=\\sqrt{1+c}\\left\\|\\sum_{s\\in[t]}\\left(\\mu\\left(\\langle x_{s},\\tilde{\\theta}\\rangle\\right)-\\mu\\left(\\langle x_{s},\\theta^{*}\\rangle\\right)\\right)x_{s}\\right\\|_{\\mathbf{G}^{-1}}\\qquad{\\mathrm{(Taylor~}}s\\mathrm{~theoren)}}\\\\ &{\\qquad\\qquad=\\sqrt{1+c}\\left\\|\\left(\\sum_{s\\in[t]}\\mu\\left(\\langle\\tilde{\\theta},x_{s}\\rangle\\right)x_{s}\\right)-\\left(\\sum_{s\\in[t]}\\mu\\left(\\langle\\theta^{*},x_{s}\\rangle\\right)x_{s}\\right)\\right\\|_{\\mathbf{G}^{-1}}}\\\\ &{\\qquad\\qquad=\\sqrt{1+c}\\left\\|\\left(\\sum_{s\\in[t]}\\mu\\left(\\langle\\tilde{\\theta},x_{s}\\rangle\\right)x_{s}\\right)-\\left(\\sum_{s\\in[t]}\\mu\\left(\\langle\\theta^{*},x_{s}\\rangle\\right)x_{s}\\right)\\right\\|_{\\mathbf{G}^{-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Let $\\begin{array}{r}{g(\\theta)=\\sum_{s=1}^{t}\\dot{\\mu}\\left(\\langle x_{s},\\theta\\rangle\\right)x_{s}}\\end{array}$ for any $\\theta$ . Therefore, we have, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left\\Vert\\tilde{\\theta}-\\theta^{*}\\right\\Vert_{\\mathbf{H}^{*}}\\leq\\sqrt{1+c}\\left\\Vert g(\\tilde{\\theta})-g(\\theta^{*})\\right\\Vert_{\\mathbf{L}^{\\infty}}}\\\\ &{=\\sqrt{1+c}\\left\\Vert g(\\tilde{\\theta})-g(\\tilde{\\theta})+g(\\tilde{\\theta})-g(\\theta^{*})\\right\\Vert_{\\mathbf{G}^{-1}}}\\\\ &{\\leq\\sqrt{1+c}\\left(\\left\\Vert g(\\tilde{\\theta})-g(\\tilde{\\theta})\\right\\Vert_{\\mathbf{G}^{-1}}+\\left\\Vert g(\\tilde{\\theta})-g(\\theta^{*})\\right\\Vert_{\\mathbf{G}^{-1}}\\right)\\qquad\\mathrm{(\\triangleleft~inequality)}}\\\\ &{\\leq{(1+c)}\\left(\\left\\Vert g(\\tilde{\\theta})-g(\\tilde{\\theta})\\right\\Vert_{\\mathbf{H}^{*}}\\!\\!\\!-\\!{\\textstyle\\left\\Vert{g(\\tilde{\\theta})-g(\\theta^{*})}\\right\\Vert_{\\mathbf{H}^{*-1}}}\\right)}\\\\ &{\\leq2(1+c)\\left\\Vert g(\\tilde{\\theta})-g(\\theta^{*})\\right\\Vert_{\\mathbf{H}^{*-1}}}\\\\ &{=2(1+c)\\left\\Vert g(\\theta^{*})-\\sum_{s\\in[\\mathbf{G}_{1}^{s},s_{s}]}\\right\\Vert_{\\mathbf{H}^{*-1}}}\\\\ &{=2(1+c)\\left\\Vert g(\\theta^{*})-\\sum_{s\\in[\\mathbf{G}_{1}^{s},s_{s}]}\\right\\Vert_{\\mathbf{H}^{*-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "( $\\widehat{\\theta}$ is the unconstrained MLE, $\\begin{array}{r}{g(\\widehat{\\theta})=\\sum_{s\\in[t]}r_{s}x_{s}.)}\\end{array}$ ", "page_idx": 32}, {"type": "text", "text": "E.1 Convex Relaxation ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "The optimization problem in (28) is a non-convex optimization problem and therefore it is not clear what is the computational complexity of the problem. However, it is possible to substitute this optimization problem with a convex one, whose computational complexity can be better tractable. The process is similar to the one detailed in [2, section 6]. Here we briefly outline the steps. ", "page_idx": 32}, {"type": "text", "text": "Let $\\begin{array}{r}{\\mathcal{L}_{t}(\\boldsymbol{\\theta})=\\sum_{s=1}^{t}\\ell(\\boldsymbol{\\theta},\\boldsymbol{x}_{s},\\boldsymbol{r}_{s})}\\end{array}$ and $\\breve{\\theta}$ be defined as follows: ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\breve{\\theta}:=\\arg\\operatorname*{min}_{\\theta\\in\\Theta}\\mathcal{L}_{t}(\\theta)\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Note that when the set $\\Theta$ is a convex set, then the above optimization problem is convex by property of the log-likelihood function of GLMs. Hence it can be solved efficiently. With this projected \u03b8\u02d8, we have the following guarantee: ", "page_idx": 32}, {"type": "text", "text": "Lemma E.2. Suppose $\\left\\|g(\\widehat{\\theta})-g(\\theta^{*})\\right\\|_{\\mathbf{H}^{*-1}}\\leq\\gamma$ and $\\lambda=\\gamma/R$ . If $\\theta^{*}\\in\\Theta$ and $\\operatorname*{max}_{i\\in[t]}|\\langle x_{i},\\breve{\\theta}-$ $\\theta^{*}\\rangle|\\leq c/R$ , then we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\left\\Vert\\breve{\\theta}-\\theta^{*}\\right\\Vert_{\\mathbf{H}(\\theta^{*})}\\leq c\\sqrt{(2+c)R^{3}S}\\gamma\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Proof. First we note that by self-concordance property of $\\mu$ , for any $s\\in[t]$ , ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\tilde{\\alpha}(x_{s},\\theta^{*},\\check{\\theta})\\geq\\displaystyle\\frac{\\dot{\\mu}\\left(\\langle x_{s},\\theta^{*}\\rangle\\right)}{2+R|\\langle x_{s},\\check{\\theta}-\\theta^{*}\\rangle|}}&{\\quad}&{\\mathrm{(Lemma~C.2)}}\\\\ {\\geq\\displaystyle\\frac{\\dot{\\mu}\\left(\\langle x_{s},\\theta^{*}\\rangle\\right)}{2+R(c/R)}}&{\\quad}&{\\mathrm{(max}_{i\\in[s]}\\,|\\langle x_{s},\\widetilde{\\theta}-\\theta^{*}\\rangle|\\leq c/R)}\\\\ {=\\displaystyle\\frac{\\dot{\\mu}\\left(\\langle x_{s},\\theta^{*}\\rangle\\right)}{2+c}}&{}&\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Let us define $\\begin{array}{r}{\\tilde{\\mathbf{G}}(\\theta^{*},\\theta):=\\sum_{s=1}^{t}\\tilde{\\alpha}(x_{s},\\theta^{*},\\theta)x_{s}x_{s}^{\\intercal}}\\end{array}$ . Using the above fact, we obtain $\\tilde{\\mathbf{G}}(\\theta^{\\ast},\\theta)\\succeq$ $\\scriptstyle{\\frac{1}{2+c}}\\mathbf{H}^{*}$ ", "page_idx": 32}, {"type": "text", "text": "We now follow closely the proof outlined in Appendix B.3 of [2] with minor changes. By second-order Taylor\u2019s expansion, for any $\\theta\\in\\ensuremath{\\mathbb{R}}^{d}$ , we can write ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathcal{L}_{t}(\\theta)-\\mathcal{L}_{t}(\\theta^{*})-\\langle\\nabla\\mathcal L_{t}(\\theta^{*}),\\theta-\\theta^{*}\\rangle=\\Vert\\theta-\\theta^{*}\\Vert_{\\tilde{\\mathbf G}(\\theta,\\theta^{*})}^{2}}&{}\\\\ {\\geq\\displaystyle\\frac{1}{2+c}\\,\\Vert\\theta-\\theta^{*}\\Vert_{\\mathbf H^{*}}^{2}}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Taking absolute value on both sides, and substituting $\\theta=\\breve{\\theta}$ , ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\left\\|\\breve{\\theta}-\\theta^{*}\\right\\|_{\\mathbf{H}^{*}}^{2}\\leq(2+c)\\left(|\\mathcal{L}_{t}(\\breve{\\theta})-\\mathcal{L}_{t}(\\theta^{*})|+|\\langle\\nabla\\mathcal{L}_{t}(\\theta^{*}),\\breve{\\theta}-\\theta^{*}\\rangle|\\right)}}\\quad}&{(\\triangle...\\mathrm{inequality})}\\\\ &{\\leq(2+c)\\left(|\\mathcal{L}_{t}(\\breve{\\theta})-\\mathcal{L}_{t}(\\theta^{*})|+\\|\\nabla\\mathcal{L}_{t}(\\theta^{*})\\|_{\\mathbf{H}^{*}}\\!\\!-\\!1\\left\\|\\breve{\\theta}-\\theta^{*}\\right\\|_{\\mathbf{H}^{*}}\\right)\\quad(\\mathrm{Cauchy-Schwarz})}\\\\ &{=(2+c)\\left(|\\mathcal{L}_{t}(\\breve{\\theta})-\\mathcal{L}_{t}(\\theta^{*})|+\\left\\|g(\\theta^{*})-\\sum_{s\\in[t]}r_{s}x_{s}\\right\\|_{\\mathbf{H}^{*}}\\left\\|\\breve{\\theta}-\\theta^{*}\\right\\|_{\\mathbf{H}^{*}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Recall that $\\widehat{\\theta}$ is the unconstrained MLE, therefore $\\nabla{\\mathcal{L}}_{t}({\\widehat{\\theta}})=\\mathbf{0}$ . By a similar Taylor expansion as above and s ome algebraic manipulations (see Appendix B.3 of [2]), we have, for $\\theta^{*}$ . ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\mathcal{L}_{t}(\\theta^{*})-\\mathcal{L}_{t}(\\widehat{\\theta})\\leq\\displaystyle\\left\\|g(\\theta^{*})-g(\\widehat{\\theta})\\right\\|_{\\mathbf{G}(\\theta^{*},\\widehat{\\theta})^{-1}}^{2}}\\\\ {\\leq\\displaystyle\\frac{R}{\\sqrt{\\lambda}}\\left\\|g(\\theta^{*})-g(\\widehat{\\theta})\\right\\|_{\\mathbf{H}^{*-1}}^{2}+\\left\\|g(\\theta^{*})-g(\\widehat{\\theta})\\right\\|_{\\mathbf{H}^{*-1}}}\\\\ {\\leq\\displaystyle\\frac{R}{\\sqrt{\\lambda}}\\gamma^{2}+\\gamma}&{{\\mathrm{(Lemm~}}}\\\\ {\\leq2R^{3}S\\gamma}&{{\\mathrm{(recall~}\\sqrt{R^{2}\\lambda}=\\gamma\\mathrm{~}\\ }}\\end{array}\n$$$\\sqrt{R^{2}\\lambda}=\\gamma/R S)$ ", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "We also have, by definition of $\\breve{\\theta}$ , whenever $\\theta^{*}\\in\\Theta$ , $\\mathcal{L}_{t}(\\ensuremath{\\boldsymbol{\\theta}})\\leq\\mathcal{L}_{t}(\\ensuremath{\\boldsymbol{\\theta}}^{*})$ , therefore we have $\\mathcal{L}_{t}(\\Breve{\\theta})-$ $\\mathcal{L}_{t}(\\widehat{\\theta})\\leq\\mathcal{L}_{t}(\\theta^{*})\\Big-\\mathcal{L}_{t}(\\widehat{\\theta})\\leq2R^{3}S\\gamma$ Thus, we have, ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\left\\|\\breve{\\theta}-\\theta^{*}\\right\\|_{\\mathbf{H}^{*}}^{2}\\leq\\left(2+c\\right)\\Big(4R^{3}S\\gamma+\\gamma\\left\\|\\breve{\\theta}-\\theta^{*}\\right\\|_{\\mathbf{H}^{*}}\\Big)\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Using the inequality that for some $x^{2}\\leq b x+c\\implies x\\leq b+{\\sqrt{c}},$ , we have, ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\left\\|\\breve{\\theta}-\\theta^{*}\\right\\|_{\\mathbf{H}^{*}}\\leq(2+c)\\gamma+\\sqrt{(2+c)4R^{3}S\\gamma}}}\\\\ {{=\\mathbf{c}\\sqrt{(2+c)R^{3}S}\\gamma}}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "IMPORTANT, please: ", "page_idx": 34}, {"type": "text", "text": "\u2022 Delete this instruction block, but keep the section heading \u201cNeurIPS paper checklist\", \u2022 Keep the checklist subsection headings, questions/answers and guidelines below. \u2022 Do not modify the questions and only use the provided macros for your answers. ", "page_idx": 34}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Justification: See Section 1 ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 34}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: See Conclusion (Section 6) ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 34}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: All details are stated in Section 2 and the proofs are given in details in the Appendices A, B, C. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 35}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: Detailed discussion is done in Section 5 and Appendix D. Code can be accessed at https://github.com/nirjhar-das/GLBandit_Limited_Adaptivity. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. ", "page_idx": 35}, {"type": "text", "text": "In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 36}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: Full code with documentation is provided at https://github.com/ nirjhar-das/GLBandit_Limited_Adaptivity. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 36}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: See Section 5. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 36}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: Execution Time plots have errorbars, but Regret plots do not as regret plots were observed to get cluttered although the variation was not significant. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. ", "page_idx": 36}, {"type": "text", "text": "\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 37}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: See Appendix D. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 37}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: There are no potential harms caused by the research process as it is mainly theoretical and the experiments are all in simulation. There might be Societal Impact of the algorithms developed here when applied in practical decision-making settings. The study of this beyond the scope of current work. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 37}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 37}, {"type": "text", "text": "Answer: [No] ", "page_idx": 37}, {"type": "text", "text": "Justification: The problem studied is of a theoretical interest and we do not foresee any negative societal impacts. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 38}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: The data and models are only toy data/fully simulated and therefore of no real impact. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 38}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: All credits regarding code are given in the README.md file at https: //github.com/nirjhar-das/GLBandit_Limited_Adaptivity. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 38}, {"type": "text", "text": "", "page_idx": 39}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 39}, {"type": "text", "text": "Justification: All details are provided in the README.md of our codebase https:// github.com/nirjhar-das/GLBandit_Limited_Adaptivity. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 39}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: Our work is mainly theoretical with only simple simulated experiments. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 39}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 39}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: Our work does not involve human participants. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 40}]