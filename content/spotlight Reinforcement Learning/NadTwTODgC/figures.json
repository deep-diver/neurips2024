[{"figure_path": "NadTwTODgC/figures/figures_1_1.jpg", "caption": "Figure 1: Unrolling imagination of DIAMOND over time. The top row depicts a policy \u03c0\u03c6 taking a sequence of actions in the imagination of our learned diffusion world model D. The environment time t flows along the horizontal axis, while the vertical axis represents the denoising time flowing backward from T to 0. Concretely, given (clean) past observations xt, actions a<t, and starting from an initial noisy sample x\u0142, we simulate a reverse noising process {x}7=9 by repeatedly calling De, and obtain the (clean) next observation x. The imagination procedure is autoregressive in that the predicted observation x and the action at taken by the policy become part of the conditioning for the next time step. Animated visualizations of this procedure can be found at https://diamond-wm.github.io.", "description": "This figure illustrates the process of imagination in the DIAMOND model.  The top row shows a policy making decisions (actions) in the simulated world. Each action produces a noisy observation, which is then denoised using the diffusion model (bottom rows). The denoising process happens in reverse time, from a highly noisy observation back to a clean one.  The denoised observation and action become the input for the next step, making it autoregressive and more realistic.  The animation can be viewed at the provided link.", "section": "Method"}, {"figure_path": "NadTwTODgC/figures/figures_4_1.jpg", "caption": "Figure 2: Mean and interquartile mean human normalized scores. DIAMOND, in blue, obtains a mean HNS of 1.46 and an IQM of 0.64.", "description": "This figure compares the performance of DIAMOND against other world models on the Atari 100k benchmark. The x-axis represents the human-normalized score (HNS), which measures the performance relative to human players. The y-axis shows the different world models.  The blue bars represent DIAMOND, indicating that it achieves a mean HNS of 1.46 and an interquartile mean (IQM) of 0.64, which is superior to other models. The IQM is a measure of central tendency that is less sensitive to outliers than the mean. ", "section": "4.2 Results on the Atari 100k benchmark"}, {"figure_path": "NadTwTODgC/figures/figures_6_1.jpg", "caption": "Figure 3: Imagined trajectories with diffusion world models based on DDPM (left) and EDM (right). The initial observation at t = 0 is common, and each row corresponds to a decreasing number of denoising steps n. We observe that DDPM-based generation suffers from compounding error, and that the smaller the number of denoising steps, n, the faster the error accumulates. In contrast, our EDM-based world model appears much more stable, even for n = 1.", "description": "This figure compares the performance of two different diffusion models, DDPM and EDM, in generating imagined trajectories.  The top row shows the initial observation which is the same for both models. Each subsequent row shows the result of increasing the number of denoising steps, from n=1 to n=10.  As the number of denoising steps increases, the generated image becomes progressively more realistic and less noisy. However, this improvement is much more pronounced in EDM compared to DDPM. Specifically, it is observed that DDPM produces highly unstable and unrealistic trajectories when fewer denoising steps are used, while EDM is much more stable, even with a single denoising step.", "section": "Analysis"}, {"figure_path": "NadTwTODgC/figures/figures_6_2.jpg", "caption": "Figure 3: Imagined trajectories with diffusion world models based on DDPM (left) and EDM (right). The initial observation at t = 0 is common, and each row corresponds to a decreasing number of denoising steps n. We observe that DDPM-based generation suffers from compounding error, and that the smaller the number of denoising steps, the faster the error accumulates. In contrast, our EDM-based world model appears much more stable, even for n = 1.", "description": "This figure compares the performance of two different diffusion models (DDPM and EDM) used for generating trajectories in a world model.  Each row shows trajectories generated with a different number of denoising steps (n). The left column uses DDPM, which shows significant compounding error, especially with fewer denoising steps. The right column uses EDM, which is much more stable even with only one denoising step. This highlights EDM's advantage for world modeling applications.", "section": "Choice of diffusion framework"}, {"figure_path": "NadTwTODgC/figures/figures_6_3.jpg", "caption": "Figure 4: Single-step (top row) versus multi-step (bottom row) sampling in Boxing. Movements of the black player are unpredictable, so that single-step denoising interpolates between possible outcomes and results in blurry predictions. In contrast, multi-step sampling produces a crisp image by driving the generation towards a particular mode. Interestingly, the policy controls the white player, so his actions are known to the world model. This information removes any ambiguity, and so we observe that both single-step and multi-step sampling correctly predict the white player's position.", "description": "This figure compares single-step and multi-step sampling in the Boxing game, highlighting how single-step sampling results in blurry predictions due to the unpredictable movements of the black player, while multi-step sampling produces clearer images by focusing on specific outcomes.  It also demonstrates that when the policy controls the white player (providing full information), both sampling methods accurately predict the player's position.", "section": "5.2 Choice of the number of denoising steps"}, {"figure_path": "NadTwTODgC/figures/figures_7_1.jpg", "caption": "Figure 5: Consecutive frames imagined with IRIS (left) and DIAMOND (right). The white boxes highlight inconsistencies between frames, which we see only arise in trajectories generated with IRIS. In Asterix (top row), an enemy (orange) becomes a reward (red) in the second frame, before reverting to an enemy in the third, and again to a reward in the fourth. In Breakout (middle row), the bricks and score are inconsistent between frames. In Road Runner (bottom row), the rewards (small blue dots on the road) are inconsistently rendered between frames. None of these inconsistencies occur with DIAMOND. In Breakout, the score is even reliably updated by +7 when a red brick is broken.", "description": "This figure compares the visual quality of imagined game trajectories generated by two different world models, IRIS and DIAMOND.  IRIS, using a discrete autoencoder, shows inconsistencies in its generated frames. For example, in Asterix, an enemy is incorrectly displayed as a reward, then back as an enemy, and again as a reward. In Breakout, the bricks and score are not consistent across frames.  In Road Runner, the rewards are inaccurately rendered. In contrast, DIAMOND's diffusion model produces consistent and more accurate visual representations across all three games. This demonstrates DIAMOND's ability to maintain fidelity to the environment even when generating longer sequences, unlike IRIS.", "section": "Qualitative visual comparison with IRIS"}, {"figure_path": "NadTwTODgC/figures/figures_8_1.jpg", "caption": "Figure 6: Images captured from people playing with keyboard and mouse inside DIAMOND\u2019s diffusion world model. This model was trained on 87 hours of static Counter-Strike: Global Offensive (CS:GO) gameplay (Pearce and Zhu, 2022) to produce an interactive neural game engine for the popular in-game map, Dust II. Best viewed as videos at https://diamond-wm.github.io.", "description": "This figure shows a series of screenshots from a video game created using DIAMOND\u2019s diffusion world model trained on 87 hours of CS:GO gameplay. The screenshots demonstrate the model\u2019s ability to generate realistic and interactive game environments, making it function as a playable game engine.  The videos showing the full sequence are available online at the URL provided in the caption.", "section": "6 Scaling the diffusion world model to Counter-Strike: Global Offensive"}, {"figure_path": "NadTwTODgC/figures/figures_20_1.jpg", "caption": "Figure 7: Performance profiles, i.e., fraction of runs above a given human normalized score.", "description": "This figure shows performance profiles comparing DIAMOND with several other world models on the Atari 100k benchmark.  A performance profile plots the fraction of games where a given method achieved a human-normalized score above a certain threshold (\u03c4) across multiple runs (seeds).  The x-axis represents the human normalized score threshold (\u03c4), and the y-axis represents the fraction of runs that exceeded that score.  A higher curve indicates better performance.  The dashed horizontal line indicates the fraction of runs that exceeds human-level performance (HNS=1).", "section": "Additional performance comparisons"}, {"figure_path": "NadTwTODgC/figures/figures_23_1.jpg", "caption": "Figure 8: Average pixel drift between an imagined trajectory and the corresponding reference trajectory collected with an expert in Breakout. The trajectories are each 1000 timesteps, starting from the same frame and following the same sequence of actions. Each line displays the average and shaded standard deviation of 400 reference trajectories held out from training data. DDPM becomes more stable with increasing number of denoising steps, but is less stable than 1-step EDM, even with 10 denoising steps. The drift we observe for EDM corresponds to differences in the imagined trajectory rather than a pathological color shift as we see in Figure 3a.", "description": "This figure shows a quantitative analysis of the compounding error in autoregressive world models. It compares the average pixel distance between imagined trajectories and reference trajectories (collected from an expert player) in the Breakout game, for both DDPM and EDM-based world models with varying numbers of denoising steps. The results show that EDM models are more stable and have less compounding error than DDPM models, even with a single denoising step.", "section": "K Quantitative analysis of autoregressive model drift"}, {"figure_path": "NadTwTODgC/figures/figures_24_1.jpg", "caption": "Figure 9: We tested two architectures for DIAMOND\u2019s diffusion model which condition on previous image observations in different ways. To illustrate differences with typical video generation models, we also visualize a U-Net 3D (\u00c7i\u00e7ek et al., 2016) which diffuses a block of frames simultaneously.", "description": "This figure compares three different architectures for diffusion models.  The first is a U-Net 3D architecture commonly used in video generation, which processes all frames simultaneously. The other two are variations of U-Net 2D designed for world modeling, one uses frame-stacking, where the previous frames are concatenated to the input, and the other uses cross-attention, a more sophisticated method to consider past frames.", "section": "M.2 Diffusion Model Architectures"}, {"figure_path": "NadTwTODgC/figures/figures_26_1.jpg", "caption": "Figure 10: Example trajectories sampled every 25 timesteps from DIAMOND (frame stack) for the modern 3D first-person shooter CS:GO (top row), and real-world motorway driving (bottom row).", "description": "This figure shows example trajectories generated by the DIAMOND model for two different environments: CS:GO and motorway driving.  The CS:GO example shows a first-person perspective, navigating a corridor and then going through a doorway. The motorway example depicts a car driving on a highway and plausibly overtaking another car. These examples illustrate the model's ability to generate plausible and coherent trajectories in complex, visually rich environments. The trajectories are sampled every 25 timesteps.", "section": "5.3 Qualitative visual comparison with IRIS"}, {"figure_path": "NadTwTODgC/figures/figures_27_1.jpg", "caption": "Figure 11: Effect of fixed actions on sampled trajectories in motorway driving. Conditioned on the same initial observations, we rollout the model applying differing actions. Interestingly, the model has learnt to associate 'Slow down' and 'Speed up' actions to the whole traffic slowing down and speeding up.", "description": "The figure shows the effect of different actions on the model's predictions for a motorway driving scenario.  The model is given the same initial observations (six previous frames), but different actions are input (continue straight, steer left, steer right, slow down, speed up). The resulting trajectories show that the model is able to generate plausible continuations that correspond to the actions applied. Notably, when \"slow down\" is applied, the model predicts the traffic ahead slowing down, showing an understanding of the scenario's dynamics.", "section": "Analysis"}, {"figure_path": "NadTwTODgC/figures/figures_27_2.jpg", "caption": "Figure 12: Effect of fixed actions on sampled trajectories in CS:GO. Conditioned on the same initial observation, we rollout the model applying differing actions. Whilst in immediate frames these have the intended effect, for longer roll-outs the observations can degenerate. For instance, it would have been very unlikely for the human demonstrator to look directly into ground in this game state, so the world model is unable to generate a plausible trajectory here, and instead snaps onto another area of the map when looking down does make sense.", "description": "This figure shows the effect of applying different actions on the generated trajectories in the CS:GO environment. The model successfully generates the intended effects for short sequences, but for longer sequences it shows some instability and is unable to generate the plausible trajectories, suggesting that the model might not have encountered the similar scenarios in the training data. For example, when looking down, the model shifts to another area of the map instead of realistically showing the ground.", "section": "Analysis"}]