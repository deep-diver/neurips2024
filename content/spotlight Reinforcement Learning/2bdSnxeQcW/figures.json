[{"figure_path": "2bdSnxeQcW/figures/figures_2_1.jpg", "caption": "Figure 1: Histograms of \u03c0 and \u03b2 (left axis), and the estimation bias of CQL with various \u03b1 (right axis) at s0 for three cases: (a) \u03b2 = Unif(\u22122, 2) and \u03c0 = N(0, 0.2) (b) \u03b2 = N(\u22121, 0.3) + N(1, 0.3) and \u03c0 = N(1, 0.2) (c) \u03b2 = N(\u22121, 0.3) + N(1, 0.3) and \u03c0 = N(0, 0.2), where Unif(\u22122, 2) represents a uniform distribution and N(\u03bc, \u03c3) denotes a Gaussian distribution with mean \u03bc and standard deviation \u03c3.", "description": "This figure demonstrates the effect of the penalization constant \u03b1 in CQL on the estimation bias. Three scenarios are shown, each with different behavior policies (\u03b2) and target policies (\u03c0). The histograms show the distribution of actions for both policies. The plots show the estimation bias of CQL (average difference between the learned Q-function and the expected return) for different values of \u03b1. The figure highlights that CQL introduces unnecessary bias for states that do not contribute to overestimation.", "section": "3.1 Motivation: Necessity of Mitigating Unnecessary Estimation Bias"}, {"figure_path": "2bdSnxeQcW/figures/figures_3_1.jpg", "caption": "Figure 2: An illustration of our exclusive penalty: (a) The log-probability of \u03b2 and the thresholds \u03c4\u2081 and \u03c4\u2082 according to the number of data samples N\u2081 and N\u2082, where N\u2081 << N\u2082. (b) The penalty adaptation factor f\u03c0,\u03b2 which represents the amount of adaptive penalty, indicating how much log \u03b2 exceeds the threshold \u03c4.", "description": "This figure illustrates the exclusive penalty used in the EPQ algorithm. Panel (a) shows how the log-probability of the behavior policy \u03b2 changes with the number of data samples (N) and how the thresholds (\u03c4) for the penalty adaptation are adjusted accordingly.  Panel (b) shows how the penalty adaptation factor (f\u03c0,\u03b2) is calculated based on the difference between the log-probability of \u03b2 and the thresholds \u03c4, resulting in different penalty amounts for different policies (\u03c0).  The goal is to selectively penalize only when policy actions are insufficient in the dataset, minimizing unnecessary bias.", "section": "3 Methodology"}, {"figure_path": "2bdSnxeQcW/figures/figures_4_1.jpg", "caption": "Figure 3: Histogram of \u03b2 (left axis), and the corresponding f\u03c0,\u03b2(s) with various \u03c4 (right axis) for two cases: (a) \u03b2 = Unif(\u22122,2) (b) \u03b2 = N(\u22121,0.3) + N(1,0.3)", "description": "This figure visualizes the penalty adaptation factor f\u03c0,\u03b2(s) for different policy distributions (\u03c0) and behavior policies (\u03b2). Two scenarios are shown: (a) a uniform behavior policy and (b) a bimodal Gaussian behavior policy. The histograms display the distribution of actions (\u03b2) and how the penalty adaptation factor varies with threshold \u03c4 for different policy distributions.  The penalty factor f\u03c0,\u03b2(s) decreases as the log-probability of the behavior policy exceeds the threshold \u03c4, reflecting the intention to reduce penalties when the policy actions have sufficient support in the dataset. ", "section": "3.1 Motivation: Necessity of Mitigating Unnecessary Estimation Bias"}, {"figure_path": "2bdSnxeQcW/figures/figures_4_2.jpg", "caption": "Figure 5: An illustration of the prioritized dataset. As the policy focuses on actions with maximum Q-values, the difference between \u03b2 and \u03c0 becomes substantial, inducing large penalty: (a) The change of data distribution from \u03b2 (w/o PD) to \u03b2\u00ba (with PD) (b) The corresponding penalty graphs for \u03b2 (w/o PD) and \u03b2\u00ba (with PD).", "description": "This figure illustrates how the prioritized dataset (PD) addresses the issue of large penalties arising when the policy \u03c0 concentrates on actions with maximum Q-values, particularly when these actions are not sufficiently present in the original dataset \u03b2.  Panel (a) shows how the PD, denoted as \u03b2\u00ba, modifies the data distribution \u03b2 by emphasizing actions with high Q-values.  Panel (b) shows that this modification significantly reduces the penalty associated with the policy \u03c0 when compared to using the unmodified dataset \u03b2.", "section": "3.3 Prioritized Dataset"}, {"figure_path": "2bdSnxeQcW/figures/figures_7_1.jpg", "caption": "Figure 6: Analysis of proposed method", "description": "This figure shows the analysis of the proposed method, EPQ, compared to CQL.  The top row (a) presents the squared value of the estimation bias for both methods across different gradient steps in three Mujoco tasks (Hopper-random, Hopper-medium, and Halfcheetah-medium).  The bottom row (b) displays the normalized average return achieved in the same tasks under similar conditions.  The plots illustrate that EPQ effectively reduces the estimation bias (both overestimation and underestimation) and improves the normalized average returns compared to CQL, especially in the Hopper and Halfcheetah tasks.", "section": "4.2 The Analysis of Estimation Bias"}, {"figure_path": "2bdSnxeQcW/figures/figures_8_1.jpg", "caption": "Figure 6: Analysis of proposed method", "description": "This figure presents a comparison of the proposed EPQ method with CQL across different Mujoco tasks. It shows plots of both squared estimation bias and normalized average return, demonstrating that EPQ significantly reduces unnecessary estimation bias compared to CQL, leading to improved performance.", "section": "4.2 The Analysis of Estimation Bias"}, {"figure_path": "2bdSnxeQcW/figures/figures_22_1.jpg", "caption": "Figure 8: Additional ablation studies on Hopper-medium task", "description": "This figure presents additional ablation studies on the Hopper-medium task focusing on the impact of three hyperparameters related to the importance sampling (IS) weight calculation in the EPQ algorithm: the IS clipping factor (Cmin), the cluster radius (\u03b5), and the temperature (\u03b6).  Each subplot shows the normalized average return over gradient steps for various settings of the corresponding hyperparameter, along with the results for the CQL baseline. The goal is to analyze how these parameters affect the performance of EPQ.", "section": "D Additional Ablation Studies Related to  Estimation"}]