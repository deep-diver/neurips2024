[{"figure_path": "4DA5vaPHFb/figures/figures_6_1.jpg", "caption": "Figure 1: Fitting of three different transport maps T\u03020 between source and target measures in R\u00b2 with Euclidean cost function c(x, y) = ||x \u2212 y||. We use the same number of iterations and MLP architecture for each method. Left: Sinkhorn divergence; Middle: Monge gap; Right: ENOT.", "description": "This figure compares three different methods for estimating optimal transport maps: Sinkhorn divergence, Monge gap, and the proposed ENOT method.  Each method's results are visualized by showing the mappings between source and target probability measures in a 2D space.  The Euclidean distance is used as the cost function.  The figure aims to illustrate the performance of ENOT relative to existing methods in terms of the accuracy and visual quality of the resulting transport map.", "section": "5.2 Different Cost Functionals"}, {"figure_path": "4DA5vaPHFb/figures/figures_6_2.jpg", "caption": "Figure 2: Recovered OT maps To between synthetic measures on 2-sphere with geodesic cost c(x, y) = arccos(xTy). All models are MLPs with outputs normalized to be on a unit sphere. Blue dots are the empirical source measure, red crosses are the empirical target measure and the orange crosses are the result of the found transport map. Left: Sinkhorn; Middle: Monge; Right: ENOT.", "description": "This figure compares the performance of three different optimal transport methods (Sinkhorn, Monge, and ENOT) on a 2-sphere dataset using a geodesic cost function.  The plots visualize the recovered optimal transport maps (T\u03b8), showing the mappings between source and target measures. The blue dots represent the source measure, red crosses the target measure, and orange crosses show the result of the transport map (push-forward).  The figure demonstrates how each method achieves different results in terms of the mappings found.", "section": "5.2 Different Cost Functionals"}, {"figure_path": "4DA5vaPHFb/figures/figures_8_1.jpg", "caption": "Figure 10: Optimal transportation mapping found by ENOT for Top: Handbags (top row) \u21d2 Shoes (bottom row); Middle: FFHQ (top row) \u21d2 Comics (bottom row); Bottom: CelebA(f) (top row) \u21d2 Anime (bottom row) image-to-image translation tasks.", "description": "This figure shows the results of unpaired image-to-image translation using the ENOT method.  Three different translation tasks are presented: handbags to shoes, FFHQ faces to comic faces, and CelebA female faces to anime faces. For each task, the top row displays the source images, and the bottom row shows the corresponding images generated by ENOT. The figure visually demonstrates the model's ability to translate images between different domains.", "section": "5.3 Unpaired Image-to-Image Translation"}, {"figure_path": "4DA5vaPHFb/figures/figures_9_1.jpg", "caption": "Figure 4: Contour plots of LUV dependence on the values of \u03bb and \u03c4 in Algorithm 1 for the dimensions of D = 256 (Left, NaN values are greyed out), D = 128 (Middle), and D = 64 (Right).", "description": "This figure shows contour plots illustrating the impact of the hyperparameters expectile (\u03c4) and regularization weight (\u03bb) on the unexplained variance percentage (LUV) metric across different dimensions (D=256, 128, 64).  The plots reveal the optimal regions for \u03c4 and \u03bb that minimize LUV.  Grey areas indicate where the OT solver failed to converge.", "section": "5.4 Ablation Study: Varying hyperparameters expectile and regularization weight"}, {"figure_path": "4DA5vaPHFb/figures/figures_13_1.jpg", "caption": "Figure 5: Expectile regression. Left: the asymmetric squared loss L\u03c4. The value \u03c4 = 0.5 corresponds to the standard MSE loss, while \u03c4 = 0.9 and \u03c4 = 0.99 give more weight to the positive differences. Right: expectile models f\u03c4(x). The value \u03c4 = 0.5 corresponds to the conditional statistical mean of the distribution, and when \u03c4 \u2192 1 it approximates the maximum operator over the corresponding values of y.", "description": "The figure demonstrates expectile regression. The left panel shows the asymmetric squared loss function L\u03c4, highlighting how different \u03c4 values (0.01, 0.5, 0.8, 0.9, 0.99) affect the weighting of positive and negative differences.  The right panel illustrates the resulting expectile models f\u03c4(x) for the same \u03c4 values.  It shows how the model shifts from representing the conditional mean (\u03c4 = 0.5) towards approximating the conditional maximum (as \u03c4 approaches 1).", "section": "Appendix A Expectile visualisations"}, {"figure_path": "4DA5vaPHFb/figures/figures_17_1.jpg", "caption": "Figure 4: Contour plots of LUV dependence on the values of \u03bb and \u03c4 in Algorithm 1 for the dimensions of D = 256 (Left, NaN values are greyed out), D = 128 (Middle), and D = 64 (Right).", "description": "This figure shows contour plots illustrating the relationship between the unexplained variance percentage (LUV) metric, the expectile hyperparameter \u03c4, and the regularization weight \u03bb across different dimensions (D = 64, 128, 256). The plots visualize how the optimal settings of \u03c4 and \u03bb change depending on the dimensionality of the problem.  Areas with NaN (Not a Number) values indicate where the optimization diverged, highlighting the impact of the hyperparameters on the stability and accuracy of the model.", "section": "5.4 Ablation Study: Varying hyperparameters expectile and regularization weight"}, {"figure_path": "4DA5vaPHFb/figures/figures_18_1.jpg", "caption": "Figure 7: Recovered optimal transport plans (T(x) and T\u207b\u00b9(y) from (23)) and learned potentials contour plots obtained from solving OT dual problem (22) with squared Euclidean cost via ENOT regularisation on synthetic datasets from Makkuva et al. [2020]. Evaluation metric is Sinkhorn distance between the measures, i.e. W\u2082(T#\u03b1, \u03b2), W\u2082(\u03b1, T\u207b\u00b9\u03b2). The estimated distance (22) from learned potentials compared with the reference value W\u2082(\u03b1, \u03b2).", "description": "This figure shows the results of applying the ENOT method to synthetic datasets from Makkuva et al. (2020) using a squared Euclidean cost function.  It displays the recovered optimal transport plans (T(x) and its inverse T\u207b\u00b9(y)), which map probability measures \u03b1 and \u03b2, along with contour plots of the learned Kantorovich potentials (f and g).  The evaluation metric used is the Sinkhorn distance (W\u2082), comparing the estimated distance from the learned potentials with the true Wasserstein distance between \u03b1 and \u03b2. The closeness of these distances demonstrates the accuracy of the learned potentials and transport plans.", "section": "Results on Synthetic 2D Datasets"}, {"figure_path": "4DA5vaPHFb/figures/figures_18_2.jpg", "caption": "Figure 8: Recovered optimal transport push forward map (23) visualization for squared Euclidean cost using ENOT algorithm on synthetic datasets from Rout et al. [2021].", "description": "This figure visualizes the optimal transport plan learned by the ENOT algorithm for a squared Euclidean cost function on synthetic datasets from the Rout et al. (2021) paper. It shows the source and target measures as point clouds and the learned transport map as lines connecting points from the source to the target. The color of the lines might represent the magnitude or other properties of the transport. The figure demonstrates the ability of ENOT to learn accurate and continuous transport maps even on complex datasets.", "section": "F Results on Synthetic 2D Datasets"}, {"figure_path": "4DA5vaPHFb/figures/figures_19_1.jpg", "caption": "Figure 10: Optimal transportation mapping found by ENOT for Top: Handbag (top row) \u21d2 Shoes (bottom row); Middle: FFHQ (top row) \u21d2 Comics (bottom row); Bottom: CelebA(f) (top row) \u21d2 Anime (bottom row) image-to-image translation tasks.", "description": "This figure shows the results of applying the ENOT model to three different image-to-image translation tasks.  The top row of each section displays the source images, while the bottom row presents the images generated by the ENOT model after the transport mapping. The tasks demonstrated are: translating images of handbags into images of shoes, translating images from the Flickr-Faces-HQ dataset into images of comic book faces, and translating images of female celebrities from the CelebA dataset into images of anime faces.", "section": "Unpaired Image-to-Image Translation"}, {"figure_path": "4DA5vaPHFb/figures/figures_19_2.jpg", "caption": "Figure 10: Optimal transportation mapping found by ENOT for Top: Handbags (top row) \u21d2 Shoes (bottom row); Middle: FFHQ (top row) \u21d2 Comics (bottom row); Bottom: CelebA(f) (top row) \u21d2 Anime (bottom row) image-to-image translation tasks.", "description": "This figure shows the results of image-to-image translation using the proposed ENOT method.  It presents three different translation tasks: handbags to shoes, high-resolution faces (FFHQ) to comic-style faces, and female celebrity faces (CelebA) to anime-style faces. For each task, the top row displays the source images, and the bottom row shows the corresponding translated images generated by ENOT. The figure visually demonstrates the model's ability to translate images across different domains while preserving important structural information.", "section": "Unpaired Image-to-Image Translation"}]