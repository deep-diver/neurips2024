[{"figure_path": "V0oJaLqY4E/tables/tables_4_1.jpg", "caption": "Table 1: Quantitative results for 8 Gaussians experiment. SW denotes the sliced Wasserstein distance between samples and data. AUC is computed for classification between data and uniform noise using the energy. The standard deviation is computed from 5 independent samplings. The ideal maximum value of AUC is about 0.906.", "description": "This table presents a quantitative comparison of different methods for density estimation on a synthetic dataset of 8 Gaussians.  The methods compared include various diffusion models with different numbers of timesteps (T), with and without the DxMI fine-tuning. The performance is evaluated using two metrics: Sliced Wasserstein Distance (SW), measuring the distance between the generated samples and the true data distribution; and Area Under the Curve (AUC) of the energy-based model's ability to discriminate between data samples and uniform noise. Lower SW indicates better sample quality, and higher AUC indicates better discriminative ability of the energy model. The table shows that DxMI consistently improves the sample quality and the discriminative power of the energy model, especially when the number of timesteps is small.", "section": "5.1 2D Synthetic Data"}, {"figure_path": "V0oJaLqY4E/tables/tables_5_1.jpg", "caption": "Table 1: Quantitative results for 8 Gaussians experiment. SW denotes the sliced Wasserstein distance between samples and data. AUC is computed for classification between data and uniform noise using the energy. The standard deviation is computed from 5 independent samplings. The ideal maximum value of AUC is about 0.906.", "description": "This table presents quantitative results of a 2D density estimation experiment using 8 Gaussian distributions.  It compares different methods (DDPM and DxMI with varying hyperparameters) by measuring the sliced Wasserstein distance (SW) between generated samples and the ground truth data, and the Area Under the Curve (AUC) of the energy-based model's ability to discriminate between data and uniform noise. Lower SW indicates better sample quality, while higher AUC indicates better anomaly detection performance.  The standard deviation is reported for 5 independent runs, and the ideal maximum AUC is given for reference.", "section": "5.1 2D Synthetic Data"}, {"figure_path": "V0oJaLqY4E/tables/tables_7_1.jpg", "caption": "Table 2: CIFAR-10 unconditional image generation. \u2020: the starting point of DxMI fine-tuning.", "description": "This table presents the quantitative results of unconditional image generation on the CIFAR-10 dataset.  It compares several different methods, including Score SDE, PD, Consistency Models, and StyleGAN-XL, to the proposed DxMI method and its variants (with different time cost functions, etc.). The results are reported using FID (Fr\u00e9chet Inception Distance) and Recall, lower FID and higher Recall indicating better sample quality. The '\u2020' symbol indicates the starting point for fine-tuning using DxMI.", "section": "5.2 Image Generation: Training Diffusion Models with Small T"}, {"figure_path": "V0oJaLqY4E/tables/tables_7_2.jpg", "caption": "Table 3: ImageNet 64\u00d764 conditional image generation. \u2020: the starting point of DxMI fine-tuning.", "description": "This table presents the results of applying different methods for conditional image generation on the ImageNet 64x64 dataset.  It compares the performance of several approaches, including different diffusion models and the proposed DxMI method, in terms of FID (Fr\u00e9chet Inception Distance), Precision, and Recall.  The number of forward passes (NFE) required for generation is also shown.  The \u2020 symbol indicates the starting point from which DxMI fine-tuning begins.", "section": "5.2 Image Generation: Training Diffusion Models with Small T"}, {"figure_path": "V0oJaLqY4E/tables/tables_7_3.jpg", "caption": "Table 4: LSUN Bedroom 256 \u00d7 256 unconditional image generation.", "description": "This table presents the results of unconditional image generation on the LSUN Bedroom dataset (256x256 resolution).  It compares the performance of several models, including StyleGAN2, EDM, Consistency Model, and DxMI, in terms of FID (Fr\u00e9chet Inception Distance), Precision, and Recall.  The number of function evaluations (NFE) required for generation is also shown. Lower FID indicates better image quality, while higher precision and recall indicate that generated images better match the true distribution of the data.", "section": "5.2 Image Generation: Training Diffusion Models with Small T"}, {"figure_path": "V0oJaLqY4E/tables/tables_8_1.jpg", "caption": "Table 5: MVTec-AD multi-class anomaly detection and localization experiment. Anomaly detection (DET) and localization (LOC) performance are measured in AUC. Due to the space constraint, only the average AUC over 15 classes is presented. The full results are provided in Table 6.", "description": "This table shows the performance of DxMI and other methods on the MVTec-AD anomaly detection dataset.  The AUC scores for both anomaly detection and localization are reported.  DxMI achieves the highest AUC for both tasks, highlighting its effectiveness in this application.  The results for \u03c4=0 show the importance of entropy maximization in DxMI.", "section": "5.3 Energy-Based Anomaly Detection and Localization"}, {"figure_path": "V0oJaLqY4E/tables/tables_19_1.jpg", "caption": "Table 1: Quantitative results for 8 Gaussians experiment. SW denotes the sliced Wasserstein distance between samples and data. AUC is computed for classification between data and uniform noise using the energy. The standard deviation is computed from 5 independent samplings. The ideal maximum value of AUC is about 0.906.", "description": "This table presents a quantitative comparison of different methods for density estimation on a synthetic dataset of 8 Gaussian distributions.  The methods are compared using two metrics: the sliced Wasserstein distance (SW), measuring the distance between the generated samples and the true data distribution, and the Area Under the Curve (AUC) of a classifier trained to distinguish between generated samples and uniform noise. Lower SW values and higher AUC values indicate better performance. The table also shows the number of function evaluations (T) used in each method.", "section": "5.1 2D Synthetic Data"}]