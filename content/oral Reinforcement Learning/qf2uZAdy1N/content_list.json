[{"type": "text", "text": "Reinforcement Learning under Latent Dynamics: Toward Statistical and Algorithmic Modularity ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Philip Amortila\\* Dylan J. Foster Nan Jiang philipa4@illinois.edu dylanfoster@microsoft.com nanjiang@illinois.edu ", "page_idx": 0}, {"type": "text", "text": "Akshay Krishnamurthy Zakaria Mhammedi akshaykr@microsoft.com mhammedi@google.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Real-world applications of reinforcement learning often involve environments where agents operate on complex, high-dimensional observations, but the underlying (\"latent\") dynamics are comparatively simple. However, outside of restrictive settings such as small latent spaces, the fundamental statistical requirements and algorithmic principles for reinforcement learning under latent dynamics are poorly understood. ", "page_idx": 0}, {"type": "text", "text": "This paper addresses the question of reinforcement learning under general latent dynamics from a statistical and algorithmic perspective. On the statistical side, our main negative result shows that most well-studied settings for reinforcement learning with function approximation become intractable when composed with rich observations; we complement this with a positive result, identifying latent pushforward coverability as a general condition that enables statistical tractability. Algorithmically, we develop provably efficient observable-to-latent reductions\u2014\u2014that is, reductions that transform an arbitrary algorithm for the latent MDP into an algorithm that can operate on rich observations\u2014in two settings: one where the agent has access to hindsight observations of the latent dynamics [LADZ23], and one where the agent can estimate self-predictive latent models [SAGHCB20]. Together, our results serve as a first step toward a unified statistical and algorithmic theory for reinforcement learning under latent dynamics. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Many application domains for reinforcement learning (RL) require the agent to operate on rich, high-dimensional observations of the environment, such as images or text [WSD15; LFDA16; KFPM21; NRKFG22; $\\mathrm{Bak}{+}22$ \uff1bBro $+22$ ]. However, the environment itself can often be summarized by latent dynamics for a low-dimensional or otherwise simple latent state space. The decoupling of latent dynamics from the complex observation process naturally suggests a modular framework for algorithm design: first learn a representation that decodes the latent state from observations, then apply a reinforcement learning algorithm for the latent dynamics on top of the learned representation. This paper investigates the algorithmic and statistical foundations of this framework. We ask: Can we take existing algorithms and sample complexity guarantees for reinforcement learning in the latent statespace and lift them to the observation space in a modular fashion? ", "page_idx": 0}, {"type": "text", "text": "There is a growing body of theoretical and empirical work developing algorithms that combine representation learning and reinforcement learning to develop scalable algorithms. On the empirical side, a plethora of representation learning objectives have been deployed to varying degrees of success [PAED17; Tan $+17$ ; ZMCGL21; LSA20; YFK21; Lam $+24$ ;Guo $+22$ ; HPBL23], but we lack a mathematical framework to systematically compare these objectives and understand when one might be preferred to another. On the theoretical side, all existing approaches suffer from three primary drawbacks: (a) they are tailored to restricted classes of latent dynamics models (tabular MDPs [KAL16; DKJADL19; MHKL20; ZSUWAS22; MFR23], LQR [DR21; Mha $+20$ I,orfactored MDPs [MLJL21]), limiting generality; (b) the analyses, despite focusing on restrictive settings, are unwieldy, limiting progress in algorithm development; and (c) they are not modular, in the sense that the representation learning procedures are specialized to specific choices of latent reinforcement learning algorithm, limiting ease of use. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "1.1 Contributions ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "We address the aforementioned limitations by introducing a new framework, reinforcement learning undergeneral latentdynamics. ", "page_idx": 1}, {"type": "text", "text": "Reinforcement learning under general latent dynamics (Section 2). In our framework, the agent performs control based on high-dimensional observations, but the dynamics of the environment are governed by an unobserved latent state space. Following prior work (particularly the so-called Block MDP formulation [DKJADL19]), we assume that the latent states can be uniquely decoded from observations, but that the true decoder is unknown and must be learned. To aid in the decoding process, we supply the learner with a class of representations that is realizable in the sense that it is powerful enough to represent the true decoder. Our point of departure from prior theoretical works is that we do not assume specific structure (e.g., tabular or linear dynamics) on the Markov decision process (MDP) that governs the latent dynamics. Instead, we make the minimal assumption that the latent dynamics belong to a base MDP class which is statistically tractable, in the sense that when the latent states are directly observed there exists some reinforcement learning algorithm with low sample complexity that is capable of learning a near-optimal policy for every MDP in the class. We take the first steps toward building a unified and modular theory for reinforcement learning in this setting. ", "page_idx": 1}, {"type": "text", "text": "Contributions: Statistical modularity (Section 3).  A central consideration for reinforcement learning under latent dynamics is that representation learning and exploration must be intertwined: an accurate decoder is required to explore the latent state space, but exploration is required to learn an accurate decoder. To develop provable sample complexity guarantees, one must prevent errors from compounding during this interleaving process, a challenging statistical problem which prior work addresses through strong structural assumptions on the base MDP [KAL16; DKJADL19; MHKL20; ZSUWAS22; MFR23; DR21; Mha $+20$ ; MLJL21]. For the general latent-dynamics setting we consider, it is unclear whether similar techniques can be applied, or whether the setting is even statistically tractable, ignoring computational considerations. Thus, our first contribution considers the question of statistical modularity:2 ", "page_idx": 1}, {"type": "text", "text": "If a base MDP class is tractable when observed directly, is the corresponding latent-dynamics problemtractable? ", "page_idx": 1}, {"type": "text", "text": "Statistical modularity adopts a minimax perspective by assuming that the base MDP lies in a given class, and demands that the sample complexity of the latent-dynamics setting is controlled by a natural bound on the sample complexity of the base MDP class. We show, perhaps surprisingly, that most well-studied reinforcement learning settings involving function approximation [RVR13; JKALS17; SJKAL19; MJTS20; AJSWY20; Li09; DVRZ19; WSY20; ZGS21; $\\mathrm{Du}+21$ ;JLM21; FKQR21] do not admit statistical modularity (Theorem 3.1). In other words, statistical tractability of an MDP class does not extend to the latent-dynamics setting. We complement these negative findings with a positive result, identifying pushforward coverability as a general structural condition on the latent dynamics that enables sample efficiency (Theorem 3.2). ", "page_idx": 1}, {"type": "text", "text": "Contributions: Algorithmic modularity (Section 4). Beyond developing a modular understanding of the statistical landscape, we investigate modular algorithm design principles for RL under general latent dynamics. Specifically, we consider the question of observable-to-latent reductions, whereby RL under latent dynamics can be reduced to the simpler problem of RL with latent states directly observed: ", "page_idx": 1}, {"type": "text", "text": "Can we generically lift algorithms for a base MDP class to solve the corresponding latent-dynamics problem? ", "page_idx": 1}, {"type": "text", "text": "This property, which we refer to as algorithmic modularity, enables modular, greatly simplified algorithm design, allowing one to use an arbitrary base algorithm for the base MDP class to solve the corresponding latent-dynamics problem. Algorithmic modularity is a stronger property than mere statistical modularity, and thus is subject to our statistical lower bound. Accordingly, we consider two settings that sidestep the lower bound through additional feedback and modeling assumptions. Our first algorithmic result considers hindsight observability [LADZ23], where latent states are revealed during training, but not at deployment (Theorem 4.1). Our second considers stronger function approximation conditions that enable the estimation of self-predictive latent models [SAGHCB20] through representation learning (Theorem A.1). Both results are fully modular: they transform any sample-efficient algorithm for the base MDP class into a sample-efficient algorithm for the latent-dynamics setting. Thus, they constitute the first general-purpose algorithms for RL under latent dynamics. ", "page_idx": 2}, {"type": "text", "text": "Together, we believe our results can serve as a foundation for further development of practical, general-purpose algorithms for RL under latent dynamics. To this end, we highlight a number of fascinating and challenging open problems for future research (Section 5). ", "page_idx": 2}, {"type": "text", "text": "2   Reinforcement Learning under General Latent Dynamics ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section we formally introduce our framework, reinforcement learning under general latent dynamics. ", "page_idx": 2}, {"type": "text", "text": "MDP preliminaries. We consider an episodic finite-horizon online reinforcement learning setting.... With $H$ _denoting the horizon, a Markov decision process (MDP) $\\begin{array}{r l}{M^{\\star}}&{{}=}\\end{array}$ $\\{\\bar{\\chi},\\mathcal{A},\\{\\bar{P_{h}^{\\star}}\\}_{h=0}^{H},\\{R_{h}^{\\star}\\}_{h=1}^{H},H\\}$ consistsofastatespace $\\mathcal{X}$ an etion spaece $\\boldsymbol{\\mathcal{A}}$ arewardisribution $R_{h}^{\\star}:\\mathcal{X}\\times\\mathcal{A}\\rightarrow\\Delta([0,1])$ (with expectation $r_{h}^{\\star}(x,a))$ , and a transition kernel $P_{h}^{\\star}:\\mathcal{X}\\times\\mathcal{A}\\rightarrow\\Delta(\\mathcal{X})$ (with the convention that $P_{0}^{\\star}(\\cdot\\mid\\emptyset)$ is the initial state distribution).3 ", "page_idx": 2}, {"type": "text", "text": "At the beginning of the episode, the learner selects a randomized, non-stationary policy $\\pi\\ =$ $(\\pi_{1},\\ldots,\\pi_{H})$ , where $\\pi_{h}:\\mathcal{X}\\to\\Delta(\\mathcal{A})$ ; we let $\\Pi_{\\mathsf{r n s}}$ denote the set of all such policies. The episode evolves through the following process; beginning from $x_{1}\\sim P_{0}^{\\star}(\\cdot\\mid\\emptyset)$ , the MDP generates a trajectory $(x_{1},a_{1},r_{1}),\\dots,(x_{H},a_{H},r_{H})$ via $a_{h}\\sim\\pi_{h}(x_{h})$ \uff0c $r_{h}\\sim R_{h}^{\\star}(x_{h},a_{h})$ , and $x_{h+1}\\sim P_{h}^{\\star}(\\cdot\\mid x_{h},a_{h})$ We let $\\mathbb{P}^{M^{\\star},\\pi}$ denote the law under this process, and let $\\mathbb{E}^{M^{\\star},\\pi}$ denote the corresponding expectation, and likewise let $\\mathbb{P}^{M,\\pi}$ and $\\mathbb{E}^{M,\\pi}$ denote the analogous laws and expectations in another MDP $M$ We assume that $\\textstyle\\sum_{h=1}^{H}r_{h}\\in[0,1]$ almost surely for any trajectory in $M^{\\star}$ ", "page_idx": 2}, {"type": "text", "text": "Fo a policy $\\pi$ and MDP $M$ th expected reward for $\\pi$ is given by $\\begin{array}{r}{J^{\\scriptscriptstyle M}(\\pi)\\,:=\\,\\mathbb{E}^{_M,\\pi}\\bigl[\\sum_{h=1}^{H}r_{h}\\bigr]}\\end{array}$ \uff0c and the value functions are given by $\\begin{array}{r l r}{V_{h}^{^{M,\\pi}}(x)\\!}&{{}:=}&{\\!\\mathbb{E}^{^{M,\\pi}}[\\sum_{h^{\\prime}=h}^{H}r_{h^{\\prime}}\\quad|\\quad x_{h}\\;\\;=\\;\\;x]}\\end{array}$ , and $\\begin{array}{r}{Q_{h}^{{\\scriptscriptstyle M,\\pi}}(x,a)\\;:=\\;\\mathbb{E}^{{\\scriptscriptstyle M,\\pi}}[\\sum_{h^{\\prime}=h}^{H}r_{h^{\\prime}}\\;\\;|\\;\\;x_{h}\\;=\\;x,a_{h}\\;=\\;a]}\\end{array}$ We let $\\pi_{\\scriptscriptstyle M}~=~\\{\\pi_{\\scriptscriptstyle M,h}\\}_{h=1}^{H}$ denote an optimal deterministic policy of $M$ , which maximizes $V^{\\vec{M},\\pi}$ (over $\\pi$ ) at all states (and in particular, satisfies $\\pi_{\\scriptscriptstyle M}\\;\\in\\;\\arg\\operatorname*{max}_{\\pi\\in\\Pi_{r n s}}\\,J^{\\scriptscriptstyle M}(\\pi))$ , and write $Q^{M,\\star}\\;:=\\;Q^{M,\\pi_{M}}$ . For $f\\,:\\,\\mathcal{X}\\,\\times\\,\\mathcal{A}\\,\\rightarrow\\,\\mathbb{R}$ we write $\\pi_{f}(x)\\ :=\\ \\arg\\operatorname*{max}_{a}f(x,a)$ as well as $V_{f}(x)~=~\\operatorname*{max}_{a}f(x,a)$ . For MDP $M$ , horizon $\\textit{b}\\in\\textit{}[\\dot{H}]$ , and $g\\ :\\ \\mathcal{X}\\ \\rightarrow\\ \\mathbb{R}$ , we let $\\mathcal{T}_{h}^{M}$ denote the Bellman (optimality) operator defined via $[\\mathcal{T}_{h}^{M}g](x,a)\\,=\\,\\mathbb{E}^{M}[r_{h}+g(x_{h+1})\\mid\\overleftarrow{x}_{h}=x,a_{h}=a],$ and we overload notation by letting $[{\\mathcal T}_{h}^{\\scriptscriptstyle M}f](x,a)\\;\\;=\\;\\;[{\\mathcal T}_{h}^{\\scriptscriptstyle M}V_{f}](x,a)$ . We also let $\\angles{\\mathcal{T}_{h}^{M,\\pi}}$ denote the Bellman evaluation operator defined via $[\\mathcal{T}_{h}^{M,\\pi}\\bar{f}](x,a)=\\mathbb{E}^{M}\\big[r_{h}+\\mathbb{E}_{a^{\\prime}\\sim\\pi_{h+1}(\\cdot|x_{h+1})}[f(x_{h+1},a^{\\prime})]\\mid x_{h}=x,a_{h}=a]$ for any $\\pi\\,\\in\\,\\Pi_{r\\mathfrak{n}s}$ We define the occupancy measures for layer $h$ via $d_{h}^{M,\\pi}(x)\\,=\\,\\mathbb{P}^{M,\\pi}[x_{h}\\,=\\,x]$ and $d_{h}^{^{M,\\pi}}(x,a)=\\mathbb{P}^{^{M,\\pi}}[x_{h}=x,a_{h}=a]$ ", "page_idx": 2}, {"type": "text", "text": "Online reinforcement learning. In online reinforcement learning, the learning algorithm ALG repeatedly interacts with an unknown MDP $M^{\\star}$ by executing a policy and observing the resulting trajectory. After $T$ rounds of interaction, the algorithm outputs a final policy $\\widehat{\\pi}$ , with the goal of minimizing their $r i s k$ defined via ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathsf{R i}\\,\\mathsf{s k}(T,\\mathrm{ALG},M^{\\star}):=J^{M^{\\star}}(\\pi_{M^{\\star}})-J^{M^{\\star}}(\\widehat\\pi).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Framework: Reinforcement learning under general latent dynamics. In reinforcement learning under general latent dynamics, we consider MDPs $M^{\\star}$ where the dynamics are governed by the evolution of an unobserved latent state $s_{h}$ , while the agent observes and acts on observations $x_{h}$ generated from these latent states. Formally, a latent-dynamics MDP consists of two ingredients: a base $M D P$ $M_{\\mathrm{{lat}}}=\\{S,A,\\{P_{\\mathrm{{lat}},h}\\}_{h=0}^{H},\\{\\dot{R_{\\mathrm{{lat}},h}}\\}_{h=1}^{H},\\dot{H}\\}$ defned overalatenstatespaece $\\boldsymbol{S}$ and adecodable emission process $\\psi:=\\{\\psi_{h}:S\\rightarrow\\Delta(\\mathcal{X})\\}_{h=1}^{H}$ whichmaps eachlant stattoadistributione observations. The former is an arbitrary MDP defined over $\\boldsymbol{S}$ , while the latter is defined as follows. ", "page_idx": 3}, {"type": "text", "text": "Definition 2aI Emsion proces), An mision proces i anyfunction $\\psi:=\\{\\psi_{h}:S\\rightarrow\\Delta(\\mathcal{X})\\}_{h=1}^{H}$ and issaid tobedecodable $i f$ ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\forall h,\\forall s^{\\prime}\\neq s\\in S:\\quad\\operatorname{supp}\\psi_{h}(s)\\cap\\operatorname{supp}\\psi_{h}(s^{\\prime})=\\emptyset.\\quad.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "When $\\psi=\\{\\psi_{h}\\}_{h=1}^{H}$ is decodable, we let $\\psi^{-1}:=\\{\\psi_{h}^{-1}:\\mathcal{X}\\to\\mathcal{S}\\}_{h=1}^{H}$ denote the associated decoder. ", "page_idx": 3}, {"type": "text", "text": "With this, we can formally introduce the notion of a latent-dynamics MDP. ", "page_idx": 3}, {"type": "text", "text": "Definition  2 (Latent-dynamics  MDP). For $a$ baseMDP . $\\begin{array}{r l r l}{M_{\\mathrm{1at}}}&{{}}&{}&{{}=}\\end{array}$ $\\{S,A,\\{P_{1a t,h}\\}_{h=0}^{H},\\{R_{1a t,h}\\}_{h=1}^{H^{'}},H\\}$ and a decodable emission process $\\psi$ the latent-dynamics MDP $\\begin{array}{r}{\\langle\\!\\langle M_{\\mathrm{1at}},\\psi\\rangle\\!\\rangle:=\\{\\mathcal{X},\\mathcal{A},\\{P_{\\mathrm{obs},h}\\}_{h=0}^{H},\\{R_{\\mathrm{obs},h}\\}_{h=1}^{H},H\\}}\\end{array}$ is defined as the MDP where the latent dynamics evolve based on the agent's action $a_{h}\\in A$ via the process $s_{h+1}\\sim P_{\\mathrm{lat},h}(s_{h},a_{h})$ and $r_{h}\\,\\sim\\,R_{\\mathrm{lat},h}(s_{h},a_{h})$ .The latent state is not observed directly, and instead the agent observes $x_{h}\\in\\mathcal{X}$ generated by the emission process $x_{h}\\sim\\psi_{h+1}(s_{h})$ 4. ", "page_idx": 3}, {"type": "text", "text": "Note that under these dynamics, the decoder $\\psi^{-1}$ associated with $\\psi$ ensures that $\\psi_{h}^{-1}(x_{h})\\,=\\,s_{h}$ almost surely for all $h\\in[H]$ . That is, the latent states can be uniquely decoded from the observations. To emphasize the distinction between the latent-dynamics MDP $\\langle\\!\\langle M_{\\mathrm{1at}},\\psi\\rangle\\!\\rangle$ (which operates on the observable state space $\\mathcal{X}$ ) and the MDP $M_{\\mathrm{1at}}$ (which operates on the latent state space $\\boldsymbol{S}$ ), we refer to the latter as a base $M D P$ rather than, for example, a \u201clatent MDP\", and apply a similar convention to other latent objects whenever possible.5 ", "page_idx": 3}, {"type": "text", "text": "Departing from prior work, we do not place any inherent restrictions on the base MDP, and in particular do not assume that the latent space is small (i.e., tabular). Rather, we aim to understand\u2014in a unified fashion\u2014what structural assumptions on the base MDP $M_{\\mathrm{lat}}$ are required to enable learnability under latent dynamics. To this end, it will be useful to considers specific classes (i.e., subsets) of baseMDPs $\\mathcal{M}_{\\mathrm{{lat}}}$ and the classes of latent-dynamics MDPs they induce. ", "page_idx": 3}, {"type": "text", "text": "Definition 2.3 (Latent-dynamics MDP class). Given a set of base MDPs $\\mathcal{M}_{\\mathrm{{lat}}}$ and a set of decoders $\\Phi\\subset\\{\\mathcal{X}\\rightarrow S\\}$ welet ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\langle\\mathcal{M}_{\\mathrm{1at}},\\Phi\\rangle:=\\{\\langle\\mathcal{(M}_{\\mathrm{1at}},\\psi\\rangle\\rangle:M_{\\mathrm{1at}}\\in\\mathcal{M}_{\\mathrm{1at}},\\psi\\;i s\\;d e c o d a b l e,\\;\\psi^{-1}\\in\\Phi\\}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "denote the class of induced latent-dynamics MDPs. ", "page_idx": 3}, {"type": "text", "text": "Stated another way, $\\langle\\!\\langle\\mathcal{M}_{\\mathrm{1at}},\\Phi\\rangle\\!\\rangle$ is the set of all latent-dynamics MDPs $\\langle\\!\\langle M_{\\mathrm{{lat}}},\\psi\\rangle\\!\\rangle$ where (i) the base MDP $M_{\\mathrm{lat}}$ lies in $\\mathcal{M}_{\\mathrm{{lat}}}$ , and (ii), the emission process $\\psi$ is decodable, with the corresponding decoder belonging to $\\Phi$ . The class $\\mathcal{M}_{\\mathrm{{lat}}}$ represents our prior knowledge about the underlying MDP $M_{\\mathrm{lat}}$ ; concrete classes considered in prior work include tabular MDPs [KAL16; DKJADL19; MHKL20; ZSUWAS22; MFR23], linear dynamical systems [DMRY20; DR21; $\\mathrm{Mha}{+}20]$ , and factored MDPs [MLJL21]. In particular, the class $\\mathcal{M}_{\\mathrm{{lat}}}$ may itself warrant using function approximation. At the same time, the class $\\Phi$ represents our prior knowledge or inductive bias about the emission process, enabling representation learning. In what follows, we investigate what conditions on $\\mathcal{M}_{\\mathrm{{lat}}}$ make the induced class $\\langle\\!\\langle\\mathcal{M}_{\\mathrm{1at}},\\Phi\\rangle\\!\\rangle$ tractable, both statistically (statistical modularity; Section 3) and via reduction (algorithmic modularity; Section 4). ", "page_idx": 3}, {"type": "text", "text": "3 Statistical Modularity: Positive and Negative Results ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "This section presents our main statistical results. We begin by formally defining the notion of statistical modularity introduced in Section 1, present our main impossibility result (lower bound) and its implications (Section 3.2), then give positive results for the general class of pushforward-coverable MDPs (Section 3.3). ", "page_idx": 3}, {"type": "text", "text": "3.1  Statistical modularity: A formal definition ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We first define the statistical complexity for a MDP class (or, model class) $\\mathcal{M}$ ", "page_idx": 4}, {"type": "text", "text": "Definition 3.1 (Statistical complexity). We say that an MDP class $\\mathcal{M}$ can be learned up to $\\varepsilon$ optimality using comp $(\\mathcal{M},\\varepsilon,\\delta)$ samples if there exists an algorithm ALG which, for every $M\\in\\mathcal{M}$ attains ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathsf{R i s k}(T,\\mathbf{ALG},M)\\leq\\varepsilon\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "with probability at least $1-\\delta$ after $T={\\mathsf{c o m p}}({\\mathcal{M}},\\varepsilon,\\delta)$ rounds of online interaction in $M$ ", "page_idx": 4}, {"type": "text", "text": "We say that a baseMDP class $\\mathcal{M}_{\\mathrm{{lat}}}$ admits statistically modularity if, for any decoder class $\\Phi$ the induced latent-dynamics MDP class $\\langle\\!\\langle\\mathcal{M}_{\\mathrm{1at}},\\Phi\\rangle\\!\\rangle$ can be learned with statistical complexity that is polynomial in: (i) the statistical complexity for the base class, and (i) the capacity of the decoder class. ", "page_idx": 4}, {"type": "text", "text": "Definition 3.2 (Statistical modularity). We say the MDP class $\\mathcal{M}_{\\mathrm{{lat}}}$ is statistically modular under complexitycomp $\\langle\\mathcal{M}_{\\mathrm{lat}},\\varepsilon,\\delta\\rangle$ if, for every decoder class $\\Phi$ wehave ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathsf{c o m p}(\\langle\\!\\langle\\mathcal{M}_{\\mathrm{1at}},\\Phi\\rangle\\!\\rangle,\\varepsilon,\\delta)=\\mathsf{p o l y}(\\mathsf{c o m p}(\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta),\\log|\\Phi|).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Wesaythat $\\mathcal{M}_{\\mathrm{{lat}}}$ admits strong statistical modularity if Eq. (4) holds when comp $(\\mathcal{M}_{\\sf l a t},\\varepsilon,\\delta)$ isthe minimax samplecomplexty for $\\mathcal{M}_{\\mathrm{{lat}}}$ ", "page_idx": 4}, {"type": "text", "text": "In the sequel, we examine well-studied MDP classes $\\mathcal{M}_{\\mathrm{{lat}}}$ (e.g., those which admit low Bellman rank [JKALS17]) and choose ( $\\mathsf{z o m p}(\\mathcal{M}_{\\mathrm{lat}},\\varepsilon,\\delta)$ based on natural upper bounds on their optimal sample complexity; in this case we will simply say they are (or are not) statistical modular, leaving the complexity upper bound comp implicit. Following prior work [KAL16; DKJADL19; MHKL20; ZSUWAS22; MFR23; DR21; Mha $+20$ ; MLJL21], we use $\\log\\!|\\Phi|$ as a proxy for the statistical complexity of supervised learning with the decoder class $\\Phi$ 6. ", "page_idx": 4}, {"type": "text", "text": "The two most notable examples of statistical modularity covered by prior work are: (i) taking $\\mathcal{M}_{\\mathrm{1at}}$ as the set of tabular MDPs admits strong statistical modularity [DKJADL19; MHKL20; MFR23], and (ii) taking $\\mathcal{M}_{\\mathrm{{lat}}}$ as the set of linear MDPs admits statistical modularity with complexity $\\mathsf{p o l y}(d,H,|\\mathcal{A}|,\\varepsilon^{-1},\\mathsf{l o g}(\\delta^{-1}))$ [AKKS20; UZS22; MCKJA24; MBFR23].7 Interestingly, the latter does not admit strong statistical modularity, because the optimal rate for $\\mathcal{M}_{\\mathrm{{lat}}}$ does not scale with $|{\\mathcal{A}}|$ , but the rate for $\\langle\\!\\langle\\mathcal{M}_{\\mathrm{1at}},\\Phi\\rangle\\!\\rangle$ necessarily does [LS20; HLSW21]. The results of Mhammedi et al.; Misra et al.; Song et al. [Mha $+20$ ; MLJL21; SWFK24] can also be viewed as instances of statistical modularity for other base MDP classes. ", "page_idx": 4}, {"type": "text", "text": "3.2 Lower bounds: Impossibility of statistical modularity ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Our main result in this section is to show that for most MDP classes $\\mathcal{M}_{\\mathrm{{lat}}}$ considered inthe literature on sample-efficient reinforcement learning with function approximation [RVR13; JKALS17; SJKAL19; MJTS20; AJSWY20; Li09; DVRZ19; WSY20; ZGS21; $\\mathrm{Du}+21$ ; JLM21; FKQR21], statistical modularity (under the natural complexity upper bound for the class of interest) is impossible. Our central technical result is the following lower bound, which shows that statistical modularity can be impossible even when the base MDP is known to the learner a-priori. The lower bound is a significant generalization of the result from Song et al. [SWFK24]; we first state the lower bound, then discuss implications. ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.1 (Impossibility of statistical modularity). For every $N\\geq4,$ there exists a decoder class $\\Phi$ with $|\\Phi|=N$ and afamily ofbaseMDPs $\\mathcal{M}_{\\mathrm{{lat}}}$ satisfying (i) $|\\mathcal{M}_{\\mathrm{{lat}}}|=1_{\\cdot}$ (ii) $H\\leq O(\\log(N))$ (iii) $|S|=|\\mathcal{X}|\\le N^{2}$ (iv) $|{\\mathcal{A}}|=2$ ,and such that ", "page_idx": 4}, {"type": "text", "text": "1. For all $\\varepsilon,\\delta>0$ we have comp $(\\mathcal{M}_{\\sf l a t},\\varepsilon,\\delta)=0.$   \n2. For an absolute constant $c>0$ $0,\\,{\\mathsf{c o m p}}(\\langle\\!\\langle M_{\\mathrm{1at}},\\Phi\\rangle\\!\\rangle,c,c)\\geq\\Omega(N/\\log(N)).$ ", "page_idx": 4}, {"type": "text", "text": "In other words, even when the base dynamics are fully known, strong statistical modularity (in this_case, $\\mathtt{p o l y}(\\log|\\Phi|)$ complexity) is impossible;  any algorithm  will  require  at  least $\\operatorname*{min}\\{\\sqrt{S},2^{\\Omega(H)}/H,|\\Phi|\\big/\\mathrm{log}|\\Phi|\\}$ episodes to learn a near-optimal policy for a latent-dynamics MDP $\\displaystyle\\langle\\!\\left<M_{\\mathrm{lat}},\\psi\\right>\\!\\right>\\in\\langle\\!\\left<\\mathcal{M}_{\\mathrm{lat}},\\Phi\\right>\\!\\right>$ ", "page_idx": 4}, {"type": "table", "img_path": "qf2uZAdy1N/tmp/520e2f69e1c790a795ce47cf634657ec7f750b258f2f1b945de7f7d5ab85e8c1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "Figure 1: Summary of statistical modularity (SM) results.   \n\u221a: SM ispossible for a natural choice of comp(-) (e.g., $\\mathsf{p o l y}(|S|,|A|,H,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))$ for tabular MDPs).   \n$\\underline{{\\boldsymbol{x}}}\\colon\\mathbf{SM}$ is not possible with natural choices of $\\mathsf{c o m p}(\\cdot)$   \n?: open.   \n$\\mathopen{}\\mathclose\\bgroup\\left\\{\\mathopen{}\\mathclose\\bgroup\\left\\{\\mathopen{}\\mathclose\\bgroup\\left\\{\\left.\\star\\aftergroup\\egroup\\right.\\aftergroup\\egroup\\right.}\\aftergroup\\egroup\\right.\\aftergroup\\egroup\\right.\\aftergroup\\egroup\\right.\\left.\\mathrm{SM}\\aftergroup\\egroup\\right.$ is possible if willing to pay for (suboptimal) $|{\\mathcal{A}}|$ complexity. See Appendix E.2 for precise descriptions of each setting and our choices for their complexities. ", "page_idx": 5}, {"type": "text", "text": "Intuition for lower bound. The intuition behind the lower bound in Theorem 3.1 is as follows: the unobserved latent state space consists of $N=|\\Phi|$ binary trees (indexed from 1 to $N$ ), each with $N$ leaf nodes. The starting distribution is uniform over the roots of the $N$ trees, and the agent receives a reward of 1 if and only if they navigate to the leaf node that corresponds to the index of their current tree. The observed state space is identical to the latent state space, but the emission process shifts the index of the tree by an amount which is unknown to the agent. Despite the base MDP being known and the decoder class satisfying realizability, the agent requires near-exhaustive search to identify the value of the shift and recover a near-optimal policy. ", "page_idx": 5}, {"type": "text", "text": "A taxonomy of statistical modularity.  As a corollary, we prove that many (but not all) well-studied function approximation settings do not admit statistical modularity by embedding them into the lower bound construction of Theorem 3.1 (as well as a variant of the result, Theorem E.1). Our results are summarized in Figure 1. Our impossibility results highlight the following phenomenon: many MDP classes $\\mathcal{M}_{\\mathrm{{lat}}}$ that place structural assumptions via the value functions (e.g., MDPs with linear- $Q^{\\star}/V^{\\star}$ $[\\mathrm{Du}+21]$ or MDPs with a Bellman complete value function class of bounded eluder dimension [JLM21; WSY20]) become intractable under latent dynamics. Intuitively, this is because it is not possible to take advantage of structure in value functions without learning a good representation, and, simultaneously, these assumptions are too weak by themselves to enable learning such a representation. Meanwhile, MDP classes $\\mathcal{M}_{\\mathrm{{lat}}}$ that place structural assumptions on the transition distribution (e.g., MDPs with low state occupancy complexity $[\\mathrm{Du}+21]$ or low-rank MDPs [AKKS20]) are sometimes (but not always) tractable under latent dynamics.8 ", "page_idx": 5}, {"type": "text", "text": "We point to Appendix E.2 for background on all the settings in Figure 1 and proofs that they are (or are not) statistically modular. We remark that it is fairly straightforward to embed most of the MDP classes of Figure 1 into the construction of Theorem 3.1 since it only uses only a single base MDP $M_{\\mathrm{lat}}$ , and we expect that many other base MDP classes can similarly be shown to be intractable. However, proving the positive results in Figure 1 requires establishing several new results showing that certain base classes are tractable under latent dynamics; most notably, we next discuss the case ofpushforwardcoverability. ", "page_idx": 5}, {"type": "text", "text": "3.3 Upper bounds: Pushforward-coverable MDPs are statistically modular ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Our main postive result concerning statistical modularity is to highlight pushforward coverability [XJ21; AFK24; MFR24]\u2014a strengthened version of the coverability parameter introduced in Xie et al. [XFBJK23]\u2014as a general structural parameter that enables sample-effcient reinforcement learning under latent dynamics. ", "page_idx": 5}, {"type": "text", "text": "Definition 3.3 (Pushforward coverability). The pushforward coverability coefficient $C_{\\mathsf{p u s h}}$ for an MDP $M_{\\mathrm{lat}}$ withtransitionkernel $P_{\\mathrm{1at}}$ isdefinedby ", "page_idx": 6}, {"type": "equation", "text": "$$\nC_{\\mathrm{push}}(M_{\\mathrm{1at}})=\\operatorname*{max}_{h\\in[H]}\\operatorname*{inf}_{\\mu\\in\\Delta(S)}\\operatorname*{sup}_{(s,a,s^{\\prime})\\in S\\times A\\times S}\\frac{P_{\\mathrm{1at},h-1}(s^{\\prime}\\mid s,a)}{\\mu(s^{\\prime})}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Concrete examples [AFK24; MFR24] include: (i) tabular MDPs $M_{\\mathrm{lat}}$ admit $C_{\\mathsf{p u s h}}(M_{\\mathsf{l a t}})\\leq|S|$ ; and (ii) Low-Rank MDPs $M_{\\mathrm{lat}}$ (with or without known features) in dimension $d$ admit $C_{\\mathsf{p u s h}}(M_{\\mathrm{lat}})\\leq d$ Further examples include analytically sparse Low-Rank MDPs [GMR24] and Exogenous Block MDPs with weakly correlated noise [MFR24]. Our main result is as follows. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.2 (Pushforward-coverable MDPs are statistically modular). Let $\\mathcal{M}_{\\mathrm{{lat}}}$ be a base MDP class such that each $M_{\\mathrm{{lat}}}\\in\\mathcal{M}_{\\mathrm{{lat}}}$ has pushforward coverability bounded by $C_{\\mathsf{p u s h}}(M_{\\mathsf{l a t}})\\leq C_{\\mathsf{p u s h}}$ Then, for any decoder class $\\Phi$ , we have: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\cdot\\mathrm{\\sf~comp}(\\langle\\langle\\mathcal{M}_{\\mathrm{1at}},\\Phi\\rangle,\\varepsilon,\\delta)\\leq\\sf p o l y(C_{\\mathrm{push}},|\\mathcal{A}|,H,\\log|\\mathcal{M}_{\\mathrm{1at}}|,\\log|\\Phi|,\\varepsilon^{-1},\\log(\\delta^{-1}),\\log\\log|\\mathcal{S}|).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Theorem 3.2 shows that, modulo a term that is doubly-logarithmic in $|{\\cal S}|$ , latent pushforward coverability enables statistical modularity. That is, when the base (latent) dynamics satisfy pushforward coverability, there exists an algorithm for the latent-dynamics setting which scales with the statistical complexity of the base MDP class and $\\log\\!|\\Phi|$ . We suspect that the additional $\\log\\log\\left|S\\right|$ factor is not essential and can be removed with a more sophisticated analysis. We note that the complexity comp chosen above is not the minimax complexity for $\\mathcal{M}_{\\mathrm{{lat}}}$ , since every set of pushforward coverable MDPs is also a set of coverable MDPs with a potentially smaller coverability parameter [AFK24]. ", "page_idx": 6}, {"type": "text", "text": "Let us provide some intuition for this result. We firstly note that when $M_{\\mathrm{1at}}^{\\star}$ has pushforward coverability parameter $C_{\\mathsf{p u s h}}$ it holds that for any emission process $\\psi^{\\star}$ , the observation-level MDP $M_{\\mathsf{o b s}}^{\\star}:=$ $\\langle\\!\\langle M_{\\mathrm{1at}}^{\\star},\\psi^{\\star}\\rangle\\!\\rangle$ also satisfies pushforward coverability with the same parameter $C_{\\mathsf{p u s h}}$ (Lemma D.5). Yet, despite access to realizable base MDP class $\\mathcal{M}_{\\mathrm{{lat}}}$ and decoder class $\\Phi$ , it is unclear whether the latentdynamics MDP $M_{\\mathrm{obs}}^{\\star}$ satisfhe any of the observation-level function approximation conditions required by existing approaches that provide sample complexity guarantees under pushforward coverability. In particular, known algorithms for this setting either require a Bellman-complete value function class [XFBJK23], a class realizing certain density ratios [AFJSX24; AFK24], or a realizable model class [AFK24], and it is highly nontrivial to construct these for the latent-dynamics MDP $M_{\\mathsf{o b s}}^{\\star}=$ $\\langle\\!\\langle M_{\\mathrm{lat}}^{\\star},\\psi^{\\star}\\rangle\\!\\rangle$ given only the base MDP class $\\mathcal{M}_{\\mathrm{{lat}}}$ and the decoder class $\\Phi$ . Intuitively, this is because the former observation-level function approximation classes capture properties of the observationlevel dynamics which cannot be obtained without some knowledge of the emission process. ", "page_idx": 6}, {"type": "text", "text": "Our main technical contribution is to establish a new structural property for pushforward-coverable MDPs (Lemma F.1): low-dimensional linear embeddings of their latent models can approximate the Bellman updates for an arbitrary set of test functions (as long as the set is not too large). We use this property to construct low-dimensional linear features that can approximate Bellman backups in observation-space, allowing us to (approximately) satisfy the Bellman completeness assumption required to apply GOLF [JLM21] to the latent-dynamics MDP. A fascinating open question is whether a similar approach can be used to establish that standard (as opposed to pushforward) coverable MDPs are statistically modular, which would encompass all other known positive cases of statistical modularity (cf. Figure 1). We refer interested readers to a more detailed technical overview in Appendix F.1, as well as the full proof in Appendix F.2. ", "page_idx": 6}, {"type": "text", "text": "4  Algorithmic Modularity ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We now turn our attention to algorithmic modularity. Specifically, we aim for observable-to-latent reductions, whereby\u2014-via representation learning\u2014-RL under latent dynamics can be efficiently reduced to the simpler problem of RL with latent states directly observed. Since algorithmic modularity is a stronger property than statistical modularity, we sidestep the previous lower bounds in Section 3 through additional feedback and modeling assumptions. Our main result for this section is a new meta-algorithm, O2L, which, under these assumptions (and when equipped with an appropriately designed representation learning oracle), acts as a universal reduction in the sense that, whenever the representation learning oracle has low risk, the reduction transforms any sample-efficient algorithm for any base MDP class into a sample-efficient algorithm for the induced latent-dynamics MDP class. ", "page_idx": 6}, {"type": "text", "text": "1: input: Epochs $T$ , episodes $K$ , decoder set $\\Phi$ , rep. learning oracle REPLEARN, base alg. $\\mathrm{\\bfALG_{\\mathrm{1at}}}$   \n2: for $t=1,2,\\cdots,T$ do   \n3: REPLEARN chooses a representation ${\\widehat{\\phi}}^{(t)}:{\\mathcal{X}}\\to S\\in\\Phi$ based on data collected so far.   \n4: Initialize new instance of $\\mathrm{ALG_{\\mathrm{1at}}}$   \n5: for $k=1,2,\\cdots\\,,K$ do // ALGlat plays $K$ rounds in the $\\widehat{\\ast\\phi}^{\\left(t\\right)}$ -compressed dynamics.\"   \n67 $\\mathrm{\\bfALG_{\\mathrm{1at}}}$ $\\pi_{\\mathrm{1at}}\\circ\\widehat{\\phi}^{\\left(t\\right)}$ $\\pi_{\\mathrm{1at}}^{(t,k)}:S\\times[H]\\to\\Delta(A)$ $\\{x_{h}^{(t,k)},a_{h}^{(t,k)},r_{h}^{(t,k)}\\}_{h=1}^{H}$   \n8: Update $\\mathrm{ALG_{\\mathrm{1at}}}$ with compressed trajectory $\\{\\widehat{\\phi}_{h}^{(t)}(x_{h}^{(t,k)}),a_{h}^{(t,k)},r_{h}^{(t,k)}\\}_{h=1}^{H}.$   \n9: end for   \n10: $\\mathrm{\\bfALG}_{\\mathrm{1at}}$ returns final policy ${\\widehat{\\pi}}^{(t)}:S\\times[H]\\to\\Delta(A)$ , deploy $\\widehat{\\pi}^{(t)}\\circ\\widehat{\\phi}^{(t)}$ to collect one trajectory.   \n11: end for   \n12: return $\\widehat{\\pi}=\\mathsf{U n i f}\\,\\big(\\widehat{\\pi}^{(1)}\\circ\\widehat{\\phi}^{(1)},\\cdot\\cdot\\cdot,\\widehat{\\pi}^{(T)}\\circ\\widehat{\\phi}^{(T)}\\big).$ ", "page_idx": 7}, {"type": "text", "text": "Setup and O2L meta-algorithm. For the results in this section, we denote the (unknown) latentdynamics MDP of interest by $M_{\\mathrm{obs}}^{\\star}:=\\langle\\!\\langle M_{\\mathrm{lat}}^{\\star},\\psi^{\\star}\\rangle\\!\\rangle$ ,and use $\\phi^{\\star}:=(\\psi^{\\star})^{-1}$ to denote the true decoder. The O2L meta-algorithm (Algorithm 1) learns a near-optimal policy for $M_{\\mathsf{o b s}}^{\\star}$ by alternating between performing representation learning and executing a black-box \u201cbase\u201d RL algorithm (designed for the base MDP) on the learned representation; this approach is inspired by empirical methods that blend representation learning and RL in the latent space (e.g., [GKBNB19; SAGHCB20; $\\mathrm{Ni}{+}24]$ ", "page_idx": 7}, {"type": "text", "text": "Concretely, the algorithm takes as input a representation learning oracle REPLEARN and a base RL algorithm $\\mathrm{{ALG}_{\\mathrm{{lat}}}}$ that operates in the latent space. In each epoch $t\\in[T]$ , REPLEARN produces a new representation ${\\widehat{\\phi}}^{(t)}:{\\mathcal{X}}\\to{\\mathcal{S}}$ based on data observed so far (potentially using additional side information, which we will elaborate on in the sequel). Then, the reduction invokes $\\mathrm{{ALG}_{\\mathrm{{lat}}}}$ , using $\\widehat{\\phi}^{\\left(t\\right)}$ to simulate access to the true latent states. In particular, $\\mathrm{\\bfALG}_{\\mathrm{1at}}$ runs for $K$ episodes, where at each episode $k$ (i) $\\mathrm{\\bfALG_{\\mathrm{1at}}}$ produces a latent policy $\\pi_{\\mathrm{1at}}(\\cdot,k):S\\times[H]\\to\\Delta(A)$ (i the latent policy is transformed into an observation-level policy via composition with $\\widehat{\\phi}^{\\left(t\\right)}$ , i.e. $\\pi_{\\mathrm{lat}}(\\mathit{t},\\mathit{k})\\;\\circ\\;\\widehat{\\phi}^{(t)}$ , which is then deployed to produce a trajectory , aft,t), (t.e) h=1, and (i) the trajectory is compressed through (t) andused toudate $\\mathrm{{ALG}_{\\mathrm{{lat}}}}$ $\\{\\widehat{\\phi}_{h}^{(t)}(x_{h}^{(t,k)}),a_{h}^{(t,k)},r_{h}^{(t,k)}\\}_{h=1}^{H}$ (cf. Line of Algorithm )Afterthe K rounds conclude, ALGlat produces a final latent policy iat : $\\widehat{\\pi}_{\\mathrm{1at}}^{(t)}:S\\times[H]\\rightarrow\\Delta(A)$ . The final policy $\\widehat{\\pi}$ chosen by the $\\mathrm{O}2\\mathrm{L}$ algorithm is a uniform mixture of $\\widehat{\\pi}_{\\mathrm{lat}}^{(t)}\\circ\\widehat{\\phi}^{(t)}$ over all the epochs. ", "page_idx": 7}, {"type": "text", "text": "The central assumption behind $\\mathrm{O}2\\mathrm{L}$ is that the base algorithm $\\mathrm{ALG_{\\mathrm{1at}}}$ can achieve low-risk in the underlying base MDP $M_{\\mathrm{1at}}^{\\star}$ if given access to the true latent states $s_{h}=\\phi^{\\star}(x_{h})$ . Beyond this assumption, we require that the representation learning oracle REPLEARN can learn a sufficiently high-quality representation. In our applications, this will be made possible by assuming access to a realizable decoder class $\\Phi$ and two distinct assumptions: hindsight observability (Section 4.1) and conditions enabling self-predictive representation learning (Section 4.2). We will show that under these conditions, we can instantiate a representation learning oracle such that $\\mathrm{O}2\\mathrm{L}$ inherits the sample complexity guarantee for $\\mathrm{{ALG}_{\\mathrm{{lat}}}}$ , thereby achieving algorithmic modularity. ", "page_idx": 7}, {"type": "text", "text": "4.1  Algorithmic modularity via hindsight observability ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Our first algorithmic result bypasses the hardness in Section 3 by considering the setting of hindsight observability, which has garnered recent interest in the context of POMDPs [LADZ23; GCWXWB24; SLS23; LXJZV24]. Here, we assume that at training time (but not during deployment), the algorithm has access to additional feedback in the form of the true latent states, which are revealed at the end of eachepisode. ", "page_idx": 7}, {"type": "text", "text": "Assumption 4.1 (Hindsight Observability [LADZ23]). The latent states $\\bigl(\\phi_{1}^{\\star}(x_{1}),\\ldots,\\phi_{H}^{\\star}(x_{H})\\bigr)$ are revealed to the learner after each episode $(x_{1},a_{1},r_{1},\\dots,x_{H},a_{H},r_{H})$ concludes. ", "page_idx": 7}, {"type": "text", "text": "We emphasize that in the hindsight observability framework, the learner must still execute observationspacepolicies $\\pi_{\\mathsf{o b s}}:{\\mathcal{X}}\\times[H]\\to\\Delta(A)$ , as the latent states are only revealed at the end of each episode. Under hindsight observability, we can instantiate the representation learning oracle in $\\mathrm{O}2\\mathrm{L}$ sothat the reduction achieves low risk for any choice of black-box base algorithm $\\mathrm{\\bfALG}_{\\mathrm{1at}}$ .In particular, we make use of online classification oracles, which use the revealed latent states to achieve low classification losswithrespectto $\\phi^{\\star}$ under adaptively generated data. We first state a guarantee based on generic classification oracles, then instantiate it to give a concrete end-to-end sample complexity bound. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Formally, at each step $t$ , the online classification oracle, denoted via $\\mathrm{REP}_{\\mathsf{c l a s s}}$ , is given the states and hindsight observations collected so far and produces a deterministic estimate $\\widehat{\\phi}^{\\scriptscriptstyle(t)}\\;=$ $\\mathrm{REP}_{\\mathrm{class}}\\big(\\{x_{h}^{(i)},\\phi_{h}^{\\ast}(x_{h}^{(i)})\\}_{i<t,h\\leq H}\\big)$ for the true decoder $\\phi^{\\star}$ Wemeasure theregret of the oracle via the $0/1$ loss for classification: ", "page_idx": 8}, {"type": "equation", "text": "$$\n{\\mathsf{R e g}}_{\\mathtt{c l a s s}}(T):=\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}_{\\pi^{(t)}\\sim p^{(t)}}\\,\\mathbb{E}^{\\pi^{(t)}}\\Bigl[\\mathbb{I}\\bigl\\{\\widehat{\\phi}_{h}^{(t)}(x_{h})\\not=\\phi_{h}^{\\star}(x_{h})\\bigr\\}\\Bigr],\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $\\boldsymbol{p}^{(t)}$ represents a randomization distribution over the policy $\\pi^{(t)}$ . Our reduction succeeds under the assumption that the oracle has low expected regret. ", "page_idx": 8}, {"type": "text", "text": "Assumption 4.2. For any (possibly adaptive) sequence $\\pi^{(t)}$ with $\\pi^{(t)}\\sim p^{(t)}$ ,the online classification oracle $\\mathbf{REP}_{\\mathsf{c l a s s}}$ has expected regret bounded by ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathsf{R e g}_{\\mathsf{c l a s s}}(T)]\\leq\\mathsf{E s t}_{\\mathsf{c l a s s}}(T),\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $\\mathsf{E s t}_{\\mathsf{c l a s s}}(T)$ is a known upper bound. ", "page_idx": 8}, {"type": "text", "text": "We apply such an oracle within $\\mathrm{O}2\\mathrm{L}$ as follows: at the end of each iteration $t~\\in~[T]$ in $\\mathrm{O}2\\mathrm{L}$ $k\\ \\sim\\ \\lceil K\\rceil$   \n$\\big(x_{1}^{(t,k)},a_{1}^{(t,k)},r_{1}^{(\\hat{t},k)}\\big),\\dots,\\big(\\dot{x}_{H}^{(t,k)}a_{H}^{(t,k)},r_{H}^{(\\hat{t},k)}\\big)$   \n$\\mathsf{R i s k}_{\\mathsf{o b s}}(T K)$ denote the risk of the O2L reduction when run for $T$ epochs of $K$ episodes, and we let $\\mathsf{R i s k}_{\\star}(K):=\\mathbb{E}[\\mathsf{R i s k}(K,\\mathsf{A L G}_{\\mathrm{lat}},M_{\\mathrm{lat}}^{\\star})]$ denote the expected risk of $\\mathrm{\\bfALG_{\\mathrm{1at}}}$ when executed on $M_{\\mathrm{1at}}^{\\star}$ with access to the true latent states $\\bar{s_{h}}=\\phi^{\\star}(x_{h})$ for $K$ episodes. ", "page_idx": 8}, {"type": "text", "text": "Theorem 4.1 (Risk bound for O2L under hindsight observability). Let $\\mathrm{ALG}_{\\mathrm{1at}}$ bea base algorithm with base risk $\\mathsf{R i s k}_{\\star}(K)$ , and REPclass $a$ representation learning oracle satisfying Assumption 4.2. Then Algorithm $^{\\,l}$ with inputs $T,K,\\Phi$ $\\mathrm{REP}_{\\mathsf{c l a s s}}$ ,and $\\mathrm{\\bfALG}_{\\mathrm{1at}}$ ,has expected risk ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathsf{R i}\\,\\mathsf{s k}_{\\mathsf{o b s}}(T K)]\\le\\mathsf{R i}\\,\\mathsf{s k}_{\\star}(K)+\\frac{2K}{T}\\mathsf{E s t}_{\\mathsf{c l a s s}}(T).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "This result shows that we can achieve sublinear risk under latent dynamics as long as (i) the base algorithm achieves sublinear risk $\\mathsf{R i s k}_{\\star}(K)$ given access to the true latent states, and (ii) the classification oracle achieves sublinear regret $\\mathsf{E s t}_{\\mathsf{c l a s s}}(T)$ . Notably, the result is fully modular, meaning we require no explicit conditions on the latent dynamics or the base algorithm, and is computationally efficient whenever the base algorithm and classification oracle are efficient. ", "page_idx": 8}, {"type": "text", "text": "To make Theorem 4.1 concrete, we next provide a representation learning oracle (ExPWEIGHTs.DR; Algorithm 3 in Appendix G.1) based on a derandomization of the classical exponential weights mechanism, which satisfies Assumption 4.2 with Estclass $\\lesssim H\\log|\\Phi|$ whenever it has access to a class $\\Phi$ that satisfies decoder realizability. ", "page_idx": 8}, {"type": "text", "text": "Lemma 4.1 (Online classification via ExPWEIGHTs.DR). Under decoder realizability $(\\phi^{\\star}\\in\\Phi)$ ExPWEIGHTs.DR (Algorithm 3) satisfies Assumption $4.2\\ w i t h^{10}$ ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathsf{E s t}_{\\mathsf{c l a s s}}(T)=\\widetilde{\\mathcal{O}}(H\\log|\\Phi|).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Instantiating Theorem 4.1 with the above representation learning oracle, we obtain the following algorithmic modularity result. ", "page_idx": 8}, {"type": "text", "text": "Corollary 4.1 (Algorithmic modularity under hindsight observability). For any base algorithm $\\mathrm{ALG_{\\mathrm{1at}}}$ underdecoderrealizability $(\\phi^{\\star}\\in\\Phi]$ ,O2Lwithinputs $T,K,\\Phi$ ,EXPWEIGHTS.DR, and $\\mathrm{ALG_{\\mathrm{1at}}}$ achieves ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathsf{R i s k}_{\\mathsf{o b s}}(T K)]\\lesssim\\mathsf{R i s k}_{\\star}(K)+\\frac{H K\\log|\\Phi|}{T}.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Consequently, for any $\\mathrm{{ALG}_{\\mathrm{{lat}}}}$ setting $T\\approx K H\\log|\\Phi|/\\mathsf{R i s k}_{\\star}(K)$ achieves $\\mathbb{E}[{\\sf R i s k}_{\\sf o b s}(T K)]\\lesssim$ $\\mathsf{R i s k}_{\\star}(K)$ with a number of trajectories $T K=\\widetilde{\\mathcal{O}}\\big(K^{2}H\\log|\\Phi|\\big/\\mathsf{R i s k}_{\\star}(K)\\big)$ ", "page_idx": 8}, {"type": "text", "text": "Beyond achieving algorithmic modularity, this result shows that under hindsight observability, we can achieve strong statistical modularity (modulo possible $H$ factors) for every base MDP class $\\mathcal{M}_{\\mathrm{{lat}}}$ , an important result in its own right.11 As an example, suppose that $\\mathsf{R i s k}_{\\star}(K)=\\mathcal O(K^{-1/2})$ which is satisfied by many standard algorithms of interest [JKALS17; JYWJ20; JLM21; FKQR21]. Then, seting $T$ according to Corollary 4.1 obtains an expected risk bound of $\\varepsilon$ using ${\\mathcal{O}}{\\bigl(}H\\log|\\Phi|/\\varepsilon^{5}{\\bigr)}$ trajectories. ", "page_idx": 9}, {"type": "text", "text": "Remark 4.1 (Online versus offine oracles). Theorem 4.1 critically uses that assumption that $\\mathrm{REP}_{\\mathsf{c l a s s}}$ satisfies an online classification error bound to handle the fact that data is generated adaptively based on the estimators $\\widehat{\\phi}^{(1)},\\ldots,\\widehat{\\phi}^{(T)}$ it produces, which is by now a relatively standard technique in the design of interactive decision making algorithms [FR20; FKQR21; FR23]. We note that under coverability and other exploration conditions, online oracles for classification can be directly obtained from offine (i.e. supervised) classification oracles [XFBJK23; BRS24; FHQR24]. ", "page_idx": 9}, {"type": "text", "text": "4.2  Algorithmic modularity via self-predictive estimation ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We complement the above results by studying the general online RL setting without hindsight observations. To address this more challenging setting, we design an optimistic self-predictive estimation objective (Eq. (7)), which learns a representation by jointly fitting a decoder together with a latent model. We prove that any representation learning oracle that attains low regret with respect to this objective can be used in O2L to obtain observable-to-latent reductions for any low-risk basealgorithm $\\mathrm{{ALG}_{\\mathrm{{lat}}}}$ (for a formal statement, see Theorem A.1). We provide a (computationally inefficient) estimator (SELFPREDICT.OPT; Algorithm 4 in Appendix H.1) which we show attains low optimistic self-regret under certain statistical conditions (namely, coverability of the base MDP and a function approximation condition enabling us to express the self-prediction target as a latent model, see Lemma A.1 for a formal statement), thereby obtaining an end-to-end reduction for the general online RL setting. For lack of space, these results are deferred to Appendix A. ", "page_idx": 9}, {"type": "text", "text": "5 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Our work initiates the study of statistical and algorithmic modularity for reinforcement learning under general latent dynamics. Our positive and negative results serve as a first step toward a unified theory for reinforcement learning in the presence of high-dimensional observations. To this end, we close with some important future directions and open problems. ", "page_idx": 9}, {"type": "text", "text": "Statistical modularity. Can we obtain a unified characterization for the statistical complexity of RL under latent dynamics with a given class of base MDPs $\\mathcal{M}_{\\mathrm{1at}}?$ Our results in Section 3 suggest that this will require new tools that go beyond existing notions of statistical complexity. Toward resolving this problem, concrete questions that are not yet understood include: (i) Is coverability [XFBJK23] (as opposed to pushforward coverability) sufficient for learnability under latent dynamics? (i) Is the Exogenous Block MDP problem [EMKAL22; MFR24]\u2014a special case of our general framework\u2014 statistically tractable? Lastly, are there additional types of feedback that are weaker than hindsight observability, yet suffice to bypass the hardness results in Section 3? ", "page_idx": 9}, {"type": "text", "text": "Algorithmic modularity. Can we derive a unified representation learning objective that enables algorithmic modularity whenever statistical modularity is possible? Ideally, such an objective would be computationally tractable. Alternatively, can we show that algorithmic modularity fundamentally requires stronger modeling assumptions than statistical modularity? Toward addressing the problems above, a first step might be to understand: (i) What are the minimal statistical assumptions under which we can minimize the self-predictive objective in Section 4.2? (i) How can we encourage finding good representations via self-prediction beyond the use of optimism over the base (latent) models; and (ii) when can we minimize self-prediction in a computationally efficient fashion? ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Nan Jiang acknowledges funding support from NSF IS-2112471, NSF CAREER IIS-2141781, Google Scholar Award, and Sloan Fellowship. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[ACK24] Philip Amortila, Tongyi Cao, and Akshay Krishnamurthy. \u201cMitigating Covariate Shift in Misspecified Regression With Applications to Reinforcement Learning\". In: Conference on Learning Theory. 2024.   \n[AFJSX24] Philip Amortila, Dylan J. Foster, Nan Jiang, Ayush Sekhari, and Tengyang Xie. \"Harnessing Density Ratios for Online Reinforcement Learning\". In: International Conference on Learning Representations. 2024.   \n[AFK24] Philip Amortila, Dylan J Foster, and Akshay Krishnamurthy. \u201cScalable Online Exploration via Coverability\". In: International Conference on Machine Learning. 2024.   \n[AHKLLS14] Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, and Robert Schapire. \"Taming the monster: A fast and simple algorithm for contextual bandits\"'. In: International Conference on Machine Learning. 2014.   \n[AJKS22] Alekh Agarwal, Nan Jiang, Sham M Kakade, and Wen Sun. Reinforcement learning: Theory and algorithms. https : / / rltheorybook . github . io/. Version: January 31, 2022. 2022.   \n[AJSWY20] Alex Ayoub, Zeyu Jia, Csaba Szepesvari, Mengdi Wang, and Lin Yang. \u201cModelBased Reinforcement Learning with Value-Targeted Regresson\". In: International Conference on Machine Learning. 2020.   \n[AKKS20] Alekh Agarwal, Sham Kakade, Akshay Krishnamurthy, and Wen Sun. \u201cFLAMBE: Structural Complexity and Representation Learning of Low Rank MDPs\". In: Neural Information Processing Systems. 2020.   \n[AOM17] Mohammad Gheshlaghi Azar, Ian Osband, and Remi Munos. \u201cMinimax Regret Bounds for Reinforcement Learning\". In: International Conference on Machine Learning. 2017.   \n[AZ22] Alekh Agarwal and Tong Zhang. \u201cModel-based RL with Optimistic Posterior Sampling: Structural Conditions and Sample Complexity\". In: Neural Information Processing Systems. 2022.   \n[Bak+22] Bowen Baker, Ilge Akkaya, Peter Zhokov, Joost Huizinga, Jie Tang, Adrien Ecoffet, Brandon Houghton, Raul Sampedro, and Jeff Clune. \u201cVideo PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos\". In: Neural Information Processing Systems. 2022.   \n[BLM13] Stephane Boucheron, Gabor Lugosi, and Pascal Massart. Concentration inequalities: A nonasymptotic theory of independence. Oxford university press, 2013.   \n[Bro+22] Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Joseph Dabis, Chelsea Finn, Kerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Jasmine Hsu, Julian Ibarz, Brian Ichter, Alx Irpan, Tomas Jackson, Sally Jesmonth, Nihil J Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Isabel Leal, Kuang-Huei Lee, Sergey Levine, Yao Lu, Utsav Malla, Deeksha Manjunath, Igor Mordatch, Ofir Nachum, Carolina Parada, Jodilyn Peralta, Emily Perez, Karl Pertsch, Jornell Quiambao, Kanishka Rao, Michael Ryoo, Grecia Salazar, Pannag Sanketi, Kevin Sayed, Jaspiar Singh, Sumedh Sontakke, Austin Stone, Clayton Tan, Huong Tran, Vincent Vanhoucke, Steve Vega, Quan Vuong, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu, Tianhe Yu, and Brianna Zitkovich. \u201cRT-1: Robotics Transformer for RealWorld Control at Scale\". In: arXiv:2212.06817. 2022.   \n[BRS24] Adam Block, Alexander Rakhlin, and Abhishek Shetty. \u201cOn the Performance of Empirical Risk Minimization with Smoothed Data\". In: Conference on Learning Theory. 2024.   \n[CBL06] Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge universty press, 2006.   \n[CJ19] Jinglin Chen and Nan Jiang. \u201cInformation-Theoretic Considerations in Batch Reinforcement Learning\". In: International Conference on Machine Learning. 2019.   \n[DKJADL19] Simon Du, Akshay Krishnamurthy, Nan Jiang, Alekh Agarwal, Miroslav Dudik, and John Langford. \u201cProvably Efficient RL With Rich Observations via Latent State Decoding\". In: International Conference on Machine Learning. 2019.   \n[DMKV21] Omar Darwiche Domingues, Pierre Menard, Emilie Kaufmann, and Michal Valko. \"Episodic Reinforcement Learning in Finite MDPs: Minimax Lower Bounds Revisited\". In: Algorithmic Learning Theory. 2021.   \n[DMRY20] Sarah Dean, Nikolai Matni, Benjamin Recht, and Vickie Ye. \u201cRobust Guarantees for Perception-Based Control\". in: Learning for Dynamics and Control. 2020.   \n[DR21] Sarah Dean and Benjamin Recht. \u201cCertainty Equivalent Perception-Based Control. In: Learning for Dynamics and Control. 2021.   \n$[\\mathrm{Du}+21]$ Simon S Du, Sham M Kakade, Jason D Lee, Shachar Lovet, Gaurav Mahajan, Wen Sun, and Ruosong Wang. \u201cBilinear Classes: A Structural Framework for Provable Generalization in RL\". In: International Conference on Machine Learning. 2021.   \n[DVRZ19] Shi Dong, Benjamin Van Roy, and Zhengyuan Zhou. \u201cProvably Effcient Reinforcement Learning With Aggregated States\". In: arXiv:1912.06366. 2019.   \n[EFMKL22] Yonathan Efroni, Dylan J Foster, Dipendra Misra, Akshay Krishnamurthy, and John Langford. \u201cSample-Efficient Reinforcement Learning in the Presence of Exogenous Information\". In: Conference on Learning Theory. 2022.   \n[EMKAL22] Yonathan Efroni, Dipendra Misra, Akshay Krishnamurthy, Alekh Agarwal, and John Langford.\u201cProvable RL With Exogenous Distractors via Multistep Inverse Dynamics\". In: International Conference on Learning Representations. 2022.   \n[FGH23] Dylan J Foster, Noah Golowich, and Yanjun Han. \u201cTight Guarantees for Interactive Decision Making with the Decision-Estimation Coefficient'. In: Conference on Learning Theory. 2023.   \n[FGQRS23] Dylan J Foster, Noah Golowich, Jian Qian, Alexander Rakhlin, and Ayush Sekhari. \"Model-Free Reinforcement Learming with the Decision-Estimation Coefficient'. In: Neural Information Processing Systems. 2023.   \n[FHQR24] Dylan J Foster, Yanjun Han, Jian Qian, and Alexander Rakhlin. \u201cOnline Estimation via Offine Estimation: An Information-Theoretic Framework\". In: arXiv:2404.10122. 2024.   \n[FKQR21] Dylan J Foster, Sham M Kakade, Jian Qian, and Alexander Rakhlin. \\*The Statistical Complexity of Interactive Decision Making\". In: arXiv:2112.13487. 2021.   \n[FR20] Dylan J Foster and Alexander Rakhlin. \u201cBeyond UCB: Optimal and Efficient Contextual Bandits With Regression Oracles\". In: International Conference on Machine Learning. 2020.   \n[FR23] Dylan J Foster and Alexander Rakhlin. \u201cFoundations of Reinforcement Learning and Interactive Decision Making\". In: arXiv:2312.16730. 2023.   \n[FWYDY20] Fei Feng, Ruosong Wang, Wotao Yin, Simon S Du, and Lin Yang. \u201cProvably Efficient Exploration for Reinforcement Learning Using Unsupervised Learning\". In: Neural Information Processing Systems. 2020.   \n[GCWXWB24] Jiacheng Guo, Minshuo Chen, Huan Wang, Caiming Xiong, Mengdi Wang, and Yu Bai. \u201cSample-Efficient Learning of POMDPs with Multiple Observations In Hindsight\". In: International Conference on Learning Representations. 2024.   \n[Gee00] S. A. van de Geer. Empirical Processes in M-Estimation. Cambridge University Press, 2000.   \n[GKBNB19] Carles Gelada, Saurabh Kumar, Jacob Buckman, Ofr Nachum, and Marc G Bellemare. \u201cDeepMDP: Learning Continuous Latent Space Models for Representation Learning\". In: International Conference on Machine Learning. 2019.   \n[GMR24] Noah Golowich, Ankur Moitra, and Dhruv Rohatgi. \u201cExploring and Learning in Sparse Linear MDPs Without Computationally Intractable Oracles\". In: Symposium on Theory of Computing. 2024.   \n[Guo+22] Zhaohan Guo, Shantanu Thakoor, Miruna Pislar, Bernardo Avila Pires, Florent Altche, Corentin Tallec, Alaa Saade, Daniele Calandriello, Jean-Bastien Grill, Yunhao Tang, Michal Valko, Remi Munos, Mohammad Gheshlaghi Azar, and Bilal Piot. \u201cBYOL-Explore: Exploration by Bootstrapped Prediction\". In: Neural Information Processing Systems. 2022.   \n[Haf+19] Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee, and James Davidson. \u201cLearning Latent Dynamics for Planning From Pixels\". In: International Conference on Machine Learning. 2019.   \n[HLBN19] Danijar Hafner, Timothy Lillicrap, Jimmy Ba, and Mohammad Norouzi. \u201cDream to Control: Learning Behaviors by Latent Imagination\". In: International Conference on Learning Representations. 2019.   \n[HLNB21] Danijar Hafner, Timothy Lillicrap, Mohammad Norouzi, and Jimmy Ba. \u201cMastering Atari With Discrete World Models\". In: International Conference on Learning Representations. 2021.   \n[HLSW21] Botao Hao, Tor Lattimore, Csaba Szepesvari, and Mengdi Wang.\u201cOnline Sparse Reinforcement Learning\" In: International Conference on Artificial Intelligence and Statistics. 2021.   \n[HPBL23] Danijar Hafner, Jurgis Pasukonis, Jimmy Ba, and Timothy Lillicrap.\u201cMastering Diverse Domains Through World Models\"'. In: arXiv:2301.04104. 2023.   \n[Jia24] Nan Jiang. \u201cA Note on Loss Functions and Error Compounding in Model-based Reinforcement Learning\"'. In: arXiv:2404.09946. 2024.   \n[JKALS17] Nan Jiang, Akshay Krishnamurthy, Alekh Agarwal, John Langford, and Rober E Schapire. \u201cContextual Decision Processes With Low Bellman Rank Are PACLearnable\"'. In: International Conference on Machine Learning. 2017.   \n[JLM21] Chi Jin, Qinghua Liu, and Sobhan Miryoosef. \u201cBellman Eluder Dimension: New Rich Classes of RL Problems, and Sample-Efficient Algorithms\". In: Neural Information Processing Systems. 2021.   \n[JYWJ20] Chi Jin,Zhuoran Yang,Zhaoran Wang, and Michael  Jordan.Provably Effcient Reinforcement Learning With Linear Function Approximation\". In: Conference on Learning Theory. 2020.   \n[KAL16] Akshay Krishnamurthy, Alekh Agarwal, and John Langford. \u201cPAC Reinforcement Learning With Rich Observations\". In: Neural Information Processing Systems. 2016.   \n[KFPM21] Ashish Kumar, Zipeng Fu, Deepak Pathak, and Jitendra Malik. \u201c\\*RMA: Rapid Motor Adaptation for Legged Robots\"'. In: Robotics: Science and Systems. 2021.   \n[LADZ23] Jonathan Lee, Alekh Agarwal, Christoph Dann, and Tong Zhang. \u201cLearning in POMPDs Is Sample-Efficient With Hindsight Observability\". In: International Conference on Machine Learning. 2023.   \n[Lam+24] Alex Lamb, Riashat Islam, Yonathan Efroni, Aniket Rajiv Didolkar, Dipendra Misra, Dylan J Foster, Lekan P Molu, Rajan Chari, Akshay Krishnamurthy, and John Langford. \u201cGuaranteed Discovery of Control-Endogenous Latent States with Multi-Step Inverse Models\". In: Transactions on Machine Learning Research. 2024.   \n[LFDA16] Sergey Levine, Chelsea Finn, Trevor Darrell, and Pieter Abbeel. \u201cEnd-To-End Training of Deep Visuomotor Policies\". In: The Journal of Machine Learning Research. 2016.   \n[Li09] Lihong Li. A Unifying Framework for Computational Reinforcement Learning Theory. Rutgers, The State University of New Jersey, 2009.   \n[LS20] Tor Latimore and Csaba Szepesvari. Bandit Algorithms. Cambridge University Press, 2020.   \n[LSA20] Michael Laskin, Aravind Srinivas, and Pieter Abbeel. \u201cCURL: Contrastive Unsupervised Representations for Reinforcement Learning\". In: International Conference on Machine Learning. 2020.   \n[LXJZV24] Michael Lanier, Ying Xu, Nathan Jacobs, Chongjie Zhang, and Yevgeniy Vorobeychik. \u201cLearning Interpretable Policies in Hindsight-Observable POMDPs through Partially Supervised Reinforcement Learning\". In: arXiv: 2402.09290. 2024.   \n[MBFR23] Zak Mhammedi, Adam Block, Dylan J Foster, and Alexander Rakhlin. \u201cEffcient Model-Free Exploration in Low-Rank MDPs\". In: Neural Information Processing Systems. 2023.   \n[MCKJA24] Aditya Modi, Jinglin Chen, Akshay Krishnamurthy, Nan Jiang, and Alekh Agarwal. \"\u201cModel-Free Representation Learning and Exploration in Low-Rank Mdps\". In: Journal of MachineLearning Research.2024.   \n[MFR23] Zakaria Mhammedi, Dylan J Foster, and Alexander Rakhlin. \u201cRepresentation Learning With Multi-Step Inverse Kinematics: An Eficient and Optimal Approach to Rich-Observation RL\". In: International Conference on Machine Learning. 2023.   \n[MFR24] Zakaria Mhammedi, Dylan J Foster, and Alexander Rakhlin. \u201cThe Power of Resets in Online Reinforcement Learning\"'. In: arXiv:2404.15417. 2024.   \n[Mha+20] Zakaria Mhammedi, Dylan J Foster, Max Simchowitz, Dipendra Misra, Wen Sun, Akshay Krishnamurthy, Alexander Rakhlin, and John Langford. \u201cLearning the Linear Quadratic Regulator From Nonlinear Observations\". In: Neural Information Processing Systems. 2020.   \n[MHKL20] Dipendra Misra, Mikael Henaff, Akshay Krishnamurthy, and John Langford. \u201cKinematic State Abstraction and Provably Effcient Rich-Observation Reinforcement Learning\". In: International Conference on Machine Learning. 2020.   \n[MJTS20] Aditya Modi, Nan Jiang, Ambuj Tewari, and Satinder Singh. \u201cSample Complexity of Reinforcement Learning Using Linearly Combined Model Ensembles\". In: International Conference on Artificial Intelligence and Statistics. 2020.   \n[MLJL21] Dipendra Misra, Qinghua Liu, Chi Jin, and John Langford. \u201cProvable Rich Observation Reinforcement Learning With Combinatorial Latent States\". In: International Conference on Learning Representations. 2021.   \n$[\\mathrm{Ni}+24]$ Tianwei Ni, Benjamin Eysenbach, Erfan Seyedsalehi, Michel Ma, Clement Gehring, Aditya Mahajan, and Pierre-Luc Bacon. Bridging State and History Representations: Understanding Self-Predictive RL\". In: arXiv:2401.08898. 2024.   \n[NRKFG22] Suraj Nair, Aravind Rajeswaran, Vikash Kumar, Chelsea Finn, and Abhinav Gupta. \u201c\"R3M: A Universal Visual Representation for Robot Manipulation\". In: arXiv:2203.12601. 2022.   \n[OVR16] Ian Osband and Benjamin Van Roy.\\*On Lower Bounds for Regret in Reinforcement Learning\"'. In: arXiv:1608.02732. 2016.   \n[PAED17] Deepak Pathak, Pulkit Agrawal, Alexei A Efros, and Trevor Darrell \u201cCuriosityDriven Exploration by Self-Supervised Prediction\". In: International Conference on Machine Learning. 2017, pp. 2778-2787.   \n[RH23] Philippe Rigollet and Jan-Christian Hutter. \u201cHigh-dimensional statistics\". In: arXiv:2310.19244. 2023.   \n[RVR13] Daniel Russo and Benjamin Van Roy. \u201cEluder Dimension and the Sample Complexity of Optimistic Exploration\". In: Neural Information Processing Systems. 2013.   \n[SAGHCB20] Max Schwarzer, Ankesh Anand, Rishab Goel, R Devon Hjelm, Aaron Courville, and Philip Bachman. \u201cData-Efficient Reinforcement Learning with Self-Predictive Representations\". In: International Conference on Learning Representations. 2020.   \n$[\\mathrm{Sch}+20]$ Julian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen Smonyan,Larent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis Hassabis, Thore Graepel, Timothy Lillicrap, and David Silver. \u201cMastering Atari, Go, Chess and Shogi by Planning With a Learned Model\". In: Nature. 2020.   \n[SJKAL19] Wen Sun, Nan Jiang, Akshay Krishnamurthy, Alekh Agarwal, and John Langford. \"Model-Based RL in Contextual Decision Processes: PAC Bounds and Exponential Improvements Over Model-Free Approaches\". In: Conference on Learning Theory. 2019.   \n[SLS23] Ming Shi, Yingbin Liang, and Ness Shroff. \u201cTheoretical Hardness and Tractability of POMDPs in RL with Partial Hindsight State Information\"'. In: arXiv:2306.08762. 2023.   \n[SWFK24] Yuda Song, Lili Wu, Dylan J Foster, and Akshay Krishnamurthy. \u201cRichObservation Reinforcement Learning with Continuous Latent Dynamics\". In: International Conference on Machine Learning. 2024.   \n[SZSBKS23] Yuda Song, Yifei Zhou, Ayush Sekhari, J Andrew Bagnell, Akshay Krishnamurthy, and Wen Sun. \u201cHybrid RL: Using Both Offline and Online Data Can Make RL Efficient'. In: International Conference on Learning Representations. 2023.   \n[Tan+17] Haoran Tang, Rein Houthooft, Davis Foote, Adam Stooke, OpenAI Xi Chen, Yan Duan, John Schulman, Filip DeTurck, and Pieter Abbeel. \\*# Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning\". In: Neural Information Processing Systems. 2017.   \n[Tan+23] Yunhao Tang, Zhaohan Daniel Guo, Pierre Harvey Richemond, Bernardo Avila Pires, Yash Chandak, Remi Munos, Mark Rowland, Mohammad Gheshlaghi Azar, Charline Le Lan, Clare Lyle, Andras Gyorgy, Shantanu Thakoor, Will Dabney, Bilal Piot, Daniele Calandriello, and Michal Valko. \u201cUnderstanding Self-Predictive Learning for Reinforcement Learning\". In: International Conference on Machine Learning. 2023.   \n[UZS22] Masatoshi Uehara, Xuezhou Zhang, and Wen Sun. \u201cRepresentation Learning for Online and Ofline RL in Low-rank MDPs\". In: The Tenth International Conference on Learning Representations. 2022.   \n[WSD15] Niklas Wahlstrom, Thomas B Schon, and Marc Peter Deisenroth. \u201cFrom Pixels to Torques: Policy Learning With Deep Dynamical Models\". In: International Conference on Machine Learning. 2015.   \n[WSY20] Ruosong Wang, Russ R Salakhutdinov, and Lin Yang. \u201cReinforcement Learning with General Value Function Approximation: Provably Effcient Approach via Bounded Eluder Dimension\". In: Neural Information Processing Systems. 2020.   \n[WYDW21] Tianhao Wu, Yunchang Yang, Simon Du, and Liwei Wang. \u201c\"On Reinforcement Learning With Adversarial Corruption and Its Application to Block MDP\". In: International Conference on Machine Learning. 2021.   \n[XFBJK23] Tengyang Xie, Dylan J Foster, Yu Bai, Nan Jiang, and Sham M Kakade. \u201cThe Role of Coverage in Online Reinforcement Learning\". In: International Conference on Learning Representations. 2023.   \n[XJ21] Tengyang Xie and Nan Jiang. \u201cBatch Value-Function Approximation With Only Realizability'\". In: International Conference on Machine Learning. 2021.   \n[YFK21] Denis Yarats, Rob Fergus, and llya Kostrikov. \u201cImage Augmentation Is All You Need: Regularizing Deep Reinforcement Learning From Pixels\". In: International Conference on Learning Representations.2021.   \n[ZGS21] Dongruo Zhou, Quanquan Gu, and Csaba Szepesvari. \u201cNearly Minimax Optimal Reinforcement Learning for Linear Mixture Markov Decision Processes\". In: Conference on Learning Theory. 2021.   \n[Zha06] Tong Zhang. \u201cFrom $\\epsilon$ -entropy to KL-entropy: Analysis of minimum information complexity density estimation\". In: The Annals of Statistics. Vol. 34. 5. Institute of Mathematical Statistics, 2006, pp. 2180-2210.   \n[Zha22] Tong Zhang. \u201cFeel-Good Thompson Sampling for Contextual Bandits and Reinforcement Learning\". In: SIAM Journal on Mathematics of Data Science. 2022.   \n[ZMCGL21] Amy Zhang, Rowan McAllister, Roberto Calandra, Yarin Gal, and Sergey Levine. \"Learning Invariant Representations for Reinforcement Learning Without Reconstruction\". In: International Conference on Learning Representations. 2021.   \n[ZSUWAS22] Xuezhou Zhang, Yuda Song, Masatoshi Uehara, Mengdi Wang, Alekh Agarwal, and Wen Sun. \u201cEfficient Reinforcement Learning in Block MDPs: A Model-Free Representation Learning Approach\". In: International Conference on Machine Learning.2022. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "Contents ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A  Omitted Results from Section 4: Algorithmic Modularity via Self-predictive Estimation 17 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A.1 Self-predictive estimation . . 17   \nA.2Main result 18   \nA.3  Instantiating the self-predictive estimation oracle 19 ", "page_idx": 15}, {"type": "text", "text": "B  Additional Discussion of Related Work 22 ", "page_idx": 15}, {"type": "text", "text": "C Technical Tools 23 ", "page_idx": 15}, {"type": "text", "text": "D   Structural Properties of Coverability and Mismatch Functions 24 ", "page_idx": 15}, {"type": "text", "text": "E Proofs and Additional Results for Section 3.2: Impossibility Results 28 ", "page_idx": 15}, {"type": "text", "text": "E.1 Additional Lower Bound 28   \nE.2  Details for Figure 1 . . 28   \nE.3  Proofs for Lower Bounds (Theorems 3.1 and E.1) . 34 ", "page_idx": 15}, {"type": "text", "text": "11UUIs IvI DELuUn J.J. 1 vsIuvE NESULs ?V F.1 Technical Overview: Low-dimensional embeddings for pushforward-coverable MDPs. 40 F.2 Proofs for Latent Model Class $^+$ Pushforward Coverability (Theorem 3.2). . . 41 ", "page_idx": 15}, {"type": "text", "text": "G Proofs and Additional Information for Section 4.1: Hindsight RL 52 ", "page_idx": 15}, {"type": "text", "text": "G.1  Pseudocode and Proofs for ExPWEIGHTs.DR (Lemma 4.1) . . . 52   \nG.2Proofs for O2L Under Hindsight Observability (Theorem 4.1\uff09 . : 53 ", "page_idx": 15}, {"type": "text", "text": "H Proofs for Appendix A: Self-Predictive Estimation 56 ", "page_idx": 15}, {"type": "text", "text": "H.1 Pseudocode and Proofs for SELFPREDICT.OPT (Lemma A.1) . . 56   \nH.2 Proofs for Main Risk Bound (Theorem A.1) . . 60 ", "page_idx": 15}, {"type": "text", "text": "1  Additional Results for Appendix A: Self-Predictive Estimation 63 ", "page_idx": 15}, {"type": "text", "text": "1.1 O2L with Self-predictive Estimation and CorruptionRobust Base Algorithms . : 63   \n1.2 Proofs for Appendix I.1.2: Properties of $\\phi$ -compressed POMDPs . : : : 66   \n1.3 Proofs for Appendix I.1.3: Risk Bound Under CorruptionRobustness (Theorem H.1) 71   \nI.4 Proofs for Appendix I.1.4: Examples of CorruptionRobust Algorithms . . . . . . 73 ", "page_idx": 15}, {"type": "text", "text": "A Omitted Results from Section 4: Algorithmic Modularity via Self-predictive Estimation ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section, we remove the assumption of hindsight observability used in Section 4.1 and instantiate O2L in the general online RL setting. Rather than assume access to additional side-information, we adopt a model-based representation learning approach, and augment our ability to perform representation learning by equipping the representation learning algorithm with a set of base MDPs $\\mathcal{M}_{\\mathrm{{lat}}}$ in addition to the decoder class $\\Phi$ . We will learn a representation by jointly fitting a decoder and the base (latent) dynamics, which is a common approach in practice [GKBNB19; HLBN19; Haf $+1\\varsigma$ ; HLNB21; ${\\mathrm{Sch}}+20$ ; SAGHCB20; Gu0 $+22$ 1.We firstly present in Appendix A.1 a new notion of optimistic self-predictive regret which combines self-predictive representation learning with a form of optimism over a learned latent model. We then show in Appendix A.2 that any representation learning oracle that attains low regret, when used within O2L (Algorithm 1), leads to observable-tolatent reductions that ensure low risk for any base algorithm $\\mathrm{{ALG}_{\\mathrm{{lat}}}}$ , thereby achieving algorithmic modularity. Lastly, in Appendix A.3, we instantiate this oracle under natural structural and function approximation conditions, yielding end-to-end modularity and sample complexity guarantees. ", "page_idx": 16}, {"type": "text", "text": "A.1  Self-predictive estimation ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Our self-predictive representation learning oracles learn to fit a representation $\\phi$ such that the induced latent transitions $(\\phi_{h}(x_{h})$ to $\\phi_{h+1}(x_{h+1}))$ can be accurately modeled by some base (latent) MDP $M_{\\mathrm{{lat}}}\\in\\mathcal{M}_{\\mathrm{{lat}}}$ . To describe the objective, let us first introduce some notation. For a given MDP $M$ over either $\\boldsymbol{S}$ (resp. $\\mathcal{X}$ ), we write $M_{h}(r_{h},s_{h+1}\\mid s_{h},a_{h})$ (resp. ${\\cal M}_{h}(r_{h},x_{h+1}\\mid x_{h},a_{h}))$ for the joint conditional distribution over rewards and next states. Next, for any $\\phi\\in\\Phi$ ,we define the pushforward model for $M_{\\mathsf{o b s},h}^{\\star}$ induced by $\\phi$ via: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\left[\\phi_{h+1}\\sharp M_{\\sf o b s}^{\\star},h\\right](r,s^{\\prime}\\mid x,a):=\\sum_{x^{\\prime}:\\phi_{h+1}(x^{\\prime})=s^{\\prime}}M_{\\sf o b s}^{\\star},h(r,x^{\\prime}\\mid x,a).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The pushforward model for $\\phi$ captures the forward probability of the estimated latent state $\\phi({\\boldsymbol{x}}^{\\prime})$ given a current observation $x$ . To measure distance between models, we will use squared Hellinger distane (eg Ffste et al EKQR1 ),defned ia $\\begin{array}{r}{D_{\\mathsf{H}}^{2}(\\mathbb{P},\\mathbb{Q})=\\int\\!\\big(\\sqrt{\\frac{\\mathrm{d}\\mathbb{P}}{\\mathrm{d}\\nu}}-\\sqrt{\\frac{\\mathrm{d}\\mathbb{Q}}{\\mathrm{d}\\nu}}\\big)^{2}\\mathrm{d}\\nu}\\end{array}$ for a common dominating measure $\\nu$ . Then, for a base model $M_{\\mathrm{lat}}$ and a decoder $\\phi$ ,the self-predictive error of $(M_{\\mathrm{{lat}}},\\phi)$ , at state-action pair $x_{h},a_{h}$ , is given by ", "page_idx": 16}, {"type": "equation", "text": "$$\n[\\Delta_{h}(M_{\\mathrm{1at}},\\phi)](x_{h},a_{h}):=D_{\\mathsf{H}}^{2}\\big(M_{\\mathrm{1at},h}(\\phi_{h}(x_{h}),a_{h}),\\big[\\phi_{h+1}\\sharp M_{\\mathsf{0b s},h}^{\\star}\\big](x_{h},a_{h})\\big).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "This term captures the ability of $M_{\\mathrm{1at},h}(\\phi_{h}(x_{h}),a_{h})$ to predict the next latent state $\\phi_{h+1}(x_{h+1})$ which is obtained by the pushforward model $\\left[\\phi_{h+1}\\sharp M_{\\sf o b s}^{\\star},h\\right](x_{h},a_{h})$ . Formally, in our model-based representation learning setup, we consider oracles which, for each iteration $t$ within O2L, take as input the trajectories collected so far and produce an estimate $(\\widehat{M}_{\\mathrm{lat}}^{(t)},\\widehat{\\phi}^{(t)})$ for the decoder and base model. The representation learning oracle's self-predictive regret, for the sequence $(\\widehat{M}_{\\mathrm{lat}}^{(t)},\\widehat{\\phi}^{(t)})$ ,is then defined as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathsf{R e g}_{\\mathtt{s e l f}}(T)=\\sum_{t=1}^{T}\\sum_{h=0}^{H}\\mathbb{E}_{\\pi^{(t)}\\sim p^{(t)}}\\mathbb{E}^{\\pi^{(t)}}\\Bigl[[\\Delta_{h}\\bigl(\\widehat{M}_{\\mathtt{l a t}}^{(t)},\\widehat{\\phi}^{(t)}\\bigr)](x_{h},a_{h})\\Bigr],\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\boldsymbol{p}^{(t)}$ represents a randomization distribution over the policy $\\pi^{(t)}$ ", "page_idx": 16}, {"type": "text", "text": "On its own, minimizing this regret may lead to degenerate solutions, a widely observed phenomenon inpractice $[\\mathrm{Tan}+23]$ . For example, in a standard combination lock MDP (e.g., Agarwal et al.; Misra et al. [AJKS22; MHKL20]), a degenerate decoder-model pair that maps all observations to a single latent state will have zero self-predictive loss until we reach the goal, which can take exponentially long.12 We address this via the notion of optimistic estimation used in Zhang; Foster et al. [Zha22; FGQRS23], which biases the objective towards latent models with high return. This leads to the following optimistic self-predictive regret, defined for a parameter $\\gamma>0$ ,via ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{R e g}_{\\mathrm{self};\\mathrm{opt}}(T,\\gamma)=\\displaystyle\\sum_{t=1}^{T}\\sum_{h=0}^{H}\\mathbb{E}_{\\pi^{(t)}\\sim p^{(t)}}\\,\\mathbb{E}^{\\pi^{(t)}}\\Bigl[[\\Delta_{h}(\\widehat{M}_{\\mathrm{lat}}^{(t)},\\widehat{\\phi}^{(t)})](x_{h},a_{h})\\Bigr]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\,\\gamma^{-1}\\bigl(J^{M_{\\mathrm{lat}}^{\\star}}(\\pi_{M_{\\mathrm{lat}}^{\\star}})-J^{\\widehat{M}_{\\mathrm{lat}}^{(t)}}(\\pi_{\\widehat{M}_{\\mathrm{lat}}^{(t)}})\\bigr).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We assume going forward that $\\mathbf{REP}_{\\mathsf{s e l f;o p t}}$ obtains low optimistic self-predictive regret; in Appendix A.3 we provide a maximum-likelihood-type estimator and conditions under which this holds. ", "page_idx": 17}, {"type": "text", "text": "AssumptionA.1.Foraparameter $\\gamma>0$ andany(possiblyadaptive)sequence $\\pi^{(t)}$ ,with $\\pi^{(t)}\\sim p^{(t)}$ theonlerepreseationleang oracl $\\mathbf{REP}_{\\mathsf{s e l f;o p t}}$ $i s$ proper (i. ouputs $\\widehat{M}_{\\mathrm{1at}}^{(t)}\\in\\mathcal{M}_{\\mathrm{1at}}$ for all $t\\in[T])$ and satisfies ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\big[\\mathsf{R e g}_{s\\mathrm{elf};\\mathrm{opt}}(T,\\gamma)\\big]\\leq\\mathsf{E s t}_{\\mathrm{self};\\mathrm{opt}}(T,\\gamma),}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where Est $\\mathsf{\\bar{\\Gamma}}_{\\mathsf{s e l f};\\mathsf{o p t}}(T,\\gamma)$ is a known upper bound. ", "page_idx": 17}, {"type": "text", "text": "We note that only the decoder $\\widehat{\\phi}^{\\left(t\\right)}$ is used within O2L; the model $\\widehat{M}_{\\mathrm{1at}}^{(t)}$ is only used for analysis (and possibly within the representation learner $\\mathsf{R E P}_{\\mathsf{s e l f};\\mathsf{o p t}}\\$ ", "page_idx": 17}, {"type": "text", "text": "A.2 Main result ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We now state the main guarantee for O2L with self-predictive representation learning. Recall that $\\mathsf{R i s k}_{\\mathsf{o b s}}(T K)$ denotes the risk of the O2L reduction. Compared to the hindsight-observable setting, we require a slightly stronger performance guarantee from the base algorithm $\\mathrm{ALG}_{\\mathrm{1at}}$ : our result scales with the worst-case expected risk for $\\mathrm{\\bfALG_{\\mathrm{1at}}}$ over all $M_{\\mathrm{1at}}\\,\\in\\,\\mathcal{M}_{\\mathrm{1at}}$ , defined via $\\begin{array}{r}{\\mathsf{R i s k}_{\\mathsf{b a s e}}(K):=\\operatorname*{sup}_{M_{\\mathrm{lat}}\\in\\mathcal{M}_{\\mathrm{lat}}}\\mathbb{E}[\\mathsf{R i s k}(K,\\mathsf{A L G}_{\\mathrm{lat}},M_{\\mathrm{lat}}))]}\\end{array}$ ", "page_idx": 17}, {"type": "text", "text": "Theorem A.1 (Risk bound for O2L under self-predictive estimation). Suppose $\\mathrm{REP}_{\\mathsf{s e l f};\\mathsf{o p t}}$ satisfes Assumption A.1 with parameter $\\gamma>0$ .Then Algorithm $^{\\,l}$ , with inputs $T,K,\\Phi$ $\\mathrm{REP}_{\\mathsf{s e l f};\\mathsf{o p t}}$ and $\\mathrm{ALG_{\\mathrm{1at}}}$ has expected risk ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathtt{R i s k}_{\\mathtt{o b s}}(T K)]\\le c_{1}\\cdot\\mathtt{R i}\\,\\mathtt{s k}_{\\mathtt{b a s e}}(K)+c_{2}\\gamma\\cdot\\frac{K}{T}\\mathsf{E s t}_{\\mathtt{s e l f};\\mathtt{o p t}}(T,\\gamma)+c_{3}\\gamma^{-1}\\cdot K H,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "for absolute constants $c_{1},c_{2},c_{3}>0$ ", "page_idx": 17}, {"type": "text", "text": "Theorem A.1 achieves sublinear risk as long as (i) the latent algorithm achieves sublinear risk $\\mathsf{R i s k}_{\\mathsf{b a s e}}(K)$ given access to the true states, and (ii) the self-predictive representation learning oracle achieves sublinear regret $\\mathsf{E s t}_{\\mathsf{s e l f};\\mathsf{o p t}}(T,\\gamma)$ for an appropriate choice of $\\gamma$ 13 Intuitively, our result scales with $\\mathsf{R i s k}_{\\mathsf{b a s e}}(K)$ instead of $\\mathsf{R i s k}_{\\star}(K)$ due to potential symmetries in the self-predictive objective. For example, there might be a representation-model pair $(\\widehat{M}_{\\mathrm{lat}},\\widehat{\\phi})$ that is identical to $(M_{\\mathrm{lat}}^{\\star},\\phi^{\\star})$ up to permutations of the latent state space; these cannot be distinguished by a representation learning oracle that does not observe the latent states directly, and thus the base algorithm may be tasked with solving either of these base MDPs. As with Theorem 4.1, this result achieves algorithmic modularity (since O2L inherits the risk of the base algorithm), and is computationally efficient whenever the base algorithm and self-predictive representation learning oracle are efficient. ", "page_idx": 17}, {"type": "text", "text": "Let us provide some intuition behind the proof of Theorem A.1. Recall that, within the inner loop of O2L, the latent algorithm $\\mathrm{ALG}_{\\mathrm{1at}}$ interacts with the $\\widehat{\\phi}^{\\left(t\\right)}$ -compressed dynamics generated by compressing the observations $x_{h},a_{h}$ through the current decoder $\\widehat{\\phi}_{h}^{(t)}$ (Line 8). The crux of the analysis is the following observation: by the self-predictive representation learning guarantee, these dynamics, despite being possibly non-Markovian and generated from a POMDP (Definition I. 1), are well pproximaed in quared Hellinger distance by the base model $\\widehat{M}_{\\mathrm{1at}}^{(t)}$ estimated by $\\mathsf{R E P}_{\\mathsf{s e l f};\\mathsf{o p t}}$ (cf. Lemma I.2). We can then show that $\\mathrm{ALG}_{\\mathrm{1at}}$ , when given data from the $\\widehat{\\phi}^{\\left(t\\right)}$ -compressed dynamics, has risk (for solving $\\widehat{M}_{\\mathrm{1at}}^{(t)})$ that is proportional to: i) its base risk if it were to observe states from $\\widehat{M}_{\\mathrm{1at}}^{(t)}$ , and i) the Hellinger distance between $\\widehat{M}_{\\mathrm{1at}}^{(t)}$ and the process induced by its $\\widehat{\\phi}^{\\left(t\\right)}$ -compressed dynamics. The last ingredient is theuse of latent optimism in Eq. (7),through which the risk on $M_{\\mathrm{1at}}^{\\star}$ is upper bounded by the risk on $\\widehat{M}_{\\mathrm{1at}}^{(t)}$ ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "Inthe above,showingthat $\\mathrm{\\bfALG}_{\\mathrm{1at}}$ obtains ow rsk for $\\widehat{M}_{\\mathrm{1at}}^{(t)}$ (despitegiven datafrom adifferent process) is done by establishing a certain form of corruption robustness (Definition I.2). Indeed, Theorem A.1 is a special case of a more general theorem (Theorem H.1), which provides a bound that adaptsto $\\mathrm{ALG}_{\\mathrm{1at}}$ 's level of robustness. We obtain Theorem A.1 by showing that any algorithm satisfies the property we require (for a suitably slow rate), but we further show that tighter rates can be achieved by analyzing the specifics of various algorithms of interest (Appendix I.1.4). ", "page_idx": 18}, {"type": "text", "text": "A.3 Instantiating the self-predictive estimation oracle ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We now present an algorithm, SELFPREDICT.OPT (Algorithm 4 in Appendix H.1), which satisfies Assumption A.1 under additional technical conditions, allowing us to instantiate Theorem A.1 to give end-to-end guarantees. Before stating the main guarantee, we highlight a few technical difficulties regarding obtaining finite-sample guarantees for (online) self-predictive estimation, and use them to motivate our statistical assumptions and algorithm design. ", "page_idx": 18}, {"type": "text", "text": "The statistics of (online) self-predictive estimation.  The first challenge is a realizability issue: when $\\phi\\neq\\phi^{\\star}$ , we may not even be able to represent the objective $\\phi_{\\mathsf{H}}^{\\dagger}M_{\\mathsf{o b s}}^{\\star}$ as a latent model using only decoder and latent model realizability. Since we can never guarantee that $\\phi=\\phi^{\\star}$ exactly in the presence of statistical errors, we must introduce a modelling assumption which lets us capture the pushforward models $\\phi_{\\mathsf{H}}^{\\dagger}M_{\\mathsf{o b s}}^{\\star}$ . To this end, we introduce the mismatch functions, which are defined as follows. ", "page_idx": 18}, {"type": "text", "text": "Definition A.1 (Mismatch functions). For a decodable emission process $\\psi^{\\star}$ and decoder $\\phi\\in\\Phi$ the mismatch function for $\\phi$ $,\\Gamma_{\\phi}=\\{\\Gamma_{\\phi,h}:S\\to\\Delta(S)\\}_{h=1}^{H},$ is defined, for every $h\\in[H]$ as the probability kernel ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\Gamma_{\\phi,h}(s_{h}^{\\prime}\\mid s_{h}):=\\mathbb{P}_{x_{h}\\sim\\psi_{h}^{\\star}(s_{h})}(\\phi_{h}(x_{h})=s_{h}^{\\prime}).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "In the context of self-prediction, we show that the following mismatch completeness assumption suffices tocapturethe pushforward models $\\phi_{\\mathsf{H}}^{\\dagger}M_{\\mathsf{o b s}}^{\\star}$ ", "page_idx": 18}, {"type": "text", "text": "Assumption A.2 (Mismatch completeness). We have a model class $\\mathcal{L}$ suchthat,for each $\\phi\\in\\Phi$ ,and $M_{\\mathrm{{lat}}}\\in\\mathcal{M}_{\\mathrm{{lat}}}$ wehave $\\Gamma_{\\phi}\\circ M_{\\tt l a t}\\in{\\mathcal{L}}$ where ", "page_idx": 18}, {"type": "equation", "text": "$$\n[\\Gamma_{\\phi}\\circ M_{\\mathrm{1at}}]_{h}(r_{h},s_{h+1}\\mid s_{h},a_{h}):=\\sum_{s_{h+1}^{\\prime}\\in\\mathcal{S}}M_{\\mathrm{1at},h}(r_{h},s_{h+1}^{\\prime}\\mid s_{h},a_{h})\\Gamma_{\\phi,h+1}(s_{h+1}\\mid s_{h+1}^{\\prime}).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "In particular, Lemma D.8 establishes that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\big[\\phi_{h+1}\\sharp M_{\\sf o b s}^{\\star}{}_{,h}\\big](\\cdot\\mid x,a)=[\\Gamma_{\\phi}\\circ M_{\\sf l a t}^{\\star}]_{h}(\\cdot\\mid\\phi_{h}^{\\star}(x),a).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Accordingl, weviwthis atias ainmalwatalze tepsrwardl $\\phi_{\\mathsf{H}}^{\\mathsf{H}}M_{\\mathsf{o b s}}^{\\star}$ ", "page_idx": 18}, {"type": "text", "text": "The second challenge is a double-sampling issue, which appears because the decoders in Eq. (7) are coupled at different horizons. We address this with a novel \u201cdebiased\" maximum likelihood procedure that subtracts a form of excess risk (cf. Eq. (60)) to recover an unbiased estimator [Jia24]. Our debiased estimator and the mismatch completeness assumption can be viewed as analogous to the techniques and assumptions that are required for squared Bellman error minimization in the context of value function approximation [CJ19; JLM21]. ", "page_idx": 18}, {"type": "text", "text": "The last issue stems from seeking an online estimation guarantee: the policies chosen by the latent algorithm are a function of the estimated decoders, which precludes the use of randomized estimators (e.g. exponential weights). We bypass this issue by appealing to the structural condition of coverability [XFBJK23], which allows us to restrict our attention to estimators that achieve low offine estimation error (via Lemma C.7).14 ", "page_idx": 18}, {"type": "text", "text": "Definition A.2 (State Coverability). The state coverability coefficient for an MDP M and a policy class II defined over a state space $\\mathcal{Z}$ $C_{\\mathsf{c o v,s t}}(M,\\Pi)$ isgivenby ", "page_idx": 18}, {"type": "equation", "text": "$$\nC_{\\mathsf{c o v,s t}}(M,\\Pi):=\\operatorname*{max}_{h\\in[H]}\\operatorname*{min}_{\\mu\\in\\Delta(\\mathcal{Z})}\\operatorname*{max}_{\\pi\\in\\Pi}\\operatorname*{max}_{z\\in\\mathcal{Z}}\\bigg\\{\\frac{d_{h}^{M,\\pi}(z)}{\\mu(z)}\\bigg\\}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We require coverability in $M_{\\mathsf{o b s}}^{\\star}$ over the set of (observation-space) policies played by the O2L reduction (cf. Line 7). Again appealing to the mismatch functions, we can express this as an assumption about the base dynamics $M_{\\mathrm{1at}}^{\\star}$ : we show (Lemma D.1) that the latter is equivalent to assuming coverability in $M_{\\mathrm{1at}}^{\\star}$ over the set of stochastic policies ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\Gamma_{\\Phi}\\circ\\Pi_{\\mathrm{lat}}:=\\left\\{[\\Gamma_{\\phi}\\circ\\pi_{\\mathrm{lat}}]_{h}(a\\mid s)=\\sum_{s^{\\prime}\\in S}\\Gamma_{\\phi,h}(s^{\\prime}\\mid s)\\pi_{\\mathrm{lat},h}(a\\mid s^{\\prime})\\mid\\phi\\in\\Phi,\\pi_{\\mathrm{lat}}\\in\\Pi_{\\mathrm{lat}}\\right\\},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\Pi_{\\mathrm{1at}}$ denotes the set of policies that $\\mathrm{ALG}_{\\mathrm{1at}}$ may execute. While this set may appear complicated, it is sufficient to assume coverability over the set of all deterministic non-stationary policies on $M_{\\mathrm{1at}}^{\\star}$ .15 ", "page_idx": 19}, {"type": "text", "text": "Guarantee for our self-predictive estimation oracle. With these prerequisites, the main guarantee for our estimator, SELFPREDICT.OPT (Algorithm 4), is as follows. ", "page_idx": 19}, {"type": "text", "text": "Lemma A.1 (Optimistic self-predictive estimation via SELFPREDICT.OPT). Let $\\Pi_{\\mathrm{1at}}$ denote the set of policies played by $\\mathrm{ALG_{\\mathrm{1at}}}$ and $C_{\\mathsf{c o v,s t}}=C_{\\mathsf{c o v,s t}}(M_{\\mathsf{l a t}}^{\\star},\\Gamma_{\\Phi}\\circ\\Pi_{\\mathsf{l a t}})$ be the state coverability parameter on $M_{\\mathrm{1at}}^{\\star}$ over the set of stochastic policies $\\Gamma_{\\Phi}\\circ\\Pi_{1a t}$ (Eq. (9)). Then, for any $\\gamma>0$ under decoder realizability $(\\phi^{\\star}\\,\\in\\,\\Phi)$ , base model realizability $(M_{\\mathrm{lat}}^{\\star}\\in\\,\\mathcal{M}_{\\mathrm{lat}})$ , and mismatch function completeness with class $\\mathcal{L}_{\\mathrm{1at}}$ (Assumption A.2), the estimator in Algorithm $^{4}$ with inputs $\\Phi,\\mathcal{M}_{\\mathrm{lat}},\\mathcal{L}_{\\mathrm{lat}}$ , and $\\gamma$ satisfies Assumption $A.I\\,\\,\\stackrel{.}{w i t h}^{16}$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathsf{E s t}_{\\mathsf{s e l f};\\mathsf{o p t}}(T,\\gamma)=\\widetilde{\\mathcal{O}}\\bigg(\\sqrt{H C_{\\mathsf{c o v},\\mathsf{s t}}|A|T}\\log(|\\mathcal{M}_{\\mathrm{lat}}||\\mathcal{L}_{\\mathrm{lat}}||\\Phi|)\\bigg).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Instantiating Theorem A.1 with the above representation learning oracle, we obtain the following algorithmic modularity result. ", "page_idx": 19}, {"type": "text", "text": "Corollary A.1 (Algorithmic modularity via SELFPREDICT.OPT). Under the same conditions as in Lemma A.1, and for any base algorithm $\\mathrm{ALG}_{\\mathrm{1at}}$ O2Lwith inputs $T,K,\\Phi$ ,SELFPREDICT.OPT, and $\\mathrm{ALG_{\\mathrm{1at}}}$ achieves ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathfrak{L}[\\mathbb{R}\\mathbf{i}\\operatorname{sk}_{\\sf o b s}(T K)]\\lesssim c_{1}\\cdot\\mathtt{R i}\\operatorname{sk}_{\\sf b a s e}(K)+c_{2}\\gamma\\cdot\\frac{K}{\\sqrt{T}}\\sqrt{H C_{\\mathrm{cov},\\mathfrak{s t}}|\\mathcal{A}|}\\log(|\\mathcal{M}_{\\sf l a t}||\\mathcal{L}_{\\sf l a t}||\\Phi|)+c_{3}\\gamma^{-1}\\cdot K H,\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "for absolute constants $c_{1},c_{2},c_{3}$ . Consequently, for any $\\mathrm{\\bfALG}_{\\mathrm{1at}}$ with base risk R $\\mathsf{i}\\,\\mathsf{s k}_{\\mathsf{b a s e}}(K)$ , setting $\\gamma$ and $T$ appropriately gives ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathsf{R i}\\,\\mathsf{s k}_{\\mathsf{o b s}}(T K)]\\lesssim\\mathsf{R i}\\,\\mathsf{s k}_{\\mathsf{b a s e}}(K),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "with a number of trajectories $T K=\\widetilde{\\mathcal{O}}\\big(K^{5}H^{3}C_{\\mathtt{c o v,s t}}|\\mathcal{A}|\\log^{2}(|\\mathcal{M}_{\\mathtt{l a t}}||\\mathcal{L}_{\\mathtt{l a t}}||\\Phi|)\\big/(\\mathtt{R i}\\mathtt{s k}_{\\mathtt{b a s e}}(K))^{4}\\big).$ ", "page_idx": 19}, {"type": "text", "text": "For example, if $\\mathrm{\\bfALG_{\\mathrm{1at}}}$ is a base algorithm with $\\begin{array}{r l r}{\\mathsf{R i s k}_{\\mathsf{b a s e}}(K)}&{{}\\!=}&{\\!\\mathcal{O}(K^{-1/2})}\\end{array}$ , seting $\\gamma$ and $T$ appropriately gives an expected risk of $\\varepsilon$ with a number of trajectories $T K\\quad=$ $\\widetilde{\\mathcal{O}}\\Big(H^{3}C_{\\mathsf{c o v,s t}}|\\mathcal{A}|(\\log(|\\mathcal{M}_{\\mathrm{1at}}||\\mathcal{L}_{\\mathrm{1at}}||\\Phi|))^{2}\\Big/\\varepsilon^{14}\\Big)$ . This result shows that statistical modularity can be achieved up to $\\log(|\\mathcal{L}_{\\mathrm{lat}}|)$ factors for every base MDP class $\\mathcal{M}_{\\mathrm{{lat}}}$ which is subsumed by coverability, including tabular MDPs and low-rank MDPs.17  Compared to our positive result for the case of pushforward coverability (Section 3.3), this imposes less dynamics assumptions (since coverability is implied by pushforward coverability) but requires more representational assumptions (namely, access to the mismatch-complete class $\\mathcal{L}_{\\mathrm{{lat}}}$ ). We further remark that the mismatch completeness assumption always holds for i) the Block MDP setting, since we can always construct $\\mathcal{L}_{\\mathrm{lat}}$ such that $\\log(|\\bar{\\mathcal{L}}_{\\mathrm{lat}}|)=\\bar{\\mathcal{O}}(H S^{2})$ , and ii) every MDP class $\\mathcal{M}_{\\mathrm{{lat}}}$ whenever we also have a realizable set of emission processes $(\\psi^{\\star}\\in\\Psi)$ , since we can construct $\\mathcal{L}_{\\mathrm{lat}}$ such that $\\log(|\\mathcal{L}_{\\mathrm{{lat}}}|)=\\log(|\\Phi||\\mathcal{M}_{\\mathrm{{lat}}}||\\Psi|)$ However, the mismatch completeness assumption may be more general than either of these settings. ", "page_idx": 19}, {"type": "text", "text": "Our results can be viewed as providing a theoretical justification for self-predictive representation learning, which has been widely used in empirical works [GKBNB19; SAGHCB2O]. We consider self-prediction's ability to obtain universal observable-to-latent reductions as a strong indicator that it merits further theoretical study. In particular, many empirical works propose heuristics to alleviate the degeneracy/non-uniqueness issues inherent with self-prediction [GKBNB19; SAGHCB2O; HPBL23; Tan $+23$ 1. Our methods provide a principled way to address these, and it would be interesting to investigate whether this is also empirically effective. In general, however, it is unclear whether our loss admits a computationally effcient implementation, due to the presence of optimism. Towards this, a fascinating direction for future work is understanding how self-predictive estimation can be used to obtain algorithmic modularity without the addition of optimism over the base (latent) models. ", "page_idx": 20}, {"type": "text", "text": "B Additional Discussion of Related Work ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In this section, we discuss aspects of related work not already covered in greater detail. ", "page_idx": 21}, {"type": "text", "text": "Reinforcement learning under latent dynamics (or, with rich observations). Reinforcement learning under latent dynamics (or, with rich observations) has received extensive investigation in recent years, however most works have been focused on the Block MDP model in which the latent state space is tabular/finite [KAL16; DKJADL19; MHKL20; ZSUWAS22; MFR23] (see also the the closely related framework of Low-Rank MDPs [AKKS20; MCKJA24; ZSUWAS22; UZS22; MBFR23]). Beyond tabular spaces, Dean et al.; Dean et al.; Mhammedi et al. [DMRY20; DR21; $\\mathrm{Mha}{+20}]$ consider continuous linear dynamics, Misra et al. [MLJL21] considers factored (but discrete) latent dynamics, Efroni et al.; Efroni et al.; Mhammedi et al. [EMKAL22; EFMKL22; MFR24] consider the Exogenous Block MDP problem in which a tabular latent state space is augmented with a non-controllable (\"exogenous\") factor, and Song et al. [SWFK24] consider Lipshitz continuous dynamics. To our knowledge, our work is the first to: i) explore reinforcement learning under general latent dynamics, in particular in settings where the latent space itself admits function approximation, and i) take a more modular approach (cf. the taxonomy of Section 3). ", "page_idx": 21}, {"type": "text", "text": "On the algorithmic side, the works of Uehara et al. [UZS22] and Zhang et al. [ZSUWAS22], which consider Low-Rank MDPs and Block MDPs respectively, can be viewed as interleaving representation learning with \u201clatent\u201d\u2019 reinforcement learning algorithms that assume access to a good representation, and were an inspiration for this work. However, the algorithmic details and analyses are highly specialized to Block/Low-Rank MDPs, and unlikely to be directly_ applicable to reinforcement learning under general latent dynamics. Other works with a modular flavor include: ", "page_idx": 21}, {"type": "text", "text": "\u00b7 Feng et al. [FWYDY20] solve tabular Block MDPs by combining a black-box latent algorithm with an \u201cunsupervised learning oracle\u201d for representation learning. This approach only leads to guarantees for tabular Block MDPs, and it is unclear whether the unsupervised learning oracle their approach requires can be constructed in natural settings. \u00b7 Wu et al. [WYDW21] solve tabular block MDPs by combining a corruption-robust latent algorithm with a representation learning procedure based on clustering. Again, this work is restricted to the tabular setting, and requires a separation condition which may not be satisfied in general. ", "page_idx": 21}, {"type": "text", "text": "General complexity measures for reinforcement learning. Another line of research provides general complexity measures that enable sample-efficient reinforcement learning, including Bellman rank [JKALS17; SJKAL19; $\\mathrm{Du}+21$ ; JLM21], eluder dimension [RVR13], coverability [XFBJK23], and the Decision-Estimation Coefficient (DEC) [FKQR21; FGH23; FGQRS23]. Bellman rank and other complexity measures based on average Bellman error [JKALS17; SJKAL19; $\\mathrm{Du}+21$ ;JLM21] are insufficient to characterize learnability under general latent dynamics, as there are classes $\\mathcal{M}_{\\mathrm{{lat}}}$ that are known to be learnable, yet do not have bounded Bellman rank or Bellman-Eluder dimension [EMKAL22; XFBJK23]. Meanwhile, variants of Bellman rank based on squared Bellman error or related notions of error can [XFBJK23; AFJSX24] address this problem for some settings, but satisfying the modeling/realizability assumptions (e.g., Bellman completeness) required by these methods in the latent-dynamics setting is non-trivial. For example, the crux of our sample complexity bounds under latent pushforward coverability in Section 3 (Theorem 3.2) is to prove a rather involved structural result which shows that Bellman completeness can indeed be satisfied under this assumption, but it is unclear whether these techniques can be applied to more general latent dynamics classes. We expect that it is possible to bound the Decision-Estimation Coefficient [FKQR21; FGH23; FGQRS23] for the framework, but deriving efficient algorithms using this framework is non-trivial. ", "page_idx": 21}, {"type": "text", "text": "C Technical Tools ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Lemma C.1. For any sequence of real-valued random variables $(X_{t})_{t\\leq T}$ adapted to a filtration $(\\mathcal{F}_{t})_{t\\leq T}$ , it holds that with probability at least $1-\\delta$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}X_{t}\\leq\\sum_{t=1}^{T}\\log\\bigl(\\mathbb{E}_{t-1}\\big[e^{X_{t}}\\big]\\bigr)+\\log\\bigl(\\delta^{-1}\\bigr).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Lemma C.2 (Freedman's inequality (e.g., Agarwal et al. [AHKLLS14]). Let $(X_{t})_{t\\le T}$ bea realvalued martingale difference sequence adapted to a filtration $(\\mathcal{F}_{t})_{t\\leq T}.\\;I f\\vert X_{t}\\vert\\leq R$ almost surely, thenfor any $\\eta\\in(0,1/R)$ ,with probability at least $1-\\delta$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}X_{t}\\leq\\eta\\sum_{t=1}^{T}\\mathbb{E}_{t-1}\\big[X_{t}^{2}\\big]+\\frac{\\log\\bigl(\\delta^{-1}\\bigr)}{\\eta}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Lemma C.3 (Corollary of Lemma C.2). Let $(X_{t})_{t\\leq T}$ be a sequence of random variables adapted to afiltration $(\\mathcal{F}_{t})_{t\\leq T}$ .1 ${\\boldsymbol{\\mathsf{\\ell}}}({\\boldsymbol{\\mathsf{0}}}\\leq X_{t}\\leq R$ almost surely, then with probability at least $1-\\delta$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}X_{t}\\leq{\\frac{3}{2}}\\sum_{t=1}^{T}\\mathbb{E}_{t-1}[X_{t}]+4R\\log\\bigl(2\\delta^{-1}\\bigr),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "and ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\mathbb{E}_{t-1}[X_{t}]\\leq2\\sum_{t=1}^{T}X_{t}+8R\\log\\bigl(2\\delta^{-1}\\bigr).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Lemma C.4 (Lemma D.2 of Foster et al. [FHQR24]). Let $(\\mathcal{X}_{1},\\mathfrak{F}_{1}),\\ldots,(\\mathcal{X}_{n},\\mathfrak{F}_{n})$ be a sequence of measurablespaces,andlet $\\textstyle\\mathcal{X}^{(i)}=\\prod_{t=1}^{i}\\mathcal{X}_{t}$ and $\\mathfrak{F}^{(i)}=\\otimes_{t=1}^{i}\\mathfrak{F}_{t}$ . For each $i,$ let $P^{(i)}$ and $Q^{(i)}$ be probabilitykernelsfrom $(\\mathcal{X}^{(i-1)},\\mathfrak{F}^{(i-1)})$ $(\\mathcal{X}_{i},\\mathfrak{F}_{i})$ . Let $P$ and $Q$ be the laws of $X_{1},\\ldots,X_{n}$ under $\\bar{X_{i}}\\sim P^{(i)}(\\cdot\\mid X_{1:i-1})$ and $X_{i}\\sim Q^{(i)}(\\cdot\\mid X_{1:i-1})$ ,respectively.Thenit holdsthat ", "page_idx": 22}, {"type": "equation", "text": "$$\nD_{\\mathsf{H}}^{2}(P,Q)\\leq7\\mathbb{E}_{P}\\left[\\sum_{i=1}^{n}D_{\\mathsf{H}}^{2}(P^{(i)}(\\cdot\\mid X_{1:i-1}),Q^{(i)}(\\cdot\\mid X_{1:i-1}))\\right]\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Lemma C.5 (Lemma A.11 of Foster et al. [FKQR21]). Let $\\mathbb{P}$ and $\\mathbb{Q}$ be probability measures on $({\\mathcal{X}},{\\mathfrak{F}})$ . For all $h:\\mathcal{X}\\to\\mathbb{R}$ with $0\\leq h(X)\\leq R$ almost surely under $\\mathbb{P}$ and $\\mathbb{Q}_{:}$ we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mathbb{P}}[h(X)]\\leq3\\mathbb{E}_{\\mathbb{Q}}[h(X)]+4R D_{\\mathbb{H}}^{2}(\\mathbb{P},\\mathbb{Q}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Lemma C.6 (Lemma 1 of Jiang et al. [JKALS17]). For any $f:\\mathcal{X}\\!\\times\\!\\mathcal{A}\\to[0,1],\\pi:\\mathcal{S}\\!\\times\\![H]\\to\\Delta(\\mathcal{A}),$ wehave ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}_{x_{1}}[f(x_{1},\\pi(x_{1}))]-J(\\pi)=\\sum_{h=1}^{H}\\mathbb{E}^{\\pi}[f(x_{h},a_{h})-\\mathcal{T}^{\\pi}f(x_{h},a_{h})].\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Lemma C.7 (Offline-to-online conversion under coverability [XFBJK23; FHQR24]). Let $M$ be an MDPoverstatespace $\\mathcal{Z}$ ,IIbe apolicyset,and $C_{\\mathsf{c o v}}=C_{\\mathsf{c o v}}(M,\\Pi)$ be the(state-action)coverability coefficient for $M$ and $\\Pi$ (Definition $D.3$ ). Let $p^{(t)}\\in\\Delta(\\Pi)$ beasequenceofdistributionsover $\\Pi$ and ght : Z \u00d7 A \u2192 [O, 1] be a sequence of functions. Then we have that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi^{(t)}\\sim p^{(t)}}\\mathbb{E}^{\\pi^{(t)}}\\left[g_{h}^{(t)}\\left(x_{h},a_{h}\\right)\\right]}\\\\ &{\\qquad\\le\\mathcal{O}\\left(\\sqrt{H C_{\\mathrm{cov}}\\log(T)\\displaystyle\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\sum_{i=1}^{t-1}\\mathbb{E}_{\\pi^{(i)}\\sim p^{(i)}}\\mathbb{E}^{\\pi^{(i)}}\\left[g_{h}^{(t)}(x_{h},a_{h})\\right]}+H C_{\\mathrm{cov}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "D  Structural Properties of Coverability and Mismatch Functions ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "This appendix contains structural results regarding coverability and the mismatch functions. We firstly recall the definition of the mismatch functions. ", "page_idx": 23}, {"type": "text", "text": "Definition D.1 (Mismatch functions). For decodable emission process $\\psi^{\\star}$ decoder $\\phi\\,\\in\\,\\Phi$ and $h\\in[H]$ , we define the mismatch function for $\\phi$ $\\Gamma_{\\phi,h}:S\\to\\Delta(S)$ as the probability kernel ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\Gamma_{\\phi,h}(s_{h}^{\\prime}\\mid s_{h}):=\\mathbb{P}_{x_{h}\\sim\\psi_{h}^{\\star}(s_{h})}(\\phi_{h}(x_{h})=s_{h}^{\\prime}).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We also recall the definition of state coverability. ", "page_idx": 23}, {"type": "text", "text": "Definition D.2 (State Coverability). The coverability coefficient for an MDP M and a policy class II defined over a state space $\\mathcal{Z}$ $C_{\\mathsf{c o v,s t}}(M,\\Pi)$ isgivenby ", "page_idx": 23}, {"type": "equation", "text": "$$\nC_{\\mathrm{cov,st}}(M,\\Pi):=\\operatorname*{max}_{h\\in[H]}\\operatorname*{min}_{\\mu\\in\\Delta(\\mathcal{Z})}\\operatorname*{max}_{\\pi\\in\\Pi}\\operatorname*{max}_{z\\in\\mathcal{Z}}\\biggl\\{\\frac{d_{h}^{M,\\pi}(z)}{\\mu(z)}\\biggr\\}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We also define the related notion of state-action coverability. ", "page_idx": 23}, {"type": "text", "text": "Definition D.3 (State-Action Coverability). The coverability coeffcient for an MDP M and a policy class $\\Pi$ defined over a statespace $\\mathcal{Z}$ andactionspace $\\boldsymbol{\\mathcal{A}}$ $C_{\\mathsf{c o v}}(M,\\Pi)$ isgivenby ", "page_idx": 23}, {"type": "equation", "text": "$$\nC_{\\mathsf{c o v}}(M,\\Pi):=\\operatorname*{max}_{h\\in[H]}\\operatorname*{min}_{\\mu\\in\\Delta(\\mathcal{Z}\\times\\mathcal{A})}\\operatorname*{max}_{\\pi\\in\\Pi}\\operatorname*{max}_{z,a\\in\\mathcal{Z}\\times\\mathcal{A}}\\biggl\\{\\frac{d_{h}^{M,\\pi}(z,a)}{\\mu(z,a)}\\biggr\\}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "In the remainder of the section, we let $\\Pi_{\\mathrm{1at}}\\subseteq\\{S\\times[H]\\rightarrow\\Delta(A)\\}$ denote an arbitrary set of latent policies, and ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\Gamma_{\\Phi}\\circ\\Pi_{\\mathrm{lat}}=\\left\\{[\\Gamma_{\\phi}\\circ\\pi_{\\mathrm{lat}}]_{h}(a\\mid s):=\\sum_{s^{\\prime}\\in S}\\Gamma_{\\phi,h}(s^{\\prime}\\mid s)\\pi_{\\mathrm{lat},h}(a\\mid s^{\\prime})\\mid\\phi\\in\\Phi,\\pi_{\\mathrm{lat}}\\in\\Pi_{\\mathrm{lat}}\\right\\}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Lemma D.1 (State coverability is invariant to rich observations). Let $M_{\\sf o b s}^{\\star}=\\langle\\!\\langle M_{\\sf l a t}^{\\star},\\psi^{\\star}\\rangle\\!\\rangle$ Then,we have ", "page_idx": 23}, {"type": "equation", "text": "$$\nC_{\\mathsf{c o v},\\mathsf{s t}}(M_{\\mathsf{o b s}}^{\\star},\\Pi_{\\mathsf{l a t}}\\circ\\Phi)=C_{\\mathsf{c o v},\\mathsf{s t}}(M_{\\mathsf{l a t}}^{\\star},\\Gamma_{\\Phi}\\circ\\Pi_{\\mathsf{l a t}}).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Furthermore, leting $\\{\\mu_{\\mathrm{lat},h}\\in\\Delta(S)\\}_{h\\in[H]}$ denote the distribution which witnesses the right-handside, the left-hand-side is witnessed by the distribution ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mu_{\\sf o b s}{}_{,h}(x)=\\psi_{h}^{\\star}(x\\mid\\phi_{h}^{\\star}(x))\\mu_{\\sf l a t}{}_{,h}(\\phi_{h}^{\\star}(x)).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "The lemma follows from the following two observations. ", "page_idx": 23}, {"type": "text", "text": "LemmaD.2.Let $\\left\\{\\Gamma_{\\phi}\\right\\}_{\\phi\\in\\Phi}$ denote the mismatch functions for emission $\\psi^{\\star}$ and let $M_{0{\\tt b s}}~=~$ $\\langle\\!\\langle M_{\\mathrm{lat}},\\psi^{\\star}\\rangle\\!\\rangle$ Then,forany ${\\bar{\\pi}}_{\\mathrm{lat}}\\in\\Pi_{\\mathrm{lat}},\\,\\phi\\in\\Phi,\\,h\\in[H],\\,x\\in\\chi,$ wehave ", "page_idx": 23}, {"type": "equation", "text": "$$\nd_{h}^{M_{\\mathrm{obs}},\\pi_{\\mathrm{lat}}\\circ\\phi}(x)=\\psi_{h}^{\\star}(x\\mid\\phi_{h}^{\\star}(x))d_{h}^{M_{\\mathrm{lat}},\\Gamma_{\\phi}\\circ\\pi_{\\mathrm{lat}}}(\\phi_{h}^{\\star}(x)).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof of Lemma D.2. Below, we write $s_{h}=\\phi^{\\star}(x_{h})$ . We proceed by induction, simply writing $d_{\\mathsf{o b s},h}:=d_{h}^{M_{\\mathsf{o b s}},\\pi_{\\mathsf{l a t}}\\circ\\phi}$ dMos,Tlato\u4e2d and dlat,h := dh $d_{\\mathrm{1at},h}:=d_{h}^{M_{\\mathrm{1at}},\\Gamma_{\\phi}\\circ\\pi_{\\mathrm{1at}}}$ dMiat, soT1at The base case (h = 1) is obtained by noting that $d_{\\mathrm{1at,1}}(\\boldsymbol{s})=P_{\\mathrm{1at,1}}(\\boldsymbol{s}\\mid\\emptyset)$ while $\\bar{d}_{\\mathsf{o b s},1}\\,\\overset{\\cdot}{(x)}=P_{\\mathsf{o b s},1}(x\\mid\\emptyset)=\\psi_{1}^{\\star}(x\\mid s)P_{\\mathsf{l a t},1}(s\\mid\\emptyset)$ . For the general case, via the Bellman flow equations, we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{d_{\\mathsf{o b s},h}(x_{h})=\\sum_{\\substack{x_{h-1},a_{h-1}\\in\\mathcal{X}\\times A}}P_{\\mathsf{o b s},h}(x_{h}\\mid x_{h-1},a_{h-1})d_{\\mathsf{o b s},h-1}(x_{h-1})\\pi_{\\mathrm{lat}}(a_{h-1}\\mid\\phi(x_{h-1}))}}\\\\ &{=\\psi(x_{h}\\mid s_{h})\\sum_{\\substack{x_{h-1},a_{h-1}\\in\\mathcal{X}\\times A}}P_{\\mathsf{l a t},h}(s_{h}\\mid s_{h-1},a_{h-1})d_{\\mathsf{l a t},h-1}(s_{h-1})\\psi(x_{h-1}\\mid s_{h-1})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times\\pi_{\\mathrm{lat}}(a_{h-1}\\mid\\phi(x_{h-1}))}\\\\ &{=\\psi(x_{h}\\mid s_{h})\\sum_{\\substack{s_{h-1},a_{h-1}\\in\\mathcal{S}\\times A}}P_{\\mathsf{l a t},h}(s_{h}\\mid s_{h-1},a_{h-1})d_{\\mathsf{l a t},h-1}(s_{h-1})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\times\\qquad\\qquad\\psi(x_{h-1}\\mid s_{h-1})\\pi_{\\mathsf{l a t}}(a_{h-1}\\mid\\phi(x_{h-1})).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "The result is obtained by noting that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Gamma_{\\phi}\\circ\\pi_{1\\mathrm{at}}(a_{h-1}\\mid s_{h-1})=\\displaystyle\\sum_{s^{\\prime}\\in S}\\Gamma_{\\phi}(s^{\\prime}\\mid s_{h-1})\\pi_{1\\mathrm{at}}(a_{h-1}\\mid s^{\\prime})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\displaystyle\\sum_{s^{\\prime}\\in S}\\displaystyle\\sum_{x_{h-1}:\\phi^{*}(x_{h-1})=s_{h-1}}\\psi(x_{h-1}\\mid s_{h-1})\\mathbb{I}\\{\\phi(x_{h-1})=s^{\\prime}\\}\\pi_{1\\mathrm{at}}(a_{h}\\mid s^{\\prime})}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\displaystyle\\sum_{x_{h-1}:\\phi^{*}(x_{h-1})=s_{h-1}}\\psi(x_{h-1}\\mid s_{h-1})\\pi_{1\\mathrm{at}}(a_{h-1}\\mid\\phi(x_{h-1})),}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the second line follows from the definition of the mismatch functions. ", "page_idx": 24}, {"type": "text", "text": "Lemma D.3 (Equivalence of state coverability and cumulative state reachability). Let M be an MDP definedoverastatespace $\\mathcal{Z}$ .Thefollowing definition is equivalent toDefinition $D.2$ ", "page_idx": 24}, {"type": "equation", "text": "$$\nC_{\\mathsf{c o v,s t}}(M,\\Pi):=\\operatorname*{max}_{h\\in[H]}\\sum_{z\\in\\mathcal{Z}}\\operatorname*{max}_{\\pi\\in\\Pi}d_{h}^{M,\\pi}(z).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof of Lemma D.3. Straightforward adaptation of the proof of Lemma 3 from Xie et al. [XFBJK23]. \u53e3 ", "page_idx": 24}, {"type": "text", "text": "Proof of Lemma D.1. Using Lemma D.2 and Lemma D.3, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{C_{\\mathrm{cov,st}}(M_{\\mathrm{obs}},\\Pi_{\\mathrm{lat}}\\circ\\Phi)=\\underset{h\\in[H]}{\\operatorname*{max}}\\sum_{\\underset{x\\in\\mathcal{X}}{\\operatorname*{max}},\\phi}\\frac{\\operatorname*{max}}{\\alpha\\operatorname*{sis}}\\mathcal{I}_{\\mathrm{obs}}^{\\mathrm{raco}\\phi}(x)}&{}\\\\ {=\\underset{h\\in[H]}{\\operatorname*{max}}\\sum_{\\underset{x\\in\\mathcal{X}}{\\operatorname*{max}},\\phi}\\psi^{\\star}(x\\mid\\phi^{\\star}(x))d_{\\mathrm{lat}}^{\\Gamma_{\\phi}\\circ\\pi_{\\mathrm{lat}}}(\\phi^{\\star}(x))}&{}\\\\ {=\\underset{h\\in[H]}{\\operatorname*{max}}\\sum_{\\underset{s\\in\\mathcal{X}}{\\operatorname*{max}},\\phi\\in\\mathcal{X}}\\underset{x\\in[x_{1},\\phi]}{\\operatorname*{max}}\\psi^{\\star}(x\\mid s)d_{\\mathrm{lat}}^{\\Gamma_{\\phi}\\circ\\pi_{\\mathrm{lat}}}(s)}&{}\\\\ {=\\underset{h\\in[H]}{\\operatorname*{max}}\\sum_{\\underset{s\\in\\mathcal{S}}{\\operatorname*{max}},\\phi}d_{\\mathrm{lat}}^{\\Gamma_{\\phi}\\circ\\pi_{\\mathrm{lat}}}(s)\\underset{x\\in\\phi^{\\star}(x)=s}{\\sum}\\psi^{\\star}(x\\mid s)}&{}\\\\ {=C_{\\mathrm{cov,st}}(M_{\\mathrm{lat}},\\Gamma_{\\phi}\\circ\\Pi_{\\mathrm{lat}}).}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Lastly, we show that state-action coverability is bounded by state coverability times the size of the actionset. ", "page_idx": 24}, {"type": "text", "text": "Lemma D.4 (State-action coverability bound). For any MDP $M$ andpolicyset $\\Pi$ wehave ", "page_idx": 24}, {"type": "equation", "text": "$$\nC_{\\mathsf{c o v}}(M,\\Pi)\\leq C_{\\mathsf{c o v,s t}}(M,\\Pi)|A|.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof of Lemma D.4. Let $\\mu_{s}\\in\\Delta(\\mathcal{Z})$ witness $C_{\\mathsf{c o v,s t}}(M,\\Pi)$ . Fix $h\\in[H]$ , which we omit below for cleanliness. Then, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\mu_{s,a}\\in\\Delta(\\mathcal{Z}\\times A)}{\\operatorname*{min}}\\underset{\\pi\\in\\Pi}{\\operatorname*{max}}\\underset{z,a\\in\\mathcal{Z}\\times A}{\\operatorname*{max}}\\Biggl\\{\\frac{d^{M,\\pi}(z,a)}{\\mu_{s,a}(z,a)}\\Biggr\\}\\leq\\underset{\\pi\\in\\Pi}{\\operatorname*{max}}\\underset{z,a\\in\\mathcal{Z}\\times A}{\\operatorname*{max}}\\Biggl\\{\\frac{d^{M,\\pi}(z)\\pi(a\\mid z)}{\\mu_{s}(z)^{1/|A|}}\\Biggr\\}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq|A|\\underset{\\pi\\in\\Pi}{\\operatorname*{max}}\\underset{z\\in\\mathcal{Z}}{\\operatorname*{max}}\\Biggl\\{\\frac{d^{M,\\pi}(z)}{\\mu_{s}(z)}\\Biggr\\}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=C_{\\mathrm{cov},\\mathrm{st}}(M,\\Pi)|A|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Lemma D.5 (Pushforward coverability is invariant to rich observations). Let $C_{\\mathsf{p u s h}}(M)$ denotethe pushforward coverabilityparameter for anMDP $M$ (Definion3.3,and $M_{\\mathrm{obs}}^{\\star}:=\\langle\\!\\langle M_{\\tt l a t}^{\\star},\\psi^{\\star}\\rangle\\!\\rangle$ Then, wehave ", "page_idx": 24}, {"type": "equation", "text": "$$\nC_{\\mathsf{p u s h}}(M_{\\mathsf{o b s}}^{\\star})=C_{\\mathsf{p u s h}}(M_{\\mathsf{l a t}}^{\\star}).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Furthermore, leting $\\{\\mu_{\\mathrm{lat},h}\\in\\Delta(S)\\}_{h\\in[H]}$ denote the distribution which witnesses the right-handside, the left-hand-side is witnessed by the distribution ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mu_{\\sf o b s}{}_{,h}(x)=\\psi_{h}^{\\star}(x\\mid\\phi_{h}^{\\star}(x))\\mu_{\\sf l a t}{}_{,h}(\\phi_{h}^{\\star}(x)).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "This follows from an analogous equivalence of pushforward coverability and cumulative conditional reachability. ", "page_idx": 25}, {"type": "text", "text": "Lemma D.6 (Equivalence of pushforward coverability and cumulative conditional reachability). Let $M$ be anMDPdefinedover astatespace $\\mathcal{Z}$ withtransitionkernel $P$ .Thefollowingdefinitionis equivalent to pushforward coverability (Definition3.3): ", "page_idx": 25}, {"type": "equation", "text": "$$\nC_{\\sf p u s h}(M):=\\operatorname*{max}_{h\\in[H]}\\sum_{z^{\\prime}\\in\\mathcal{Z}}\\operatorname*{max}_{z,a\\in\\mathcal{Z}\\times A}P_{h}(z^{\\prime}\\mid z,a).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof of Lemma D.6. Fix $h\\in[H]$ , whose dependence we omit below. For the first direction, letting $\\mu$ denote the pushforward coverability distribution, we have: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\sum_{z^{\\prime}\\in\\mathcal{Z}}\\operatorname*{max}_{z,a\\in\\mathcal{Z}\\times A}P(z^{\\prime}\\mid z,a)=\\sum_{z^{\\prime}\\in\\mathcal{Z}}\\operatorname*{max}_{z,a\\in\\mathcal{Z}\\times A}\\frac{P(z^{\\prime}\\mid z,a)}{\\mu(z^{\\prime})}\\mu(z^{\\prime})\\leq C_{\\mathrm{push}}\\sum_{z^{\\prime}\\in\\mathcal{Z}}\\mu(z^{\\prime})=C_{\\mathrm{push}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "For the second direction, taking $\\mu(z^{\\prime})\\propto\\operatorname*{max}_{z,a}P(z^{\\prime}\\mid z,a)$ we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\mu\\in\\Delta(\\mathcal{Z})}{\\operatorname*{min}}\\underset{z,a,z^{\\prime}\\in\\mathcal{Z}\\times A\\times\\mathcal{Z}}{\\operatorname*{max}}\\frac{P(z^{\\prime}\\mid z,a)}{\\mu(z^{\\prime})}\\le\\underset{z,a,z^{\\prime}\\in\\mathcal{Z}\\times A\\times\\mathcal{Z}}{\\operatorname*{max}}\\frac{P(z^{\\prime}\\mid z,a)}{\\operatorname*{max}_{\\bar{z},\\tilde{a}}P(z^{\\prime}\\mid\\tilde{z},\\tilde{a})}\\sum_{\\tilde{z}^{\\prime}}\\underset{\\tilde{z},\\tilde{a}}{\\operatorname*{max}}P(\\tilde{z}^{\\prime}\\mid\\tilde{z},\\tilde{a})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\le\\underset{z^{\\prime}}{\\sum}\\underset{z,a}{\\operatorname*{max}}P(z^{\\prime}\\mid z,a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof of Lemma D.5. This result follows by Lemma D.6 since, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{C_{\\mathrm{push}}(M_{\\mathrm{obs}})=\\displaystyle\\sum_{x^{\\prime}\\in X}\\operatorname*{max}_{x,a}P_{\\mathrm{obs}}(x^{\\prime}\\mid x,a)}\\\\ &{\\qquad\\qquad\\qquad=\\displaystyle\\sum_{s^{\\prime}\\in S}\\displaystyle\\sum_{x^{\\prime}:\\phi^{*}(x^{\\prime})=s^{\\prime}}\\operatorname*{max}_{x,a}\\psi^{*}(x^{\\prime}\\mid s^{\\prime})P_{\\mathrm{lat}}(s^{\\prime}\\mid\\phi^{\\star}(x),a)}\\\\ &{\\qquad\\qquad\\qquad=\\displaystyle\\sum_{s^{\\prime}\\in S}\\operatorname*{max}_{x,a}P_{\\mathrm{lat}}(s^{\\prime}\\mid\\phi^{\\star}(x),a)\\displaystyle\\sum_{x^{\\prime}:\\phi^{*}(x^{\\prime})=s^{\\prime}}\\psi^{*}(x^{\\prime}\\mid s^{\\prime})}\\\\ &{\\qquad\\qquad=\\displaystyle\\sum_{s^{\\prime}\\in S}\\operatorname*{max}_{s,a}P_{\\mathrm{lat}}(s^{\\prime}\\mid s,a)=C_{\\mathrm{push}}(M_{\\mathrm{lat}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "We next show that the mismatch functions can be used to express the observation-level backups for any function of the decoders. For any $g:S\\to\\mathbb{R}$ $h\\in[H]$ , we define the function $\\left[\\Gamma_{\\phi,h}\\circ g\\right]:S\\rightarrow\\mathbb{R}$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n[\\Gamma_{\\phi,h}\\circ g](s):=\\sum_{s^{\\prime}\\in\\mathcal{S}}\\Gamma_{\\phi,h}(s^{\\prime}\\mid s)g(s^{\\prime}).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "We further overload the Bellman operator notation and define, for any $g:{\\mathcal{S}}\\rightarrow\\mathbb{R}$ and $M_{\\mathrm{{lat}}}\\,=$ $\\left(r_{\\mathrm{{lat}}},P_{\\mathrm{{lat}}}\\right)$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n[\\mathcal{T}_{h}^{M_{\\mathrm{lat}}}g](s,a)=r_{\\mathrm{lat}}(s,a)+\\mathbb{E}_{s^{\\prime}\\sim P_{\\mathrm{lat}}(s,a)}[g(s^{\\prime})].\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Lemma D.7. Let $M_{\\sf o b s}=\\langle\\!\\langle M_{\\tt l a t},\\psi^{\\star}\\rangle\\!\\rangle$ $\\phi^{\\star}:=(\\psi^{\\star})^{-1}$ $\\phi\\in\\Phi$ and $\\Gamma_{\\phi}$ be the mismatch function for emission $\\psi^{\\star}$ (Definition $D.I$ ). Then, for any $f_{\\mathrm{lat}}:S\\times A\\to\\mathbb{R},$ $h\\in[H]$ and $(x,a)\\in\\mathcal{X}\\times\\mathcal{A}$ ,we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left[T_{h}^{M_{\\mathrm{obs}}}(f_{\\mathrm{lat}}\\circ\\phi_{h+1})\\right]\\!(x,a)=\\Big[\\mathcal{T}_{h}^{M_{\\mathrm{lat}}}(\\Gamma_{\\phi,h+1}\\circ V_{f_{\\mathrm{lat}}})\\Big](\\phi_{h}^{\\star}(x),a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof of Lemma D.7. Let $f:=f_{1\\mathsf{a t}},h\\in[H].$ and $(x,a)\\in\\mathcal{X}\\times\\mathcal{A}$ be given. Then, we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left[\\mathcal{T}_{h}^{M_{\\omega}}(f\\circ\\phi_{h+1})\\right](x,a)}\\\\ &{\\quad=r_{\\mathrm{lat},h}(\\phi_{h}^{\\star}(x),a)+\\mathbb{E}_{s_{h+1}\\sim P_{\\mathrm{lat},h}(\\phi_{h}^{\\star}(x),a)}\\mathbb{E}_{x_{h+1}\\sim\\psi_{h+1}^{\\star}(s_{h+1})}[V_{f}(\\phi(x_{h+1}))]}\\\\ &{\\quad=r_{\\mathrm{lat},h}(\\phi_{h}^{\\star}(x),a)+\\mathbb{E}_{s_{h+1}\\sim P_{\\mathrm{lat},h}(\\phi_{h}^{\\star}(x),a)}\\left[\\sum_{x_{h+1}\\in X}\\psi^{\\star}(x_{h+1}\\mid s_{h+1})V_{f}(\\phi(x_{h+1}))\\right]}\\\\ &{\\quad=r_{\\mathrm{lat},h}(\\phi_{h}^{\\star}(x),a)+\\mathbb{E}_{s_{h+1}\\sim P_{\\mathrm{lat},h}(\\phi_{h}^{\\star}(x),a)}\\left[\\sum_{x_{h}^{\\star}\\in X}\\phi_{\\phi}(s^{\\prime}\\mid s_{h+1})V_{f}(s^{\\prime})\\right]}\\\\ &{\\quad=r_{\\mathrm{lat},h}(\\phi_{h}^{\\star}(x),a)+\\mathbb{E}_{s_{h+1}\\sim P_{\\mathrm{lat},h}(\\phi_{h}^{\\star}(x),a)}[\\Gamma_{\\phi}\\circ V_{f}(s_{h+1})]}\\\\ &{\\quad=\\left[\\mathcal{T}_{h}^{M_{\\omega}}(\\Gamma_{\\phi}\\circ V_{f})\\right](\\phi_{h}^{\\star}(x),a),}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where the third line follows from the definition of the mismatch function $\\Gamma_{\\phi}$ ", "page_idx": 26}, {"type": "text", "text": "We next show that the mismatch functions can be used to realize the pushforward dynamics $\\phi_{\\mathsf{A}}^{\\mathsf{H}}M_{\\mathsf{o b s}}^{\\star}$ which we recall are defined as: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\left[\\phi\\sharp M_{\\sf o b s}^{\\star},h\\right](r,s^{\\prime}\\mid x,a)=\\sum_{x^{\\prime}:\\phi(x^{\\prime})=s^{\\prime}}M_{\\sf o b s}^{\\star}{}_{h}(r,x^{\\prime}\\mid x,a).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "We also recall the notation $\\left[\\Gamma_{\\phi,h+1}\\circ M_{1\\mathsf{a t}}\\right]_{h}$ , defined via: ", "page_idx": 26}, {"type": "equation", "text": "$$\n[\\Gamma_{\\phi}\\circ M_{\\mathrm{1at}}]_{h}(r_{h},s_{h+1}\\mid s_{h},a_{h}):=\\sum_{s_{h+1}^{\\prime}\\in{\\cal S}}M_{\\mathrm{1at},h}(r_{h},s_{h+1}^{\\prime}\\mid s_{h},a_{h})\\Gamma_{\\phi,h+1}(s_{h+1}\\mid s_{h+1}^{\\prime}).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Lemma D.8 (Pushforward model realizability via mismatch functions). For all $\\phi\\in\\Phi$ $h\\in[H]$ we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n[\\phi_{h+1}\\sharp M_{\\sf o b s}^{\\star},h](\\cdot\\mid x,a)=[[\\Gamma_{\\phi}\\circ M_{\\mathrm{1at}}^{\\star}]_{h}\\circ\\phi_{h}^{\\star}](\\cdot\\mid x,a)\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Proof of Lemma D.8. Note that $\\Gamma_{\\phi}$ can alternatively be written as: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\Gamma_{\\phi,h}(s_{h}^{\\prime}\\mid s_{h})=\\sum_{x_{h}:\\phi(x_{h})=s_{h}^{\\prime}}\\psi_{h}^{\\star}(x_{h}\\mid s_{h}).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "We have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\phi_{h+1}\\{\\mathcal{M}_{\\phi,\\mathbf{s},h}^{*}(r_{h+1},s_{h+1}\\mid x_{h},a_{h})}\\}}\\\\ &{=\\underbrace{\\sum_{\\mathbf{x}}}_{x_{h+1}\\cdot\\hat{\\mathbf{x}}_{h+1}(x_{h+1})=s_{h+1}}\\ M_{\\phi_{\\mathbf{s},h}}^{*}(r_{h+1},x_{h+1}\\mid x_{h},a_{h})}\\\\ &{=\\underbrace{\\sum_{\\mathbf{x}}}_{x_{h+1}\\cdot\\hat{\\mathbf{x}}_{h+1}(x_{h+1})=s_{h+1}}\\left(\\underbrace{M_{\\mathbf{s},h}^{*}}_{r,s^{*}\\in\\mathbb{R}\\times\\mathcal{S}}M_{1\\mathrm{at},h}^{*}(r,s^{\\prime}\\mid\\phi_{h}^{*}(x_{h}),a_{h})\\psi_{h+1}^{*}(x_{h+1}\\mid s^{\\prime})\\right)}\\\\ &{=\\underbrace{\\sum_{\\mathbf{x}}M_{\\mathbf{s},h}^{*}(r_{h+1},s)}_{r,s^{\\prime}\\in\\mathbb{R}\\times\\mathcal{S}}\\ \\underbrace{M_{1\\mathrm{at},h}^{*}(r,s^{\\prime}\\mid\\phi_{h}^{*}(x_{h}),a_{h})}_{x_{h+1}\\cdot\\hat{\\mathbf{x}}_{h+1}(x_{h+1})=s_{h+1}}\\psi_{h+1}^{*}(x_{h+1}\\mid s^{\\prime})}\\\\ &{=\\underbrace{\\sum_{\\mathbf{x}}M_{\\mathbf{s},h}^{*}}_{r,s^{\\prime}\\in\\mathbb{R}\\times\\mathcal{S}}\\ \\underbrace{M_{1\\mathrm{at},h}^{*}(r,s^{\\prime}\\mid\\phi_{h}^{*}(x_{h}),a_{h})}_{\\in\\hat{\\mathbb{R}}_{h}^{*}(x_{h})=\\hat{\\mathbb{S}}_{h+1}(x_{h+1})=s_{h+1}}\\left(\\!\\!\\!\\begin{array}{c}{1}\\\\ {\\delta_{h+1}}\\\\ {0}\\end{array}\\right)}\\\\ &{=[\\mathbb{F}_{\\phi}\\odot M_{1\\mathrm{at},h}^{*}]_{h}(r,s_{h+1}\\mid\\phi_{h}^{*}(x_{h}),a_{h}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "as desired. ", "page_idx": 26}, {"type": "text", "text": "E Proofs and Additional Results for Section 3.2: Impossibility Results ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "This section contains additional information and proofs related to our impossibility results regarding statistical modularity (Section 3.2), and is organized as follows: ", "page_idx": 27}, {"type": "text", "text": "\u00b7 Appendix E.1 contains the statement for an additional lower bound that is useful for establishing the impossibility results of Figure 1.   \n\u00b7 Appendix E.2 contains details for each entry of Figure 1.   \n\u00b7 Appendix E.3 contains for proofs for our main lower bound (Theorem 3.1) and the additional lower bound (Theorem E.1). ", "page_idx": 27}, {"type": "text", "text": "E.1Additional Lower Bound ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Theorem E.1 (Alternative lower bound). For every $N\\geq4$ thereexistsan emission class $\\Psi$ and $a$ decoderclass $\\Phi$ with $|\\Psi|=|\\Phi|=N$ and a family of latent MDPs $\\mathcal{M}_{\\mathrm{{lat}}}$ satisfying (i) $|\\mathcal{M}_{\\mathrm{{lat}}}|=1$ (ii) $H=1$ (iii) $|S|=|{\\mathcal{X}}|=N$ (iv) $|{\\mathcal{A}}|=N$ andsuchthat ", "page_idx": 27}, {"type": "text", "text": "1.Forall $\\varepsilon,\\delta>0$ wehavecomp $(\\mathcal{M}_{\\sf l a t},\\varepsilon,\\delta)=0.$   \n2.Foranabsoluteconstant $c>0$ $\\cdot\\ 0,\\,{\\mathsf{c o m p}}(\\langle\\!\\langle M_{1{\\mathsf{a t}}},\\Phi\\rangle\\!\\rangle,c,c)\\geq\\Omega(N/\\log(N)).$ ", "page_idx": 27}, {"type": "text", "text": "Proof of Theorem E.1. See Appendix E.3.2. ", "page_idx": 27}, {"type": "text", "text": "E.2 Details for Figure 1 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Below, we provide details on each entry in Figure 1. More precisely, for each latent class $\\mathcal{M}_{\\mathrm{{lat}}}$ ,we will give a (brief) description of the MDP class $\\mathcal{M}_{\\mathrm{{lat}}}$ , give our choice of latent complexity comp for $\\mathcal{M}_{\\mathrm{{lat}}}$ , and prove that the class is or is not statistically modular for that choice of latent complexity. We view our choices of latent complexities as natural complexities for the respective classes. ", "page_idx": 27}, {"type": "text", "text": "Tabular MDPs $\\left(\\checkmark\\right)$ ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\mathrm{{lat}}}$ : Tabular MDPs $M_{\\mathrm{{lat}}}=(S,\\mathcal{A},P_{\\mathrm{{lat}}},R_{\\mathrm{{lat}}},H)$ . [AOM17] \u00b7 Latent complexity comp: We take comp $\\begin{array}{r}{\\mathsf{\\Pi}_{\\mathsf{I}\\mathrm{at},\\,\\varepsilon,\\,\\delta}=\\mathsf{p o l y}(|S|,|A|,H,\\varepsilon^{-1},\\log\\delta^{-1})}\\end{array}$ , which is attainable, for example, via the UcB-V1 algorithm of Azar et al. [AOM17] \u00b7 Statistical modularity $(\\checkmark)$ : Known Block MDP algorithms (e.g. MuSIK [MFR23], BRIEE [ZSUWAS22]) have sample complexities of poly $\\prime(|S|,|A|,H,\\varepsilon^{-1},\\log\\delta^{-1},\\log|\\Phi|)$ ", "page_idx": 27}, {"type": "text", "text": "Contextual Bandits $\\left(\\checkmark\\right)$ ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\mathrm{{lat}}}$ : Contextual bandits with context space $\\boldsymbol{S}$ , action space $\\boldsymbol{\\mathcal{A}}$ , reward function $r_{\\mathrm{1at}}^{\\star}:S\\times\\mathcal{A}\\to[0,1]$ and a finite realizable function class satisfying $r^{\\star}\\in\\mathcal{F}_{\\tt l a t}$ \u00b7 Latent complexity comp: We take comp $)(\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta)=\\mathsf{p o l y}(|\\mathcal{A}|,\\log|\\mathcal{F}_{\\mathrm{lat}}|,\\varepsilon^{-1},\\log\\delta^{-1})$ attainable via, e.g., the SQUARE-CB algorithm [FR20]. \u00b7 Statistical modularity $(\\checkmark)$ : We note that $\\mathcal{F}_{\\mathrm{lat}}\\circ\\Phi\\,=\\,\\left\\{\\left[f\\circ\\phi\\right]\\,|\\,\\,f\\in\\mathcal{F},\\phi\\in\\Phi\\right\\}$ is a realizable function classfor the observation-level reward function $r_{\\circ\\mathsf{b}\\mathsf{s}}^{\\star}$ since $r_{\\mathrm{obs}}^{\\star}=\\left[r_{\\mathrm{lat}}^{\\star}\\circ\\phi^{\\star}\\right]\\in\\mathcal{F}_{\\mathrm{lat}}\\circ\\Phi$ \uff0c Thus, applying the SQUARE-CB algorithm directly on the observations $\\boldsymbol{x}^{(t)},\\boldsymbol{a}^{(t)},\\boldsymbol{r}^{(t)}$ will give complexity poly $(|\\mathcal{A}|\\log(|\\mathcal{F}_{\\mathrm{1at}}||\\Phi|),\\overline{{\\varepsilon}}^{-1},\\log\\delta^{-1})\\stackrel{*}{=}\\mathrm{poly}(|\\mathcal{A}|,\\log|\\mathcal{F}_{\\mathrm{1at}}|,\\log|\\Phi|,\\varepsilon^{-1},\\log\\delta^{\\overline{{\\cdot}}1})$ ", "page_idx": 27}, {"type": "text", "text": "Low-rank MDP $\\left(\\checkmark\\right)$ ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\mathrm{{lat}}}$ : MDPs $M_{\\mathrm{{lat}}}\\;=\\;(S,A,H,P_{\\mathrm{{lat}}},r_{\\mathrm{{lat}}})$ such that there exists $\\mu_{\\mathrm{lat},h}^{\\star}\\ \\in\\ \\mathbb{R}^{d}$ $\\theta_{1{\\mathsf{a t}},h}^{\\star}\\in\\mathbb{R}^{d}$ , and a known set of features $\\Xi_{\\mathrm{1at}}=\\left\\{\\xi_{\\mathrm{1at}}=\\left\\{\\xi_{\\mathrm{1at},h}:S\\times A\\to\\mathbb{R}^{d}\\right\\}_{h=1}^{H}\\right\\}$ such that for all $h\\in[H]$ we have $r_{\\mathrm{1at}}(s_{h},a_{h})=\\langle\\xi_{\\mathrm{1at},h}^{\\star}(s_{h},a_{h}),\\theta_{\\mathrm{1at},h}^{\\star}\\rangle$ as well as ", "page_idx": 27}, {"type": "equation", "text": "$$\nP_{\\mathrm{lat},h}(s_{h+1}\\mid s_{h},a_{h})=\\langle\\xi_{\\mathrm{lat},h}^{\\star}(s_{h},a_{h}),\\mu_{\\mathrm{lat},h+1}^{\\star}(s_{h+1})\\rangle\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "for some $\\xi_{\\mathrm{lat}}^{\\star}\\in\\Xi_{\\mathrm{lat}}$ ", "page_idx": 27}, {"type": "text", "text": "\u00b7 Latent complexity comp: We take $\\mathsf{c o m p}(\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta)\\,=\\,\\mathsf{p o l y}(d,\\vert A\\vert,H,\\log\\vert\\Xi_{\\mathrm{1at}}\\vert,\\varepsilon^{-1},\\log\\delta^{-1})$ which is attainable via the VoX algorithm of Mhammedi et al. [MBFR23]. ", "page_idx": 27}, {"type": "text", "text": "\u00b7 Statistical modularity $(\\checkmark)$ : This is obtained by noting that the observation-level dynamics also satisfy the low-rank property with the same dimension. Formally, letting $P_{\\mathsf{o b s}}$ be the transition kernel for $\\langle\\!\\langle M_{\\mathrm{lat}},\\psi^{\\star}\\bar{\\rangle}\\!\\rangle$ and $\\bar{\\phi^{\\star}}=(\\psi^{\\star})^{-1}$ ,wehave ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{P_{\\mathrm{obs},h}(x_{h+1}\\mid x_{h},a_{h})=\\sum_{s_{h+1}\\in\\mathcal{S}}P_{\\mathrm{lat},h}(s_{h+1}\\mid\\phi_{h}^{\\star}(x_{h}),a_{h})\\psi_{h+1}^{\\star}(x_{h+1}\\mid s_{h+1})}}\\\\ &{=\\displaystyle\\sum_{s_{h+1}\\in\\mathcal{S}}\\langle\\xi_{\\mathrm{lat},h}^{\\star}(\\phi_{h}^{\\star}(x),a),\\mu_{\\mathrm{lat},h+1}^{\\star}(s_{h+1})\\rangle\\psi_{h+1}^{\\star}(x_{h+1}\\mid s_{h+1})}\\\\ &{=\\displaystyle\\bigg\\langle\\xi_{\\mathrm{lat},h}^{\\star}(\\phi_{h}^{\\star}(x),a),\\displaystyle\\sum_{s_{h+1}\\in\\mathcal{S}}\\mu_{\\mathrm{lat},h+1}^{\\star}(s_{h+1})\\psi_{h+1}^{\\star}(x_{h+1}\\mid s_{h+1})\\bigg\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Thus, the transition  kernel $P_{\\mathsf{o b s}}$ is a low-rank MDP  with $\\begin{array}{r l r}{\\mu_{065,h+1}(x_{h+1})}&{{}:=}&{}\\end{array}$ $\\begin{array}{r}{\\sum_{s_{h+1}}\\mu_{\\mathrm{1at},h+1}^{\\star}(s_{h+1})\\psi_{h+1}^{\\star}(x_{h+1}\\mid s_{h+1})}\\end{array}$ and feature class ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\Xi_{\\mathrm{lat}}\\circ\\Phi=\\Bigl\\{\\xi_{\\mathrm{lat}}\\circ\\phi=\\{\\xi_{h}\\circ\\phi_{h}:x,a\\mapsto\\xi_{h}(\\phi_{h}(x),a)\\}_{h=1}^{H}\\mid\\xi_{\\mathrm{lat}}\\in\\Xi_{\\mathrm{lat}},\\phi\\in\\Phi\\Bigr\\}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Lastly, since $r_{\\mathrm{obs}}=[r_{\\mathrm{lat}}\\circ\\phi^{\\star}]$ , the reward function is also linear with the same unknown feature class. Thus we can apply Vox directly on top of the observations, with the feature class $\\Xi_{\\mathrm{lat}}\\circ\\Phi$ which will achieve a complexity poly $\\langle d,|\\hat{A|},H,\\mathrm{log}|\\Xi_{\\mathrm{1at}}|,\\mathrm{log}|\\Phi|,\\varepsilon^{-1},\\mathrm{log}(\\delta^{-1}))$ ", "page_idx": 28}, {"type": "text", "text": "Known Deterministic MDP $\\begin{array}{r}{\\left(\\left|\\mathcal{M}_{\\sf l a t}\\right|=1\\right)(\\mathcal{A}).}\\end{array}$ ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\sf1a t}\\colon\\mathcal{M}_{\\sf1a t}=\\{M_{\\sf1a t}=(S,\\mathcal{A},P_{\\sf1a t},R_{\\sf1a t},H)\\}$ is a set of MDPs of size 1 with both deterministic rewards and deterministic transitions.   \n\u00b7 Latent complexity comp: We take comp $(\\mathcal{M}_{\\mathrm{{lat}}},\\varepsilon,\\delta)=0$ , which is attainable as $M_{\\mathrm{1at}}$ is known and we can simply deploy its optimal policy.   \n\u00b7 Statistical modularity $(\\checkmark)$ : We note that, due to determinism, the latent optimal policy can be chosen to be open-loop without loss of generality, and thus will always experience the same trajectory $(s_{1}^{\\star},a_{1}^{\\star},\\ldots,s_{H}^{\\star},a_{H}^{\\star})$ . We can define the observation-level policy which commits to this same sequence of actions, i.e. $\\pi_{\\mathsf{o b s},h}(x_{h})=a_{h}^{\\star}$ for all $x_{h}$ . This will be an optimal policy for any $M_{\\sf o b s}=\\langle\\!\\langle M_{\\sf l a t},\\psi\\rangle\\!\\rangle$ , and can also be learned in O samples. ", "page_idx": 28}, {"type": "text", "text": "Low State Occupancy $\\cup\\pi:S\\rightarrow\\Delta(A))\\;(\\mathcal{A}).$ ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\mathrm{{lat}}}$ .. $\\mathcal{M}_{\\sf{l a t}}\\;=\\;\\{M_{\\sf{l a t}}\\;=\\;(S,A,P_{\\mathrm{lat}},R_{\\mathrm{lat}},H)\\}$ is a set of MDPs for which we have a realizable value function class, and such that there exists a feature map $\\zeta_{\\mathrm{1at}}~=$ $\\left\\{\\zeta_{\\mathrm{1at},h}:S\\to\\mathbb{R}^{d}\\right\\}_{h=1}^{H}$ such that for al $\\pi:S\\rightarrow\\Delta(A)$ and for all $M_{\\mathrm{{lat}}}\\in\\mathcal{M}_{\\mathrm{{lat}}}$ we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\forall h\\in[H]\\ \\exists\\theta_{h}^{M_{\\mathrm{lat}},\\pi}:\\quad d_{h}^{M_{\\mathrm{lat}},\\pi}(s)=\\Big\\langle\\zeta_{\\mathrm{lat},h}(s),\\theta_{h}^{M_{\\mathrm{lat}},\\pi}\\Big\\rangle.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Note that the feature map does not need to be known. ", "page_idx": 28}, {"type": "text", "text": "\u00b7 Latent complexity comp: We take com $\\mathsf{\\Lambda}_{?}(\\mathcal{M}_{\\sf1a t},\\varepsilon,\\delta)=\\mathsf{p o l y}(d,|\\mathcal{A}|,H,\\log|\\mathcal{F}_{\\sf1a t}|,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))$ which is attainable by the BILIN-UCB algorithm of Du et al., since i) MDPs with this property have Bilinear rank bounded by $d|\\mathcal{A}|$ (see Definition 4.3 and Lemma 4.6 of Du et al. $[\\mathrm{Du}+21]$ ), and ii) one can construct the value function class $\\mathcal{F}_{\\mathrm{lat}}=\\{Q^{M_{\\mathrm{lat}},\\star}\\mid M_{\\mathrm{lat}}\\in\\mathcal{M}_{\\mathrm{lat}}\\}$ , Which is realizable and has size $\\log\\lvert\\mathcal{F}_{\\mathrm{lat}}\\rvert=\\log\\lvert\\mathcal{M}_{\\mathrm{lat}}\\rvert$ ", "page_idx": 28}, {"type": "text", "text": "\u00b7 Statistical modularity $(\\checkmark)$ : We firstly note that one can construct a realizable value function class for the set $\\langle\\!\\langle\\mathcal{M}_{\\mathrm{1at}},\\Phi\\rangle\\!\\rangle$ , via the set $\\bar{\\mathcal{F}_{\\mathsf{o b s}}}=\\left\\{Q^{M_{\\mathrm{lat}},\\star}\\circ\\phi\\ |\\ M_{\\mathrm{lat}}\\in\\mathcal{M}_{\\mathrm{lat}},\\phi\\in\\Phi\\right\\}$ This is realizable since, for any $M_{\\sf o b s}:=\\langle\\!\\langle M_{\\sf l a t},\\psi\\rangle\\!\\rangle$ letting $\\phi^{\\star}=\\psi^{-1}$ , we have $Q^{M_{\\mathrm{obs}},\\star}=Q^{M_{\\mathrm{lat}},\\star}\\circ\\phi^{\\star}$ , and that this class has size $\\log\\lvert\\mathcal{M}_{\\mathrm{1at}}\\rvert\\rvert\\Phi\\rvert$ We can then show that the occupancies $d^{M_{\\tt o b s},\\pi_{f_{0}\\tt b s}}$ , for $f_{\\tt o b s}\\in\\mathcal{F}_{\\tt o b s}$ can also be expressed as $d$ -dimensional linear function for an appropriate choice of features, which will imply that the BILIN-UCB algorithm run directly on $M_{\\mathsf{o b s}}$ will attain a complexity of $\\mathsf{p o l y}(d,|\\mathcal{A}|,\\bar{H},\\log\\mathcal{M}_{\\mathrm{1at}},\\log\\Phi,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))$ . To obtain this, we recall the following lemma: ", "page_idx": 28}, {"type": "text", "text": "Lemma D.2.Let $\\left\\{\\Gamma_{\\phi}\\right\\}_{\\phi\\in\\Phi}$ denote themismatchfunctions for emission $\\psi^{\\star}$ and let $M_{\\tt o b s}\\;=\\;$ $\\langle\\!\\langle M_{\\mathrm{lat}},\\psi^{\\star}\\rangle\\!\\rangle$ .Then,for any $\\pi_{\\mathrm{lat}}\\in\\Pi_{\\mathrm{lat}},\\,\\phi\\in\\Phi,\\,h\\in[H],\\,x\\in\\mathcal{X},$ We have ", "page_idx": 28}, {"type": "equation", "text": "$$\nd_{h}^{M_{\\mathrm{obs}},\\pi_{\\mathrm{lat}}\\circ\\phi}(x)=\\psi_{h}^{\\star}(x\\mid\\phi_{h}^{\\star}(x))d_{h}^{M_{\\mathrm{lat}},\\Gamma_{\\phi}\\circ\\pi_{\\mathrm{lat}}}(\\phi_{h}^{\\star}(x)).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Thanks to the above lemma, we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{d_{\\mathrm{obs}}^{\\pi_{f0}\\phi}(x_{h})=\\psi(x_{h}\\mid\\phi^{\\star}(x_{h}))d_{\\mathrm{lat}}^{\\Gamma_{\\phi}\\circ\\pi_{f}}(\\phi^{\\star}(x_{h}))}\\\\ &{\\qquad\\qquad=\\psi(x_{h}\\mid\\phi^{\\star}(x_{h}))\\Bigl\\langle[\\zeta_{\\mathrm{lat},h}\\circ\\phi_{h}^{\\star}](x_{h}),\\theta_{h}^{M_{\\mathrm{lat}},\\Gamma_{\\phi}\\circ\\pi_{f}}\\Bigl\\rangle}\\\\ &{\\qquad\\qquad=\\Bigl\\langle\\psi(x_{h}\\mid\\phi^{\\star}(x_{h}))[\\zeta_{\\mathrm{lat},h}\\circ\\phi_{h}^{\\star}](x_{h}),\\theta_{h}^{M_{\\mathrm{lat}},\\Gamma_{\\phi}\\circ\\pi_{f}}\\Bigl\\rangle}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "andso $d_{\\mathsf{o b s}}^{\\pi_{f\\circ\\phi}}$ is linear with fature mapping $\\psi(x_{h}\\mid\\phi^{\\star}(x_{h}))[\\zeta_{\\mathrm{1at},h}\\circ\\phi_{h}^{\\star}]$ and parameter $\\theta^{M_{\\mathrm{lat}},\\Gamma_{\\phi}\\circ\\pi_{f}}$ Recall that the feature map need not be known, so that BILIN-UCB can still be applied despite not knowing $\\psi$ and $\\phi^{\\star}$ ", "page_idx": 29}, {"type": "text", "text": "Model class $^+$ Pushforward Coverability $(\\checkmark)$ ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\mathrm{{lat}}}$ $_{\\mathrm{lat}}\\colon\\mathcal{M}_{\\mathrm{1at}}\\,=\\,\\{M_{\\mathrm{1at}}\\,=\\,(S,A,P_{\\mathrm{1at}},R_{\\mathrm{1at}},H)\\}$ is a set of MDPs that all satisfy pushforward coverability $C_{\\mathsf{p u s h}}(M_{\\mathsf{l a t}})\\leq C_{\\mathsf{p u s h}}$ (cf. Eq. (28) for the definition). ", "page_idx": 29}, {"type": "text", "text": "\u00b7 Latent complexity comp: Wetake $\\mathsf{c o m p}(\\mathcal{M}_{\\mathrm{lat}},\\varepsilon,\\delta)$ $=$ $\\mathsf{p o l y}(C_{\\mathsf{p u s h}},|\\mathcal{A}|,H,\\log|\\mathcal{M}_{\\mathrm{1at}}|,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))$ \uff0c which is attainable by the GoLF algorithm via the results of Xie et al. [XFBJK23] (see also Lemma F.3). We obtain this by noting that i) $C_{\\mathsf{c o v}}\\leq C_{\\mathsf{p u s h}}|\\mathcal{A}|$ , where $C_{\\mathsf{c o v}}$ is defined in Definition 2 of Xie et al. [XFBJK23], and i) a realizable model class can be used to construct a realizable value function class $\\mathcal{F}$ and a Bellman-complete value function helper class $\\mathcal{G}$ with sizes $\\log\\!|\\mathcal{F}|=\\log|\\mathcal{M}|$ and $\\log|\\mathcal{G}|=\\mathcal{O}(\\log|\\mathcal{M}|)$ ", "page_idx": 29}, {"type": "text", "text": "\u00b7 Statistical modularity $(\\checkmark)$ : This is obtained via Theorem 3.2. ", "page_idx": 29}, {"type": "text", "text": "Linear CB/MDP $(\\pmb{x}^{\\star})$ ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\mathrm{{lat}}}$ : MDPs $M_{\\mathrm{{lat}}}=(S,\\mathcal{A},P_{\\mathrm{{lat}}},R_{\\mathrm{{lat}}},H)$ that are linear with respect to a known feature map $\\xi_{\\mathrm{lat}}^{\\star}:S\\times A\\rightarrow\\mathbb{R}^{d}$ (i.e. such that Eq. (16) holds for $\\xi_{\\mathrm{lat}}^{\\star}$ ", "page_idx": 29}, {"type": "text", "text": "\u00b7 Latent complexity comp: We take comp $\\begin{array}{r}{(M_{\\mathrm{1at}},\\varepsilon,\\delta)=\\mathsf{p o l y}(d,H,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))}\\end{array}$ , which is attainable via the LsVI-UCB algorithm of Jin et al. [JYWJ20]. Note that this guarantee does not depend on the number of actions. ", "page_idx": 29}, {"type": "text", "text": "\u00b7 Statistical intractability $({\\pmb X})$ : The latent model used in the construction of Theorem E.1 is a set (of size 1) of linear MDPs with $d=1$ . In particular, that construction was a contextual bandit so we only have to realize a reward function, and since there is only one latent model so we can trivially embed this with $d=1$ via $\\xi_{\\mathrm{1at}}^{\\star}(s,a)=r_{\\mathrm{1at}}(s,a)$ , where $r_{\\tt l a t}$ is the reward function of the MDP used in Theorem E.1. ", "page_idx": 29}, {"type": "text", "text": "\u00b7 Statistical modularity with additional $|{\\mathcal{A}}|$ -dependence: As in the Low-rank MDP case above, $\\langle\\!\\langle M_{\\mathrm{{lat}}},\\psi\\rangle\\!\\rangle$ is low-rank with unknown feature set $\\Phi^{\\prime}\\,=\\,\\{\\xi_{\\mathrm{lat}}^{\\star}\\circ\\phi\\mid\\phi\\in\\Phi\\}$ .Thus, by the same conclusion, a the Vox algorithm will have complexity $\\mathsf{p o l y}(d,|\\mathcal{A}|,H,\\log|\\Phi|)$ , which is of the desired form if we allow suboptimal dependence on $|{\\mathcal{A}}|$ ", "page_idx": 29}, {"type": "text", "text": "Model class $^+$ Coverability $(\\forall\\,\\pi_{M}:M\\in\\mathcal{M})\\,(\\$ ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "\u00b7 Latent assumption: $\\mathcal{M}_{\\sf{l a t}}\\,=\\,\\{M_{\\sf{l a t}}=(S,\\mathcal{A},P_{\\mathrm{lat}},R_{\\mathrm{lat}},H)\\}$ is a set of MDPs that all satisfy coverability with respect to the policy class $\\Pi_{\\mathcal{M}}=\\left\\{\\pi_{\\scriptscriptstyle M}\\;\\vert\\;M\\in\\mathcal{M}\\right\\}$ , i.e. we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\forall M_{\\mathrm{{lat}}}\\in{\\mathcal{M}}_{\\mathrm{{lat}}}:\\quad C_{\\mathrm{cov}}(M_{\\mathrm{{lat}}})=\\operatorname*{inf}_{\\mu_{h}\\in\\Delta(S\\times A)}\\operatorname*{sup}_{h\\in[H]}\\operatorname*{sup}_{\\pi\\in\\Pi_{M}}\\left\\|{\\frac{d_{h}^{M_{\\mathrm{{lat}}},\\pi}}{\\mu_{h}}}\\right\\|_{\\infty}<\\infty\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "\u00b7 Latent complexity comp: We take $\\mathsf{c o m p}(\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta)=\\mathsf{p o l y}(C_{\\mathsf{c o v}},H,\\log|\\mathcal{M}_{\\mathrm{1at}}|,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))$ \uff0c which is attainable by the GoLF algorithm via the results of Xie et al. [XFBJK23] (see also   \nLemma F.3). We obtain this by noting that a realizable model class can be used to construct a realizable value function class $\\mathcal{F}$ and a complete value function class $\\mathcal{G}$ of sizes $\\log\\!|\\mathcal{F}|=\\log|\\mathcal{M}|$ and $\\log\\vert\\mathcal{G}\\vert=\\mathcal{O}(\\log\\vert\\mathcal{M}\\vert)$   \n\u00b7 Statistical intractability $(\\pmb{X})$ : The latent models used in the construction of Theorem 3.1 are a set of coverable MDPs - in particular, these are trivially coverable with $C_{\\mathsf{c o v}}=1$ since there is a single   \nlatent model and we can take $\\mu=d^{M_{\\mathrm{lat}}^{\\star},\\pi_{M_{\\mathrm{lat}}^{\\star}}}$ We remark that it is aninteresting openquestion whether this impossibility result continues to hold if we require coverability with respect to the class $\\Pi$ of all possible latent policies. ", "page_idx": 29}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\sf1a t}\\colon\\mathcal{M}_{\\sf1a t}=\\{M_{\\sf1a t}=(S,\\mathcal{A},P_{\\sf1a t},R_{\\sf1a t},H)\\}$ is a set of MDPs of size 1. ", "page_idx": 30}, {"type": "text", "text": "\u00b7 Latent complexity comp: We take comp $(\\mathcal{M}_{\\mathrm{{lat}}},\\varepsilon,\\delta)=0$ , which is attainable as $M_{\\mathrm{1at}}$ is known and we can simply deploy its optimal policy.   \n\u00b7 Statistical intractability $({\\pmb X})$ : This is precisely the setting of Theorem 3.1, which shows that at least $\\Omega(N/\\log(N))$ samples will be needed, where $N=|\\Phi|$ ", "page_idx": 30}, {"type": "text", "text": "Bellman rank ( $Q$ -type or $V$ -type) $(\\pmb{x})$ ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "\u00b7 Latent assumption: $\\mathcal{M}_{\\sf{l a t}}=\\left\\{M_{\\sf{l a t}}=(S,\\mathcal{A},P_{\\sf{l a t}},R_{\\sf{l a t}},H)\\right\\}$ is a set of latent models such that each $M_{\\mathrm{{lat}}}\\in\\mathcal{M}_{\\mathrm{{lat}}}$ has $Q$ -type Bellman rank $d$ or $V$ -type Bellman rank $d$ [JLM21]. Letting $\\mathcal{F}$ be a realizable value function class for $\\mathcal{M}_{\\mathrm{{lat}}}$ , in the $Q$ -type case, this means that the $|\\Pi_{\\mathcal{F}}|\\times|\\bar{\\mathcal{F}}|$ matrix ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathcal{E}_{h}^{Q}(\\pi,f)=\\mathbb{E}^{\\pi}\\Big[f_{h}\\big(s_{h},a_{h}\\big)-r_{h}-\\operatorname*{max}_{a^{\\prime}}f_{h+1}\\big(s_{h+1},a^{\\prime}\\big)\\Big],\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "admits a rank $d$ factorization. In the $V$ -type case, the matrix ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathcal{E}_{h}^{V}(\\pi,f)=\\mathbb{E}_{s_{h}\\sim d_{h}^{\\pi},a_{h}\\sim\\pi_{f}}\\Big[f_{h}(s_{h},a_{h})-r_{h}-\\operatorname*{max}_{a^{\\prime}}f_{h+1}\\big(s_{h+1},a^{\\prime}\\big)\\Big]\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "admits a rank- $d$ matrix factorization. ", "page_idx": 30}, {"type": "text", "text": "\u00b7 Latent complexity comp: We take $\\mathsf{c o m p}(\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta)\\;=\\;\\mathsf{p o l y}(d,H,|\\mathcal{A}|\\log|\\mathcal{F}|,\\varepsilon^{-1},$ $\\log\\!\\left(\\delta^{-1}\\right))$ for the $V$ -type Bellman rank case, which is achievable by the OLIVE algorithm of Jiang et al. [JKALS17], and co $\\mathsf{m p}(\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta)=\\mathsf{p o l y}(d,H,\\log|\\mathcal{F}|,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))$ for $Q$ -type Bellman rank, which is achievable by the BILIN-UcB algorithm of Du et al. $[\\mathrm{Du}+21]$ ", "page_idx": 30}, {"type": "text", "text": "\u00b7Statistical intractability $(\\pmb{X})$ : We note that the construction in Theorem 3.1 has $|\\mathcal{M}_{\\mathrm{lat}}|\\;=\\;1$ which trivially has Bellman rank equal to 1, so Theorem 3.1 precludes statistical modularity with complexitycomp. ", "page_idx": 30}, {"type": "text", "text": "Eluder dimension $^+$ Bellman Completeness (x) ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\sf1a t}\\colon\\mathcal{M}_{\\sf1a t}=\\{M_{\\sf1a t}=(S,\\mathcal{A},P_{\\sf1a t},R_{\\sf1a t},H)\\}$ is a set of MDPs such that there is a function class ${\\mathcal{F}}_{\\mathrm{lat}}$ satisfying ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\forall f_{\\mathrm{lat}}\\in\\mathcal{F}_{\\mathrm{lat}},M_{\\mathrm{lat}}\\in\\mathcal{M}_{\\mathrm{lat}}:\\quad\\mathcal{T}^{M_{\\mathrm{lat}}}f_{\\mathrm{lat}}\\in\\mathcal{F}_{\\mathrm{lat}}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Furthermore, each $M_{\\mathrm{{lat}}}\\in\\mathcal{M}_{\\mathrm{{lat}}}$ has Bellman-Eluder dimension bounded by $d$ (see Definition 8 of [JLM21]). ", "page_idx": 30}, {"type": "text", "text": "\u00b7 Latent complexity comp: We take comp $)(\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta)=\\mathsf{p o l y}(d,H,\\log|\\mathcal{F}|,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))$ which is attainable by the GOLF algorithm of Jin et al. [JLM21]. ", "page_idx": 30}, {"type": "text", "text": "\u00b7 Statistical intractability $(\\pmb{X})$ : As in the Bellman rank case, the construction in Theorem 3.1 has $|\\mathcal{M}_{\\mathrm{1at}}|\\;=\\;1$ , so we can take $\\mathcal{F}_{\\mathrm{lat}}\\,=\\,\\{Q^{M_{\\mathrm{lat}},\\star}\\,\\mid\\,M_{\\mathrm{lat}}\\,\\in\\,\\mathcal{M}_{\\mathrm{lat}}\\}$ which is evidently complete for ${\\mathcal{T}}^{M_{\\mathrm{lat}}}$ , and has Eluder dimension 1, so Theorem 3.1 precludes statistical modularity with complexity comp. ", "page_idx": 30}, {"type": "text", "text": "$Q^{\\star}$ -irrelevant State Abstraction $(\\pmb{x})$ ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\mathrm{{lat}}}$ $M_{\\mathrm{1at}}\\,=\\,(S,\\mathcal{A},P_{\\mathrm{1at}},R_{\\mathrm{1at}},H)$ such that there is a known state abstraction function $\\zeta_{\\mathrm{lat}}:{\\cal S}\\rightarrow{\\cal\\mathcal{Z}}$ such that $\\zeta_{\\mathrm{lat}}(s)=\\zeta_{\\mathrm{lat}}(s^{\\prime})$ implies that $Q^{M_{\\mathrm{{lat}}},\\star}(s,a)=Q^{M_{\\mathrm{{lat}}},\\star}(s^{\\prime},a)$ for all $a\\in A$ ", "page_idx": 30}, {"type": "text", "text": "\u00b7 Latent complexity comp: We take $\\mathsf{c o m p}(\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta)=\\mathsf{p o l y}(|\\mathcal{Z}|,|\\mathcal{A}|,H,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))$ Which is attainable by the OLIVE algorithm of Jiang et al. [JKALS17]. ", "page_idx": 30}, {"type": "text", "text": "\u00b7 Statistical intractability $({\\pmb X})$ : We take $\\mathcal{M}_{\\mathrm{lat}}=\\{M_{\\mathrm{lat}}\\}$ as the MDP class from the construction of Theorem 3.1. Let $Q_{\\mathrm{1at}}^{\\star}:=Q^{M_{\\mathrm{1at}},\\star}$ Note that we have $\\bar{Q}_{\\mathrm{1at}}^{\\star}(s,a)\\in\\{0,1\\}$ for all $s,a$ , so we can take a latent abstract state space $\\mathcal{Z}=\\{(0,0),(0,1),(1,0),\\tilde{(1,1)}\\}$ and a state abstraction function $\\zeta_{\\mathrm{1}a\\mathrm{t}}$ such that $\\zeta_{\\mathrm{lat}}(s)=(i,\\dot{\\j})$ if $Q_{\\mathrm{1at}}^{\\star}(s,0)=i$ and $Q_{\\mathrm{1at}}^{\\star}(s,1)=j$ . This satisfies the property of a $Q^{\\star}$ irrelevant abstraction, since $\\zeta_{\\mathrm{1at}}(s)=\\zeta_{\\mathrm{1at}}(s^{\\prime})=(i,j)$ implies that $Q_{\\mathrm{1at}}^{\\star}(s,0)\\bar{=}\\bar{Q_{\\mathrm{1at}}^{\\star}}(s^{\\prime},0)=i$ and $Q_{\\mathrm{1at}}^{\\star}(s,1)=Q_{\\mathrm{1at}}^{\\star}(s^{\\prime},1)=j$ . This has a constant-sized abstract space ( $|\\mathcal{Z}|=4,$ and $|{\\mathcal{A}}|=2$ so Theorem 3.1 precludes statistical modularity with complexity comp. ", "page_idx": 30}, {"type": "text", "text": "Linear Mixture MDP $(\\pmb{x})$ ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\mathrm{1at}}$ : MDPs $M_{\\mathrm{{lat}}}=(S,\\mathcal{A},P_{\\mathrm{{lat}}},R_{\\mathrm{{lat}}},H)$ such that there is a known feature map $\\zeta_{\\mathrm{lat}}=\\{\\zeta_{\\mathrm{lat},h}:s^{\\prime},s,a\\mapsto\\mathbb{R}^{d}\\}_{h=1}^{H}$ such that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\forall h\\in[H],\\exists\\theta_{h}\\in\\mathbb{R}^{d}:\\quad P_{\\mathrm{lat},h}(s^{\\prime}\\mid s,a)=\\langle\\zeta_{\\mathrm{lat},h}(s^{\\prime}\\mid s,a),\\theta_{h}\\rangle\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "\u00b7 Latent complexity comp: We take comp $(\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta)=\\mathsf{p o l y}(d,H,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))$ , which is attainable by the UCRL- $\\mathrm{VTR}^{+}$ algorithm of Zhou et al. [ZGS21] ", "page_idx": 31}, {"type": "text", "text": "\u00b7 Statistical intractability $(\\pmb{X})$ : We take $\\mathcal{M}_{\\mathrm{lat}}=\\{M_{\\mathrm{lat}}\\}$ to be the construction of Theorem 3.1. Here, there is a single latent model, so this is trivially embeddable with $\\zeta_{\\mathrm{lat},h}(s^{\\prime}\\mid s,a)=P_{\\mathrm{lat},h}^{\\star}(s^{\\prime}\\mid$ $s,a)\\,\\in\\,\\mathbb{R}^{1}$ . This has dimension $d\\,=\\,1$ , so Theorem 3.1 precludes statistical modularity with complexity comp. ", "page_idx": 31}, {"type": "text", "text": "Linear $Q^{\\star}/V^{\\star}\\left(x\\right)$ ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\mathrm{{lat}}}$ : MDPs $M_{\\mathrm{1at}}\\:=\\:(S,\\mathcal{A},P_{\\mathrm{1at}},R_{\\mathrm{1at}},H)$ such that there are known features maps $\\alpha_{\\mathrm{lat}}\\,:\\,S\\,\\times\\,A\\,\\to\\,\\mathbb{R}^{d}$ and $\\beta_{\\mathrm{1at}}\\,:\\,S\\,\\rightarrow\\,\\mathbb{R}^{d}$ such that for all $M_{\\mathrm{1at}}\\,\\in\\,\\mathcal{M}_{\\mathrm{1at}}$ , there exists unknown parameters $\\theta_{Q},\\theta_{V}\\in\\mathbb{R}^{d}$ such that $Q^{M_{\\mathrm{1at}},\\star}(s,a)\\,=\\,\\langle\\alpha_{\\mathrm{1at}}(s,a),\\theta_{Q}\\rangle$ and $V^{M_{\\mathrm{1at}},\\star}(s)=$ $\\langle\\beta_{\\mathrm{lat}}(s),\\theta_{V}\\rangle$ ", "page_idx": 31}, {"type": "text", "text": "\u00b7 Latent complexity comp: We take $\\mathsf{c o m p}(\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta)=\\mathsf{p o l y}(d,H,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))$ , which is attainable by the BILIN-UCB algorithm of Du et al. $[\\mathrm{Du}+21]$ ", "page_idx": 31}, {"type": "text", "text": "\u00b7 Statistical intractability $(\\pmb{X})$ : We can take $\\mathcal{M}_{\\mathrm{{lat}}}$ to be the latent MDP class from the construction of Theorem 3.1. Since there is a single latent model, this is trivially embeddable with dimension 1, i.e. we can take $\\zeta_{\\mathrm{lat}}(s,a)=Q_{\\mathrm{lat}}^{\\star}\\bar{(s,a)}$ and $\\beta_{\\mathrm{1at}}(s)=V_{\\mathrm{1at}}^{\\star}(s)$ . This has dimension $d=1$ Theorem 3.1 precludes statistical modularity with complexity comp. ", "page_idx": 31}, {"type": "text", "text": "Low State or State-Action Occupancy $(\\forall\\,\\pi_{M}:M\\in\\mathcal{M})\\,(\\pmb{X})$ ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\mathrm{1at}}\\colon$ In the Low State Occupancy model, $\\mathcal{M}_{\\sf{l a t}}=\\left\\{M_{\\sf{l a t}}=(S,\\mathcal{A},P_{\\sf{l a t}},R_{\\sf{l a t}},H)\\right\\}$ isasetofMP such hat hereexisafeaturemapt =lat,R h=1 such that for all $\\pi\\in\\{\\pi_{M_{1a t}}\\mid M_{1a t}\\in\\mathcal{M}_{\\mathrm{lat}}\\}$ and for all $M_{\\mathrm{{lat}}}\\in\\mathcal{M}_{\\mathrm{{lat}}}$ , we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\forall h\\in[H]\\ \\exists\\theta_{h}^{M_{\\mathrm{lat}},\\pi}:\\quad d_{h}^{M_{\\mathrm{lat}},\\pi}(s)=\\Big\\langle\\zeta_{\\mathrm{lat},h}^{V}(s),\\theta_{h}^{M_{\\mathrm{lat}},\\pi}\\Big\\rangle.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "For the State-Action Occupancy model, we have that there exists a feature map $\\begin{array}{r l}{\\zeta_{\\mathrm{1at}}^{Q}}&{{}=}\\end{array}$ {Slat,h:SxA \u2192Rd)#= such that for all $\\pi\\;\\in\\;\\{\\pi_{M_{1a t}}\\;\\mid\\;M_{1a t}\\;\\in\\;\\mathcal{M}_{1a t}\\}$ and for all $M_{\\mathrm{lat}}~\\in$ $\\mathcal{M}_{\\mathrm{{lat}}}$ ,wehave ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\forall h\\in[H]\\ \\exists\\theta_{h}^{M_{\\mathrm{lat}},\\pi}:\\quad d_{h}^{M_{\\mathrm{lat}},\\pi}(s,a)=\\Big\\langle\\zeta_{\\mathrm{lat},h}^{Q}(s,a),\\theta_{h}^{M_{\\mathrm{lat}},\\pi}\\Big\\rangle.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Note that the feature map does not need to be known in either case. ", "page_idx": 31}, {"type": "text", "text": "\u00b7 Latent complexity comp: We take comp $\\begin{array}{r}{\\mathfrak{I}(\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta)=\\mathsf{p o l y}(d,|A|,H,\\log|\\mathcal{F}_{\\mathrm{1at}}|,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))}\\end{array}$ for the state occupancy case and comp( $\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta)=\\mathsf{p o l y}(d,H,\\log|\\mathcal{M}_{\\mathrm{1at}}|,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))$ Both are attainable by the BILIN-UCB algorithm of Du et al., since i) MDPs with this property have Bilinear rank bounded by $d|\\mathcal{A}|$ and $d$ respectively (see Definition 4.3 and Lemma 4.6 of $[\\mathrm{Du}+21]$ \uff0c and i) one can construct the value function class $\\mathcal{F}_{\\mathrm{lat}}\\,=\\,\\{Q^{M_{\\mathrm{lat}},\\star}\\mid M_{\\mathrm{lat}}\\,\\in\\,\\mathcal{M}_{\\mathrm{lat}}\\}$ which is realizable and has size $\\log\\lvert\\mathcal{F}_{\\mathrm{lat}}\\rvert=\\log\\lvert\\mathcal{M}_{\\mathrm{lat}}\\rvert$ ", "page_idx": 31}, {"type": "text", "text": "\u00b7 Intractability: We can take the construction of Theorem 3.1, which has $|\\mathcal{M}_{\\mathrm{1at}}|=1$ and thus is trivially embeddable with dimension 1, i. we can take $\\zeta_{\\mathrm{lat}}^{V}(s)=d^{M_{\\mathrm{lat}},\\pi_{M_{\\mathrm{lat}}}}(s)$ and $\\zeta_{\\mathrm{lat}}^{Q}(s,a)=$ $d^{M_{\\mathrm{lat}},\\pi_{M_{\\mathrm{lat}}}}(s,a)$ ", "page_idx": 31}, {"type": "text", "text": "Bisimulation (?) ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\mathrm{1at}}$ : MDPs $M_{\\mathrm{{lat}}}=(S,\\mathcal{A},P_{\\mathrm{{lat}}},R_{\\mathrm{{lat}}},H)$ such that there is a known state abstraction function $\\zeta_{\\mathrm{lat}}:{\\cal S}\\to{\\mathcal Z}$ such that $\\zeta_{\\mathrm{1at}}(s)\\,=\\,\\zeta_{\\mathrm{1at}}(\\widetilde{s})$ implies that $R_{\\mathrm{1at}}(s,a)\\rightharpoonup R_{\\mathrm{1at}}(\\widetilde{s},a)$ for all $a\\in{\\mathcal{A}}$ as well as $\\begin{array}{r}{\\sum_{s^{\\prime}:\\zeta_{\\mathrm{lat}}(s^{\\prime})=z^{\\prime}}P_{\\mathrm{lat}}(s^{\\prime}\\mid s,a)=\\sum_{s^{\\prime}:\\zeta_{\\mathrm{lat}}(s^{\\prime})=z^{\\prime}}P_{\\mathrm{lat}}(s^{\\prime}\\mid\\widetilde{s},a)}\\end{array}$ for all $z^{\\prime}$ ", "page_idx": 31}, {"type": "text", "text": "\u00b7 Latent complexity comp: We take comp $)(\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta)=\\mathsf{p o l y}(|\\mathcal{Z}|,|\\mathcal{A}|,H,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))$ which is attainable by the OLIVE algorithm of [JKALS17]. ", "page_idx": 32}, {"type": "text", "text": "\u00b7 Openness (?): A negative result does not follow from existing constructions, since the dynamics from the tree-based construction of Theorem 3.1 are not bisimilar unless $|{\\mathcal{Z}}|=|S|$ which allowsfor the application of tabular methods. At the same time, a positive result does not foilow from existing methods, since it is non-trivial to extend existing Block MDP methods to use the bisimulation state abstraction in a way that only pays for $|\\mathcal{Z}|$ ", "page_idx": 32}, {"type": "text", "text": "Low State-Action Occupancy $\\operatorname{\\mathrm{(}}\\forall\\pi:S\\to\\Delta(A))\\operatorname{\\mathrm{(}}?^{\\star})$ ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\mathrm{{lat}}}$ $\\mathcal{M}_{\\sf{l a t}}\\,=\\,\\left\\{M_{\\sf{l a t}}\\,=\\,(S,A,P_{\\mathrm{lat}},R_{\\mathrm{lat}},H)\\right\\}$ is a set of MDPs such that there exists a feature map Siat ={Siath:SxA\u2192R)H such that for all $\\pi:S\\to\\Delta(A)$ and for all $M_{\\mathrm{{lat}}}\\in\\mathcal{M}_{\\mathrm{{lat}}}$ , we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\forall h\\in[H]\\ \\exists\\theta_{h}^{M_{\\mathrm{lat}},\\pi}:\\quad d_{h}^{M_{\\mathrm{lat}},\\pi}(s,a)=\\Big\\langle\\zeta_{\\mathrm{lat},h}^{Q}(s,a),\\theta_{h}^{M_{\\mathrm{lat}},\\pi}\\Big\\rangle.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Note that the feature map does not need to be known. ", "page_idx": 32}, {"type": "text", "text": "\u00b7 We take con $\\begin{array}{r}{\\mathfrak{P}(\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta)\\,=\\,\\mathsf{p o l y}(d,H,\\log|\\mathcal{M}_{\\mathrm{1at}}|,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))}\\end{array}$ , which is attainable by the BILIN-UcB algorithm of Du et al., since i) MDPs with this property have Bilinear rank bounded by $d$ (see Definition 4.3 and Lemma 4.6 of $[\\mathrm{Du}+21]$ ), and i) one can construct a realizable value function class of size $\\log\\!|\\mathcal{F}|=\\log\\!|\\mathcal{M}|$ ", "page_idx": 32}, {"type": "text", "text": "\u00b7 Openness (?): A negative result does not follow from existing constructions, since the dynamics from the tree-based construction of Theorem 3.1 do not have linear occupancies for all $\\pi:{\\mathcal{S}}\\rightarrow$ $\\Delta(A)$ unless $d=|S|$ , which allows for the application of tabular methods, and the dynamics from the bandit-based construction Theorem E.1 do not have linear occupancies for all $\\dot{\\pi}:S\\rightarrow\\Delta(A)$ unles $d=|\\mathcal{A}|$ . At the same time, unlike the low state occupancy case, a positive result does not follow as it is unclear if we can express the observation-space occupancies linearly. ", "page_idx": 32}, {"type": "text", "text": "\u00b7 Statistical tractability with additional (suboptimal) $|{\\mathcal{A}}|$ -dependence $(\\checkmark)$ : Note that we can reduce to the Low State Occupancy case $(\\checkmark)$ ,since ", "page_idx": 32}, {"type": "equation", "text": "$$\nd^{\\pi}(s)=\\sum_{a\\in\\mathcal{A}}d^{\\pi}(s,a)=\\left\\langle\\theta^{\\pi},\\sum_{a\\in\\mathcal{A}}\\zeta_{\\mathrm{lat}}^{Q}(s,a)\\right\\rangle:=\\left\\langle\\theta^{\\pi},\\zeta_{\\mathrm{lat}}^{V}(s)\\right\\rangle\\!.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "However, this blows up the feature norm bound of the feature map $\\zeta_{\\mathrm{lat}}^{V}(s)$ by a factor of $|{\\mathcal{A}}|$ which will appear logarithmically in the bound obtained by BILIN-UCB. ", "page_idx": 32}, {"type": "text", "text": "Model class $^+$ Coverability $(\\forall\\,\\pi:S\\rightarrow\\Delta(A))$ (?). ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "\u00b7 Latent class $\\mathcal{M}_{\\mathrm{{lat}}}$ $\\mathcal{M}_{\\sf{l a t}}\\,=\\,\\left\\{M_{\\sf{l a t}}=(S,\\mathcal{A},P_{\\mathrm{lat}},R_{\\mathrm{{lat}}},H)\\right\\}$ is a set of MDPs that all satisfy coverability with respect to all policies $\\pi_{\\mathrm{lat}}:S\\to\\Delta(A)$ , i.e. we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\forall M_{\\mathrm{{lat}}}\\in\\mathcal{M}_{\\mathrm{{lat}}}:\\quad C_{\\mathrm{cov}}(M_{\\mathrm{{lat}}})=\\operatorname*{inf}_{\\mu_{h}\\in\\Delta(S\\times A)}\\operatorname*{sup}_{h\\in[H]}\\operatorname*{sup}_{\\pi:S\\to\\Delta(A)}\\Bigl|\\left|\\frac{d_{h}^{M_{\\mathrm{{lat}}},\\pi}}{\\mu_{h}}\\right|\\Bigr|_{\\infty}<\\infty\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "\u00b7 Latent complexity comp: We take co $\\begin{array}{r}{\\mathsf{m p}(\\mathcal{M}_{\\sf1a t},\\varepsilon,\\delta)=\\mathsf{p o l y}(C_{\\mathsf{c o v}},H,\\log|\\mathcal{M}_{\\sf1a t}|,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr))}\\end{array}$ which is attainable by the GoLF algorithm via the results of Xie, Foster, Bai, Jiang, and Kakade (see also Lemma F.3). We obtain this by noting that a realizable model class can be used to construct a realizable value function class $\\mathcal{F}$ and a complete value function class $\\mathcal{G}$ of sizes $\\log\\!|\\mathcal{F}|=\\log|\\mathcal{M}|$ and $\\log\\vert\\mathcal{G}\\vert=\\mathcal{O}(\\log\\vert\\mathcal{M}\\vert)$ ", "page_idx": 32}, {"type": "text", "text": "\u00b7 Openness (?): A negative result does not follow from the existing constructions. The tree-based construction of Theorem 3.1 satisfies coverability with $C_{\\mathsf{c o v}}=\\exp(\\Omega(H))$ and the bandit-based construction of Theorem E.1 satisfies coverability with $C_{\\mathsf{c o v}}=|\\boldsymbol{A}|$ . In both cases,the lower bounds cannot be used to rule out statistical modularity with the above latent complexity. Similarly, it unclear how to obtain a positive result for the latent-dynamics class $\\langle\\!\\langle M_{\\mathrm{{lat}}},{\\bar{\\Phi}}\\rangle\\!\\rangle$ ", "page_idx": 32}, {"type": "text", "text": "E.3 Proofs for Lower Bounds (Theorems 3.1 and E.1) ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "E.3.1 Main lower bound (Theorem 3.1) ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "We will prove the following result. ", "page_idx": 33}, {"type": "text", "text": "Theorem 3.1 (Impossibility of statistical modularity). For every $N\\geq4,$ there exists a decoder class $\\Phi$ with $|\\Phi|=N$ and afamily of baseMDPs $\\mathcal{M}_{\\mathrm{{lat}}}$ satisfying (i) $|\\mathcal{M}_{\\mathrm{{lat}}}|=1$ (ii) $H\\leq O(\\log(N))$ (iii) $|S|=|\\mathcal{X}|\\le N^{2}$ \uff0c $(i\\nu,$ $|{\\mathcal{A}}|=2$ andsuchthat ", "page_idx": 33}, {"type": "text", "text": "1. For all $\\varepsilon,\\delta>0$ we have comp $(\\mathcal{M}_{\\sf l a t},\\varepsilon,\\delta)=0.$ ", "page_idx": 33}, {"type": "text", "text": "2.For an absoluteconstant $c>0$ $\\begin{array}{r}{\\mathsf{\\Pi}_{\\mathsf{C O m p}}(\\langle\\!\\langle\\mathcal{M}_{\\mathrm{1at}},\\Phi\\rangle\\!\\rangle,c,c)\\ge\\Omega(N/\\log(N)).}\\end{array}$ ", "page_idx": 33}, {"type": "text", "text": "Proof. Let $N$ be given and assume without loss of generality that it is a power of 2. We first construct the class of latent-dynamics MDPs, following Song et al. [SWFK24]. ", "page_idx": 33}, {"type": "text", "text": "Latent MDP. The construction has a single \u201cknown\" latent MDP $M_{\\mathrm{lat}}$ , so that the only uncertainty in the family of latent-dynamics MDPs we construct arises from the emission processes. We set $\\mathcal{M}_{\\mathrm{lat}}\\,=\\,\\{\\dot{M}_{\\mathrm{lat}}\\}$ .Set $\\dot{H}=\\log_{2}(N)+1$ and ${\\cal A}=\\left\\{0,1\\right\\}$ . We define the state space and latent transition dynamics as follows. ", "page_idx": 33}, {"type": "text", "text": "\u00b7 The state space can be partitioned as $S=S^{1},\\ldots,S^{N}$ \u00b7 Each block $S^{i}$ corresponds to a standard depth- $\\mathcal{H}$ binary tree MDP with deterministic dynamics (e.g., Osband et al.; Domingues et al. [OVR16; DMKV21]). There is a single \u201croot' node at layer $h=1$ whiehwedenoeby $s_{\\mathrm{root}}^{i}$ Cand $N$ \"lea'nodes alayer $H$ Whieh we denoteby $\\left\\{s_{\\mathsf{l e a f}}^{i,j}\\right\\}_{j\\in[N]}$ For each $h\\,=\\,1,\\ldots,H\\,-\\,1$ , choosing action 0 leads to the left successor of the current state deterministically, and choosing action 1 leads to the right sucessor; this process continues until we reach a leaf node at layer $H$ ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "\u00b7The initalstate distributionisPat, () =Unif(sot t. ", "page_idx": 33}, {"type": "text", "text": "\u00b7 There are no rewards for layers $1,\\cdot\\cdot,H-1$ . For layer $H$ , the reward is ", "page_idx": 33}, {"type": "equation", "text": "$$\nR_{H}(s_{\\mathsf{l e a f}}^{i,j},\\cdot)=\\mathbb{I}\\{j=i\\}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "This construction can summarized as follows. At layer 1, we draw the index of one of $N$ binary trees uniformly at random, and initialize into the root of the tree. From here, we receive a reward of 1 if we successfully navigate to the leaf node whose index agrees with the index of the tree itself, and receive a reward of O otherwise. ", "page_idx": 33}, {"type": "text", "text": "Note that the total number of latent states in this construction is $|S|=N\\cdot|S_{1}|=N(2N-1)$ ", "page_idx": 33}, {"type": "text", "text": "Observation space and decoder class. Let us introduce some additional notation. For each block $S^{i}$ let $\\begin{array}{r}{S_{h}^{i}:=\\{s_{h}^{i,j}\\}_{j\\in[2^{h-1}]}}\\end{array}$ denote the states in block $i$ that are reachable at layer $h$ othat $S_{1}^{i}=\\left\\{s_{\\mathrm{root}}^{i}\\right\\}$ and $\\begin{array}{r}{S_{H}^{i}=\\{s_{\\mathrm{leaf}}^{i,j}\\}_{j\\in[N]}}\\end{array}$ Wedefine $\\mathcal{X}=\\mathcal{S}$ so that $|\\mathcal{X}|\\le4N^{2}$ , and consider a class of emission processes corresponding to deterministic maps. Let $\\Sigma$ denote the set of cyclic permutations on $N$ elements, excluding the identity permutation. That is, each $\\sigma_{i}\\in\\Sigma$ takes the form ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\sigma_{i}:k\\mapsto k+i\\mod N\\;\\;\\;\\;{\\mathrm{for~}}i\\in\\{1,\\ldots,N\\}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "For each $\\sigma\\in\\Sigma$ , we consider the emission process ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\psi_{h}^{\\sigma}\\big(\\cdot\\mid s_{h}^{(i,j)}\\big)=\\mathbb{I}_{s_{h}^{(\\sigma(i),j)}}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "That is,  shifts the index of the binary tree containing s according to $\\sigma$ . Let $\\Psi=\\{\\psi^{\\sigma}\\mid\\sigma\\in\\Sigma\\}$ Consider the decoder class ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\Phi=\\Psi^{-1}:=\\{s^{i}\\mapsto s^{\\psi^{-1}(i)}\\mid\\psi\\in\\Psi\\},\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "which has $|\\Phi|=N$ . We consider the class of rich-observation MDPs given by ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\langle\\!\\left\\langle\\mathcal{M}_{\\mathrm{1at}},\\Phi\\right\\rangle\\!\\rangle:=\\left\\{M^{i}:=\\left\\langle\\!\\left\\langle M_{\\mathrm{1at}},\\psi^{\\sigma_{i}}\\right\\rangle\\!\\right\\rangle\\mid\\sigma_{i}\\in\\Sigma\\right\\}\\!.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "It is clear that this class of rich-observation MDPs satisfies the decodability assumption for emissions $\\Psi$ ", "page_idx": 33}, {"type": "text", "text": "Sample complexity lower bound._ To lower bound the sample complexity, we prove a lower bound on the constrained PAC Decision-Estimation Coeffcient (DEC) of [FGH23]. For an arbitrary MDP $\\overline{{M}}$ (defined over the space $\\mathcal{X}$ and $\\varepsilon\\in[0,2^{1/2}]$ ,define1l8 ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathsf{d e c}_{\\varepsilon}(\\mathcal M,\\overline{M})=\\operatorname*{inf}_{\\substack{p,q\\in\\Delta(\\Pi)\\,M\\in\\mathcal M}}\\left\\{\\mathbb E_{\\pi\\sim p}[J^{M}(\\pi_{M})-J^{M}(\\pi)]\\mid\\mathbb E_{\\pi\\sim q}\\big[D_{\\mathsf H}^{2}\\big(M(\\pi),\\overline{M}(\\pi)\\big)\\big]\\leq\\varepsilon^{2}\\right\\},\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $M(\\pi)$ denotes the law over trajectories $(x_{1},a_{1},r_{1}),\\dots,(x_{H},a_{H},r_{H})$ induced by executing the policy $\\pi$ in the MDP $M$ $J^{M}(\\pi)$ denotes the expected reward for policy $\\pi$ under $M$ , and $\\pi_{M}$ denotes the optimal policy for $M$ . We further define ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathsf{d e c}_{\\varepsilon}(\\mathcal M)=\\operatorname*{sup}_{\\overline{{M}}}\\mathsf{d e c}_{\\varepsilon}(\\mathcal M,\\overline{{M}}),\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where the supremum ranges over all MDPs defined over $\\mathcal{X}$ and $\\boldsymbol{\\mathcal{A}}$ . We now appeal to the following technical lemma. ", "page_idx": 34}, {"type": "text", "text": "Lemma E.1. For all $\\varepsilon^{2}\\geq4/N$ we have that $\\mathsf{d e c}_{\\varepsilon}(\\langle\\!\\langle\\mathcal{M}_{\\mathrm{lat}},\\Phi\\rangle\\!\\rangle)\\geq\\frac12$ ", "page_idx": 34}, {"type": "text", "text": "In light of Lemma E.1, it follows from Theorem 2.1 in Foster et al. $[\\mathrm{FGH}23]^{19}$ that any PAC RL algorithm that uses $T$ episodes of interaction for $T\\log(T)\\leq c{\\cdot}N$ must have $\\mathbb{E}[J^{M}(\\pi_{M})-\\dot{J}^{M}(\\widehat{\\pi})]\\geq$ $c^{\\prime}$ for a worst-case MDP in $\\mathcal{M}$ , where $c,c^{\\prime}>0$ are absolute constants. This implies that any PAC RL which has $\\mathbb{E}[J^{M}(\\pi_{M})-J^{M}(\\widehat{\\pi})]\\leq c^{\\prime}$ must have $T\\log(T)\\geq c\\cdot N$ and thus $\\bar{T}\\geq c\\cdot N/\\log(N)$ ", "page_idx": 34}, {"type": "text", "text": "Proof of Lemma E.1. Define $\\overline{{M}}_{\\mathrm{1at}}$ as the latent-space MDP that has identical dynamics to $M_{\\mathrm{lat}}$ but, has zero reward in every state, and define $\\overline{{M}}:=\\langle\\!\\langle\\overline{{M}}_{\\mathrm{1at}},\\mathrm{id}\\rangle\\!\\rangle$ as the rich-observation MDP obtained by composing $\\overline{{M}}_{\\mathrm{1at}}$ with the \u201cidentity\u201d' emission process id that sets $x_{h}=s_{h}$ . Observe that $\\overline{{M}}$ and ${\\dot{M}}^{i}$ , induce identical dynamics in observation space if rewards are ignored: For all policies $\\pi$ \uff0c ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathbb{P}^{\\overline{{M}},\\pi}[(x_{1},a_{1}),\\cdot\\,\\cdot\\,,(x_{H},a_{H})=\\cdot]=\\mathbb{P}^{M^{i},\\pi}[(x_{1},a_{1}),\\cdot\\,\\cdot\\,,(x_{H},a_{H})=\\cdot].\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "It follows that for each $i$ , for all policies $\\pi$ , we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D_{k}^{\\ast}(M^{i}(\\pi),\\bar{M}(\\pi))}\\\\ &{=D_{k}^{\\top}\\big(([M_{\\mathrm{Ltt}},\\psi_{i}])(\\pi),(\\{\\sqrt[\\alpha]{M_{\\mathrm{Ltt}}},\\mathrm{id}\\})\\big)(\\pi)}\\\\ &{=\\displaystyle\\sum_{j=1}^{N}\\mathbf{p}^{\\top}\\pi^{\\top}\\big[x_{H}=s_{\\mathrm{baf}}^{(\\nu_{i},\\bar{\\pi}),j}\\big]\\cdot D_{k}^{\\top}(\\bar{\\mathbf{I}}_{1},\\bar{\\mathbf{I}}_{0})}\\\\ &{=2\\displaystyle\\sum_{j=1}^{N}\\mathbf{p}^{\\top\\pi}\\mathbf{\\cdot}[x_{H}=s_{\\mathrm{baf}}^{(\\nu_{i},\\bar{\\pi}),j}]}\\\\ &{=\\displaystyle\\frac{2}{N}\\displaystyle\\sum_{j=1}^{N}\\mathbf{p}^{\\top,\\pi}[x_{H}=s_{\\mathrm{baf}}^{(\\nu_{i},\\bar{\\pi}),j}]\\:\\pi_{1}=s_{\\mathrm{baf}}^{(\\nu_{i},\\bar{\\pi})}\\Big],}\\\\ &{=\\displaystyle\\frac{2}{N}\\sum_{j=1}^{N}\\mathbf{p}^{\\top\\pi}\\mathbf{\\cdot}\\left[x_{H}=s_{\\mathrm{baf}}^{(\\nu_{i},\\bar{\\pi}),(\\nu)}\\mid x_{1}=s_{\\mathrm{baf}}^{(\\nu_{i},\\bar{\\pi})}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "since the learner receives identical feedback in the MDPs $M^{i}$ and $\\overline{{M}}$ unless they reach the observation $x_{H}=s_{\\mathrm{|eaf}}^{(\\psi_{i}(j),j)}$ forsome $j$ Ceorresponding t latentstate $s_{\\mathrm{leaf}}^{(j,j)}$ $M^{i}$   \nreward 1 in $M^{i}$ but reward O in . We now claim that for any $q\\in\\Delta(\\Pi)$ , there exists a set of at least $N/2$ indices $\\mathcal{T}_{q}\\subset[N]$ such that ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\pi\\sim q}\\big[D_{\\mathsf{H}}^{2}\\big(M^{i}(\\pi),\\overline{{M}}(\\pi)\\big)\\big]\\leq\\frac{4}{N}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "for all $i\\in\\mathcal{Z}_{q}$ . To see this, note that by Eq. (21), we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathfrak{L}_{i\\sim\\operatorname{slnif}([N])}\\mathbb{E}_{\\pi\\sim q}\\left[D_{\\mathsf{H}}^{2}\\big(M^{i}(\\pi),\\overline{{M}}(\\pi)\\big)\\right]\\le\\mathbb{E}_{\\pi\\sim q}\\left[\\displaystyle\\frac{2}{N}\\sum_{j=1}^{N}\\frac{1}{N}\\sum_{i=1}^{N}\\mathbb{P}^{\\pi,\\pi}\\Big[x_{H}=s_{\\mathsf{l e a f}}^{(j,\\psi_{i}^{-1}(j))}\\mid x_{1}=s_{\\mathsf{r o o t}}^{(j)}\\Big]\\right.}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\left.\\le\\mathbb{E}_{\\pi\\sim q}\\left[\\displaystyle\\frac{2}{N}\\sum_{j=1}^{N}\\frac{1}{N}\\right]=\\displaystyle\\frac{2}{N},}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where th seond inequaltyuss that $\\begin{array}{r}{\\sum_{i=1}^{N}\\mathbb{P}^{\\overline{{M}},\\pi}\\Big[x_{H}=s_{\\mathsf{l e a f}}^{(j,\\psi_{i}^{-1}(j))}\\mid x_{1}=s_{\\mathsf{r o o t}}^{(j)}\\Big]\\le1.}\\end{array}$ in the sum are mutually exclusive (and the event we condition on does not depend on $i$ ). We conclude by Markov's inequality that $\\mathbb{P}_{i\\sim\\mathsf{U n i f}([N])}\\left[\\mathbb{E}_{\\pi\\sim q}\\big[D_{\\mathsf{H}}^{2}\\big(M^{i}(\\pi),\\overline{{M}}(\\pi)\\big)\\big]\\geq4/\\bar{N}\\right]\\leq1/2$ , giving $\\mathcal{Z}_{q}\\geq$ $N/2$ ", "page_idx": 35}, {"type": "text", "text": "From Eq. (26), we conclude that for all $\\varepsilon^{2}\\geq4/N$ \uff0c ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathsf{d e c}_{\\varepsilon}({\\mathcal M},\\overline{{M}})\\geq\\operatorname*{inf}_{q\\in{\\Delta}(\\Pi)}\\operatorname*{inf}_{p\\in{\\Delta}(\\Pi)}\\operatorname*{sup}_{i\\in{\\mathcal{I}}_{q}}\\Big\\{\\mathbb{E}_{\\pi\\sim p}\\Big[J^{M^{i}}\\big(\\pi_{M^{i}}\\big)-J^{M^{i}}(\\pi)\\Big]\\Big\\}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "To lower bound this quantity, observe that for any index $i$ and any policy $\\pi$ wehave ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{c c l}{\\displaystyle J^{M^{i}}(\\pi_{M^{i}})-J^{M^{i}}(\\pi)=\\frac{1}{N}\\sum_{j=1}^{N}{\\mathbb P}^{M^{i}),\\pi}\\left[x_{H}\\neq s_{\\mathrm{leaf}}^{(\\psi_{i}(j),j)}\\;\\middle|\\;x_{1}=s_{\\mathrm{rot}}^{(\\psi_{i}(j))}\\right]}\\\\ {\\displaystyle}&{\\displaystyle=1-\\frac{1}{N}\\sum_{j=1}^{N}{\\mathbb P}^{M^{i}),\\pi}\\left[x_{H}=s_{\\mathrm{leaf}}^{(\\psi_{i}(j),j)}\\;\\middle|\\;x_{1}=s_{\\mathrm{rot}}^{(\\psi_{i}(j))}\\right]}\\\\ {\\displaystyle}&{\\displaystyle=1-\\frac{1}{N}\\sum_{j=1}^{N}{\\mathbb P}^{M,\\pi}\\left[x_{H}=s_{\\mathrm{leaf}}^{(\\psi_{i}(j),j)}\\;\\middle|\\;x_{1}=s_{\\mathrm{rot}}^{(\\psi_{i}(j))}\\right]}\\\\ {\\displaystyle}&{\\displaystyle=1-\\frac{1}{N}\\sum_{j=1}^{N}{\\mathbb P}^{M,\\pi}\\left[x_{H}=s_{\\mathrm{leaf}}^{(\\psi_{i},\\psi_{i}^{-1}(j))}\\;\\middle|\\;x_{1}=s_{\\mathrm{rot}}^{(\\psi_{i})}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where the third inequality uses Eq. (19). We conclude that for any distribution $p,q\\in\\Delta(\\Pi)$ ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\operatorname*{sup}_{i\\in\\mathbb{Z}_{q}}\\biggl\\{\\mathbb{E}_{\\pi\\sim p}\\biggl[J^{M^{i}}\\bigl(\\pi_{M^{i}})-J^{M^{i}}(\\pi)\\biggr]\\biggr\\}}\\\\ {\\displaystyle\\geq\\mathbb{E}_{i\\sim\\mathrm{lnif}(\\mathbb{Z}_{q})}\\biggl\\{\\mathbb{E}_{\\pi\\sim p}\\biggl[J^{M^{i}}\\bigl(\\pi_{M^{i}}\\bigr)-J^{M^{i}}(\\pi)\\biggr]\\biggr\\}}\\\\ {\\displaystyle\\geq1-\\frac{1}{N}\\sum_{j=1}^{N}\\mathbb{E}_{i\\sim\\mathrm{lnif}(\\mathbb{Z}_{q})}\\mathbb{P}^{\\overline{{M}},\\pi}\\biggl[x_{H}=s_{\\mathrm{leaf}}^{(j,\\psi_{i}^{-1}(j))}\\mid x_{1}=s_{\\mathrm{root}}^{(j)}\\biggr]}\\\\ {\\displaystyle=1-\\frac{1}{N}\\sum_{j=1}^{N}\\frac{1}{|\\mathbb{Z}_{q}|}\\sum_{i\\in\\mathbb{Z}_{q}}\\mathbb{P}^{\\overline{{M}},\\pi}\\biggl[x_{H}=s_{\\mathrm{leaf}}^{(j,\\psi_{i}^{-1}(j))}\\mid x_{1}=s_{\\mathrm{root}}^{(j)}\\biggr]\\geq1-\\frac{1}{|\\mathbb{Z}_{q}|}\\geq\\frac{1}{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "as longas $N\\ge4$ $j$ thevents $\\left\\{x_{H}=s_{\\mathsf{l e a f}}^{(j,\\psi_{i}^{-1}(j))}\\ \\right\\vert$ $x_{1}=s_{\\mathrm{root}}^{(j)}\\}$ are disjoint for al $i$ Since tiswebounhlsiflyfll $q,p\\in\\Delta(\\Pi)$ we conclude that ", "page_idx": 35}, {"type": "equation", "text": "$$\n{\\sf d e c}_{\\varepsilon}(\\langle\\!\\langle\\mathcal{M}_{\\mathrm{lat}},\\Phi\\rangle\\!\\rangle,\\overline{{M}})\\geq\\frac{1}{2}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "E.3.2 Proof of alternative lower bound (Theorem E.1) ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "We will prove the following result. ", "page_idx": 35}, {"type": "text", "text": "Theorem E.1 (Alternative lower bound). For every $N\\geq4$ there exists an emission class $\\Psi$ and $a$ decoder class $\\Phi$ with $\\vert\\Psi\\vert=\\vert\\Phi\\vert=N$ and $a$ family of latent MDPs $\\mathcal{M}_{\\mathrm{{lat}}}$ satisfying (i) $|\\mathcal{M}_{\\mathrm{{lat}}}|=1$ \uff0c (ii) $H=1$ (ii) $|S|=|{\\mathcal{X}}|=N$ (iv) $|{\\mathcal{A}}|=N$ andsuchthat ", "page_idx": 36}, {"type": "text", "text": "1. For all $\\varepsilon,\\delta>0$ wehavecomp $(\\mathcal{M}_{\\sf l a t},\\varepsilon,\\delta)=0.$   \n2. For an absolute constant $c>0$ $\\mathrm{~\\cdot~}0,\\,\\mathsf{c o m p}(\\langle\\!\\langle M_{\\mathrm{1at}},\\Phi\\rangle\\!\\rangle,c,c)\\geq\\Omega(N/\\log(N)).$ ", "page_idx": 36}, {"type": "text", "text": "Proof of Theorem E.1. We repeat more or less repeat the same proof as Theorem 3.1, but with the appropriate modifications to translate from the contextual tree-based construction in Theorem 3.1 to the contextual bandit-based construction in the theorem statement. Let $N$ begiven and assume without loss of generality that it is a power of 2. ", "page_idx": 36}, {"type": "text", "text": "Latent MDP. Our construction has a single \u201cknown\" latent MDP $M_{\\mathrm{lat}}$ ; that is, the only uncertainty in the family of rich-observation MDPs we construct arises from the emission processes. Set $\\mathcal{M}_{\\mathrm{lat}}=\\{M_{\\mathrm{lat}}\\}$ .Set $H=1$ and $\\boldsymbol{\\mathcal{A}}=[N]$ . We define the state space and latent transition dynamics as follows. ", "page_idx": 36}, {"type": "text", "text": "\u00b7 The state space can be partitioned as $S=S^{1},\\ldots,S^{N}$   \n\u00b7 Each block $S^{i}$ corresponds to a single state $s^{i}$ with $N$ actions denoted by $a^{i}$ $\\mathbf{\\mu}^{i},\\,i\\in[N]$   \n\u00b7 The initial state distribution is $P_{\\mathrm{1at,1}}(\\emptyset)=\\mathsf{U n i f}(s^{1},\\ldots,s^{N}).$   \n\u00b7 The reward function is ", "page_idx": 36}, {"type": "equation", "text": "$$\nR_{1}(s^{i},a^{j})=\\mathbb{I}\\{j=i\\}.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Informally, this construction can summarized as a contextual bandit (with uniform context distribution), with a reward of 1 if and only if we play the action corresponding to the index of the context drawn. ", "page_idx": 36}, {"type": "text", "text": "Note that the total number of latent states in this construction is $|{\\cal S}|={\\cal N}$ and the number of actions $|{\\mathcal{A}}|=N$ ", "page_idx": 36}, {"type": "text", "text": "Observation space and decoder class. We define $\\mathcal{X}=\\mathcal{S}$ so that $|{\\boldsymbol{\\mathcal{X}}}|=|{\\boldsymbol{\\mathcal{S}}}|$ , and consider a class of emission processes corresponding to deterministic maps. Let $\\Sigma$ denote the set of cyclic permutations on $N$ elements, excluding the identity permutation. That is, each $\\sigma_{i}\\in\\Sigma$ takes the form ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\sigma_{i}:k\\mapsto k+i\\mod N,\\quad{\\mathrm{~for~}}i\\in\\{1,\\ldots,N\\}.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "For each $\\sigma\\in\\Sigma$ , we consider the emission process ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\psi^{\\sigma}\\big(\\cdot\\mid s^{i}\\big)=\\mathbb{I}_{s^{\\sigma(i)}}\\big(\\cdot\\big)\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "That is, $\\psi^{\\sigma}$ shifts the context $s^{i}$ according to $\\sigma$ . Let $\\Psi=\\{\\psi^{\\sigma}\\mid\\sigma\\in\\Sigma\\}$ . Consider the decoder class ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\Phi=\\Psi^{-1}:=\\{s^{i}\\mapsto s^{\\psi^{-1}(i)}\\mid\\psi\\in\\Psi\\},\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "which has $|\\Phi|=N$ . We consider the class of rich-observation MDPs given by ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\langle\\!\\left\\langle\\mathcal{M}_{\\mathrm{1at}},\\Phi\\right\\rangle\\!\\rangle:=\\left\\{M^{i}:=\\left\\langle\\!\\left\\langle M_{\\mathrm{1at}},\\psi^{\\sigma_{i}}\\right\\rangle\\!\\right\\rangle\\mid\\sigma_{i}\\in\\Sigma\\right\\}\\!.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "It is clear that this class of rich-observation MDPs satisfies the decodability assumption for emissions $\\Psi$ ", "page_idx": 36}, {"type": "text", "text": "Sample complexity lower bound._ To lower bound the sample complexity, we prove a lower bound on the constrained PAC Decision-Estimation Coefficient (DEC) of [FGH23]. For an arbitrary MDP $\\overline{{M}}$ (defined over the space $\\mathcal{X}$ )and $\\varepsilon\\in[0,2^{1/2}]$ ,define20 ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\mathsf{d e c}_{\\varepsilon}(\\mathcal M,\\overline{M})=\\operatorname*{inf}_{\\substack{p,q\\in\\Delta(\\Pi)\\,M\\in\\mathcal M}}\\left\\{\\mathbb E_{\\pi\\sim p}[J^{M}(\\pi_{M})-J^{M}(\\pi)]\\mid\\mathbb E_{\\pi\\sim q}\\big[D_{\\mathsf H}^{2}\\big(M(\\pi),\\overline{M}(\\pi)\\big)\\big]\\leq\\varepsilon^{2}\\right\\},\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where $M(\\pi)$ denotes the law over observations $(x_{1},a_{1},r_{1})$ induced by executing the policy $\\pi$ in the MDP $M$ $\\dot{J^{M}}(\\pi)$ denotes the expected reward for policy $\\pi$ under $M$ , and $\\pi_{M}$ denotes the optimal policy for $M$ . We further define ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\mathsf{d e c}_{\\varepsilon}(\\mathcal M)=\\operatorname*{sup}_{\\overline{{M}}}\\mathsf{d e c}_{\\varepsilon}(\\mathcal M,\\overline{{M}}),\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where the supremum ranges over all MDPs defined over $\\mathcal{X}$ and $\\boldsymbol{\\mathcal{A}}$ . We now appeal to the following technical lemma. ", "page_idx": 36}, {"type": "text", "text": "Lemma E.2. For all $\\varepsilon^{2}\\geq4/N$ we have that $\\mathrm{sup}_{\\overline{{M}}}\\,\\mathsf{d e c}_{\\varepsilon}({\\mathcal{M}},\\overline{{M}})\\geq\\frac12$ In light of Lemma E.2, it follows from Theorem 2.1 in Foster et al. $[\\mathrm{FGH}23]^{21}$ that any PAC RL algorithm that uses $T$ episodes of interaction for $T\\log(T)\\leq c\\cdot N$ must have $\\mathbb{E}[J^{M}(\\pi_{M})-J^{M}(\\widehat{\\pi})]\\geq c^{\\prime}$ for a worst-case MDP in $\\mathcal{M}$ , where $c$ $c^{\\prime}>0$ are absolute constants. This implies that any PAC RL which has $\\mathbb{E}[J^{M}(\\pi_{M})-J^{M}(\\widehat{\\pi})]\\leq c^{\\prime}$ must have $T\\log(T)\\geq c\\cdot N$ and thus $\\bar{T}\\geq c\\cdot N/\\log(N)$ .\u53e3 ", "page_idx": 37}, {"type": "text", "text": "", "page_idx": 37}, {"type": "text", "text": "Proof of Lemma E.2. Define $\\overline{{M}}_{\\mathrm{1at}}$ as the latent-space MDP that has identical dynamics to $M_{\\mathrm{1at}}$ but, has zero reward for every state-action pair, and define $\\overline{{M}}:=\\langle\\!\\langle\\overline{{M}}_{\\mathrm{1at}},\\mathrm{id}\\rangle\\!\\rangle$ as the rich-observation MDP obtained by composing $\\overline{{M}}_{\\mathrm{1at}}$ with the identity emission process that sets $x_{h}=s_{h}$ . In the rest of the proof, we use the shorthand $\\psi_{i}:=\\psi^{\\sigma_{i}}$ . Observe that $\\overline{{M}}$ and $M^{i}$ , induce identical dynamics in observation space if rewards are ignored, i.e. for all policies $\\pi:{\\mathcal{X}}\\rightarrow\\Delta(A)$ ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\mathbb{P}^{\\overline{{M}},\\pi}[(x_{1},a_{1})=\\cdot]=\\mathbb{P}^{M^{i},\\pi}[(x_{1},a_{1})=\\cdot].\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "It follows that for each $i$ , for all policies $\\pi$ , we have ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D_{q}^{2}\\big(M^{\\dagger}(\\pi),\\bar{M}(\\pi)\\big)}\\\\ &{=D_{q}^{2}\\big((\\mathcal{G}[M_{1:\\mathbf{u}},\\psi_{\\hat{t}}])(\\pi),(\\{\\overline{{M_{1:\\mathbf{u}}}}\\}\\theta)\\big)(\\pi)}\\\\ &{=\\displaystyle\\sum_{j=1}^{N}\\mathbb{P}^{\\pi,\\pi}\\Big[x_{1}=s^{\\psi_{\\hat{t}}(j)},a_{1}=a^{j}\\Big]\\cdot D_{\\mathbb{N}}^{2}(\\mathbb{I}_{1},\\mathbb{I}_{0})}\\\\ &{=2\\displaystyle\\sum_{j=1}^{N}\\mathbb{P}^{\\pi,\\pi}\\Big[x_{1}=s^{\\psi_{\\hat{t}}(j)},a_{1}=a^{j}\\Big]}\\\\ &{=\\displaystyle\\frac{2}{N}\\sum_{j=1}^{N}\\mathbb{P}^{\\pi,\\pi}\\Big[a_{1}=a^{j}\\mid x_{1}=s^{\\psi_{\\hat{t}}(j)}\\Big]}\\\\ &{=\\displaystyle\\frac{2}{N}\\sum_{j=1}^{N}\\mathbb{P}^{\\pi,\\pi}\\Big[a_{1}=a^{\\psi_{\\hat{t}}^{-1}(j)}\\mid x_{1}=s^{j}\\Big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "since the learner receives identical feedback in the MDPs $M^{i}$ and $\\overline{{M}}$ unless they play the action $a_{1}=a^{j}$ given observation $x_{1}=s^{\\psi_{i}(j)}$ (corresponding to latent state $s^{i}$ in $M^{i}$ ), in which case they receiver reward 1 in $M^{i}$ but reward O in $\\overline{{M}}$ . We now claim that for any $q\\in\\Delta(\\Pi)$ , there exists a set of at least $N/2$ indices $\\mathcal{T}_{q}\\subset[N]$ such that ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\pi\\sim q}\\big[D_{\\mathsf{H}}^{2}\\big(M^{i}(\\pi),\\overline{{M}}(\\pi)\\big)\\big]\\leq\\frac{4}{N}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "for all $i\\in\\mathcal{Z}_{q}$ . To see this, note that by Eq. (21), we have ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{E}_{i\\sim\\mathsf{U n i f}([N])}\\mathbb{E}_{\\pi\\sim q}\\big[D_{\\mathsf{H}}^{2}\\big(M^{i}(\\pi),\\overline{{M}}(\\pi)\\big)\\big]\\leq\\mathbb{E}_{\\pi\\sim q}\\left[\\displaystyle\\frac{2}{N}\\sum_{j=1}^{N}\\frac{1}{N}\\sum_{i=1}^{N}\\mathbb{P}^{\\mathtt{M},\\pi}\\Big[a_{1}=a^{\\psi_{i}^{-1}(j)}\\mid x_{1}=j\\Big]\\right]}}\\\\ &{}&{\\leq\\mathbb{E}_{\\pi\\sim q}\\left[\\displaystyle\\frac{2}{N}\\sum_{j=1}^{N}\\frac{1}{N}\\right]=\\frac{2}{N}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "We conclude by Markov's inequality that $\\mathbb{P}_{i\\sim\\mathsf{U n i f}([N])}\\left[\\mathbb{E}_{\\pi\\sim q}\\big[D_{\\mathsf{H}}^{2}\\big(M^{i}(\\pi),\\overline{{M}}(\\pi)\\big)\\big]\\geq4/N\\right]\\leq1/2,$ giving $\\mathcal{Z}_{q}\\geq N/2$ ", "page_idx": 37}, {"type": "text", "text": "From Eq. (26), we conclude that for all $\\varepsilon^{2}\\geq4/N$ ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\mathsf{d e c}_{\\varepsilon}(\\langle\\!\\langle\\mathcal M_{\\mathrm{1at}},\\Phi\\rangle\\!\\rangle,\\overline{{M}})\\ge\\operatorname*{inf}_{q\\in\\Delta(\\Pi)}\\operatorname*{inf}_{p\\in\\Delta(\\Pi)}\\operatorname*{sup}_{i\\in\\mathcal Z_{q}}\\Big\\{\\mathbb E_{\\pi\\sim p}\\Big[J^{M^{i}}(\\pi_{M^{i}})-J^{M^{i}}(\\pi)\\Big]\\Big\\}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "2lTheorem n Fostere l IEGH3 is tated wit respet to $\\operatorname*{sup}_{\\overline{{M}}\\in\\mathsf{c o n v}(\\mathcal{M})}\\mathsf{d e c}_{\\varepsilon}(\\mathcal{M},\\overline{{M}})$ ,but the aetual proof (Section 2.2) gives a stronger result that scales with $\\operatorname*{sup}_{\\overline{{M}}}\\mathsf{d e c}_{\\varepsilon}(\\mathcal{M},\\overline{{M}})$ ", "page_idx": 37}, {"type": "text", "text": "To lower bound this quantity, observe that for any index $i$ and any policy $\\pi$ ,wehave ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\cal J}^{M^{i}}\\big(\\pi_{M^{i}}\\big)-{\\cal J}^{M^{i}}(\\pi)=1-\\frac{1}{N}\\sum_{j=1}^{N}\\mathbb{P}^{M^{(i)},\\pi}\\big[a_{1}=a^{(j)}\\mid x_{1}=s^{(\\psi_{i}(j))}\\big]}}\\\\ {{\\displaystyle\\qquad\\qquad\\qquad\\qquad=1-\\frac{1}{N}\\sum_{j=1}^{N}\\mathbb{P}^{\\overline{{{M}}},\\pi}\\big[a_{1}=a^{(j)}\\mid x_{1}=s^{(\\psi_{i}(j))}\\big]}}\\\\ {{\\displaystyle\\qquad\\qquad\\qquad\\qquad=1-\\frac{1}{N}\\sum_{j=1}^{N}\\mathbb{P}^{\\overline{{{M}}},\\pi}\\bigg[a_{1}=a^{(\\psi_{i}^{-1}(j))}\\mid x_{1}=s^{(j)}\\bigg],}}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where the third inequality uses Eq. (25). We conclude that for any distribution $p,q\\in\\Delta(\\Pi)$ ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{i\\in\\mathbb{Z}_{q}}{\\operatorname*{sup}}\\biggl\\{\\mathbb{E}_{\\pi\\sim p}\\biggl[J^{M^{i}}\\bigl(\\pi_{M^{i}}\\bigr)-J^{M^{i}}(\\pi)\\biggr]\\biggr\\}}\\\\ &{\\geq\\mathbb{E}_{i\\sim\\operatorname*{sup}\\{T_{q}\\}}\\biggl\\{\\mathbb{E}_{\\pi\\sim p}\\biggl[J^{M^{i}}\\bigl(\\pi_{M^{i}}\\bigr)-J^{M^{i}}(\\pi)\\biggr]\\biggr\\}}\\\\ &{\\geq1-\\frac{1}{N}\\sum_{j=1}^{N}\\mathbb{E}_{i\\sim\\operatorname*{sup}\\{T_{q}\\}}\\mathbb{P}^{\\overline{{M}},\\pi}\\Bigl[a_{1}=a^{(\\Psi_{i}^{-1}(q))}\\mid x_{1}=s^{(j)}\\Bigr]}\\\\ &{=1-\\frac{1}{N}\\sum_{j=1}^{N}\\frac{1}{|T_{q}|}\\sum_{\\ell=1}^{\\infty}\\mathbb{P}^{\\overline{{M}},\\pi}\\biggl[a_{1}=a^{(\\Psi_{i}^{-1}(j))}\\mid x_{1}=s^{(j)}\\biggr]\\geq1-\\frac{1}{|T_{q}|}\\geq\\frac{1}{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "as long as $N\\ge4$ . Since this lower bound holds uniformly for all $q,p\\in\\Delta(\\Pi)$ , we conclude that ", "page_idx": 38}, {"type": "equation", "text": "$$\n{\\sf d e c}_{\\varepsilon}(\\langle\\!\\langle\\mathcal{M}_{\\mathrm{lat}},\\Phi\\rangle\\!\\rangle,\\overline{{M}})\\geq\\frac{1}{2}.\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "FProofs for Section 3.3: Positive Results ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "This section is dedicated to our upper bound establishing that pushforward-coverable MDPs are statistically modular (Theorem 3.2). We provide a technical overview in Appendix F.1, and provide a full proof in Appendix F.2. ", "page_idx": 39}, {"type": "text", "text": "F.1 Technical Overview: Low-dimensional embeddings for pushforward-coverable MDPs. ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "The idea behind our positive result is to show that under the conditions of Theorem 3.2, it is possible to construct an (approximately) Bellman-complete value function class for the latent-dynamics MDP $M_{\\mathsf{o b s}}^{\\star}$ , at which point we can apply the GOLF algorithm of Jin et al. [JLM21]. We achieve this via two technical contributions. The first is the introduction of the mismatch functions $\\Gamma_{\\phi}$ , formally defined asfollows. ", "page_idx": 39}, {"type": "text", "text": "Definition F.1 (Mismatch functions). For a decodable emission process $\\psi^{\\star}$ and decoder $\\phi\\in\\Phi$ the mismatch function for $\\phi$ $,\\,\\Gamma_{\\phi}=\\{\\Gamma_{\\phi,h}:\\mathcal{S}\\to\\Delta(\\mathcal{S})\\}_{h=1}^{H},$ is defined, for every $h\\in[H]$ as the probability kernel ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\Gamma_{\\phi,h}(s_{h}^{\\prime}\\mid s_{h}):=\\mathbb{P}_{x_{h}\\sim\\psi_{h}^{\\star}(s_{h})}(\\phi_{h}(x_{h})=s_{h}^{\\prime}).\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "The mismatch functions allow us to express functions of the decoders as latent objects, and we revisit them in the context of self-predictive estimation (Appendix A). For the present result, we show (Lemma D.7) that the mismatch functions can capture the observation-level Bellman backups for any function of the decoders. That is, for any $x_{h},a_{h}$ , letting $s_{h}=(\\psi^{\\star})^{-1}(x_{h})$ denote the true latent state, we have that for any $f_{\\mathrm{lat}}:S\\times A\\rightarrow\\mathbb{R}$ and $\\phi\\in\\Phi$ ", "page_idx": 39}, {"type": "equation", "text": "$$\n[\\mathcal{T}_{h}^{M_{\\mathrm{obs}}^{\\star}}(f_{\\mathrm{lat}}\\circ\\phi_{h+1})](x_{h},a_{h})=[\\mathcal{T}_{h}^{M_{\\mathrm{lat}}^{\\star}}(\\Gamma_{\\phi,h+1}\\circ V_{f_{\\mathrm{lat}}})](s_{h},a_{h}).\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "That is, the Bellman update of $f_{\\mathrm{1at}}\\circ\\phi_{h+1}$ in the latent-dynamics MDP $M_{\\mathsf{o b s}}^{\\star}$ can be expressed as a Bellman update in the base MDP $M_{\\mathrm{1at}}^{\\star}$ for a different (latent) function $\\stackrel{...}{\\Gamma_{\\phi,h+1}}\\circ V_{f_{1a t}}(s_{h+1}):=$ $\\begin{array}{r}{\\sum_{s_{h+1}^{\\prime}}\\Gamma_{\\phi,h+1}\\!\\left(s_{h+1}^{\\prime}\\mid s_{h+1}\\right)\\operatorname*{max}_{a^{\\prime}}{f_{\\mathrm{{lat}}}\\!\\left(s_{h+1}^{\\prime},a^{\\prime}\\right)}.}\\end{array}$ ", "page_idx": 39}, {"type": "text", "text": "However, the mismatch functions $\\Gamma_{\\phi}$ embed some knowledge of the emission process, and (with only decoder and base model realizability) are unknown to the learner. Our second technical contribution bypasses this by establishing a new structural property for pushforward-coverable MDPs (Lemma F.1): there exist low-dimensional linear embeddings of their transition kernels which can approximate Bellman backups for an arbitrary and potentially unknown set of functions, as long as the set is not toolarge. ", "page_idx": 39}, {"type": "text", "text": "Lemma F.1 (Pushforward-coverable MDPs admit low-dimensional embeddings). Let $M$ bea known MDP with reward function $r$ ,transitionkernel $P$ andpushforwardcoverabilityparameter $C_{\\mathsf{p u s h}}$ Let $\\mu=\\{\\mu_{h}\\}_{h\\in[H]}$ denote its pushforward coverability distribution (i.e. the minimizer of Definition 3.3) and $\\mathcal{F}\\overset{\\cdot}{\\leq}(S\\times[H]\\rightarrow[0,1])$ be an arbitrary class of functions.Suppose that we sample W E {\u00b11}dxs asamatrixofindependentRademacherrandomvariables,anddefine ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\psi_{h}(s,a)=r_{h}(s,a)\\oplus\\frac{1}{\\sqrt{d}}W\\Big(P_{h}(\\cdot\\mid s,a)/\\mu_{h}^{1/2}(\\cdot)\\Big)_{\\cdot\\in\\mathcal{S}}\\in\\mathbb{R}^{d+1}.\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "and ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r}{w_{f,h}=1\\oplus\\frac{1}{\\sqrt{d}}W\\Big(\\mu_{h}^{1/2}(\\cdot)f_{h+1}(\\cdot)\\Big)_{\\cdot\\in\\mathcal{S}}\\in\\mathbb{R}^{d+1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Then for any $\\varepsilon_{\\mathsf{a p x}}\\in(0,1)$ , as long as we set ", "page_idx": 39}, {"type": "equation", "text": "$$\nd\\geq2^{9}\\frac{C_{\\mathsf{p u s h}}\\log\\!\\left(16|\\mathcal{F}|H\\delta^{-1}/\\varepsilon_{\\mathsf{a p x}}\\right)}{\\varepsilon_{\\mathsf{a p x}}},\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "we have that for all $f\\in\\mathcal F$ and $h\\in[H]$ , with probability at least $1-\\delta$ ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mu_{h}\\otimes\\mathsf{U n i f}(A)}\\Big[\\big(\\mathtt{c l}\\,\\mathtt{i i p}_{[0,2]}\\big[\\langle w_{f,h},\\psi_{h}(s,a)\\rangle\\big]-\\mathcal{T}_{h}\\,f_{h+1}(s,a)\\big)^{2}\\Big]\\le\\varepsilon_{\\mathsf{a p x}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "$\\begin{array}{r c l}{\\operatorname*{max}_{s,a,h}\\|\\psi_{h}(s,a)\\|_{2}^{2}}&{\\leq}&{C_{\\sf p u s h}(16\\log(|\\mathcal{S}||\\mathcal{A}|H)\\ +\\ 11)}\\end{array}$ $\\operatorname*{max}_{f,h}\\left\\|w_{f,h}\\right\\|_{2}^{2}\\;\\;\\leq$ $16\\log(|\\mathcal{F}|H)+11$ $\\psi\\,=\\,\\{\\psi_{h}\\}_{h=1}^{H}$ $\\mathcal{F}$ $M$ $\\mathcal{F}$ ", "page_idx": 39}, {"type": "text", "text": "We use this property, in conjunction with latent model realizability, to construct linear features that can approximate the right-hand-side of Eq. (27), thus yielding an (approximately) Bellman-complete value function class for the latent-dynamics MDP M\\*bs\\* ", "page_idx": 39}, {"type": "text", "text": "F.2 Proofs for Latent Model Class $^+$ Pushforward Coverability (Theorem 3.2) ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "In this section, we establish positive results under latent MDP classes which satisfy pushforward coverability. We assume that every model in $\\mathcal{M}_{\\mathrm{{lat}}}$ satisfies pushforward coverability, defined as follows: ", "page_idx": 40}, {"type": "text", "text": "Definition F.2 (Pushforward coverability). The pushforward coverability coefficient $C_{\\mathsf{p u s h}}$ for an MDP $M$ withtransitionkernel $P$ isdefinedby ", "page_idx": 40}, {"type": "equation", "text": "$$\nC_{\\sf p u s h}(M)=\\operatorname*{max}_{h\\in[H]}\\operatorname*{inf}_{\\mu\\in\\Delta(S)}\\operatorname*{sup}_{(s,a,s^{\\prime})\\in S\\times A\\times S}\\frac{P_{h-1}(s^{\\prime}\\mid s,a)}{\\mu(s^{\\prime})}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "The pushforward coverability coefficient for an MDP class $\\mathcal{M}$ is definedby ", "page_idx": 40}, {"type": "equation", "text": "$$\nC_{\\mathsf{p u s h}}(\\mathcal{M})=\\operatorname*{max}_{M\\in\\mathcal{M}}C_{\\mathsf{p u s h}}(M).\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Note that for any MDP $M$ we always have ", "page_idx": 40}, {"type": "equation", "text": "$$\nC_{\\mathsf{c o v}}(M,\\Pi_{\\mathsf{r n s}})\\leq C_{\\mathsf{p u s h}}(M)|\\mathcal{A}|,\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where $C_{\\mathsf{c o v}}$ is the state-action coverability coefficient (Definition D.3). Thus, an MDP with low pushforward coverability is also an MDP with low state-action coverability for all policies (upto a dependenceon $|{\\mathcal{A}}|)$ ", "page_idx": 40}, {"type": "text", "text": "We will show the show the following result. ", "page_idx": 40}, {"type": "text", "text": "Theorem 3.2 (Pushforward-coverable MDPs are statistically modular). Let $\\mathcal{M}_{\\mathrm{{lat}}}$ bea baseMDP class such that each $M_{\\mathrm{{lat}}}\\in\\mathcal{M}_{\\mathrm{{lat}}}$ has pushforward coverability bounded by $C_{\\mathsf{p u s h}}(M_{\\mathsf{l a t}})\\leq C_{\\mathsf{p u s h}}$ Then, for any decoder class $\\Phi$ , wehave: ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\cdot\\mathrm{\\mathsf{comp}}(\\langle\\langle\\mathcal{M}_{\\mathrm{1at}},\\Phi\\rangle,\\varepsilon,\\delta)\\leq\\mathrm{poly}(C_{\\mathrm{push}},|\\mathcal{A}|,H,\\log|\\mathcal{M}_{\\mathrm{1at}}|,\\log|\\Phi|,\\varepsilon^{-1},\\log(\\delta^{-1}),\\log\\log|\\mathcal{S}|).\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "The proof comes in three parts. We will firstly show that MDP that satisfies pushforward coverability admit low-dimensional feature maps that can approximate Bellman backups (Appendix F.2.1), then establish that a regret bound for the GOLF algorithm [XFBJK23] under misspecification (Appendix F.2.2), and then combine these ingredients (Appendix F.2.3). ", "page_idx": 40}, {"type": "text", "text": "F.2.1 A structural result: Pushforward-coverable MDPs are approximately low-rank ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Our central technical result for this section is Lemma F.1, which is based on a variant of the JohnsonLindenstrauss lemma and establishes that under pushforward coverability, we can define a linear feature class which satisfies an approximate form of Bellman completeness. We define the clipping operatorvia ", "page_idx": 40}, {"type": "equation", "text": "$$\n{\\mathsf{c l i p}}_{[0,2]}(x):=\\operatorname*{max}\\{\\operatorname*{min}\\{x,2\\},0\\}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "We prove the following lemma. ", "page_idx": 40}, {"type": "text", "text": "Lemma F.1 (Pushforward-coverable MDPs admit low-dimensional embeddings). Let $M$ be a knownMDPwithrewardfunction $r$ ,transition kernel $P$ andpushforwardcoverabilityparameter $C_{\\mathsf{p u s h}}$ Let $\\mu=\\{\\mu_{h}\\}_{h\\in[H]}$ denote its pushforward coverability distribution (i.e. the minimizer of Definition 3.3) and $\\mathcal{F}\\subseteq(S\\times[H]\\to[0,1])$ be an arbitrary class of functions.Suppose that we sample W E {\u00b11}dxs asamatrixofindependentRademacherrandomvariables,anddefine ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\psi_{h}(s,a)=r_{h}(s,a)\\oplus\\frac{1}{\\sqrt{d}}W\\Big(P_{h}(\\cdot\\mid s,a)/\\mu_{h}^{1/2}(\\cdot)\\Big)_{\\cdot\\in\\mathcal{S}}\\in\\mathbb{R}^{d+1}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "and ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r}{w_{f,h}=1\\oplus\\frac{1}{\\sqrt{d}}W\\Big(\\mu_{h}^{1/2}(\\cdot)f_{h+1}(\\cdot)\\Big)_{\\cdot\\in\\mathcal{S}}\\in\\mathbb{R}^{d+1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Then for any $\\varepsilon_{\\mathsf{a p x}}\\in(0,1)$ , as long as we set ", "page_idx": 40}, {"type": "equation", "text": "$$\nd\\geq2^{9}\\frac{C_{\\mathsf{p u s h}}\\log\\!\\left(16|\\mathcal{F}|H\\delta^{-1}/\\varepsilon_{\\mathsf{a p x}}\\right)}{\\varepsilon_{\\mathsf{a p x}}},\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "we have that for all $f\\in\\mathcal F$ and $h\\in[H]$ , with probability at least $1-\\delta$ ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mu_{h}\\otimes\\mathsf{U n i f}(A)}\\Big[\\big(\\mathtt{c l}\\,\\mathtt{i i p}_{[0,2]}\\big[\\langle w_{f,h},\\psi_{h}(s,a)\\rangle\\big]-T_{h}\\,f_{h+1}(s,a)\\big)^{2}\\Big]\\le\\varepsilon_{\\mathsf{a p x}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "as well as $\\begin{array}{r c l}{\\operatorname*{max}_{s,a,h}\\|\\psi_{h}(s,a)\\|_{2}^{2}}&{\\leq}&{C_{\\sf p u s h}(16\\log(|\\mathcal{S}||\\mathcal{A}|H)\\ +\\ 11)}\\end{array}$ and $\\operatorname*{max}_{f,h}\\left\\|w_{f,h}\\right\\|_{2}^{2}\\;\\;\\leq$ $16\\log(|\\mathcal{F}|H)+11$ Wemsizethefe $\\psi\\,=\\,\\{\\psi_{h}\\}_{h=1}^{H}$ is oblivious to $\\mathcal{F}$ inthe sensethatitcanbecomputeddirectlyfrom withoutanyknowledgeof $\\mathcal{F}$ ", "page_idx": 41}, {"type": "text", "text": "Proof of Lemma F.1. Fix $h\\in[H]$ whose dependence we omit for cleanliness. Webeginby verifying that, in expectation, $\\langle w_{f},\\psi(s,a)\\rangle$ is equal to $\\tau f(s,a)$ . For this, note that ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle=r(s,a)+\\frac{1}{d}\\sum_{i=1}^{d}\\left(\\sum_{s^{\\prime}\\in S}W_{i,s^{\\prime}}\\frac{P(s^{\\prime}\\mid s,a)}{\\mu^{1/2}(s^{\\prime})}\\right)\\left(\\sum_{s^{\\prime\\prime}\\in S}W_{i,s^{\\prime\\prime}}\\mu^{1/2}(s^{\\prime\\prime})f(s^{\\prime\\prime})\\right)}}\\\\ {{\\displaystyle=r(s,a)+\\sum_{s^{\\prime}\\in S}P(s^{\\prime}\\mid s,a)f(s^{\\prime})+\\frac{1}{d}\\sum_{i=1}^{d}\\sum_{s^{\\prime}\\in S}\\sum_{s^{\\prime\\prime}\\in S}W_{i,s^{\\prime}}\\frac{P(s^{\\prime}\\mid s,a)}{\\mu^{1/2}(s^{\\prime})}W_{i,s^{\\prime\\prime}}\\mu^{1/2}(s^{\\prime\\prime})f(s^{\\prime\\prime}).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Consequently, we have ", "page_idx": 41}, {"type": "equation", "text": "$$\n|T f(s,a)-\\langle w_{f},\\psi(s,a)\\rangle|=\\left|\\frac{1}{d}\\sum_{i=1}^{d}\\sum_{s^{\\prime}\\in S}\\sum_{s^{\\prime\\prime}\\in S}W_{i,s^{\\prime}}\\frac{P(s^{\\prime}\\mid s,a)}{\\mu^{1/2}(s^{\\prime})}W_{i,s^{\\prime\\prime}}\\mu^{1/2}(s^{\\prime\\prime})f(s^{\\prime\\prime})\\right|.\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Note that this remaining noise term is zero-mean - we will show in the sequel that it can be made small by picking $d$ appropriately. We next examine the norms of the vectors $\\psi(s,a)$ and $w_{f}$ .Note thatwehave ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\|\\psi(s,a)\\|_{2}^{2}=\\displaystyle\\frac{1}{d}\\sum_{i=1}^{d}\\!\\left(\\sum_{s^{\\prime}\\in\\mathcal{S}}W_{i,s^{\\prime}}\\frac{P(s^{\\prime}\\mid s,a)}{\\mu^{1/2}(s^{\\prime})}\\right)^{2}}\\\\ {\\displaystyle=\\sum_{s^{\\prime}\\in\\mathcal{S}}\\frac{P^{2}(s^{\\prime}\\mid s,a)}{\\mu(s^{\\prime})}+\\displaystyle\\frac{1}{d}\\sum_{i=1}^{d}\\sum_{s^{\\prime}\\in\\mathcal{S}}\\sum_{s^{\\prime\\prime}\\in\\mathcal{S}}W_{i,s^{\\prime}W_{i,s^{\\prime\\prime}}}\\frac{P(s^{\\prime}\\mid s,a)}{\\mu^{1/2}(s^{\\prime})}\\frac{P(s^{\\prime\\prime}\\mid s,a)}{\\mu^{1/2}(s^{\\prime\\prime})}}\\\\ {\\displaystyle\\leq C_{\\mathrm{pash}}+\\frac{1}{d}\\sum_{i=1}^{d}\\sum_{s^{\\prime}\\in\\mathcal{S}}\\sum_{s^{\\prime\\prime}\\in\\mathcal{S}}W_{i,s^{\\prime}W_{i,s^{\\prime\\prime}}}\\frac{P(s^{\\prime}\\mid s,a)}{\\mu^{1/2}(s^{\\prime})}\\frac{P(s^{\\prime\\prime}\\mid s,a)}{\\mu^{1/2}(s^{\\prime\\prime})},}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "where we have used that ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\sum_{s^{\\prime}\\in\\mathcal{S}}\\frac{P^{2}(s^{\\prime}\\mid s,a)}{\\mu(s^{\\prime})}\\leq C_{\\sf p u s h}\\sum_{s^{\\prime}\\in\\mathcal{S}}P(s^{\\prime}\\mid s,a)=C_{\\sf p u s h}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "by definition of pushforward coverability. Further note that we have ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\|w_{f}\\|_{2}^{2}=\\frac{1}{d}\\sum_{i=1}^{d}\\left(\\sum_{s^{\\prime}\\in S}W_{i,s^{\\prime}}\\mu^{1/2}(s^{\\prime})f(s^{\\prime})\\right)^{2}}\\\\ {\\displaystyle\\qquad=\\mathbb{E}_{s^{\\prime}\\sim\\mu}[f(s^{\\prime})]+\\frac{1}{d}\\sum_{i=1}^{d}\\sum_{s^{\\prime}\\in S}\\sum_{s^{\\prime\\prime}\\in S}W_{i,s^{\\prime}}W_{i,s^{\\prime\\prime}}\\mu^{1/2}(s^{\\prime})f(s^{\\prime})\\cdot\\mu^{1/2}(s^{\\prime\\prime})f(s^{\\prime\\prime})}\\\\ {\\displaystyle\\qquad\\leq1+\\frac{1}{d}\\sum_{i=1}^{d}\\sum_{s^{\\prime}\\in S}\\sum_{s^{\\prime\\prime}\\in S}W_{i,s^{\\prime}}W_{i,s^{\\prime\\prime}}\\mu^{1/2}(s^{\\prime})f(s^{\\prime})\\cdot\\mu^{1/2}(s^{\\prime\\prime})f(s^{\\prime\\prime}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "We will now appeal to the following technical lemma to upper bound Eq. (30), Eq. (31), and Eq. (32) by establishing that the Rademacher noise terms concentrate to their expectations. The proof of the lemma will be given in the sequel. ", "page_idx": 41}, {"type": "text", "text": "Lemma F.2. Let $u,v\\in\\mathbb{R}^{n}$ and let $W\\in\\{\\pm1\\}^{d\\times n}$ have independent Rademacher entries. Then with probability at least $1-\\delta$ ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\left|\\frac{1}{d}\\sum_{i\\in[d]}\\sum_{j\\in[n]}\\sum_{k\\in[n]}W_{i,j}W_{i,k}u_{j}v_{k}\\right|\\leq\\|u\\|_{2}\\|v\\|_{2}\\cdot\\sqrt{\\frac{32\\log(2\\delta^{-1})}{d}}+\\|u\\|_{2}^{2}\\|v\\|_{2}^{2}\\cdot\\frac{64\\log\\left(2\\delta^{-1}\\right)}{d}.\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Furthermore, for any set of vectors $\\mathcal{V}\\subset\\mathbb{R}^{n}$ , we also have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\frac{1}{d}\\operatorname*{max}_{v\\in\\mathcal{V}}\\sum_{i\\in[d]}\\sum_{j\\in[n]}\\sum_{k\\in[n]}W_{i,j}W_{i,k}v_{j}v_{k}}}\\\\ &{\\leq\\operatorname*{max}_{v\\in\\mathcal{V}}\\|v\\|_{2}^{2}(16\\log|\\mathcal{V}|+9)+\\operatorname*{max}_{v\\in\\mathcal{V}}\\|v\\|_{2}^{2}\\cdot\\sqrt{\\frac{32\\log(2\\delta^{-1})}{d}}+\\operatorname*{max}_{v\\in\\mathcal{V}}\\|v\\|_{2}^{4}\\cdot\\frac{64\\log\\left(2\\delta^{-1}\\right)}{d}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Let $(s,a)\\in S\\times A$ and $f\\in\\mathcal F$ To bound $|\\langle\\psi(s,a),w_{f}\\rangle-T f(s,a)|$ (cf. Eq. (30)), we apply the first bound of Lemma F.2 with $u\\,=\\,\\bigl(P(s^{\\prime}\\mid s,a)/\\mu^{1/2}(s^{\\prime})\\bigr)_{s^{\\prime}\\in S}$ and $v\\,=\\,\\bigl(\\mu^{1/2}(s^{\\prime})f(s^{\\prime})\\bigr)_{s^{\\prime}\\in S}$ which gives ", "page_idx": 42}, {"type": "equation", "text": "$$\n|\\langle\\psi(s,a),w_{f}\\rangle-T f(s,a)|\\leq\\sqrt{\\frac{32C_{\\mathrm{push}}\\log(2\\delta^{-1})}{d}}+64C_{\\mathrm{push}}\\frac{\\log(2\\delta^{-1})}{d}:=\\varepsilon(\\delta^{-1}),\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "where we have again used tha ll2 =s'es P. P(s1.a)\u2264 Cpush and also tha Il/l2 = 1 since $\\|f\\|_{\\infty}\\leq1$ for all $f\\,\\in\\,{\\mathcal{F}}$ : To bound Eq. (31), we apply the second bound of Lemma F.2 with $\\begin{array}{r}{\\mathcal{V}=\\left\\{\\left(\\frac{P_{h-1}(s^{\\prime}|s,a)}{\\mu_{h}^{1/2}(s^{\\prime})}\\right)_{s^{\\prime}\\in S}\\right\\}_{s,a\\in S\\times A}.}\\end{array}$ which gives ", "page_idx": 42}, {"type": "text", "text": "$\\operatorname*{max}_{\\substack{{a\\in S\\times A,h\\in[H]}}}\\|\\psi_{h}(s,a)\\|_{2}^{2}\\leq C_{\\mathrm{push}}(16\\log|S||A|H+9)+C_{\\mathrm{push}}\\sqrt{\\frac{32\\log(2\\delta^{-1})}{d}}+C_{\\mathrm{push}}^{2}\\frac{64\\log\\left(2\\delta^{-1}\\right)}{d}=\\frac{3}{2}\\sum_{\\substack{{a\\in S\\times A,h\\in[H]}}}\\|\\psi_{h}(s,a)\\|_{2}^{2}.$ Lastly, to bound Eq. (32), we take $\\mathcal{V}\\,=\\,\\left\\{\\left(\\mu_{h}^{1/2}(s^{\\prime})f_{h}(s^{\\prime})\\right)_{s^{\\prime}\\in\\mathcal{S}}\\right\\}_{h\\in[H]}$ in Lemma F.2, which establishes that ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{f\\in\\mathcal{F},h\\in[H]}\\lVert w_{f,h}\\rVert_{2}^{2}\\leq9+16\\log\\lvert\\mathcal{F}\\rvert H+\\sqrt{\\frac{32\\log(2\\delta^{-1})}{d}}+\\frac{64\\log\\bigl(2\\delta^{-1}\\bigr)}{d}.\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Note that Eq. (34) establishes that the Bellman backup $\\tau f(s,a)$ is well-approximated by $\\langle\\psi(s,a),w_{f}\\rangle$ only at a single state-action pair $(s,a)$ : We can obtain an $L_{\\infty}$ -approximation guarantee by taking a union bound over $\\boldsymbol{S}$ and $\\boldsymbol{\\mathcal{A}}$ , which would incur a dependence on $\\log\\!|S|$ in the final sample complexity. Here, we bypass this by instead requiring only an approximation guarantee under the $L_{2}(\\mu\\otimes\\mathsf{U n i f}(A))$ norm.  Via (pushforward) coverability, this will ensure that $\\mathbb{E}^{\\pi}\\Big[\\big(\\langle w_{f},\\psi(s,a)\\rangle-T f(s,a)\\big)^{2}\\Big]$ is well-controlled for all policies $\\pi$ , which will be suffcient for our downstream sample-complexity analysis of GoLF. However, directly establishing an $L_{2}(\\mu\\otimes\\mathsf{U n i f}(A))$ approximation guarantee is technically challenging since it would require establishing a fourth-order (rather than second-order) equivalent of Eq. (33). The remainder of the proof will obtain an $L_{2}(\\mu\\otimes\\mathsf{U n i f}(A))$ approximation guarantee by instead sampling a dataset of size $n$ from $\\mu\\otimes$ Uni $\\mathsf{f}({\\mathcal{A}})$ and taking a union bound over that dataset to ensure a uniform bound on all state-action pairs in that dataset. Via an additional concentration bound, this will ensure that the error is well-behaved under the $L_{2}(\\mu\\otimes\\mathsf{U n i f}(A))$ norm. ", "page_idx": 42}, {"type": "text", "text": "For each $h\\in[H]$ , sample a dataset $D=\\{(s_{h}^{(i)},a_{h}^{(i)})\\}_{i=1}^{n}$ i.i.d. from $\\mu_{h}\\otimes\\mathsf{U n i f}(A)$ . By a union bound over $n,{\\mathcal{F}}$ , and $H$ , we have that ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\forall i\\in[n],f\\in\\mathcal{F},h\\in[H]:\\quad\\left|\\left\\langle\\psi_{h}(s_{h}^{(i)},a_{h}^{(i)}),w_{f,h}\\right\\rangle-\\mathcal{T}_{h}f_{h+1}(s_{h}^{(i)},a_{h}^{(i)})\\right|\\leq\\varepsilon(n|\\mathcal{F}|H\\delta^{-1}),\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "where we recall the definition of $\\varepsilon(\\cdot)$ from Eq. (34). Now, let ", "page_idx": 42}, {"type": "equation", "text": "$$\nX_{f,h}(s,a):=\\big(\\mathbf{cl\\,ip}_{[0,2]}[\\langle\\psi_{h}(s,a),w_{f,h}\\rangle]-T_{h}f_{h+1}(s,a)\\big)^{2}.\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Note that $|X_{f,h}(s,a)|\\leq4$ and ", "page_idx": 43}, {"type": "equation", "text": "$$\nX_{f,h}(s,a)\\leq(\\langle\\psi_{h}(s,a),w_{f,h}\\rangle-T_{h}f_{h+1}(s,a))^{2},\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "since $\\mathcal{T}_{h}f_{h+1}(s,a)\\in[0,2]$ and the clipping operator is 1-Lipshitz. Note that ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{(s,a)\\sim\\mu_{h}\\otimes\\mathsf{I n i f}(A)}[X_{f,h}(s,a)]:=\\mathbb{E}_{\\mu_{h}\\otimes\\mathsf{I n i f}(A)}\\Big[\\big(\\mathbf{clip}_{[0,2]}[\\langle\\psi_{h}(s,a),w_{f}\\rangle]-T_{h}f_{h+1}(s,a)\\big)^{2}\\Big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "where this expectation is only over the sampling of the data point $(s,a)$ (and not the Rademacher matrix $W$ ). Let ", "page_idx": 43}, {"type": "equation", "text": "$$\nX_{i,f,h}:=X_{f,h}\\big(s_{h}^{(i)},a_{h}^{(i)}\\big).\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "By boundedness of $X_{f,h}(s,a)$ and Hoeffding's inequality, we have that with probability at least $1-\\delta$ ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\left|\\frac{1}{n}\\sum_{i=1}^{n}X_{i,f,h}-\\mathbb{E}_{\\mu\\otimes\\mathsf{U n i f}(A)}[X_{f,h}(s,a)]\\right|\\leq4\\sqrt{\\frac{\\log(2\\delta^{-1})}{n}}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Taking another union bound over $\\mathcal{F}$ and $H$ as well as the event in Eq. (35) gives that ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\forall f\\in\\mathcal{F},h\\in[H]:\\quad\\left|\\frac{1}{n}\\sum_{i=1}^{n}X_{i,f,h}-\\mathbb{E}_{\\mu\\otimes\\operatorname{Unif}(A)}[X_{f,h}(s,a)]\\right|\\leq4\\sqrt{\\frac{\\log(2|\\mathcal{F}|H\\delta^{-1})}{n}},\n$$", "text_format": "latex", "page_idx": 43}, {"type": "equation", "text": "$\\forall i\\in[n],f\\in\\mathcal{F},h\\in[H]:\\ \\ X_{i,f,h}\\leq\\varepsilon^{2}(n|\\mathcal{F}|H\\delta^{-1}),$ ", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "recalling the definition of $\\varepsilon(\\cdot)$ from Eq. (34). Then, re-arranging Eq. (36) gives us that ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\mu\\otimes\\operatorname{lnif}(A)}\\Big[\\big(\\mathbf{c}\\mathbf{1}\\mathbf{i}\\mathsf{p}_{[0,2]}[\\langle\\psi_{h}(s_{h},a_{h}),w_{f}\\rangle]-\\mathcal{T}_{h}f_{h+1}(s_{h},a_{h})\\big)^{2}\\Big]}\\\\ &{\\qquad\\leq\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}X_{i,f,h}+4\\sqrt{\\frac{\\log(2|\\mathcal{F}|H\\delta^{-1})}{n}}}\\\\ &{\\qquad\\leq\\varepsilon^{2}(n|\\mathcal{F}|H\\delta^{-1})+4\\sqrt{\\frac{\\log(2|\\mathcal{F}|H\\delta^{-1})}{n}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "We now conclude the proof by picking $n$ and $d$ appropriately to ensure that the right-hand-side is bounded by $\\varepsilon_{\\mathsf{a p x}}$ , which will ensure the desired claim that ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mu\\otimes\\mathsf{U n i f}(A)}\\Big[\\big(\\mathtt{c l}\\,\\mathtt{i p}_{[0,2]}\\big[\\langle\\psi_{h}(s_{h},a_{h}),w_{f}\\rangle\\big]-\\mathcal{T}_{h}\\,f_{h+1}\\big(s_{h},a_{h}\\big)\\big)^{2}\\Big]\\le\\varepsilon_{\\mathsf{a p x}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "For convenience, we introduce absolute constants $c$ and $c^{\\prime}$ whose precise values may change from line to ine. We pick $n=64\\log(2|\\mathcal{F}|H\\delta^{-1})/\\varepsilon_{\\mathsf{a p x}}^{2}$ Plugging this into (38) gives ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mu\\otimes\\mathsf{U n i f}}({\\boldsymbol{A}})\\Big[\\big(\\mathsf{c l}\\,\\mathtt{i p}_{[0,2]}\\big[\\langle\\psi_{h}(s_{h},a_{h}),{\\boldsymbol{w}}_{f}\\rangle\\big]-\\mathcal{T}_{h}f_{h+1}(s_{h},a_{h})\\big)^{2}\\Big]\\leq\\varepsilon^{2}(n|\\mathcal{F}|H\\delta^{-1})+c\\cdot\\varepsilon\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Noting that n \u2264 128lF[H6-1 and plugging this into $\\varepsilon$ (Eq. (34)) gives ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\varepsilon(n|\\mathcal{F}|H\\delta^{-1})\\leq C_{\\mathrm{push}}^{1/2}\\sqrt{\\frac{64\\log(16|\\mathcal{F}|H\\delta^{-1}/\\varepsilon_{\\mathrm{apx}})}{d}}+C_{\\mathrm{push}}\\frac{128\\log\\left(16|\\mathcal{F}|H\\delta^{-1}/\\varepsilon_{\\mathrm{apx}}\\right)}{d}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Setting ", "page_idx": 43}, {"type": "equation", "text": "$$\nd\\geq2^{9}\\frac{C_{\\sf p u s h}\\log\\left(16|\\mathcal{F}|H\\delta^{-1}/\\varepsilon_{\\sf a p x}\\right)}{\\varepsilon_{\\sf a p x}}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "ensures that ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\varepsilon^{2}(n|\\mathcal{F}|H\\delta^{-1})\\leq\\varepsilon(n|\\mathcal{F}|H\\delta^{-1})\\leq\\frac{\\varepsilon_{\\mathsf{a p x}}}{2}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "by Eq. (40). Combining Eq. (38) and Eq. (41), we get ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mu\\otimes\\mathsf{U n i f}(A)}\\Big[\\big(\\mathtt{c l}\\,\\mathtt{i p}_{[0,2]}\\big[\\langle\\psi_{h}(s_{h},a_{h}),w_{f}\\rangle\\big]-\\mathcal{T}_{h}f_{h+1}\\big(s_{h},a_{h}\\big)\\big)^{2}\\Big]\\le\\varepsilon_{\\mathsf{a p x}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Proof of Lemma F.2. We establish the first claim. Let $i\\in[d]$ be fixed, and consider the random variable ", "page_idx": 44}, {"type": "equation", "text": "$$\nZ_{i}:=\\sum_{j\\in[n]}\\sum_{k\\in[n]}W_{i,j}W_{i,k}v_{j}u_{k}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Note that $\\mathbb{E}[Z_{i}]\\;=\\;0$ by independence of $W_{i,j}$ and $W_{i,k}$ for every $j\\neq k$ .By Exercise 6.9 of Boucheron et al. [BLM13], we have that ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\log\\mathbb{E}[\\exp(\\lambda Z_{i})]\\leq\\frac{16\\lambda^{2}}{2(1-64\\|u\\|_{2}^{2}\\|v\\|_{2}^{2}\\lambda)}\\|u\\|_{2}^{2}\\|v\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Since $Z_{i}$ are independent, it follows that ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\log\\mathbb{E}\\left[\\exp\\left(\\lambda\\sum_{i=1}^{d}Z_{i}\\right)\\right]\\leq\\frac{16\\lambda^{2}}{2(1-64\\|u\\|_{2}^{2}\\|v\\|_{2}^{2}\\lambda)}\\|u\\|_{2}^{2}\\|v\\|_{2}^{2}d.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Hence, $\\textstyle\\sum_{i=1}^{d}Z_{i}$ is a sub-Gamma random variable with parameters $\\nu\\,=\\,16\\|u\\|_{2}^{2}\\|v\\|_{2}^{2}d$ and $c=$ $64\\|u\\|_{2}^{2}\\|v\\|_{2}^{2}$ , and it follows from Equation (2.5) on page 29 of Boucheron et al. [BLM13] that for all $\\varepsilon>0$ ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\sum_{i=1}^{d}Z_{i}\\geq\\|u\\|_{2}\\|v\\|_{2}\\sqrt{32d\\varepsilon}+64\\|u\\|_{2}^{2}\\|v\\|_{2}^{2}\\varepsilon\\right)\\leq e^{-\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Taking a union bound, and using that the random variable is symmetric, we obtain the desired claim. We now establish the second claim. Let $\\mathcal{V}\\subset\\mathbb{R}^{n}$ be a subset of vectors. Let $i\\in[d]$ be fixed, and re-consider the random variable ", "page_idx": 44}, {"type": "equation", "text": "$$\nZ_{i}:=\\operatorname*{max}_{v\\in\\mathcal{V}}\\sum_{\\textstyle j\\in[n]}\\sum_{\\textstyle k\\in[n]}W_{i,j}W_{i,k}v_{j}v_{k}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Again appealing to Exercise 6.9 of Boucheron et al. [BLM13], we have that ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\log\\mathbb{E}[\\exp(\\lambda(Z_{i}-\\mathbb{E}[Z_{i}]))]\\leq\\frac{16\\lambda^{2}}{2(1-64B\\lambda)}\\,\\mathbb{E}\\left[\\operatorname*{max}_{v\\in\\mathcal{V}\\atop v\\in\\mathcal{V}}\\sum_{j\\in[n]}\\sum_{k\\in[n]}W_{i,j}W_{i,k}v_{j}^{2}v_{k}^{2}\\right]}&{}\\\\ {\\leq\\frac{16\\lambda^{2}}{2(1-64B\\lambda)}\\,\\mathbb{E}\\left[\\operatorname*{max}_{v\\in\\mathcal{V}\\atop v\\in\\mathcal{V}}\\sum_{j,k=1}^{n}v_{j}^{2}v_{k}^{2}\\right]}&{}\\\\ {=\\frac{16\\lambda^{2}}{2(1-64B\\lambda)}\\,\\operatorname*{max}_{v\\in\\mathcal{V}}\\|v\\|_{2}^{4}}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where $B:=\\operatorname*{max}_{v\\in\\nu}\\lVert v\\rVert_{2}^{4}$ . Since $Z_{i}$ are independent, it follows that ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\log\\mathbb{E}\\left[\\exp\\left(\\lambda\\sum_{i=1}^{d}(Z_{i}-\\mathbb{E}[Z_{i}])\\right)\\right]\\leq\\frac{16\\lambda^{2}}{2(1-64B\\lambda)}\\operatorname*{max}_{v\\in\\mathcal{V}}\\lVert v\\rVert_{2}^{4}d.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Hence, $\\textstyle\\sum_{i=1}^{d}Z_{i}$ is a sub-Gamma random variable with parameters $\\nu\\,=\\,16\\operatorname*{max}_{v\\in\\mathcal{V}}\\lVert v\\rVert_{2}^{4}d$ and $c=64\\operatorname*{max}_{v\\in\\mathcal{V}}{\\left\\|v\\right\\|_{2}^{4}}$ , and it follows from Equation (2.5) on page 29 of Boucheron et al. [BLM13] that for all $\\varepsilon>0$ ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\mathbb{P}\\bigg(\\frac{1}{d}\\sum_{i=1}^{d}Z_{i}\\geq\\mathbb{E}[Z_{i}]+\\operatorname*{max}_{v\\in\\mathcal{V}}\\lVert v\\rVert_{4}^{2}\\sqrt{\\frac{32\\varepsilon}{d}}+64\\operatorname*{max}_{v\\in\\mathcal{V}}\\lVert v\\rVert_{2}^{4}\\frac{\\varepsilon}{d}\\bigg)\\leq e^{-\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "To conclude, it remains only to show the bound $\\mathbb{E}[Z_{i}]\\le\\operatorname*{max}_{v}\\|v\\|_{2}^{2}(16\\log|\\mathcal{V}|+9)$ . This follows by a standard log-sum-exp approach. Below, we abbreviate $\\rho_{j}:=W_{i,j}$ . We can observe that for any $\\lambda>0$ ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[Z_{i}]=\\mathbb{E}\\left[\\underset{v\\in V}{\\operatorname*{max}}\\displaystyle\\sum_{j\\in[n]}\\sum_{k\\in[n]}\\rho_{j}\\rho_{k}v_{j}v_{k}\\right]}\\\\ &{\\phantom{\\mathbb{E}[Z_{i}]=}\\leq\\frac{1}{\\lambda}\\log\\left(\\underset{v\\in V}{\\sum_{j\\in[n]}}\\mathbb{E}\\left[\\exp\\left(\\lambda\\displaystyle\\sum_{j\\in[n]}\\sum_{k\\in[n]}\\rho_{j}\\rho_{k}v_{j}v_{k}\\right)\\right]\\right)}\\\\ &{\\phantom{\\mathbb{E}[Z_{i}]=}\\leq\\frac{1}{\\lambda}\\log\\left(\\underset{v\\in V}{\\sum_{j\\in[n]}}\\mathbb{E}\\left[\\exp\\left(\\lambda\\left(\\underset{j\\in[n]}{\\sum_{j\\in[j]}}\\rho_{j}v_{j}\\right)^{2}\\right)\\right]\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Note that $\\begin{array}{r}{X:=\\sum_{j}\\rho_{j}v_{j}}\\end{array}$ is subGaussian with parameter $\\|\\boldsymbol{v}\\|_{2}^{2}$ , since: ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\exp\\left(\\lambda\\sum_{j=1}^{n}\\rho_{j}v_{j}\\right)\\right]=\\prod_{j=1}^{n}\\mathbb{E}[\\exp(\\lambda\\rho_{j}v_{j})]\\leq\\prod_{j=1}^{n}\\exp\\left(\\frac{\\lambda^{2}v_{j}^{2}}{2}\\right)=\\exp\\left(\\frac{\\lambda^{2}}{2}\\|v\\|_{2}^{2}\\right).\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Then, it follows (e.g. Lemma 1.12 of Rigollet et al. [RH23]) that $X^{2}-\\mathbb{E}[X^{2}]$ satisfies a subexponential MGF bound with parameter $16\\bar{||}v\\|_{2}^{2}$ ,i.e. ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\exp\\bigl(\\lambda(X^{2}-\\mathbb{E}[X^{2}])\\bigr)]\\leq\\exp\\biggl(\\frac{256}{2}\\lambda^{2}\\|v\\|_{2}^{4}\\biggr)\\qquad\\forall|\\lambda|\\leq\\frac{1}{16\\|v\\|_{2}^{2}}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "We also note that ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\mathbb{E}[X^{2}]=\\sum_{i,j=1}^{n}v_{i}v_{j}\\,\\mathbb{E}[\\varepsilon_{i}\\varepsilon_{j}]=\\|v\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Adding and subtracting $\\mathbb{E}[X^{2}]$ in Eq. (43) gives ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\displaystyle\\frac{1}{\\lambda}\\log\\left(\\sum_{v\\in\\mathcal{V}}\\mathbb{E}\\big[\\exp\\big(\\lambda\\big(X^{2}-\\|v\\|_{2}^{2}\\big)+\\lambda\\|v\\|_{2}^{2}\\big)\\big]\\right)}\\\\ &{=\\displaystyle\\frac{1}{\\lambda}\\log\\left(\\sum_{v\\in\\mathcal{V}}\\mathbb{E}\\big[\\exp\\big(\\lambda\\big(X^{2}-\\|v\\|_{2}^{2}\\big)\\big)\\big]\\exp\\big(\\lambda\\|v\\|_{2}^{2}\\big)\\right)}\\\\ &{\\leq\\displaystyle\\frac{1}{\\lambda}\\log\\left(\\sum_{v\\in\\mathcal{V}}\\exp\\big(128\\lambda^{2}\\|v\\|_{2}^{4}+\\lambda\\|v\\|_{2}^{2}\\big)\\right)\\qquad\\forall|\\lambda|\\leq\\frac{1}{16\\operatorname*{max}_{v}\\|v\\|_{2}^{2}}}\\\\ &{\\leq\\displaystyle\\frac{1}{\\lambda}\\log|\\mathcal{V}|+\\operatorname*{max}_{v}128\\lambda\\|v\\|_{2}^{4}+\\operatorname*{max}_{v}\\|v\\|_{2}^{2}\\qquad\\forall|\\lambda|\\leq\\frac{1}{16\\operatorname*{max}_{v}\\|v\\|_{2}^{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Picking \u5165 = 16 maxsI concludes the proof. ", "page_idx": 45}, {"type": "text", "text": "F.2.2  GoLF with on-policy misspecification ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Consider the version of GOLF [JLM21] in Algorithm 2. We have the following guarantee for the regret of GOLF, which extends Jin et al. [JLM21] to allow for on-policy misspecification. ", "page_idx": 45}, {"type": "text", "text": "Lemma F.3. Suppose that $Q^{M_{\\mathrm{obs}}^{\\star},\\star}\\,\\in\\,\\mathcal{F}$ and $\\mathcal{G}$ satisfies $\\varepsilon_{\\mathsf{a p x}}$ -completenessinthesensethatfor all $\\textit{h}\\in[H]$ and $f\\ \\in\\ {\\mathcal{F}}_{h+1}$ therexists $g\\ \\in\\ \\mathcal{G}_{h}$ such that $\\mathbb{E}^{\\pi}\\Big(g-T_{h}^{M_{\\mathrm{obs}}^{\\star}}f\\Big)^{2}\\;\\leq\\;\\varepsilon_{\\mathsf{a p x}}^{2}$ for al $\\pi\\in\\Pi_{\\mathcal{F}}:=\\{\\pi_{f}:f\\in\\mathcal{F}\\}$ Let $C_{\\mathsf{c o v}}:=C_{\\mathsf{c o v}}(M_{\\mathsf{o b s}}^{\\star},\\Pi_{\\mathcal{F}})$ (Definition $D.3$ ). Then for an appropriate choice of $\\beta$ Algorithm2ensuresthat ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\mathsf{R e g}\\leq H\\sqrt{C_{\\mathsf{c o v}}T\\log(|\\mathcal{F}||\\mathcal{G}|H T/\\delta)}+H T\\sqrt{C_{\\mathsf{c o v}}\\log(T)}\\varepsilon_{\\mathsf{a p x}}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "input: Function classes $\\mathcal{F}$ and $\\mathcal{G}$ , confidence width $\\beta>0$   \ninitialize: $\\mathcal{F}^{(0)}\\leftarrow\\mathcal{F}$ $\\mathcal{D}_{h}^{(0)}\\leftarrow\\emptyset\\;\\;\\forall h\\in[H]$ 1: for episode $t=1,2,\\ldots,T$ do 2: Select policy $\\pi^{(t)}\\leftarrow\\pi_{f^{(t)}}$ , where $f^{(t)}:=\\arg\\operatorname*{max}_{f\\in{\\mathcal{F}}^{(t-1)}}f\\bigl(x_{1},\\pi_{f,1}(x_{1})\\bigr)$ 3: Execute $\\pi^{(t)}$ for one episode andobtaintraectory $\\big(x_{1}^{(t)},a_{1}^{(t)},r_{1}^{(t)}\\big),\\dots,\\big(x_{H}^{(t)},a_{H}^{(t)},r_{H}^{(t)}\\big).$ 4: Uupdate datase: $\\mathcal{D}_{h}^{(t)}\\leftarrow\\mathcal{D}_{h}^{(t-1)}\\cup\\left\\{\\left(x_{h}^{(t)},a_{h}^{(t)},x_{h+1}^{(t)}\\right)\\right\\}\\,\\,\\forall h\\in[\\bar{H}]$ \uff1a 5: Compute confidence set: ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{F}^{(t)}\\leftarrow\\Bigg\\{f\\in\\mathcal{F}:\\mathcal{L}_{h}^{(t)}(f_{h},f_{h+1})-\\underset{g_{h}\\in\\mathcal{G}_{h}}{\\operatorname*{min}}\\mathcal{L}_{h}^{(t)}(g_{h},f_{h+1})\\leq\\beta\\;\\;\\forall h\\in[H]\\Bigg\\},}\\\\ &{\\mathrm{ere}\\;}&{\\mathcal{L}_{h}^{(t)}(f,f^{\\prime}):=\\underset{(x,a,r,x^{\\prime})\\in\\mathcal{D}_{h}^{(t)}}{\\sum}\\Big(f(x,a)-r-\\underset{a^{\\prime}\\in\\mathcal{A}}{\\operatorname*{max}}f^{\\prime}(x^{\\prime},a^{\\prime})\\Big)^{2},\\;\\forall f,f^{\\prime}\\in\\mathcal{F}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "6: end for   \n7: Output $\\widehat{\\pi}=\\mathsf{U n i f}\\left(\\pi^{(1:T)}\\right)$ ", "page_idx": 46}, {"type": "text", "text": "Proofof Lemma F.3. For each $f_{h+1}$ E Fh+1, let  apx[ fh] ar $\\begin{array}{r l}{\\small}&{{}\\operatorname{g\\,min}_{g_{h}\\in\\mathcal{G}_{h}}\\operatorname*{sup}_{\\pi\\in\\Pi}\\mathbb{E}^{\\pi}\\left[\\left(g_{h}-\\mathcal{T}_{h}f_{h+1}\\right)^{2}\\right]}\\end{array}$ . Let ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\delta_{h}^{(t)}(\\cdot,\\cdot):=f_{h}^{(t)}(\\cdot,\\cdot)-\\mathcal{T}_{f}f_{h+1}^{(t)}(\\cdot,\\cdot)\\quad\\&\\quad\\widetilde{\\delta}_{h}^{(t)}(\\cdot,\\cdot):=f_{h}^{(t)}(\\cdot,\\cdot)-\\mathsf{a p x}\\big[f_{h+1}^{(t)}\\big]\\big(\\cdot,\\cdot\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "and note that by Jensen's inequality we have that for all $\\begin{array}{r}{\\pi,\\,\\mathbb{E}^{\\pi}\\left[\\delta_{h}^{(t)}(\\cdot,\\cdot)\\right]\\,\\le\\,\\mathbb{E}^{\\pi}\\left[\\widetilde{\\delta}_{h}^{(t)}(\\cdot,\\cdot)\\right]\\,+\\,\\varepsilon_{\\mathsf{a p x}}.}\\end{array}$ We further adopt the shorthand $d_{h}^{(t)}(x,a)\\;:=\\;d_{h}^{\\pi^{(t)}}(x,a)$ and $\\begin{array}{r}{\\tilde{d}_{h}^{(t)}(x,a)\\;:=\\;\\sum_{i<t}d_{h}^{(t)}(x,a)}\\end{array}$ As a consequence of realizability $(Q_{\\mathsf{o b s},h}^{\\star}\\,\\in\\,\\mathcal{F}_{h})$ andapproximateBelmacompleteness standad concentration arguments (proved in the sequel) lead to the following result. ", "page_idx": 46}, {"type": "text", "text": "Lemma F.4 (Optimism and small in-sample squared Bellman errors). With probability at least $1-\\delta$ by taking $\\beta=\\bar{c}\\log(T H|\\mathcal{F}||\\mathcal{G}|/\\delta)+T\\bar{\\varepsilon_{\\mathsf{a p x}}}$ wehavethat for all $t\\in[T]$ ", "page_idx": 46}, {"type": "equation", "text": "$$\n(i)\\ Q_{\\mathrm{obs},h}^{\\star}\\in{\\mathscr F}^{(t)},\\quad a n d\\quad(i i)\\ \\sum_{x,a}\\tilde{d}_{h}^{(t)}(x,a)\\Bigl(\\widetilde{\\delta}_{h}^{(t)}(x,a)\\Bigr)^{2}\\leq\\mathcal{O}(\\beta).\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "The rest of the proof proceeds similarly to the analysis of Section 3.2 in Xie et al. [XFBJK23]. Namely, by optimism (Lemma F.4) and a standard Bellman error decomposition (Lemma C.6) we have ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\mathsf{R e g}\\leq\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}_{d_{h}^{(t)}}\\left[\\delta_{h}^{(t)}(x,a)\\right]\\leq T H\\cdot\\varepsilon_{\\mathsf{a p x}}+\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}_{d_{h}^{(t)}}\\left[\\widetilde{\\delta}_{h}^{(t)}(x,a)\\right].\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Let us defining the burn-in time ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\tau_{h}(x,a)=\\operatorname*{min}\\{t\\mid\\tilde{d}_{h}^{(t)}(x,a)\\geq C_{\\mathsf{c o v}}\\mu_{h}^{\\star}(x,a)\\},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where $\\mu_{h}^{\\star}$ is the coverability distribution for the set of policies $\\Pi_{\\mathcal{F}}$ (i.e., the distribution $\\mu_{h}^{\\star}$ that achieves the minimum in the coverability definition). Using the same decomposition into \u201cburn-in phase\" and \u201cstable phase in Xie et al. [XFBJK23], we have: ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}_{d_{h}^{(t)}}\\Big[\\widetilde{\\delta}_{h}^{(t)}(x,a)\\Big]\\leq2H C_{\\mathrm{cov}}+\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}_{d_{h}^{(t)}}\\Big[\\widetilde{\\delta}_{h}^{(t)}(x,a)\\mathbb{I}\\{t\\geq\\tau_{h}(x,a)\\}\\Big].\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Applying a change of measure argument on the second term then gives: ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}_{d_{h}^{(t)}}\\left[\\widetilde{\\delta}_{h}^{(t)}(x,a)\\mathbb{I}\\{t\\geq\\tau_{h}(x,a)\\}\\right]\\leq H\\underbrace{\\sqrt{\\displaystyle\\sum_{t=1}^{T}\\sum_{x,a}\\frac{\\left(\\mathbb{I}\\{t\\geq\\tau_{h}(x,a)\\}d_{h}^{(t)}(x,a)\\right)^{2}}{\\tilde{d}_{h}^{(t)}(x,a)}}}_{(\\Lambda)}}\\\\ &{\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times\\underbrace{\\sqrt{\\displaystyle\\sum_{t=1}^{T}\\sum_{x,a}\\tilde{d}_{h}^{(t)}(x,a)\\left(\\widetilde{\\delta}_{h}^{(t)}(x,a)\\right)^{2}}}_{(\\displaystyle)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "By the same reasoning as in Xie et al. [XFBJK23], we have (A) $\\leq\\mathcal{O}(\\sqrt{C_{\\mathsf{c o v}}\\log(T)})$ ,and by Lemma F.4 we have (B) $\\leq{\\mathcal{O}}({\\sqrt{\\beta T}})$ .Using that $\\beta=\\log(T H|\\mathcal{F}|/\\delta)+T\\varepsilon_{\\mathsf{a p x}}^{2}$ gives the desired result. It remains to establish the concentration results of Lemma F.4. \u53e3 ", "page_idx": 47}, {"type": "text", "text": "Proof of Lemma F.4. For any function $f$ , define a random variable ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "$X_{t}(h,f)=\\big(f_{h}(s_{h}^{(t)},a_{h}^{(t)})-r_{h}^{(t)}-f_{h+1}(s_{h+1}^{(t)})\\big)^{2}-\\big(7h f_{h+1}(s_{h}^{(t)},a_{h}^{(t)})-r_{h}^{(t)}-f_{h+1}(s_{h+1}^{(t)})\\big)^{2}.$ Let $\\mathfrak{F}_{t,h}=\\{s_{1}^{(i)},a_{1}^{(i)},r_{1}^{(i)},\\ldots,s_{H}^{(i)},a_{H}^{(i)},r_{H}^{(i)}\\}_{i<t}.$ Note that ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\mathbb{E}\\big[r_{h}^{(t)}+f_{h+1}\\big(s_{h+1}^{(t)}\\big)\\mid\\mathfrak{F}_{t,h}\\big]=\\mathbb{E}^{\\pi^{(t)}}[\\mathcal{T}_{h}f\\big(s_{h},a_{h}\\big)].\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "and thus that ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\mathbb{E}[X_{t}(h,f)\\mid\\mathfrak{F}_{t,h}]=\\mathbb{E}^{\\pi^{(t)}}\\Big[\\big(f_{h}\\big(s_{h},a_{h}\\big)-\\mathcal{T}_{h}f_{h}\\big(s_{h},a_{h}\\big)\\big)^{2}\\Big].\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Next, note that ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{'\\mathsf{a r}[X_{t}(h,f)\\mid\\mathfrak{F}_{t,h}]\\le\\mathbb{E}\\Bigl[(X_{t}(h,f))^{2}\\mid\\mathfrak{F}_{t,h}\\Bigr]}\\\\ &{\\le\\mathbb{E}\\Bigl[\\bigl(f_{h}(s_{h}^{(t)},a_{h}^{(t)})-\\mathcal{T}_{h}f_{h}(s_{h}^{(t)},a_{h}^{(t)})\\bigr)^{2}\\bigl(f_{h}(s_{h}^{(t)},a_{h}^{(t)})+\\mathcal{T}_{h}f_{h}(s_{h}^{(t)},a_{h}^{(t)})+2\\bigl(r_{h}^{(t)}-f_{h+1}(s_{h+1}^{(t)})\\bigr)\\bigr)^{2}\\mid\\mathfrak{F}_{t}}\\\\ &{\\le16\\mathbb{E}\\Bigl[\\bigl(f_{h}(s_{h}^{(t)},a_{h}^{(t)})-\\mathcal{T}_{h}f_{h}(s_{h}^{(t)},a_{h}^{(t)})\\bigr)^{2}\\mid\\mathfrak{F}_{t,h}\\Bigr]=16\\,\\mathbb{E}[X_{t}(h,f)\\mid\\mathfrak{F}_{t,h}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "By Freedman's inequality (Lemma C.2, Lemma C.3), we have that with probability at least $1-\\delta$ ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\left|\\sum_{i<t}X_{i}(h,f)-\\sum_{i<t}\\mathbb{E}[X_{i}(h,f)\\mid\\mathfrak{F}_{i,h}]\\right|\\leq\\mathcal{O}\\left(\\sqrt{\\log(1/\\delta)\\sum_{i<t}\\mathbb{E}[X_{i}(h,f)\\mid\\mathfrak{F}_{i,h}]}+\\log(1/\\delta)\\right)\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Taking a union bound over $[T]\\times[H]\\times{\\mathcal{F}}$ , we have that for all $t,h,f$ , with probability at least $1-\\delta$ ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\left\\lvert\\sum_{i<t}X_{i}(h,f)-\\sum_{i<t}\\mathbb{E}^{\\pi^{(i)}}\\left[(f_{h}(s_{h},a_{h})-\\mathcal{T}_{h}f_{h}(s_{h},a_{h}))^{2}\\right]\\right\\rvert}\\\\ &{\\quad\\quad\\leq\\mathcal{O}\\left(\\sqrt{\\displaystyle\\sum_{i<t}\\mathbb{E}^{\\pi^{(i)}}\\left[(f_{h}(s_{h},a_{h})-\\mathcal{T}_{h}f_{h}(s_{h},a_{h}))^{2}\\right]}+\\iota\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "where $\\iota=\\log(|\\mathcal{F}|H T/\\delta)$ . We now show that ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\sum_{i<t}X_{i}(h,f^{(t)})\\leq\\beta+\\mathcal{O}\\big(T\\varepsilon_{\\mathsf{a p x}}^{2}+\\iota\\big)=\\mathcal{O}(\\beta),\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "which will imply, from Eq. (46), that ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\sum_{i<t}\\mathbb{E}^{\\pi^{(t)}}\\Big[\\big(f_{h}\\big(s_{h},a_{h}\\big)-\\mathcal{T}_{h}f_{h}\\big(s_{h},a_{h}\\big)\\big)^{2}\\Big]\\leq\\mathcal{O}(\\iota+\\beta)=\\mathcal{O}(\\beta),\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "as desired. To see Eq. (47), let ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\lambda_{t}=\\sum_{i<t}\\bigl(\\mathsf{a p x}\\bigl[\\mathcal{T}_{h}f_{h+1}^{(t)}\\bigr]\\bigl(s_{h}^{(i)},a_{h}^{(i)}\\bigr)-r_{h}^{(i)}-f_{h+1}^{(t)}\\bigl(s_{h+1}^{(i)}\\bigr)\\bigr)^{2}-\\bigl(\\mathcal{T}_{h}f_{h}^{(t)}\\bigl(s_{h}^{(i)},a_{h}^{(i)}\\bigr)-r_{h}^{(i)}-f_{h+1}^{(t)}\\bigl(s_{h+1}^{(i)}\\bigr)\\bigr)^{2}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "and then note that: ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{i\\in\\{I\\}}X_{i}(h,f^{(i)})=\\displaystyle\\sum_{i<t}(f_{h}^{(i)}(s_{h}^{(i)},a_{h}^{(i)})-r_{h}^{(i)}-f_{h+1}^{(i)}(s_{h+1}^{(i)}))^{2}-\\left(\\mathcal{T}_{h}f_{h}^{(i)}(s_{h}^{(i)},a_{h}^{(i)})-r_{h}^{(i)}-f_{h+1}^{(i)}(s_{h+1}^{(i)})\\right.}\\\\ {\\displaystyle=\\displaystyle\\sum_{i<t}(f_{h}^{(i)}(s_{h}^{(i)},a_{h}^{(i)})-r_{h}^{(i)}-f_{h+1}^{(i)}(s_{h+1}^{(i)}))^{2}}\\\\ &{\\qquad\\qquad\\left.-\\sum_{i<t}(\\mathrm{aps}\\big[\\mathcal{T}_{h}f_{h+1}^{(i)}\\big]\\big(s_{h}^{(i)},a_{h}^{(i)}\\big)-r_{h}^{(i)}-f_{h+1}^{(i)}\\big(s_{h+1}^{(i)}\\big)\\right)^{2}+\\Delta_{t}}\\\\ {\\le\\displaystyle\\sum_{i<t}(f_{h}^{(i)}(s_{h}^{(i)},a_{h}^{(i)})-r_{h}^{(i)}-f_{h+1}^{(i)}\\big(s_{h+1}^{(i)}\\big))^{2}}\\\\ &{\\qquad\\qquad\\cdot\\mathrm{inf~\\ensuremath{\\sum_{j\\in\\{h_{i}\\}\\in\\{\\mathscr{G}_{h}^{(i)},\\mathscr{a}_{h}^{(i)}\\}}-r_{h}^{(i)}-f_{h+1}^{(i)}\\big(s_{h+1}^{(i)}\\big)\\big)^{2}+\\Delta_{t}}}\\\\ &{<\\beta+\\Delta_{t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "where the second-to-last line follows from $\\mathsf{a p x}\\!\\left[\\mathcal{T}_{h}f_{h+1}^{(t)}\\right]\\,\\in\\,\\mathcal{G}$ and the last line follows from the definition of the confidence set. It remains to show that $\\Delta_{t}\\,\\leq\\,\\mathcal{O}(T\\varepsilon_{\\mathsf{a p x}}^{2}+\\iota)$ , which we do via a similar concentration argument. Namely, let ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\check{\\tau}_{t}(h,f)=\\big(\\mathsf{a p x}[\\mathcal{T}_{h}f_{h+1}]\\big(s_{h}^{(t)},a_{h}^{(t)}\\big)-r_{h}^{(t)}-f_{h+1}^{(k)}\\big(s_{h+1}^{(t)}\\big)\\big)^{2}-\\big(\\mathcal{T}_{h}f_{h}\\big(s_{h}^{(t)},a_{h}^{(t)}\\big)-r_{h}^{(t)}-f_{h+1}^{(k)}\\big(s_{h+1}^{(t)}\\big)\\big)^{2},\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "and note that, as before, ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\mathbb{E}[Y_{t}(h,f)\\mid\\mathfrak{F}_{t,h}]=\\mathbb{E}^{\\pi^{(t)}}\\Big[\\big(\\mathsf{a p x}[\\mathcal{T}_{h}f_{h+1}]\\big(s_{h},a_{h}\\big)-\\mathcal{T}_{h}f_{h}\\big(s_{h},a_{h}\\big)\\big)^{2}\\Big],\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "and ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\mathsf{V a r}[Y_{t}(h,f)\\mid\\mathfrak{F}_{t,h}]\\le16\\,\\mathbb{E}[Y_{t}(h,f)\\mid\\mathfrak{F}_{t,h}],\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "by the same calculation as earlier. Thus, by Freedman's inequality and a union bound, we have that, with probability at least $1-\\delta$ ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\displaystyle\\sum_{i<t}Y_{t}(h,f)-\\displaystyle\\sum_{i<t}\\mathbb{E}^{\\pi^{(t)}}\\left[(\\mathbf{apx}[\\mathcal{T}_{h}f_{h+1}](s_{h},a_{h})-\\mathcal{T}_{h}f_{h}(s_{h},a_{h}))^{2}\\right]\\right|}\\\\ &{\\le\\mathcal{O}\\left(\\sqrt{\\displaystyle\\sum_{i<t}\\mathbb{E}^{\\pi^{(t)}}\\left[(\\mathbf{apx}[\\mathcal{T}_{h}f_{h+1}](s_{h},a_{h})-\\mathcal{T}_{h}f_{h}(s_{h},a_{h}))^{2}\\right]}+\\iota\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "where $\\iota=\\log(|\\mathcal{F}|H T/\\delta)$ . Recalling the misspecification assumption, this implies that ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\sum_{i<t}Y_{t}(h,f)\\leq\\mathcal{O}\\big(t\\varepsilon_{\\mathsf{a p x}}^{2}+\\iota\\big),\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "for all $h,f,t$ , with high probability. This concludes the result for $(i i)$ .For $(i)$ , this follows identically to the proof of Lemma 40 in Jin et al. [JLM21], since this only uses the property that $Q^{\\star}\\in{\\mathcal{F}}$ ", "page_idx": 48}, {"type": "text", "text": "F.2.3  Sample-efficient latent-dynamics RL under pushforward coverability ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "We conclude by combining the previous two results to obtain the main result for this section. ", "page_idx": 48}, {"type": "text", "text": "Theorem 3.2 (Pushforward-coverable MDPs are statistically modular). Let $\\mathcal{M}_{\\mathrm{{lat}}}$ be a base MDP class such that each $M_{\\mathrm{{lat}}}\\in\\mathcal{M}_{\\mathrm{{lat}}}$ has pushforward coverability bounded by $C_{\\mathsf{p u s h}}(M_{\\mathsf{l a t}})\\leq C_{\\mathsf{p u s h}}$ Then, for any decoder class $\\Phi$ ,we have: ", "page_idx": 48}, {"type": "equation", "text": "$\\begin{array}{r}{\\mathrm{comp}(\\mathcal{M}_{\\mathrm{1at}},\\varepsilon,\\delta)\\leq\\mathsf{p o l y}(C_{\\mathsf{p u s h}},|A|,H,\\log|\\mathcal{M}_{\\mathrm{1at}}|,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr)),\\,a n}\\end{array}$ ", "text_format": "latex", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{comp}(\\langle\\!\\langle M_{1\\mathrm{at}},\\Phi\\rangle\\!\\rangle,\\varepsilon,\\delta)\\leq\\mathsf{p o l y}(C_{\\mathsf{p u s h}},|\\mathcal{A}|,H,\\log|\\mathcal{M}_{1\\mathrm{at}}|,\\log|\\Phi|\\!\\rangle,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr),\\log\\log|\\mathcal{S}|).}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "Proof of Theorem 3.2. Let $M_{\\sf o b s}^{\\star}:=\\langle\\!\\langle M_{\\sf l a t}^{\\star},\\psi^{\\star}\\rangle\\!\\rangle\\in\\langle\\!\\langle M_{\\sf l a t},\\Phi\\rangle\\!\\rangle$ be the unknown latent-dynamics MDP. Define observation-level value functions ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\mathcal{F}=\\{Q^{M_{\\mathrm{lat}},\\star}\\circ\\phi\\ |\\ M_{\\mathrm{lat}}\\in\\mathcal{M}_{\\mathrm{lat}},\\phi\\in\\Phi\\},\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "so that $Q^{M_{\\mathrm{obs}}^{\\star},\\star}=Q^{M_{\\mathrm{lat}}^{\\star},\\star}\\circ\\phi^{\\star}\\in\\mathcal{F}$ via decoder and model realizability, and $\\log\\lvert\\mathcal{F}_{h}\\rvert\\le\\,\\log\\lvert\\mathcal{M}_{\\mathrm{lat}}\\rvert\\rvert\\Phi\\rvert$ Consider any function class $\\mathcal{L}\\subseteq\\{S\\to[0,1]\\}$ and MDP $M_{\\mathrm{{lat}}}\\,=\\,\\left(r_{\\mathrm{{lat}}},P_{\\mathrm{{lat}}}\\right)$ . For a given value $\\varepsilon_{\\mathsf{a p x}}>0$ , setting $d$ according to Lemma F.1 implies that there exists a $d$ -dimensional feature map $\\dot{\\varphi}_{M_{1a},h}(s,a)\\in\\mathbb R^{d+1}$ such that for all $\\ell\\in{\\mathcal{L}}$ and $h\\in[H]$ , there exists $w_{\\ell,h}\\in\\mathbb{R}^{d+1}$ such that ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mu_{M_{\\mathrm{lat}}}\\otimes\\mathsf{U n i f}(A)}\\bigg[\\Big(\\mathrm{c}1\\,\\mathrm{i}\\,\\mathrm{p}_{[0,2]}\\big[\\big\\langle\\varphi_{M_{\\mathrm{lat}},h}(s,a),w_{\\ell,h}\\big\\rangle\\big]-\\mathcal{T}_{h}^{M_{\\mathrm{lat}}}\\ell_{h+1}(s,a)\\Big)^{2}\\bigg]\\leq\\varepsilon_{\\mathsf{a p x}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where $\\mu_{M_{\\mathrm{1at}}}$ is the pushforward coverability distribution for $M_{\\mathrm{lat}}$ . Moreover, the map $\\varphi_{h}$ is explicitly computed as a function of $M_{\\mathrm{lat}}$ by a randomized algorithm with success probability $1-\\delta$ ,with no knowledge of the class $\\mathcal{L}$ required. We consider the class ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\mathcal{L}=\\left\\{\\Gamma_{\\phi}\\circ Q^{M_{\\mathrm{lat}},\\star}(s,a):=\\sum_{s^{\\prime}\\in\\mathcal{S}}\\Gamma_{\\phi}(s^{\\prime}\\mid s)Q^{M_{\\mathrm{lat}},\\star}(s^{\\prime},a)\\mid\\phi\\in\\Phi,M_{\\mathrm{lat}}\\in\\mathcal{M}_{\\mathrm{lat}}\\right\\},\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where $\\Gamma_{\\phi}\\;:\\;{\\mathcal{S}}\\;\\rightarrow\\;\\Delta({\\mathcal{S}})$ is the mismatch function for decoder $\\phi$ and emission $\\psi^{\\star}$ , defined in Definition F.1. Note that $\\mathcal{L}$ has size $\\log\\lvert\\mathcal{L}\\rvert\\le\\log\\lvert\\mathcal{M}_{\\mathrm{1at}}\\rvert\\rvert\\Phi\\rvert$ , and that we have ", "page_idx": 49}, {"type": "equation", "text": "$$\nT_{h}^{M_{\\mathrm{obs}}^{\\star}}(Q_{h}^{M_{\\mathrm{lat}},\\star}\\circ\\phi_{h})(x,a)=T_{h}^{M_{\\mathrm{lat}}^{\\star}}(\\Gamma_{\\phi,h+1}\\circ V_{h}^{M_{\\mathrm{lat}},\\star})(\\phi_{h}^{\\star}(x),a)\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "by Lemma D.7. By Lemma D.1 we have that $\\mu_{M_{\\mathrm{obs}}^{\\star},h}(x)=\\psi_{h}^{\\star}(x\\mid\\phi_{h}^{\\star}(x))\\mu_{M_{\\mathrm{lat}}^{\\star},h}(\\phi_{h}^{\\star}(x))$ is the coverability distribution for MDP $M_{\\mathsf{o b s}}^{\\star}$ , and ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mu_{M_{\\mathrm{hat}}^{\\star}}\\otimes\\mathsf{U n i f}(A)}[f(s,a)]=\\mathbb{E}_{\\mu_{M_{\\mathrm{obs}}^{\\star}}\\otimes\\mathsf{U n i f}(A)}[f(\\phi^{\\star}(x),a)].\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Now, define ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat{\\iota}_{M_{10},h}=\\Big\\{({x,a})\\mapsto\\mathrm{clip}_{[0,2]}\\big[\\langle\\varphi_{M_{10},h}(\\phi(x),a),w\\rangle\\big]\\;|\\;\\phi\\in\\Phi,\\|w\\|_{2}^{2}\\leq11+16\\log(|\\mathcal{M}_{1\\mathrm{at}}||\\Phi|H)\\Big\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Recall the definition of $w_{f}$ (for $f\\,:\\,S\\,\\times\\,A\\,\\rightarrow\\,[0,1])$ from Lemma F.1, and note that by the norm bound $\\begin{array}{r}{\\operatorname*{max}_{\\ell\\in\\mathcal{L}}\\|w_{\\ell}\\|_{2}^{2}\\leq11+16\\log(|\\mathcal{M}_{\\mathrm{{lat}}}||\\Phi|H)}\\end{array}$ given by Lemma F.1, we have $(x,a)\\mapsto$ $\\left\\langle\\varphi_{M_{1a t},h}(\\phi(x),a),w_{\\ell}\\right\\rangle\\in\\overbar{\\mathcal{G}_{h}}$ for every $\\ell\\in{\\mathcal{L}}$ Next, note that by the norm bound $\\mathrm{max}_{s,a}\\|\\psi(s,a)\\|_{2}^{2}\\leq$ $C_{\\mathsf{p u s h}}(11+16\\log(|S||A|H))$ , given by Lemma F.1, we have every $g_{h}\\in\\mathcal{G}_{M_{\\mathrm{lat}},h}$ satisfies $\\begin{array}{r}{\\|g_{h}\\|_{\\infty}\\leq}\\end{array}$ $c C_{\\mathsf{p u s h}}^{1/2}\\log(|\\mathcal{M}_{\\mathrm{1at}}||\\Phi||S||A|H)\\,:=\\,B$ for some absolte constant $c$ Therefore, $\\mathcal{G}_{M_{\\mathrm{lat}},h}$ has size $\\log\\lvert\\mathcal{G}_{M_{\\mathrm{lat}},h}\\rvert\\leq\\tilde{O}(d\\cdot\\log(B)+\\log\\lvert\\Phi\\rvert)=\\tilde{O}(d\\log\\log(\\lvert S\\rvert)+\\log\\lvert\\Phi\\rvert)$ , where the $\\widetilde O$ notation ignores logarithmic factors of $C_{\\mathsf{p u s h}},|\\mathcal{A}|,\\log|\\mathcal{M}_{\\mathsf{l a t}}|$ , and $\\log\\!|\\Phi|$ 22 Define $\\mathcal{G}_{h}=\\cup_{M_{\\mathrm{{lat}}}\\in\\mathcal{M}_{\\mathrm{{lat}}}}\\mathcal{G}_{M_{\\mathrm{{lat}}},h}$ which has size $\\log\\lvert\\mathcal{G}_{h}\\rvert\\leq\\log\\lvert M_{\\mathrm{1at}}\\rvert+(\\tilde{O}(d\\log\\log(\\lvert S\\rvert)+\\log\\lvert\\Phi\\rvert))$ . Together, these results with Lemma F.1 imply that for all $f_{h+1}\\in\\mathcal{F}_{h+1}$ , there exists $g_{h}\\in\\mathcal{G}_{h}$ such that ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mu_{M_{\\mathrm{obs}}^{\\star},h}\\otimes\\mathsf{U n i f}(A)}\\bigg[\\Big(g_{h}\\big(x_{h},a_{h}\\big)-\\Big[\\mathcal{T}_{h}^{M_{\\mathrm{obs}}^{\\star}}f_{h+1}\\Big]\\big(x_{h},a_{h}\\big)\\Big)^{2}\\bigg]\\le\\varepsilon_{\\mathsf{a p x}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "This, in turn, implies that for all $\\pi_{\\mathsf{o b s}}\\in\\Pi_{\\mathsf{r n s}}$ we have ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}^{\\pi_{\\mathrm{obs}}}\\bigg[\\Big(g_{h}(x_{h},a_{h})-\\Big[\\mathcal{T}_{h}^{M_{\\mathrm{obs}}^{\\star}}f_{h+1}\\Big](x_{h},a_{h})\\Big)^{2}\\bigg]\\leq C_{\\mathrm{push}}|\\mathcal{A}|\\varepsilon_{\\mathrm{apx}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "since $\\mu_{M_{\\tt o b s}^{\\star},h}\\otimes\\mathsf{U n i f}(A)$ satisfies coverability (Definition D.3) with parameter $C_{\\mathsf{c o v}}(M_{\\mathsf{o b s}}^{\\star},\\Pi_{\\mathsf{r n s}})\\leq$ $C_{\\mathsf{p u s h}}|\\mathcal{A}|$ (Eq. (29). ", "page_idx": 49}, {"type": "text", "text": "Then, it follows by Lemma F.3 that if we run Algorithm 2 with the classes $\\mathcal{F}$ and $\\mathcal{G}$ we will get ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{1}\\mathsf{e g}\\le H\\sqrt{C_{\\mathrm{push}}|\\mathcal{A}|T\\log(|\\mathcal{M}_{1\\mathrm{at}}||\\Phi|H T/\\delta)(d\\log\\log(|\\mathcal{S}|)+\\log|\\Phi|)}+H T\\sqrt{C_{\\mathrm{push}}^{2}|\\mathcal{A}|^{2}\\log(T)\\varepsilon_{\\mathsf{a p s}}}}\\\\ &{\\quad\\le H\\sqrt{C_{\\mathrm{push}}^{5}|\\mathcal{A}|T\\log(|\\mathcal{M}_{1\\mathrm{at}}||\\Phi|H T/\\delta)}\\frac{\\log\\left(C_{\\mathrm{push}}^{2}|\\mathcal{M}_{1\\mathrm{at}}||\\Phi|^{2}H\\delta^{-1}/\\varepsilon_{\\mathsf{a p x}}\\right)\\log\\log(|\\mathcal{S}|)}{\\varepsilon_{\\mathsf{a p x}}}}\\\\ &{\\qquad\\qquad+\\,H T\\sqrt{C_{\\mathrm{push}}^{2}|\\mathcal{A}|^{2}\\log(T)\\varepsilon_{\\mathsf{a p x}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Choosing $\\begin{array}{r}{\\varepsilon_{\\mathsf{a p x}}=\\frac{1}{\\sqrt{T}}}\\end{array}$ to balance leads to ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{R e g}\\lesssim H T^{3/4}\\sqrt{C_{\\mathrm{push}}^{5}|A|\\log(|\\mathcal{M}_{\\mathrm{1at}}||\\Phi|H T/\\delta)\\log\\bigl(C_{\\mathrm{push}}^{2}|\\mathcal{M}_{\\mathrm{1at}}||\\Phi|^{2}H\\delta^{-1}T\\bigr)\\log\\log(|\\mathcal{S}|)}}\\\\ &{\\qquad\\qquad+\\ H T^{3/4}\\sqrt{C_{\\mathrm{push}}^{2}|A|^{2}\\log(T)}}\\\\ &{\\qquad\\lesssim H T^{3/4}\\sqrt{C_{\\mathrm{push}}^{5}|A|^{2}\\log(|\\mathcal{M}_{\\mathrm{1at}}||\\Phi|H T/\\delta)\\log\\bigl(T C_{\\mathrm{push}}^{2}|\\mathcal{M}_{\\mathrm{1at}}||\\Phi|^{2}H/\\delta\\bigr)\\log\\log(|S|)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "which gives a risk bound of ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\mathtt{R i s k}\\lesssim\\frac{1}{T^{1/4}}H\\sqrt{C_{\\mathrm{push}}^{5}|\\mathcal{A}|^{2}\\log(|\\mathcal{M}_{\\mathrm{1}\\mathrm{{at}}}||\\Phi|H T/\\delta)\\log\\bigl(T C_{\\mathrm{push}}^{2}|\\mathcal{M}_{\\mathrm{1}\\mathrm{{at}}}||\\Phi|^{2}H/\\delta\\bigr)\\log\\log(|\\mathcal{S}|)}.\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "Equating this to $\\varepsilon$ gives a sample complexity of ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r}{T=\\mathsf{p o l y}(C_{\\mathrm{push}},A,H,\\log|\\mathcal{M}_{\\mathrm{1at}}|,\\log|\\Phi|,\\varepsilon^{-1},\\log\\bigl(\\delta^{-1}\\bigr),\\log\\log(|\\mathcal{S}|)),}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "as desired. Note that we have not made much effort to optimize the rate; in particular, a faster rate is likely possible by using the GOLF.DBR algorithm of Amortila et al. [ACK24], which improves over the GoLF algorithm under the presence of misspecification. \u53e3 ", "page_idx": 50}, {"type": "text", "text": "G Proofs and Additional Information for Section 4.1: Hindsight RL ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "This appendix contains additional information and proofs related to algorithmic modularity under hindsight observations (Section 4.1), and is organized as follows: ", "page_idx": 51}, {"type": "text", "text": "\u00b7 Appendix G.1 contains the pseudocode and proofs related to the online representation learning Oracle ExPWEIGHTS.DR (Lemma 4.1).   \n\u00b7 Appendix G.2 contains the proof for our risk bound of the O2L algorithm under hindsight observability (Theorem 4.1). ", "page_idx": 51}, {"type": "text", "text": "G.1 Pseudocode and Proofs for ExPWEIGHTs.DR (Lemma 4.1) ", "page_idx": 51}, {"type": "text", "text": "Algorithm 3 Derandomized Exponential Weights (ExPWEIGHTs.DR) input: Decoder set $\\Phi$ for $t=1,2,\\cdots,T$ do Get datae (rl, \\*(2l) ie(t-1,h(H) for $h=1,\\ldots,H$ do For $\\phi\\in\\Phi$ , compute $q_{h}^{(t)}(\\phi_{h})\\propto\\exp\\mathopen{}\\mathclose\\bgroup\\mathopen{}\\mathclose\\bgroup\\mathopen{}\\mathclose\\bgroup\\mathopen{}\\mathclose\\bgroup\\mathopen{}\\mathclose\\bgroup\\mathopen{}\\mathclose\\bgroup\\mathopen{}\\mathclose\\bgroup\\mathopen{}\\mathclose\\bgroup\\mathopen{}\\mathclose\\bgroup\\mathopen{}\\mathclose\\bgroup\\mathopen{}\\mathclose\\bgroup\\left(-\\sum_{i=1}^{t-1}\\mathbb{I}\\bigl[\\phi_{h}(x_{h}^{(i)})\\not\\to\\phi_{h}^{\\star}(x_{h}^{(i)})\\bigr]\\aftergroup\\egroup\\aftergroup\\egroup\\aftergroup\\egroup\\aftergroup\\egroup\\aftergroup\\egroup\\aftergroup\\egroup\\aftergroup\\egroup\\aftergroup\\egroup\\aftergroup\\egroup\\aftergroup\\egroup\\aftergroup\\egroup\\aftergroup\\egroup\\right),$ and set $\\bar{\\phi}_{h}^{(t)}(x)=\\underset{s\\in\\cal S}{\\arg\\operatorname*{max}}\\,\\mathbb{P}_{\\phi_{h}\\sim q_{h}^{(t)}}(\\phi_{h}(x)=s).$ (52) end for Retum $\\bar{\\phi}^{(t)}=\\{\\bar{\\phi}_{h}^{(t)}\\}_{h=1}^{H}$ end for ", "page_idx": 51}, {"type": "text", "text": "The main result for this estimator is the following. ", "page_idx": 51}, {"type": "text", "text": "Lemma 4.1 (Online classification via ExPWEIGHTs.DR). Under decoder realizability $(\\phi^{\\star}\\in\\Phi)$ EXPWEIGHTs.DR (Algorithm 3) satisfies Assumption $4.2\\;w i t h^{23}$ ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\mathsf{E s t}_{\\mathsf{c l a s s}}(T)=\\widetilde{\\mathcal{O}}(H\\log|\\Phi|).\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "Proof of Lemma 4.1. For each $h\\in[H]$ , consider the realizable online classification problem where $x_{h}^{(t)}\\sim d_{h}^{\\pi^{(t)}}$ , for $\\pi^{(t)}$ chosen adversarially, and $y_{h}^{(t)}=\\phi_{h}^{\\star}(x_{h}^{(t)})$ . Consider the exponential weights estimator ", "page_idx": 51}, {"type": "equation", "text": "$$\nq_{h}^{(t)}(\\phi)\\propto\\exp\\left(-\\sum_{i=1}^{t-1}\\mathbb{I}\\big[\\phi(x_{h}^{(i)})\\neq\\phi_{h}^{\\star}(x_{h}^{(i)})\\big]\\right).\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "For every sequence $(x_{h}^{(t)})_{t=1}^{T}$ , these distributions satisfy the deterministic regret bound ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\mathbb{E}_{\\widehat{\\phi}_{h}^{(t)}\\sim q_{h}^{(t)}}\\left[\\mathbb{I}\\!\\left[\\widehat{\\phi}_{h}^{(t)}(x_{h}^{(t)})\\neq\\phi_{h}^{\\star}(x_{h}^{(t)})\\right]\\right]\\leq2\\log|\\Phi|,\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "by Corllary 2.3 o CesaBianchi etal [CBL6] Taking conditional expectations ovr and using Lemma C.3 gives that with probability at least $1-\\delta$ $x_{h}^{(t)}\\sim d_{h}^{\\pi^{(t)}}$ ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\mathbb{E}_{\\widehat{\\phi}_{h}^{(t)}\\sim q_{h}^{(t)}}\\mathbb{E}^{\\pi^{(t)}}\\left[\\mathbb{I}\\Big[\\widehat{\\phi}_{h}^{(t)}(x_{h})\\neq\\phi_{h}^{\\star}(x_{h})\\Big]\\right]\\leq4\\log\\left|\\Phi\\right|+8\\log\\bigl(2\\delta^{-1}\\bigr).\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "Taking a union bound over $h\\in[H]$ and summing over $h\\in[H]$ we obtain that with probability at least $1-\\delta$ ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}_{\\widehat{\\phi}_{h}^{(t)}\\sim q_{h}^{(t)}}\\mathbb{E}^{\\pi^{(t)}}\\left[\\mathbb{I}\\Big[\\widehat{\\phi}_{h}^{(t)}(x_{h})\\neq\\phi_{h}^{\\star}(x_{h})\\Big]\\right]\\leq4H\\log\\vert\\Phi\\vert+8H\\log\\big(2H\\delta^{-1}\\big).\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "23In this section, the notations $\\widetilde{\\mathcal{O}},\\approx$ , and $\\lesssim$ ignore only constants and logarithmic factors of $H$ ", "page_idx": 51}, {"type": "text", "text": "Now, recall that at each time $t$ , we define the improper decoder $\\bar{\\phi}_{h}^{(t)}$ via: ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\bar{\\phi}_{h}^{(t)}(x)=\\arg\\operatorname*{max}_{s\\in\\mathcal{S}}\\mathbb{P}_{\\phi_{h}^{(t)}\\sim q_{h}^{(t)}}\\big(\\phi_{h}^{(t)}(x)=s\\big)\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Let $\\ell_{h}(x_{h},q_{h}^{(t)})=\\mathbb{P}_{\\phi_{h}^{(t)}\\sim q_{h}^{(t)}}(\\phi_{h}^{(t)}(x_{h})\\neq\\phi_{h}^{\\star}(x_{h}))$ (t) \\~g(t)(\u03a6t(xn) \u2260 \u03a6(ch)). Note that & satisfies ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{t=1}^{T}\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\phi_{h}^{(t)}\\sim q_{h}^{(t)}}\\mathbb{E}^{\\pi^{(t)}}\\left[\\mathbb{I}\\!\\left[\\phi_{h}^{(t)}(x_{h})\\neq\\phi_{h}^{\\star}(x_{h})\\right]\\right]=\\displaystyle\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{(t)}}\\mathbb{E}_{\\phi_{h}^{(t)}\\sim q_{h}^{(t)}}\\left[\\mathbb{I}\\!\\left[\\phi_{h}^{(t)}(x_{h})\\neq\\phi_{h}^{\\star}(x_{h})\\right]\\right]}\\\\ &{\\quad=\\displaystyle\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{(t)}}[\\ell_{h}(x_{h},q_{h}^{(t)})].}\\end{array}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "By abuse of notation we also denote $\\ell_{h}(x_{h},\\bar{\\phi}_{h})=\\mathbb{I}[\\bar{\\phi}_{h}(x)\\neq\\phi^{\\star}(x)]$ . We will show that ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\forall x,t,h:\\ell_{h}(x_{h},\\bar{\\phi}_{h}^{(t)})\\leq2\\ell_{h}(x_{h},q_{h}^{(t)}),\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "from which we will obtain that with probability at least $1-\\delta$ ", "page_idx": 52}, {"type": "equation", "text": "$$\n{\\mathsf{R e g}}_{\\mathrm{class}}(T)=\\sum_{t=1}^{T}\\sum_{h=1}^{H}{\\mathbb{E}}^{\\pi^{(t)}}\\left[\\mathbb{I}\\big[\\bar{\\phi}_{h}^{(t)}(x_{h})\\neq\\phi_{h}^{\\star}(x_{h})\\big]\\right]\\leq8H\\log|\\Phi|+16H\\log\\big(2H\\delta^{-1}\\big).\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Integrating the high-probability regret bound gives ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathsf{R e g}_{\\mathsf{c l a s s}}(T)]=\\mathcal{O}(H\\log(H|\\Phi|)),\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "as desired. Towards establishing Eq. (56), let us fix $x$ and let $s_{\\mathrm{max}}$ denote the argmax in Eq. (53). There are two cases: ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\phi_{h}^{(t)}\\sim q_{h}^{(t)}}\\bigl(\\phi_{h}^{(t)}(x)=s_{\\operatorname*{max}}\\bigr)\\geq\\frac{1}{2};\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "$\\rightarrow$ Otherwise, $s_{\\mathrm{max}}\\neq\\phi^{\\star}(x)$ and we have $\\ell(x,\\bar{\\phi}_{h}^{(t)})=1$ . However, since $\\phi^{\\star}(x)\\neq s_{\\mathrm{max}}$ we have $\\phi_{h}^{(t)}(x)=s_{\\mathrm{max}}\\implies\\phi_{h}^{(t)}(x)\\neq\\phi_{h}^{\\star}(x)$ and so ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\phi_{h}^{(t)}\\sim q_{h}^{(t)}}\\big(\\phi_{h}^{(t)}(x)\\neq\\phi_{h}^{\\star}(x)\\big)\\ge\\mathbb{P}_{\\phi_{h}^{(t)}\\sim q_{h}^{(t)}}\\big(\\phi_{h}^{(t)}(x)=s_{\\operatorname*{max}}\\big)\\ge\\frac{1}{2}=\\frac{1}{2}\\ell(x,\\bar{\\phi}_{h}^{(t)}).\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "$\\rightarrow$ Otherwise, $s_{\\mathrm{max}}\\neq\\phi^{\\star}(x)$ and we have $\\ell(x,\\bar{\\phi}_{h}^{(t)})=1$ . However, by definition of $s_{\\mathrm{max}}$ as the mode we also have ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\phi_{h}^{(t)}\\sim q_{h}^{(t)}}\\big(\\phi_{h}^{(t)}(x)=\\phi_{h}^{\\star}(x)\\big)\\le\\mathbb{P}_{\\phi_{h}^{(t)}\\sim q_{h}^{(t)}}\\big(\\phi_{h}^{(t)}(x)=s_{\\operatorname*{max}}\\big)<\\frac{1}{2},\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "so in particular we have ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\ell(x,q_{h}^{(t)})=\\mathbb{P}_{\\phi_{h}^{(t)}\\sim q_{h}^{(t)}}\\big(\\phi_{h}^{(t)}(x)\\neq\\phi_{h}^{\\star}(x)\\big)>\\frac{1}{2}=\\frac{1}{2}\\ell(x,\\bar{\\phi}_{h}^{(t)}).\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "G.2 Proofs for O2L Under Hindsight Observability (Theorem 4.1) ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Theorem 4.1 (Risk bound for $\\mathrm{O}2\\mathrm{L}$ under hindsight observability). Let $\\mathrm{ALG}_{\\mathrm{1at}}$ be abasealgorithm with base risk $\\mathsf{R i s k}_{\\star}(K)$ , and REPclass $a$ representation learning oracle satisfying Assumption 4.2. Then Algorithm $^{\\,l}$ with inputs $T,K,\\Phi$ $\\mathrm{REP}_{\\mathsf{c l a s s}}$ , and $\\mathrm{{ALG}_{\\mathrm{{lat}}}}$ , has expected risk ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathsf{R i}\\,\\mathsf{s k}_{\\mathsf{o b s}}(T K)]\\le\\mathsf{R i}\\,\\mathsf{s k}_{\\star}(K)+\\frac{2K}{T}\\mathsf{E s t}_{\\mathsf{c l a s s}}(T).\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Proof of Theorem 4.1. Let $(\\widehat{\\phi}^{(t)})_{t\\in[T]}$ denote the decoders chosen by $\\mathrm{REP}_{\\mathsf{c l a s s}}$ , and let $\\rho^{(t)}$ denote the distribution over decoders induced at time $t$ from the interaction of $\\mathrm{REP}_{\\mathsf{c l a s s}}$ $\\mathrm{ALG_{\\mathrm{1at}}}$ , and $M_{\\mathrm{obs}}^{\\star}$ Let $\\pi_{\\mathfrak{o b s}}^{(t,k)}:=\\pi_{\\mathrm{lat}}^{(t,k)}\\circ\\widehat{\\phi}^{(t)}$ di $p_{\\mathtt{o b s}}^{(t,k)}$ denotethedisuibuionoverobsevaionspael polie played at epoch $t$ and episode $k$ , induced by the interaction of \uff0c , and .We adopt the notation miat $\\pi_{\\mathrm{1at}}^{(t,\\bar{K}+1)}\\;:=\\;\\widehat{\\pi}_{\\mathrm{1at}}^{(t)}\\;\\sim\\;p_{\\mathrm{1at}}^{(t,\\bar{K}+1)}$ for the fnal policy output by $\\mathrm{ALG_{\\mathrm{1at}}}$ in epoch $t$ and $(x_{h}^{(t,K+1)},a_{h}^{(t,K+1)},r_{h}^{(t,K+1)})$ $\\widehat{\\pi}_{\\mathrm{lat}}^{(t)}\\circ\\widehat{\\phi}^{(t)}$ We firstly note that by assumption, we have the guarantee ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\mathbb{E}\\!\\left[\\underset{t=1}{\\sum}\\displaystyle\\sum_{k=1}^{K+1}\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{\\phi\\mathrm{s}}^{(t,k)}\\sim p_{\\phi\\mathrm{s}}^{(t,k)}}\\mathbb{E}^{\\pi_{\\phi\\mathrm{s}}^{(t,k)}}\\left[\\mathbb{I}\\!\\left[\\widehat{\\phi}_{h}^{(t)}(x_{h})\\neq\\phi_{h}^{\\star}(x_{h})\\right]\\right]\\right]\\leq(K+1)\\mathsf{E s t}_{\\mathrm{class}}(T)}\\\\ &{}&{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq2K\\mathsf{E s t}_{\\mathrm{class}}(T).}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "which follows by applying Assumption 4.2 to the distributions Ps = (K+1) \u2265k=1 Pobs) k+1 pobs) and noting that ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\frac{1}{K+1}\\sum_{k=1}^{K+1}\\mathbb{E}_{\\pi_{\\mathtt{o b s}}^{(t,k)}\\sim p_{\\mathtt{o b s}}^{(t,k)}}\\mathbb{E}^{\\pi_{\\mathtt{o b s}}^{(t,k)}}\\left[\\mathbb{I}\\Big[\\widehat{\\phi}_{h}^{(t)}(x_{h})\\neq\\phi_{h}^{\\star}(x_{h})\\Big]\\right]}\\\\ &{\\quad\\quad=\\displaystyle\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}_{\\overline{{\\pi}}_{\\mathtt{o b s}}^{(t)}\\sim\\bar{p}_{\\mathtt{o b s}}^{(t)}}\\mathbb{E}^{\\bar{\\pi}_{\\mathtt{o b s}}^{(t)}}\\left[\\mathbb{I}\\Big[\\widehat{\\phi}_{h}^{(t)}(x_{h})\\neq\\phi_{h}^{\\star}(x_{h})\\Big]\\right]\\leq\\mathsf{E s t}_{\\mathrm{class}}(T).}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "Let $\\mathsf{R i s k}(K,\\mathrm{ALG}_{1\\mathrm{at}},\\phi,M_{\\mathsf{o b s}}^{\\star})\\,=\\,J^{M_{\\mathrm{obs}}^{\\star}}(\\pi_{M_{\\mathsf{o b s}}^{\\star}}^{\\star})\\,-\\,J^{M_{\\mathrm{obs}}^{\\star}}(\\widehat{\\pi}_{1\\mathrm{at}}\\circ\\phi)$ be the random variable denoting the risk of the final policy output by $\\mathrm{ALG_{\\mathrm{1at}}}$ after $K$ rounds of interaction with $M_{\\mathsf{o b s}}^{\\star}$ when given feature $\\phi$ in any epoch $t$ . For any $\\phi\\,:\\,\\mathcal{X}\\,\\rightarrow\\,\\mathcal{S}$ ,let $\\mathbb{E}_{\\phi}$ denote the law over trajectories $(x_{h}^{(k)},a_{h}^{(k)},r_{h}^{(k)})_{k\\in[K+1],h\\in[H]}$ and policies $(\\pi_{\\mathrm{1at}}^{(k)}\\circ\\phi)_{k\\in[K+1]}$ generated after $K$ rounds ofinteraction when $\\mathrm{ALG}_{\\mathrm{1at}}$ is given feature $\\phi$ in any epoch. (Recali that, for all of the above definitions, a new instance of $\\mathrm{{ALG}_{\\mathrm{{lat}}}}$ is initialized at every epoch, so we do not have to specify which epoch it is, only the current feature $\\phi$ ). Finally, let $G_{t}$ be the \u201cgood\" event ", "page_idx": 53}, {"type": "equation", "text": "$$\nG_{t}=\\Big\\{\\forall k\\in[K+1],\\forall h\\in[H]:\\ \\widehat{\\phi}_{h}^{(t)}(x_{h}^{(t,k)})=\\phi_{h}^{\\star}(x_{h}^{(t,k)})\\Big\\}.\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "Recall that, in any round $t$ $\\mathrm{ALG}_{\\mathrm{1at}}$ only observes the latent (\\*\"compressed\") trajectories $(\\widehat{\\phi}_{h}^{(t)}(x_{h}^{(t,k)}),a_{h}^{(t,k)},r_{h}^{(t,k)})$ ass $\\widehat{\\phi}^{(t)}\\big(x_{h}^{(t,k)}\\big)=\\phi^{\\star}\\big(x_{h}^{(t,k)}\\big)$ foral $k\\in[K+1],h\\in[H]$ thedisionelpe $\\widehat{\\pi}_{\\mathrm{1at}}^{(t)}$ chosen by $\\mathrm{{ALG}_{\\mathrm{{lat}}}}$ will be identical as if we had chosen $\\phi^{\\star}$ as our decoder. In particular, this implies ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\widehat{\\phi}^{(t)}}\\left[\\mathbb{I}\\{G_{t}\\}\\mathsf{R i}\\,\\mathsf{s k}(K,\\mathsf{A L G}_{\\mathrm{lat}},\\widehat{\\phi}^{(t)},M_{\\mathsf{o b s}}^{\\star})\\right]=\\mathbb{E}_{\\phi^{\\star}}\\big[\\mathbb{I}\\{G_{t}\\}\\mathsf{R i}\\,\\mathsf{s k}\\big(K,\\mathsf{A L G}_{\\mathrm{lat}},\\phi^{\\star},M_{\\mathsf{o b s}}^{\\star}\\big)\\big]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\le\\mathsf{R i}\\,\\mathsf{s k}_{\\star}(K),}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "where the second line simply follows by removing the indicator function, recalling that $\\mathsf{R i s k}_{\\star}(K)=$ $\\mathbb{E}[\\mathsf{R i\\,s k}(K,\\mathrm{ALG}_{\\mathrm{lat}},M_{\\mathrm{lat}}^{\\star})]$ ,and using that $\\mathsf{R i}\\,\\mathsf{s k}(K,\\mathrm{ALG}_{1\\mathrm{at}},\\phi^{\\star},M_{\\mathsf{o b s}}^{\\star})=\\mathsf{R i}\\,\\mathsf{s k}(K,\\mathrm{ALG}_{1\\mathrm{at}},M_{1\\mathrm{at}}^{\\star})$ ", "page_idx": 53}, {"type": "text", "text": "Then, we have: ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}[\\mathbb{R}\\mathbf{is}\\mathbf{k}_{\\mathrm{obs}}(T K)]=\\displaystyle\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{E}_{\\hat{\\mathcal{G}}(\\cdot)\\sim\\rho_{t}(t)}\\Big[\\mathbb{E}_{\\hat{\\mathcal{G}}(\\cdot)}\\Big[\\mathbb{R}\\mathbf{is}\\mathbf{k}(K,\\mathbf{ALG}_{\\mathrm{lat}},\\hat{\\mathcal{G}}^{(t)},M_{\\mathrm{obs}}^{\\star})\\Big]\\Big]}\\\\ {\\le\\displaystyle\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{E}_{\\hat{\\mathcal{G}}(\\cdot)\\sim\\rho_{t}(t)}\\Big[\\mathbb{E}_{\\hat{\\mathcal{G}}(\\cdot)}\\Big[\\mathbb{E}\\big(G_{t}\\}\\mathbf{r}\\big)\\mathbf{is}\\mathbf{k}\\big(K,\\mathbf{ALG}_{\\mathrm{lat}},\\hat{\\mathcal{G}}^{(t)},M_{\\mathrm{obs}}^{\\star}\\big)\\Big]\\Big]}\\\\ {\\quad}&{\\quad\\quad+\\displaystyle\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{E}_{\\hat{\\mathcal{G}}(\\cdot)\\sim\\rho_{t}(t)}\\Big[\\mathbb{E}_{\\hat{\\mathcal{G}}(\\cdot)}\\big[\\mathbb{I}_{\\+}(G_{t})\\big]\\Big]}\\\\ {\\le\\displaystyle\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{R}\\mathbf{is}\\mathbf{k}_{\\mathbf{k}}\\big(K)+\\displaystyle\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{P}\\big(-G_{t}\\big)}\\\\ {=\\mathbb{R}\\mathbf{is}_{\\mathbf{k}},(K)+\\displaystyle\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{P}\\big(-G_{t}\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "where the first equality applies the tower rule for conditional expectation, the second equality applies linearity of conditional expectations and the upper bound $\\mathtt{R i s k}(K,\\mathrm{ALG}_{\\mathrm{lat}},\\widehat{\\phi}^{(t)},M_{\\mathtt{o b s}}^{\\star})\\leq1$ and the third lines applies the upper bound Eq. (58). It remains to bound the last term. Here, note that by a unionbound, ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\neg G_{t})\\le\\mathbb{E}\\left[\\sum_{k=1}^{K+1}\\sum_{h=1}^{H}\\mathbb{E}_{\\pi^{(t,k)}\\sim p^{(t,k)}}\\,\\mathbb{E}^{\\pi^{(t,k)}}\\,\\mathbb{I}\\!\\left\\{\\widehat{\\phi}^{(t)}(x_{h}^{(t,k)})\\neq\\phi^{\\star}(x_{h}^{(t,k)})\\right\\}\\right],\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "where we have used that trajectory $k$ in round $t$ is sampled from policy $\\pi^{(t,k)}$ , which is in turn sampled from $\\boldsymbol{p}^{(t,k)}$ . Summing over $t$ and using the bound in Eq. (57) concludes the proof. ", "page_idx": 54}, {"type": "text", "text": "H Proofs for Appendix A: Self-Predictive Estimation ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "This appendix contains additional information and proofs related to algorithmic modularity under self-predictive estimation (Appendix A), and is organized as follows: ", "page_idx": 55}, {"type": "text", "text": "\u00b7 Appendix H.1 contains the pseudocode and proofs related to the online representation learning oracle SELFPREDICT.OPT (Lemma A.1).   \n\u00b7 Appendix H.2 contains the proof for our risk bound of the O2L algorithm under self-predictive estimation (Theorem A.1). ", "page_idx": 55}, {"type": "text", "text": "H.1 Pseudocode and Proofs for SELFPREDICT.OPT (Lemma A.1) The pseudocode for our self-predictive estimation procedure is given in Algorithm 4. ", "page_idx": 55}, {"type": "text", "text": "Algorithm 4 Optimistic Self-Predictive Latent Model Estimation (SELFPREDICT.OPT)   \n1: input: Decoder set $\\Phi$ , Latent model class $\\mathcal{M}_{\\mathrm{{lat}}}$ , Mismatch-complete class $\\mathcal{L}_{\\mathrm{lat}}$ , Optimism parameter $\\gamma$   \n2: Set $\\begin{array}{r}{\\beta:=\\frac{1}{2}\\sqrt{C_{\\mathrm{cov}}H\\log(T)/T}}\\end{array}$   \n3: for $t=1,2,\\cdots,T$ $\\begin{array}{r}{\\dot{\\mathcal{D}}^{(t)}=\\{x_{h}^{(i)},a_{h}^{(i)},r_{h}^{(i)},x_{h+1}^{(i)}\\}_{i\\in[t-1],h\\in[H]}}\\end{array}$ Compute   \n$\\begin{array}{r}{(\\widehat{M}^{\\scriptscriptstyle(t)},\\widehat{\\phi}^{\\scriptscriptstyle(t)})=\\underset{(M,\\phi)\\in(M_{\\scriptscriptstyle{\\mathrm{lat}},\\Phi})}{\\arg\\operatorname*{max}}\\left\\{(\\gamma\\beta)^{-1}J^{\\scriptscriptstyle{M}}(\\pi_{M})+\\displaystyle\\sum_{h=1}^{H}\\sum_{i=1}^{n}\\log\\bigl(M_{h}(r_{h}^{\\scriptscriptstyle(i)},\\phi_{h+1}(x_{h+1}^{\\scriptscriptstyle(i)})\\mid\\phi_{h}(x_{h}^{\\scriptscriptstyle(i)}),a_{h}^{\\scriptscriptstyle(i)})\\bigr)\\right.}\\\\ {\\left.\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\left.(59)\\right.}\\\\ {\\left.-\\underset{(M^{\\prime},\\phi^{\\prime})\\in(\\mathcal{L}_{\\scriptscriptstyle{\\mathrm{lat}}},\\Phi)}{\\operatorname*{max}}\\sum_{i=1}^{n}\\log\\bigl(M_{h}^{\\prime}(r_{h}^{\\scriptscriptstyle(i)},\\phi_{h+1}(x_{h+1}^{\\scriptscriptstyle(i)})\\mid\\phi_{h}^{\\prime}(x_{h}^{\\scriptscriptstyle(i)}),a_{h}^{\\scriptscriptstyle(i)})\\bigr)\\right\\}}\\\\ {\\left.\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(60)}\\end{array}$ (60)   \n6: Return $\\widehat{\\phi}^{(t)}=\\left\\{\\widehat{\\phi}_{h}^{(t)}\\right\\}_{h\\in[H]}.$   \n7: end for ", "page_idx": 55}, {"type": "text", "text": "Our main result concerning the SELFPREDICT.OPT estimator for online optimistic self-predictive estimation is the following. We recall our notation for the instantaneous self-prediction error ", "page_idx": 55}, {"type": "equation", "text": "$$\n[\\Delta_{h}(M_{\\mathrm{1at}},\\phi)](x_{h},a_{h}):=D_{\\mathsf{H}}^{2}\\big(M_{\\mathrm{1at},h}(\\phi_{h}(x_{h}),a_{h}),\\big[\\phi_{h+1}\\sharp M_{\\mathsf{0b s},h}^{\\star}\\big](x_{h},a_{h})\\big).\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Lemma A.1 (Optimistic self-predictive estimation via SELFPREDICT.OPT). Let $\\Pi_{\\mathrm{1at}}$ denote the set of policies played by $\\mathrm{ALG_{\\mathrm{1at}}}$ ,and $C_{\\mathsf{c o v,s t}}=C_{\\mathsf{c o v,s t}}(M_{\\mathsf{l a t}}^{\\star},\\Gamma_{\\Phi}\\circ\\Pi_{\\mathsf{l a t}})$ be the state coverability parameter on $M_{\\mathrm{1at}}^{\\star}$ over the set of stochastic policies $\\Gamma_{\\Phi}\\circ\\Pi_{1a t}$ (Eq. (9)). Then, for any $\\gamma>0$ under decoder realizability $(\\phi^{\\star}\\,\\in\\,\\Phi)$ , base model realizability $(M_{\\mathrm{lat}}^{\\star}\\in\\mathcal{M}_{\\mathrm{lat}})$ ,and mismatch functioncompletenesswithclass $\\mathcal{L}_{\\mathrm{1at}}$ (Assumption A.2), the estimator in Algorithm $^{4}$ with inputs $\\Phi,\\mathcal{M}_{\\mathrm{lat}},\\mathcal{L}_{\\mathrm{lat}}$ , and $\\gamma$ satisfies Assumption A.1 with24 ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\mathsf{E s t}_{\\mathsf{s e l f};\\mathsf{o p t}}(T,\\gamma)=\\widetilde{\\mathcal{O}}\\bigg(\\sqrt{H C_{\\mathsf{c o v},\\mathsf{s t}}|A|T}\\log(|\\mathcal{M}_{\\mathrm{lat}}||\\mathcal{L}_{\\mathrm{lat}}||\\Phi|)\\bigg).\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Proof of Lemma A.1. We willfirstly establish that the algorithm obtains low offine estimation error. ", "page_idx": 55}, {"type": "text", "text": "Lemma H.1 (SELFPREDICT.OPT attains low offline estimation error). For any $\\gamma>0$ under decoder realizability $\\langle\\phi^{\\star}\\in\\Phi,$ , model realizability $(M_{\\mathrm{lat}}^{\\star}\\in\\mathcal{M}_{\\mathrm{lat}})$ andmismatch function completeness with class $\\mathcal{L}_{\\mathrm{lat}}$ (Assumption A.2), the estimator in Algorithm 4 with inputs $\\Phi$ $M_{\\mathrm{{lat}}},\\,\\mathcal{L}_{\\mathrm{{lat}}}.$ and $\\gamma$ satisfies ", "page_idx": 55}, {"type": "text", "text": "that for all $t\\in[T]$ with probability at least $1-\\delta$ ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{h=0}^{H}\\sum_{i=1}^{t-1}\\mathbb{E}_{\\pi^{(i)}\\sim p^{(i)}}\\mathbb{E}^{\\pi^{(i)}}\\left[\\big[\\Delta_{h}\\big(\\widehat{M^{(t)}},\\widehat{\\phi}^{(t)}\\big)\\big](x_{h},a_{h})\\right]+\\gamma^{-1}\\Big(J^{M_{\\mathrm{lat}}^{\\star}}\\big(\\pi_{M_{\\mathrm{lat}}^{\\star}}\\big)-J^{\\widehat{M^{(t)}}}\\big(\\pi_{\\widehat{M}^{(t)}}\\big)\\Big)}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\leq\\mathcal{O}\\big(\\log\\big(|{\\cal M}_{1\\mathrm{at}}||\\mathcal{L}_{1\\mathrm{at}}||\\Phi|H T\\delta^{-1}\\big)\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "Given this result, we can appeal to offline-to-online conversions to establish the final result. Let $C_{\\mathsf{c o v}}\\,:=\\,C_{\\mathsf{c o v}}(M_{\\mathsf{o b s}}^{\\star},\\Pi_{\\mathsf{l a t}}\\circ\\Phi)$ denote the (state-action) coverability coeficient in $M_{\\mathsf{o b s}}^{\\star}$ over the set of policies $\\Pi_{\\mathrm{1at}}\\circ\\Phi$ . Note that by Lemma D.1 we have $C_{\\mathsf{c o v,s t}}(\\operatorname{\\dot{M}}_{\\mathsf{o b s}}^{\\star},\\Pi_{\\mathsf{l a t}}\\circ\\Phi)=\\overleftarrow{C}_{\\mathsf{c o v,s t}}$ and therefore by Lemma D.4 we have $C_{\\mathsf{c o v}}(M_{\\mathsf{o b s}}^{\\star},\\Pi_{\\mathsf{l a t}}\\circ\\Phi)\\leq C_{\\mathsf{c o v,s t}}|A|$ Let $\\eta>0$ be a parameter to be chosen later, and $\\beta_{\\mathsf{o f f}}\\,=\\,\\mathcal{O}\\big(\\log\\bigl(|\\mathcal{M}_{\\sf l a t}||\\mathcal{L}_{\\sf l a t}||\\Phi|H T\\delta^{-1}\\bigr)\\big)$ ) be the offline estimation error guaranteed by Lemma H.1. We abbreviate $\\alpha:=\\sqrt{C_{\\mathsf{c o v}}H\\log(T)},\\mathbb{E}^{p^{(t)}}[\\cdot]:=\\mathbb{E}_{\\pi^{(t)}\\sim p^{(t)}}\\,\\mathbb{E}^{\\pi^{(t)}}[\\cdot],$ and $\\begin{array}{r}{\\mathbb{E}^{\\widetilde{p}^{(t)}}:=\\sum_{i=1}^{t-1}\\mathbb{E}_{\\pi^{(i)}\\sim p^{(i)}}\\mathbb{E}^{\\pi^{(i)}}\\left[\\cdot\\right]}\\end{array}$ Then, we have: ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\displaystyle\\sum_{h=1}^{H^{(t)}}\\mathbb{E}^{p^{(t)}}\\left[\\big[\\Delta_{h}(\\widehat{M^{(t)}},\\widehat{\\phi}^{(t)})\\big](x_{h},a_{h})\\right]+\\gamma^{-1}\\Bigg(J^{M_{\\mathrm{lat}}^{\\star}}(\\pi_{M_{\\mathrm{lat}}^{\\star}})-J^{\\widehat{M^{(t)}}}(\\pi_{\\widehat{M}^{(t)}})\\Bigg)}\\\\ &{\\leq\\alpha\\sqrt{\\displaystyle\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}^{\\widetilde{p}^{(t)}}\\left[\\big[\\Delta_{h}(\\widehat{M^{(t)}},\\widehat{\\phi}^{(t)})\\big](x_{h},a_{h})\\right]}+\\gamma^{-1}\\displaystyle\\sum_{t=1}^{T}\\left(J^{M_{\\mathrm{lat}}^{\\star}}(\\pi_{M_{\\mathrm{lat}}^{\\star}})-J^{\\widehat{M^{(t)}}}(\\pi_{\\widehat{M}^{(t)}})\\right)}\\\\ &{\\qquad+\\mathcal{O}(H C_{\\mathrm{cov}})}\\\\ &{\\leq\\alpha\\Bigg(\\displaystyle\\frac{\\eta}{2}\\sum_{t=1}^{T}\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}^{\\widetilde{p}^{(t)}}\\left[\\big[\\Delta_{h}(\\widehat{M^{(t)}},\\widehat{\\phi}^{(t)})\\big](x_{h},a_{h})\\right]+\\displaystyle\\frac{1}{2\\eta}\\Bigg)+\\gamma^{-1}\\displaystyle\\sum_{t=1}^{T}\\left(J^{M_{\\mathrm{lat}}^{\\star}}(\\pi_{M_{\\mathrm{lat}}^{\\star}})-J^{\\widehat{M^{(t)}}}(\\pi_{\\widehat{M}^{(t)}}}\\\\ &{\\qquad+\\mathcal{O}(H C_{\\mathrm{cov}})\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "where in the first inequality we have used Lemma C.7 with $g_{h}^{(t)}=\\Delta_{h}\\big(\\widehat{M}^{(t)},\\widehat{\\phi}^{(t)}\\big)$ and in the second inequality we have used the AM-GM inequality with parameter $\\eta$ . Collecting terms, we proceed via: ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\displaystyle\\frac{\\alpha\\eta}{2}\\displaystyle\\sum_{t=1}^{T}\\left(\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}^{\\tilde{p}^{(t)}}\\left[\\Delta_{h}(\\widehat{M^{(t)}},\\widehat{\\phi}^{(t)})(x_{h},a_{h})\\right]+(\\displaystyle\\frac{\\gamma\\eta\\alpha}{2})^{-1}\\Big(J^{M_{\\mathrm{in}}^{*}}(\\pi_{M_{\\mathrm{in}}^{*}})-J^{\\widehat{M^{(t)}}}(\\pi_{\\widehat{M^{(t)}}})\\Big)\\right)}\\\\ &{\\qquad+\\displaystyle\\frac{\\alpha}{2\\eta}+\\mathcal{O}(H C_{\\mathrm{cov}})}\\\\ &{\\leq\\displaystyle\\frac{\\alpha\\eta}{2}T\\beta_{\\mathrm{off}}+\\frac{\\alpha}{2\\eta}+\\mathcal{O}(H C_{\\mathrm{cov}})}\\\\ &{\\leq\\mathcal{O}\\left(\\sqrt{C_{\\mathrm{cov,st}}|\\mathcal{A}|H\\log(T)T\\beta_{\\mathrm{off}}}+H C_{\\mathrm{cov,st}}|\\mathcal{A}|\\right)}\\\\ &{\\leq\\mathcal{O}\\left(\\sqrt{H C_{\\mathrm{cov,st}}|\\mathcal{A}|T\\log(T)}\\log\\big(|\\mathcal{M}_{\\mathrm{lat}}||\\mathcal{Q}_{\\mathrm{lat}}||\\Phi|H T\\delta^{-1}\\big)\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "where in the first inequality we have used Lemma H.1 and the definition of $\\gamma$ in Algorithm 4 (cf. Eq. (59)) and in the second inequality we have chosen $\\eta=1/\\sqrt{T}$ to balance the terms and used the bound $C_{\\mathsf{c o v}}\\leq C_{\\mathsf{c o v,s t}}|A|$ . We convert to an expected regret bound by picking $\\delta$ appropriately, which gives the final result. It remains to show Lemma H.1. \u53e3 ", "page_idx": 56}, {"type": "text", "text": "Proof of Lemma H.1. Fix an iteration $t\\,\\in\\,[T]$ , and abbreviate $\\widehat{M}:=\\widehat{M}^{(t)}$ and $\\widehat{\\phi}:=\\widehat{\\phi}^{\\left(t\\right)}$ .We follow the analysis of maximum likelihood estimation from Geer; Zhang; Agarwal et al. [Gee00; Zha06; AKKS20]. In particular, we quote Lemma 24 of [AKKS20], which in an abstract conditional estimation framework with density class $\\mathcal{F}$ states the following. ", "page_idx": 56}, {"type": "text", "text": "Lemma H.2 (Lemma 24 of Agarwal et al. [AKKS20]). Let $D=\\{(x_{i},y_{i})\\}$ be a dataset collected with $x_{i}\\sim p^{(i)}(x_{1:i-1},y_{1:i-1})$ and $y_{i}\\sim f^{\\star}(\\cdot\\mid x_{i})$ \uff0c $\\begin{array}{r}{L(f,D)=\\sum_{i=1}^{n}\\ell(f,(x_{i},y_{i}))}\\end{array}$ be any loss function thatdecomposesadditively, ${\\widehat{f}}:D\\to{\\mathcal{F}}$ be an estimator, $D^{\\prime}$ be a tangent sequence $D^{\\prime}=\\{(\\widetilde{x}_{i},\\widetilde{y}_{i})\\}$ sampled independently via $\\widetilde{x}_{i}\\sim p^{(i)}(x_{1:i-1},y_{1:i-1})$ and $\\widetilde{y}_{i}\\sim f^{\\star}(\\cdot\\mid\\widetilde{x}_{i})$ . Then, with probability at least $1-\\delta$ we have ", "page_idx": 56}, {"type": "text", "text": "", "page_idx": 57}, {"type": "equation", "text": "$$\n-\\log\\mathbb{E}_{D^{\\prime}}\\exp\\Bigl(L\\bigl(\\widehat{f}(D),D^{\\prime})\\Bigr)\\le-L\\bigl(\\widehat{f}(D),D\\bigr)+\\log\\bigl(\\vert\\mathcal{F}\\vert\\delta^{-1}\\bigr),\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "For our purposes, we have that $\\mathcal{F}=\\mathcal{M}_{\\sf l a t}\\circ\\Phi$ , the data distribution is collected adaptively (for each $h\\in[H])$ via $\\pi^{(i)}\\sim p^{(i)}$ $x_{h}^{(i)},a_{h}^{(i)}\\sim d_{h}^{M_{\\mathrm{obs}}^{\\star},\\pi^{(i)}}$ , and $r_{h}^{(i)},x_{h+1}^{(i)}\\sim M_{\\tt o b s}^{\\star}(\\cdot\\mid x_{h}^{(i)},a_{h}^{(i)})$ .For the loss function $L$ ,wetake ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L((M,\\phi),D)=-\\displaystyle\\sum_{h=0}^{H}\\displaystyle\\sum_{i=1}^{t}\\log\\left(\\frac{M_{\\sf o b s}^{\\star}(r_{h+1}^{(i)},\\phi_{h+1}(x_{h+1}^{(i)})\\mid x_{h}^{(i)},a_{h}^{(i)})}{[M_{h}\\circ\\phi_{h}](r_{h}^{(i)},\\phi_{h+1}(x_{h+1}^{(i)})\\mid x_{h}^{(i)},a_{h}^{(i)})}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad-\\displaystyle\\frac{\\gamma^{-1}}{2}(J^{M_{\\mathrm{iat}}^{\\star}}(\\pi_{M_{\\mathrm{lat}}^{\\star}})-J^{M}(\\pi_{M})).}\\end{array}\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "We begin by upper bounding the quantity $-L((\\widehat{M},\\widehat{\\phi})(D),D)$ appearing on the right-hand side of Eq. (62), or equivalently lower bounding $L((\\widehat{M},\\widehat{\\phi})(D),D)$ . Let us abbreviate $\\widehat V=J^{\\widehat M}(\\pi_{\\widehat M})$ and $V^{\\star}={\\cal J}^{M_{\\mathrm{lat}}^{\\star}}(\\pi_{M_{\\mathrm{lat}}^{\\star}})$ . Towards this, note that ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{H(\\widetilde{M}_{c}|\\widetilde{M})_{i}|\\mathcal{B}_{i}|\\mathcal{B}_{i}^{\\frac{\\alpha-\\frac{3}{2}}{2}}\\underset{=}{\\longrightarrow}\\frac{\\mathcal{E}}{\\underset{=}{M_{m}^{3}}}\\sum_{\\alpha,m_{i}=1}^{\\infty}\\Bigg(\\widetilde{M}_{m}^{0}\\otimes\\widehat{\\alpha}_{i}^{\\alpha}\\left[\\widehat{\\alpha}_{i}^{\\alpha\\beta}\\right]_{i}\\left[\\widehat{\\alpha}_{i}^{\\alpha\\beta}\\right]_{i}\\left[\\widehat{\\alpha}_{i}^{\\alpha},u_{i}^{\\alpha}\\right]_{i}\\Bigg)}\\\\ &{\\ \\ \\ \\ \\ -\\underset{=}{\\overset{,}{M_{m}^{3}}}\\sum_{\\alpha,m_{i}=1}^{\\infty}\\Bigg(\\widetilde{M}_{m}^{0}\\otimes\\widehat{\\alpha}_{i}^{\\alpha\\beta}\\left[\\widehat{\\alpha}_{i}^{\\alpha\\beta},\\widehat{\\alpha}_{m}^{\\alpha\\beta},(u_{i}^{\\alpha})^{\\alpha},u_{i}^{\\alpha})\\right)+\\frac{\\gamma-1}{2}(\\widetilde{U}-U^{\\alpha})}\\\\ &{\\ \\ \\ \\ \\ -\\frac{\\gamma-1}{2}\\sum_{\\alpha,m_{i}=1}^{\\infty}\\Bigg(\\widetilde{M}_{m}^{0}\\otimes\\widehat{\\alpha}_{i}^{\\alpha\\beta}\\left[\\widehat{\\alpha}_{i}^{\\alpha\\beta},\\widehat{\\alpha}_{m}^{\\alpha\\beta},(u_{i}^{\\alpha})^{\\alpha},(u_{i}^{\\alpha})^{\\alpha},u_{i}^{\\alpha})\\right]}\\\\ &{\\ \\ \\ \\ \\ \\geq\\frac{\\gamma-1}{2}(\\widetilde{M}_{m}^{0}\\otimes\\widehat{\\alpha}_{i}^{\\alpha\\beta}\\left[\\widehat{\\alpha}_{i}^{\\alpha\\beta},\\widehat{\\alpha}_{m}^{\\alpha\\beta},(u_{i}^{\\alpha})^{\\alpha},(u_{i}^{\\alpha})^{\\alpha},(u_{i}^{\\alpha})^{\\alpha},(u_{i}^{\\alpha})^{\\beta}\\right])}\\\\ &{\\ \\ \\ \\ \\ -\\frac{\\gamma-1}{2}(\\widetilde{U}-M_{m}^{0})\\underset{=}{\\longrightarrow}\\frac{\\gamma}{M_{m}^{2}}\\Bigg(\\mathrm{bot}\\left[(M_{m}^{2}\\otimes\\widehat{\\alpha}_{i}^{\\alpha\\beta})\\right]\\left\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "where in the second line we have used Lemma D.8 with Assumption A.2 and in the third line we have used the ERM property of $\\widehat{M}\\circ\\widehat{\\phi}$ together with decoder and model realizability. We claim that this implies ", "page_idx": 57}, {"type": "equation", "text": "$$\nL((\\widehat{M},\\widehat{\\phi})(D),D)\\ge-\\log\\bigl(|\\mathcal{L}_{\\mathrm{lat}}\\circ\\Phi|H\\delta^{-1}\\bigr)\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "by concentration. Indeed, for each $h\\in[H],i\\in[t]$ , and $\\left[M^{\\prime}\\circ\\phi^{\\prime}\\right]\\in\\mathcal{L}_{\\mathrm{1at}}\\circ\\Phi$ , let ", "page_idx": 57}, {"type": "equation", "text": "$$\nZ_{i,h}^{[M^{\\prime}\\circ\\phi^{\\prime}]}=-\\frac{1}{2}\\log\\left(\\frac{M_{\\sf o b s}^{\\star}(r_{h}^{(i)},\\phi_{h+1}^{\\star}(x_{h+1}^{(i)})\\mid x_{h}^{(i)},a_{h}^{(i)})}{[M^{\\prime}\\circ\\phi^{\\prime}](r_{h}^{(i)},\\phi_{h+1}^{\\star}(x_{h+1}^{(i)})\\mid x_{h}^{(i)},a_{h}^{(i)})}\\right)\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "Applying Lemma C.1, we have that ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i=1}^{t}\\log\\left(\\frac{M_{\\mathrm{obs}}^{\\star}(r_{i}^{(i)},\\phi_{h+1}^{\\star}(x_{h+1}^{(i)})\\mid x_{h}^{(i)},a_{h}^{(i)})}{[M^{\\prime}\\circ\\phi^{\\prime}](r_{h}^{(i)},\\phi_{h+1}^{\\star}(x_{h+1}^{(i)})\\mid x_{h}^{(i)},a_{h}^{(i)})}\\right)}\\\\ &{\\ge\\displaystyle\\sum_{i=1}^{t}-2\\log\\left(\\mathbb{E}_{\\pi^{(i)}\\sim p^{(i)}}\\mathbb{E}^{\\pi^{(i)}}\\left[\\exp\\left(-\\frac{1}{2}\\log\\left(\\frac{M_{\\mathrm{obs}}^{\\star}(r_{h}^{(i)},\\phi_{h+1}^{\\star}(x_{h+1}^{(i)})\\mid x_{h}^{(i)},a_{h}^{(i)})}{[M^{\\prime}\\circ\\phi^{\\prime}](r_{h}^{(i)},\\phi_{h+1}^{\\star}(x_{h+1}^{(i)})\\mid x_{h}^{(i)},a_{h}^{(i)})}\\right)\\right)\\right]\\right)}\\\\ &{\\quad-\\log\\left(\\delta^{-1}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "with probability at least $1-\\delta$ , where we have recalled that data is gathered adaptively according to $\\pi^{(i)}\\sim p^{(i)}$ .We now quote the following lemma from Zhang; Agarwal et al. [Zha06; AKKS20]. ", "page_idx": 58}, {"type": "text", "text": "Lemma H.3 (Lemma 25 of Agarwal et al. [AKKS20]). For any $\\mathcal{D}\\in\\Delta(\\mathcal{X})$ and $p,q\\in[\\mathcal{X}\\rightarrow\\Delta(\\mathcal{Y})],$ wehave ", "page_idx": 58}, {"type": "equation", "text": "$$\n-2\\log\\mathbb{E}_{x\\sim\\mathcal{D},y\\sim q(\\cdot|x)}\\exp\\!\\left(-\\frac{1}{2}\\log\\!\\left(q(y|x)/p(y|x)\\right)\\right)\\ge\\mathbb{E}_{x\\sim\\mathcal{D}}\\big[D_{\\mathsf{H}}^{2}(q(\\cdot\\mid x),p(\\cdot\\mid x))\\big]\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "Proof of Lemma H.3. We include the proof for completeness. The result follows via the following steps. ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{-2\\log\\mathbb{E}_{x\\sim\\mathcal{D},y\\sim q(\\cdot\\vert x)}\\exp\\biggl(-\\frac{1}{2}\\log(q(y\\vert x)/p(y\\vert x))\\biggr)=-2\\log\\mathbb{E}_{x\\sim\\mathcal{D},y\\sim q(\\cdot\\vert x)}\\,\\sqrt{p(y\\vert x)/q(y\\vert x)}}&{}\\\\ {\\ge2\\Bigl(1-\\mathbb{E}_{x\\sim\\mathcal{D},y\\sim q(\\cdot\\vert x)}\\,\\sqrt{p(y\\vert x)/q(y\\vert x)}\\Bigr)}&{}\\\\ {(\\forall x:\\log(x)\\le x-1)}&{}\\\\ {=\\mathbb{E}_{x\\sim\\mathcal{D}}\\Bigl[2\\Bigl(1-\\mathbb{E}_{y\\sim q(\\cdot\\vert x)}\\,\\sqrt{p(y\\vert x)/q(y\\vert x)}\\Bigr)\\Bigr]}&{}\\\\ {=\\mathbb{E}_{x\\sim\\mathcal{D}}\\bigl[D_{\\mathsf{H}}^{2}(p(\\cdot\\mid x),q(\\cdot\\mid x))\\bigr]}\\end{array}\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "By Lemma H.3, we have that the right-hand-side of Eq. (64) is further lower bounded by ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{i=1}^{t}\\log\\left(\\frac{M_{\\mathrm{obs}}^{\\star}\\left(r_{h}^{(i)},\\,\\phi_{h+1}^{\\star}\\left(x_{h+1}^{(i)}\\right)\\mid x_{h}^{(i)},a_{h}^{(i)}\\right)}{\\left[M^{\\prime}\\circ\\phi^{\\prime}\\right]\\left(r_{h}^{(i)},\\,\\phi_{h+1}^{\\star}\\left(x_{h+1}^{(i)}\\right)\\mid x_{h}^{(i)},a_{h}^{(i)}\\right)}\\right)}\\quad}&{}\\\\ &{\\geq\\sum_{i=1}^{t}\\mathbb{E}_{\\pi^{(i)}\\sim p^{(i)}}\\mathbb{E}^{\\pi^{(i)}}\\left[D_{\\mathsf{H}}^{2}\\big(\\phi_{h+1}^{\\star}\\sharp M_{\\mathrm{obs}}^{\\star}(\\cdot\\mid x_{h}^{(i)},a_{h}^{(i)}),[M^{\\prime}\\circ\\phi^{\\prime}](\\cdot\\mid x_{h}^{(i)},a_{h}^{(i)})\\big)\\right]-\\log\\left(\\delta^{-1}\\right)}\\\\ &{\\geq-\\log\\bigl(\\delta^{-1}\\bigr),}\\end{array}\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "where the last line follows from the non-negativity of squared Hellinger. Taking a union bound over $M^{\\prime}\\circ\\phi^{\\prime}\\in\\mathcal{L}_{\\mathrm{lat}}\\circ\\Phi$ and $h\\in[H]$ gives the desired lower bound in Eq. (63). ", "page_idx": 58}, {"type": "text", "text": "To conclude the proof, it remains to lower bound the left-hand side in Eq. (62). Here, note that: ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-\\log\\mathbb{E}_{D^{\\prime}}\\exp\\!\\Big(L((\\widehat{M},\\widehat{\\phi})(D),D^{\\prime})\\Big)+\\frac{\\gamma^{-1}}{2}(V^{\\star}-\\widehat{V})}\\\\ &{=-\\log\\mathbb{E}_{D^{\\prime}}\\Bigg[\\!\\exp\\!\\left(\\!-\\frac{1}{2}\\displaystyle\\sum_{h=1}^{H}\\!\\sum_{i=1}^{t}\\!\\log\\!\\left(\\!\\frac{M_{\\sf d b s}^{\\star}(\\widehat{r}_{h}^{(i)},\\widehat{\\phi}_{h+1}(\\widetilde{x}_{h+1}^{(i)})\\mid x_{h}^{(i)},a_{h}^{(i)})}{\\left[\\widehat{M}_{h}\\circ\\widehat{\\phi}_{h}\\right](r_{h}^{(i)},\\widehat{\\phi}_{h+1}(x_{h+1}^{(i)})\\mid x_{h}^{(i)},a_{h}^{(i)})}\\!\\right)\\!\\right)\\!\\Bigg]}\\\\ &{=-\\displaystyle\\sum_{h=1}^{H}\\!\\sum_{i=1}^{t}\\!\\log\\mathbb{E}_{\\pi^{(i)}\\sim p^{(i)}}\\mathbb{E}^{\\pi^{(i)}}\\!\\left[\\!\\exp\\!\\left(\\!-\\frac{1}{2}\\log\\!\\left(\\!\\frac{M_{\\sf d b s}^{\\star}(r_{h}^{(i)},\\widehat{\\phi}_{h+1}(x_{h+1}^{(i)})\\mid x_{h}^{(i)},a_{h}^{(i)})}{\\left[\\widehat{M}_{h}\\circ\\widehat{\\phi}_{h}\\right](r_{h}^{(i)},\\widehat{\\phi}_{h+1}(x_{h+1}^{(i)})\\mid x_{h}^{(i)},a_{h}^{(i)})}\\!\\right)\\!\\right)\\!\\Bigg],}\\end{array}\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "where we have used that in the \u201ctangent sequence $D^{\\prime}$ the current sample $(\\widetilde{r}_{h}^{(i)},\\widetilde{x}_{h+1}^{(i)})$ is independent $(r_{h}^{(i)},x_{h+1}^{(i)})$ Tbo ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-\\displaystyle\\sum_{h=1}^{H}\\sum_{i=1}^{t}\\log\\mathbb{E}_{\\pi^{(i)}\\sim p^{(i)}}\\mathbb{E}^{\\pi^{(i)}}\\left[\\exp\\left(-\\frac{1}{2}\\log\\left(\\frac{M_{\\sf d b s}^{\\star}(r_{h}^{(i)},\\widehat\\phi_{h+1}(x_{h+1}^{(i)})\\mid x_{h}^{(i)},a_{h}^{(i)})}{\\left[\\widehat{M}_{h}\\circ\\widehat\\phi_{h}\\right](r_{h}^{(i)},\\widehat\\phi_{h+1}(x_{h+1}^{(i)})\\mid x_{h}^{(i)},a_{h}^{(i)})}\\right)\\right)\\right]}\\\\ &{~~\\ge\\displaystyle\\frac{1}{2}\\displaystyle\\sum_{h=1}^{H}\\sum_{i=1}^{t}\\mathbb{E}_{\\pi^{(i)}\\sim p^{(i)}}\\mathbb{E}^{\\pi^{(i)}}\\left[D_{\\mathsf{H}}^{2}\\Big([\\widehat{M}_{h}\\circ\\widehat\\phi_{h}](x_{h},a_{h}),\\widehat\\phi_{h+1}\\sharp M_{\\sf d b s}^{\\star}(x_{h},a_{h})\\Big)\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "Combining everything, we have: ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{2}\\displaystyle\\left(\\sum_{h=1}^{H}\\sum_{i=1}^{t}\\mathbb{E}_{\\pi^{(i)}\\sim p^{(i)}}\\mathbb{E}^{\\pi^{(i)}}\\left[D_{\\mathsf{H}}^{2}\\Big(\\Big[\\widehat{M}_{h}\\circ\\widehat{\\phi}_{h}\\Big](x_{h},a_{h}),\\widehat{\\phi}_{h+1}\\sharp M_{\\mathsf{o b s}}^{\\star}(x_{h},a_{h})\\Big)\\right]+\\gamma^{-1}(V^{\\star}-\\widehat{V})\\right)}\\\\ &{\\qquad\\leq\\log\\big(|\\mathcal{L}_{\\mathrm{Mt}}||\\Phi|H\\delta^{-1}\\big)+\\log\\big(|\\mathcal{M}_{\\mathrm{1at}}||\\Phi|\\delta^{-1}\\big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "Taking an additional union bound over $t\\in[T]$ , we have that with probability at least $1-\\delta$ ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{h=1}^{H}\\sum_{i=1}^{t}\\mathbb{E}_{\\pi^{(i)}\\sim p_{h}^{(i)}}\\mathbb{E}^{\\pi^{(i)}}\\left[D_{\\mathsf{H}}^{2}\\Big(\\Big[\\widehat{M}_{h}\\circ\\widehat{\\phi}_{h}\\Big](x_{h},a_{h}),\\widehat{\\phi}_{h+1}\\sharp M_{\\mathsf{o b s}}^{\\star}(x_{h},a_{h})\\Big)\\right]}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad+\\gamma^{-1}\\Big(J^{M_{\\mathrm{iat}}^{\\star}}(\\pi_{M_{\\mathrm{iat}}^{\\star}})-J^{M^{(t)}}(\\pi_{M^{(t)}})\\Big)\\le\\mathcal{O}\\big(\\log\\big(|{\\mathcal{M}}_{\\mathrm{1at}}||{\\mathcal{L}}_{\\mathrm{1at}}||\\Phi|H T\\delta^{-1}\\big)\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "for all $t\\in[T]$ , as desired. ", "page_idx": 59}, {"type": "text", "text": "Corollary A.1 (Algorithmic modularity via SELFPREDICT.OPT). Under the same conditions as in Lemma A.1, and for any base algorithm $\\mathrm{ALG}_{\\mathrm{1at}}$ ,O2Lwithinputs $T,K,\\Phi$ , SELFPREDICT.OPT, and $\\mathrm{ALG_{\\mathrm{1at}}}$ achieves ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\mathfrak{L}[\\mathbb{R}\\mathbf{i}\\operatorname{sk}_{\\sf o b s}(T K)]\\lesssim c_{1}\\cdot\\mathtt{R i}\\operatorname{sk}_{\\sf b a s e}(K)+c_{2}\\gamma\\cdot\\frac{K}{\\sqrt{T}}\\sqrt{H C_{\\mathrm{cov},\\mathfrak{s t}}|\\mathcal{A}|}\\log(|\\mathcal{M}_{\\sf l a t}||\\mathcal{L}_{\\sf l a t}||\\Phi|)+c_{3}\\gamma^{-1}\\cdot K H,\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "for absolute constants $c_{1},c_{2},c_{3}$ . Consequently, for any $\\mathrm{ALG_{\\mathrm{1at}}}$ with base risk Ri $\\mathsf{s k}_{\\mathsf{b a s e}}(K)$ setting $\\gamma$ and $T$ appropriately gives ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathsf{R i}\\,\\mathsf{s k}_{\\mathsf{o b s}}(T K)]\\lesssim\\mathsf{R i}\\,\\mathsf{s k}_{\\mathsf{b a s e}}(K),\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "with a number of trajectories $T K=\\widetilde{\\mathcal{O}}\\big(K^{5}H^{3}C_{\\mathtt{c o v,s t}}|\\mathcal{A}|\\log^{2}(|\\mathcal{M}_{\\mathtt{l a t}}||\\mathcal{L}_{\\mathtt{l a t}}||\\Phi|)\\big/(\\mathtt{R i}\\,\\mathtt{s k}_{\\mathtt{b a s e}}(K))^{4}\\big).$ ", "page_idx": 59}, {"type": "text", "text": "Proof of Corollary A.1.The first inequality simply follows by plugging the bound of $\\mathsf{E s t}_{\\mathsf{s e l f};\\mathsf{o p t}}$ from Lemma A.1 into Theorem A.1. For the second inequality, let $\\Delta\\ =$ $c_{2}\\sqrt{H C_{\\mathrm{cov,st}}|\\mathcal{A}|}\\log(|\\mathcal{M}_{\\mathrm{1at}}||\\mathcal{L}_{\\mathrm{1at}}||\\Phi|)$ . The result follows by setting $\\gamma$ s.t. $c_{3}\\gamma^{-1}H K~~=~~$ $\\mathsf{R i s k}_{\\mathsf{b a s e}}(K)$ i.e. $\\begin{array}{r}{\\gamma=c_{3}\\frac{K H}{\\mathsf{R i s k}_{\\mathsf{b a s e}}(K)}}\\end{array}$ and $T$ such that = Riskbase(K) i.e. T = Riskae(k)z Rik(. Then the resltfllows by dirct substitution and by noting that  1 since $\\mathsf{R i s k}_{\\mathsf{b a s e}}(K)\\leq1$ ", "page_idx": 59}, {"type": "text", "text": "H.2 Proofs for Main Risk Bound (Theorem A.1) ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Our main risk bound (Theorem A.1) follows as a special case of a more general theorem (Theorem H.1), which holds for algorithm that satisfies a property we refer to as CorruptionRobust-ness (Definition I.2). We now state the more general theorem, postponing its proof (and a formal definition of corruption robustness) until Appendix I. ", "page_idx": 59}, {"type": "text", "text": "Theorem H.1 (Risk bound for O2L under self-predictive estimation and CorruptionRobustness). Assume $\\mathbf{REP}_{\\mathsf{s e l f;o p t}}$ satisfies Assumption $A.I$ with parameter $\\gamma>0$ and that $\\mathcal{M}_{\\mathrm{{lat}}}$ is realizable (i.e. $M_{\\mathrm{1at}}^{\\star}\\in\\mathcal{M}_{\\mathrm{1at}},$ .Furthermore, let $\\mathrm{ALG}_{\\mathrm{1at}}$ be CorruptionRobust (Definition I.2) with parameter $\\alpha$ Then, O2L (Algorithm $^{\\,l}$ )with inputs $T,K,\\Phi$ \uff0c $\\mathrm{\\bfALG}_{\\mathrm{\\bflat}}$ , and REPself;opt has expected risk ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathsf{R i\\,s k}_{\\mathsf{o b s}}(T K)]\\leq c_{1}\\cdot\\mathsf{R i\\,s k}_{\\mathsf{b a s e}}(K)+c_{2}\\gamma\\cdot\\frac{K}{T}\\mathsf{E s t}_{\\mathsf{s e l f;o p t}}(T,\\gamma)+c_{3}\\gamma^{-1}\\cdot\\left(\\alpha^{2}+H\\right)\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "for absolute constants $c_{1},c_{2},c_{3}>0$ ", "page_idx": 60}, {"type": "text", "text": "Our main risk bound (Theorem A.1) follows from the following lemma, which establishes that any $\\mathrm{ALG}_{\\mathrm{1at}}$ is CorruptionRobust in the sense of Definition I.2 for a sufficiently large corruption robustness parameter. Below, for any POMDP M over state-action space $s\\times A$ \uff0cwe write $\\widetilde{M}(s_{1:h},a_{1:h})$ for the conditional probability over reward $r_{h}$ and $s_{h+1}$ given $s_{1:h},a_{1:h}$ , i.e. $\\widetilde{M}_{h}(s_{1:h},a_{1:h})=\\widetilde{M}_{h}(r_{h},s_{h+1}=\\cdot\\mid s_{1:h},a_{1:h})$ ", "page_idx": 60}, {"type": "text", "text": "Lemma H.4. Let $M^{\\star}$ be any reference MDP and M be any POMDP with the same state and action space.Then for any algorithm $\\mathrm{ALG}_{\\mathrm{1at}}$ wehave ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathbb{E}^{\\widetilde{M},\\mathrm{ALG}_{\\mathrm{lat}}}[\\mathbb{R}\\mathbf{i}\\,\\mathbf{s}\\mathbf{k}_{M^{\\star}}(K)]\\leq c_{1}\\,\\mathbb{E}^{M^{\\star},\\mathrm{ALG}_{\\mathrm{lat}}}[\\mathbb{R}\\mathbf{i}\\,\\mathbf{s}\\mathbf{k}_{M^{\\star}}(K)]}\\\\ &{\\displaystyle\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad+\\,c_{2}\\,\\mathbb{E}^{\\widetilde{M},\\mathrm{ALG}_{\\mathrm{lat}}}\\left[\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\mathbb{E}^{\\widetilde{M},\\pi^{(k)}}\\left[D_{\\mathbb{H}}^{2}\\Big(M_{h}^{\\star}(s_{h},a_{h}),\\widetilde{M}_{h}\\big(s_{1:h},a_{1:h}\\big)\\Big)\\right]\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "where $c_{1},c_{2}>0$ are absolute constants. In particular, $\\mathrm{ALG}_{\\mathrm{1at}}$ is CorruptionRobust (Definition I.2) with $\\alpha=c_{2}\\sqrt{K H}$ ", "page_idx": 60}, {"type": "text", "text": "Proof of Lemma H.4. Let us abbreviate $\\mathrm{ALG}:=\\mathrm{ALG}_{\\mathrm{lat}}$ . For $i\\in[K]$ , let $\\tau^{(i)}$ denote the trajectory $\\big(s_{1}^{(i)},a_{1}^{(i)},r_{1}^{(i)},\\cdot\\cdot\\cdot,s_{H}^{(i)},a_{H}^{(i)},r_{H}^{(i)}\\big)$ Let $\\mathbb{P}:=\\mathbb{P}^{M^{\\star},\\mathrm{ALG}}$ denote the law of $\\left\\{\\left(\\pi^{(i)},\\tau^{(i)}\\right)\\right\\}_{i\\in[K]}$ under ALG in the true MDP $M^{\\star}$ and $\\mathbb{Q}:=\\mathbb{P}^{\\widetilde{M},\\mathrm{ALG}}$ denote the law of $\\left\\{\\left(\\pi^{(i)},\\tau^{(i)}\\right)\\right\\}_{i\\in[K]}$ under ALG under the POMDP $\\widetilde{M}$ . Let us write $M^{\\star}(\\pi)$ and $\\widetilde{M}(\\pi)$ for the laws of trajectory $\\tau$ sampled from policy $\\pi$ in $M^{\\star}$ or $\\widetilde{M}$ respectively. Let $\\widehat{\\pi}$ denote the policy output by the algorithm after $K$ rounds of interaction with the environment. By Lemma C.5 we have ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathsf{g}^{\\widetilde{M},\\mathrm{ALG}}\\Big[J^{M^{\\star}}(\\pi_{M^{\\star}})-J^{M^{\\star}}(\\widehat{\\pi})\\Big]\\le3\\,\\mathbb{E}^{M^{\\star},\\mathrm{ALG}}\\Big[J^{M^{\\star}}(\\pi_{M^{\\star}})-J^{M^{\\star}}(\\widehat{\\pi})\\Big]+4D_{\\mathsf{H}}^{2}\\Big(\\mathbb{P}^{M^{\\star},\\mathrm{ALG}},\\mathbb{P}^{\\widetilde{M},\\mathrm{ALG}}\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "By the subadditivity property for squared Hellinger distance (Lemma C.4) applied to the sequence $\\pi^{\\bar{(1)}},\\tau^{(1)},\\cdot\\cdot\\cdot,\\pi^{(K)},\\bar{\\tau^{(K)}}$ wehave ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\gamma_{\\mathbb{H}}^{2}\\left(\\mathbb{P}^{M^{\\star},\\lambda\\times\\0,\\mathbb{P}^{M,\\mathrm{Atat}}}\\right)\\leq\\tau\\mathbb{E}^{\\widetilde{M},\\operatorname{Atat}}\\left[\\sum_{k=1}^{K}D_{\\mathbb{H}}^{2}\\big(\\mathbb{P}^{(\\tau^{(k)}\\mid\\pi^{(k-1)},\\tau^{(1+k-1)}),\\mathbb{Q}(\\pi^{(k)}\\mid\\pi^{(1\\delta-1)},\\tau^{(1\\delta-1)})\\big)},\\mathbb{Q}(\\pi^{(k)}\\mid\\pi^{(1\\delta-1)},\\tau^{(1\\delta-1)})\\big)\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\displaystyle D_{\\mathbb{H}}^{2}\\big(\\mathbb{P}(\\tau^{(k)}\\mid\\pi^{(1\\delta)},\\tau^{(1\\delta-1)}),\\mathbb{Q}(\\tau^{(k)}\\mid\\pi^{(1\\delta)},\\tau^{(1\\delta-1)})\\big)\\Bigg]}\\\\ &{\\qquad=\\tau\\,\\mathbb{E}^{\\widetilde{M},\\operatorname{Atat}}\\left[\\displaystyle\\sum_{k=1}^{K}D_{\\mathbb{H}}^{2}\\big(\\mathbb{P}(\\tau^{(k)}\\mid\\pi^{(1\\delta)},\\tau^{(1\\delta-1)}),\\mathbb{Q}(\\tau^{(k)}\\mid\\pi^{(1\\delta)},\\tau^{(1\\delta-1)})\\big)\\right]}\\\\ &{\\qquad=\\tau\\,\\mathbb{E}^{\\widetilde{M},\\operatorname{Atat}}\\left[\\displaystyle\\sum_{k=1}^{K}D_{\\mathbb{H}}^{2}\\big(M^{\\star}(\\pi^{(k)}),\\widetilde{M}(\\pi^{(k)})\\big)\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\times\\Big.}\\end{array}\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "where in the second step we have used that $\\mathbb{P}\\big(\\pi^{(k)}\\;\\;\\big|\\;\\;\\pi^{(1:k)},\\tau^{(1:k-1)}\\big)\\;=\\;\\mathbb{Q}\\big(\\pi^{(k)}\\;\\;\\big|\\;\\;\\pi^{(1:k)},\\tau^{(1:k-1)}\\big)$ since the histories are equivalent, in the third step we have used that the trajectories are generated by the MDP/PODMP $M^{\\star}$ and $\\widetilde{M}$ , respectively, in the fourth step we have again applied the subadditivity property of the squared Hellinger distance (Lemma C.4) to the sequence $\\left(s_{1},a_{1},r_{1},\\dots,s_{H},a_{H},r_{H}\\right)$ \u53e3 ", "page_idx": 60}, {"type": "text", "text": "Theorem A.1 (Risk bound for $\\mathrm{O}2\\mathrm{L}$ under self-predictive estimation). Suppose REPself;opt satisfes Assumption A.1 with parameter $\\gamma>0$ Then Algorithm $^{\\,l}$ with inputs $T,K,\\Phi$ , REPself;opt, and $\\mathrm{ALG_{\\mathrm{1at}}}$ has expected risk ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathtt{R i s k}_{\\mathtt{o b s}}(T K)]\\le c_{1}\\cdot\\mathtt{R i}\\,\\mathtt{s k}_{\\mathtt{b a s e}}(K)+c_{2}\\gamma\\cdot\\frac{K}{T}\\mathsf{E s t}_{\\mathtt{s e l f};\\mathtt{o p t}}(T,\\gamma)+c_{3}\\gamma^{-1}\\cdot K H,\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "for absolute constants $c_{1},c_{2},c_{3}>0$ ", "page_idx": 61}, {"type": "text", "text": "Proof of Theorem A.1.  This follows from Theorem H.1 as well as Lemma H.4, by taking $\\alpha=c_{2}\\sqrt{K H}$ and simplifying ", "page_idx": 61}, {"type": "text", "text": "I Additional Results for Appendix A: Self-Predictive Estimation ", "text_level": 1, "page_idx": 62}, {"type": "text", "text": "This section contains a more general result for algorithmic modularity under self-predictive estimation (Theorem H.1), from which our main result is derived as a special case, along with associated background, applications, and proofs. This section is organized as follows. ", "page_idx": 62}, {"type": "text", "text": "\u00b7 Appendix I.1 presents: definitions for the $\\phi$ -compressed POMDP and CorruptionRobust algorithms (Appendix I.1.1), statements for properties of the $\\phi$ -compressed dynamics (Appendix I.1.2). The risk bound for O2L under self-predictive estimation and CorruptionRobustness (Theorem H.1) is given in Appendix I.1.3, and a statement that the GoLF algorithm is CorruptionRobust (Appendix I.1.4).   \n\u00b7 Appendix I.2 presents for the proofs for the properties of the $\\phi$ -compressed POMDPs.   \n\u00b7 Appendix I.3 presents a proof for the risk bound of O2L under self-predictive estimation and CorruptionRobustness.   \n\u00b7 Appendix I.4 presents a proof that the GoLF algorithm is CorruptionRobust. ", "page_idx": 62}, {"type": "text", "text": "1.1 O2L with Self-predictive Estimation and CorruptionRobust Base Algorithms I.1.1Definitions: $\\phi$ -compressed POMDP and CorruptionRobustness ", "text_level": 1, "page_idx": 62}, {"type": "text", "text": "Consider iteration $\\textit{k}\\in\\textit{}[K]$ of epoch $t\\ \\in\\ [T]$ within O2L. Suppose that REPLEARN has chosen decoder $\\phi~=~\\phi^{(t)}~~:~\\mathcal{X}~\\rightarrow~\\mathcal{S}.$ Then, the latent algorithm has observed the data $\\mathcal{D}^{(t,k)}\\ =\\ \\{\\phi({x}_{h}^{(t,k)}),a_{h}^{(t,k)},r_{h}^{(t,k)},\\phi({x}_{h+1}^{(t,k)})\\}$ collected from the preceding policies in the epoch: $\\pi_{\\mathrm{lat}}^{(t,1)}\\circ\\phi^{(t)},\\cdot\\cdot\\cdot,\\pi_{\\mathrm{lat}}^{(t,k-1)}\\circ\\phi^{(t)}$ - ( Line 8)Due to possible inaccuracies in the decoder , the dataset $\\mathcal{D}^{(t,k)}$ maynotbegeneratedfromaMarkovian processandmustinsteadeiwedasbenggeneratd from a PODMP, formally defined as follows. ", "page_idx": 62}, {"type": "text", "text": "Definition I.1 ( $\\mathit{\\Delta}\\left(\\phi\\right)$ -compressed POMDP). The $\\phi$ -compressed POMDP $\\widetilde{M}_{\\phi}^{\\star}$ induced by $M_{\\mathrm{obs}}^{\\star}$ and $\\phi$ is defined by: ", "page_idx": 62}, {"type": "text", "text": "1. Latent state space $\\mathcal{X}$   \n2. Action space $\\boldsymbol{\\mathcal{A}}$   \n3. Observation state space $\\boldsymbol{S}$   \n4. Latent reward functions $R_{\\mathsf{o b s},h}^{\\star}:\\mathcal{X}\\times\\mathcal{A}\\to[0,1]$   \n5. Latent dynamics $P_{\\mathsf{o b s},h}^{\\star}:\\mathcal{X}\\times\\mathcal{A}\\to\\Delta(\\mathcal{X})$   \n6.(Deterministic) observation function $O_{h}:\\mathcal{X}\\rightarrow\\mathcal{S}$ defined by $O_{h}(x)=\\phi_{h}(x)$   \n7. Horizon $H$   \n8. Initial latent distribution $P_{\\mathsf{o b s}}^{\\star}(x_{0}\\mid\\emptyset)$ ", "page_idx": 62}, {"type": "text", "text": "Note that the latent space for the POMDP is the observation space of the ltent-dynamics MDP $M_{\\mathsf{o b s}}^{\\star}$ and vice-versa; we adopt this terminology because\u2014from the perspective of the base algorithm, the observations $x_{h}$ can be viewed as a Markovian (yet partially observed process) that generates the learned states $\\phi({\\boldsymbol{x}}_{h})$ on which the algorithm acts. We write $\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}:=\\bar{\\mathbb{P}}^{\\widetilde{M}_{\\phi}^{\\star},\\pi_{\\mathrm{lat}}}$ for the probability distribution over trajectories $(x_{h},s_{h},a_{h},r_{h})_{h\\in[H]}$ in the $\\phi$ -compressed POMDP when playing policy $\\pi_{\\mathrm{lat}}:S\\!\\times\\![H]\\to\\Delta(A)$ ,where $x_{h}\\in\\mathcal{X}$ are the POMDP's latent states, $s_{h}\\in{\\mathcal{S}}$ are the observed states, and $a_{h}\\in A$ are the actions. We let $\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}:=\\mathbb{E}^{\\widetilde{M}_{\\phi}^{\\star},\\pi_{\\mathrm{lat}}}$ denote the coresponding expectation. We write $\\widetilde{P}_{\\phi,h}(s_{h+1}\\mid s_{1:h},a_{1:h})=\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(s_{h+1}\\mid s_{1:h},a_{1:h})$ and $\\tilde{r}_{\\phi,h}(r_{h}\\mid s_{1:h},a_{1:h})=\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(r_{h}\\mid s_{1:h},a_{1:h})$ for the conditional distributions of next states and rewards given the first $h$ state-action pairs, which are policy-independent. We also write $\\widetilde{M}_{\\phi}^{\\star}(\\boldsymbol{r}_{h},\\boldsymbol{s}_{h+1}\\mid\\boldsymbol{s}_{1:h},\\boldsymbol{a}_{1:h})=\\widetilde{r}_{\\phi,h}(\\boldsymbol{r}_{h}\\mid\\boldsymbol{s}_{1:h},\\boldsymbol{a}_{1:h})\\widetilde{P}_{\\phi,h}(\\boldsymbol{s}_{h+1}\\mid\\boldsymbol{s}_{h+1})$ $s_{1:h},a_{1:h})$ for the joint one-step probability. We will abbreviate $\\widetilde{M}_{\\phi}^{\\star}(s_{1:h},a_{1:h}):=\\widetilde{M}_{\\phi}^{\\star}(r_{h},s_{h+1}=$ $\\cdot\\mid s_{1:h},a_{1:h})$ ", "page_idx": 62}, {"type": "text", "text": "Note that for any $\\pi_{\\mathrm{lat}}$ $\\widetilde{P}_{\\phi,h}^{\\pi_{\\mathrm{lat}}}(s_{h+1}\\mid s_{h},a_{h})$ is a well-defined (Markovian, policy-dependent) probability kernel, which is equivalent to ", "page_idx": 63}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{P}_{\\phi,h}^{\\pi_{\\mathrm{lat}}}(s_{h+1}\\mid s_{h},a_{h})=\\displaystyle\\sum_{s_{1:h-1},a_{1:h-1}}\\widetilde{P}_{\\phi,h}^{\\pi_{\\mathrm{lat}}}(s_{1:h-1},a_{1:h-1}\\mid s_{h},a_{h})\\widetilde{P}_{\\phi,h}(s_{h+1}\\mid s_{1:h},a_{1:h})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}\\Bigl[\\widetilde{P}_{\\phi,h}(s_{h+1}\\mid s_{1:h},a_{1:h})\\mid s_{h},a_{h}\\Bigr]}\\end{array}\n$$", "text_format": "latex", "page_idx": 63}, {"type": "text", "text": "Similarly, $\\tilde{r}_{\\phi,h}^{\\pi_{1a t}}(r_{h}\\;\\mid\\;s_{h},a_{h})$ is a Markovian and policy-dependent reward distribution which is equivalent to ", "page_idx": 63}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\tilde{r}_{\\phi,h}^{\\pi_{\\mathrm{lat}}}(r_{h}\\mid s_{h},a_{h})=\\displaystyle\\sum_{s_{1:h-1},a_{1:h-1}}\\widetilde{P}_{\\phi,h}^{\\pi_{\\mathrm{lat}}}(s_{1:h-1},a_{1:h-1}\\mid s_{h},a_{h})\\tilde{r}_{\\phi,h}(r_{h}\\mid s_{1:h},a_{1:h})}\\\\ {\\quad\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ =\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}[\\tilde{r}_{\\phi,h}(r_{h}\\mid s_{1:h},a_{1:h})\\mid s_{h},a_{h}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 63}, {"type": "text", "text": "Finally, we let ", "page_idx": 63}, {"type": "equation", "text": "$$\n\\widetilde{M}_{\\phi,h}^{\\pi_{\\mathrm{lat}},\\star}(\\boldsymbol{r}_{h},s_{h+1}\\mid s_{h},a_{h})=\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}\\Big[\\widetilde{M}_{\\phi}^{\\star}(\\boldsymbol{r}_{h},s_{h+1}\\mid s_{1:h},a_{1:h})\\mid s_{h},a_{h}\\Big]\n$$", "text_format": "latex", "page_idx": 63}, {"type": "text", "text": "denote the associated one-step model over joint rewards and transitions. ", "page_idx": 63}, {"type": "text", "text": "Our CorruptionRobustness condition asserts that the agent-when observing data from the $\\phi^{(t)}$ compressed dynamics $\\widetilde{M}_{\\phi}^{\\star}$ attains a risk bound for $M_{\\mathrm{lat}}$ which is proportional to its risk when observing data from $M_{\\mathrm{1at}}$ itself, plus a term that captures the degree of misspecification between $\\widetilde{M}_{\\phi}^{\\star}$ and $M_{\\mathrm{lat}}$ ", "page_idx": 63}, {"type": "text", "text": "Definition I.2 (CorruptionRobust algorithm). We say that $\\mathrm{\\bfALG}_{\\mathrm{1at}}$ is CorruptionRobust with parameters $\\alpha$ and Riskbase $i f$ there exists a constant $c_{1}$ such that, for any $(\\phi,M_{\\mathrm{1at}})\\in\\Phi\\times\\mathcal{M}_{\\mathrm{1at}}$ ,we have ", "page_idx": 63}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Sigma_{\\hbar}^{\\widetilde{M}_{\\phi}^{\\star},\\mathrm{ALG}_{\\mathrm{lat}}}[\\mathtt{R i s k}(K,\\mathrm{ALG}_{\\mathrm{lat}},M_{\\mathrm{lat}})]\\le c_{1}\\cdot\\mathtt{R i}\\,\\mathtt{s k}_{\\mathtt{b a s e}}(K)}\\\\ &{\\qquad\\qquad+\\,\\alpha\\,\\mathbb{E}^{\\widetilde{M}_{\\phi}^{\\star},\\mathrm{ALG}_{\\mathrm{lat}}}\\left[\\sqrt{\\displaystyle{\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{\\mathrm{lat}}^{(k)}\\sim p^{(k)}}\\,\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}^{(k)}}\\left[{D_{\\mathtt{H}}^{2}\\Big(M_{\\mathrm{lat},h}\\big(s_{h},a_{h}\\big),\\widetilde{M}_{\\phi,h}^{\\star}\\big(s_{1:h},a_{1:h}\\big)\\Big)}\\right]}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 63}, {"type": "text", "text": "where werecall the definition of the randomvariable ${\\tt R i s k}(K,{\\tt A L G}_{1a t},M_{1a t})$ from Eq. (1), the expectation $\\mathbb{E}^{\\widetilde{M}_{\\phi}^{\\star},\\mathrm{ALG}_{\\mathrm{lat}}}$ denotesthnteractinprtoclof $\\mathrm{ALG_{\\mathrm{1at}}}$ inthe $\\phi$ compressed dynamics $\\displaystyle\\widetilde{M}_{\\phi}^{\\star}$ and $p^{(k)}$ denotes the randomization distribution over latent policies that ALGiat plays. ", "page_idx": 63}, {"type": "text", "text": "1.1.2 Basic properties of the $\\phi$ -compressed dynamics (Definition 1.1) ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "We establish a number of basic properties for the $\\phi$ -compressed POMDP and their relation to the self-prediction guarantee obtained by $\\mathbf{REP}_{\\mathsf{s e l f;o p t}}$ . These properties are proved in Appendix I.2. Firstly, we have the following change-of-measure lemma: ", "page_idx": 63}, {"type": "text", "text": "Lemma I1 (Change of measure lemma). For any $\\phi\\in\\Phi$ $f\\,\\in\\,[S\\times A\\to[0,1]]$ $h\\,\\in\\,[H]$ and $\\pi_{\\mathrm{lat}}\\in[S\\times[H]\\to\\Delta(A)]$ wehave: ", "page_idx": 63}, {"type": "equation", "text": "$$\n\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}[f(s_{h},a_{h})]=\\mathbb{E}^{\\pi_{\\mathrm{lat}}\\circ\\phi}[[f\\circ\\phi](x_{h},a_{h})].\n$$", "text_format": "latex", "page_idx": 63}, {"type": "text", "text": "The next lemma states that the kernels of the $\\phi$ -compressed POMDP are well-approximated by the (Markovian) latent model fit by $\\mathrm{REP}_{\\mathsf{s e l f;o p t}}$ . We recall the instantaneous self-prediction error ", "page_idx": 63}, {"type": "equation", "text": "$$\n[\\Delta_{h}(M_{\\mathrm{1at}},\\phi)](x_{h},a_{h}):=D_{\\mathsf{H}}^{2}\\big(M_{\\mathrm{1at},h}(\\phi_{h}(x_{h}),a_{h}),\\big[\\phi_{h+1}\\sharp M_{\\mathsf{0b s},h}^{\\star}\\big](x_{h},a_{h})\\big).\n$$", "text_format": "latex", "page_idx": 63}, {"type": "text", "text": "Lemma I.2 (Near-markovianity of the $\\phi$ -compressed dynamics). For any decoder $\\phi_{i}$ basemodel $M_{\\mathrm{lat}}$ and policy $\\pi_{\\mathrm{lat}}:S\\times[H]\\to\\Delta(A)$ we have: ", "page_idx": 63}, {"type": "equation", "text": "$$\n\\sum_{h=0}^{H}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}\\Bigl[D_{\\mathrm{H}}^{2}\\Bigl(M_{\\mathrm{lat},h}(s_{h},a_{h}),\\widetilde{M}_{\\phi,h}^{\\star}(s_{1:h},a_{1:h})\\Bigr)\\Bigr]\\le\\sum_{h=0}^{H}\\mathbb{E}^{\\pi_{\\mathrm{lat}}\\circ\\phi}[[\\Delta_{h}(M_{\\mathrm{lat}},\\phi)](x_{h},a_{h})].\n$$", "text_format": "latex", "page_idx": 63}, {"type": "text", "text": "Furthermore, we also have ", "page_idx": 64}, {"type": "equation", "text": "$$\n\\sum_{h=0}^{H}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}\\Bigl[D_{\\mathsf{H}}^{2}\\Bigl(M_{\\mathrm{lat},h}\\bigl(s_{h},a_{h}\\bigr),\\widetilde{M}_{\\phi,h}^{\\star,\\pi_{\\mathrm{lat}}}(s_{h},a_{h})\\Bigr)\\Bigr]\\le\\sum_{h=0}^{H}\\mathbb{E}^{\\pi_{\\mathrm{lat}}\\circ\\phi}[[\\Delta_{h}(M_{\\mathrm{lat}},\\phi)](x_{h},a_{h})].\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "A corollary is the following lemma establishing errors between expectations under $M_{\\mathrm{lat}}$ , the model estimated by $\\mathrm{REP}_{\\mathsf{s e l f};\\mathsf{o p t}}$ , and those underthe $\\phi$ compressedPOMDP $\\widetilde{M}_{\\phi}^{\\star}$ ", "page_idx": 64}, {"type": "text", "text": "Lemma I.3 (Simulation lemma). For any latent model $M_{\\mathrm{lat}}$ with Markovian transition kernel $\\{P_{1\\mathsf{a t},h}\\}_{h\\in[H]}$ latent policy $\\pi_{\\mathrm{lat}}:S\\times[H]\\to\\Delta(A)$ and decoder $\\phi\\,\\in\\,\\Phi$ we have that for all $f:S\\times A\\to[0,1]$ ", "page_idx": 64}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigl|\\mathbb{E}^{M_{\\mathrm{lat}},\\pi_{\\mathrm{lat}}}[f(s_{h},a_{h})]-\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}[f(s_{h},a_{h})]\\bigr|}\\\\ &{\\qquad\\le\\displaystyle\\sum_{h^{\\prime}<h}\\mathbb{E}^{\\pi_{\\mathrm{lat}}\\circ\\phi}\\Bigl[\\bigl\\|[P_{\\mathrm{lat}}\\circ\\phi]_{h}(x_{h^{\\prime}},a_{h^{\\prime}})-\\phi_{h+1}\\sharp P_{\\mathrm{obs},h}^{\\star}(x_{h^{\\prime}},a_{h^{\\prime}})\\bigr\\|_{\\mathrm{tv}}\\Bigr],}\\end{array}\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "andtusfranysequenceofpolic $\\pi_{\\mathrm{lat}}^{(t)}$ latent models $M_{\\mathrm{1at}}^{(t)}$ and decoders $\\phi^{(t)}$ , we have: ", "page_idx": 64}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\displaystyle\\sum_{h=0}^{H}\\vert\\mathbb{E}^{M_{\\mathrm{lat}}^{(t)},\\pi_{\\mathrm{lat}}^{(t)}}\\vert f\\bigl(s_{h},a_{h}\\bigr)\\bigr]-\\widetilde{\\mathbb{E}}_{\\phi^{(t)}}^{\\pi_{\\mathrm{lat}}^{(t)}}\\bigl[f\\bigl(s_{h},a_{h}\\bigr)\\bigr]\\vert}\\\\ &{\\qquad\\le H\\sqrt{T H}\\displaystyle\\sqrt{\\displaystyle\\sum_{t=1}^{T}\\sum_{h=0}^{H}\\mathbb{E}^{\\pi_{\\mathrm{lat}}^{(t)}\\circ\\phi^{(t)}}\\left[\\left[\\Delta_{h}\\bigl(M_{\\mathrm{lat}}^{(t)},\\phi^{(t)}\\bigr)\\right]\\bigl(x_{h},a_{h}\\bigr)\\right]}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "1.1.3 Risk bound for O2L under CorruptionRobustness ", "text_level": 1, "page_idx": 64}, {"type": "text", "text": "We state the main risk bound for O2L under self-predictive estimation and the above definition of corruption robustness. ", "page_idx": 64}, {"type": "text", "text": "Theorem H.1 (Risk bound for O2L under self-predictive estimation and CorruptionRobustness). Assume REPself;opt satisfies Assumption A.1 with parameter $\\gamma>0$ and that $\\mathcal{M}_{\\mathrm{{lat}}}$ is realizable (i.e. $M_{\\mathrm{1at}}^{\\star}\\in\\mathcal{M}_{\\mathrm{1at}})$ .Furthermore,let $\\mathrm{ALG}_{\\mathrm{1at}}$ be CorruptionRobust (Definition I.2) with parameter $\\alpha$ Then,O2L(Algorithm $^{\\,l}$ \uff09with inputs $T,K,\\Phi$ \uff0c $\\mathrm{\\bfALG}_{\\mathrm{\\bflat}}$ and $\\mathrm{REP}_{\\mathsf{s e l f};\\mathsf{o p t}}$ hasexpectedrisk ", "page_idx": 64}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathsf{R i\\,s k}_{\\mathsf{o b s}}(T K)]\\leq c_{1}\\cdot\\mathsf{R i\\,s k}_{\\mathsf{b a s e}}(K)+c_{2}\\gamma\\cdot\\frac{K}{T}\\mathsf{E s t}_{\\mathsf{s e l f;o p t}}(T,\\gamma)+c_{3}\\gamma^{-1}\\cdot\\left(\\alpha^{2}+H\\right)\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "for absolute constants $c_{1},c_{2},c_{3}>0$ ", "page_idx": 64}, {"type": "text", "text": "1.1.4 Examples of CorruptionRobust algorithms ", "text_level": 1, "page_idx": 64}, {"type": "text", "text": "In this section, we establish that the GoLF algorithm satisfies the CorruptionRobust definition (Definition I.2) with a parameter $\\alpha\\approx K^{-1/2}$ . This improves upon the rate that would be obtained by invoking the generic guarantee in Lemma H.4. We expect that several other algorithms can be analyzed in a similar way, thereby leading to tight rates in the same fashion. We restate the pseudocode in Algorithm 5 for convenience. ", "page_idx": 64}, {"type": "text", "text": "Let $M_{\\mathrm{{lat}}}=\\left(r_{\\mathrm{{lat}}},P_{\\mathrm{{lat}}}\\right)$ be given, and we let $Q_{\\mathrm{1at}}^{\\star}:=Q^{M_{\\mathrm{lat}},\\star}$ , and $\\begin{array}{r}{T_{\\mathrm{lat},h}f(s,a):=r_{\\mathrm{lat},h}(s,a)\\,+}\\end{array}$ $\\mathbb{E}_{s^{\\prime}\\sim P_{\\mathrm{lat},h}(s,a)}[V_{f}(s^{\\prime})]$ We assume that the algorithm has a latent function class $\\mathcal{F}_{\\sf a l g}$ which realizes $Q_{\\mathrm{{lat}}}^{\\star}$ ,aswell asahelperclass $\\mathcal{G}_{\\sf a l g}$ which is $\\mathcal{T}_{\\mathrm{1at}}$ -complete for $\\mathcal{F}_{\\sf a l g}$ ", "page_idx": 64}, {"type": "text", "text": "Assumption I.1 ( $\\mathcal{T}_{\\mathrm{1at}}$ -completeness). We have: ", "page_idx": 64}, {"type": "equation", "text": "$$\n\\begin{array}{r}{Q_{\\mathrm{lat}}^{\\star}\\in\\mathcal{F}_{\\mathrm{alg}},\\quad a n d\\quad T_{\\mathrm{lat}}\\mathcal{F}_{\\mathrm{alg}}\\subseteq\\mathcal{G}_{\\mathrm{alg}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "For our analysis of GoLF, it is most natural to quantify the corruption levels in the following way. ", "page_idx": 64}, {"type": "text", "text": "Assumption I2 Corrupton levels of $M_{\\mathrm{lat}}$ and $\\widetilde{M}_{\\phi\\,.}^{\\star}$ . Let $\\varepsilon_{\\mathsf{r e p}}^{2}$ be such that frany sequence of policies $\\pi_{\\mathrm{1at}}^{(k)}$ played by the algorithm when interacting with the $\\phi$ -compressed POMDP, we have ", "page_idx": 64}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{\\mathrm{lat}}^{(k)}\\sim p_{\\mathrm{lat}}^{(k)}}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}^{(k)}}\\left[(r_{1\\mathrm{at},h}(s_{h},a_{h})-\\tilde{r}_{\\phi,h}^{\\pi^{(k)}}(s_{h},a_{h}))^{2}+\\left\\|P_{\\mathrm{lat},h}(s_{h},a_{h})-\\tilde{P}_{\\phi,h}^{\\pi^{(k)}}(s_{h},a_{h})\\right\\|_{\\mathrm{tr}}^{2}\\right]}}\\\\ &{}&{\\le\\varepsilon_{r\\mathrm{ep}}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "Algorithm 5 GOLF [JLM21] ", "page_idx": 65}, {"type": "text", "text": "input: Function classes $\\mathcal{F}$ and $\\mathcal{G}$ , confidence width $\\beta>0$   \ninitialize: $\\mathcal{F}^{(0)}\\leftarrow\\mathcal{F}$ $\\mathcal{D}_{h}^{(0)}\\leftarrow\\emptyset\\;\\;\\forall h\\in[H]$ 1: for episode $t=1,2,\\ldots,T$ do 2: Select policy $\\pi^{(t)}\\leftarrow\\pi_{f^{(t)}}$ , where $f^{(t)}:=\\arg\\operatorname*{max}_{f\\in{\\mathcal{F}}^{(t-1)}}f\\bigl(x_{1},\\pi_{f,1}(x_{1})\\bigr)$ 3: Execute $\\pi^{(t)}$ forone episode and obtain raetory $\\big(x_{1}^{(t)},a_{1}^{(t)},r_{1}^{(t)}\\big),\\dots,\\big(x_{H}^{(t)},a_{H}^{(t)},r_{H}^{(t)}\\big).$ 4: Udate dataet: $\\mathcal{D}_{h}^{(t)}\\leftarrow\\mathcal{D}_{h}^{(t-1)}\\cup\\left\\{\\left(x_{h}^{(t)},a_{h}^{(t)},x_{h+1}^{(t)}\\right)\\right\\}\\,\\,\\forall h\\in[\\bar{H}]$ 5: Compute confidence set: ", "page_idx": 65}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{F}^{(t)}\\leftarrow\\Bigg\\{f\\in\\mathcal{F}:\\mathcal{L}_{h}^{(t)}(f_{h},f_{h+1})-\\underset{g_{h}\\in\\mathcal{G}_{h}}{\\operatorname*{min}}\\mathcal{L}_{h}^{(t)}(g_{h},f_{h+1})\\leq\\beta\\;\\;\\forall h\\in[H]\\Bigg\\},}\\\\ &{\\mathrm{ere}\\;}&{\\mathcal{L}_{h}^{(t)}(f,f^{\\prime}):=\\underset{(x,a,r,x^{\\prime})\\in\\mathcal{D}_{h}^{(t)}}{\\sum}\\Big(f(x,a)-r-\\underset{a^{\\prime}\\in\\mathcal{A}}{\\operatorname*{max}}f^{\\prime}(x^{\\prime},a^{\\prime})\\Big)^{2},\\;\\forall f,f^{\\prime}\\in\\mathcal{F}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 65}, {"type": "text", "text": "6: end for ", "text_level": 1, "page_idx": 65}, {"type": "text", "text": "7: Output $\\widehat{\\pi}=\\mathsf{U n i f}\\left(\\pi^{(1:T)}\\right)$ ", "page_idx": 65}, {"type": "text", "text": "We note that ", "page_idx": 65}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\varepsilon_{\\mathrm{rep}}^{2}\\lesssim\\displaystyle\\sum_{k=1}^{K}\\displaystyle\\sum_{h=1}^{H}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}^{(k)}}\\left[D_{\\mathsf{H}}^{2}\\!\\left(M_{\\mathrm{lat},h}\\!\\left(s_{h},a_{h}\\right),\\widetilde{M}_{\\phi,h}^{\\star,\\pi_{\\mathrm{lat}}^{(k)}}\\left(s_{h},a_{h}\\right)\\right)\\right]}\\\\ {\\leq\\displaystyle\\sum_{k=1}^{K}\\displaystyle\\sum_{h=1}^{H}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}^{(k)}}\\left[D_{\\mathsf{H}}^{2}\\!\\left(M_{\\mathrm{lat},h}\\!\\left(s_{h},a_{h}\\right),\\widetilde{M}_{\\phi,h}^{\\star}\\!\\left(s_{1:h},a_{1:h}\\right)\\right)\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 65}, {"type": "text", "text": "by the data-processing inequality (cf. Eq. (90) and Eq. (80)) and the inequality $\\lVert p-q\\rVert_{\\mathsf{t v}}^{2}\\leq D_{\\mathsf{H}}^{2}(p,q)$ and thus a CorruptionRobustness bound in terms of $\\varepsilon_{\\mathsf{r e p}}$ implies a CorruptionRobustness bound in the sense of Definition I.2. ", "page_idx": 65}, {"type": "text", "text": "Theorem I.1 (Latent GOLF is CorruptionRobust). Under Assumption I.1 and Assumption I.2, Algorithm5with $\\beta=c(\\log(|\\mathcal{F}||\\mathcal{G}|K\\dot{H}\\delta^{-1})+\\varepsilon_{\\mathsf{r e p}})$ hasregret ", "page_idx": 65}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{k=1}^{K}J^{M_{\\mathrm{lat}}}(\\pi_{M_{\\mathrm{lat}}})-J^{M_{\\mathrm{lat}}}(\\pi^{(k)})\\leq\\mathcal{O}\\Big(H\\sqrt{C_{\\mathrm{cov}}K\\log(K)\\log(|\\mathcal{F}||\\mathcal{G}|H K/\\delta)}\\Big)}&{}\\\\ {\\displaystyle+\\ \\mathcal{O}\\Big(H^{3/2}\\sqrt{K C_{\\mathrm{cov}}\\log(K)\\varepsilon_{\\mathrm{rep}}^{2}}\\Big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 65}, {"type": "text", "text": "and consequently is CorruptionRobust (Definition I.2) with parameters ", "page_idx": 65}, {"type": "equation", "text": "$$\n\\alpha=\\frac{H^{3/2}}{\\sqrt{K}}\\sqrt{C_{\\mathrm{cov}}\\log(K)}\\,a n d\\,\\mathsf{R i}\\,\\mathsf{s k}_{\\mathsf{b a s e}}(K)=\\mathcal{O}\\bigg(\\frac{H}{\\sqrt{K}}\\sqrt{C_{\\mathrm{cov}}\\log(K)\\log(|\\mathcal{F}||\\mathcal{G}|H K)}\\bigg).\n$$", "text_format": "latex", "page_idx": 65}, {"type": "text", "text": "Corollary I1 (GoLF applied in  O2L). Let us suppose that the appropriate _assumptions for the estimator in Algorithm $^{4}$ to have regret bounded by Est $\\begin{array}{r l}{\\mathsf{\\bar{\\Pi}}_{\\mathsf{s e l f}}(T,\\gamma)}&{{}=}\\end{array}$ $\\mathcal{O}(\\sqrt{H C_{\\mathrm{cov}}T}\\log(C_{\\mathrm{cov}}|\\mathcal{M}_{\\mathrm{1at}}||\\mathcal{L}_{\\mathrm{1at}}||\\Phi|H T))$ (Lemma A.1) hold. Then, we can take $\\gamma\\approx K^{-1/2}$ and $T\\approx K^{4}$ and the bound Theorem $H.l$ gives an expected risk of $\\varepsilon$ with a number of trajectories $T K=\\mathsf{p o l y}(C_{\\mathsf{c o v}},H,\\log|\\mathcal{M}_{\\mathrm{1at}}|,\\log|\\Phi|,\\log|\\mathcal{L}_{\\mathrm{1at}}|)\\cdot1/\\varepsilon^{10}$ improving over the $1/\\varepsilon^{14}$ rate of the universal result (Corollary A.1). ", "page_idx": 65}, {"type": "text", "text": "1.2Proofs for Appendix I.1.2: Properties of $\\phi$ -compressedPOMDPs ", "text_level": 1, "page_idx": 65}, {"type": "text", "text": "Lemma I1 (Change of measure lemma). For any $\\phi\\in\\Phi$ $f\\,\\in\\,[S\\times A\\to[0,1]]$ $h\\,\\in\\,[H]$ and $\\pi_{\\mathrm{lat}}\\in[S\\times[H]\\to\\Delta(A)]$ ,wehave: ", "page_idx": 65}, {"type": "equation", "text": "$$\n\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}[f(s_{h},a_{h})]=\\mathbb{E}^{\\pi_{\\mathrm{lat}}\\circ\\phi}[[f\\circ\\phi](x_{h},a_{h})].\n$$", "text_format": "latex", "page_idx": 65}, {"type": "text", "text": "Proof of Lemma IL1l. Recal that $\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}$ denotes the law of $(x_{h},s_{h},a_{h})_{h\\in[H]}$ inthe $\\phi$ compressed POMDP when playing policy $\\pi_{\\mathrm{lat}}$ . For clarity, and to differentiate a random variable from its realization, in the proofs below we will use upper-case notation such as $\\{S_{h}=s_{h},A_{h}=a_{h},X_{h}=x_{h}\\}$ to indicate realizations of random variables in the POMDP. ", "page_idx": 65}, {"type": "text", "text": "Let $\\widetilde{d}_{h}^{\\pi_{\\mathrm{lat}}}(s,a)\\,=\\,\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(S_{h}\\,=\\,s,A_{h}\\,=\\,a)$ be the marginalized occupancy measure for in the $\\phi$ compressed POMDP $\\widetilde{M}_{\\phi}^{\\star}$ . We write $d_{h}^{\\pi_{\\mathrm{lat}}\\circ\\phi}:=d_{h}^{M_{\\mathsf{o b s}}^{\\star},\\pi_{\\mathrm{lat}}\\circ\\phi}$ e Tlaso The left-hand side in Eq (72 is qual to: ", "page_idx": 66}, {"type": "equation", "text": "$$\n\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}[f(s_{h},a_{h})]=\\sum_{s\\in S,a\\in A}\\tilde{d}_{h}^{\\pi_{\\mathrm{lat}}}(s,a)f(s,a),\n$$", "text_format": "latex", "page_idx": 66}, {"type": "text", "text": "Meanwhile, the right-hand side is equal to: ", "page_idx": 66}, {"type": "equation", "text": "$$\n\\mathbb{E}_{h}^{\\pi_{\\mathrm{lat}}\\circ\\phi}[[f\\circ\\phi](x_{h},a_{h})]=\\sum_{s\\in\\mathcal{S},a\\in\\mathcal{A}}f(s,a)\\sum_{x:\\phi(x)=s}d_{h}^{\\pi_{\\mathrm{lat}}\\circ\\phi}(x,a).\n$$", "text_format": "latex", "page_idx": 66}, {"type": "text", "text": "So it only remains to show that, for each $s\\ \\ \\in\\ S$ and $a\\mathrm{~\\ensuremath~{~\\in~}~}A$ , we have $\\begin{array}{r l}{\\tilde{d}_{h}^{\\pi_{1\\mathrm{at}}}(s,a)}&{{}=}\\end{array}$ $\\textstyle\\sum_{x:\\phi(x)=s}d_{h}^{\\pi_{\\mathrm{lat}}\\circ\\phi}(x,a)$ dTlato (z, a). Frsty, note that it is enough to show that zn:(zh)=sh @ $\\begin{array}{r}{\\sum_{x_{h}:\\phi(x_{h})=s_{h}}d_{h}^{\\pi_{1a t}\\circ\\phi}(x_{h})=}\\end{array}$ $\\tilde{d}_{h}^{\\pi_{\\mathrm{lat}}}(s_{h})$ ,since $\\tilde{d}_{h}^{\\pi_{\\mathrm{lat}}}(s_{h},a_{h})\\ =\\ \\tilde{d}_{h}^{\\pi_{\\mathrm{lat}}}(s_{h})\\pi_{\\mathrm{lat}}(a_{h}\\ \\ \\ |\\ \\ s_{h})$ and $\\begin{array}{r l}{\\sum_{x_{h}:\\phi(x_{h})=s_{h}}d_{h}^{\\pi_{1a t}\\circ\\phi}(x_{h},a_{h})}&{{}\\!\\!=}\\end{array}$ $\\begin{array}{r}{\\sum_{x_{h}:\\phi(x_{h})=s_{h}}d_{h}^{\\pi_{\\mathrm{lat}}\\circ\\phi}(x_{h})\\pi_{\\mathrm{lat}}(a_{h}\\mid\\phi(x_{h}))=\\pi_{\\mathrm{lat}}(a_{h}\\mid s_{h})\\sum_{x_{h}:\\phi(x_{h})=s_{h}}d_{h}^{\\pi_{\\mathrm{lat}}\\circ\\phi}(x_{h}).}\\end{array}$ Toward this, we have: ", "page_idx": 66}, {"type": "equation", "text": "$$\n\\sum_{\\stackrel{\\scriptstyle h:\\phi(x_{h})=s_{h}}{x_{h}\\cdot\\phi(x_{h})=s_{h}}}d_{h}^{\\pi_{\\mathrm{lat}}\\circ\\phi}(x_{h})=\\sum_{\\substack{x_{h}:\\phi(x_{h})=s_{h}\\,x_{h-1},a_{h-1}\\in\\mathcal{X}\\times A}}d_{h-1}^{\\pi_{\\mathrm{lat}}\\circ\\phi}(x_{h-1},a_{h-1})P_{\\mathrm{obs},h}^{\\star}(x_{h}\\mid x_{h-1},a_{h-1})}\\\\ {=\\sum_{\\substack{x_{h-1},a_{h-1}\\in\\mathcal{X}\\times A}}d_{h-1}^{\\pi_{\\mathrm{lat}}\\circ\\phi}(x_{h-1},a_{h-1})\\sum_{\\substack{x_{h}:\\phi(x_{h})=s_{h}}}P_{\\mathrm{obs},h}^{\\star}(x_{h}\\mid x_{h-1},a_{h-1})}\\\\ {=\\sum_{\\substack{x_{h-1},a_{h-1}\\in\\mathcal{X}\\times A}}d_{h-1}^{\\pi_{\\mathrm{lat}}\\circ\\phi}(x_{h-1},a_{h-1})P_{\\mathrm{obs},h}^{\\star}(\\phi(x_{h})=s_{h}\\mid x_{h-1},a_{h-1})}\\end{array}\n$$", "text_format": "latex", "page_idx": 66}, {"type": "text", "text": "At the same time, ", "page_idx": 66}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{d}_{h}^{\\pi_{\\mathrm{lat}}}(s_{h})=\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(S_{h}=s_{h})}\\\\ &{\\qquad\\qquad=\\displaystyle\\sum_{\\widetilde{x},\\widetilde{a}}\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(X_{h-1}=\\widetilde{x},A_{h-1}=\\widetilde{a})\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(S_{h}=s_{h}\\mid X_{h-1}=\\widetilde{x},A_{h-1}=\\widetilde{a})}\\\\ &{\\qquad\\qquad=\\displaystyle\\sum_{\\widetilde{x},\\widetilde{a}}\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(X_{h-1}=\\widetilde{x},A_{h-1}=\\widetilde{a})P_{\\phi\\mathrm{bs}}^{\\star}(\\phi(x_{h})=s_{h}\\mid x_{h-1},a_{h-1}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 66}, {"type": "text", "text": "where in the second equality we have used the definition of the observation function $s_{h}=\\mathcal{O}(x_{h})=$ $\\phi({\\boldsymbol{x}}_{h})$ ", "page_idx": 66}, {"type": "text", "text": "To conclude, it remains to show that for all $h$ ,wehave: ", "page_idx": 66}, {"type": "equation", "text": "$$\nd_{h}^{\\pi_{\\mathrm{lat}}\\circ\\phi}(x_{h},a_{h})=\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(X_{h}=x_{h},A_{h}=a_{h}).\n$$", "text_format": "latex", "page_idx": 66}, {"type": "text", "text": "eds $d_{h}^{\\pi_{\\mathrm{lat}}\\circ\\phi}(x_{h})=\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(X_{h}=x_{h})$ The case $h=1$ is clear. For the general case, we have: ", "page_idx": 66}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\vert_{\\hbar}^{\\pi_{\\mathrm{lat}}\\circ\\phi}(x_{h})=\\underset{x_{h-1},a_{h-1}\\in\\mathcal{X}\\times A}{\\sum\\sum}d_{\\hbar-1}^{\\pi_{\\mathrm{lat}}\\circ\\phi}(x_{h-1},a_{h-1})P_{\\mathrm{obs}}^{\\star}(x_{h}\\mid x_{h-1},a_{h-1})}\\\\ {=\\underset{x_{h-1},a_{h-1}\\in\\mathcal{X}\\times A}{\\sum}\\overset{\\sim}{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(X_{h}=x_{h-1},A_{h-1}=a_{h-1})P_{\\mathrm{obs}}^{\\star}(x_{h}\\mid x_{h-1},a_{h-1})}\\\\ {=\\underset{x_{h-1},a_{h-1}\\in\\mathcal{X}\\times A}{\\sum\\sum}\\overset{\\sim}{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(X_{h}=x_{h-1},A_{h-1}=a_{h-1})}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\times\\left.\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(X_{h}=x_{h}\\mid X_{h-1}=x_{h-1},A_{h-1}=a_{h-1})\\right.}\\\\ &{=\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(X_{h}=x_{h}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 66}, {"type": "text", "text": "Lemma I.2 (Near-markovianity of the $\\phi$ -compressed dynamics). For any decoder $\\phi$ ,basemodel $M_{\\mathrm{{1at}}}$ andpolicy $\\pi_{\\mathrm{lat}}:S\\times[H]\\to\\Delta(A)$ wehave: ", "page_idx": 67}, {"type": "equation", "text": "$$\n\\sum_{h=0}^{H}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}\\Bigl[D_{\\mathrm{H}}^{2}\\Bigl(M_{\\mathrm{lat},h}(s_{h},a_{h}),\\widetilde{M}_{\\phi,h}^{\\star}(s_{1:h},a_{1:h})\\Bigr)\\Bigr]\\le\\sum_{h=0}^{H}\\mathbb{E}^{\\pi_{\\mathrm{lat}}\\circ\\phi}[[\\Delta_{h}(M_{\\mathrm{lat}},\\phi)](x_{h},a_{h})].\n$$", "text_format": "latex", "page_idx": 67}, {"type": "text", "text": "Furthermore, we also have ", "page_idx": 67}, {"type": "equation", "text": "$$\n\\sum_{h=0}^{H}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}\\Bigl[D_{\\mathsf{H}}^{2}\\Bigl(M_{\\mathrm{lat},h}\\bigl(s_{h},a_{h}\\bigr),\\widetilde{M}_{\\phi,h}^{\\star,\\pi_{\\mathrm{lat}}}(s_{h},a_{h})\\Bigr)\\Bigr]\\le\\sum_{h=0}^{H}\\mathbb{E}^{\\pi_{\\mathrm{lat}}\\circ\\phi}[[\\Delta_{h}(M_{\\mathrm{lat}},\\phi)](x_{h},a_{h})].\n$$", "text_format": "latex", "page_idx": 67}, {"type": "text", "text": "Proof of Lemma I.2. We begin with the first event. Note that, for any $\\pi_{\\mathrm{1at}}$ ,thePODMPkernel $\\widetilde{M}_{\\phi,h}^{\\star}(r_{h},s_{h+1}=\\cdot\\mid s_{1:h},a_{1:h})$ canbe written as: ", "page_idx": 67}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{\\cal M}_{\\phi,h}^{\\star}(r_{h},s_{h+1}=\\cdot\\mid s_{1:h},a_{1:h})=\\displaystyle\\sum_{x_{h},a_{h}\\in\\chi\\times A}\\widetilde P_{\\phi}^{\\pi_{\\mathrm{at}}}(r_{h},s_{h+1}=\\cdot\\mid x_{h},a_{h},s_{1:h},a_{1:h})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\quad\\times\\widetilde P_{\\phi}^{\\pi_{\\mathrm{lat}}}(x_{h},a_{h}\\mid s_{1:h},a_{1:h})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\widetilde P_{\\phi}^{\\pi_{\\mathrm{at}}}(r_{h},s_{h+1}=\\cdot\\mid x_{h},a_{h})\\widetilde P_{\\phi}^{\\pi_{\\mathrm{at}}}(x_{h},a_{h}\\mid s_{1:h},a_{1:h}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 67}, {"type": "text", "text": "where we hae used $\\widetilde{M}(r_{h},s_{h+1}=\\cdot\\mid s_{1:h},a_{1:h})=\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(r_{h},s_{h+1}=\\cdot\\mid s_{1:h},a_{1:h})$ probability, and that $x_{h},a_{h}$ is a sufficient statistic for $r_{h}$ and $s_{h+1}$ . We further note that ", "page_idx": 67}, {"type": "equation", "text": "$$\n\\widetilde{P}_{\\phi}^{\\pi_{\\mathrm{lat}}}(r_{h},s_{h+1}=\\cdot\\mid x_{h},a_{h})=M_{\\mathrm{obs},h}^{\\star}(r_{h},\\phi_{h+1}(x_{h+1})=\\cdot\\mid x_{h},a_{h}),\n$$", "text_format": "latex", "page_idx": 67}, {"type": "text", "text": "since $s_{h+1}\\,=\\,\\mathcal{O}_{h+1}(x_{h+1})\\,=\\,\\phi_{h+1}(x_{h+1})$ is a deterministic function of $x_{h+1}$ and $r_{h},x_{h+1}\\,\\sim$ $M_{\\sf o b s}^{\\star}{}_{,h}(x_{h},a_{h})$ Thus, for a fixed $h$ and $t$ , and omiting the $h$ indices on the decoder $\\phi$ for cleanliness, the expectation in equation Eq. (73) becomes: ", "page_idx": 67}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\begin{array}{r l}&{\\widetilde{\\mathbb{E}}_{\\phi}^{\\mathrm{rot}}\\left[D_{\\mathbf{i}}^{2}\\!\\left(M_{\\mathrm{1at},h}(s_{h},a_{h}),\\widetilde{M}_{\\phi,h}^{*}(r_{h},s_{h+1}=-\\,\\lvert\\,s_{1h},a_{1:h})\\right)\\right]}\\\\ &{\\le}&{\\displaystyle\\sum_{s_{1},h_{1},a_{1}\\wedge\\epsilon}\\widetilde{P}_{\\phi}^{\\mathrm{rot}}(s_{1:h},a_{1:h})\\sum_{x_{h},a_{h}}\\widetilde{P}_{\\phi}^{\\mathrm{rot}}(x_{h},a_{h}\\mid s_{1:h},a_{1:h})}\\\\ &{~~\\times_{1}\\alpha_{1:h}\\epsilon(s\\times A)^{h}\\phi}\\\\ &{=\\displaystyle\\sum_{s_{h+1},a_{h}\\in\\{\\mathcal{S}\\}}\\widetilde{P}_{\\phi}^{\\mathrm{rot}}(s_{1:h},a_{1:h})\\widetilde{P}_{\\phi}^{\\mathrm{rot}}(x_{h},a_{h}\\mid s_{1:h},a_{1:h})}\\\\ &{~~\\times_{1}\\alpha_{1:h}\\epsilon(s\\times A)^{h}\\phi}\\\\ &{~~~\\times_{h}\\alpha_{1:h}\\epsilon(s\\times A)^{2}\\qquad\\qquad\\qquad\\qquad\\qquad\\quad\\times D_{\\mathbf{i}}^{2}\\!\\left(M_{\\mathrm{1at},h}(\\phi(x_{h}),a_{h}),\\widetilde{P}_{\\phi}^{\\mathrm{rot}}(r_{h},\\phi(x_{h+1})=\\,\\cdot\\mid x_{h},a_{h})\\right)}\\\\ &{=\\displaystyle\\sum_{x_{h},a_{h}\\in\\mathcal{S}\\times\\mathcal{N}}\\widetilde{P}_{\\phi}^{\\mathrm{rot}}(x_{h},a_{h})D_{\\mathbf{i}}^{2}(M_{\\mathrm{1at}}(\\phi(x_{h}),a_{h}),M_{\\phi,h}^{*}(r_{h},\\phi(x_{h+1}=\\,\\cdot\\mid x_{h},a_{h}))}\\\\ &{~~\\times_{1}\\alpha_{1:h}\\epsilon(s\\times A)^{2}\\phi}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 67}, {"type": "text", "text": "(Change of measure (Lemma I.1)) ", "page_idx": 67}, {"type": "text", "text": "as desired.Summing over $\\textit{h}\\in[H]$ we obtain the desired bound. The bound Eq. (74) is a consequence of Eq. (73) and the data-processing inequality. Namely, using the definition of $\\widetilde{M}_{\\phi,h}^{\\star,\\pi_{\\mathrm{lat}}}$ from Eq. (71) and the joint convexity of the squared Hellinger distance we have: ", "page_idx": 67}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D_{\\mathsf{H}}^{2}\\bigg(M_{\\mathrm{1at},h}\\big(\\cdot\\mid s_{h},a_{h}\\big),\\widetilde{M}_{\\phi,h}^{\\star,\\pi_{\\mathrm{lat}}}\\big(\\cdot\\mid s_{h},a_{h}\\big)\\bigg)}\\\\ &{\\qquad\\le\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}\\Big[D_{\\mathsf{H}}^{2}\\Big(M_{\\mathrm{1at},h}\\big(\\cdot\\mid s_{h},a_{h}\\big),\\widetilde{M}_{\\phi,h}^{\\star}\\big(\\cdot\\mid s_{1:h},a_{1:h}\\big)\\Big)\\mid s_{h},a_{h}\\Big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 67}, {"type": "text", "text": "Thus, we have ", "page_idx": 68}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb E_{\\phi}^{\\pi_{\\mathrm{lat}}}\\Bigl[D_{\\mathsf{H}}^{2}\\Bigl(M_{\\mathrm{lat},h}\\bigl(\\cdot\\mid s_{h},a_{h}\\bigr),\\widetilde{M}_{\\phi,h}^{\\star,\\pi_{\\mathrm{lat}}}\\bigl(\\cdot\\mid s_{h},a_{h}\\bigr)\\Bigr)\\Bigr]}\\\\ &{\\quad\\le\\mathbb E_{\\phi}^{\\pi_{\\mathrm{lat}}}\\Bigl[\\mathbb E_{\\phi}^{\\pi_{\\mathrm{lat}}}\\Bigl[D_{\\mathsf{H}}^{2}\\Bigl(M_{\\mathrm{lat},h}\\bigl(\\cdot\\mid s_{h},a_{h}\\bigr),\\widetilde{M}_{\\phi,h}^{\\star}\\bigl(\\cdot\\mid s_{1:h},a_{1:h}\\bigr)\\Bigr)\\mid s_{h},a_{h}\\Bigr]\\Bigr]}\\\\ &{\\quad=\\mathbb E_{\\phi}^{\\pi_{\\mathrm{lat}}}\\Bigl[D_{\\mathsf{H}}^{2}\\Bigl(M_{\\mathrm{lat},h}\\bigl(\\cdot\\mid s_{h},a_{h}\\bigr),\\widetilde{M}_{\\phi,h}^{\\star}\\bigl(\\cdot\\mid s_{1:h},a_{1:h}\\bigr)\\Bigr)\\Bigr],}\\end{array}\n$$", "text_format": "latex", "page_idx": 68}, {"type": "text", "text": "as desired. ", "page_idx": 68}, {"type": "text", "text": "Lemma I.3 (Simulation lemma). For any latent model $M_{\\mathrm{lat}}$ with Markovian transition kernel $\\{P_{1\\mathsf{a t},h}\\}_{h\\in[H]}$ latent policy $\\pi_{\\mathrm{lat}}:S\\times[H]\\to\\Delta(A)$ and decoder $\\phi\\,\\in\\,\\Phi$ we have that for all $f:S\\times A\\to[0,1]$ ", "page_idx": 68}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigl|\\mathbb{E}^{M_{\\mathrm{lat}},\\pi_{\\mathrm{lat}}}[f(s_{h},a_{h})]-\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}[f(s_{h},a_{h})]\\bigr|}\\\\ &{\\qquad\\le\\displaystyle\\sum_{h^{\\prime}<h}\\mathbb{E}^{\\pi_{\\mathrm{lat}}\\circ\\phi}\\Bigl[\\bigl\\|[P_{\\mathrm{lat}}\\circ\\phi]_{h}(x_{h^{\\prime}},a_{h^{\\prime}})-\\phi_{h+1}\\sharp P_{\\mathrm{obs},h}^{\\star}(x_{h^{\\prime}},a_{h^{\\prime}})\\bigr\\|_{\\mathrm{tv}}\\Bigr],}\\end{array}\n$$", "text_format": "latex", "page_idx": 68}, {"type": "text", "text": "and thusforany sequenceofpolicies $\\pi_{\\mathrm{lat}}^{(t)}$ latent models $M_{\\mathrm{1at}}^{(t)}$ and decoders $\\phi^{(t)}$ , we have: ", "page_idx": 68}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\displaystyle\\sum_{h=0}^{H}\\vert\\mathbb{E}^{M_{\\mathrm{lat}}^{(t)},\\pi_{\\mathrm{lat}}^{(t)}}\\vert f\\bigl(s_{h},a_{h}\\bigr)\\bigr]-\\widetilde{\\mathbb{E}}_{\\phi^{(t)}}^{\\pi_{\\mathrm{lat}}^{(t)}}\\bigl[f\\bigl(s_{h},a_{h}\\bigr)\\bigr]\\vert}\\\\ &{\\qquad\\le H\\sqrt{T H}\\displaystyle\\sqrt{\\displaystyle\\sum_{t=1}^{T}\\sum_{h=0}^{H}\\mathbb{E}^{\\pi_{\\mathrm{lat}}^{(t)}\\circ\\phi^{(t)}}\\left[\\left[\\Delta_{h}\\bigl(M_{\\mathrm{lat}}^{(t)},\\phi^{(t)}\\bigr)\\right]\\bigl(x_{h},a_{h}\\bigr)\\right]}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 68}, {"type": "text", "text": "Proof of Lemma I.3. Firstly note that, from Lemma I.1, the left-hand-side of Eq. (75) is equivalent to ", "page_idx": 68}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 68}, {"type": "text", "text": "$\\begin{array}{r}{\\left|\\mathbb{E}^{M_{\\mathrm{lat}},\\pi_{\\mathrm{lat}}}[f(s_{h},a_{h})]-\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi_{\\mathrm{lat}}}[f(s_{h},a_{h})]\\right|=\\left|\\mathbb{E}^{M_{\\mathrm{lat}},\\pi_{\\mathrm{lat}}}[f(s_{h},a_{h})]-\\mathbb{E}^{M_{\\mathrm{obs}}^{\\star},\\pi_{\\mathrm{lat}}\\circ\\phi}[[f\\circ\\phi](x_{h},a_{h})]\\right|}\\end{array}$ (81) For any T1at : S \u00d7 [H] \u2192 \u25b3(A), let dTat,h = dh dMiat,T1at denote the occupancy in M1at, and similarly for any $\\pi_{\\mathsf{o b s}}:{\\mathcal{X}}\\times[H]\\to\\Delta(A)$ let $d_{\\mathsf{o b s},h}^{\\pi_{\\mathsf{o b s}}}(x_{h},a_{h})=d_{h}^{M_{\\mathsf{o b s}}^{\\star},\\pi_{\\mathsf{o b s}}}(x_{h},a_{h})$ Mos Toa(Ch, ah) denote theocupancy in $M_{\\mathsf{o b s}}^{\\star}$ Weoverload otationbyletting $\\begin{array}{r}{d_{\\mathsf{o b s},h}^{\\pi_{\\mathrm{lat}}\\circ\\phi}(s,a):=\\sum_{x:\\phi(x)=s}d_{\\mathsf{o b s},h}^{\\pi\\circ\\phi}(x,a)}\\end{array}$ . We will establishthe stronger result that ", "page_idx": 68}, {"type": "equation", "text": "$$\n\\Big\\|d_{\\mathrm{lat},h}^{\\pi_{\\mathrm{lat}}}(\\cdot)-d_{\\mathrm{obs},h}^{\\pi_{\\mathrm{lat}}\\circ\\phi}(\\cdot)\\Big\\|_{\\mathrm{tv}}\\le\\sum_{h^{\\prime}<h}\\mathbb{E}^{\\pi_{\\mathrm{lat}}\\circ\\phi}\\big[\\|[P_{\\mathrm{lat}}\\circ\\phi](x_{h^{\\prime}},a_{h^{\\prime}})-\\phi\\|P_{\\mathrm{obs}}^{\\star}(x_{h^{\\prime}},a_{h^{\\prime}})\\|_{\\mathrm{tv}}\\big],\n$$", "text_format": "latex", "page_idx": 68}, {"type": "text", "text": "where the tv norm on the left-hand-side is over ${\\mathcal{S}}\\times{\\mathcal{A}}$ . Note that this implies the desired bound on Eq. (81) by Holder's inequality. We prove this by induction over $h$ . For the base case $[h=0]$ O,we have: ", "page_idx": 68}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{s_{1},a_{1}}\\left|d_{14\\pi,1}^{\\pi_{\\mathrm{trat}}}(s_{1},a_{1})-d_{04\\pi}^{\\pi_{\\mathrm{trat}}}\\phi(s_{1},a_{1})\\right|}}\\\\ &{=\\sum_{s_{1},a_{1}}\\left|P_{14\\pi,0}(s_{1}\\mid\\theta)\\pi_{14\\pi}(a_{1}\\mid s_{1})-\\sum_{x_{1}=\\phi(x_{1})=s_{1}}d_{04\\pi}^{\\pi_{\\mathrm{trat}}}\\phi(x_{1},a_{1})\\right|}\\\\ &{=\\displaystyle\\sum_{s_{1},a_{1}}\\left|P_{14\\pi,0}(s_{1}\\mid\\theta)\\pi_{14\\pi}(a_{1}\\mid s_{1})-\\sum_{x_{1}=\\phi(x_{1})=s_{1}}P_{04\\pi,0}^{\\star}(x_{1}\\mid\\theta)\\pi_{14\\pi}(a_{1}\\mid\\phi(x_{1}))\\right|}\\\\ &{=\\displaystyle\\sum_{s_{1}}\\left|P_{14\\pi,0}(s_{1}\\mid\\theta)-\\phi_{1}\\xi_{\\quad\\phi(s_{1},0)}^{\\star}(s_{1}\\mid\\theta)\\right|\\sum_{a_{1}}\\pi_{14\\pi}(a_{1}\\mid s_{1})}\\\\ &{=\\|P_{14\\pi,0}(\\theta)-\\phi_{1}\\|P_{\\neq\\phi(s_{1},0)}^{\\star}(\\theta)\\|_{W_{1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 68}, {"type": "text", "text": "F $\\begin{array}{r}{d_{\\mathrm{obs},h}^{\\pi\\circ\\phi}(s_{h})\\,=\\,\\sum_{a_{h}}d_{\\mathrm{obs},h}^{\\pi\\circ\\phi}(s_{h},a_{h})}\\end{array}$ and $\\begin{array}{r}{P_{\\mathtt{o b s}}^{\\star}(s_{h}\\ |\\ x_{h-1},a_{h-1})=\\phi\\sharp P_{\\mathtt{o b s}}^{\\star}(s_{h}\\ |\\ x_{h-1},a_{h-1})=\\sum_{x_{h}:\\phi(x_{h})=s_{h}}P_{\\mathtt{o b s}}^{\\star}(x_{h}\\overset{\\cdot}{\\ }x_{h-1},a_{h-1}).}\\end{array}$ Let us also abbreviate $\\pi~:=\\pi_{\\mathrm{lat}}$ .Firstly note that it is suficient to establish the result for $\\begin{array}{r}{\\sum_{s_{h}\\in\\cal S}\\left|d_{\\mathrm{lat},h}^{\\pi}(s_{h})-d_{\\mathrm{obs},h}^{\\pi\\circ\\phi}(s_{h})\\right|}\\end{array}$ since ", "page_idx": 69}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{s_{h},a_{h}\\in\\mathcal{S}\\times\\mathcal{A}}\\left|d_{\\mathrm{lat},h}^{\\pi}(s_{h},a_{h})-d_{\\mathrm{obs},h}^{\\pi\\circ\\phi}(s_{h},a_{h})\\right|=\\displaystyle\\sum_{s_{h},a_{h}\\in\\mathcal{S}\\times\\mathcal{A}}\\left|d_{\\mathrm{lat},h}^{\\pi}(s_{h})-d_{\\mathrm{obs},h}^{\\pi\\circ\\phi}(s_{h})\\right|\\pi(a_{h}\\mid s_{h})}\\\\ {=\\displaystyle\\sum_{s_{h}\\in\\mathcal{S}}\\left|d_{\\mathrm{lat},h}^{\\pi}(s_{h})-d_{\\mathrm{obs},h}^{\\pi\\circ\\phi}(s_{h})\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 69}, {"type": "text", "text": "Below, all summations over $s_{h}$ (resp. $x_{h}$ ) with domain unspecified are over $\\boldsymbol{S}$ (resp. $\\mathcal{X}$ ), and likewise for summations over $s_{h},a_{h}$ or $x_{h},a_{h}$ . We have: ", "page_idx": 69}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{i=1}^{\\infty}\\left|\\sum_{j=1}^{\\infty}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i})}-\\sum_{n\\geq0}^{\\infty}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i})}\\right|^{2}}}\\\\ &{=\\sum_{i=1}^{\\infty}\\sum_{j=1}^{\\infty}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times}\\\\ &{=\\sum_{i=1}^{\\infty}\\sum_{j=1}^{\\infty}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad-\\sum_{n\\geq0}^{\\infty}\\sum_{i=1}^{\\infty}(\\theta_{i+1})\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}}\\\\ &{=\\sum_{i=1}^{\\infty}\\sum_{j=1}^{\\infty}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j}(\\theta_{i+1,n})}\\mathrm{e}^{\\tau_{i,j \n$$$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{i,j=1,\\dots,N}\\left(\\sum_{l=1}^{N}\\sum_{l=1}^{N}\\left(\\sum_{l=k}^{l}\\phi_{l,i}(l_{i},l_{j})\\right)P_{l,j}(l_{i},l_{j+1},l_{i+1})\\right)}\\Bigg|}&{=\\exp\\left(\\phi_{l,i}\\left(\\phi_{l-1};l_{i+1},l_{i+1}\\right)\\right)}\\\\ &{=-\\sum_{i,j=1,\\dots,N}\\frac{\\hat{P}_{l}(l_{i},l_{j})}{\\sin\\theta_{i}}(\\phi_{l,i}(l_{i+1,i+1}))P_{l,j}(l_{i+1,j+1},l_{i+1})}\\\\ &{\\quad-\\sum_{i,j=1}^{N}\\sum_{l=1}^{N}\\phi_{l,i}^{(k)}(l_{i+1,i+1})P_{l,j}(l_{i},l_{i+1})\\phi_{l,i}(l_{i+1,j+1})}\\\\ &{\\quad+\\sum_{i,j=1}^{N}\\sum_{l=1}^{N}\\phi_{l,i}^{(k)}(l_{i+1,i+1})P_{l,j}(l_{i+1,j})\\phi_{l,i}(l_{i+1,j+1})}\\\\ &{\\quad-\\sum_{i,j=1}^{N}\\frac{\\hat{P}_{l}(l_{i+1,i+1})}{\\sin\\theta_{i}}(\\phi_{l-1,i+1})P_{l,j}(l_{i+1,j+1},l_{i+1})\\Bigg|}\\\\ {\\xi_{i,j}\\sum_{i,k=1}^{N}\\left(\\phi_{l,i}(l_{i+1,i+1})\\right)=\\frac{\\sum_{i,j=1}^{N}(\\phi_{l,i}(l_{i+1,i+1}))}{\\cos\\theta_{i}}\\sqrt{\\phi_{l,i}(l_{i+1,i+1})}\\displaystyle\\sum_{l=1}^{N}P_{l}(l_{i+1,i+1})\\left(\\sum_{l=1}^{l}\\phi_{l,i}(l_{i+1,i+1})\\right)}\\\\ &{\\quad+\\sum_{i,j=1}^{N}\\sum_{l=1}^{N}\\frac{\\hat{P}_{l}(l_{i+1,i+1})}{\\sin\\theta_{i}}(\\phi_{l-1,i+1})\\left(\\phi_{l,i+1}(l_{i+1,i+\n$$", "text_format": "latex", "page_idx": 69}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 69}, {"type": "text", "text": "From which it follows that, for each $h$ ,wehave: ", "page_idx": 70}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\Big\\vert\\displaystyle d_{1\\mathrm{at},h}^{\\pi}(\\cdot)-d_{\\mathsf{o b s},h}^{\\pi\\circ\\phi}(\\phi^{-1}(\\cdot))\\Big\\vert\\Big\\vert_{\\mathrm{tv}}\\le\\displaystyle\\sum_{h^{\\prime}<h}\\mathbb{E}^{\\pi\\circ\\phi}\\Big[\\big\\vert\\big\\vert\\big[P_{\\mathrm{lat}}\\circ\\phi\\big]_{h^{\\prime}}(x_{h^{\\prime}},a_{h^{\\prime}})-\\phi_{h^{\\prime}+1}\\sharp_{\\phi\\mathrm{bs},h^{\\prime}}^{\\star}(x_{h^{\\prime}},a_{h^{\\prime}})\\big\\vert\\Big\\vert_{\\mathrm{tv}}\\Big]}&{}\\\\ {\\displaystyle\\le\\sum_{h^{\\prime}\\in[H]}\\mathbb{E}^{\\pi\\circ\\phi}\\Big[\\big\\vert\\big\\vert\\big[P_{\\mathrm{lat}}\\circ\\phi\\big]_{h^{\\prime}}(x_{h^{\\prime}},a_{h^{\\prime}})-\\phi_{h^{\\prime}+1}\\sharp_{\\phi\\mathrm{bs},h^{\\prime}}^{\\star}(x_{h^{\\prime}},a_{h^{\\prime}})\\big\\vert\\Big\\vert_{\\mathrm{tv}}\\Big].}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 70}, {"type": "text", "text": "1.3 Proofs for Appendix I.1.3: Risk Bound Under CorruptionRobustness (Theorem H.1) ", "text_level": 1, "page_idx": 70}, {"type": "text", "text": "Theorem H.1 (Risk bound for O2L under self-predictive estimation and CorruptionRobustness). Assume $\\mathbf{REP}_{\\mathsf{s e l f;o p t}}$ satisfiesAssumption A.1 with parameter $\\gamma>0$ and that $\\mathcal{M}_{\\mathrm{{lat}}}$ isrealizable(i.e. $M_{\\mathrm{1at}}^{\\star}\\in\\mathcal{M}_{\\mathrm{1at}},$ .Furthermore, let $\\mathrm{ALG}_{\\mathrm{1at}}$ be CorruptionRobust (Definition I.2) with parameter $\\alpha$ Then,O2L(Algorithm $^{\\,l}$ )with inputs $T,K,\\Phi$ \uff0c $\\mathrm{\\bfALG}_{\\mathrm{\\bflat}}$ , and REPself;opt has expected risk ", "page_idx": 70}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathsf{R i\\,s k}_{\\mathsf{o b s}}(T K)]\\leq c_{1}\\cdot\\mathsf{R i\\,s k}_{\\mathsf{b a s e}}(K)+c_{2}\\gamma\\cdot\\frac{K}{T}\\mathsf{E s t}_{\\mathsf{s e l f;o p t}}(T,\\gamma)+c_{3}\\gamma^{-1}\\cdot\\left(\\alpha^{2}+H\\right)\n$$", "text_format": "latex", "page_idx": 70}, {"type": "text", "text": "for absolute constants $c_{1},c_{2},c_{3}>0$ ", "page_idx": 70}, {"type": "text", "text": "Proof of Theorem H.1. Let us write mTat $\\pi_{\\mathrm{1at}}^{(t,K+1)}=\\widehat{\\pi}_{\\mathrm{1at}}^{(t)}$ and, for any $t,k\\in[T]\\times[K+1]$ \uff0c $\\pi_{\\mathsf{o b s}}^{(t,k)}:=$ \u03c0(t,k) o \u03a6(t). Let Pobs denote the distributions of played policies Ts) induced by the interaction of $\\mathrm{\\bfALG_{\\mathrm{1at}}}$ and $\\mathrm{REP}_{\\mathsf{s e l f};\\mathsf{o p t}}$ inside the O2L algorithm. Let us write the online sum of self-prediction errors as ", "page_idx": 70}, {"type": "equation", "text": "$$\n\\varepsilon_{\\mathrm{rep}}^{2}:=\\sum_{t=1}^{T}\\sum_{k=1}^{K+1}\\sum_{h=0}^{H}\\mathbb{E}_{\\pi_{\\mathrm{obs}}^{(t,k)}\\sim p^{(t,k)}}\\mathbb{E}_{\\mathrm{H}}^{\\pi_{\\mathrm{obs}}^{(t,k)}}\\left[D_{\\mathrm{H}}^{2}\\big([M_{\\mathrm{lat}}^{(t)}\\circ\\phi^{(t)}]_{h}(x_{h},a_{h}),\\phi_{h+1}^{(t)}\\sharp_{\\mathrm{obs},h}^{(k)}(x_{h},a_{h})\\big)\\right]\n$$", "text_format": "latex", "page_idx": 70}, {"type": "text", "text": "S $\\widehat{\\pi}_{\\mathrm{lat}}=\\mathsf{U n i f}(\\widehat{\\pi}_{\\mathrm{lat}}^{(1)},\\cdot\\cdot\\cdot,\\widehat{\\pi}_{\\mathrm{lat}}^{(T)})$ (Line 2) we have ", "page_idx": 70}, {"type": "equation", "text": "$$\n\\mathbb{E}[{\\tt R i s k}_{\\tt o b s}(T K)]=\\frac{1}{T}\\sum_{t=1}^{T}\\mathbb{E}\\Big[J^{M_{\\mathrm{obs}}^{\\star}}(\\pi_{\\tt o b s}^{\\star})-J^{M_{\\mathrm{obs}}^{\\star}}(\\widehat{\\pi}_{\\tt o b s}^{(t)})\\Big].\n$$", "text_format": "latex", "page_idx": 70}, {"type": "text", "text": "We take the following decomposition on the risk ", "page_idx": 70}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{J^{M_{\\mathrm{obs}}^{\\star}}(\\pi_{\\mathsf{o b s}}^{\\star})-J^{M_{\\mathrm{obs}}^{\\star}}(\\widehat{\\pi}_{\\mathsf{o b s}}^{(t)})=J^{M_{\\mathrm{lat}}^{\\star}}(\\pi_{M_{\\mathrm{lat}}^{\\star}})-J^{M_{\\mathrm{lat}}^{(t)}}(\\pi_{M_{\\mathrm{lat}}^{(t)}})+\\underbrace{J^{M_{\\mathrm{lat}}^{(t)}}(\\pi_{M_{\\mathrm{lat}}^{(t)}})-J^{M_{\\mathrm{lat}}^{(t)}}(\\widehat{\\pi}_{\\mathrm{lat}}^{(t)})}_{\\mathrm{A_{t}}}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(\\mathsf{J}_{\\mathrm{lat}}^{M_{\\mathrm{lat}}^{(t)}}(\\widehat{\\pi}_{\\mathsf{l a t}}^{(t)})-J^{M_{\\mathrm{obs}}^{\\star}}(\\widehat{\\pi}_{\\mathsf{o b s}}^{(t)})\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 70}, {"type": "text", "text": "We will show that $\\begin{array}{r l r}{\\mathbb E\\!\\left[\\sum_{t=1}^{T}\\mathrm{A}_{\\mathrm{t}}\\right]}&{\\lesssim}&{{\\cal T}\\mathsf{R e g}_{\\mathsf{b a s e}}(K)\\,+\\,\\alpha\\sqrt{T}\\,\\mathbb E\\!\\left[\\varepsilon_{\\mathsf{r e p}}\\right]}\\end{array}$ and that $\\mathbb{E}\\Big[\\sum_{t=1}^{T}\\mathrm{B}_{\\mathrm{t}}\\Big]\\;\\;\\lesssim$ $\\sqrt{T H}\\,\\mathbb{E}[\\varepsilon_{\\mathsf{r e p}}]$ then retuim to the isterm $J^{M_{\\mathrm{lat}}^{\\star}}\\big(\\pi_{M_{\\mathrm{lat}}^{\\star}}\\big)-J^{M_{\\mathrm{lat}}^{(t)}}\\big(\\pi_{M_{\\mathrm{lat}}^{(t)}}\\big)$ athe endo theprof. ", "page_idx": 70}, {"type": "text", "text": "To bound $\\mathbb{E}\\left[\\sum_{t=1}^{T}A_{t}\\right]$ we note that ", "page_idx": 70}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[A_{t}]\\leq c_{1}T\\mathbb{R}\\mathbb{i}\\times\\!\\operatorname{kase}(K)+}\\\\ &{\\qquad\\qquad\\alpha\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}\\left[\\sqrt{\\displaystyle\\sum_{k=1}^{K}\\mathbb{E}\\mathbb{E}_{\\pi_{\\mathrm{i}}^{(t,k)}\\sim p_{k\\mathrm{i}}^{(t,k)}}\\mathbb{E}_{\\hat{\\phi}^{(t)}}^{\\pi_{\\mathrm{i}}^{(t,k)}}\\left[D_{\\mathbb{H}}^{2}\\!\\left(M_{1\\mathrm{H},h}^{(s)}(s_{h},a_{h}),\\widetilde{M}_{\\phi^{(t)},h}^{*}(s_{1},a_{1:h})\\right)\\right]}\\right]}\\\\ &{\\qquad\\qquad\\qquad\\alpha\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}\\left[\\sqrt{\\displaystyle\\sum_{k=1}^{K}\\mathbb{E}\\mathbb{E}_{\\pi_{\\mathrm{i}}^{(t,k)}\\sim p_{k\\mathrm{i}}^{(t,k)}}\\mathbb{E}_{\\pi_{\\mathrm{i}}^{(t,k)}}^{\\pi^{(t,k)}\\sim p_{k\\mathrm{i}}^{(t,k)}\\sim p_{k\\mathrm{i}}^{(t)}}\\left[\\big[\\Delta_{h}(M_{1\\mathrm{H}}^{(t)},\\phi^{(s)})\\big](x_{h},a_{h})\\right]}\\right]}\\\\ &{\\leq c_{1}T\\mathbb{R}\\mathbb{i}\\times\\!\\operatorname{kase}(K)+\\alpha\\sqrt{T}\\mathbb{E}\\left[\\sqrt{\\displaystyle\\sum_{k=1}^{T}\\sum_{k=1}^{K}\\mathbb{E}_{\\pi_{\\mathrm{i}}^{(t,k)}\\sim p_{k\\mathrm{i}}^{(t,k)}}\\mathbb{E}_{\\pi_{\\mathrm{i}}^{(t,k)}}^{\\pi^{(t,k)}}\\left[\\big[\\Delta_{h}(M_{1\\mathrm{H}}^{(t)},\\phi^{(s)})\\big](x_{h},a_{h})\\right]}\\right]}\\\\ &{\\leq c_{1}T\\mathbb{R}\\mathbb{i}\\times\\!\\operatorname{kase}(K)+\\alpha\\sqrt{T}\\mathbb{E}\\left[\\sqrt{\\displaystyle\\sum_{l=1}^{T}\\sum_{k=1}^{K}\\mathbb{E}_{\\pi_{\\mathrm{i}}^{(t,k)}\\sim p_{k\\mathrm{i}}^{(t,k)}}\\mathbb{E}_{\\pi_{\\mathrm{i}}^{(\n$$", "text_format": "latex", "page_idx": 70}, {"type": "text", "text": "where the first line follows from the CorruptionRobust definition (Definition I.2), the second line follows from Lemma I.2, the third line follows by Cauchy-Schwartz, and the last line recalls the definition of $\\varepsilon_{\\mathsf{r e p}}$ from Eq. (83). ", "page_idx": 71}, {"type": "text", "text": "For the term $\\textstyle\\sum_{t=1}^{T}B_{t}$ , for any $\\pi_{\\mathrm{lat}}:S\\times[H]\\to\\Delta(A)$ we let $Q_{\\mathrm{1at}^{(t)},h}^{\\pi_{\\mathrm{1at}}}=T_{h}^{M_{\\mathrm{1at}}^{(t)}}Q_{\\mathrm{1at}^{(t)},h+1}^{\\pi_{\\mathrm{1at}}}$ be the $Q^{\\pi_{\\mathrm{lat}}}$ function of the latent MDP $M_{\\mathrm{1at}}^{(t)}$ . Note that ", "page_idx": 71}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{t=1}^{T}\\biggl\\{J_{\\mathrm{int}}^{(t)}(\\hat{\\pi}_{1\\mathrm{in}}^{(t)})-\\mathbb{E}^{\\hat{\\pi}_{1\\mathrm{in}}^{(t)}\\phi^{(t)}}\\left[\\big[Q_{\\mathrm{int}}^{\\hat{\\pi}_{1}^{(t)}}\\circ\\phi^{(\\varepsilon)}\\big]_{1}(x_{1},a_{1})\\right]\\biggr\\}}\\qquad}&{}\\\\ &{=\\sum_{t=1}^{T}\\mathbb{E}^{M_{\\mathrm{int}}^{(t)},\\hat{\\pi}_{1\\mathrm{in}}^{(t)}}\\left[Q_{\\mathrm{int}}^{\\hat{\\pi}_{1}^{(t)}}(s_{1},a_{1})\\right]-\\mathbb{E}^{\\hat{\\pi}_{1\\mathrm{in}}^{(t)}\\phi^{(t)}}\\left[\\big[Q_{\\mathrm{int}}^{\\hat{\\pi}_{1}^{(t)}}\\circ\\phi^{(\\varepsilon)}\\big]_{1}(x_{1},a_{1})\\right]}\\\\ &{\\leq\\sum_{t=1}^{T}\\mathbb{E}^{\\hat{\\pi}_{1\\mathrm{in}}^{(t)}\\phi^{(t)}}\\left[\\big[|[P_{\\mathrm{int}}^{(t)}\\circ\\phi^{(t)}]_{0}(\\theta)-\\phi_{1}^{(t)}\\Sigma_{\\hat{\\pi}_{1}^{(t)}}^{\\rho_{1}}(\\hat{\\pi}_{1})\\big]\\qquad\\qquad\\qquad\\qquad(\\mathrm{by~I~})}\\\\ &{\\leq\\sum_{t=1}^{T}\\underbrace{\\mathbb{E}^{\\hat{\\pi}_{1}^{(t)}\\phi^{(t)}}}_{\\in\\mathrm{in}}\\varnothing^{(t)}\\left[\\big[|[P_{\\mathrm{int}}^{(t)}\\circ\\phi^{(t)}]_{h}(x_{h},a_{h})-\\phi_{h+1}^{(t)}\\Sigma_{\\hat{\\pi}_{1}^{(t)},h}^{\\rho_{1}}(x_{h},a_{h})\\big|\\right]_{\\mathrm{tv}}\\right]}\\\\ &{\\leq\\sqrt{T}\\bar{H}_{E\\mathrm{in}}^{\\varepsilon}\\varphi,}&{(\\mathrm{by~Cauchy})}\\end{array}\n$$", "text_format": "latex", "page_idx": 71}, {"type": "text", "text": "so it is enough to bound ", "page_idx": 71}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\Biggl\\{\\mathbb{E}^{\\widehat{\\pi}_{\\mathrm{lat}}^{(t)}\\circ\\phi^{(t)}}\\left[[Q_{\\mathrm{1at}^{(t)}}^{\\widehat{\\pi}_{\\mathrm{lat}}^{(t)}}\\circ\\phi^{(t)}]_{1}\\bigl(x_{1},a_{1}\\bigr)\\right]-J^{M_{\\mathrm{obs}}^{\\star}}\\bigl(\\widehat{\\pi}_{\\mathrm{obs}}^{(t)}\\bigr)\\Biggr\\}.\n$$", "text_format": "latex", "page_idx": 71}, {"type": "text", "text": "Fix $t$ and $h$ , whose indexing we omit below for cleanliness. Note that, for any $\\pi_{\\mathrm{lat}}:S\\!\\times\\![H]\\to\\Delta(A)$ wehave: ", "page_idx": 71}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\mathbb E^{\\pi_{\\mathrm{iat}}\\circ\\phi}\\bigg[\\Big([Q_{\\mathrm{iat}}^{\\pi_{\\mathrm{lat}}}\\circ\\phi]_{h}(x_{h},a_{h})-T_{h}^{M_{\\mathrm{ss}}^{\\star},\\pi_{\\mathrm{lat}}\\circ\\phi}[Q_{\\mathrm{lat}}^{\\pi_{\\mathrm{lat}}}\\circ\\phi]_{h+1}(x_{h},a_{h})\\Big)^{2}\\bigg]}&{\\quad{\\scriptstyle(86.4\\pi^{5})}}\\\\ &{\\leq2\\,\\mathbb E^{\\pi_{\\mathrm{iat}}\\circ\\phi}\\bigg[\\big([r_{\\mathrm{lat}}\\circ\\phi]_{h}-r_{\\mathrm{obs},h}^{\\star}\\big)^{2}(x_{h},a_{h})\\Big]}&{\\quad{\\scriptstyle(87.1\\pi^{5})}}\\\\ &{\\quad+\\,2\\,\\mathbb E^{\\pi_{\\mathrm{lat}}\\circ\\phi}\\bigg[\\Big(\\mathbb E_{P_{\\mathrm{lat},h}(\\phi(x_{h}),a_{h})}\\big[Q_{\\mathrm{lat},h+1}^{\\pi_{\\mathrm{lat}}}(\\cdot,\\pi_{\\mathrm{lat}})\\Big]-\\mathbb E_{P_{\\mathrm{obs},h}^{\\star}(x_{h},a_{h})}\\big[[Q_{\\mathrm{lat}}^{\\pi_{\\mathrm{lat}}}\\circ\\phi]_{h+1}(\\cdot,\\pi_{\\mathrm{lat}})\\big]\\Big)^{2}\\bigg]}&{\\quad{\\scriptstyle(16.4\\pi^{5})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 71}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\leq2\\mathbb{E}^{\\pi\\mathrm{iat}\\circ\\phi}\\Big[\\big([r_{140}\\circ\\phi]_{h}-r_{\\circ\\mathrm{bs},h}^{\\star}\\big)^{2}(x_{h},a_{h})+\\big\\|P_{1\\mathrm{at},h}(\\phi(x_{h}),a_{h})-\\phi_{h+1}\\sharp P_{\\circ\\mathrm{bs},h}^{\\star}(x_{h},a_{h})\\big\\|_{\\mathrm{tv}}^{2}\\Big]}&{}\\\\ &{\\leq4\\mathbb{E}^{\\pi\\mathrm{iat}\\circ\\phi}\\big[D_{\\mathsf{H}}^{2}\\big(M_{141,h}(\\phi_{h}(x_{h}),a_{h}),\\phi_{h+1}\\sharp M_{\\circ\\mathrm{bs},h}^{\\star}(x_{h},a_{h})\\big)\\big],}&{\\quad{\\mathrm{~(~L~a~n~d~\\textstyle~R~~~}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 71}, {"type": "text", "text": "where the final line follows from two applications of the data-processing inequality (since $\\begin{array}{r c l l c l}{{M_{{\\bf1}{\\bf a t},h}(r_{h},s_{h+1}}}&{{\\mid\\phi_{h}(x_{h}),a_{h})}}&{{=}}&{{R_{{\\bf1}{\\bf a t},h}(r_{h}}}&{{\\mid\\phi_{h}(x_{h}),a_{h})P_{{\\bf1}{\\bf a t},h}(s_{h+1}}}&{{\\mid\\phi_{h}(x_{h}),a_{h})}}\\end{array}$ and $\\phi_{h+1}\\sharp M_{\\mathrm{obs},h}^{\\star}(r_{h},s_{h+1}~\\mid~x_{h},a_{h})\\;=\\;R_{\\mathrm{obs},h}^{\\star}(r_{h}~\\mid~x_{h},a_{h})\\phi_{h+1}\\sharp P_{\\mathrm{obs},h}^{\\star}(s_{h+1}~\\mid~x_{h},a_{h}))$ as well as the bound $\\left\\lVert p-q\\right\\rVert_{\\mathsf{t v}}^{2}\\le D_{\\mathsf{H}}^{2}(p,q)$ . Summing this over $t,h$ and using a standard decomposition for ", "page_idx": 71}, {"type": "text", "text": "regret (Lemma C.6) gives: ", "page_idx": 72}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{t=1}^{T}\\Bigg\\{\\mathbb{E}^{\\eta_{\\mathrm{t}}^{(s)}\\omega^{(s)}}\\Bigg[\\big[Q_{\\mathrm{lat}}^{\\eta_{\\mathrm{t}}^{(s)}}\\circ\\phi^{(s)}\\big]_{\\mathrm{l}}(x_{1},a_{1})\\Bigg]-J^{M_{\\mathrm{at}}^{\\eta_{\\mathrm{t}}^{(s)}}}\\big[\\widehat\\pi_{\\mathrm{abs}}^{(s)}\\big]\\Bigg\\}}\\\\ {\\displaystyle}&{=\\displaystyle\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}^{\\eta_{\\mathrm{t}}^{(s)}\\omega^{(s)}}\\Bigg[\\big[Q_{\\mathrm{lat}}^{\\eta_{\\mathrm{t}}^{(s)}}\\circ\\phi^{(s)}\\big]_{h}(x_{h},a_{h})-T_{h}^{M_{\\mathrm{at}}^{\\eta_{\\mathrm{t}}^{(s)}},\\eta_{\\mathrm{t}}^{(s)}\\omega^{(s)}}\\big[Q_{\\mathrm{lat}}^{\\eta_{\\mathrm{t}}^{(s)}}\\circ\\phi^{(s)}\\big]_{h+1}(x_{h},a_{h})\\Bigg]}\\\\ {\\displaystyle}&{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(\\mathrm{Lemma~C.~G})}\\\\ {\\displaystyle}&{\\leq\\sqrt{T H}\\sqrt{\\displaystyle\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}^{\\eta_{\\mathrm{t}}^{(s)}\\omega^{(s)}}\\Bigg[\\left(\\big[Q_{\\mathrm{lat}}^{\\eta_{\\mathrm{t}}^{(s)}}\\circ\\phi^{(s)}\\big]_{h}(x_{h},a_{h})-T_{h}^{M_{\\mathrm{at}}^{\\eta_{\\mathrm{t}}^{(s)}},\\eta_{\\mathrm{t}}^{(s)}\\omega^{(s)}}\\big[Q_{\\mathrm{lat}}^{\\eta_{\\mathrm{t}}^{(s)}}\\circ\\phi^{(s)}\\big]_{h+1}(x_{h},a_{h})\\right.}\\\\ {\\displaystyle}&{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\left.\\qquad\\qquad\\qquad\\qquad\\times\\Big](\\overline{{\\mathcal{L}}})^{\\eta_{\\mathrm{t}}^{(s)}}\\times\\widehat{\\mathcal{L}}_{\\mathrm{abs}}^{\\eta_{\\mathrm{\n$$", "text_format": "latex", "page_idx": 72}, {"type": "text", "text": "\u2264\u221a4THerep. ", "page_idx": 72}, {"type": "text", "text": "Returning to the decomposition of Eq. (84) and combining everything gives: ", "page_idx": 72}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[\\mathsf{R i}\\,\\mathsf{s k}_{\\mathrm{obs}}\\big]\\leq\\displaystyle\\frac{1}{T}\\Bigg\\{\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}\\Big[J^{M_{\\mathrm{lat}}^{\\star}}\\big(\\pi_{M_{\\mathrm{lat}}^{\\star}}\\big)-J^{M_{\\mathrm{lat}}^{(t)}}\\big(\\pi_{M_{\\mathrm{lat}}^{(t)}}\\big)\\Big]\\Bigg\\}+\\displaystyle\\frac{1}{T}\\Big(\\alpha\\sqrt{T}+4\\sqrt{T H}\\Big)\\,\\mathbb{E}\\big[\\varepsilon_{\\mathrm{rep}}\\big]}\\\\ &{\\qquad\\qquad+\\displaystyle c_{1}\\cdot\\mathsf{R i}\\,\\mathsf{s k}_{\\mathrm{base}}(K)}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\frac{1}{T}\\Bigg\\{\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}\\Big[J(\\pi^{\\star})-J^{M_{\\mathrm{lat}}^{(t)}}\\big(\\pi_{M_{\\mathrm{lat}}^{(t)}}\\big)+\\gamma\\varepsilon_{\\mathrm{rep}}^{2}\\Big]\\Bigg\\}+\\displaystyle\\frac{\\gamma^{-1}}{T}\\Big(\\alpha\\sqrt{T}+4\\sqrt{T H}\\Big)^{2}}\\\\ &{\\qquad\\qquad+\\displaystyle c_{1}\\cdot\\mathsf{R i}\\,\\mathsf{s k}_{\\mathrm{base}}(K)}\\\\ &{\\qquad\\qquad\\leq\\gamma\\displaystyle\\frac{2K}{T}\\mathbb{E}\\,\\mathsf{s t}_{\\mathrm{self,opt}}(T,\\gamma)+2\\gamma^{-1}\\big(\\alpha^{2}+16H\\big)+c_{1}\\cdot\\mathsf{R i}\\,\\mathsf{s k}_{\\mathrm{base}}(K),}\\end{array}\n$$", "text_format": "latex", "page_idx": 72}, {"type": "text", "text": "where the second inequality follows by AM-GM applied to the middle term and the third inequality follows from: i) Jensen's inequality, ii) Assumption A.1 applied to the distributions $\\begin{array}{r}{\\bar{p}_{\\mathsf{o b s}}^{(t)}=\\frac{1}{K}\\sum_{k=1}^{K}p_{\\mathsf{o b s}}^{(t,k)}}\\end{array}$ ,ii) the bound $K\\!+\\!1\\leq2K$ , and iv) theinequality $(x\\!+\\!y)^{2}\\leq2(x^{2}\\!+\\!y^{2})$ \u53e3 ", "page_idx": 72}, {"type": "text", "text": "1.4 Proofs for Appendix I.1.4: Examples of CorruptionRobust Algorithms ", "text_level": 1, "page_idx": 72}, {"type": "text", "text": "Theorem I.1 (Latent GOLF is CorruptionRobust). Under Assumption I.1 and Assumption I.2, Algorithm $^{5}$ With $\\beta=c(\\log(|\\mathcal{F}||\\mathcal{G}|K\\dot{H}\\delta^{-1})+\\varepsilon_{\\mathsf{r e p}})$ hasregret ", "page_idx": 72}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{k=1}^{K}J^{M_{\\mathrm{lat}}}(\\pi_{M_{\\mathrm{lat}}})-J^{M_{\\mathrm{lat}}}(\\pi^{(k)})\\leq\\mathcal{O}\\Big(H\\sqrt{C_{\\mathrm{cov}}K\\log(K)\\log(|\\mathcal{F}||\\mathcal{G}|H K/\\delta)}\\Big)}&{}\\\\ {\\displaystyle+\\ \\mathcal{O}\\Big(H^{3/2}\\sqrt{K C_{\\mathrm{cov}}\\log(K)\\varepsilon_{\\mathrm{rep}}^{2}}\\Big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 72}, {"type": "text", "text": "and consequently is CorruptionRobust (Definition I.2) with parameters ", "page_idx": 72}, {"type": "equation", "text": "$$\n\\alpha=\\frac{H^{3/2}}{\\sqrt{K}}\\sqrt{C_{\\mathrm{cov}}\\log(K)}\\,a n d\\,\\mathsf{R i}\\,\\mathsf{s k}_{\\mathsf{b a s e}}(K)=\\mathcal{O}\\bigg(\\frac{H}{\\sqrt{K}}\\sqrt{C_{\\mathrm{cov}}\\log(K)\\log(|\\mathcal{F}||\\mathcal{G}|H K)}\\bigg).\n$$", "text_format": "latex", "page_idx": 72}, {"type": "text", "text": "Proof of Theorem I.1. Recall that the agent is observing data from the $\\phi$ -compressed POMDP $\\widetilde{M}_{\\phi}^{\\star}$ and thus the datasets are of the form $\\mathcal{D}_{h}^{(k)}=\\mathcal{D}_{\\phi,h}^{(k)}=\\{\\phi(x_{h}^{(i)}),a_{h}^{(i)},r_{h}^{(i)},\\phi(x_{h+1}^{(i)})\\}_{i=1}^{k-1}$ .For any $\\pi_{\\mathrm{1at}}\\in\\Pi_{\\mathrm{1at}}$ ,we define ", "page_idx": 72}, {"type": "equation", "text": "$$\n\\widetilde{T}_{\\phi,h}^{\\pi_{\\mathrm{lat}}}f(s_{h},a_{h})=\\widetilde{r}_{\\phi,h}^{\\pi_{\\mathrm{lat}}}(s_{h},a_{h})+\\mathbb{E}_{s^{\\prime}\\sim\\widetilde{P}_{\\phi,h}^{\\pi_{\\mathrm{lat}}}(s_{h},a_{h})}[f(s^{\\prime})],\n$$", "text_format": "latex", "page_idx": 72}, {"type": "text", "text": "where WhererT.lat tandpmlat and are the poliey-dependent Markov operators defined in Eq. (67) and Eq. (i9) As a consequence, we observe the following misspecification guarantee for $\\mathcal{T}_{\\mathrm{1at}}$ ", "page_idx": 72}, {"type": "text", "text": "Lemma I.4 (Misspecification guarantee for $\\mathcal{T}_{\\mathrm{1at}}$ ", "page_idx": 73}, {"type": "equation", "text": "$$\n\\forall f:\\mathcal{S}\\times\\mathcal{A}\\to[0,1]:\\quad\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi^{(k)}}\\bigg[\\Big(\\mathcal{T}_{\\mathrm{lat},h}f(s_{h},a_{h})-\\widetilde{\\mathcal{T}}_{\\phi,h}^{\\pi^{(k)}}f(s_{h},a_{h})\\Big)^{2}\\bigg]\\leq\\mathcal{O}(\\varepsilon_{\\mathrm{rep}}^{2}).\n$$", "text_format": "latex", "page_idx": 73}, {"type": "text", "text": "Proofof Lemma4. FollowsfmAsumtionI2 anthe denitions of T and Tiat,h. \u53e3", "page_idx": 73}, {"type": "text", "text": "We begin with the following lemmas, which will be proved in the sequel. ", "page_idx": 73}, {"type": "text", "text": "Lemma I.5 (Optimism). For the choice of $\\beta$ in Theorem I.1, with probability at least $1-\\delta$ wehave that for all $k\\in[K]$ ", "page_idx": 73}, {"type": "equation", "text": "$$\nQ_{\\mathrm{1at}}^{\\star}\\in\\mathcal{F}^{(k)}.\n$$", "text_format": "latex", "page_idx": 73}, {"type": "text", "text": "Lemma I.6 (Small in-sample squared Bellman errors). With probability at least $1-\\delta$ wehavethat forall $k\\in[K]$ $h\\in[H]$ and $f\\in\\mathcal{F}^{(k)}$ ", "page_idx": 73}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{k-1}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi^{(i)}}\\left[\\left(f(s_{h},a_{h})-\\widetilde{\\mathcal{T}}_{\\phi,h}^{\\pi^{(i)}}f(s_{h},a_{h})\\right)^{2}\\right]\\le\\mathcal{O}(\\beta).\n$$", "text_format": "latex", "page_idx": 73}, {"type": "text", "text": "Let us write $\\pi_{\\circ\\mathfrak{b}s}^{(k)}:=\\pi^{(k)}\\circ\\phi$ Let us intd the sorthand $\\begin{array}{r}{\\tilde{d}_{\\mathsf{o b s},h}^{(k)}:=\\sum_{i=1}^{k-1}d_{\\mathsf{o b s},h}^{\\pi_{\\mathsf{o b s}}^{(k)}}}\\end{array}$ , where $d_{\\mathsf{o b s}}^{\\pi}$ .is the occupancy for $M_{\\mathsf{o b s}}^{\\star}$ , and also the burn-in time ", "page_idx": 73}, {"type": "equation", "text": "$$\n\\kappa_{h}(x,a):=\\operatorname*{min}\\Biggl\\{k:\\sum_{i=1}^{k-1}d_{\\mathsf{o b s},h}^{\\pi^{(k)}}(x,a)\\geq C_{\\mathsf{c o v}}\\mu_{h}^{\\star}(x,a)\\Biggr\\}.\n$$", "text_format": "latex", "page_idx": 73}, {"type": "text", "text": "Let us recall, from the analysis of [XFBJK23], that for any $h\\in[H]$ and $f:S\\times A\\to[0,1]$ wehave ", "page_idx": 73}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{K}\\mathbb{E}^{\\pi^{(k)}}[f(s_{h},a_{h})\\mathbb{I}\\{k<\\kappa_{h}(s_{h},a_{h})\\}]\\leq2C_{\\mathrm{cov}},\n$$", "text_format": "latex", "page_idx": 73}, {"type": "text", "text": "as well as ", "page_idx": 73}, {"type": "equation", "text": "$$\n\\sum_{h=1}^{H}\\sum_{k=1}^{K}\\sum_{s,a}\\frac{(d_{h^{\\mathrm{obs}}}^{\\pi_{\\mathrm{obs}}^{(k)}}(x,a)\\mathbb{I}\\{k\\geq\\kappa_{h}(x,a)\\})^{2}}{\\tilde{d}_{h}^{(k)}(x,a)}\\leq O(H C_{\\mathrm{cov}}\\log(K)).\n$$", "text_format": "latex", "page_idx": 73}, {"type": "equation", "text": "$$\n\\sum_{k}J^{M_{\\mathrm{lat}}}(\\pi_{M_{\\mathrm{lat}}})-J^{M_{\\mathrm{lat}}}(\\pi^{(k)})\\le\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\mathbb{E}^{M_{\\mathrm{lat}},\\pi^{(k)}}[f^{(k)}(s_{h},a_{h})-\\mathcal{T}_{\\mathrm{lat}}f^{(k)}(s_{h},a_{h})]\n$$", "text_format": "latex", "page_idx": 74}, {"type": "text", "text": "(Optimism (Lemma I1.5)) ", "page_idx": 74}, {"type": "equation", "text": "$$\n\\leq\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi^{(k)}}[f^{(k)}(s_{h},a_{h})-T_{\\mathrm{1at}}f^{(k)}(s_{h},a_{h})]+H^{3/2}\\sqrt{K\\varepsilon_{\\mathrm{rep}}^{2}}\n$$", "text_format": "latex", "page_idx": 74}, {"type": "equation", "text": "$$\n=\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{(k)}\\circ\\phi}[[(f^{(k)}-\\mathcal{T}_{\\mathrm{lat}}f^{(k)})\\circ\\phi](x_{h},a_{h})]+H^{3/2}\\sqrt{K\\varepsilon_{\\mathrm{rep}}^{2}}\n$$", "text_format": "latex", "page_idx": 74}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\leq\\sum_{k=1}^{K}\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{(k)}\\circ\\phi}[\\big[\\big(f^{(k)}-\\mathcal{T}_{\\mathrm{at}}f^{(k)}\\big)\\circ\\phi\\big]\\big(x_{h},a_{h}\\big)\\mathbb{I}\\big\\{k\\geq\\kappa_{h}(x_{h},a_{h})\\big\\}]}\\\\ &{\\displaystyle\\qquad+2H C_{\\mathrm{cov}}+H^{3/2}\\sqrt{K\\varepsilon_{\\mathrm{rep}}^{2}}}\\\\ &{\\displaystyle\\leq\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{(k)}\\circ\\phi}\\Big[\\Big(\\big(f^{(k)}-\\widetilde{\\mathcal{T}}_{\\phi,h}^{\\pi^{(k)}}f^{(k)}\\big)\\circ\\phi\\Big]\\big(x_{h},a_{h}\\big)\\mathbb{I}\\big\\{k\\geq\\kappa_{h}(x_{h},a_{h})\\big\\}\\Big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 74}, {"type": "text", "text": "Note that, by change of measure (Lemma I.1) and the misspecification guarantee (Lemma I.4), the second term is bounded by: ", "page_idx": 74}, {"type": "equation", "text": "$$\n(\\mathrm{II})=\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\widetilde\\mathbb{E}_{\\phi}^{\\pi^{(k)}}\\left[(\\widetilde{\\mathcal{T}}_{\\phi,h}^{\\pi^{(k)}}f^{(k)}-\\mathcal{T}_{\\mathrm{lat},h}f^{(k)})(s_{h},a_{h})\\right]\\le\\sqrt{K H\\varepsilon_{\\mathrm{rep}}^{2}}.\n$$", "text_format": "latex", "page_idx": 74}, {"type": "text", "text": "Turning to the first term, we have: ", "page_idx": 74}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{\\tau=1}^{H}\\sum_{k=1}^{K}\\mathbb{E}^{\\pi_{k}^{(k)}}\\left[\\left(f^{(k)}-\\widetilde{\\mathcal{T}}_{\\phi,h}^{\\pi_{k}^{(k)}}f^{(k)}\\right)\\circ\\phi\\right](x_{h},a_{h})\\mathbb{I}\\{k\\geq\\kappa_{h}(x_{h},a_{h})\\}\\right]}\\\\ &{\\leq\\sqrt{\\displaystyle\\sum_{h=1}^{H}\\sum_{k=1}^{K}\\frac{(d_{h}^{\\pi_{k}^{(k)}}(x,a)]\\{k\\geq\\kappa_{h}(x,a)\\}\\}^{2}}\\sqrt{\\displaystyle\\sum_{h=1}^{H}\\sum_{k=1}^{K}\\mathbb{E}_{d_{\\phi,h}^{\\kappa}}\\left[\\left(f^{(k)}-\\widetilde{\\mathcal{T}}_{\\phi,h}^{\\pi_{k}^{(k)}}f^{(k)}\\right)\\circ\\phi\\right)^{2}(x_{h},a_{h})}}\\\\ &{\\leq\\sqrt{H C_{\\mathrm{cov}}\\log(K)}\\sqrt{\\displaystyle\\sum_{h=1}^{H}\\sum_{k=1}^{K}\\mathbb{E}_{d_{\\phi,h}^{\\kappa}}\\left[\\left(f^{(k)}-\\widetilde{\\mathcal{T}}_{\\phi,h}^{\\pi_{k}^{(k)}}f^{(k)}\\right)\\circ\\phi\\right)^{2}(x_{h},a_{h})}\\Bigg]}\\\\ &{\\quad\\times\\left(\\mathrm{coverability~potential~Eq.~}(92)\\right)}\\\\ &{\\overbrace{\\displaystyle\\int_{\\mathrm{dativ}}^{H}\\sum_{k=1}^{K}\\sum_{k=1}^{K-1}\\widetilde{\\pi}\\tau^{(i)}\\left[\\int_{\\mathrm{cov}}\\sum_{h=1}^{K}\\sum_{k=1}^{\\infty}\\widetilde{\\tau}\\left(\\int_{\\mathrm{cov}}\\sum_{h=1}^{K}\\sum_{l=k}^{\\infty}\\phi_{\\mathrm{dot}}\\right)\\times\\left(\\int(f^{(k)}-\\widetilde{\\mathcal{T}}_{\\phi,h}^{\\pi_{k}^{(k)}}f^{(k)})\\circ\\phi\\right)^{2}\\right]}^{\\left(1/\\infty\\right)}}\\\\ &{\\overbrace{\\left[\\mathrm{dative~}\\right]}^{H}\\left[\\phi\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 74}, {"type": "text", "text": "(change of measure, Lemma I.1) ", "page_idx": 74}, {"type": "text", "text": "where we have used that, from Lemma I.6, we have: ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\sum_{h=1}^{H}\\sum_{k=1}^{K}\\sum_{i=1}^{k-1}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi^{(i)}}\\bigg[\\Big(f^{(k)}\\big(s_{h},a_{h}\\big)-\\widetilde{\\mathcal{T}}_{\\phi}^{\\pi^{(i)}}f^{(k)}\\big(s_{h},a_{h}\\big)\\Big)^{2}\\bigg]\\le\\mathcal{O}(\\beta H K).\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "This gives an upper bound on the regret of ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{K}J^{M_{\\mathrm{lat}}}(\\pi_{M_{\\mathrm{lat}}})-J^{M_{\\mathrm{lat}}}(\\pi^{(k)})\\leq\\mathcal{O}\\Big(H\\sqrt{C_{\\mathrm{cov}}K\\log(K)\\beta}+H^{3/2}\\sqrt{K\\varepsilon_{\\mathrm{rep}}^{2}}\\Big).\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "Using that $\\begin{array}{r}{\\beta=\\mathcal{O}\\Big(\\!\\log\\!\\Big(\\frac{|\\mathcal{F}||\\mathcal{G}|H K}{\\delta}\\Big)+\\varepsilon_{\\mathsf{r e p}}\\Big)}\\end{array}$ and simplifying gives ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{\\Lambda}J^{M_{\\mathrm{lat}}}(\\pi_{M_{\\mathrm{lat}}})-J^{M_{\\mathrm{lat}}}(\\pi^{(k)})\\leq\\mathcal{O}\\Big(H\\sqrt{C_{\\mathrm{cov}}K\\log(K)\\log(|\\mathcal{F}||\\mathcal{G}|H K/\\delta)}\\Big)+\\mathcal{O}\\Big(H^{3/2}\\sqrt{K C_{\\mathrm{cov}}\\log(|\\mathcal{F}||\\mathcal{G}|H K/\\delta)}\\Big).\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "as desired. It only remains to establish the concentrations results. ", "page_idx": 75}, {"type": "text", "text": "Concentration analysis. We establish the concentration results of Lemma I.5 and Lemma I.6. ", "page_idx": 75}, {"type": "text", "text": "Proof of Lemma I.6. Let ", "text_level": 1, "page_idx": 75}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{{\\calX}}_{k}(h,f)=\\big(f_{h}(s_{h}^{(k)},a_{h}^{(k)})-r_{h}^{(k)}-f_{h+1}(s_{h+1}^{(k)})\\big)^{2}-\\Big(\\widetilde{\\mathrm{\\calT}}_{\\phi}^{\\pi^{(k)}}f_{h}\\big(s_{h}^{(k)},a_{h}^{(k)}\\big)-r_{h}^{(k)}-f_{h+1}\\big(s_{h+1}^{(k)}\\big)\\Big)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "Let $\\mathfrak{F}_{k,h}=\\{s_{1}^{(i)},a_{1}^{(i)},r_{1}^{(i)},\\ldots,s_{H}^{(i)},a_{H}^{(i)},r_{H}^{(i)}\\}_{i=1}^{k}.$ ..,.SH,aH,r=1 Note that ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[r_{h}^{(k)}+f_{h+1}\\big(s_{h+1}^{(k)}\\big)\\mid\\mathfrak{F}_{k,h}\\big]=\\mathbb{E}\\big[r_{h}^{(k)}+f_{h+1}\\big(s_{h+1}^{(k)}\\big)\\mid\\pi^{(k)}\\big]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}\\big[\\mathbb{E}\\big[r_{h}^{(k)}+f_{h+1}\\big(s_{h+1}^{(k)}\\big)\\mid s_{h}^{(k)},a_{h}^{(k)},\\pi^{(k)}\\big]\\mid\\pi^{(k)}\\big]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}\\Big[\\widetilde{\\mathcal{T}}_{\\phi}^{\\pi^{(k)}}f\\big(s_{h}^{(k)},a_{h}^{(k)}\\big)\\mid\\pi^{(k)}\\Big]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi^{(k)}}\\Big[\\widetilde{\\mathcal{T}}_{\\phi}^{\\pi^{(k)}}f\\big(s_{h},a_{h}\\big)\\Big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "and thus that ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[X_{k}(h,f)\\mid\\mathfrak{F}_{k,h}]=\\smash{\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi^{(k)}}}\\bigg[\\Big(f_{h}(s_{h},a_{h})-\\widetilde{\\mathcal{T}}_{\\phi}^{\\pi^{(k)}}f_{h}(s_{h},a_{h})\\Big)^{2}\\bigg].}\\end{array}\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "Next, note that ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{V a r}[X_{k}(h,f)\\mid\\mathfrak{F}_{k,h}]\\le\\mathbb{E}\\Bigl[\\left(X_{k}(h,f)\\right)^{2}\\mid\\mathfrak{F}_{k,h}\\Bigr]}\\\\ &{\\phantom{x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x}}\\\\ &{\\phantom{x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x}\\le16\\,\\mathbb{E}\\biggl[\\left(f_{h}(s_{h}^{(k)},a_{h}^{(k)})-\\widetilde{\\mathcal{T}}_{\\phi}^{\\pi^{(k)}}f_{h}(s_{h}^{(k)},a_{h}^{(k)})\\right)^{2}\\mid\\mathfrak{F}_{k,h}\\biggr]}\\\\ &{\\phantom{x x x x x}=16\\,\\mathbb{E}[X_{k}(h,f)\\mid\\mathfrak{F}_{k,h}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "By Freedman's inequality (Lemma C.2, Lemma C.3), we have that with probability at least $1-\\delta$ ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\left|\\sum_{t<k}X_{t}(h,f)-\\sum_{t<k}\\mathbb{E}[X_{t}(h,f)\\mid\\mathfrak{F}_{t,h}]\\right|\\leq\\mathcal{O}\\left(\\sqrt{\\log(1/\\delta)\\sum_{t<k}\\mathbb{E}[X_{t}(h,f)\\mid\\mathfrak{F}_{t,h}]}+\\log(1/\\delta)\\right)\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "Taking a union bound over $[K]\\times[H]\\times{\\mathcal{F}}$ we have that for all $k,h,f$ , with probability at least $1-\\delta$ ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\left\\lvert\\sum_{t<k}X_{t}(h,f)-\\sum_{t<k}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi^{(k)}}\\left[\\left(f_{h}(s_{h},a_{h})-\\widetilde{\\mathcal{T}}_{\\phi}^{\\pi^{(k)}}f_{h}(s_{h},a_{h})\\right)^{2}\\right]\\right\\rvert}\\\\ &{\\quad\\le\\mathcal{O}\\left(\\sqrt{\\iota\\sum_{t<k}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi^{(k)}}\\left[\\left(f_{h}(s_{h},a_{h})-\\widetilde{\\mathcal{T}}_{\\phi}^{\\pi^{(k)}}f_{h}(s_{h},a_{h})\\right)^{2}\\right]}+\\iota\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "where $\\iota=\\log(|\\mathcal{F}|H K/\\delta)$ . We now show that ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\sum_{t<k}X_{t}(h,f^{(k)})\\leq\\beta+\\mathcal{O}(\\varepsilon_{\\sf r e p}+\\iota)=\\mathcal{O}(\\beta),\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "which will imply, from Eq. (96), that ", "page_idx": 76}, {"type": "equation", "text": "$$\n\\sum_{t<k}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi^{(k)}}\\bigg[\\Big(f_{h}\\big(s_{h},a_{h}\\big)-\\widetilde{\\mathcal{T}}_{\\phi}^{\\pi^{(k)}}f_{h}\\big(s_{h},a_{h}\\big)\\Big)^{2}\\bigg]\\le\\mathcal{O}(\\iota+\\beta)=\\mathcal{O}(\\beta),\n$$", "text_format": "latex", "page_idx": 76}, {"type": "text", "text": "as desired. To see Eq. (98), let ", "page_idx": 76}, {"type": "equation", "text": "$$\n\\lambda_{k}=\\sum_{t<k}\\Bigl(\\mathcal{T}_{\\mathrm{lat}}f_{h}^{(k)}\\bigl(s_{h}^{(t)},a_{h}^{(t)}\\bigr)-r_{h}^{(t)}-f_{h+1}^{(k)}\\bigl(s_{h+1}^{(t)}\\bigr)\\Bigr)^{2}-\\Bigl(\\widetilde{\\mathcal{T}}_{\\phi}^{\\pi^{(t)}}f_{h}^{(k)}\\bigl(s_{h}^{(t)},a_{h}^{(t)}\\bigr)-r_{h}^{(t)}-f_{h+1}^{(k)}\\bigl(s_{h+1}^{(t)}\\bigr)\\Bigr)^{2}\n$$", "text_format": "latex", "page_idx": 76}, {"type": "text", "text": "and then note that: ", "page_idx": 76}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{t<k}X_{t}(h,f^{(k)})=\\displaystyle\\sum_{t<k}(f_{h}^{(k)}(s_{h}^{(t)},a_{h}^{(t)})-r_{h}^{(t)}-f_{h+1}^{(k)}(s_{h+1}^{(t)}))^{2}-\\left(\\widetilde{T}_{\\phi}^{\\alpha^{(t)}}f_{h}^{(k)}(s_{h}^{(t)},a_{h}^{(t)})-r_{h}^{(t)}-f_{h+1}^{(k)}\\right.}&{}\\\\ {\\left.=\\displaystyle\\sum_{t<k}(f_{h}^{(k)}(s_{h}^{(t)},a_{h}^{(t)})-r_{h}^{(t)}-f_{h+1}^{(k)}(s_{h+1}^{(t)}))^{2}\\right.}&{}\\\\ {\\displaystyle-\\sum_{t<k}(\\widetilde{T}_{1\\mathrm{taf}}f_{h}^{(k)}(s_{h}^{(t)},a_{h}^{(t)})-r_{h}^{(t)}-f_{h+1}^{(k)}(s_{h+1}^{(t)}))^{2}+\\Delta_{k}}&{}\\\\ {\\left.\\leq\\displaystyle\\sum_{t<k}(f_{h}^{(k)}(s_{h}^{(t)},a_{h}^{(t)})-r_{h}^{(t)}-f_{h+1}^{(k)}(s_{h+1}^{(t)}))^{2}\\right.}&{}\\\\ {\\left.\\quad-\\left.\\frac{\\mathrm{inf}}{g_{h}\\epsilon_{\\mathcal{R}}}\\displaystyle\\sum_{t<k}(g(s_{h}^{(t)},a_{h}^{(t)})-r_{h}^{(t)}-f_{h+1}^{(t)}(s_{h+1}^{(t)})\\right)^{2}+\\Delta_{k}}&{}\\\\ {\\left.<\\beta+\\Delta_{k}.}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 76}, {"type": "text", "text": "where the second-to-last line follows from $\\begin{array}{r}{\\tau_{\\mathrm{lat}}\\mathcal{F}\\subseteq\\mathcal{G}}\\end{array}$ and the last line follows from the definition of the confidence set. It remains to show that $\\Delta_{k}\\le\\mathcal{O}(\\varepsilon_{\\mathsf{r e p}}+\\iota)$ , which we do via a similar concentration argument. Namely, let ", "page_idx": 76}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\check{\\mathit{t}}_{t}(h,f)=\\left(7_{\\mathrm{lat}}f_{h}(s_{h}^{(t)},a_{h}^{(t)})-r_{h}^{(t)}-f_{h+1}^{(k)}(s_{h+1}^{(t)})\\right)^{2}-\\left(\\widetilde{\\mathit{T}}_{\\phi}^{\\pi^{(t)}}f_{h}(s_{h}^{(t)},a_{h}^{(t)})-r_{h}^{(t)}-f_{h+1}^{(k)}(s_{h+1}^{(t)})\\right)^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 76}, {"type": "text", "text": "and note that, as before, ", "page_idx": 76}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[Y_{t}(h,f)\\mid\\mathfrak{F}_{t,h}]=\\mathfrak{F}_{\\phi}^{\\pi^{(t)}}\\bigg[\\Big({\\mathcal{T}}_{\\mathrm{lat}}f_{h}\\big(s_{h},a_{h}\\big)-\\widetilde{{\\mathcal T}}_{\\phi}^{\\pi^{(t)}}f_{h}\\big(s_{h},a_{h}\\big)\\Big)^{2}\\bigg],}\\end{array}\n$$", "text_format": "latex", "page_idx": 76}, {"type": "text", "text": "and ", "page_idx": 76}, {"type": "equation", "text": "$$\n\\mathsf{V a r}[Y_{t}(h,f)\\mid\\mathfrak{F}_{t,h}]\\le16\\,\\mathbb{E}[Y_{t}(h,f)\\mid\\mathfrak{F}_{t,h}],\n$$", "text_format": "latex", "page_idx": 76}, {"type": "text", "text": "by the same calculation as earlier. Thus, by Freedman's inequality and a union bound, we have that, with probability at least $1-\\delta$ ", "page_idx": 76}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\left\\lvert\\sum_{t<k}Y_{t}(h,f)-\\sum_{t<k}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi^{(k)}}\\left[\\left(\\mathcal{T}_{\\mathrm{lat}}f_{h}(s_{h},a_{h})-\\widetilde{\\mathcal{T}}_{\\phi}^{\\pi^{(k)}}f_{h}(s_{h},a_{h})\\right)^{2}\\right]\\right\\rvert}\\\\ &{\\quad\\le\\mathcal{O}\\left(\\sqrt{\\iota\\sum_{t<k}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi^{(k)}}\\left[\\left(\\mathcal{T}_{\\mathrm{lat}}f_{h}(s_{h},a_{h})-\\widetilde{\\mathcal{T}}_{\\phi}^{\\pi^{(k)}}f_{h}(s_{h},a_{h})\\right)^{2}\\right]}+\\iota\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 76}, {"type": "text", "text": "where $\\iota=\\log(|\\mathcal{F}|H K/\\delta)$ . Recalling the misspecification assumption Lemma I.4, this implies that ", "page_idx": 76}, {"type": "equation", "text": "$$\n\\sum_{t<k}Y_{t}(h,f)\\leq\\mathcal{O}(\\varepsilon_{\\sf r e p}+\\iota),\n$$", "text_format": "latex", "page_idx": 76}, {"type": "text", "text": "for all $h,f,k$ , with high probability. Applying this to $f=f^{(k)}$ concludes the result. ", "page_idx": 76}, {"type": "text", "text": "Proof of Lemma I.5. Weuse similar arguments to the preceding lemma. Let $Q_{\\mathrm{1at},h}^{\\star}:=Q_{M_{\\mathrm{1at}},h}^{\\star}.$ The aim is to show that, for all $h\\in[H],k\\in[K],g\\in\\mathcal{G}$ wehave: ", "page_idx": 76}, {"type": "equation", "text": "$$\n\\sum_{t<k}\\bigl(g\\bigl(s_{h}^{(t)},a_{h}^{(t)}\\bigr)-r_{h}^{(t)}-Q_{\\mathrm{lat},h+1}^{\\star}\\bigl(s_{h+1}^{(t)}\\bigr)\\bigr)^{2}-\\bigl(Q_{\\mathrm{lat},h}^{\\star}\\bigl(s_{h}^{(t)},a_{h}^{(t)}\\bigr)-r_{h}^{(t)}-Q_{\\mathrm{lat},h}^{\\star}\\bigl(s_{h+1}^{(t)}\\bigr)\\bigr)^{2}\\geq-\\beta,\n$$", "text_format": "latex", "page_idx": 76}, {"type": "text", "text": "from which the conclusion will follow. We show that ", "page_idx": 77}, {"type": "equation", "text": "$$\n\\sum_{<k}\\left(g(s_{h}^{(t)},a_{h}^{(t)})-r_{h}^{(t)}-Q_{\\mathrm{lat},h+1}^{*}(s_{h+1}^{(t)})\\right)^{2}-\\left(\\widetilde{T}_{\\phi}^{\\pi^{(t)}}Q_{\\mathrm{lat},h}^{*}(s_{h}^{(t)},a_{h}^{(t)})-r_{h}^{(t)}-Q_{\\mathrm{lat},h}^{*}(s_{h+1}^{(t)})\\right)^{2}\\geq-\\beta\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "and also that ", "page_idx": 77}, {"type": "equation", "text": "$$\n\\sum_{<k}\\Big(\\widetilde{\\mathcal{T}}_{\\phi}^{\\pi^{(t)}}Q_{\\mathrm{lat},h}^{*}(s_{h}^{(t)},a_{h}^{(t)})-r_{h}^{(t)}-Q_{\\mathrm{lat},h}^{*}\\big(s_{h+1}^{(t)}\\big)\\Big)^{2}-\\big(Q_{\\mathrm{lat},h}^{*}\\big(s_{h}^{(t)},a_{h}^{(t)}\\big)-r_{h}^{(t)}-Q_{\\mathrm{lat},h}^{*}\\big(s_{h+1}^{(t)}\\big)\\big)^{2}\\geq0\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "For Eq. (101), note that ", "page_idx": 77}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[W_{t}(h,g)\\mid\\mathcal{F}_{t,h}]=\\mathbb{\\widetilde{E}}_{\\phi}^{\\pi^{(t)}}\\bigg[\\Big(g_{h}\\big(s_{h},a_{h}\\big)-\\widetilde{\\mathcal{T}}_{\\phi,h}^{\\pi^{(t)}}Q_{1\\mathrm{at},h}^{\\star}\\big(s_{h},a_{h}\\big)\\Big)^{2}\\bigg],}\\end{array}\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "and that $\\mathsf{V a r}[W_{t}(h,g)\\mid\\mathcal{F}_{t,h}]\\le16\\,\\mathbb{E}[W_{t}(h,g)\\mid\\mathcal{F}_{t,h}]$ . By Freedman, this gives ", "page_idx": 77}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\left|\\sum_{t<k}W_{t}(h,g)-\\sum_{t<k}\\mathbb{E}[W_{t}(h,g)\\mid\\mathfrak{F}_{t,h}]\\right|\\le\\mathcal{O}\\left(\\sqrt{\\iota\\sum_{t<k}\\mathbb{E}[W_{t}(h,g)\\mid\\mathcal{F}_{t,h}]}+\\iota\\right)}}\\\\ &{}&{\\le\\frac{1}{2}\\,\\mathbb{E}[W_{t}(h,g)\\mid\\mathcal{F}_{t,h}]+\\mathcal{O}(\\iota),}\\end{array}\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "or in other words ", "page_idx": 77}, {"type": "equation", "text": "$$\n\\sum_{t<k}W_{t}(h,g)\\geq\\frac{1}{2}\\sum_{t<k}\\mathbb{E}[W_{t}(h,g)\\mid\\mathfrak{F}_{t,h}]-\\mathcal{O}(\\iota)\\geq-\\mathcal{O}(\\iota),\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "using the non-negativity of Eq. (103). For Eq. (102), note that ", "page_idx": 77}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[V_{t}(h)\\ |\\ \\mathfrak{F}_{t,h}]=-\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi^{(t)}}\\left[\\left(\\mathcal{T}_{\\mathrm{lat},h}Q_{\\mathrm{lat},h}^{\\star}-\\widetilde{\\mathcal{T}}_{\\phi,h}^{\\pi^{(t)}}Q_{\\mathrm{lat},h}^{\\star}\\right)^{2}\\right]\\geq-\\varepsilon_{\\mathsf{r e p}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "and that $\\mathsf{V a r}[V_{t}(h)\\mid\\mathfrak{F}_{t,h}]\\le16\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi^{(t)}}\\bigg[\\Big(\\mathcal{T}_{\\mathrm{1at},h}Q_{\\mathrm{1at},h}^{\\star}-\\widetilde{\\mathcal{T}}_{\\phi,h}^{\\pi^{(t)}}Q_{\\mathrm{1at},h}^{\\star}\\Big)^{2}\\bigg].$ By Freedman, thi gies ", "page_idx": 77}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\displaystyle\\sum_{t<k}V_{t}(h)-\\displaystyle\\sum_{t<k}\\mathbb{E}[V_{t}(h)\\mid\\mathfrak{F}_{t,h}]\\right|}\\\\ &{\\qquad\\le\\mathcal{O}\\left(\\sqrt{\\iota\\displaystyle\\sum_{t<k}\\widetilde{\\mathbb{E}}_{\\phi}^{\\pi^{(t)}}\\left[\\left(\\mathcal{T}_{\\mathrm{lat}}Q_{\\mathrm{lat},h+1}^{\\star}(s_{h},a_{h})-\\widetilde{\\mathcal{T}}_{\\phi,h}^{\\pi^{(t)}}Q_{\\mathrm{lat},h+1}^{\\star}(s_{h},a_{h})\\right)^{2}\\right]}+\\iota\\right)}\\\\ &{\\qquad=\\mathcal{O}(\\varepsilon_{r\\mathrm{ep}}+\\iota),}\\end{array}\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "or in other words ", "page_idx": 77}, {"type": "equation", "text": "$$\n\\sum_{t<k}V_{t}(h)\\geq\\sum_{t<k}\\mathbb{E}[V_{t}(h)\\mid\\mathfrak{F}_{t,h}]-\\mathcal{O}(\\varepsilon_{\\sf r e p}+\\iota)\\geq-\\mathcal{O}(\\varepsilon_{\\sf r e p}+\\iota),\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "where we have used Eq. (104). ", "page_idx": 77}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 78}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 78}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? ", "page_idx": 78}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 78}, {"type": "text", "text": "Justification: All results in this paper are of a theoretical nature, and the stated contributions in the abstract and introduction are given in a precise, formal language. ", "page_idx": 78}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 78}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 78}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 78}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 78}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 78}, {"type": "text", "text": "Justification: All results in this paper are of a theoretical nature - we precisely state the conditions under which our results hold. ", "page_idx": 78}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 78}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 78}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 79}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 79}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 79}, {"type": "text", "text": "Justification: Each theoretical result is stated with all necessary assumptions and is accompanied by complete (and correct) proofs. ", "page_idx": 79}, {"type": "text", "text": "Guidelines: ", "page_idx": 79}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 79}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 79}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 79}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 79}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 79}, {"type": "text", "text": "Guidelines: ", "page_idx": 79}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 79}, {"type": "text", "text": "(d)  We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 80}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 80}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 80}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 80}, {"type": "text", "text": "Justification: The paper does not include experiments requiring code. Guidelines: ", "page_idx": 80}, {"type": "text", "text": "", "page_idx": 80}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/public/ guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: / /nips. cc/public/ guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 80}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 80}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 80}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 80}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 80}, {"type": "text", "text": "Guidelines: ", "page_idx": 80}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments ", "page_idx": 80}, {"type": "text", "text": "\u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 80}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 80}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 80}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 80}, {"type": "text", "text": "Justification: The paper does not include experiments. Guidelines: ", "page_idx": 80}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. ", "page_idx": 81}, {"type": "text", "text": "\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 81}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 81}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 81}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 81}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 81}, {"type": "text", "text": "Guidelines: ", "page_idx": 81}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into thepaper). ", "page_idx": 81}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 81}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 81}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 81}, {"type": "text", "text": "Justification: The research conducted in the paper conforms with the NeurIPs Code of Etichs. Guidelines: ", "page_idx": 81}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 81}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 81}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 82}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 82}, {"type": "text", "text": "Justification: This is a primarily theoretical work. ", "page_idx": 82}, {"type": "text", "text": "Guidelines: ", "page_idx": 82}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 82}, {"type": "text", "text": "\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 82}, {"type": "text", "text": "\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. ", "page_idx": 82}, {"type": "text", "text": "\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 82}, {"type": "text", "text": "\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. ", "page_idx": 82}, {"type": "text", "text": "\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 82}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 82}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 82}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 82}, {"type": "text", "text": "Justification: This is a purely theoretical work, and as such poses no such risks. ", "page_idx": 82}, {"type": "text", "text": "Guidelines: ", "page_idx": 82}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks. ", "page_idx": 82}, {"type": "text", "text": "\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. ", "page_idx": 82}, {"type": "text", "text": "\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. ", "page_idx": 82}, {"type": "text", "text": "\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 82}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 82}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 82}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 82}, {"type": "text", "text": "Justification: The paper does not use existing assets. ", "page_idx": 82}, {"type": "text", "text": "Guidelines: ", "page_idx": 83}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode. com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 83}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 83}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 83}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 83}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 83}, {"type": "text", "text": "Guidelines: ", "page_idx": 83}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 83}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 83}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 83}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 83}, {"type": "text", "text": "Justification: The paper does not involve crowdsouring nor research with human subjects. ", "page_idx": 83}, {"type": "text", "text": "Guidelines: ", "page_idx": 83}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 83}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 83}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 84}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 84}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 84}, {"type": "text", "text": "Guidelines: ", "page_idx": 84}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 84}]