[{"figure_path": "T0glCBw28a/figures/figures_1_1.jpg", "caption": "Figure 1: Examples of generated programs and their prompts. These are synthesized by GPT-4 for spam detection and cancer identification tasks. Programs use regular expressions (left program) and keyword matching (right program) as their labeling logic to classify data points.", "description": "This figure shows two examples of Python code generated by GPT-4 to perform labeling tasks.  The left example uses regular expressions to identify spam in YouTube comments, while the right example uses keyword matching to classify biomedical documents by cancer type (colon, lung, or thyroid).  This illustrates how the ALCHEMist system generates programs for labeling, rather than directly generating labels.", "section": "1 Introduction"}, {"figure_path": "T0glCBw28a/figures/figures_2_1.jpg", "caption": "Figure 2: Overall workflow for Alchemist.", "description": "The figure illustrates the overall workflow of the Alchemist system. It starts with specialized prompt design, which is fed into a language model for program generation.  These generated programs then collect outputs, which are finally aggregated for use in a downstream task. This shows how Alchemist uses language models to generate programs that perform the labeling task, rather than directly querying labels from the models. This approach allows for significant cost reductions and improvements in label quality.", "section": "3 Alchemist System"}, {"figure_path": "T0glCBw28a/figures/figures_3_1.jpg", "caption": "Figure 3: Alchemist can handle rich modalities through a simple extension. First, a language model identifies task-specific concepts (top). Then, a local multimodal model is used as a feature extractor for these concepts, producing low-dimensional feature vectors that can be ingested by generated labeling programs.", "description": "This figure illustrates how Alchemist extends its capabilities to handle non-text modalities, such as images.  It shows a two-step process: 1) A language model identifies key concepts for classifying the data (e.g., 'wing shape', 'bill length'), and 2) A local multimodal model extracts features representing these concepts from the raw image data, generating low-dimensional vectors.  These vectors are then used as input to the generated labeling programs produced by Alchemist.", "section": "3.3 Extensions: Handling Complex Modalities"}, {"figure_path": "T0glCBw28a/figures/figures_4_1.jpg", "caption": "Figure 4: Program examples generated by GPT40 on Waterbirds dataset. The left program is synthesized by directly asking for a labeling program when the input is an image (raw pixels), while the right program uses Alchemist's extension. The former labels birds using the dominant color in the image, which can be predicted incorrectly due to spurious correlations (e.g., background).", "description": "This figure shows two example programs generated by GPT-4 for the Waterbirds dataset.  The left program attempts to classify birds as landbirds or waterbirds based directly on raw pixel data from images, using color as a proxy for the environment.  This method is prone to errors due to spurious correlations (e.g., a bird in a green field might incorrectly be classified as a landbird). The right program uses Alchemist's extension, which leverages higher-level concepts and similarity scores from a multimodal model.  This approach is more robust to spurious correlations.", "section": "3.2 Dataset Synthesis"}, {"figure_path": "T0glCBw28a/figures/figures_7_1.jpg", "caption": "Figure 5: Performance is reported using their average performance and standard deviations. Results indicate that the label model is improved when the number of diverse programs increases.", "description": "This figure displays the impact of the number of collected programs on the performance of a label model in three different datasets: SMS, Yelp, and IMDb. The x-axis represents the number of programs collected, and the y-axis shows the average F1-score or accuracy for each dataset. The shaded areas represent the standard deviation, indicating the variability in performance. The results suggest that increasing the diversity of programs can improve the label model's performance.", "section": "4.3 Use of Supplementary Information"}]