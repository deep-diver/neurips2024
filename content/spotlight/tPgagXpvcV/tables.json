[{"figure_path": "tPgagXpvcV/tables/tables_7_1.jpg", "caption": "Table 1: Graph level, edge level, and node level metrics reported on test for the different models and datasets. * denotes methods that use the actual size of the graph at inference time, hence the performance reported is a non-realistic upper bound. We where not able to train FGWBary on all dataset due to the prohibitive cost of barycenter computations. N.A. stands for not applicable.", "description": "This table presents a comparison of different graph prediction models (FGWBary-NN*, FGWBary-ILE*, Relationformer, Any2Graph) across five datasets (Coloring, Toulouse, USCities, QM9, GDB13).  It evaluates model performance using graph-level metrics (Edit Distance, GI Accuracy, PMFGW), edge-level metrics (Precision, Recall), and node-level metrics (Node Accuracy, Size Accuracy). The asterisk (*) indicates that some methods used the true graph size during inference, providing an unrealistic upper bound on performance.  Note that FGWBary was not always able to be trained due to computational cost.", "section": "5.2 Comparison with existing SGP methods on diverse modalities"}, {"figure_path": "tPgagXpvcV/tables/tables_7_2.jpg", "caption": "Table 1: Graph level, edge level, and node level metrics reported on test for the different models and datasets. * denotes methods that use the actual size of the graph at inference time, hence the performance reported is a non-realistic upper bound. We where not able to train FGWBary on all dataset due to the prohibitive cost of barycenter computations. N.A. stands for not applicable.", "description": "This table presents a comparison of different graph prediction methods across five datasets, evaluating performance using various graph-level, edge-level, and node-level metrics.  It highlights the trade-off between performance and the computational cost of methods that require knowledge of the graph size a priori.", "section": "5.2 Comparison with existing SGP methods on diverse modalities"}, {"figure_path": "tPgagXpvcV/tables/tables_19_1.jpg", "caption": "Table 1: Graph level, edge level, and node level metrics reported on test for the different models and datasets. * denotes methods that use the actual size of the graph at inference time, hence the performance reported is a non-realistic upper bound. We where not able to train FGWBary on all dataset due to the prohibitive cost of barycenter computations. N.A. stands for not applicable.", "description": "This table presents a comparison of different graph prediction models (Any2Graph, Relationformer, FGWBary-NN*, FGWBary-ILE*) on five datasets (Coloring, Toulouse, USCities, QM9, GDB13).  It shows the performance of each model using several metrics at different granularities: graph level (edit distance, GI accuracy, PMFGW loss), edge level (precision, recall), and node level (node accuracy, size accuracy). The * indicates methods that unrealistically use the true graph size during inference.  Some methods are marked N.A. (not applicable) because they could not be trained on all datasets due to computational cost.", "section": "5.2 Comparison with existing SGP methods on diverse modalities"}, {"figure_path": "tPgagXpvcV/tables/tables_20_1.jpg", "caption": "Table 1: Graph level, edge level, and node level metrics reported on test for the different models and datasets. * denotes methods that use the actual size of the graph at inference time, hence the performance reported is a non-realistic upper bound. We where not able to train FGWBary on all dataset due to the prohibitive cost of barycenter computations. N.A. stands for not applicable.", "description": "This table presents a comparison of different graph prediction methods (Any2Graph, Relationformer, FGW-Bary-NN, FGW-Bary-ILE) across five datasets (Coloring, Toulouse, USCities, QM9, GDB13).  The comparison uses multiple metrics evaluating performance at the graph, edge, and node levels.  The asterisk (*) indicates that some methods use the actual graph size at inference time, which is unrealistic.  Note that FGW-Bary could not be trained on all datasets due to computational cost.", "section": "5.2 Comparison with existing SGP methods on diverse modalities"}, {"figure_path": "tPgagXpvcV/tables/tables_20_2.jpg", "caption": "Table 1: Graph level, edge level, and node level metrics reported on test for the different models and datasets. * denotes methods that use the actual size of the graph at inference time, hence the performance reported is a non-realistic upper bound. We where not able to train FGWBary on all dataset due to the prohibitive cost of barycenter computations. N.A. stands for not applicable.", "description": "This table presents a comparison of different graph prediction methods on five datasets.  For each dataset and method, it reports graph-level metrics (edit distance, GI accuracy, PMFGW loss), edge-level metrics (precision, recall), and node-level metrics (node accuracy, size accuracy).  The table highlights the superior performance of Any2Graph, especially considering its efficiency and ability to handle graphs of arbitrary size.", "section": "5.2 Comparison with existing SGP methods on diverse modalities"}, {"figure_path": "tPgagXpvcV/tables/tables_23_1.jpg", "caption": "Table 1: Graph level, edge level, and node level metrics reported on test for the different models and datasets. * denotes methods that use the actual size of the graph at inference time, hence the performance reported is a non-realistic upper bound. We where not able to train FGWBary on all dataset due to the prohibitive cost of barycenter computations. N.A. stands for not applicable.", "description": "This table presents a comparison of different graph prediction methods across five datasets.  For each dataset and method, it reports graph-level metrics (edit distance, graph isomorphism accuracy, and PMFGW loss), edge-level metrics (precision and recall), and node-level metrics (node accuracy and size accuracy). The table highlights the superior performance of Any2Graph and indicates computational limitations of other methods.", "section": "5.2 Comparison with existing SGP methods on diverse modalities"}, {"figure_path": "tPgagXpvcV/tables/tables_23_2.jpg", "caption": "Table 1: Graph level, edge level, and node level metrics reported on test for the different models and datasets. * denotes methods that use the actual size of the graph at inference time, hence the performance reported is a non-realistic upper bound. We where not able to train FGWBary on all dataset due to the prohibitive cost of barycenter computations. N.A. stands for not applicable.", "description": "This table compares the performance of different graph prediction models (Any2Graph, Relationformer, FGW-Bary-NN, FGW-Bary-ILE) on five different datasets (Coloring, Toulouse, USCities, QM9, GDB13) using various metrics.  The metrics assess performance at the graph, edge, and node levels, offering a comprehensive evaluation of model accuracy.  Note that some methods use the graph's true size during inference, leading to potentially inflated results, while others couldn't be trained on all datasets due to high computational demands.", "section": "5.2 Comparison with existing SGP methods on diverse modalities"}, {"figure_path": "tPgagXpvcV/tables/tables_25_1.jpg", "caption": "Table 1: Graph level, edge level, and node level metrics reported on test for the different models and datasets. * denotes methods that use the actual size of the graph at inference time, hence the performance reported is a non-realistic upper bound. We where not able to train FGWBary on all dataset due to the prohibitive cost of barycenter computations. N.A. stands for not applicable.", "description": "This table presents a comparison of different graph prediction models across five datasets, evaluating performance at the graph, edge, and node levels.  Metrics include edit distance, graph isomorphism accuracy, PMFGW loss, precision, recall, node accuracy, and size accuracy.  The table highlights the superior performance of Any2Graph compared to other methods, while also noting limitations in training certain methods on all datasets due to computational costs.", "section": "5.2 Comparison with existing SGP methods on diverse modalities"}, {"figure_path": "tPgagXpvcV/tables/tables_26_1.jpg", "caption": "Table 1: Graph level, edge level, and node level metrics reported on test for the different models and datasets. * denotes methods that use the actual size of the graph at inference time, hence the performance reported is a non-realistic upper bound. We where not able to train FGWBary on all dataset due to the prohibitive cost of barycenter computations. N.A. stands for not applicable.", "description": "This table presents a comparison of different graph prediction models on five datasets.  It evaluates performance using various graph-level, edge-level, and node-level metrics.  The asterisk (*) indicates methods that require knowing the graph's size beforehand, which is unrealistic in real-world scenarios.  The 'N.A.' entries signify that results could not be obtained due to computational limitations.", "section": "5.2 Comparison with existing SGP methods on diverse modalities"}]