[{"figure_path": "wm9JZq7RCe/tables/tables_22_1.jpg", "caption": "Table 2: A representation of the behavior of BPE when trained on the dataset in eq. (15). We assume that 1/\u03b4 - 1 is a power of 2 and define r = log\u2082(1/\u03b4 - 1).", "description": "This table shows how the BPE algorithm works on a specific dataset (equation 15 in the paper) that's designed to highlight some aspects of BPE's behavior. It illustrates the iterative merging process where frequently adjacent token pairs are combined into new tokens.  The table tracks this process, showing how the dictionary evolves and tokens are replaced in each iteration.  The purpose is to demonstrate how BPE's behavior might not always lead to optimal generalization, as the resulting model might not generalize well to unseen sequences.", "section": "B Additional Theoretical Results I: A sequential variant of BPE"}, {"figure_path": "wm9JZq7RCe/tables/tables_45_1.jpg", "caption": "Table 3: Hyperparameter choices", "description": "This table lists the hyperparameter choices used in the experiments described in the paper.  Many of the hyperparameters were grid-searched, meaning multiple values were tested and the best-performing one chosen. The architecture is based on GPT-2.  The settings show the model is relatively small, not a massive LLM, which allows for faster experiment times, and facilitates analysis of the observed behavior.", "section": "Experiment details"}]