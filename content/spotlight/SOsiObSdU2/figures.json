[{"figure_path": "SOsiObSdU2/figures/figures_3_1.jpg", "caption": "Figure 1: HDTwinGen: evolutionary framework. The process begins with user-provided modeling context Scontext and D = {Dtrain, Dval}. 1) In iteration g, the modeling agent generates model specification as a Python program fe,w(0). 2) Parameters are optimized using the offline optimization tool to yield fe,w* (0). 3) The HDTwin is evaluated based on model loss v and component-wise loss \u03b4. Subsequently, the model pool P(9) is updated with top-K models. 4) The evaluation agent provides targeted feedback for model improvement H(9) by analyzing models in P(9) using performance metrics requirements outlined in Scontext. This iterative loop repeats for G iterations.", "description": "This figure illustrates the HDTwinGen evolutionary framework.  It starts with user-defined context and data, showing an iterative process where a modeling agent generates a hybrid digital twin (HDTwin) model specification. The parameters of this specification are then optimized.  The resulting HDTwin is evaluated and based on its performance (loss), the model pool is updated, keeping the top-K performing models. An evaluation agent then analyzes these models and provides feedback to improve subsequent HDTwin generations. This loop continues for a specified number of iterations (G).", "section": "4 HDTwinGen: Automatic Design of HDTwins"}, {"figure_path": "SOsiObSdU2/figures/figures_7_1.jpg", "caption": "Figure 2: Sample efficiency. Analyzing performance as a function of the number of training trajectories in the Lung Cancer (with Chemo. & Radio.) dataset. We observe that HDTwinGen achieves the lowest test prediction error, even in the very challenging low data regime. This highlights the role of priors embedded in HDTwin in sample-efficient generalization.", "description": "This figure demonstrates the sample efficiency of the HDTwinGen model.  It shows the test MSE performance on the Lung Cancer (with Chemo. & Radio.) dataset as the number of training trajectories is varied. Even with very few training trajectories, HDTwinGen outperforms the other models, indicating its ability to learn effectively with limited data. The superior performance is attributed to the use of priors, which help the model generalize better.", "section": "7.1 Insight Experiments"}, {"figure_path": "SOsiObSdU2/figures/figures_8_1.jpg", "caption": "Figure 3: HDTwinGen effectively evolves HDTwin. Validation MSE of the HDTwin generated in each iteration, showing the Pareto-front of the best generated HDTwin (Top-1 HDTwin), and the generated HDTwin per generation step\u2014additionally with a few of the HDTwins labeled with their model descriptions. HDTwinGen can efficiently understand, modify, and hence evolve the HDTwin to achieve a better-fitting model (Appendix H\u041d.4).", "description": "This figure shows how the HDTwinGen algorithm iteratively improves the hybrid digital twin model over multiple generations.  The validation mean squared error (MSE) is plotted against the number of generations.  Each point represents a generated model, with the top-performing model at each generation highlighted.  The figure also includes descriptions of several models, illustrating how the architecture and complexity of the model evolve over time, ultimately leading to a more accurate and efficient representation of the underlying system.", "section": "4 HDTwinGen: Automatic Design of HDTwins"}, {"figure_path": "SOsiObSdU2/figures/figures_8_2.jpg", "caption": "Figure 4: COVID-19 unobserved intervention. The symbolic code-based representation of HDTwin can be easily adapted to unobserved interventions through targeted adjustments of parameters.", "description": "This figure demonstrates the ability of HDTwins, generated by HDTwinGen, to adapt to unanticipated real-world events.  A COVID-19 epidemic simulation is used, where a lockdown (intervention) occurs midway through the simulation period. The training data only includes the time period before the lockdown. The HDTwin model is able to adjust its parameters to accurately predict the change in the number of exposed individuals after the lockdown is introduced, a task that is challenging for other models (DyNODE and SINDy) which only see data before the intervention.  The HDTwin's code-based representation makes it easily adaptable.", "section": "Insight Experiments"}, {"figure_path": "SOsiObSdU2/figures/figures_16_1.jpg", "caption": "Figure 1: HDTwinGen: evolutionary framework. The process begins with user-provided modeling context Scontext and D = {Dtrain, Dval}. 1) In iteration g, the modeling agent generates model specification as a Python program fe,w(0). 2) Parameters are optimized using the offline optimization tool to yield fe,w* (0). 3) The HDTwin is evaluated based on model loss v and component-wise loss \u03b4. Subsequently, the model pool P(9) is updated with top-K models. 4) The evaluation agent provides targeted feedback for model improvement H(9) by analyzing models in P(9) using performance metrics requirements outlined in Scontext. This iterative loop repeats for G iterations.", "description": "The figure illustrates the HDTwinGen evolutionary framework. It starts with a user-provided modeling context and dataset.  The modeling agent generates a hybrid digital twin model specification (as Python code), which is then optimized using offline tools. The HDTwin's performance is evaluated, and the top-performing models are selected. An evaluation agent analyzes these models and provides feedback to the modeling agent, guiding the generation of improved models.  This iterative process repeats until the desired performance is achieved, resulting in an optimized HDTwin.", "section": "4 HDTwinGen: Automatic Design of HDTwins"}, {"figure_path": "SOsiObSdU2/figures/figures_28_1.jpg", "caption": "Figure 6: Average evolution over generations for HDTwinGen\u2014for the Lung Cancer (with Chemo. & Radio.)", "description": "This figure shows the average validation mean squared error (MSE) for the top-performing HDTwin model (Top 1) and the average MSE for the top three HDTwin models (Top 3 Mean) across multiple generations of the HDTwinGen evolutionary algorithm.  The shaded area represents the 95% confidence interval.  It illustrates the iterative improvement in model accuracy as HDTwinGen evolves the HDTwin models over generations, achieving lower validation MSE over time, for the Lung Cancer (with Chemo. & Radio.) dataset.", "section": "H.4 HDTwinGen Evolution"}, {"figure_path": "SOsiObSdU2/figures/figures_29_1.jpg", "caption": "Figure 1: HDTwinGen: evolutionary framework. The process begins with user-provided modeling context Scontext and D = {Dtrain, Dval}. 1) In iteration g, the modeling agent generates model specification as a Python program fe,w(0). 2) Parameters are optimized using the offline optimization tool to yield fe,w* (0). 3) The HDTwin is evaluated based on model loss v and component-wise loss \u03b4. Subsequently, the model pool P(9) is updated with top-K models. 4) The evaluation agent provides targeted feedback for model improvement H(9) by analyzing models in P(9) using performance metrics requirements outlined in Scontext. This iterative loop repeats for G iterations.", "description": "This figure illustrates the HDTwinGen evolutionary framework, which iteratively generates, optimizes, and evaluates hybrid digital twin (HDTwin) models. The process starts with user-provided context (Scontext) and datasets (Dtrain, Dval). In each iteration, a modeling agent proposes HDTwin specifications, which are optimized offline, and an evaluation agent provides feedback using performance metrics. This iterative refinement leads to increasingly effective HDTwin models.", "section": "4 HDTwinGen: Automatic Design of HDTwins"}, {"figure_path": "SOsiObSdU2/figures/figures_30_1.jpg", "caption": "Figure 1: HDTwinGen: evolutionary framework. The process begins with user-provided modeling context Scontext and D = {Dtrain, Dval}. 1) In iteration g, the modeling agent generates model specification as a Python program fe,w(0). 2) Parameters are optimized using the offline optimization tool to yield fe,w* (0). 3) The HDTwin is evaluated based on model loss v and component-wise loss \u03b4. Subsequently, the model pool P(9) is updated with top-K models. 4) The evaluation agent provides targeted feedback for model improvement H(9) by analyzing models in P(9) using performance metrics requirements outlined in Scontext. This iterative loop repeats for G iterations.", "description": "This figure illustrates the HDTwinGen evolutionary framework. It starts with user-defined modeling context and data.  The modeling agent generates model specifications (as Python code), which are then optimized offline.  The model is evaluated, and top-performing models are selected.  The evaluation agent then provides feedback, driving iterative improvement of the model specifications until the final HDTwin is produced.", "section": "4 HDTwinGen: Automatic Design of HDTwins"}, {"figure_path": "SOsiObSdU2/figures/figures_35_1.jpg", "caption": "Figure 1: HDTwinGen: evolutionary framework. The process begins with user-provided modeling context Scontext and D = {Dtrain, Dval}. 1) In iteration g, the modeling agent generates model specification as a Python program fe,w(0). 2) Parameters are optimized using the offline optimization tool to yield fe,w* (0). 3) The HDTwin is evaluated based on model loss v and component-wise loss \u03b4. Subsequently, the model pool P(9) is updated with top-K models. 4) The evaluation agent provides targeted feedback for model improvement H(9) by analyzing models in P(9) using performance metrics requirements outlined in Scontext. This iterative loop repeats for G iterations.", "description": "This figure illustrates the HDTwinGen evolutionary framework. It starts with user-provided modeling context and data, which includes training and validation datasets. The modeling agent then generates model specifications represented as Python programs. These specifications are subsequently optimized offline to obtain parameters. The resulting HDTwins are then evaluated based on model and component-wise losses. The top-performing models are retained, and feedback is provided to improve model specifications. This process iteratively enhances model performance.", "section": "4 HDTwinGen: Automatic Design of HDTwins"}, {"figure_path": "SOsiObSdU2/figures/figures_36_1.jpg", "caption": "Figure 8: Best-performing model performance against each generation, for setup in Appendix H.12. HDTwinGen Generates Better Performing Models for a Fixed Model Budget.", "description": "This figure compares the best-performing model's test MSE across different methods over a fixed budget of model evaluations.  It shows the performance of HDTwinGen against human experts and Bayesian hyperparameter optimization (BO) for DyNODE and SINDy.  The results indicate that HDTwinGen consistently produces better-performing models than human experts and the BO-tuned baselines, highlighting its efficiency and effectiveness in finding high-performing models within a limited number of iterations.", "section": "H.12 HDTwinGen Accelerates Model Development and Enhances Performance"}]