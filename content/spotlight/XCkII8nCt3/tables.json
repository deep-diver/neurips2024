[{"figure_path": "XCkII8nCt3/tables/tables_30_1.jpg", "caption": "Table S1: Approximation errors of PQCs and ReLU FNNs", "description": "This table compares the approximation errors of Parameterized Quantum Circuits (PQCs) and Rectified Linear Unit feedforward neural networks (ReLU FNNs) for approximating multivariate monomials and smooth functions in C([0,1]d).  It shows the width, depth, number of parameters, and approximation error for each approach, highlighting the differences in resource requirements and approximation capabilities.  The approximation error for PQCs is 0 for multivariate monomials because they can be implemented exactly using the described constructions.  For smooth functions in C([0,1]d), both the nested PQCs and ReLU FNNs achieve an approximation error that decreases with increasing K (number of partitions) and N (width of the FNN), respectively,  though the scaling behavior is different for the two models.", "section": "E Comparison with related works in classical machine learning"}]