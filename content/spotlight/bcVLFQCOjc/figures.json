[{"figure_path": "bcVLFQCOjc/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of the DETIKZIFY architecture: A multimodal language model converts sketches or figures into TikZ programs, which are compiled by a LATEX engine. This provides a reward signal to the model via MCTS, allowing it to iteratively refine the output until satisfactory results are achieved.", "description": "This figure illustrates the architecture of DETIKZIFY, a multimodal language model.  It shows how DETIKZIFY takes either a sketch or an existing figure as input.  These inputs are processed by the model, which generates a TikZ program as output. The TikZ program is then compiled using a LATEX engine.  The resulting output is used to generate a reward signal that is fed back into the model via a Monte Carlo Tree Search (MCTS) algorithm, allowing for iterative refinement of the generated TikZ program until satisfactory results are achieved.", "section": "1 Introduction"}, {"figure_path": "bcVLFQCOjc/figures/figures_4_1.jpg", "caption": "Figure 1: Overview of the DETIKZIFY architecture: A multimodal language model converts sketches or figures into TikZ programs, which are compiled by a LATEX engine. This provides a reward signal to the model via MCTS, allowing it to iteratively refine the output until satisfactory results are achieved.", "description": "The figure illustrates the architecture of DETIKZIFY, a multimodal language model. It takes sketches or figures as input and generates TikZ programs. These programs are then compiled by a LATEX engine, and the result is used to provide a reward signal to the model.  The model uses Monte Carlo Tree Search (MCTS) to refine the output iteratively until satisfactory results are obtained.", "section": "1 Introduction"}, {"figure_path": "bcVLFQCOjc/figures/figures_7_1.jpg", "caption": "Figure 3: Bivariate distributions of BWS scores (higher is better) using kernel density estimation (left) and log-linear regression over TI reward scores for different generation strategies over time (right).", "description": "This figure visualizes the performance of different text generation strategies over time using two methods: kernel density estimation and log-linear regression.  The left panel shows a bivariate distribution of Best-Worst Scaling (BWS) scores, illustrating the relationship between the quality of generated figures (higher scores are better) for reference figures and human sketches. The right panel presents a log-linear regression analysis of the SELFSIM reward scores across time for both sampling and Monte Carlo Tree Search (MCTS) methods.  The results highlight the consistent improvement in performance over time seen with the MCTS algorithm, outperforming the sampling-based approach.", "section": "6.2 Human Evaluation"}, {"figure_path": "bcVLFQCOjc/figures/figures_8_1.jpg", "caption": "Figure 1: Overview of the DETIKZIFY architecture: A multimodal language model converts sketches or figures into TikZ programs, which are compiled by a \\LaTeX engine. This provides a reward signal to the model via MCTS, allowing it to iteratively refine the output until satisfactory results are achieved.", "description": "The figure illustrates the DETIKZIFY architecture, a multimodal language model that takes sketches or figures as input and generates TikZ programs.  These programs are then compiled using a \\LaTeX engine, providing a reward signal that is used by a Monte Carlo Tree Search (MCTS) algorithm to iteratively refine the generated TikZ program until a satisfactory result is obtained.  The process involves a vision encoder, a language model (such as LLAMA), and a reward module that incorporates feedback from the \\LaTeX compilation.", "section": "1 Introduction"}, {"figure_path": "bcVLFQCOjc/figures/figures_20_1.jpg", "caption": "Figure 1: Overview of the DETIKZIFY architecture: A multimodal language model converts sketches or figures into TikZ programs, which are compiled by a LaTeX engine. This provides a reward signal to the model via MCTS, allowing it to iteratively refine the output until satisfactory results are achieved.", "description": "The figure illustrates the architecture of DETIKZIFY, a multimodal language model.  It takes sketches or figures as input, processes them using a combination of a large language model (LLM) and a vision encoder, and outputs TikZ programs. These programs are then compiled using a LaTeX engine, providing feedback to the model through Monte Carlo Tree Search (MCTS). The MCTS algorithm allows for iterative refinement of the output until satisfactory results are obtained.", "section": "1 Introduction"}, {"figure_path": "bcVLFQCOjc/figures/figures_24_1.jpg", "caption": "Figure 1: Overview of the DETIKZIFY architecture: A multimodal language model converts sketches or figures into TikZ programs, which are compiled by a LATEX engine. This provides a reward signal to the model via MCTS, allowing it to iteratively refine the output until satisfactory results are achieved.", "description": "The figure illustrates the architecture of DETIKZIFY, a multimodal language model.  It takes either a sketch or an existing figure as input.  The model then generates a TikZ program (a type of code for creating graphics).  This program is then compiled using a LATEX engine. The output of the LATEX compilation provides a reward signal, used by the Monte Carlo Tree Search (MCTS) algorithm to iteratively refine the generated TikZ program until it's satisfactory.", "section": "1 Introduction"}, {"figure_path": "bcVLFQCOjc/figures/figures_25_1.jpg", "caption": "Figure 1: Overview of the DETIKZIFY architecture: A multimodal language model converts sketches or figures into TikZ programs, which are compiled by a \\LaTeX engine. This provides a reward signal to the model via MCTS, allowing it to iteratively refine the output until satisfactory results are achieved.", "description": "This figure shows the architecture of DETIKZIFY, a multimodal language model that synthesizes scientific figures as TikZ programs.  It takes sketches or figures as input, processes them using an LLAMA language model and a SIGLIP vision encoder, and generates TikZ code that is then compiled using a \\LaTeX engine. The resulting output is used to provide a reward signal, which is fed back into the model through a Monte Carlo Tree Search (MCTS) algorithm. This iterative refinement process continues until satisfactory results are obtained.", "section": "1 Introduction"}, {"figure_path": "bcVLFQCOjc/figures/figures_27_1.jpg", "caption": "Figure 1: Overview of the DETIKZIFY architecture: A multimodal language model converts sketches or figures into TikZ programs, which are compiled by a LATEX engine. This provides a reward signal to the model via MCTS, allowing it to iteratively refine the output until satisfactory results are achieved.", "description": "The figure illustrates the DETIKZIFY architecture, a multimodal language model that takes sketches or figures as input and generates TikZ programs as output.  The TikZ code is then compiled by a LATEX engine, which provides feedback to the model through a Monte Carlo Tree Search (MCTS) algorithm. This iterative refinement process continues until satisfactory results are achieved.", "section": "1 Introduction"}, {"figure_path": "bcVLFQCOjc/figures/figures_28_1.jpg", "caption": "Figure 1: Overview of the DETIKZIFY architecture: A multimodal language model converts sketches or figures into TikZ programs, which are compiled by a LATEX engine. This provides a reward signal to the model via MCTS, allowing it to iteratively refine the output until satisfactory results are achieved.", "description": "This figure illustrates the architecture of DETIKZIFY, which is a multimodal language model designed for automatic synthesis of scientific figures as semantics-preserving TikZ graphics programs.  It takes as input either a sketch or an existing figure.  The model uses a LATEX engine to compile the generated TikZ code, providing a reward signal that is fed back to the model via a Monte Carlo Tree Search (MCTS) algorithm.  This iterative refinement process allows the model to improve its outputs until they are satisfactory.", "section": "1 Introduction"}]