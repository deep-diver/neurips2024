[{"figure_path": "N8YbGX98vc/figures/figures_1_1.jpg", "caption": "Figure 1: (a) Illustration of the unified search space of our proposed TFG, where the height (color) stands for performance. Existing algorithms search along sub-manifolds, while TFG results in improved guidance thanks to its extended search space. (b) The label accuracy (higher the better) and Fr\n\nchet inception distance (FID, lower the better) of different methods for the label guidance task on CIFAR10 [30], averaged across ten labels. Ours (TFG-4) performs much closer to training-based methods. (c~h) TFG generated samples across various tasks in vision, audio, and geometry domains.", "description": "This figure presents the unified search space for the proposed Training-Free Guidance (TFG) framework, highlighting its advantage over existing methods. Subfigure (a) visually shows that TFG explores a larger search space compared to other methods, leading to improved performance.  Subfigure (b) demonstrates the superiority of TFG in a label guidance task by comparing label accuracy and Fr\u00e9chet Inception Distance (FID) with existing methods on CIFAR10. Finally, subfigures (c) through (h) showcase example outputs generated by TFG across different tasks involving vision, audio, and geometric domains, further illustrating its versatility.", "section": "1 Introduction"}, {"figure_path": "N8YbGX98vc/figures/figures_6_1.jpg", "caption": "Figure 2: Comparison of three structures in Equation (8) of p and \u03bc on CIFAR10 and ImageNet, under different choices of the rest hyper-parameters in HTFG. We set p = 0, \u03b3 = 0 when studying structures of \u03bc, and similarly for p. Results are averaged across all labels. The comparative relationship between structures remains unchanged when the rest of the parameters vary.", "description": "This figure compares three different structures for the hyperparameters p and \u03bc within the TFG framework, across the CIFAR-10 and ImageNet datasets.  The structures are 'increase', 'decrease', and 'constant'. The x-axis represents the value of p or \u03bc, and the y-axis represents the accuracy or FID.  The figure shows that the relative performance of these structures remains consistent across different settings of the other hyperparameters.  The results suggest that a suitable structure can be pre-selected and then refined by tuning the remaining hyperparameters, leading to an efficient hyperparameter search strategy.", "section": "Design Space of TFG: Analysis and Searching Strategy"}, {"figure_path": "N8YbGX98vc/figures/figures_7_1.jpg", "caption": "Figure 2: Comparison of three structures in Equation (8) of p and \u03bc on CIFAR10 and ImageNet, under different choices of the rest hyper-parameters in HTFG. We set p = 0, \u03b3 = 0 when studying structures of \u03bc, and similarly for p. Results are averaged across all labels. The comparative relationship between structures remains unchanged when the rest of the parameters vary.", "description": "This figure compares three different structures for the hyperparameters \u03c1 and \u03bc in the TFG framework across CIFAR10 and ImageNet datasets. It analyzes how the choice of these structures affects the model's performance when other hyperparameters are varied. The results demonstrate that the relative relationships between the structures remain consistent regardless of the values of other hyperparameters. This finding is important because it allows for a more efficient hyperparameter search strategy by first determining appropriate structures and then optimizing the remaining scalar parameters.", "section": "Design Space of TFG: Analysis and Searching Strategy"}, {"figure_path": "N8YbGX98vc/figures/figures_15_1.jpg", "caption": "Figure 1: (a) Illustration of the unified search space of our proposed TFG, where the height (color) stands for performance. Existing algorithms search along sub-manifolds, while TFG results in improved guidance thanks to its extended search space. (b) The label accuracy (higher the better) and Fr\n\n\n\u00b4echet inception distance (FID, lower the better) of different methods for the label guidance task on CIFAR10 [30], averaged across ten labels. Ours (TFG-4) performs much closer to training-based methods. (c~h) TFG generated samples across various tasks in vision, audio, and geometry domains.", "description": "This figure demonstrates the unified search space of the proposed Training-Free Guidance (TFG) framework, showing how existing methods are special cases within this space.  It compares TFG's performance to other methods on a label guidance task using CIFAR10, showing TFG's superior accuracy and lower FID.  Finally, it showcases example outputs generated by TFG across a variety of tasks.", "section": "1 Introduction"}, {"figure_path": "N8YbGX98vc/figures/figures_16_1.jpg", "caption": "Figure 1: (a) Illustration of the unified search space of our proposed TFG, where the height (color) stands for performance. Existing algorithms search along sub-manifolds, while TFG results in improved guidance thanks to its extended search space. (b) The label accuracy (higher the better) and Fr\n\n\n\n\n\n\n\n\u00e9chet inception distance (FID, lower the better) of different methods for the label guidance task on CIFAR10 [30], averaged across ten labels. Ours (TFG-4) performs much closer to training-based methods. (c~h) TFG generated samples across various tasks in vision, audio, and geometry domains.", "description": "This figure provides a comprehensive overview of the Training-Free Guidance (TFG) framework proposed in the paper. Panel (a) visually represents the unified search space of TFG, highlighting its ability to encompass existing methods as special cases. Panel (b) presents a quantitative comparison of TFG against state-of-the-art methods on the CIFAR-10 label guidance task, demonstrating TFG's superior performance. Panels (c) through (h) showcase illustrative examples of image and audio generation, style transfer, and geometry manipulation tasks performed by TFG, showcasing its versatility and efficacy across various applications.", "section": "1 Introduction"}, {"figure_path": "N8YbGX98vc/figures/figures_17_1.jpg", "caption": "Figure 6: (Left) The accuracy and FID of different methods under different settings on CIFAR10 [30], average across ten labels and 2048 samples per label. The suffix number in UGD and FreeDoM represents recurrent step Nrecur, and (fake) stands for a synthetic setting where we apply a training-based classifier but set t = 0 and use the same training-free guidance methods. A huge performance gap between different settings suggests the intrinsic difficulty of training-free guidance. (Right) Illustration of generated \u201cship\u201d using MPGD under different settings (top) and the sampling trajectory of the predicted clean image xot (down).", "description": "The figure presents a comparison of the performance of different training-free guidance methods on CIFAR10. The left panel shows a scatter plot comparing accuracy and FID for various methods, with and without a \"fake\" classifier trained on clean data.  The results demonstrate a significant performance gap between training-based and training-free approaches. The right panel illustrates how MPGD generates an image of a ship at various stages of the sampling process. It highlights that training-free guidance methods struggle to generate high-quality images compared to training-based methods.", "section": "3 TFG: A Unified Framework for Training-free Guidance"}, {"figure_path": "N8YbGX98vc/figures/figures_17_2.jpg", "caption": "Figure 7: Illustration on CIFAR10 dogs generated with different algorithms. Compared with training-based method, training-free methods fall behind but TFG significantly outperforms existing methods.", "description": "This figure compares the image generation results of different training-free guidance methods with a training-based method as a baseline on the CIFAR-10 dataset.  The task is generating images of dogs. The training-based method produces high-quality, realistic images of dogs. The training-free methods produce less realistic images, but the TFG method significantly outperforms the other training-free methods in terms of image quality and accuracy.  This demonstrates the effectiveness of the TFG framework.", "section": "3 TFG: A Unified Framework for Training-free Guidance"}, {"figure_path": "N8YbGX98vc/figures/figures_20_1.jpg", "caption": "Figure 8: (a) The reversed diffusion process. (b) Illustration of different training-free guidance algorithms at the t-th reversed diffusion step.", "description": "This figure illustrates the reversed diffusion process and how different training-free guidance algorithms modify it at step *t*.  Panel (a) shows the standard diffusion process, sampling from a noisy distribution at time *T* down to a clean distribution at time 0.  Panel (b) details the modifications introduced by different training-free guidance algorithms (DPS, LGD, FreeDoM, MPGD, and UGD).  Each algorithm modifies the sampling process by incorporating the gradient of the target predictor function at different points in the process.  The arrows and plus signs indicate the added guidance term.", "section": "Pseudo-code and schematics"}, {"figure_path": "N8YbGX98vc/figures/figures_24_1.jpg", "caption": "Figure 7: Illustration on CIFAR10 dogs generated with different algorithms. Compared with training-based method, training-free methods fall behind but TFG significantly outperforms existing methods.", "description": "This figure compares the image generation quality of different methods on the CIFAR10 dataset, focusing on the \"dog\" class.  It visually demonstrates the performance gap between training-based methods and training-free methods for conditional image generation. The training-based method serves as the ground truth, showcasing high-quality images that accurately reflect the target class (dog). The training-free methods, such as FreeDoM and others, generate images with lower quality and faithfulness to the target.  Crucially, the Training-Free Guidance (TFG) method introduced in the paper significantly improves upon these other training-free methods, generating images closer in quality and accuracy to the training-based method.", "section": "3 TFG: A Unified Framework for Training-free Guidance"}, {"figure_path": "N8YbGX98vc/figures/figures_24_2.jpg", "caption": "Figure 9: Quantitative comparison of different training-free guidance methods on Gaussian deblur task. Our TFG method can produce clean images without background noise (unlike FreeDoM and UGD), faithful image features (unlike DPS) and vivid image details (compared to LGD). Nrecur is set to 1 for all methods.", "description": "This figure shows a qualitative comparison of different training-free guidance methods applied to the Gaussian deblurring task. The top row displays the noisy input images. The subsequent rows illustrate the results obtained using various methods: DPS, LGD, MPGD, FreeDoM, UGD, and TFG.  The comparison highlights TFG's ability to produce clean images without the background noise present in FreeDoM and UGD's outputs.  TFG also demonstrates superior fidelity in capturing image features compared to DPS and richer detail compared to LGD.  The parameter Nrecur is set to 1 for all methods shown.", "section": "D Task details"}, {"figure_path": "N8YbGX98vc/figures/figures_26_1.jpg", "caption": "Figure 7: Illustration on CIFAR10 dogs generated with different algorithms. Compared with training-based method, training-free methods fall behind but TFG significantly outperforms existing methods.", "description": "This figure is a qualitative comparison of different methods for generating images of dogs from the CIFAR-10 dataset.  The top row shows examples generated using a training-based method, which serves as a benchmark for high-quality results.  The subsequent rows demonstrate the performance of several training-free guidance methods: FreeDoM, UGD, and TFG. The figure highlights that while training-free methods struggle to match the quality of the training-based approach, the TFG approach produces notably better-quality images compared to the other training-free methods.", "section": "3 TFG: A Unified Framework for Training-free Guidance"}, {"figure_path": "N8YbGX98vc/figures/figures_26_2.jpg", "caption": "Figure 9: Quantitative comparison of different training-free guidance methods on Gaussian deblur task. Our TFG method can produce clean images without background noise (unlike FreeDoM and UGD), faithful image features (unlike DPS) and vivid image details (compared to LGD). Nrecur is set to 1 for all methods.", "description": "This figure presents a visual comparison of different training-free guidance methods applied to the Gaussian deblurring task.  The top row shows the noisy input images.  The subsequent rows show the results from applying DPS, LGD, MPGD, FreeDoM, UGD, and TFG. The caption highlights TFG's superior performance in removing noise and preserving image details compared to other methods. The number of recurrences (Nrecur) is set to 1 for all methods.", "section": "D Task details"}, {"figure_path": "N8YbGX98vc/figures/figures_28_1.jpg", "caption": "Figure 11: Quantitative comparison of different training-free guidance methods on ImageNet label guidance (with target = 222, Kuvasz). The suffix of FreeDoM, UGD, TFG represents the number of recurrence Nrecur. Notice that all the samples are generated based on the same seed and we do not conduct cherry-picking. It is apprent that TFG generates the most valid samples among all the compared methods.", "description": "This figure compares different training-free guidance methods on an ImageNet label guidance task with the target label as \"Kuvasz\".  Each method's generated images are shown in a grid, illustrating the quality and variety of samples produced.  The suffix number (e.g., -4) indicates the number of recurrence steps used in the algorithms.  The figure highlights that TFG outperforms other methods, generating more valid samples of Kuvasz dogs, demonstrating the effectiveness of the proposed approach. The consistent seed ensures fair comparison and eliminates bias from different random initializations.", "section": "D.3 Label Guidance"}, {"figure_path": "N8YbGX98vc/figures/figures_30_1.jpg", "caption": "Figure 12: Quantitative comparison of different training-free guidance methods on combined guidance task (male+young). Our TFG method can produce images with high fidelity and validity compared to all the baselines. Notice that we use the fixed seed for all the methods in this figure and do not conduct cherry picking. Nrecur is set to 1 for all methods.", "description": "This figure compares the results of six different training-free guidance methods on a combined guidance task, specifically targeting the generation of images of young men.  The methods compared are DPS, LGD, MPGD, FreeDoM, UGD, and the authors' proposed TFG. Each method's output is displayed as a grid of generated images, showcasing the visual quality and fidelity of the generated images. The caption highlights that TFG outperforms the other methods in terms of both fidelity and validity, achieving higher quality and more accurate results for the specified target.", "section": "D.4 Combined Guidance"}, {"figure_path": "N8YbGX98vc/figures/figures_32_1.jpg", "caption": "Figure 11: Quantitative comparison of different training-free guidance methods on ImageNet label guidance (with target = 222, Kuvasz). The suffix of FreeDoM, UGD, TFG represents the number of recurrence Nrecur. Notice that all the samples are generated based on the same seed and we do not conduct cherry-picking. It is apprent that TFG generates the most valid samples among all the compared methods.", "description": "This figure compares the results of different training-free guidance methods on an ImageNet label guidance task, specifically targeting the \"Kuvasz\" dog breed (label 222).  It displays generated images from six different methods: DPS, LGD, MPGD, FreeDoM-4, UGD-4, and TFG-4.  The number after FreeDoM, UGD, and TFG indicates the number of recurrence steps (Nrecur) used. Importantly, all images were generated using the same random seed to eliminate the effects of randomness in the generation process and ensure a fair comparison. The figure highlights that TFG produces the most realistic and accurate images of Kuvasz dogs compared to the other methods.", "section": "D.3 Label Guidance"}, {"figure_path": "N8YbGX98vc/figures/figures_33_1.jpg", "caption": "Figure 1: (a) Illustration of the unified search space of our proposed TFG, where the height (color) stands for performance. Existing algorithms search along sub-manifolds, while TFG results in improved guidance thanks to its extended search space. (b) The label accuracy (higher the better) and Fr\n\n\n\n\n\n\n\n\u00e9chet inception distance (FID, lower the better) of different methods for the label guidance task on CIFAR10 [30], averaged across ten labels. Ours (TFG-4) performs much closer to training-based methods. (c~h) TFG generated samples across various tasks in vision, audio, and geometry domains.", "description": "This figure illustrates the unified search space of the proposed Training-Free Guidance (TFG) framework.  Panel (a) shows that existing methods explore only a subset of the possible hyperparameter space, while TFG explores the entire space. Panel (b) compares the performance of TFG to existing methods on a label guidance task.  The remaining panels (c-h) showcase example outputs from TFG across several diverse tasks.", "section": "1 Introduction"}, {"figure_path": "N8YbGX98vc/figures/figures_34_1.jpg", "caption": "Figure 15: Quantitative comparison of different training-free guidance methods on style transfer task with the target image as The Starry Night by Von Gogh. Our TFG generates the images with the most faithful style, while DPS, LGD, FreeDoM, and UGD fail to capture the target style. The images of MPGD is also of good quality, but the style score is also inferior than TFG by a large margin. We set Nrecur = 1 for all methods.", "description": "This figure compares the results of different training-free guidance methods on a style transfer task, using Van Gogh's \"The Starry Night\" as the target style. The figure shows that TFG generates images with the most faithful reproduction of the target style compared to other methods (DPS, LGD, MPGD, FreeDoM, UGD).  While MPGD produces reasonably good results, TFG significantly outperforms it in terms of style similarity.  The other methods fail to capture the target style effectively.", "section": "D.6 Style Transfer"}, {"figure_path": "N8YbGX98vc/figures/figures_34_2.jpg", "caption": "Figure 15: Quantitative comparison of different training-free guidance methods on style transfer task with the target image as The Starry Night by Von Gogh. Our TFG generates the images with the most faithful style, while DPS, LGD, FreeDoM, and UGD fail to capture the target style. The images of MPGD is also of good quality, but the style score is also inferior than TFG by a large margin. We set Nrecur = 1 for all methods.", "description": "This figure compares different training-free guidance methods on a style transfer task.  The target style is Van Gogh's \"The Starry Night\". The figure shows that TFG (Training-Free Guidance) generates images that are most faithful to the target style, outperforming methods like DPS, LGD, FreeDoM, and UGD, while MPGD also performs well but is still inferior to TFG.  Nrecur, a hyperparameter representing recurrence, is set to 1 for all methods.", "section": "D.6 Style Transfer"}, {"figure_path": "N8YbGX98vc/figures/figures_36_1.jpg", "caption": "Figure 16: Quanlitative comparison of different training-free guidance methods on molecule generation task with the target property \u03b1 (polarizability). Our TFG generates valid molecules with better design target, while baselines often fail to produce valid molecules or offer poor guidance towards the design target. The molecules generated by our approach are increasingly polarizable as \u03b1 goes up.", "description": "This figure shows a qualitative comparison of different training-free guidance methods for generating molecules with a specific polarizability (\u03b1).  Each row represents a different method (TFG, DPS, LGD, FreeDoM, MPGD, UGD), and each column shows generated molecules for increasing target polarizability values.  The figure demonstrates that TFG is superior at producing valid molecules that closely match the target polarizability, unlike other methods which frequently fail to generate valid molecules or achieve the target property.", "section": "D.7 Molecule Property Guidance"}]