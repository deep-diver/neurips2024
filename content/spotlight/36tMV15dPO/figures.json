[{"figure_path": "36tMV15dPO/figures/figures_0_1.jpg", "caption": "Figure 1: Comparison between the rendering-based 3D generation [49, 14] and our proposed X-Ray generation. The competitors focus on the visible outer surface in multiple camera views. In contrast, our model can sense both the visible and hidden surface in single camera view and generate the outer and inner surfaces of objects. An example of missing mesh interior from rendering-based 3D synthesis vs. complete mesh interior from our X-Ray generator are shown in the bottom row.", "description": "This figure compares two different approaches to 3D object generation: rendering-based and the authors' proposed X-Ray method. Rendering-based methods typically use multiple camera views to reconstruct only the visible outer surface of an object, resulting in incomplete 3D models with missing interior details.  The X-Ray method, on the other hand, uses a single camera view and leverages ray casting to capture both visible and hidden surfaces, generating complete 3D models with full interior details. The bottom row shows a visual comparison of the results, highlighting the difference in completeness between the two approaches.", "section": "Abstract"}, {"figure_path": "36tMV15dPO/figures/figures_2_1.jpg", "caption": "Figure 2: Samples of our X-Ray 3D sequential representation. Given a viewpoint, we capture the 3D attributes multi-layer surface frames, including hit H, depth D, normal N, and color C, in a video format. Noted that the number of frames in an X-Ray varies depending on the complexity of the 3D objects. The dotted yellow lines indicate the ray or sequence direction.", "description": "This figure shows four examples of the X-Ray 3D sequential representation.  Each example shows a 3D object (car, mug, gun, book) and its corresponding X-Ray representation. The X-Ray representation is a sequence of frames, each showing the hit (H), depth (D), normal (N), and color (C) information for the surfaces intersected by a ray cast from the camera. The number of frames in the X-Ray representation varies depending on the complexity of the 3D object. The dotted yellow lines show the direction of the ray cast.", "section": "3 Our X-Ray Representation"}, {"figure_path": "36tMV15dPO/figures/figures_4_1.jpg", "caption": "Figure 3: Overview of our proposed generative pipeline for the X-Ray 3D representation. There are three main components: (a) The X-Ray diffusion model, which generates a low-resolution X-Ray from an image input. (b) The upsampler, which enlarges the low-resolution X-Ray into 4\u00d7 high resolution. (c) The mesh decoding model, which decodes the high-resolution X-Ray into a point cloud with color and normal, and then converts it into the final generated mesh.", "description": "This figure illustrates the three-stage pipeline for generating 3D models using the X-Ray representation.  First, an image is fed into the X-Ray diffusion model to create a low-resolution X-Ray representation.  This is then upsampled to a higher resolution. Finally, the high-resolution X-Ray is decoded into a 3D point cloud, which is converted to a mesh.", "section": "3 Our X-Ray Representation"}, {"figure_path": "36tMV15dPO/figures/figures_7_1.jpg", "caption": "Figure 4: The encoding-decoding intrinsic error of different frame resolutions and number of layers.", "description": "This figure shows two plots illustrating the encoding-decoding intrinsic error of the X-Ray representation. The left plot shows how the error (measured by Chamfer Distance) decreases as the number of layers (L) increases, stabilizing around 8 layers. The right plot shows how the error decreases with increasing frame resolution (H or W), also stabilizing after 256.  This analysis helps determine the optimal balance between accuracy and efficiency for the X-Ray representation.", "section": "5.3 Efficient Comparison with Different 3D Representation"}, {"figure_path": "36tMV15dPO/figures/figures_7_2.jpg", "caption": "Figure 4: The encoding-decoding intrinsic error of different frame resolutions and number of layers.", "description": "This figure shows the relationship between the encoding-decoding intrinsic error and the resolution (height and width) and number of layers of the X-Ray representation. The encoding-decoding intrinsic error is the difference between the original 3D mesh and the 3D mesh reconstructed from the encoded X-Ray representation. As shown in the graph, the error decreases as the resolution increases and the number of layers increases. This suggests that a higher resolution and more layers leads to a more accurate reconstruction.", "section": "5.3 Efficient Comparison with Different 3D Representation"}, {"figure_path": "36tMV15dPO/figures/figures_8_1.jpg", "caption": "Figure 5: Quantitative Comparison in Image-to-3D Generation.", "description": "This figure shows a quantitative comparison of image-to-3D mesh generation results using different methods.  The input images are shown in the leftmost column, followed by reconstruction results from four different models: One-2-3-4-5, OpenLRM, TripoSR, and the authors' proposed X-Ray method. The ground truth (GT) meshes are shown in the rightmost column.  The comparison demonstrates the superior performance of the X-Ray method in generating complete and accurate 3D models from single input images across various object categories including boxes, footwear, cabinets, bowls, and cars.", "section": "5.4 Quantitative Comparison"}, {"figure_path": "36tMV15dPO/figures/figures_9_1.jpg", "caption": "Figure 6: Failure cases. The generated meshes will miss behind parts because of the limited number of frame layers.", "description": "This figure demonstrates failure cases of the X-Ray 3D generation method.  The top row shows an example with a hamburger.  The X-Ray representation successfully captures the visible layers, but the model fails to reconstruct the complete object, missing parts of the interior (indicated by the red dashed box). A similar problem is observed in the bottom row with a banana image, where the generated mesh is incomplete and lacks details.", "section": "5.6 Failure Cases"}, {"figure_path": "36tMV15dPO/figures/figures_13_1.jpg", "caption": "Figure 3: Overview of our proposed generative pipeline for the X-Ray 3D representation. There are three main components: (a) The X-Ray diffusion model, which generates a low-resolution X-Ray from an image input. (b) The upsampler, which enlarges the low-resolution X-Ray into 4\u00d7 high resolution. (c) The mesh decoding model, which decodes the high-resolution X-Ray into a point cloud with color and normal, and then converts it into the final generated mesh.", "description": "This figure illustrates the three main components of the proposed generative pipeline for X-Ray 3D representation. The pipeline consists of an X-Ray diffusion model that generates a low-resolution X-Ray from an image; an upsampler that increases the resolution of the low-resolution X-Ray by a factor of 4; and a mesh decoding model that converts the high-resolution X-Ray into a point cloud, which is then converted into a 3D mesh.", "section": "3 Our X-Ray Representation"}, {"figure_path": "36tMV15dPO/figures/figures_14_1.jpg", "caption": "Figure 3: Overview of our proposed generative pipeline for the X-Ray 3D representation. There are three main components: (a) The X-Ray diffusion model, which generates a low-resolution X-Ray from an image input. (b) The upsampler, which enlarges the low-resolution X-Ray into 4\u00d7 high resolution. (c) The mesh decoding model, which decodes the high-resolution X-Ray into a point cloud with color and normal, and then converts it into the final generated mesh.", "description": "This figure illustrates the three-stage pipeline for generating 3D mesh from a single image.  First, an X-Ray diffusion model takes an image as input and produces a low-resolution X-Ray representation. Second, an upsampler increases the resolution of this X-Ray fourfold. Finally, a mesh decoding model converts the high-resolution X-Ray into a 3D point cloud with color and normal information, which is then transformed into the final 3D mesh.", "section": "3 Our X-Ray Representation"}, {"figure_path": "36tMV15dPO/figures/figures_15_1.jpg", "caption": "Figure 7: Visualization of Image-to-3D Generation from X-Ray. These findings provide insights into the optimal configuration for diffusion models in 3D related tasks.", "description": "This figure visualizes the image-to-3D generation process using the X-Ray representation.  It shows four examples, each with an input image and the resulting synthesized X-Ray, the encoded point cloud, and three views of the decoded mesh. The figure demonstrates the method\u2019s ability to reconstruct 3D models from single images, highlighting the quality and detail achieved in the output meshes.", "section": "Experiments"}, {"figure_path": "36tMV15dPO/figures/figures_16_1.jpg", "caption": "Figure 8: Visualization of Text-to-3D Generation from X-Ray.", "description": "This figure demonstrates the Text-to-3D generation pipeline using X-Ray representation. Starting from textual descriptions (e.g., \u201ca black and silver power supply\u201d, \u201cgreen wine bottle\u201d, \u201ca polar bear\u201d, \u201ca rolled haystack\u201d), the pipeline first generates images using a pre-trained text-to-image diffusion model. Then, image segmentation is applied to isolate the object from the background. Next, the X-Ray representation is extracted from the segmented images, followed by point cloud encoding and mesh decoding to obtain the final 3D mesh model. The figure shows the synthesized image, segmented image, synthesized X-Ray, encoded point cloud, and the resulting decoded mesh for each textual input. This showcases the capability of X-Ray in translating text descriptions into 3D object representations.", "section": "4.1 X-Ray Diffusion Model"}]