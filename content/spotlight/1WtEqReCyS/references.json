{"references": [{"fullname_first_author": "A. Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational vision-language model that heavily influences the current paradigm and is directly compared against in this paper's experiments."}, {"fullname_first_author": "S. Changpinyo", "paper_title": "Conceptual 12M: Pushing web-scale image-text pre-training to recognize long-tail visual concepts", "publication_date": "2021-06-01", "reason": "This paper introduces Conceptual Captions 12M, a large-scale dataset used for data filtering in this paper, and its methodology is critically examined."}, {"fullname_first_author": "S. Y. Gadre", "paper_title": "DataComp: In search of the next generation of multimodal datasets", "publication_date": "2024-01-01", "reason": "This paper introduces the DataComp benchmark, providing the dataset and evaluation metrics used in the main experiments of this paper."}, {"fullname_first_author": "C. Schuhmann", "paper_title": "LAION-5B: An open large-scale dataset for training next generation image-text models", "publication_date": "2022-12-01", "reason": "This paper introduces LAION-5B, a large-scale dataset that is discussed as a relevant prior work that uses English-centric data filtering methods."}, {"fullname_first_author": "A. Fang", "paper_title": "Data filtering networks", "publication_date": "2023-09-01", "reason": "This paper introduces DFN, a data filtering method used and compared to CLIP's filtering method in this paper's experiments."}]}