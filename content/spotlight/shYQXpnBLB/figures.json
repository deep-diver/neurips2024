[{"figure_path": "shYQXpnBLB/figures/figures_1_1.jpg", "caption": "Figure 1: Original T2I models can generate stereotypes when given prompts involving multiple objects; when the prompts are \u201ca photo of black/white people\u201d or \u201ca photo of a house\u201d, they do not engender stereotypes. However, if the prompt is \u201ca photo of black/white people and a house\u201d, the model may engender stereotypes that the white people's house is better than the black people's house. It is noted that previous mitigation approaches have yet to mitigate these association-engendered stereotypes. Our approach, MAS, demonstrates the capability to effectively mitigate these stereotypes.", "description": "This figure demonstrates how text-to-image (T2I) models can generate stereotypical images when prompts involve associations between multiple objects (e.g., associating black people with smaller houses). It shows that while prompts mentioning \"black people\" or \"houses\" alone don't inherently create bias, combining them in a prompt can lead to the generation of biased images. The figure highlights the limitations of existing approaches in mitigating these \"association-engendered stereotypes\" and showcases the effectiveness of the proposed MAS framework in addressing this issue.", "section": "1 Introduction"}, {"figure_path": "shYQXpnBLB/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of our proposed MAS. (1) In the PIS model pre-training stage, we adjust the traditional CLIP structure from the original \u201ctext-image\u201d two-dimensional mapping to a \u201ctext-image-text\u201d three-dimensional mapping, thereby obtaining a mapping of prompts to stereotypes. (2) In constructing sensitive constraints, we propose a Sensitive Transformer based on the transformer structure to construct sensitive constraints for each prompt. (3) In the stage of adding sensitive constraints to the T2I, we embed the sensitive constraints into the T2I diffusion model to guide the generation of stereotype-free images.", "description": "This figure illustrates the MAS framework's three stages: 1. Pre-training the Prompt-Image-Stereotype CLIP (PIS CLIP) to learn associations between prompts, images, and stereotypes. 2. Employing a Sensitive Transformer to create sensitive constraints based on prompts. 3. Integrating these constraints into a T2I diffusion model to generate stereotype-free images.", "section": "3 Our framework: mitigate association-engendered stereotypes (MAS)"}, {"figure_path": "shYQXpnBLB/figures/figures_8_1.jpg", "caption": "Figure 3: Images generated from the original SD-1.5 (left) and the SD-1.5 with MAS for mitigating stereotypes (right). Use the same prompt and T2I parameter settings for each category to generate 100 batch images and calculate the SDTV value. Compare the changes in SDTV values before and after mitigation. After applying MAS to the original model, the stereotypes are significantly mitigated. More images in Appendix H.", "description": "This figure shows the results of applying the MAS framework to mitigate stereotypes in images generated by the Stable Diffusion model (SD-1.5). Four scenarios are presented, each illustrating a different type of stereotype: single object with single sensitive attribute, single object with multiple sensitive attributes, multiple objects with single sensitive attribute, and multiple objects with multiple sensitive attributes.  The left column shows images generated by the original SD-1.5 model, exhibiting clear stereotypes. The right column displays images generated after applying MAS, demonstrating a significant reduction in stereotypes. The SDTV (Stereotype-Distribution-Total-Variation) values, quantifying the severity of stereotypes, are provided for each scenario, showing a substantial decrease after the application of MAS.", "section": "4.1 Mitigation effects"}, {"figure_path": "shYQXpnBLB/figures/figures_13_1.jpg", "caption": "Figure 1: Original T2I models can generate stereotypes when given prompts involving multiple objects; when the prompts are \u201ca photo of black/white people\u201d or \u201ca photo of a house\u201d, they do not engender stereotypes. However, if the prompt is \u201ca photo of black/white people and a house\u201d, the model may engender stereotypes that the white people's house is better than the black people's house. It is noted that previous mitigation approaches have yet to mitigate these association-engendered stereotypes. Our approach, MAS, demonstrates the capability to effectively mitigate these stereotypes.", "description": "This figure demonstrates how original text-to-image models can generate stereotypical images when given prompts containing multiple objects with associated sensitive attributes.  The examples show that while prompts about individual objects (black people, white people, or houses) may not produce stereotypes, combining them in a single prompt (e.g., \"a photo of black and white people and a house\") can lead to biased results, such as associating wealthier houses with white people and poorer houses with black people.  The figure highlights the limitations of previous stereotype mitigation techniques and showcases the effectiveness of the proposed MAS (Mitigate Association-Engendered Stereotypes) framework in addressing these biases.", "section": "1 Introduction"}, {"figure_path": "shYQXpnBLB/figures/figures_14_1.jpg", "caption": "Figure 3: Images generated from the original SD-1.5 (left) and the SD-1.5 with MAS for mitigating stereotypes (right). Use the same prompt and T2I parameter settings for each category to generate 100 batch images and calculate the SDTV value. Compare the changes in SDTV values before and after mitigation. After applying MAS to the original model, the stereotypes are significantly mitigated. More images in Appendix H.", "description": "This figure shows a comparison of images generated by the original Stable Diffusion model (SD-1.5) and the model enhanced with the proposed MAS framework.  Four scenarios are presented, each demonstrating different types of stereotypes (Single Object with Single Sensitive Attribute, Single Object with Multiple Sensitive Attributes, Multiple Objects with Single Sensitive Attribute, and Multiple Objects with Multiple Sensitive Attributes). For each scenario, the figure displays 100 images generated using the same prompt and settings.  The results demonstrate that MAS effectively reduces stereotypes in the generated images.", "section": "4.1 Mitigation effects"}, {"figure_path": "shYQXpnBLB/figures/figures_14_2.jpg", "caption": "Figure 2: Overview of our proposed MAS. (1) In the PIS model pre-training stage, we adjust the traditional CLIP structure from the original \u201ctext-image\u201d two-dimensional mapping to a \u201ctext-image-text", "description": "This figure illustrates the MAS framework, showing three main stages: (1) PIS CLIP pre-training, which learns the association between prompts, images, and stereotypes; (2) Sensitive constraint construction, using a Sensitive Transformer to generate constraints tailored to each prompt; and (3) Constraint addition to the T2I model, guiding image generation toward alignment with a stereotype-free distribution. The framework aims to effectively mitigate association-engendered stereotypes in text-to-image generation.", "section": "3 Our framework: mitigate association-engendered stereotypes (MAS)"}, {"figure_path": "shYQXpnBLB/figures/figures_16_1.jpg", "caption": "Figure 6: Training data annotation visualization.", "description": "This figure illustrates how the training data is annotated for the PIS CLIP model.  It shows that for each image, its corresponding stereotype is represented by a probability distribution.  This distribution is then summarized using text descriptions that capture the dominant stereotypes present. The examples highlight the categorization of stereotypes: single object with multiple sensitive attributes (S-O & M-SA) and multiple objects with a single sensitive attribute (M-O & S-SA).", "section": "3.1 Modeling stereotypes in T2I"}, {"figure_path": "shYQXpnBLB/figures/figures_16_2.jpg", "caption": "Figure 2: Overview of our proposed MAS. (1) In the PIS model pre-training stage, we adjust the traditional CLIP structure from the original \u201ctext-image\u201d two-dimensional mapping to a \u201ctext-image-text\u201d three-dimensional mapping, thereby obtaining a mapping of prompts to stereotypes. (2) In constructing sensitive constraints, we propose a Sensitive Transformer based on the transformer structure to construct sensitive constraints for each prompt. (3) In the stage of adding sensitive constraints to the T2I, we embed the sensitive constraints into the T2I diffusion model to guide the generation of stereotype-free images.", "description": "This figure illustrates the MAS framework's three stages: pre-training the Prompt-Image-Stereotype CLIP (PIS CLIP) to map prompts to stereotypes, constructing sensitive constraints using a Sensitive Transformer, and incorporating these constraints into a T2I diffusion model to generate stereotype-free images.  The diagram visually represents the data flow and interactions between the different components of the framework.", "section": "3 Our framework: mitigate association-engendered stereotypes (MAS)"}, {"figure_path": "shYQXpnBLB/figures/figures_17_1.jpg", "caption": "Figure 2: Overview of our proposed MAS. (1) In the PIS model pre-training stage, we adjust the traditional CLIP structure from the original \u201ctext-image\u201d two-dimensional mapping to a \u201ctext-image-text", "description": "The figure illustrates the MAS framework's three stages: (1) PIS CLIP pre-training to learn the association between prompts, images, and stereotypes; (2) construction of sensitive constraints using a Sensitive Transformer; and (3) integration of these constraints into the T2I diffusion model to guide the generation of stereotype-free images.  It highlights the three-dimensional mapping from prompts, images to stereotype descriptions,  the generation of sensitive constraints and their embedding into the diffusion process.", "section": "3 Our framework: mitigate association-engendered stereotypes (MAS)"}, {"figure_path": "shYQXpnBLB/figures/figures_17_2.jpg", "caption": "Figure 2: Overview of our proposed MAS. (1) In the PIS model pre-training stage, we adjust the traditional CLIP structure from the original \u201ctext-image\u201d two-dimensional mapping to a \u201ctext-image-text", "description": "This figure illustrates the MAS framework's three stages: (1) PIS CLIP pre-training to learn the association between prompts, images, and stereotypes. (2) Construction of sensitive constraints using a Sensitive Transformer. (3) Integration of these constraints into the T2I diffusion model to guide the generation of stereotype-free images.  The framework maps prompts to stereotypes, generating sensitive constraints that align the image's probability distribution with a stereotype-free distribution.", "section": "3.3 Mitigating association-engendered stereotypes"}, {"figure_path": "shYQXpnBLB/figures/figures_19_1.jpg", "caption": "Figure 3: Images generated from the original SD-1.5 (left) and the SD-1.5 with MAS for mitigating stereotypes (right). Use the same prompt and T2I parameter settings for each category to generate 100 batch images and calculate the SDTV value. Compare the changes in SDTV values before and after mitigation. After applying MAS to the original model, the stereotypes are significantly mitigated. More images in Appendix H.", "description": "This figure demonstrates the effectiveness of the proposed MAS framework in mitigating stereotypes in text-to-image generation. It shows pairs of images generated by the original SD-1.5 model and the modified SD-1.5 model with MAS for four different scenarios representing varying levels of object-attribute combinations. Each pair uses the same prompt, and the significant reduction in stereotypes in the MAS-generated images (right) is evident. The quantitative results in terms of SDTV values are also provided, further emphasizing the impact of MAS.", "section": "4.1 Mitigation effects"}, {"figure_path": "shYQXpnBLB/figures/figures_20_1.jpg", "caption": "Figure 3: Images generated from the original SD-1.5 (left) and the SD-1.5 with MAS for mitigating stereotypes (right). Use the same prompt and T2I parameter settings for each category to generate 100 batch images and calculate the SDTV value. Compare the changes in SDTV values before and after mitigation. After applying MAS to the original model, the stereotypes are significantly mitigated. More images in Appendix H.", "description": "This figure shows the results of mitigating stereotypes using the proposed MAS framework. It compares images generated by the original SD-1.5 model and the SD-1.5 model with MAS applied. Four different scenarios are shown, illustrating how MAS effectively reduces stereotypes in various situations. The caption mentions the use of the same prompts and parameters, the calculation of the SDTV (Stereotype-Distribution-Total-Variation) value, and the significant reduction in stereotypes after applying MAS.", "section": "4.1 Mitigation effects"}, {"figure_path": "shYQXpnBLB/figures/figures_21_1.jpg", "caption": "Figure 2: Overview of our proposed MAS. (1) In the PIS model pre-training stage, we adjust the traditional CLIP structure from the original \u201ctext-image\u201d two-dimensional mapping to a \u201ctext-image-text\u201d three-dimensional mapping, thereby obtaining a mapping of prompts to stereotypes. (2) In constructing sensitive constraints, we propose a Sensitive Transformer based on the transformer structure to construct sensitive constraints for each prompt. (3) In the stage of adding sensitive constraints to the T2I, we embed the sensitive constraints into the T2I diffusion model to guide the generation of stereotype-free images.", "description": "This figure illustrates the MAS framework's three stages:  pre-training a Prompt-Image-Stereotype CLIP (PIS CLIP) to learn prompt-stereotype associations; constructing sensitive constraints using a Sensitive Transformer; and integrating these constraints into a T2I diffusion model to generate stereotype-free images. The three panels show the process for each stage.", "section": "3 Our framework: mitigate association-engendered stereotypes (MAS)"}, {"figure_path": "shYQXpnBLB/figures/figures_21_2.jpg", "caption": "Figure 3: Images generated from the original SD-1.5 (left) and the SD-1.5 with MAS for mitigating stereotypes (right). Use the same prompt and T2I parameter settings for each category to generate 100 batch images and calculate the SDTV value. Compare the changes in SDTV values before and after mitigation. After applying MAS to the original model, the stereotypes are significantly mitigated. More images in Appendix H.", "description": "This figure shows the effectiveness of the proposed MAS framework in mitigating stereotypes in image generation. It compares images generated by a standard T2I model (SD-1.5) with those generated by the same model but with the MAS framework integrated. Four different scenarios representing varying complexities of stereotypes (single object/multiple objects, single attribute/multiple attributes) are presented. The SDTV (Stereotype-Distribution-Total-Variation) values are calculated for each scenario to quantitatively assess the extent of stereotype mitigation.  The results demonstrate that MAS significantly reduces stereotypes in all scenarios, showcasing its ability to handle various stereotype contexts.", "section": "4.1 Mitigation effects"}, {"figure_path": "shYQXpnBLB/figures/figures_21_3.jpg", "caption": "Figure 3: Images generated from the original SD-1.5 (left) and the SD-1.5 with MAS for mitigating stereotypes (right). Use the same prompt and T2I parameter settings for each category to generate 100 batch images and calculate the SDTV value. Compare the changes in SDTV values before and after mitigation. After applying MAS to the original model, the stereotypes are significantly mitigated. More images in Appendix H.", "description": "This figure shows a comparison of images generated by the original SD-1.5 model and the modified version with the MAS framework applied. Four scenarios are depicted, showcasing how the MAS framework effectively reduces stereotypes in image generation.  Each scenario has two sets of 100 images generated under identical parameters - one using the original model, the other using the MAS-modified model.  The visual difference highlights the mitigation of stereotypes achieved through the MAS framework.  Further examples are provided in Appendix H.", "section": "4.1 Mitigation effects"}, {"figure_path": "shYQXpnBLB/figures/figures_22_1.jpg", "caption": "Figure 1: Original T2I models can generate stereotypes when given prompts involving multiple objects; when the prompts are \u201ca photo of black/white people\u201d or \u201ca photo of a house\u201d, they do not engender stereotypes. However, if the prompt is \u201ca photo of black/white people and a house\u201d, the model may engender stereotypes that the white people's house is better than the black people's house. It is noted that previous mitigation approaches have yet to mitigate these association-engendered stereotypes. Our approach, MAS, demonstrates the capability to effectively mitigate these stereotypes.", "description": "This figure demonstrates that while text-to-image models may not generate stereotypes when prompted with single objects (e.g., \"a photo of black people\", \"a photo of a house\"), they can produce stereotypical associations when multiple objects are combined (e.g., \"a photo of black people and a house\").  The example shown highlights a potential bias where houses associated with white people are depicted as superior to those associated with black people. The authors' proposed method, MAS, aims to address this issue.", "section": "1 Introduction"}, {"figure_path": "shYQXpnBLB/figures/figures_22_2.jpg", "caption": "Figure 1: Original T2I models can generate stereotypes when given prompts involving multiple objects; when the prompts are \u201ca photo of black/white people\u201d or \u201ca photo of a house\u201d, they do not engender stereotypes. However, if the prompt is \u201ca photo of black/white people and a house\u201d, the model may engender stereotypes that the white people's house is better than the black people's house. It is noted that previous mitigation approaches have yet to mitigate these association-engendered stereotypes. Our approach, MAS, demonstrates the capability to effectively mitigate these stereotypes.", "description": "This figure illustrates how stereotypes can emerge in text-to-image generation when prompts involve associations between multiple objects.  It contrasts the output of standard models, which may show biases (e.g., associating wealthier houses with white people), with the improved, less-biased outputs achieved by the authors' proposed MAS framework.", "section": "1 Introduction"}, {"figure_path": "shYQXpnBLB/figures/figures_23_1.jpg", "caption": "Figure 3: Images generated from the original SD-1.5 (left) and the SD-1.5 with MAS for mitigating stereotypes (right). Use the same prompt and T2I parameter settings for each category to generate 100 batch images and calculate the SDTV value. Compare the changes in SDTV values before and after mitigation. After applying MAS to the original model, the stereotypes are significantly mitigated. More images in Appendix H.", "description": "This figure shows the results of stereotype mitigation using the proposed MAS framework. It presents images generated by the original SD-1.5 model and the modified SD-1.5 model with MAS, demonstrating the effectiveness of the framework in reducing stereotypes. Four scenarios are illustrated, each demonstrating the effect of mitigation on different types of stereotypes. For each scenario, the SDTV values are compared before and after the mitigation, illustrating the reduction in stereotypes.", "section": "4.1 Mitigation effects"}, {"figure_path": "shYQXpnBLB/figures/figures_24_1.jpg", "caption": "Figure 3: Images generated from the original SD-1.5 (left) and the SD-1.5 with MAS for mitigating stereotypes (right). Use the same prompt and T2I parameter settings for each category to generate 100 batch images and calculate the SDTV value. Compare the changes in SDTV values before and after mitigation. After applying MAS to the original model, the stereotypes are significantly mitigated. More images in Appendix H.", "description": "This figure shows a comparison of images generated by the original SD-1.5 model and the SD-1.5 model with the proposed MAS (Mitigate Association-Engendered Stereotypes) framework. Four scenarios are presented, each illustrating a different type of stereotype (Single Object with Single Sensitive Attribute, Single Object with Multiple Sensitive Attributes, Multiple Objects with Single Sensitive Attribute, and Multiple Objects with Multiple Sensitive Attributes). For each scenario, 100 images were generated using the same prompt and parameters. The SDTV (Stereotype-Distribution-Total-Variation) values are shown for both the original and MAS-modified models, demonstrating the effectiveness of MAS in reducing stereotypes. Appendix H provides additional images.", "section": "4.1 Mitigation effects"}, {"figure_path": "shYQXpnBLB/figures/figures_25_1.jpg", "caption": "Figure 3: Images generated from the original SD-1.5 (left) and the SD-1.5 with MAS for mitigating stereotypes (right). Use the same prompt and T2I parameter settings for each category to generate 100 batch images and calculate the SDTV value. Compare the changes in SDTV values before and after mitigation. After applying MAS to the original model, the stereotypes are significantly mitigated. More images in Appendix H.", "description": "This figure demonstrates the effectiveness of the proposed MAS framework in mitigating stereotypes in text-to-image generation. It presents four scenarios with varying levels of object and attribute complexity (single object/single attribute, single object/multiple attributes, multiple objects/single attribute, multiple objects/multiple attributes). For each scenario, it shows the images generated by the original SD-1.5 model (left) and the SD-1.5 model after the MAS framework is applied (right). The SDTV (Stereotype-Distribution-Total-Variation) values are provided for comparison, highlighting the significant reduction in stereotypes after using MAS.", "section": "4.1 Mitigation effects"}]