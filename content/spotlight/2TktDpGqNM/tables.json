[{"figure_path": "2TktDpGqNM/tables/tables_14_1.jpg", "caption": "Table 1: Selected DeepGambler reward hyperparameter based on the AUGRC on the validation set for all confidence scoring functions trained with the DeepGamblers objective.", "description": "This table shows the selected hyperparameters for the DeepGambler reward and dropout for different datasets used in the study. The selection is based on the AUGRC metric on the validation set. For each dataset, the table lists the selected hyperparameter value for different confidence scoring functions.", "section": "A.2.1 Datasets and Methods"}, {"figure_path": "2TktDpGqNM/tables/tables_14_2.jpg", "caption": "Table 4: Comparing Rankings of AURC \u2192 \u03b1 versus AUGRC \u2192 \u03b2. Differences in the method rankings between AURC and AUGRC demonstrate the relevance of the pitfalls of the AURC discussed in Section 2.4. Upper half: Model selection for dropout and DG hyperparameter was done for both metrics separately. Lower half: Model selection was done based on AUGRC for both \u03b1 and \u03b2. The selected hyperparameters are reported in Appendix A.2.2. The color heatmap is normalized per column, whereby whiter colors depict better scores. \"cor\" is the average over 5 intensity levels of image corruption shifts. AUGRC scores are averaged over 10 runs on CAMELYON-17-Wilds, over 2 runs on BREEDS, and over 5 runs on all other datasets. Abbreviations: ncs: new-class shift (s for semantic, ns for non-semantic), iid: independent and identically distributed, sub: sub-class shift, cor: image corruptions, c10/100: CIFAR-10/100, ti: TinyImagenet.", "description": "This table compares the ranking of Confidence Scoring Functions (CSFs) based on two different metrics: AURC and AUGRC. It highlights the differences in rankings obtained using these two metrics across various datasets and distribution shifts.  The table shows that substantial differences exist between the rankings, indicating that the choice of metric significantly impacts the assessment of CSF performance. The upper half displays results where hyperparameters were independently tuned for each metric. The lower half shows results where hyperparameters were tuned using the AUGRC metric.", "section": "4.1 Comparing Method Rankings of AUGRC and AURC"}]