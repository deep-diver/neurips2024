[{"figure_path": "JyWAFGCJPl/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison between (a) traditional 'makeshift' embedding OOV recommendation framework, and (b) user sequence imagination OOV recommendation framework.", "description": "The figure compares two different approaches for out-of-vocabulary (OOV) item recommendation. (a) shows the traditional 'makeshift' embedding method, which generates embeddings for OOV items using only content features, without considering user behavior. This method is shown to have limitations. (b) presents the proposed User Sequence Imagination (USIM) framework, which first imagines user sequences and then uses these imagined sequences to refine the generated OOV embeddings through backpropagation. The USIM method aims to bridge the gap between content features and behavioral embeddings for improved recommendation performance. The figure illustrates the key difference between these methods, highlighting USIM's ability to better utilize user interaction data for more effective OOV recommendations.", "section": "1 Introduction"}, {"figure_path": "JyWAFGCJPl/figures/figures_3_1.jpg", "caption": "Figure 2: The overview framework of USIM. USIM fine-tunes the generated OOV item embeddings through sequential user interaction imagination, guided by exploration set construction, state transition, and a tailored reward mechanism.", "description": "The figure illustrates the USIM framework, showing how it fine-tunes generated OOV item embeddings through sequential user interaction imagination.  The process is guided by three key components: exploration set construction (selecting users for interaction simulation), state transition (updating the item embedding based on imagined user interactions), and a reward function (guiding the optimization process using embedding alignment and recommendation performance rewards). The diagram visually represents the interactions between these components, using different shapes and colors to represent users, items, embeddings, and actions.", "section": "3 Proposed User Sequence Imagination Model"}, {"figure_path": "JyWAFGCJPl/figures/figures_8_1.jpg", "caption": "Figure 3: Comparing USIM with other RL methods for overall and OOV recommendation performance in CiteULike dataset.", "description": "This figure compares the performance of USIM against three other reinforcement learning methods (MLP, WP, and HRL) for both overall and OOV recommendation tasks using the CiteULike dataset.  It visually demonstrates the superiority of USIM in terms of NDCG@K scores, showcasing its effectiveness in improving recommendation quality, especially for OOV items.", "section": "4.4 Comparison with Representative RL Methods (RQ3)"}, {"figure_path": "JyWAFGCJPl/figures/figures_8_2.jpg", "caption": "Figure 4: Performance analysis of different generation methods on the CiteUlike dataset.", "description": "This figure analyzes the performance of three different user selection methods for the USIM model on the CiteULike dataset.  The three methods are: (1) selecting users with highest cosine similarity to the current state, (2) randomly selecting from the top 20 most relevant users, and (3) completely random user selection.  The graphs show NDCG scores for OOV and overall recommendation performance across different steps of the optimization process (x-axis represents the step, and y-axis represents the NDCG score).  This visualization helps in understanding how different user selection methods affect the efficacy of the embedding optimization process within the USIM framework.", "section": "4.5 Case Study (RQ4)"}, {"figure_path": "JyWAFGCJPl/figures/figures_16_1.jpg", "caption": "Figure 5: Hyperparameter analysis of MF backbone on CiteULike dataset", "description": "This figure presents a hyperparameter analysis for the matrix factorization (MF) backbone on the CiteULike dataset.  It shows the impact of four key hyperparameters (k, N, p, \u03bb) on both overall and out-of-vocabulary (OOV) recommendation performance as measured by NDCG. Each subplot displays the NDCG scores for varying values of a single hyperparameter, holding others constant.  The analysis helps to determine the optimal settings for these hyperparameters, balancing overall recommendation quality with the specific needs of OOV item recommendations.", "section": "4.1 Experimental Setup"}, {"figure_path": "JyWAFGCJPl/figures/figures_16_2.jpg", "caption": "Figure 6: Hyperparameter analysis of GNN backbone on CiteULike dataset", "description": "This figure shows the result of hyperparameter analysis on the GNN backbone using the CiteULike dataset.  It presents the impact of four hyperparameters (k, N, p, \u03bb) on both overall and OOV recommendation performance, as measured by NDCG. Each subplot displays the NDCG scores for varying values of a single hyperparameter, while holding others constant.  The plots illustrate how these hyperparameters influence the model's ability to recommend both in-vocabulary and out-of-vocabulary items.", "section": "4.6 Online Evaluation (RQ5)"}, {"figure_path": "JyWAFGCJPl/figures/figures_17_1.jpg", "caption": "Figure 7: Overall framework of online implementation.", "description": "This figure illustrates the online implementation of the USIM framework. When a new out-of-vocabulary (OOV) item is uploaded, its content features (name, description etc.) are embedded by a Language Model.  The USIM module then imagines a user sequence and refines the OOV item's embedding. Finally, the refined embeddings are integrated into the Online Recommendation Model to recommend the OOV item to users, alongside existing in-vocabulary (IV) items. The process highlights the interplay between offline pre-processing (embedding updating via USIM) and online real-time recommendations.", "section": "Online Evaluation (RQ5)"}]