[{"figure_path": "6vNPPtWH1Q/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN f\u03b8(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "The figure illustrates the architecture of the Graph Energy-based Model (GEBM) for estimating epistemic uncertainty in Graph Neural Networks (GNNs).  It shows how graph-agnostic uncertainty from a pre-trained GNN is processed through three levels: local, group, and independent. Each level uses graph diffusion and energy marginalization to capture uncertainty at different structural scales.  Finally, these uncertainty estimates are combined using a \"softmax\"-like aggregation to produce a single measure of epistemic uncertainty sensitive to various anomaly types.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_8_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN fe(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "This figure illustrates the GEBM (Graph Energy-Based Model) framework for estimating epistemic uncertainty in Graph Neural Networks (GNNs).  It begins with a pre-trained GNN that produces graph-agnostic energy representing uncertainty. This energy is then regularized to address overconfidence issues. Next, the energy is aggregated at three different structural scales: local (fine-grained, sensitive to conflicting evidence), group (evidence smoothing, highlighting clusters), and independent (structure-agnostic, based on individual nodes).  Graph diffusion is interleaved with energy marginalization at each level to capture different granularities of patterns. Finally, the aggregated energies from all three levels are combined to produce a single, comprehensive measure of epistemic uncertainty for each node.  The figure visually represents the process with nodes, edges, and illustrative energy distributions.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_24_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN f\u03b8(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "This figure illustrates the architecture of the Graph Energy-based Model (GEBM). It shows how graph-agnostic energy (uncertainty) from a pre-trained Graph Neural Network (GNN) is first regularized to reduce overconfidence, then aggregated across different scales (local, cluster, and global) using graph diffusion and energy marginalization.  The different energy types are combined using a soft-maximum function to produce a single uncertainty score that is sensitive to anomalies at various structural levels.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_26_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN f\u03b8(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "This figure illustrates the architecture of the Graph Energy-based Model (GEBM).  It shows how graph-agnostic uncertainty from a pre-trained Graph Neural Network (GNN) is processed through regularization to reduce overconfidence. The model then aggregates this uncertainty across three different scales: local, cluster, and graph-agnostic.  Local uncertainty is highly granular and can detect inconsistencies in local neighborhoods; cluster uncertainty considers broader evidence smoothing; and graph-agnostic uncertainty is fully structure-agnostic. By combining these levels of uncertainty via soft maximum selection, GEBM produces a single uncertainty measure that is sensitive to various anomaly types.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_27_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN f\u03b8(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "This figure illustrates the architecture of the Graph Energy-based Model (GEBM). It starts with a pre-trained Graph Neural Network (GNN) which produces graph-agnostic energy. This energy is then regularized to reduce overconfidence.  After regularization, the energy is aggregated at different structural scales: local (fine-grained, sensitive to neighborhood disagreements), group (evidence smoothing, highlighting cluster anomalies), and independent (structure-agnostic, considering individual nodes).  The aggregation uses soft minimum selection to combine these energy types. The result is a single measure of epistemic uncertainty. The figure highlights that GEBM handles different anomaly types.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_28_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN fe(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "This figure illustrates the architecture of the Graph Energy-based Model (GEBM).  It shows how graph-agnostic energy (uncertainty) from a trained Graph Neural Network (GNN) is processed in three stages: regularization to reduce overconfidence, aggregation of energy at different structural levels (local, cluster, and global), and combining these levels via soft maximum selection.  Different aggregation methods are used at each level to capture different levels of granularity in the uncertainty. The resulting GEBM provides a single uncertainty measure sensitive to multiple anomaly types.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_29_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN f\u03b8(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "This figure illustrates the GEBM (Graph Energy-based Model) framework.  It begins with a pre-trained Graph Neural Network (GNN) that provides graph-agnostic energy (uncertainty). This energy is then regularized to reduce overconfidence. The core of the model involves aggregating the energy at three different levels: local, cluster, and graph-agnostic.  This aggregation is achieved by combining graph diffusion with energy marginalization at each level. The different levels capture uncertainty at different structural scales within the graph. Ultimately, GEBM combines these three energy levels into a single uncertainty measure that is able to detect anomalies of different types simultaneously.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_29_2.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN fe(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "This figure illustrates the GEBM (Graph Energy-based Model) framework.  It shows how graph-agnostic energy, representing uncertainty from a pre-trained Graph Neural Network (GNN), is processed. The process involves three steps: regularization to reduce overconfidence, aggregation of energy at different scales (local, cluster, and global), and the combination of these energy scales into a single uncertainty estimate.  The figure highlights that the GEBM method considers uncertainty arising at various levels of graph structure, leading to improved anomaly detection.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_30_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN fe(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "The figure illustrates the architecture of the Graph Energy-based Model (GEBM) for estimating epistemic uncertainty in Graph Neural Networks (GNNs).  It shows how graph-agnostic uncertainty from a pre-trained GNN is regularized to handle overconfidence.  Then, this uncertainty is aggregated across different structural scales (local, cluster, and global) using a process involving energy marginalization and graph diffusion. The different scales of aggregation are meant to capture uncertainty at different granularities in the graph structure.  The resulting GEBM combines these different levels of uncertainty into a single measure, which is shown to be effective at identifying various types of anomalies.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_33_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN f\u03b8(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "This figure illustrates the architecture of the Graph Energy-based Model (GEBM). It shows how graph-agnostic energy (uncertainty) from a trained Graph Neural Network (GNN) is processed.  The process involves regularization to address overconfidence, and then aggregation of energy at different scales (local, cluster, and structure-independent) by combining energy marginalization and graph diffusion. The different energy types are shown in separate boxes, highlighting how the model integrates information from various structural levels in the graph. Finally, the figure emphasizes that GEBM is effective at detecting multiple types of anomalies simultaneously by assigning high uncertainty.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_34_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN f\u03b8(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "This figure illustrates the architecture of the Graph Energy-based Model (GEBM).  It starts with a pre-trained Graph Neural Network (GNN) that produces graph-agnostic energy representing uncertainty.  This energy is then regularized to reduce overconfidence. Next, the energy is aggregated across different structural scales: local (fine-grained, sensitive to neighborhood disagreements), group (evidence smoothing emphasizing anomalous clusters), and independent (structure-agnostic, considering individual nodes).  The aggregation process interleaves graph diffusion to capture patterns at different granularities. Finally, the combined energy represents the overall epistemic uncertainty assigned by GEBM, showing its ability to detect various anomaly types.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_34_2.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN f\u03b8(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "This figure illustrates the Graph Energy-based Model (GEBM) and its process.  Graph-agnostic energy, representing uncertainty from a trained Graph Neural Network (GNN), is first regularized to avoid overconfidence. Then, this energy is aggregated across different scales (local, cluster, and global) by combining energy marginalization and graph diffusion.  The different energy types (group, local, and independent) are shown, highlighting how they're combined using a soft maximum. The final output is a single uncertainty estimate which considers uncertainty at different structural levels, ultimately making GEBM more robust and accurate in identifying various types of anomalies.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_35_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN f\u03b8(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "This figure illustrates the architecture of the Graph Energy-based Model (GEBM) which aggregates uncertainty from different structural levels using graph diffusion and energy marginalization.  It begins with graph-agnostic energy from a pre-trained Graph Neural Network (GNN), which is then regularized to reduce overconfidence. This energy is then aggregated at three levels: local (fine-grained), group (cluster-level), and independent (structure-agnostic). The aggregation process uses softmin operations and interleaves graph diffusion steps to capture patterns at various scales, ultimately assigning a high uncertainty score to instances exhibiting anomalies across various scales.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_36_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN f\u03b8(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "The figure illustrates the GEBM framework, which consists of three main components: graph-agnostic energy, local energy, and group energy.  Graph-agnostic energy represents the uncertainty of the GNN without considering the graph structure, local energy considers the uncertainty of individual nodes based on their neighbors' information, and group energy considers uncertainty at the cluster level.  The three types of energy are combined using a softmax function to produce a final uncertainty measure. The regularization step reduces overconfidence in the base GNN. The figure showcases how GEBM uses graph diffusion and energy marginalization to capture uncertainty from different structural levels and assigns high uncertainty to various anomaly types.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_37_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN f\u03b8(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "The figure illustrates the architecture of the Graph Energy-based Model (GEBM).  It shows how graph-agnostic uncertainty from a pre-trained Graph Neural Network (GNN) is processed through regularization to reduce overconfidence. This uncertainty is then aggregated at three different levels: local (fine-grained, sensitive to neighborhood disagreements), group (smooths energy within graph clusters), and independent (structure-agnostic, based on individual nodes). The integration of these different levels of uncertainty provides a more comprehensive measure, particularly for complex anomaly scenarios.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_39_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN fe(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "This figure illustrates the architecture of the Graph Energy-based Model (GEBM). It shows how graph-agnostic energy, representing uncertainty from a trained Graph Neural Network (GNN), is processed through a series of steps: regularization to address overconfidence, aggregation at different structural scales (local, cluster, and global) via energy marginalization and graph diffusion, and finally combination of these scales.  Different energy types capture patterns at different granularities, allowing GEBM to effectively detect anomalies across various structural levels within the graph.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_39_2.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN fe(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "The figure illustrates the architecture of the Graph Energy-based Model (GEBM).  It starts with a pre-trained Graph Neural Network (GNN) that outputs graph-agnostic energy.  This energy is then regularized to address overconfidence. The core of GEBM is the aggregation of this energy at multiple structural levels (local, group, and independent). This aggregation is achieved by using graph diffusion and energy marginalization. The combination of these methods enables the model to capture uncertainty at different scales and assign high uncertainty to various anomaly types.", "section": "1 Introduction"}, {"figure_path": "6vNPPtWH1Q/figures/figures_43_1.jpg", "caption": "Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN f\u03b8(G) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.", "description": "The figure illustrates the architecture of the Graph Energy-based Model (GEBM) for estimating epistemic uncertainty in Graph Neural Networks (GNNs).  It shows how graph-agnostic energy (uncertainty) from a pre-trained GNN is processed through three stages: regularization to mitigate overconfidence, aggregation at different structural levels (local, group, and global), and finally combination of these levels using a soft maximum function. Each stage uses graph diffusion techniques to incorporate structural information into the uncertainty estimation. The figure highlights that GEBM is designed to capture uncertainty at various granularities, achieving better separation of in-distribution and out-of-distribution data.", "section": "1 Introduction"}]