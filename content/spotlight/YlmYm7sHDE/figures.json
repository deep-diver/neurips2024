[{"figure_path": "YlmYm7sHDE/figures/figures_5_1.jpg", "caption": "Figure 1: An example for Theorem 3.", "description": "This figure illustrates Theorem 3, which describes how to find optimal couplings in the neighborhood of a deterministic mapping.  Specifically, it shows how to find optimal solutions for entropy values slightly above and below the entropy (R<sub>g</sub>) of the deterministic mapping.  It highlights that moving an infinitesimal probability mass from a cell with the smallest normalized value to a new column in the same row (for slightly higher entropy) or from the smallest value cell of the lowest sum column to the highest sum column (for slightly lower entropy) will find the optimal coupling.", "section": "3.2 Optimal Coupling Around Deterministic Mappings"}, {"figure_path": "YlmYm7sHDE/figures/figures_6_1.jpg", "caption": "Figure 2: Solutions to the EBIM problem for px = [0.7, 0.2, 0.1]. Left: brute force solution. Right: application of the transformations from Theorem 3 to each deterministic mapping (dashed lines) and selection of solutions with maximal mutual information for each R value (thick solid line). This strategy effectively recovers optimal solutions, aligning with those found by brute force in this case.", "description": "This figure compares two approaches for solving the Entropy-Bounded Information Maximization (EBIM) problem for a specific probability distribution (px = [0.7, 0.2, 0.1]). The left panel shows the optimal solutions obtained via an exhaustive brute-force search. The right panel demonstrates an alternative method based on Theorem 3, where the solutions are obtained by starting with a deterministic mapping and then applying transformations to close the gap to the optimal solution. The figure highlights that the method based on Theorem 3 effectively recovers the optimal solutions obtained by brute force, illustrating the effectiveness of the proposed approach.", "section": "3 Entropy-Bounded Information Maximization"}, {"figure_path": "YlmYm7sHDE/figures/figures_8_1.jpg", "caption": "Figure 4: The trade-off between average MDP reward vs. receiver's accuracy, navigated by varying the value of \u03b2. Left: using our search algorithm for compression (Algorithm 1), Right: using uniform quantization in Algorithm 5. The message size is 512 with a uniform prior, and each data point is averaged over 200 episodes.", "description": "This figure shows the trade-off between the average MDP reward and the receiver's decoding accuracy by varying the parameter \u03b2 using two different compression methods: the proposed deterministic EBIM solver and a uniform quantizer.  The left panel displays results from the deterministic EBIM solver (Algorithm 1), while the right panel shows results from the uniform quantizer (Algorithm 5).  Each data point represents the average over 200 episodes, with message size of 512 and a uniform prior.", "section": "4.2 Experimental Results"}, {"figure_path": "YlmYm7sHDE/figures/figures_9_1.jpg", "caption": "Figure 5: Evolution of message belief over time, for various values of \u03b2 and rate budget, using our search algorithm for compression in Algorithm 1 vs. uniform quantization in Algorithm 5.", "description": "This figure shows how the receiver's belief about the message evolves over time for different compression rates and values of \u03b2 (beta). \u03b2 controls the stochasticity of the agent's actions in the Markov Decision Process (MDP).  The plots compare the performance of the proposed deterministic EBIM solver (Algorithm 1) with a baseline uniform quantizer (Algorithm 5).  Different colors represent various compression rates, demonstrating the trade-off between compression efficiency and the speed of convergence to the correct message.", "section": "4.2 Experimental Results"}, {"figure_path": "YlmYm7sHDE/figures/figures_15_1.jpg", "caption": "Figure 1: An example for Theorem 3.", "description": "This figure illustrates Theorem 3, which describes how to find optimal couplings close to any deterministic mapping. It shows how to find the optimal couplings in the neighborhood of a deterministic mapping by moving infinitesimal probability mass from one cell to another.  The figure visualizes the changes in mutual information (I(X;T)) and entropy (H(T)) as a result of these small probability mass changes.  The lines show different solutions which maximize mutual information for a given entropy value.", "section": "3.2 Optimal Coupling Around Deterministic Mappings"}, {"figure_path": "YlmYm7sHDE/figures/figures_22_1.jpg", "caption": "Figure 10: Generated couplings in MEC-B formulation (2), for uniform input and output distributions. The compression rate is defined as H(X)/R. Higher compression rates lead to more stochastic couplings with increased entropy.", "description": "This figure shows the generated couplings for different compression rates in the MEC-B framework using uniform input and output distributions.  The compression rate is defined as the ratio of the input entropy to the allowed code budget. As the compression rate increases (meaning less information is allowed to be transmitted), the couplings become more stochastic and their entropy increases.", "section": "D.2 Visualizing Couplings from MEC-B"}, {"figure_path": "YlmYm7sHDE/figures/figures_23_1.jpg", "caption": "Figure 9: Obtained I(X;T) vs. maximum allowed H(T) for Binomial (left) and Truncated Geometric (right) input distributions.", "description": "This figure compares the mutual information achieved by the proposed deterministic EBIM solver and the method from Shkel et al. (2017) for two different input distributions: Binomial and Truncated Geometric. The x-axis represents the maximum allowed entropy H(T) (rate), and the y-axis represents the mutual information I(X;T) achieved.  The plot shows that both methods perform similarly in the high-rate regime, but in the low-rate regime, the proposed method identifies more mappings and outperforms the Shkel et al. (2017) method.", "section": "D.1 Deterministic EBIM Solver vs. Shkel et al. (2017)"}, {"figure_path": "YlmYm7sHDE/figures/figures_24_1.jpg", "caption": "Figure 10: Generated couplings in MEC-B formulation (2), for uniform input and output distributions. The compression rate is defined as H(X)/R. Higher compression rates lead to more stochastic couplings with increased entropy.", "description": "This figure visualizes the couplings generated by the Minimum Entropy Coupling with Bottleneck (MEC-B) framework for different compression rates.  The input and output distributions are uniform.  Each subplot shows a coupling matrix at a specific compression rate (H(X)/R).  As the compression rate increases (meaning the code budget R decreases relative to the input entropy H(X)), the couplings transition from deterministic (mostly diagonal) to increasingly stochastic (more spread out). The color intensity represents the coupling probability. Darker blue indicates higher probability.", "section": "D.2 Visualizing Couplings from MEC-B"}, {"figure_path": "YlmYm7sHDE/figures/figures_25_1.jpg", "caption": "Figure 11: Block diagram of the unsupervised image restoration framework.", "description": "This figure shows a block diagram of the unsupervised image restoration framework proposed in the paper. The framework consists of an encoder, generator, reconstructor, and discriminator. The encoder takes a low-resolution image X as input and outputs a compressed representation T. The generator takes T and a noise vector Z as input and outputs a high-resolution image Y. The reconstructor takes Y as input and outputs a reconstructed low-resolution image X'. The discriminator takes Y and X' as input and outputs an adversarial loss Ladv. The total loss is the sum of the adversarial loss and an information loss Linfo, which encourages the generated image Y to be similar to the original image X.", "section": "E Unsupervised Image Restoration"}, {"figure_path": "YlmYm7sHDE/figures/figures_26_1.jpg", "caption": "Figure 10: Generated couplings in MEC-B formulation (2), for uniform input and output distributions. The compression rate is defined as H(X)/R. Higher compression rates lead to more stochastic couplings with increased entropy.", "description": "This figure visualizes the couplings generated using the Minimum Entropy Coupling with Bottleneck (MEC-B) framework.  It shows how the joint distribution between the input (X) and output (Y) changes as the compression rate varies.  The compression rate is the ratio of the input entropy to the allowed code budget, H(X)/R. Higher compression rates mean less information is preserved. As the compression rate increases (moving from left to right and top to bottom), the coupling becomes more stochastic, as evidenced by increased entropy and less deterministic mappings between X and Y. This illustrates the trade-off between compression and the resulting entropy.", "section": "D.2 Visualizing Couplings from MEC-B"}, {"figure_path": "YlmYm7sHDE/figures/figures_26_2.jpg", "caption": "Figure 13: Input and output samples from the SVHN dataset", "description": "This figure shows example inputs (low-resolution images) and their corresponding outputs (high-resolution images upscaled by a factor of 4) from the Street View House Numbers (SVHN) dataset.  The figure illustrates the performance of the unsupervised image restoration framework proposed in the paper. Note that some color discrepancies may be observed between original and upscaled images, as pointed out in the paper, reflecting the invariance of mutual information to invertible transformations (e.g., color permutations).", "section": "E Unsupervised Image Restoration"}]