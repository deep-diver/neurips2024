[{"figure_path": "FBLJIfW64D/figures/figures_5_1.jpg", "caption": "Figure 1: Excess risk eq. (6) of RFRR as a function of the number of features p for a fixed number of samples n. Solid lines are obtained from the deterministic equivalent in Theorem 3.3, and points are numerical simulations, with the different curves denoting different regularization strengths x \u2265 0. (Left) Training data (xi, Yi)i\u2208[n], n = 500, sampled from a teacher-student model yi = erf((\u03b2, xi))+ \u03b5i, \u03c3\u00b2 = 0.1, xi ~i.i.d. N(0, Id), with a spiked random feature map \u03c6(x, w) = tanh((w + uv, x)) where v \u2208 Rd has a fixed overlap \u03b3 = (\u03c5, \u03b2) with the teacher vector, w ~ N(0,d\u00af\u00b9Id), u ~ N(0, 1). (Right) Training data (xi, Yi)i\u2208[n], n = 300, sub-sampled from the FashionMNIST data set [Xiao et al., 2017], with feature map given by \u03c6(x; w) = erf((w, x)) and \u03bc\u03c9 = N(0, d\u00af\u00b9Ia).", "description": "The figure shows the excess risk of random feature ridge regression (RFRR) as a function of the number of features (p) for a fixed number of samples (n).  The solid lines represent the theoretical predictions from a deterministic equivalent derived in the paper (Theorem 3.3), while the points are the results of numerical simulations. Different lines represent different regularization strengths (\u03bb). The left panel shows results using a teacher-student model with a spiked random feature map, while the right panel utilizes data from the FashionMNIST dataset and a different feature map.", "section": "3 Deterministic equivalents"}, {"figure_path": "FBLJIfW64D/figures/figures_7_1.jpg", "caption": "Figure 2: Excess error rate y in the regime \u03b7 \u00bb \u03c3\u03b5 as a function of (l, q), defined in eq. (40) and eq. (39) for r \u2265 1/2 (Left) and r\u2208 [0,1/2) (Right). The explicit crossover points l*, q, q are defined in eq. (43) as a function of the source r and capacity a exponents.", "description": "This figure shows the excess error rate as a function of the scaling parameters l and q for different values of the source exponent (r) and capacity exponent (a).  The left panel shows the case where r >= 1/2, while the right panel shows the case where r is between 0 and 1/2. Different colors represent different regions with different dominant factors in the excess risk (bias vs variance). The figure illustrates the trade-offs between the bias and variance terms under different scaling regimes and helps to identify the optimal scaling parameters for achieving optimal excess risk rate.", "section": "Scaling laws"}, {"figure_path": "FBLJIfW64D/figures/figures_9_1.jpg", "caption": "Figure 3: Excess risk eq. (6) of RFRR as a function of the number of samples n under source and capacity conditions eq. (37) and power-law assumptions \u03bb = n\u2212(l\u22121), p = nq, with noise variance \u03c3\u00b2 = 0.1. Solid lines are obtained from the deterministic equivalent Theorem 3.3. In the figure on the left, points are finite size numerical experiments. Dashed and dotted lines are the analytical rates from Theorem 4.1, stated in the legend. The colour scheme corresponds to the regions of Fig. 2.", "description": "This figure displays the excess risk of random feature ridge regression as a function of the number of samples (n) under specific source and capacity conditions. It compares the theoretical predictions from the deterministic equivalent (solid lines) with numerical simulations (points) for different regularization strengths and numbers of features. The dashed and dotted lines represent analytical rates from a different theorem, and the colors correspond to different regions defined in a previous figure (Fig 2). The figure highlights the different scaling regimes of the excess risk and the crossover points between them. The left panel shows a smaller \u03b1 and r<1/2 while the right panel show a larger \u03b1 and r\u22651/2.", "section": "Scaling laws"}, {"figure_path": "FBLJIfW64D/figures/figures_46_1.jpg", "caption": "Figure 1: Excess risk eq. (6) of RFRR as a function of the number of features p for a fixed number of samples n. Solid lines are obtained from the deterministic equivalent in Theorem 3.3, and points are numerical simulations, with the different curves denoting different regularization strengths \u03bb \u2265 0. (Left) Training data (xi, Yi)i\u2208[n], n = 500, sampled from a teacher-student model yi = erf((\u03b2, xi)) + \u03b5i, \u03c3\u00b2 = 0.1, xi ~i.i.d. N(0, Id), with a spiked random feature map \u03c6(x, w) = tanh((w + uv, x)) where v \u2208 Rd has a fixed overlap \u03b3 = (\u03c5, \u03b2) with the teacher vector, w ~ N(0, d\u2212\u00b9Id), u ~ N(0, 1). (Right) Training data (xi, Yi)i\u2208[n], n = 300, sub-sampled from the FashionMNIST data set [Xiao et al., 2017], with feature map given by \u03c6(x; w) = erf((w, x)) and \u03bc\u03c9 = N(0, d\u2212\u00b9Ia).", "description": "The figure shows the excess risk of random feature ridge regression (RFRR) as a function of the number of features (p) for a fixed number of samples (n).  The solid lines represent the theoretical predictions from a deterministic equivalent derived in the paper, while the points are from numerical simulations. Different lines represent different regularization strengths (\u03bb). The left panel uses synthetic data generated by a teacher-student model with a spiked random feature map, while the right panel uses real data from the FashionMNIST dataset.  The figure empirically validates the accuracy of the theoretical approximation.", "section": "3 Deterministic equivalents"}, {"figure_path": "FBLJIfW64D/figures/figures_48_1.jpg", "caption": "Figure 1: Excess risk eq. (6) of RFRR as a function of the number of features p for a fixed number of samples n. Solid lines are obtained from the deterministic equivalent in Theorem 3.3, and points are numerical simulations, with the different curves denoting different regularization strengths \u03bb \u2265 0. (Left) Training data (xi, Yi)i\u2208[n], n = 500, sampled from a teacher-student model yi = erf((\u03b2, xi)) + \u03b5i, \u03c3\u00b2 = 0.1, xi ~i.i.d. N(0, Id), with a spiked random feature map \u03c6(x, w) = tanh((w + uv, x)) where v \u2208 Rd has a fixed overlap \u03b3 = (\u03c5, \u03b2) with the teacher vector, w ~ N(0, d\u207b\u00b9Id), u ~ N(0, 1). (Right) Training data (xi, Yi)i\u2208[n], n = 300, sub-sampled from the FashionMNIST data set [Xiao et al., 2017], with feature map given by \u03c6(x; w) = erf((w, x)) and \u03bc\u03c9 = N(0, d\u207b\u00b9Ia).", "description": "The figure shows the excess risk of random feature ridge regression (RFRR) as a function of the number of features (p) for a fixed number of samples (n).  It compares theoretical predictions (solid lines) derived from a deterministic equivalent (Theorem 3.3) with numerical simulations (points). Different curves represent different regularization strengths (\u03bb). The left panel displays results for a teacher-student model with a spiked random feature map, while the right panel uses data from the FashionMNIST dataset with a different feature map.", "section": "3 Deterministic equivalents"}, {"figure_path": "FBLJIfW64D/figures/figures_48_2.jpg", "caption": "Figure 1: Excess risk eq. (6) of RFRR as a function of the number of features p for a fixed number of samples n. Solid lines are obtained from the deterministic equivalent in Theorem 3.3, and points are numerical simulations, with the different curves denoting different regularization strengths \u03bb \u2265 0. (Left) Training data (xi, yi)i\u2208[n], n = 500, sampled from a teacher-student model yi = erf((\u03b2, xi)) + \u03b5i, \u03c3\u00b2 = 0.1, xi ~i.i.d. N(0, Id), with a spiked random feature map \u03c6(x, w) = tanh((w + uv, x)) where v \u2208 Rd has a fixed overlap \u03b3 = (\u03c5, \u03b2) with the teacher vector, w ~ N(0, d\u207b\u00b9Id), u ~ N(0, 1). (Right) Training data (xi, yi)i\u2208[n], n = 300, sub-sampled from the FashionMNIST data set [Xiao et al., 2017], with feature map given by \u03c6(x; w) = erf((w, x)) and \u03bc\u03c9 = N(0, d\u207b\u00b9Ia).", "description": "This figure displays the excess risk of random feature ridge regression (RFRR) as a function of the number of features (p) for a fixed number of samples (n).  The solid lines represent the theoretical predictions from the deterministic equivalent derived in the paper (Theorem 3.3), while the points show the results of numerical simulations.  Different colors represent different regularization strengths (\u03bb). The left panel uses synthetic data generated from a teacher-student model with a spiked random feature map, while the right panel uses real data from the FashionMNIST dataset.", "section": "3 Deterministic equivalents"}, {"figure_path": "FBLJIfW64D/figures/figures_49_1.jpg", "caption": "Figure 7: (Left) Excess risk eq. (6) of random features ridge regression. Solid lines are obtained from the deterministic equivalent in Theorem 3.3, and points are numerical simulations, with the different curves denoting different regularization strengths \u03bb \u2265 0. Training data (xi, yi)i\u2208[n], n = 300, sub-sampled from the MNIST data set Lecun et al. [1998], with feature map given by \u03c6(x, w) = erf((w,x)) and \u03bc\u03c9 = N(0,d\u207b\u00b9Ia). (Right) Excess risk eq. (6) of random features ridge regression. Solid lines are obtained from the deterministic equivalent in Theorem 3.3, and points are numerical simulations, with the different curves denoting different number of total iterations of gradient descent on the weight of the first layer with learning rate \u03b7 = 10\u207b\u00b2, before training the second layer with regularization strength \u03bb = 10\u207b\u2074 (details in Appendix C.5). Zero iterations correspond to random feature regression (RF). Training data (xi, yi)i\u2208[n], sampled from a teacher-student model yi = \u3008\u03b2, xi\u3009, with random feature map \u03c6(x, w) = ReLU((w,x)) and p = 8000 fixed. Both covariates {x} and initialization weights {wi} are uniformly sampled from the d-dimensional spheres respectively with radius \u221ad and 1.", "description": "This figure compares the excess risk of random feature ridge regression obtained from simulations and the deterministic equivalent derived in the paper. The left panel shows the results for MNIST data with different regularization strengths, while the right panel demonstrates the impact of gradient descent iterations on the model's performance using a teacher-student model.", "section": "Particular limits"}, {"figure_path": "FBLJIfW64D/figures/figures_49_2.jpg", "caption": "Figure 1: Excess risk eq. (6) of RFRR as a function of the number of features p for a fixed number of samples n. Solid lines are obtained from the deterministic equivalent in Theorem 3.3, and points are numerical simulations, with the different curves denoting different regularization strengths \u03bb \u2265 0. (Left) Training data (xi, Yi)i\u2208[n], n = 500, sampled from a teacher-student model yi = erf((\u03b2, xi)) + \u03b5i, \u03c3\u00b2 = 0.1, xi ~i.i.d. N(0, Id), with a spiked random feature map \u03c6(x, w) = tanh((w + uv, x)) where v \u2208 Rd has a fixed overlap \u03b3 = (\u03c5, \u03b2) with the teacher vector, w ~ N(0, d\u207b\u00b9Id), u ~ N(0, 1). (Right) Training data (xi, Yi)i\u2208[n], n = 300, sub-sampled from the FashionMNIST data set [Xiao et al., 2017], with feature map given by \u03c6(x; w) = erf((w, x)) and \u03bc\u03c9 = N(0, d\u207b\u00b9Ia).", "description": "The figure shows the excess risk of random feature ridge regression (RFRR) as a function of the number of features (p) for a fixed number of samples (n).  It compares theoretical predictions (solid lines) derived from a deterministic equivalent (Theorem 3.3) to numerical simulations (points).  Different curves represent different regularization strengths (\u03bb). The left panel uses synthetic data from a teacher-student model, while the right panel uses real data from the Fashion-MNIST dataset.", "section": "3 Deterministic equivalents"}, {"figure_path": "FBLJIfW64D/figures/figures_52_1.jpg", "caption": "Figure 9: Excess risk eq. (6) of random features ridge regression as a function of the number of samples n under source and capacity conditions eq. (37) and power-law assumptions \u03bb = n\u2212(l\u22121), p = nq, with noise variance \u03c3\u00b2 = 1, obtained from the deterministic equivalent Theorem 3.3. Dashed and dotted lines are the analytical rates from Theorem 4.1, stated in the legend. The colour scheme is the following: variance dominated region: orange and brown for the slow decay regime; cyan for the bias dominated region; shades of green for the optimal decay (red lines in Fig. 2 (right). In particular we show: (left) the crossover between the orange and teal regions in Fig. 2 at fixed regularization and r < 1/2; (right) the optimal decay rate along the horizontal red line line in Fig. 2 at q = q* and r < 1/2, for any \u03bb < \u03bb*, included the non regularized case.", "description": "This figure shows the excess risk of random feature ridge regression as a function of the number of samples (n) under specific source and capacity conditions.  The plots illustrate the theoretical predictions (solid lines) from Theorem 3.3 and numerical simulations (points). Different lines represent different regularization strengths (\u03bb) and numbers of features (p), which are scaled relative to n. The plots also show the theoretical decay rates of the bias and variance terms, and highlight the different scaling regimes (variance-dominated, bias-dominated) and the optimal decay rate. The left subplot displays the crossover between different regimes while the right one shows the optimal decay rate.", "section": "Scaling laws"}]