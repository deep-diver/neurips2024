{"references": [{"fullname_first_author": "P. Massart", "paper_title": "Risk bounds for statistical learning", "publication_date": "2006-10-01", "reason": "This paper provides the foundational risk bounds for learning with Massart noise, which are essential to understanding the sample complexity in the problem studied."}, {"fullname_first_author": "I. Diakonikolas", "paper_title": "Distribution-independent PAC learning of halfspaces with Massart noise", "publication_date": "2019-12-01", "reason": "This paper is the first to provide a computationally efficient algorithm for learning halfspaces in the presence of Massart noise, setting the stage for further improvements."}, {"fullname_first_author": "S. Chen", "paper_title": "Classification under misspecification: Halfspaces, generalized linear models, and connections to evolvability", "publication_date": "2020-12-01", "reason": "This paper improves upon the sample complexity of learning halfspaces with Massart noise, providing a benchmark for the current work's near-optimal result."}, {"fullname_first_author": "I. Diakonikolas", "paper_title": "Information-computation tradeoffs for learning margin halfspaces with random classification noise", "publication_date": "2023-06-01", "reason": "This paper establishes lower bounds on the sample complexity of learning halfspaces with Massart noise, highlighting the optimality of the algorithm presented in this paper."}, {"fullname_first_author": "I. Diakonikolas", "paper_title": "Near-optimal bounds for learning gaussian halfspaces with random classification noise", "publication_date": "2023-12-01", "reason": "This paper further strengthens the lower bounds results, providing additional context and justification for the near-optimality of the algorithm presented."}]}