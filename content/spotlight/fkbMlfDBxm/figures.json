[{"figure_path": "fkbMlfDBxm/figures/figures_1_1.jpg", "caption": "Figure 1: Motivation of the proposed REMA. (a) Ideally, by partitioning the latent factors into common and specific parts, aligning the common factors directly enables perfect matching of two different distributions. (b) Since the latent features learned by deep networks are typically dense and continuous, most well-performing methods seek direct alignment without exploring the inherent structures. (c) Our REMA introduces a sparse and discrete element \u2013 slot [51] \u2013 to serve as a bridge for both reconstruction and relational modeling, avoiding explicit disentanglement in the latent space.", "description": "This figure illustrates the motivation behind the proposed REMA framework by comparing it to ideal and popular approaches for OOD generalization.  (a) shows the ideal scenario where latent factors are perfectly disentangled into common and specific parts, allowing for easy alignment between different distributions. (b) depicts the limitations of existing methods which often work with dense, continuous latent features and directly attempt alignment without considering underlying structures. (c) highlights REMA's novel approach, leveraging sparse, discrete 'slots' to represent object components, facilitating both reconstruction and relational modeling to achieve better OOD robustness.", "section": "1 Introduction"}, {"figure_path": "fkbMlfDBxm/figures/figures_2_1.jpg", "caption": "Figure 2: Overview of the proposed REMA, which consists of two key modules, i.e., SSR and HORR. (1) Abstraction: Slot-based reconstruction to discover the main components from the data by binding objects with a set of discrete vectors; (2) Reasoning: Introduce high-order relational inductive bias (i.e., topological homogeneity) to the network via the process of hypergraph construction, learning, and matching. HGNN means hypergraph neural networks.", "description": "This figure illustrates the Reconstruct and Match (REMA) framework, which is the core methodology of the paper.  It shows the two main modules: Selective Slot-based Reconstruction (SSR) and High-Order Relational Reasoning (HORR).  SSR extracts key components (slots) from the input image. HORR then models the relationships between these components using a hypergraph to capture high-order dependencies, achieving topological homogeneity. The figure depicts the data flow, showing the input image, feature extraction, slot attention, slot selection, reconstruction, and hypergraph reasoning steps. The final output is a representation that integrates both low and high-order relationships between the image components for object recognition.", "section": "3 Proposed Method"}, {"figure_path": "fkbMlfDBxm/figures/figures_4_1.jpg", "caption": "Figure 2: Overview of the proposed REMA, which consists of two key modules, i.e., SSR and HORR. (1) Abstraction: Slot-based reconstruction to discover the main components from the data by binding objects with a set of discrete vectors; (2) Reasoning: Introduce high-order relational inductive bias (i.e., topological homogeneity) to the network via the process of hypergraph construction, learning, and matching. HGNN means hypergraph neural networks.", "description": "This figure presents an overview of the Reconstruct and Match (REMA) framework, highlighting its two main modules: Selective Slot-based Reconstruction (SSR) and High-Order Relational Reasoning (HORR).  SSR is depicted as taking dense image pixels and converting them into a sparse set of slot vectors that represent the main components of an object. HORR then takes these slots and creates a hypergraph to model the high-order relationships between these components (slots), aiming to capture the topological homogeneity of the objects. The hypergraph is processed using a Hypergraph Neural Network (HGNN) before generating a final result.", "section": "3 Proposed Method"}, {"figure_path": "fkbMlfDBxm/figures/figures_6_1.jpg", "caption": "Figure 3: Generalizing from CIFAR-10 to CIFAR-10C using ERM and our REMA.", "description": "This figure compares the performance of ERM and REMA on CIFAR-10C, a dataset with various image corruptions, using the CIFAR-10 dataset as the source domain.  It visually demonstrates the improved robustness and generalization capabilities of the proposed REMA model compared to the standard ERM approach across different types of image corruptions. Each bar represents a specific type of corruption (e.g., Gaussian Noise, Shot Noise, etc.) and the height of each bar indicates the accuracy achieved by each method on that corruption type. REMA consistently shows higher accuracy across all corruption types, highlighting its effectiveness in handling out-of-distribution data.", "section": "4.2 Main Results"}, {"figure_path": "fkbMlfDBxm/figures/figures_7_1.jpg", "caption": "Figure 4: (a) Visualization. (b) Analysis on continuous test-time adaptation.", "description": "The figure shows two parts. (a) Grad-CAM Visualization: It visualizes the attention weights of the REMA model, highlighting the regions of the image that are most relevant to the prediction. It shows how REMA focuses on different parts of the object, enabling it to improve the overall performance. (b) Adaptation Order: It shows how the average accuracy of different test-time adaptation methods changes as the number of adaptation steps increases. It shows how REMA consistently outperforms other methods.", "section": "4.2 Main Results"}, {"figure_path": "fkbMlfDBxm/figures/figures_7_2.jpg", "caption": "Figure 5: Learned affinity vs. GT", "description": "This figure visualizes the learned affinity matrix and the ground truth (GT) matrix. The learned affinity matrix is produced by the hypergraph matching module of REMA, which models high-order topological relations. The visualization helps assess the model's ability to accurately capture the structural similarities between objects across different domains.  The top row shows the predicted affinity, while the bottom row shows the ground truth. The dark and bright colors represent low and high affinity values, respectively. Ideally, the learned affinity matrix should closely resemble the GT matrix, indicating effective matching.", "section": "3.2 High-Order Relational Reasoning (HORR)"}, {"figure_path": "fkbMlfDBxm/figures/figures_8_1.jpg", "caption": "Figure 6: Feature visualization of different methods using t-SNE.", "description": "This figure visualizes the feature embeddings obtained by different methods, namely ERM, REMA without SSR, REMA without HORR, and the full REMA model.  The visualization uses t-SNE to project the high-dimensional feature embeddings into a 2D space, allowing for visualization of the data clustering.  Different colors represent different classes in the CIFAR-10C dataset with snow corruption.  The figure demonstrates how the proposed REMA model, with both SSR and HORR modules, leads to better-clustered feature embeddings compared to the baselines. The absence of either SSR or HORR leads to reduced data separability.", "section": "5 Related Work"}]