[{"figure_path": "kQMyiDWbOG/tables/tables_6_1.jpg", "caption": "Table 1: Experimental results of time-series forecasting on 4 benchmarks with various prediction lengths 6, 24, 48, 96. \u201cPE\u201d stands for positional encoding. \u201cw/o\u201d denotes \u201cwithout\u201d while \u201cw/\u201d denotes \u201cwith\u201d. The best results of SNNs are formatted in bold font format. \u2191 (\u2193) indicates the higher (lower) the better. Shaded ones are ours. All results are averaged across 3 random seeds.", "description": "This table presents the results of time series forecasting experiments using various models (ANNs and SNNs with and without positional encoding).  It shows the R-squared (R2) and Root Relative Squared Error (RSE) values for different prediction lengths (6, 24, 48, 96 time steps) across four benchmark datasets (Metr-la, Pems-bay, Solar, Electricity).  The best performing SNN models for each dataset and prediction length are highlighted in bold. The table helps compare the performance of SNNs using CPG-PE (the proposed method) against other SNNs and their corresponding ANN counterparts.", "section": "4.2 Time-Series Forecasting"}, {"figure_path": "kQMyiDWbOG/tables/tables_6_2.jpg", "caption": "Table 2: Accuracy on 6 text classification benchmarks. The best results of SNNs and ANNs are formatted in bold font format. Experimental results are averaged across 5 random seeds.", "description": "This table presents the accuracy results achieved by various Spiking Neural Network (SNN) models and a fine-tuned BERT model on six different text classification benchmark datasets.  The table compares the performance of Spikformer models with different positional encoding methods (no positional encoding, random positional encoding, float positional encoding, and CPG-PE). The results show that the Spikformer model with CPG-PE achieves the best accuracy, surpassing other SNN models and approaching the performance of the BERT model. The results are averaged across five random seeds, showcasing the consistency of CPG-PE's effectiveness.", "section": "4.3 Text Classification"}, {"figure_path": "kQMyiDWbOG/tables/tables_7_1.jpg", "caption": "Table 3: Evaluation on image classification benchmarks. Float-PE denotes the original PE of the Transformer, while RPE denotes the original PE of the Spikformer. Numbers with * denote our implementation. The best results of SNNs and ANNs are formatted in bold font format. All results are averaged across 4 random seeds.", "description": "This table presents the results of image classification experiments conducted on three benchmark datasets: CIFAR10, CIFAR10-DVS, and CIFAR100.  It compares the performance of various Spikformer models with different positional encoding methods (no positional encoding, random positional encoding, float PE, RPE, and the proposed CPG-PE).  The table shows the number of parameters for each model and its accuracy on each dataset. The best performing models are highlighted.", "section": "4.4 Image Classification"}, {"figure_path": "kQMyiDWbOG/tables/tables_13_1.jpg", "caption": "Table 1: Experimental results of time-series forecasting on 4 benchmarks with various prediction lengths 6, 24, 48, 96. \u201cPE\u201d stands for positional encoding. \u201cw/o\u201d denotes \u201cwithout\u201d while \u201cw/\u201d denotes \u201cwith\u201d. The best results of SNNs are formatted in bold font format. \u2191 (\u2193) indicates the higher (lower) the better. Shaded ones are ours. All results are averaged across 3 random seeds.", "description": "This table presents the experimental results for time-series forecasting on four benchmark datasets (Metr-la, Pems-bay, Solar, and Electricity) using various prediction lengths (6, 24, 48, 96).  It compares the performance of different Spiking Neural Networks (SNNs) with and without positional encoding (PE), including both conventional ANN-based models for comparison.  The table shows R-squared (R2) and Root Relative Squared Error (RSE) values for each model configuration, indicating the impact of different PE methods on the prediction accuracy. The best results for SNNs are highlighted in bold.", "section": "4.2 Time-Series Forecasting"}, {"figure_path": "kQMyiDWbOG/tables/tables_17_1.jpg", "caption": "Table 5: Evaluation on ImageNet benchmarks. We employed 8 encoder blocks and 384 feature embedding dimensions across all models.", "description": "This table presents the results of image classification experiments conducted on the ImageNet dataset using three different Spikformer models: one without positional encoding, one with relative positional encoding (RPE), and one with the proposed CPG-PE. The table shows the number of parameters (in millions) and the accuracy achieved by each model.  The results demonstrate that the CPG-PE model outperforms the other two models, achieving higher accuracy with a comparable number of parameters. This highlights the effectiveness of the CPG-PE method for image classification tasks.", "section": "4.4 Image Classification"}]