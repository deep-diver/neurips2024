[{"figure_path": "VNBIF0gmkb/tables/tables_6_1.jpg", "caption": "Table 1: Diffusion Loss vs. Cross-entropy Loss. The tokenizers are VQ-16 (discrete) and KL-16 (continuous), both from the LDM codebase [42] for fair comparisons. Diffusion Loss, with continuous-valued tokens, is better than its cross-entropy counterpart with discrete-valued tokens, consistently observed across all variants of AR and MAR. All entries are implemented by us under the same setting: AR/MAR-L (~400M parameters), 400 epochs, ImageNet 256\u00d7256.", "description": "This table compares the performance of using Diffusion Loss with continuous tokens against Cross-entropy Loss with discrete tokens for various autoregressive (AR) and masked autoregressive (MAR) models.  It shows that Diffusion Loss consistently outperforms Cross-entropy Loss across different model configurations, highlighting the benefits of using continuous tokens.", "section": "5.1 Properties of Diffusion Loss"}, {"figure_path": "VNBIF0gmkb/tables/tables_6_2.jpg", "caption": "Table 2: Flexibility of Diffusion Loss. Diffusion Loss can support different types of tokenizers. (i) VQ tokenizers: we treat the continuous-valued latent before VQ as the tokens. (ii) Tokenizers with a mismatched stride (here, 8): we group 2\u00d72 tokens into a new token for sequence modeling. (iii) Consistency Decoder [35], a non-VQ tokenizer of a different decoder architecture. Here, rFID denotes the reconstruction FID of the tokenizer on the ImageNet training set. Settings in this table for all entries: MAR-L, 400 epochs, ImageNet 256\u00d7256. \u2020: This tokenizer is trained by us on ImageNet using [42]'s code; the original ones from [42] were trained on OpenImages.", "description": "This table demonstrates the flexibility of the proposed Diffusion Loss by showcasing its compatibility with various tokenizers, including VQ tokenizers, tokenizers with mismatched strides, and non-VQ tokenizers.  It compares the performance (FID and IS scores) across different tokenizer types on the ImageNet dataset, highlighting the robustness and adaptability of the Diffusion Loss.", "section": "5.1 Properties of Diffusion Loss"}, {"figure_path": "VNBIF0gmkb/tables/tables_8_1.jpg", "caption": "Table 1: Diffusion Loss vs. Cross-entropy Loss. The tokenizers are VQ-16 (discrete) and KL-16 (continuous), both from the LDM codebase [42] for fair comparisons. Diffusion Loss, with continuous-valued tokens, is better than its cross-entropy counterpart with discrete-valued tokens, consistently observed across all variants of AR and MAR. All entries are implemented by us under the same setting: AR/MAR-L (~400M parameters), 400 epochs, ImageNet 256\u00d7256.", "description": "This table compares the performance of using Diffusion Loss with continuous-valued tokens against the standard cross-entropy loss with discrete-valued tokens.  The comparison is performed across various autoregressive (AR) and masked autoregressive (MAR) model configurations, using the same hyperparameters and dataset (ImageNet 256x256). The results show that Diffusion Loss consistently outperforms cross-entropy loss, highlighting the benefits of using continuous tokens.", "section": "5.1 Properties of Diffusion Loss"}, {"figure_path": "VNBIF0gmkb/tables/tables_14_1.jpg", "caption": "Table 2: Flexibility of Diffusion Loss. Diffusion Loss can support different types of tokenizers. (i) VQ tokenizers: we treat the continuous-valued latent before VQ as the tokens. (ii) Tokenizers with a mismatched stride (here, 8): we group 2\u00d72 tokens into a new token for sequence modeling. (iii) Consistency Decoder [35], a non-VQ tokenizer of a different decoder architecture. Here, rFID denotes the reconstruction FID of the tokenizer on the ImageNet training set. Settings in this table for all entries: MAR-L, 400 epochs, ImageNet 256\u00d7256. \u2020: This tokenizer is trained by us on ImageNet using [42]'s code; the original ones from [42] were trained on OpenImages.", "description": "This table demonstrates the flexibility of the proposed Diffusion Loss by showing its effectiveness with various types of tokenizers, including VQ tokenizers, tokenizers with mismatched strides, and a non-VQ tokenizer called Consistency Decoder.  The results highlight that Diffusion Loss is not limited to specific types of tokenizers and can adapt to different scenarios, providing consistent performance gains.", "section": "5.1 Properties of Diffusion Loss"}, {"figure_path": "VNBIF0gmkb/tables/tables_15_1.jpg", "caption": "Table 1: Diffusion Loss vs. Cross-entropy Loss. The tokenizers are VQ-16 (discrete) and KL-16 (continuous), both from the LDM codebase [42] for fair comparisons. Diffusion Loss, with continuous-valued tokens, is better than its cross-entropy counterpart with discrete-valued tokens, consistently observed across all variants of AR and MAR. All entries are implemented by us under the same setting: AR/MAR-L (~400M parameters), 400 epochs, ImageNet 256\u00d7256.", "description": "This table compares the performance of the proposed Diffusion Loss with the traditional cross-entropy loss using different autoregressive (AR) and masked autoregressive (MAR) models.  Two types of tokenizers, VQ-16 (discrete) and KL-16 (continuous), are used for a fair comparison. The results show that Diffusion Loss consistently outperforms cross-entropy loss across various model configurations, highlighting its effectiveness in image generation.", "section": "5.1 Properties of Diffusion Loss"}]