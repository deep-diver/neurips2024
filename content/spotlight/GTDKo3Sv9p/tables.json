[{"figure_path": "GTDKo3Sv9p/tables/tables_3_1.jpg", "caption": "Table 1: Generating (marginal) velocity fields have identical form for the continuous and discrete Flow Matching when using denoiser/noise-prediction parameterization; x1\n\n\n\n\n\n\nt(z) = EX\u2081~pt(\u00b7|z) X1 is the standard continuous denoiser (a.k.a. x-prediction) and 20t(z) = EX0~pt(:\nz)X0 is the standard noise-prediction (a.k.a. \u03b5-prediction).", "description": "This table compares the formulas for generating velocity fields in continuous and discrete Flow Matching.  It shows that the formulas are identical when using denoiser/noise-prediction parameterization.  The table highlights the use of x-prediction (denoiser) and \u03b5-prediction (noise-prediction) and how they relate to the marginal probability and conditional probability within both continuous and discrete frameworks.", "section": "2.4 Generating Probability Velocities"}, {"figure_path": "GTDKo3Sv9p/tables/tables_5_1.jpg", "caption": "Table 1: Generating (marginal) velocity fields have identical form for the continuous and discrete Flow Matching when using denoiser/noise-prediction parameterization; x1\n\\t(z) = EX\u2081~pt(\u00b7|z) X\u2081 is the standard continuous denoiser (a.k.a. x-prediction) and x\u2080\\t(z) = EX\u2080~pt(\u00b7|z)X\u2080 is the standard noise-prediction (a.k.a. e-prediction).", "description": "This table compares the formulas for generating velocity fields in both continuous and discrete Flow Matching. It highlights that the formulas are remarkably similar when using denoiser/noise-prediction parameterization.  The table shows the marginal probability, conditional probability, velocity field formulas using denoiser and noise prediction for both continuous and discrete settings.", "section": "2.4 Generating Probability Velocities"}, {"figure_path": "GTDKo3Sv9p/tables/tables_7_1.jpg", "caption": "Table 2: Generative perplexity on unconditional text generation compared to prior work. All models are sampled without the use of temperature or corrector steps. Double precision sampling results are reported in Table 5.", "description": "This table compares the generative perplexity of various language models on unconditional text generation.  It shows the performance of the proposed Discrete Flow Matching (FM) models against several autoregressive and other non-autoregressive baselines.  The metrics include perplexity scores calculated using Llama-2, Llama-3, and GPT-2, as well as entropy, which reflects token diversity.  The number of function evaluations (NFE) is also indicated for each model, representing the computational cost. Note that results for double precision sampling are presented in a separate table (Table 5).", "section": "4.1 Language modeling"}, {"figure_path": "GTDKo3Sv9p/tables/tables_7_2.jpg", "caption": "Table 3: Generative perplexity on conditional text generation.", "description": "This table compares the generative perplexity of different language models on conditional text generation tasks.  It shows the performance of Llama-2 and Llama-3 (used as references), an autoregressive model, and the Discrete Flow Matching (FM) model with both unconditional (U-coupling) and conditional (C-coupling) strategies.  The results are presented for different model sizes and numbers of function evaluations (NFEs).  Lower perplexity scores indicate better performance.", "section": "4.1 Language modeling"}, {"figure_path": "GTDKo3Sv9p/tables/tables_8_1.jpg", "caption": "Table 4: Execution based code generation evaluation.", "description": "This table presents the results of code generation experiments on HumanEval and MBPP benchmarks.  It compares the performance of an autoregressive model against the Discrete Flow Matching (FM) model proposed in the paper. The evaluation metrics are Pass@k (percentage of correctly generated codes within k attempts). The table is broken down by data type (text and code), and the FM results are further separated into results with and without oracle length (i.e., with or without knowledge of the correct code length).  Higher Pass@k values indicate better performance.", "section": "4.1 Language modeling"}, {"figure_path": "GTDKo3Sv9p/tables/tables_26_1.jpg", "caption": "Table 2: Generative perplexity on unconditional text generation compared to prior work. All models are sampled without the use of temperature or corrector steps. Double precision sampling results are reported in Table 5.", "description": "This table compares the generative perplexity of various language models on unconditional text generation tasks.  The models include both autoregressive and non-autoregressive approaches.  The perplexity is measured using different evaluation models (LLAMA-2, LLAMA-3, GPT2), and the number of function evaluations (NFE) is also reported. Note that temperature and corrector steps are not used during sampling for these results.  A more detailed comparison including double precision sampling is available in Table 5.", "section": "4.1 Language modeling"}]