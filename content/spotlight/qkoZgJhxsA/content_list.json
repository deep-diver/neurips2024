[{"type": "text", "text": "SocraticLM: Exploring Socratic Personalized Teaching with Large Language Models ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Jiayu Liu1,2 Zhenya Huang1,2\u2217 Tong Xiao1,2 Jing Sha2 Jinze Wu2 Qi Liu1,2 Shijin Wang2 Enhong Chen1,2\u2217 ", "page_idx": 0}, {"type": "text", "text": "1: University of Science and Technology of China 2: State Key Laboratory of Cognitive Intelligence {jy251198,tongxiao2002}@mail.ustc.edu.cn; {huangzhy,qiliuql,cheneh}@ustc.edu.cn; {jingsha,jzwu4,sjwang3}@ifytek.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Large language models (LLMs) are considered a crucial technology for advancing intelligent education since they exhibit the potential for an in-depth understanding of teaching scenarios and providing students with personalized guidance. Nonetheless, current LLM-based application in personalized teaching predominantly follows a \u201cQuestion-Answering\u201d paradigm, where students are passively provided with answers and explanations. In this paper, we propose SocraticLM, which achieves a Socratic \u201cThought-Provoking\u201d teaching paradigm that fulfills the role of a real classroom teacher in actively engaging students in the thought process required for genuine problem-solving mastery. To build SocraticLM, we first propose a novel \u201cDean-Teacher-Student\u201d multi-agent pipeline to construct a new dataset, SocraTeach, which contains 35K meticulously crafted Socratic-style multi-round (equivalent to 208K single-round) teaching dialogues grounded in fundamental mathematical problems. Our dataset simulates authentic teaching scenarios, interacting with six representative types of simulated students with different cognitive states, and strengthening four crucial teaching abilities. SocraticLM is then fine-tuned on SocraTeach with three strategies balancing its teaching and reasoning abilities. Moreover, we contribute a comprehensive evaluation system encompassing five pedagogical dimensions for assessing the teaching quality of LLMs. Extensive experiments verify that SocraticLM achieves significant improvements in the teaching performance, outperforming GPT4 by more than $12\\%$ . Our dataset and code is available at https://github.com/Ljyustc/SocraticLM. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Large language models (LLMs) have achieved impressive results across a variety of tasks including natural language processing, translation, and question-answering [54, 56, 59]. This draws widespread attention to the potential of using LLMs to revolutionize intelligent education, especially personalized teaching [2, 23, 39], mainly due to their two advantages. On one hand, LLMs have displayed humanlike mastery and proficiency of knowledge in fundamental subjects like math and physics [1, 48]. Therefore, they can effectively deliver subject-specific instructions to students like a real teacher. On the other hand, LLMs exhibit exceptional understanding and adaptability to users\u2019 (i.e., students\u2019) inputs. They are capable of comprehending diverse students\u2019 demands, providing instant feedback, and engaging in interactive pedagogy. Based on these two aspects, there has been a lot of research investigating to apply a general LLM (e.g., ChatGPT) to personalized teaching [5, 18, 44, 51], or building specific teaching LLMs, such as MathGPT 2, EduGPT 3, and EduChat [10]. ", "page_idx": 0}, {"type": "image", "img_path": "qkoZgJhxsA/tmp/e5a5502be72f8115f0799b044148d36a07c1899bdd26868fec398c271dc7130b.jpg", "img_caption": ["Figure 1: Teaching paradigms: \u201cQuestion-Answering\u201d vs \u201cThought-Provoking\u201d. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "However, current LLMs-based personalized teaching methods predominantly adhere to a \u201cQuestionAnswering\u201d paradigm. As shown in Figure 1(a), they passively offer functionalities such as providing answers to questions and explaining knowledge concepts to students\u2019 queries. In this process, they oversimplify the teaching into a series of Q&As, directly delivering complete answers based on CoT [56], ToT [57], etc., which falls short of truly identifying the issues students may have and offering targeted assistance. Consequently, students may struggle to comprehend the problem-solving process, lack a genuine improvement in their ability, and fail to resolve similar issues in the future. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we draw inspiration from the Socratic method of teaching [13, 45] and propose SocraticLM, which achieves a novel \u201cThought-Provoking\u201d teaching paradigm as depicted in Figure 1(b). The key of this paradigm is to engage students in a dialogue to active participation in the learning process, which continually poses open-ended questions (marked red, e.g., \u201c... how to calculate it?\u201d) to encourage them to articulate their thoughts, challenge assumptions, and think independently. This process enables students to learn to solve a problem by themselves, thereby fostering a deeper mastery and ability. Compared with LLM-based applications using prompt engineering directly (e.g., GPT4), we aim to systematically study 1) The pedagogical demands of \u201cThought-Provoking\u201d teaching and empower SocraticLM to fulfill these demands. 2) The teaching abilities of teachers and reinforce these abilities in SocraticLM. 3) The cognitive states of students and enable SocraticLM to accurately identify them during the teaching process. Consequently, our SocraticLM can provide higher quality guidance that is more tailored and appropriate for each student\u2019s needs, transitioning from a \u201cguardian of knowledge\u201d to \u201cchoreographer of learning\u201d. ", "page_idx": 1}, {"type": "text", "text": "To build SocraticLM, we first construct a new dataset, SocraTeach, which consists of 35K high-quality, fine-grained Socratic-style multi-round teaching dialogues grounded in mathematical problems. In constructing the dataset, we propose a novel \u201cDean-Teacher-Student\u201d pipeline, implementing three LLM agents to simulate the key roles in authentic teaching scenarios: Dean, Teacher, and Student. The Dean is a director that oversees and refines the Teacher\u2019s instructions before they are presented to the Student, ensuring that the whole teaching process adheres to the Socratic style. The Teacher actively and gradually guides the Student to solve a problem by generating Socratic instructions, inspired by classic pedagogical theories [13, 45]. The Student responds to the Teacher\u2019s instructions, where we establish a student cognitive state system that simulates six kinds of students in classroom to cover real and diverse teaching scenarios. Through multiple rounds of \u201cTeacher-Student\u201d interaction under the supervision of Dean, a comprehensive Socratic teaching dialogue is formed. One step further, to enhance the diversity and robustness of our dataset, we summarize four types of student responses from real teaching scenarios and perform data augmentation to generate extra 22K single-round teaching dialogues, specifically tailored to enhance four corresponding crucial teaching abilities. ", "page_idx": 1}, {"type": "text", "text": "We fine-tune ChatGLM3-6b [12] on our SocraTeach dataset to obtain SocraticLM. During this process, we elaborate three training strategies to improve the pedagogical abilities while ensuring the problem-solving capacity of SocraticLM simultaneously. In addition, we contribute a novel evaluation system encompassing five pedagogical dimensions for assessing the teaching quality of LLMs, which to the best of our knowledge, is the first exploration in this field. Experimental results show that our dataset can enhance the pedagogical performances of LLMs and the teaching quality of our SocraticLM surpasses GPT4 by more than $12\\%$ . ", "page_idx": 2}, {"type": "text", "text": "The contributions of this paper are: ", "page_idx": 2}, {"type": "text", "text": "\u2022 We present SocraticLM, a language model that achieves Socratic \u201cThought-Provoking\u201d teaching paradigm. Experimental results show that its Socratic teaching quality exceeds GPT4 by $12\\%$ , while maintaining the good problem-solving ability of the original ChatGLM3-6b. \u2022 We construct a new dataset SocraTeach that contains massive, fine-grained Socratic teaching dialogues. To construct SocraTeach, we propose a novel \u201cDean-Teacher-Student\u201d multiagent pipeline, in which we design an innovative supervisory role Dean, a cognitive state system to direct the Student\u2019s behavior, and an enhancement in four teaching abilities for the Teacher. This pipeline is general and can be transferred to the teaching in other subjects. \u2022 We develop a five-dimensional comprehensive evaluation system to assess the teaching quality of LLMs, which to the best of our knowledge, is the first attempt in the field. ", "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "LLMs-enhanced intelligent education. Large language models (LLMs) revolutionize three typical applications of intelligent education, namely automatic generation of educational resources, instant assessment of student learning outcomes, and personalized teaching assistance [26, 29, 42]. For educational resources, there is a tendency to use LLMs to generate textbooks, exercises, etc., based on teaching goals and needs, providing teachers with richer inspiration [4, 16]. For students\u2019 outcomes, LLMs can analyze students\u2019 homework and exams to provide assessments and feedbacks on their learning progress [9]. As for the most concerned personalized teaching in this paper, one line of research uses general LLMs like ChatGPT to provide students with multi-level assistance [44, 51, 58] in multiple disciplines, such as writing [18], programming [5], and medical education [25]. By analyzing students\u2019 learning data and behavioral patterns, these LLMs also have the potential to design unique learning paths to help students learn more effectively [20]. Another line of research is to collect a large amount of teaching instructions to fine-tune large models (e.g., EduChat [10]), giving them targeted teaching capabilities such as problem solving and emotional support. ", "page_idx": 2}, {"type": "text", "text": "Personalized teaching dialogue dataset. Constructing teaching dialogues is the basis for building LLM-based personalized teaching systems. In the literature, early attempts relied on crowd-sourcing (e.g., CIMA [49]) or rules (e.g., AutoTutor [17]) to create authentic dialogues. Subsequently, researchers adopted human-computer collaborative approaches. For instance, QuizBot [46] leveraged semantic similarity algorithms to analyze real students\u2019 responses and provided adaptive question by predefined teaching workflow. However, these methods required substantial manual effort or were constrained by predefined teaching procedures, resulting in limited scalability and difficulty in covering diverse real-world teaching scenarios. Recently, with LLMs demonstrating advantages in synthetic data generation [28], utilizing them to assist in teaching dialogue generation has attracted much attention. However, existing research [51] suggests that GPTs make for a bad teacher, thus current efforts mainly use LLMs to simulate students with different backgrounds [41], personalities [41] and error types [40], followed by human teachers providing explanations. Nevertheless, this process still requires human involvement, resulting in the latest dataset MATHDIAL [40] containing only 3K samples. Besides, these datasets also lack a systematic investigation into Socratic teaching. ", "page_idx": 2}, {"type": "text", "text": "3 The SocraTeach Dataset ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Pedagogical theories point out that there are two basic demands for Socratic teaching [13, 45]: 1) it is fundamentally dialogic, relying on conversations between teachers and students to facilitate learning; 2) it uses probing questions to actively engage students, promoting independent thinking and encouraging them to find answers themselves. In building our SocraTeach dataset to meet these requirements, we face the following challenges. First, for the teacher, there is considerable variability in pedagogical methodologies and presentation styles among teachers. It may be difficult for a model to learn all of them at once, which may result in confusion and errors within the teaching logic. Second, for the student, in real teaching scenarios, students\u2019 cognitive states are intricate and heterogeneous [22, 35]. While some students have strong understanding abilities and sufficient knowledge, there are also a considerable number of students who cannot understand the problem or even lack the essential knowledge. We expect that our dataset should cover all these situations, so that the model can learn to provide different levels of guidance for students with different states. ", "page_idx": 2}, {"type": "image", "img_path": "qkoZgJhxsA/tmp/982f82b706fe40e2b4a4eec52aadae22ddc01655f991395c8755a9592492ca15.jpg", "img_caption": ["Figure 2: Workflow of our SocraTeach dataset construction. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "To solve the above challenges, we construct SocraTeach as follows. First, for each problem that needs to be taught, we decompose a list of step-wise guiding questions (Section 3.1). On this basis, we can control the simulation of teachers by aligning the instructional approach and explanatory style with these questions. Second, we devise an innovative \u201cDean-Teacher-Student\u201d pipeline, implementing three LLM agents including \u201cDean\u201d, \u201cTeacher\u201d, and \u201cStudent\u201d to collect fine-grained multi-round teaching dialogues (Section 3.2). Especially, to align with student profiles in authentic scenarios, we build a cognitive state system to simulate six kinds of students in \u201cStudent\u201d from the aspects of comprehension, calculation, knowledge mastery, etc. (Section 3.3). Finally, to further enhance the diversity and robustness of SocraTeach, we design data augmentation methods to construct additional single-round teaching dialogues for improving four crucial teaching abilities (Section 3.4). ", "page_idx": 3}, {"type": "text", "text": "3.1 Problem Collection & Step-by-Step Guiding Questions ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this paper, we take the teaching of mathematical problems at the primary school level as an example for exploration, because mathematics is a fundamental and critical subject and such problems involve the examination of students\u2019 basic understanding and reasoning abilities [32, 34]. Our problems are sourced from two representative datasets: MAWPS [27] and GSM8K [8], which contain 2.3K and 8.8K problems, respectively. ", "page_idx": 3}, {"type": "text", "text": "To ensure that the expression style and teaching approach are consistent in simulating the teacher role, we decompose each problem into a series of step-by-step guiding questions, such as Q1-Q4 in Figure 2 (please refer to Appendix A for details). It should be noted that to ensure the efficiency and conciseness of teaching, a numerical calculation and a summary of the solution do not count as a step. ", "page_idx": 3}, {"type": "text", "text": "3.2 The Dean-Teacher-Student Pipeline ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To create our SocraTeach dataset that achieves the Socratic \u201cThought-Provoking\u201d teaching paradigm, we propose a novel \u201cDean-Teacher-Student\u201d (DTS) pipeline to collect one-to-one, multi-round, teacher-student dialogues, which consists of three LLM agents: ", "page_idx": 3}, {"type": "text", "text": "\u2022 Dean $\\mathcal{D}$ : Research has indicated that GPTs have inadequacies in understanding students and language expression required to serve as a teacher [51]. To address this issue, we propose a ", "page_idx": 3}, {"type": "text", "text": "Dean agent to serve as an oversight role, which judges whether the Teacher\u2019s instructions meet the requirements of Socratic teaching. If it thinks the instructions do not meet the requirements, it has the authority to revise them before they are presented to the Student. ", "page_idx": 4}, {"type": "text", "text": "\u2022 Teacher $\\tau$ : The Teacher agent actively provokes the Student agent to solve problems in a Socratic style, serving two primary purposes according to Socrates\u2019 educational theory [13, 45]. First, it should prompt the Student to think at the appropriate time with Socratic questions, such as guiding the Student to consider the next step after completing a reasoning step. Second, it needs to provide the Student with explanations of the steps and the involved knowledge points. To maintain a consistent teaching style for a given problem, the Teacher is asked to deliver teaching following the step-by-step questions constructed in Section 3.1. ", "page_idx": 4}, {"type": "text", "text": "\u2022 Student $\\boldsymbol{S}$ : Representing the learner within the dataset, the Student agent generates replies to the Teacher\u2019s instructions (i.e., questions and explanations). To ensure the authenticity and diversity of Student, we build a cognitive state system that describes six kinds of real students in Section 3.3 and set Student to simulate one of them each time it replies. ", "page_idx": 4}, {"type": "text", "text": "In DTS pipeline, each teaching dialogue $\\{(T_{1},S_{1}),(T_{2},S_{2}),\\ldots\\}$ is formed by a cycle of interaction between Teacher and Student under the supervision of Dean, and each agent is simulated with GPT4. Taking Figure 2 as an example, in the first round $\\left(t=1\\right)$ ), the Teacher directly gives the question of the first step (i.e., $\\mathcal{T}_{1}=\\mathbf{Q1}\\mathrm{~}$ ) constructed in Section 3.1 (this process does not need the use of LLMs). Then, the Student selects a state profile (e.g., weak knowledge mastery) from six types of cognitive portraits in Section 3.3 and generates a corresponding response $S_{1}$ based on it (see Appendix B.1 for prompt). After that, at $t=2$ , the Teacher provides instruction $\\mathcal{T}_{2}$ in a Socratic style, in which we design pedagogical demands such as not providing answers but rather following the flow of the step-by-step questions. It should be emphasized that here we set up a different response style for each student profile through examples (Appendix B.2). After the Teacher generates $\\mathcal{T}_{2}$ , the Dean judges (e.g., \u201c... doesn\u2019t meet the teaching criteria\u201d) and revises it (e.g., change \u201ccan you ... 12 times $2?^{\\bullet}$ to \u201chow many ... read today?\u201d), focusing on 1) Whether it conforms to the Socratic style. 2) Whether it clearly points out the mistakes made by the Student. 3) Whether its language style resembles that of a real teacher (Appendix B.3), i.e., $\\bar{\\mathcal{T}_{2}}\\leftarrow D(\\bar{\\mathcal{T}_{2}})$ . The revised response is then sent to the Student, and the next round of dialogue begins. Ultimately, if the Teacher thinks that the teaching process has been completed, it will output an \u201c[END]\u201d token as the ending of its output, indicating to terminate the cycle. It is worth noting that although we focus on teaching mathematical problems in this paper, our DTS pipeline is general and can be extended to problems in other subjects (e.g., physics). ", "page_idx": 4}, {"type": "text", "text": "3.3 Student Cognitive State System ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "To ensure that our dataset covers the real and diverse student status throughout the teaching process, it is necessary to simulate different student cognitive states within the Student agent. However, a systematic and unified definition of these states has not been established in existing research [15]. Some previous studies have concentrated on states that are specific to particular subjects such as math and English [3, 11, 19, 50], while others abstractly define general states based on human cognitive science, such as concentration, working memory, and logical reasoning [14, 47, 53, 33]. Unfortunately, these definitions are either unadaptable to the teaching process or difficult to implement with LLMs. To address this issue, we review the Socratic teaching process from the perspective of students as follows. Initially, a student needs to grasp the meaning of the problem at hand. Then, he/she comprehends the instructions provided by the teachers and utilizes the computational ability and acquired knowledge to execute the instructions. Ultimately, this process fosters an interest in learning and helps to cultivate effective study results. Based on this idea, we summarize five dimensions of cognitive state: ", "page_idx": 4}, {"type": "text", "text": "(1) Problem Understanding: refers to the degree to which students understand the given problem. ", "page_idx": 4}, {"type": "text", "text": "(2) Instruction Understanding: refers to the degree to which students understand and carry out the teacher\u2019s instructions. A student in a good state should easily accomplish these instructions. ", "page_idx": 4}, {"type": "text", "text": "(3) Calculation: refers to the ability to derive mathematical expressions and numbers correctly. ", "page_idx": 4}, {"type": "text", "text": "(4) Knowledge Mastery: refers to the extent to which students have mastered knowledge. ", "page_idx": 4}, {"type": "text", "text": "(5) Thirst for Learning: refers to the students\u2019 desire or inclination to seek and acquire new information, ask questions, and explore possibilities. ", "page_idx": 4}, {"type": "text", "text": "Basically, we can define five types of students who perform poorly on one of the above dimensions.   \nMoreover, we add a sixth type of student who excels at all dimensions. ", "page_idx": 5}, {"type": "text", "text": "3.4 Teaching Ability Enhancement ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The multi-round dialogues constructed by DTS pipeline (denoted as $D i a_{M}$ ) ensure a model to grasp the fundamental Socratic teaching paradigm. However, in $D i a_{M}$ , the Student responds only once to each instruction given by the Teacher and tends to choose simpler student portraits, leading to a lack of simulation for long-tail student responses (as discussed in Appendix D). In this section, to further enhance the diversity and robustness of our dataset, we construct more Student-Teacher single-round dialogues $D i a_{S}$ through data augmentation on $D i a_{M}$ , improving four important teaching abilities. ", "page_idx": 5}, {"type": "text", "text": "Specifically, in real teaching processes, students\u2019 responses can be classified as follows. First, from the macro perspective, the responses can be divided into \u201cIrrelevant\u201d and \u201cRelevant\u201d. \u201cRelevant\u201d refers to responses directly related to the problem or instruction, while \u201cIrrelevant\u201d means that the responses are unrelated to the instructional content, such as asking \u201cHow\u2019s the weather today?\u201d in Figure 2. Second, within the \u201cRelevant\u201d category, it can be further divided into \u201cQuestioning\u201d and \u201cReplying\u201d, which refers to students asking questions to the teacher and answering the teacher\u2019s questions, respectively. Third, \u201cReplying\u201d can be further classified as \u201cIncorrect-reply\u201d and \u201cCorrect-reply\u201d based on whether the students\u2019 responses to the teacher\u2019s question are correct or not. Along this line, students\u2019 responses include four categories: \u201cIrrelevant\u201d, \u201cQuestioning\u201d, \u201cIncorrect-reply\u201d, and \u201cCorrect-reply\u201d. On this basis, there are four key teaching abilities that need targeted enhancement. ", "page_idx": 5}, {"type": "text", "text": "First, for \u201cIrrelevant\u201d responses, we expect a teacher to recognize them and redirect the conversation towards teaching, such as responding \u201cThis question is unrelated to ... Let\u2019s focus on the problem first ...\u201d. To achieve this, we collect 200 genuine student inquiries from MOOCs that are unrelated to teaching and then construct 2, 000 single-round Student-Teacher dialogues by randomly inserting them into $D i a_{M}$ and asking Teacher to refuse answering (please refer to Appendix C for details). ", "page_idx": 5}, {"type": "text", "text": "Second, \u201cQuestioning\u201d corresponds to the most crucial teaching ability, that is, a teacher should provide students with accurate explanations. Regarding it, we randomly sample 2, 000 Teacher-Student conversation $(\\mathcal{T}_{i},\\mathcal{S}_{i})$ from $D i a_{M}$ and use Student agent to ask three more questions $S_{i}^{1},S_{i}^{2},S_{i}^{3}$ for $\\mathcal{T}_{i}$ (see Appendix C.1 for prompt). Then, we ask the Teacher agent to provide $T_{i+1}^{1}$ $\\mathbf{\\Phi}_{+1}^{1},T_{i+1}^{2},T_{i+1}^{3}$ , ultimately forming 6, 000 single-round Student-Teacher $\\{(S_{i}^{j},T_{i+1}^{j})|j=1,2,3\\}$ dialogues. ", "page_idx": 5}, {"type": "text", "text": "Third, a teacher should accurately identify students\u2019 \u201cIncorrect-reply\u201d and point out the idea of correction. To achieve this, we similarly sample 2, 000 Teacher-Student conversation from $D i a_{M}$ and employ rules and generation techniques to rewrite the Student\u2019s responses into five wrong answers. Then, we explicitly prompt the Teacher to identify the errors and provide a response, obtaining another 10K instances of Student-Teacher dialogues (please refer to Appendix C for details). ", "page_idx": 5}, {"type": "text", "text": "Finally, to enable teachers to identify different expressions of the same \u201cCorrect-reply\u201d for enhancing robustness, we take the same 2, 000 single-round \u201cTeacher-Student\u201d dialogues used for \u201cIncorrectreply\u201d and create two correct responses with Student (see Appendix C.2 for prompt). Subsequently, we collect Teacher\u2019s replies and obtain another 4, 000 single-round \u201cStudent-Teacher\u201d dialogues. ", "page_idx": 5}, {"type": "text", "text": "3.5 Dataset Overview ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In summary, our SocraTeach consists of 35K multi-round dialogues $D i a_{M}$ constructed by \u201cDeanTeacher-Student\u201d pipeline in Sections 3.2 and 22K single-round dialogues $D i a_{S}$ through data augmentation in Section 3.4. The average number of rounds in $D i a_{M}$ is 5.28, resulting in a total of 208K single-round dialogue examples. More statistics of SocraTeach are summarized in Appendix D. ", "page_idx": 5}, {"type": "text", "text": "In comparison to existing teaching dialogue datasets [17, 40, 41, 46, 49], our SocraTeach first addresses the deficiency of LLMs inadequately simulating teachers [51] by introducing the role of \u201cDean\u201d for supervision and correction. Secondly, to the best of our knowledge, SocraTeach is the first publicly available dataset designed for Socratic teaching, which specifically enhances four key teaching abilities of Teacher. Thirdly, while existing datasets simulate different students by setting their demographic backgrounds (e.g., grade) or specific error types, SocraTeach models six cognitive states of Student during the teaching process based on pedagogical experience, which covers a wider range of authentic teaching scenarios and enables LLMs to possess better teaching capabilities. Lastly, SocraTeach is a fully automatically generated large-scale dataset containing 35K multi-round dialogues and 22K single-round dialogues, significantly surpassing the existing datasets that rely on real human students/teachers (e.g., the latest MATHDIAL [40] contains 3K dialogues). ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "4 Fine-tune SocraticLM ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Based on SocraTeach, we can fine-tune a SOTA LLM (e.g., ChatGLM3-6b [12]) by splitting each dialogue $\\{(T_{1},S_{1}),(T_{2},S_{2}),\\ldots\\}$ into multiple rounds, using the preceding context of each round $\\{({\\mathcal{T}}_{1},S_{1}),...,({\\mathcal{T}}_{i},S_{i})\\}$ as input and the Teacher\u2019s response $\\mathcal{T}_{i+1}$ as output. However, it may lead to catastrophic forgetting and reduce the problem-solving ability that the model already has because these dialogues may differ from the data used for pre-training [21, 30, 38]. Specifically, we observe a decrease of $31.2\\%/9.7\\%$ in the accuracy of SocraticLM on the GSM8K/MAWPS dataset in Section 6.2. Therefore, to enhance SocraticLM\u2019s teaching ability without compromising its fundamental problem-solving capability, we explore the following three training strategies: ", "page_idx": 6}, {"type": "text", "text": "Separate Training. To maintain problem-solving ability, one direct way is to mix the dialogue and problem-solving data for training. However, we discover that it does not yield satisfactory results as shown in Section 6.2. Therefore, we adopt a separate training approach wherein we first fine-tune SocraticLM using dialogue data and then fine-tune it on a small amount of problem-solving data randomly sampled from GSM8K and MAWPS. Our experiments revealed that optimal performance is achieved when the ratio \u03b1 of problem-solving data to the dialogue data is approximately110. ", "page_idx": 6}, {"type": "text", "text": "Instruction Tuning. Inspired by [37], we employ different instructions for the dialogue data and problem-solving data, with the templates presented in Appendix E. It is worth noting that, unlike the prompt for Teacher in Section 3.2, here our instruction for dialogues does not require the model to follow the step-by-step guiding questions in Section 3.1. This is because providing such information in training may lead the model to take shortcuts, that is, to simplify the teaching process into information extraction from the prompt, without truly mastering the pedagogical ability. ", "page_idx": 6}, {"type": "text", "text": "Mixed Prompt Setting. Training with mixed prompt settings for the same task is an important method for improving LLMs\u2019 reasoning abilities [7, 55]. To this end, in addition to the original zero-shot problem-solving data of GSM8K and MAWPS, we also construct their one-shot version for training, which consists of approximately $\\textstyle{\\frac{1}{10}}$ of the amount of zero-shot data. ", "page_idx": 6}, {"type": "text", "text": "5 Our Socratic Teaching Evaluation System ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Since there is no standard answer for the teaching process, previous metrics that calculate the similarity between model-generated responses and annotated responses (e.g., BLEU [43], Rouge [31]) may not fully assess the teaching quality of LLMs. To address this issue, in this paper, we contribute an evaluation system encompassing five pedagogical dimensions for Socratic style and teaching abilities, which to the best of our knowledge, is the first comprehensive exploration in this field. ", "page_idx": 6}, {"type": "text", "text": "(1) Overall Quality (Overall): This metric is a holistic and subjective evaluation of teaching quality, requiring that the instruction satisfies Socratic style and enhances students\u2019 experience. ", "page_idx": 6}, {"type": "text", "text": "For Overall Quality, we randomly select 1, 000 single-round \u201cStudent-Teacher\u201d conversations from $D i a_{M}$ and recruit 10 well-educated annotators to blindly rank the Teacher response pairs provided bQyu aelaictyh  ims oeds te0il. m5aantde dG bPyT a4  inno rthmea lsiazmede  cwoinnt reaxtt e( pdlieffaesree rnecfee $\\begin{array}{r}{\\frac{1}{2}(1+\\frac{W i n-L o s t}{W i n+L o s t+T i e})\\in(0,1)}\\end{array}$ e( GOvPeTr4a\u2019lsl 100 Teacher response pairs of SocraticLM and GPT4 and ask all annotators to judge which one is better. The Kappa score is 0.70, indicating good agreement among human annotators. ", "page_idx": 6}, {"type": "text", "text": "For the four Socratic teaching abilities we elaborated in Section 3.4, we propose metrics (2)-(5). For each of them, we randomly select 100 corresponding single-round dialogues from $D i a_{S}$ for testing. ", "page_idx": 6}, {"type": "text", "text": "(2) Incorrect Answer Recognition Accuracy (IARA): This dimension focuses on whether the teacher can accurately identify students\u2019 \u201cIncorrect-reply\u201d. For example, in Figure 2, if a student provides an incorrect answer (e.g., \u201c14\u201d), a competent teacher should be able to recognize and point it out. This process is objective and can be considered as a binary classification task. ", "page_idx": 6}, {"type": "table", "img_path": "qkoZgJhxsA/tmp/ebb078b99273486246dd0ad892e37ffc494bf2877b1bb8a1d5dc97eb00204e52.jpg", "table_caption": [], "table_footnote": ["Table 1: Teaching performances. For all metrics, the higher value denotes the better performance. The best methods are highlighted in bold. The runner-up baselines are represented by underline. "], "page_idx": 7}, {"type": "text", "text": "(3) Correct Answer Recognition Accuracy (CARA): In contrast to error recognition, this dimension focuses on whether the model can accurately identify students\u2019 \u201cCorrect-reply\u201d. Neglecting this metric may mislead the LLMs to consider any answer provided by the student as incorrect. ", "page_idx": 7}, {"type": "text", "text": "(4) Successful Explanation Rate (SER): This dimension focuses on whether the model can provide students with satisfactory explanations for their \u201cQuestioning\u201d. This metric is subjective, but can be converted to binary classification based on students\u2019 real experience. ", "page_idx": 7}, {"type": "text", "text": "(5) Successful Rejection Rate (SRR): This metric is designed for the case where a teacher should refuse to answer students\u2019 \u201cIrrelevant\u201d questions and redirect them back to the instructional content. Based on whether the model refuses to answer the question, it is also calculated as binary classification. ", "page_idx": 7}, {"type": "text", "text": "Compared with existing works in evaluating LLMs for education, our evaluation system offers three main advantages. First, it provides a more comprehensive and adequate assessment. While previous works either rely on similarity metrics (e.g., BLEU [43]) or limited-scale manual evaluations (e.g., issuing questionnaires [18]), our system assesses overall teaching quality along with four key teaching abilities, which provides a more systematic organization of evaluation. Second, it enables better comparability across LLMs. Limited by the fact that a student can only interact with one LLM at a time, traditional human evaluations [5, 24] are difficult to compare the effectiveness of multiple models. In contrast, our system uses the same teaching dialogues shared across different models as test samples, allowing for a fair comparison of different LLMs simultaneously. Third, our system is more extensive and reliable benefiting from our larger SocraTeach dataset, while recent studies rely on smaller datasets, such as the latest one [40] with only around 600 testing dialogues. ", "page_idx": 7}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we verify the effectiveness of our SocraticLM by taking ChatGPT, GPT4, Vicuna7b [6], Llama2-7b, Llama2-13b, Llama3-8b [52], ChatGLM3-6b [12], and EduChat-32b [10] as baselines. The implementation details are described in Appendix G. Especially, for fair comparison, for the problems taught in the testing dialogues, we omit all of their dialogues in training. In addition to our proposed evaluation system in Section 5, we also invite human annotators to give a real teacher response for each testing dialogue, taking it as a standard to calculate the BLEU and Rouge. ", "page_idx": 7}, {"type": "text", "text": "6.1 Main Results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Table 1 summarizes the results for all models. First, our SocraticLM, which contains 6 billion parameters, demonstrates a significant improvement in all Socratic teaching abilities. Notably, it outperforms GPT4 by $12\\%$ on $o$ verall, $6\\%$ on IARA, $7\\%$ on CARA, $9\\%$ on SER, and $23\\%$ on SRR, as well as over $12\\%$ in mirroring the responses of human teachers as measured by BLEU and Rouge. In Appendix $\\mathrm{H}$ , we present and analyze examples of their outputs. Second, our SocraticLM demonstrates a significant improvement in $S E R$ . This indicates that the judgement and correction of our proposed Dean agent can critically boost the explanatory capabilities of large models when they function as teachers. Third, in Figure 3, we evaluate the four teaching abilities on problems with different numbers of step-by-step guiding questions, which can reflect the difficulty of the problems. It is evident that our SocraticLM consistently outperforms GPT4 across all difficulty levels. ", "page_idx": 7}, {"type": "image", "img_path": "qkoZgJhxsA/tmp/53e6d39046f0ad237b0717eecd13e3202d4e17a747432ff08c33f207e951fa4e.jpg", "img_caption": ["Figure 3: Performances on problems with different number of step-by-step guiding questions. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "6.2 Ablation Study ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Importance of Teaching Ability Enhancement. We explore the importance of single-round teaching dialogues $D i a_{S}$ built for the four key teaching abilities in Section 3.4. From Table 1, we first observe a significant decline (e.g., Overall Quality by $8\\%$ ) when these dialogues are removed (i.e., \u201cw/o DiaS\u201d). This illustrates the necessity of our teaching ability enhancement and confirms that our proposed four teaching abilities are effective in meeting the real demands of Socratic teaching. Second, the IARA and SRR metrics decrease the most, indicating the greatest disparity between the current LLM-based teaching and human teaching may lie in the response to students\u2019 incorrect answers and irrelevant questions. Third, each time a type of single-round dialogue data is eliminated, all teaching abilities will show a decline, which indicates that there is a coupling effect among different teaching abilities. Especially, the CARA metric in the absence of dialogues for students\u2019 \u201cCorrect-reply\u201d (i.e., \u201cw/o Correct\u201d) is even lower than when all single-round data is removed $(^{\\star}\\mathrm{w}/{\\o{0}{\\ D i a_{S}}}^{\\flat})$ ). We hold the reason may be that in this case, SocraticLM was still fine-tuned on dialogues corresponding to students\u2019 \u201cIncorrect-reply\u201d. This causes the model to develop a stronger tendency to perceive a student\u2019s reply as incorrect. This phenomenon further indicates that it is necessary to balance different types of single-round dialogues to avoid overfitting on specific instructional patterns. ", "page_idx": 8}, {"type": "text", "text": "Importance of Ability-balancing Strategies. Here we discard the problem-solving data and the three ability-balancing strategies in Section 4 in training to investigate their influence. From Table 2, fine-tuning without problem-solving data (\u201cw/o Problem\u201d) will result in a $31.2\\%/9.7\\%$ lower accuracy on GSM8K/MAWPS compared with ChatGLM3- 6b. This could be attributed to the notable differences between teaching dialogues and data used for LLM pre-training, causing a dramatic disturbance in the parameters. Besides, all three training strategies are effective. Among them, ", "page_idx": 8}, {"type": "table", "img_path": "qkoZgJhxsA/tmp/168b9e2b59660890f4e74a7dcc6b382818f407e9b4962936413a49c0ae246f72.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Table 2: Performance without problem-solving data and three ability-balancing training strategies in Section 4. $A C C_{G}$ , $A C C_{M}$ represent the accuracy on GSM8K and MAWPS, respectively. ", "page_idx": 8}, {"type": "text", "text": "Separate Training/Instruction Tuning has the greatest influence on problem-solving/Socratic teaching respectively. Mixed Prompt Setting might have already been employed in the LLM pre-training, hence exhibiting less noticeable improvements. Moreover, it is worth noting that SocraticLM achieves higher accuracy on MAWPS than ChatGLM3-6b. We speculate the reason is that, through finetuning on our SocraTeach dataset, SocraticLM indeed learns to address multiple student questions about various aspects of a single problem (e.g., asking about each reasoning step and the knowledge involved). This process allows SocraticLM to develop a deeper understanding of the problem-solving process, which in turn can improve its problem-solving accuracy. ", "page_idx": 8}, {"type": "text", "text": "6.3 Influence of Data Scale ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Data scale is crucial for both the efficiency and effectiveness of training large language models. In order to investigate this issue, in this section, we vary the amount of multi-round dialogues in SocraTeach dataset and the ratio $\\alpha$ between multi-round dialogues and problem-solving data. ", "page_idx": 8}, {"type": "text", "text": "Scale of Multi-round Dialogues. To study the impact of different data scale, we randomly select $25\\%$ , $50\\%$ , $75\\%$ multiround dialogues from SocraTeach and expand it to $125\\%$ dialogues by running DTS pipeline more times to train SocraticLM. The results in Figure 4 indicate that (i) Our data is not only effective but also impactful at different scales, which can significantly enhance the teaching capability of LLMs. (ii) As the volume of data increases, we observe a corresponding increase in the teaching ability. This correlation highlights the importance of data quantity in model performance. Specifically, it is noteworthy that a minimum of $75\\%$ $(\\approx26\\mathrm{K})$ dialogues is required for surpassing the Overall Quality of GPT4. (iii) As the volume of data surpasses the 35K threshold, it tends to approach a saturation point where further increases in data volume yield smaller incremental beneftis to the model\u2019s capability. Specifically, at the $125\\%$ data scale, the IARA metric shows a decline, indicating that the root cause of this saturation is a decrease in the model\u2019s ability to identify incorrect answers (the decline in Overall Quality is a subsequent result). This may be because, with the increase in multi-round dialogue data, the proportion of single-round dialogue data for \u201cIncorrect reply\u201d decreases. When multi-round data scale exceeds $125\\%$ , this proportion may fall below a certain threshold, which results in diminishing effectiveness. ", "page_idx": 9}, {"type": "image", "img_path": "qkoZgJhxsA/tmp/48f925dff5e4a9d34fb5a3ec2d11acea63dbda42df2d13c5eaf99c863124bdd6.jpg", "img_caption": ["Figure 4: Effects of dialogue scale. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Scale of Problem-solving Data. Figure 5 shows the performance changes of SocraticLM as we adjust the ratio $\\alpha$ between problem-solving data and dialogue data. The trend indicates that having too few or too much problem-solving data does not lead to satisfactory problem-solving ability. Instead, a balance needs to be struck with the teaching dialogue data. In fact, an excessive introduction of problem-solving data may even result in $1.9\\%$ decrease in accuracy on GSM8K. This could be attributed to that the parameters corresponding to SocraticLM\u2019 problem-solving ability might undergo disturbances after initial fine-tuning using the teaching dialogues. When retraining with problem-solving data, it requires to re-strike a delicate balance between underfitting and overfitting of this ability. ", "page_idx": 9}, {"type": "image", "img_path": "qkoZgJhxsA/tmp/2294034573e73895b88dae719de83c5587c802e00a5122402c990a909475bdc9.jpg", "img_caption": ["Figure 5: Effects of problem-solving data scale. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we introduced SocraticLM, a LLM designed to facilitate Socratic \u201cThought-Provoking\u201d personalized teaching. To build SocraticLM, we proposed a \u201cDean-Teacher-Student\u201d pipeline to construct SocraTeach dataset, which simulated six student cognitive states and strengthened four crucial teaching abilities. Besides, we developed a comprehensive teaching ability evaluation system for LLMs. Experiments demonstrated that SocraticLM significantly outperforms current LLMs such as GPT4 and validated the necessity of each component within the SocraTeach dataset. We discuss more cases, the broader impacts, limitations, and future work in Appendix H, I, and J. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This research was partially supported by grants from the National Key Research and Development Program of China (No.2021YFF0901005), National Natural Science Foundation of China (No.62477044, 62337001), and the Key Technologies R&D Program of Anhui Province (No.202423k09020039). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023. ", "page_idx": 9}, {"type": "text", "text": "[2] Tufan Ad\u0131g\u00fczel, Mehmet Haldun Kaya, and Fatih K\u00fcrs\u00b8at Cansu. Revolutionizing education with ai: Exploring the transformative potential of chatgpt. Contemporary Educational Technology, 2023. ", "page_idx": 9}, {"type": "text", "text": "[3] Geoffrey D Borman, Gina M Hewes, Laura T Overman, and Shelly Brown. Comprehensive school reform and achievement: A meta-analysis. Review of educational research, 73(2):125\u2013 230, 2003.   \n[4] Andrew Caines, Luca Benedetto, Shiva Taslimipoor, Christopher Davis, Yuan Gao, Oeistein Andersen, Zheng Yuan, Mark Elliott, Russell Moore, Christopher Bryant, et al. On the application of large language models for language teaching and assessment technology. arXiv preprint arXiv:2307.08393, 2023.   \n[5] Eason Chen, Ray Huang, Han-Shin Chen, Yuen-Hsien Tseng, and Liang-Yi Li. Gptutor: a chatgpt-powered programming tool for code explanation. In International Conference on Artificial Intelligence in Education, pages 321\u2013327. Springer, 2023.   \n[6] Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, et al. Vicuna: An open-source chatbot impressing gpt-4 with $90\\%*$ chatgpt quality. See https://vicuna. lmsys. org (accessed 14 April 2023), 2(3):6, 2023.   \n[7] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022.   \n[8] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.   \n[9] Wei Dai, Jionghao Lin, Hua Jin, Tongguang Li, Yi-Shan Tsai, Dragan Ga\u0161evic\u00b4, and Guanliang Chen. Can large language models provide feedback to students? a case study on chatgpt. In 2023 IEEE International Conference on Advanced Learning Technologies (ICALT), pages 323\u2013325. IEEE, 2023.   \n[10] Yuhao Dan, Zhikai Lei, Yiyang Gu, Yong Li, Jianghao Yin, Jiaju Lin, Linhao Ye, Zhiyan Tie, Yougen Zhou, Yilei Wang, et al. Educhat: A large-scale language model-based chatbot system for intelligent education. arXiv preprint arXiv:2308.02773, 2023.   \n[11] Ian J Deary, Steve Strand, Pauline Smith, and Cres Fernandes. Intelligence and educational achievement. Intelligence, 35(1):13\u201321, 2007.   \n[12] Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. Glm: General language model pretraining with autoregressive blank infliling. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 320\u2013335, 2022.   \n[13] Linda Elder and Richard Paul. The role of socratic questioning in thinking, teaching, and learning. The Clearing House, 71(5):297\u2013301, 1998.   \n[14] Amy S Finn, Matthew A Kraft, Martin R West, Julia A Leonard, Crystal E Bish, Rebecca E Martin, Margaret A Sheridan, Christopher FO Gabrieli, and John DE Gabrieli. Cognitive skills, student achievement tests, and schools. Psychological science, 25(3):736\u2013744, 2014.   \n[15] Maren Formazin, Ulrich Schroeders, Olaf K\u00f6ller, Oliver Wilhelm, and Hans Westmeyer. Studierendenauswahl im fach psychologie. Psychologische Rundschau, 2011.   \n[16] Wensheng Gan, Zhenlian Qi, Jiayang Wu, and Jerry Chun-Wei Lin. Large language models in education: Vision and opportunities. In 2023 IEEE International Conference on Big Data (BigData), pages 4776\u20134785. IEEE, 2023.   \n[17] Arthur C Graesser, Shulan Lu, George Tanner Jackson, Heather Hite Mitchell, Mathew Ventura, Andrew Olney, and Max M Louwerse. Autotutor: A tutor with dialogue in natural language. Behavior Research Methods, Instruments, & Computers, 36:180\u2013192, 2004.   \n[18] Jieun Han, Haneul Yoo, Yoonsu Kim, Junho Myung, Minsun Kim, Hyunseung Lim, Juho Kim, Tak Yeon Lee, Hwajung Hong, So-Yeon Ahn, et al. Recipe: How to integrate chatgpt into ef writing education. In Proceedings of the Tenth ACM Conference on Learning@ Scale, pages 416\u2013420, 2023.   \n[19] Eric A Hanushek and Steven G Rivkin. Generalizations about using value-added measures of teacher quality. American economic review, 100(2):267\u2013271, 2010.   \n[20] Christothea Herodotou, Bart Rienties, Avinash Boroowa, Zdenek Zdrahal, and Martin Hlosta. A large-scale implementation of predictive learning analytics in higher education: The teachers\u2019 role and perspective. Educational Technology Research and Development, 67:1273\u20131306, 2019.   \n[21] Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. Lora: Low-rank adaptation of large language models. In International Conference on Learning Representations, 2021.   \n[22] Liya Hu, Zhiang Dong, Jingyuan Chen, Guifeng Wang, Zhihua Wang, Zhou Zhao, and Fei Wu. Ptadisc: a cross-course dataset supporting personalized learning in cold-start scenarios. Advances in Neural Information Processing Systems, 36:44976\u201344996, 2023.   \n[23] Zhenya Huang, Qi Liu, Yuying Chen, Le Wu, Keli Xiao, Enhong Chen, Haiping Ma, and Guoping Hu. Learning or forgetting? a dynamic approach for tracking the knowledge proficiency of students. ACM Transactions on Information Systems (TOIS), 38(2):1\u201333, 2020.   \n[24] Jennifer Jin and Mira Kim. Gpt-empowered personalized elearning system for programming languages. Applied Sciences, 13(23):12773, 2023.   \n[25] Tanisha Jowsey, Jessica Stokes-Parish, Rachelle Singleton, and Michael Todorovic. Medical education empowered by generative artificial intelligence large language models. Trends in Molecular Medicine, 2023.   \n[26] Enkelejda Kasneci, Kathrin Se\u00dfler, Stefan K\u00fcchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan G\u00fcnnemann, Eyke H\u00fcllermeier, et al. Chatgpt for good? on opportunities and challenges of large language models for education. Learning and individual differences, 103:102274, 2023.   \n[27] Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. Mawps: A math word problem repository. In Proceedings of the 2016 conference of the north american chapter of the association for computational linguistics: human language technologies, pages 1152\u20131157, 2016.   \n[28] Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. Camel: Communicative agents for\" mind\" exploration of large language model society. Advances in Neural Information Processing Systems, 36, 2024.   \n[29] Qingyao Li, Lingyue Fu, Weiming Zhang, Xianyu Chen, Jingwei Yu, Wei Xia, Weinan Zhang, Ruiming Tang, and Yong Yu. Adapting large language models for education: Foundational capabilities, potentials, and challenges. arXiv preprint arXiv:2401.08664, 2023.   \n[30] Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence, 40(12):2935\u20132947, 2017.   \n[31] Chin-Yew Lin. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out, pages 74\u201381, 2004.   \n[32] Xin Lin, Zhenya Huang, Hongke Zhao, Enhong Chen, Qi Liu, Defu Lian, Xin Li, and Hao Wang. Learning relation-enhanced hierarchical solver for math word problems. IEEE Transactions on Neural Networks and Learning Systems, 2023.   \n[33] Jia-Yu Liu, Fei Wang, Hai-Ping Ma, Zhen-Ya Huang, Qi Liu, En-Hong Chen, and Yu Su. A probabilistic framework for temporal cognitive diagnosis in online learning systems. Journal of Computer Science and Technology, 38(6):1203\u20131222, 2023.   \n[34] Jiayu Liu, Zhenya Huang, Zhiyuan Ma, Qi Liu, Enhong Chen, Tianhuang Su, and Haifeng Liu. Guiding mathematical reasoning via mastering commonsense formula knowledge. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 1477\u20131488, 2023.   \n[35] Qi Liu, Zhenya Huang, Yu Yin, Enhong Chen, Hui Xiong, Yu Su, and Guoping Hu. Ekt: Exercise-aware knowledge tracing for student performance prediction. IEEE Transactions on Knowledge and Data Engineering, 33(1):100\u2013115, 2019.   \n[36] Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Tam, Zhengxiao Du, Zhilin Yang, and Jie Tang. Ptuning: Prompt tuning can be comparable to fine-tuning across scales and tasks. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Association for Computational Linguistics, 2022.   \n[37] Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, et al. The flan collection: Designing data and methods for effective instruction tuning. In International Conference on Machine Learning, pages 22631\u201322648. PMLR, 2023.   \n[38] Yun Luo, Zhen Yang, Fandong Meng, Yafu Li, Jie Zhou, and Yue Zhang. An empirical study of catastrophic forgetting in large language models during continual fine-tuning. arXiv preprint arXiv:2308.08747, 2023.   \n[39] Haiping Ma, Changqian Wang, Hengshu Zhu, Shangshang Yang, Xiaoming Zhang, and Xingyi Zhang. Enhancing cognitive diagnosis using un-interacted exercises: A collaboration-aware mixed sampling approach. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 8877\u20138885, 2024.   \n[40] Jakub Macina, Nico Daheim, Sankalan Chowdhury, Tanmay Sinha, Manu Kapur, Iryna Gurevych, and Mrinmaya Sachan. Mathdial: A dialogue tutoring dataset with rich pedagogical properties grounded in math reasoning problems. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 5602\u20135621, 2023.   \n[41] Julia M Markel, Steven G Opferman, James A Landay, and Chris Piech. Gpteach: Interactive ta training with gpt-based students. In Proceedings of the tenth acm conference on learning@ scale, pages 226\u2013236, 2023.   \n[42] Steven Moore, Richard Tong, Anjali Singh, Zitao Liu, Xiangen Hu, Yu Lu, Joleen Liang, Chen Cao, Hassan Khosravi, Paul Denny, et al. Empowering education with llms-the next-gen interface and content generation. In International Conference on Artificial Intelligence in Education, pages 32\u201337. Springer, 2023.   \n[43] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311\u2013318, 2002.   \n[44] Minju Park, Sojung Kim, Seunghyun Lee, Soonwoo Kwon, and Kyuseok Kim. Empowering personalized learning through a conversation-based tutoring system with student modeling. arXiv preprint arXiv:2403.14071, 2024.   \n[45] Richard Paul and Linda Elder. Critical thinking: The art of socratic questioning. Journal of developmental education, 31(1):36, 2007.   \n[46] Sherry Ruan, Liwei Jiang, Justin Xu, Bryce Joe-Kun Tham, Zhengneng Qiu, Yeshuang Zhu, Elizabeth L Murnane, Emma Brunskill, and James A Landay. Quizbot: A dialogue-based adaptive learning system for factual knowledge. In Proceedings of the 2019 CHI conference on human factors in computing systems, pages 1\u201313, 2019.   \n[47] Yueqi Shi and Shaowei Qu. Analysis of the effect of cognitive ability on academic achievement: Moderating role of self-monitoring. Frontiers in Psychology, 13:996504, 2022.   \n[48] Aarohi Srivastava, Denis Kleyjo, and Ziyi Wu. Beyond the imitation game: Quantifying and extrapolatingthe capabilities of language models. Transactions on Machine Learning Research, (5), 2023.   \n[49] Katherine Stasaski, Kimberly Kao, and Marti A Hearst. Cima: A large open access dialogue dataset for tutoring. In Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 52\u201364, 2020.   \n[50] Jianwen Sun, Rui Zou, Ruxia Liang, Lu Gao, Sannyuya Liu, Qing Li, Kai Zhang, and Lulu Jiang. Ensemble knowledge tracing: Modeling interactions in learning process. Expert Systems with Applications, 207:117680, 2022.   \n[51] Ana\u00efs Tack and Chris Piech. The ai teacher test: Measuring the pedagogical ability of blender and gpt-3 in educational dialogues. International Educational Data Mining Society, 2022.   \n[52] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.   \n[53] Fei Wang, Qi Liu, Enhong Chen, Zhenya Huang, Yu Yin, Shijin Wang, and Yu Su. Neuralcd: a general framework for cognitive diagnosis. IEEE Transactions on Knowledge and Data Engineering, 35(8):8312\u20138327, 2022.   \n[54] Longyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui Zhang, Dian Yu, Shuming Shi, and Zhaopeng Tu. Document-level machine translation with large language models. In The 2023 Conference on Empirical Methods in Natural Language Processing, 2023.   \n[55] Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. In International Conference on Learning Representations, 2021.   \n[56] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824\u201324837, 2022.   \n[57] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. Advances in Neural Information Processing Systems, 36, 2024.   \n[58] Liang Zhang, Jionghao Lin, Ziyi Kuang, Sheng Xu, Mohammed Yeasin, and Xiangen Hu. Spl: A socratic playground for learning powered by large language mode. arXiv preprint arXiv:2406.13919, 2024.   \n[59] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. A survey of large language models. arXiv preprint arXiv:2303.18223, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A More details about problem decomposition ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A decomposition of each problem was provided in the GSM8K raw data, which we found largely met our needs. Thus, we use GPT4 to decompose the problems in MAWPS with the prompt in A.1. ", "page_idx": 14}, {"type": "text", "text": "A.1: Problem Decomposition Prompt ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "You are a math teacher, and I want you to answer the math problems I give you in steps. In   \neach step, you need to first give a guided question and then explain the process of solving it,   \nmeeting the following criteria: After all the steps, the final result is the same as the Answer The steps need to be as few as possible Not a calculation process as a step Not a result summary as a step Different steps are divided by $\"\\mathrm{n}^{\\prime}$ Please ensure that your steps are well-organized, precise, and easy to follow, with each step building upon the previous one.   \n#Problem: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips   \nin May. How many clips did Natalia sell altogether in April and May?   \n#Answer: 72   \n#Steps: How many clips did Natalia sell in May? $^{**}$ Natalia sold $48/2=24$ clips in   \nMay.\\nHow many clips did Natalia sell altogether in April and May? $^{**}$ Natalia sold $48\\substack{+24\\,=}$   \n72 clips altogether in April and May.   \n#Problem: {Here is the target problem.}   \n#Answer: {Here is the target answer.} ", "page_idx": 14}, {"type": "text", "text": "B Prompts of \u201cDean-Teacher-Student\u201d pipeline ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.1: Prompt of Student Agent ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "You are a primary school student, please refer to the dialogue and generate a possible   \nresponse for me. In generating a response, you first need to choose one of the following SITUATIONs and then respond as a student who fits that situation, meeting the following criteria:   \nYou are not a teacher, do not give any teacher reply!   \nDon't ask questions about the people in the question.   \nYour response should cohere with the given Dialogue.   \nSITUATIONs: (1) a student does not understand the meaning of the problem; (2) a student does not understand the content explained by the teacher; (3) a student makes error in   \ncalculation; (4) a student has poor knowledge mastery; (5) a student has weak thirst for knowledge; (6) a student has strong abilities in all aspects.   \nHere are some examples:   \n#Problem: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?   \n#Dialogue: [Teacher]How many clips did Natalia sell in May?\\n[Student]I'm not good at math. Can you explain it again?\\n[Teacher]Not a problem at all. Let's break it down. If Natalia sold half as many clips in May as she did in April, and she sold 48 clips in April, then how many clips will she have sold in May? Let's take the number from April and half it. What do you get? #Response:Choose SITUATION (3)[Student]I get it, the half of 48 is 240.   \n...   \nHere is the target problem:   \n#Problem: {Here is the target problem.} ", "page_idx": 14}, {"type": "text", "text": "#Dialogue: {Here is the target dialogue.} ", "page_idx": 14}, {"type": "text", "text": "B.2: Prompt of Teacher Agent ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "I am a primary school student. You are a teacher that always responds in the Socratic style. You could not give me the answer but always try to ask just the right question to help me learn to think for myself. You need to break the problem down into simpler parts until it's at the right level for me. Please explain the above steps to me in the form of questions, starting with [Step 1]. If you think you have finished teaching, please put \\\"[END]\\\" at the end of your response. ", "page_idx": 15}, {"type": "text", "text": "(Choose one of the following examples according to Student's SITUATION): (SITUATION 1) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "#Problem: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?   \n#Steps: [step 1] How many clips did Natalia sell in May?\\n[step 2] How many clips did Natalia sell altogether in April and May?   \n#Dialogue:[Teacher]: How many clips did Natalia sell in May?\\n[Student]: I'm confused. Does \\\"half as many\\\" mean the same number as April?   \n#Response:[Teacher]: In fact, \\\"half as many\\\" means half of the number. So if Natalia sold 48 clips in April, how many clips did she sell in May? ", "page_idx": 15}, {"type": "text", "text": "(SITUATION 2) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "#Problem: Randy has 60 mango trees on his farm. He also has 5 less than half as many coconut trees as mango trees. How many trees does Randy have in all on his farm? #Steps: [step 1] How many mango trees does Randy have?\\n[step 2] How many coconut trees does Randy have?\\n[Step 3] How many trees does Randy have in all on his farm? #Dialogue:[Teacher]: How many mango trees does Randy have?\\n[Student]: You mean how many are there totally or just mango? ", "page_idx": 15}, {"type": "text", "text": "#Response:[Teacher]: We're talking about just the mango trees now. So, considering just the mango trees, can you tell me how many Randy has according to the problem? ", "page_idx": 15}, {"type": "text", "text": "(SITUATION 3-6) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "\u51c0 ", "page_idx": 15}, {"type": "text", "text": "Here is the target problem: ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "#Problem: {Here is the target problem.} #Steps: {Here is the target steps.} #Dialogue: {Here is the target dialogue.} ", "page_idx": 15}, {"type": "text", "text": "B.3: Prompt of Dean Agent ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "You are a teaching director. The following is the teaching process of a Socratic teacher. Please evaluate the response of [Teacher] in the last round and judge whether it meets the following teaching criteria: ", "page_idx": 15}, {"type": "text", "text": "If the [Student] is asking a commonsense or struggles to understand a concept, the [Teacher] is allowed to give direct explanation.   \nIn other cases, no direct answer or solution to the problem can be given in a declarative or rhetorical manner.   \nIf [Student] makes a mistake, it is necessary to imply by way of question what error he/she made.   \n[Teacher] needs to speak like a teacher and does not use phrases like \\\"let me ask you\\\". The response must be smooth and fluent. ", "page_idx": 15}, {"type": "text", "text": "If you think the response meets the criteria, please reply [True], otherwise reply [False], explain your judgement and modify it according to the criteria. ", "page_idx": 15}, {"type": "text", "text": "Here are some examples: ", "text_level": 1, "page_idx": 16}, {"type": "image", "img_path": "qkoZgJhxsA/tmp/455346650f6c0e31ac04bc7050506449fea40a4a5c586dc51f585c560d354f60.jpg", "img_caption": [], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "#Problem: {Here is the target problem.} #Dialogue: {Here is the target dialogue.} ", "page_idx": 16}, {"type": "text", "text": "C More Details about Teaching Ability Enhancement ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "To build single-round dialogues for \u201cIrrelevant\u201d student response, we first randomly select 2, 000 dialogues from $D i a_{M}$ constructed by DTS pipeline. From each dialogue, we randomly select one round of Student\u2019s response and replace it with a randomly selected question from the 200 questions collected from MOOCs. We then use Teacher agent to refuse answering the question under the supervision of Dean, finally forming 2, 000 single-round Student-Teacher dialogues. ", "page_idx": 16}, {"type": "image", "img_path": "qkoZgJhxsA/tmp/5492805758d5c47b793d1134c34bedefdc218cb6abed19acfe2d50e582f45b81.jpg", "img_caption": [], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "To build five wrong answers for \u201cIncorrect-rely\u201d, on one hand, we identify all the numbers (e.g., \u201c2\u201d) and operators (e.g., $\"+\")$ in a Student\u2019s reply and randomly introduce a perturbation within the range of 10 to one number or randomly replace one operator with another. We apply these rules to obtain two new Student\u2019s responses. On the other hand, we use GPT4 to rewrite the original Student\u2019s response and generate three incorrect answers using prompt in C.2. With these five responses, we prompt the Teacher to response and obtain 10K Student-Teacher dialogues. ", "page_idx": 16}, {"type": "image", "img_path": "qkoZgJhxsA/tmp/894fc41c8b96536a202a37ba11722f4891faa540e09e4d32d82911687bccfcec.jpg", "img_caption": [], "img_footnote": [], "page_idx": 17}, {"type": "table", "img_path": "qkoZgJhxsA/tmp/44062ea2496139c77a92886d43b7e9333f9c16441eb6de0f189d382f2dc3b428.jpg", "table_caption": [], "table_footnote": ["Table 3: Statistics of our SocraTeach dataset. "], "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "D Statistics of SocraTeach Dataset ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "As stated in Section 3.5, our SocraTeach consists of 35K multi-round dialogues $D i a_{M}$ and 22K single-round dialogues $D i a_{S}$ . The average number of rounds in $D i a_{M}$ is 5.28. On average, the Student/Teacher\u2019s responses contain $16.4/30.3$ words respectively. The overall statistics is summarized in Table 3. Moreover, from Figure 6(a), most teaching dialogues consist of 5-6 rounds. In Figure 6(b), we visualize the probability mass function of Student\u2019s cognitive states in SocraTeach, where (1)-(5) correspond to a student portrait that performs poor in one of the dimensions in our proposed student cognitive system (Section 3.3), while (6) corresponds to a student with strong states in all dimensions. It can be seen that the Student agent tends to simulate a student who is excellent in all aspects or alternatively, has problems in calculation ability (i.e., \u201c(3)\u201d) or knowledge mastery (i.e., \u201c(4)\u201d). ", "page_idx": 17}, {"type": "image", "img_path": "qkoZgJhxsA/tmp/6b98af07c250af4404b7b6e6a54d1a597673f348991c3f257e71918806f3fb45.jpg", "img_caption": ["Figure 6: Distributions of Number of Rounds (a) and Student Cognitive State (b). "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "E Instruction Tuning Template ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Figure 7 shows the instruction template for teaching dialogue data and problem-solving data. ", "page_idx": 18}, {"type": "image", "img_path": "qkoZgJhxsA/tmp/559d47337f751c6c5639fdba5e2095cc59835c16e2a39d558df72ce28d31cc66.jpg", "img_caption": ["Figure 7: The templates for instruction tuning. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "F Human Evaluation for Teaching Quality ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "To evaluate the Overall Quality of different LLMs, we recruit 10 well-educated annotators to rank the instructions provided by each model compared with GPT4. Figure 8 shows the template. ", "page_idx": 18}, {"type": "image", "img_path": "qkoZgJhxsA/tmp/15ad6abc99248302c2da3e4124853f0c8149cad75b82452f51980bd815ff40cf.jpg", "img_caption": ["Figure 8: The template of human evaluation for Overall Quality. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "G Implementation Details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Our SocraticLM is obtained by P-Tuning [36] ChatGLM3-6b (not ChatGLM3-6b-Base) for 2 epochs with a learning rate of 0.02 and batch size of 64. For dataset partition, as described in Section 5, the testing set is composed of 400 single-round dialogues for evaluating objective teaching ability (i.e., IARA, CARA, SER, SRR) and 1, 000 multiple-round dialogues for evaluating subjective Overall Quality. Of the remaining data in SocraTeach, $10\\%/90\\%$ is used for validation/training. All experiments are conducted on a server with six NVIDIA RTX 3090 GPUs. Our dataset and code is available at https://github.com/Ljyustc/SocraticLM. ", "page_idx": 19}, {"type": "text", "text": "H Additional Model Samples ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In the following, we present four samples of our SocraticLM and GPT4 for students\u2019 \u201cIncorrectreply\u201d, \u201cCorrect-reply\u201d, \u201cQuestioning\u201d and \u201cIrrelevant\u201d response respectively. In the first example, both SocraticLM and GPT4 identify the student\u2019s mistake, but GPT4 gives the answer \u201c7\u201d directly, which contradicts the demands of Socratic teaching. In the second example, GPT4 also gives an almost complete solution process, which does not meet the requirements of step-by-step Socratic guidance of thinking. In the third example, GPT4\u2019s expression is more stilted and lacks the sense of a real human teacher. In the fourth example, SocraticLM redirects the student to solve the math problem first, while GPT4 is shifted to answer the irrelevant question. ", "page_idx": 19}, {"type": "text", "text": "Sample 1: Incorrect-reply ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "#Problem: Brenda's mother made cookies for 5 . If she prepared 35 cookies and each of them had the same number of cookies , how many did each of them have ?   \n#Dialogue history:   \n[Teacher]: How can we calculate the number of cookies each person gets?   \n[Student]: Can't you just divide it for me?   \n[Teacher]: Well, you could just do that, but it's important to understand why we divide. Dividing allows us to equally distribute something amongst a certain number of people or things. In this case, if Brenda's mother made 35 cookies for 5 people, how would you divide those cookies so that each person gets the same amount?   \n[Student]: Oh, do we just divide the total number of cookies by the total number of people? [Teacher]: That's right! Now using this method, how many cookies does each person get if Brenda's mother made 35 cookies for 5 people?   \n[Student]: I'm not sure. What is 35 divided by 5?   \n[Teacher]: Good question! Let's think about it. If you have 5 groups, and you need to distribute 35 items equally, how many would go in each group? You can start by seeing how many times 5 can fit into 35 without going over. Can you try to do that?   \n[Student]: So does that mean each person gets 8 cookies? ", "page_idx": 19}, {"type": "text", "text": "SocraticLM: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "That's a good start! But let's double-check. If you divide 35 by 5, what do you get? ", "page_idx": 19}, {"type": "text", "text": "GPT4: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Not quite. If you visualize a group of 35 objects, and you divide it into 5 equal groups, you would see that each group actually contains 7 objects. In this case, each person would get 7 cookies. Does that make sense? ", "page_idx": 19}, {"type": "text", "text": "Sample 2: Correct-reply ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "#Problem: Jeff makes 10 donuts each day for 12 days. Jeff eats one of the donuts each day. Chris then comes over and eats 8 donuts. If 10 donuts fit in each box, how many boxes can Jeff fill with his donuts?   \n#Dialogue history:   \n[Teacher]: How many donuts does Jeff make? [Student]: Does \\\"makes\\\" include the ones he eats or not?   \n[Teacher]: When we say \\\"Jeff makes\\\", we're referring to the total number of donuts Jeff creates, whether he eats them or not. So, how many donuts in total did Jeff make? [Student]: Jeff makes 10 donuts each day and he made donuts for 12 days, so he made 120 donuts in total. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "[Teacher]: That's correct! Now, how many donuts does Jeff eat? [Student]: Jeff eats 12 donuts because he has one each day and he made donuts for 12 days. ", "page_idx": 20}, {"type": "text", "text": "SocraticLM: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Excellent! Now, if Jeff eats 12 donuts and he made 120 donuts in total, how many donuts are left after he eats? ", "page_idx": 20}, {"type": "text", "text": "GPT4: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Exactly! Now, there is another character introduced in the problem named Chris. How many donuts does Chris eat? Given that Chris eats 8 donuts, how we calculate the total number of remaining donuts? Once we have the total number of remaining donuts, what do we do to find out the number of boxes required? Now, can you calculate the number of boxes that can Jeff needs to store all of his remaining donuts? ", "page_idx": 20}, {"type": "text", "text": "Sample 3: Questioning ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "#Problem: Matias is a salesman in a bookstore. He sold 7 books on Tuesday and three times as many on Wednesday. If the sales from Wednesday were tripled on Thursday, how many books did Matias sell during these three days combined? ", "page_idx": 20}, {"type": "text", "text": "#Dialogue history:   \n[Teacher]: How many books did Matias sell on Wednesday?   \n[Student]: What are you asking? ", "page_idx": 20}, {"type": "text", "text": "SocraticLM: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Let's break it down. If Matias sold 7 books on Tuesday, and he sold three times as many on Wednesday, how many books did he sell on Wednesday? ", "page_idx": 20}, {"type": "text", "text": "GPT4: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "How many books did Matias sell on Tuesday? And if he sold three times more on Wednesday, can you calculate how many books that would be? ", "page_idx": 20}, {"type": "text", "text": "Sample 4: Irrelevant ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "#Problem: Solomon collected three times as many cans as Juwan. Levi collected half of what   \nJuwan collected. Solomon collected 66 cans. How many cans did the boys collect in all?   \n#Dialogue history:   \n[Teacher]: How many cans did Juwan collect?   \n[Student]: How to study grammar? ", "page_idx": 20}, {"type": "text", "text": "SocraticLM: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "That's a great question! But let's first figure out how many cans Juwan collected. If Solomon collected three times as many cans as Juwan, and Solomon collected 66 cans, can you calculate how many cans Juwan collected? ", "page_idx": 20}, {"type": "text", "text": "GPT4: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "That's an entirely different topic, but I can help. Study of grammar means understanding the structure of a language. We have verbs, nouns, adjectives, adverbs, etc. in a sentence. Understanding how these work together is studying grammar. Have you tried reading about grammar before? ", "page_idx": 20}, {"type": "text", "text": "I Broader Impacts ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In this paper, we propose a large language model SocraticLM to achieve Socratic teaching, which is a crucial pedagogy in intelligent education and has a significant impact on our daily lives. On the one hand, as explained in Section 3.3 and 3.4, our SocraticLM can provide instructions to students with different cognitive states and various types of responses. Therefore, it can support multiple personalized applications in classrooms and online platforms, delivering high-quality instructions more efficiently and conveniently to students from various backgrounds, thus promoting educational equity and rapid development. On the other hand, in our work, we use GPT4 to simulate conversations between teachers and students to generate dialogue data, entirely without the involvement of real human teachers or students. This approach provides a way to collect data without interacting with or testing on real humans, reducing the burden of human interaction while also avoiding privacy, security, and other ethical concerns. However, since our model needs to be trained with multi-round teaching dialogue data, in order to expand to more subjects (e.g., physics), it may require more educational resources (e.g., problems in textbooks) and training costs. ", "page_idx": 21}, {"type": "text", "text": "J Limitations and Future Work ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "First, from Table 1, the SER metric of SocraticLM and GPT4 is 0.74 and 0.65, respectively. This shows that the current models have room for improvement in their ability to respond to real and complex student questions. Second, we focus on the teaching of mathematical problems in this paper. For other subjects, we need additional data construction and training processes. Third, the testset of problem-solving ability in this paper is the problems that our Socratic teaching dialogues are based on (i.e. GSM8K and MAWPS). In order to more accurately assess the changes in reasoning ability, we will test additional datasets and explore ability-balancing training strategies for more tasks. Finally, in this paper, we use ChatGLM3-6b, an open source large language model as our base to construct SocraticLM, because it is easy to fine-tune and has not been pre-trained with teaching capabilities, which can better verify the effect of our SocraTeach dataset. In the future, we will use our dataset to fine-tune more LLMs and explore their potential for teaching and intelligent education. ", "page_idx": 21}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We have clearly explained the scope of this paper and listed the contributions. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 22}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: We present a \"Limitations and Future Work\" section in Appendix J to discuss the limitations of our work. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 22}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: This paper does not include theoretical results. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 23}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We describe in details the construction process of our dataset in the main paper, all prompts used in this paper in Appendix A, B, C, and E, and the setups needed to reproduce the experimental results in Appendix G. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 23}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: Our dataset and code is available at https://github.com/Ljyustc/ SocraticLM. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 24}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We clearly describe the dataset splits, hyperparameters, training methods, and GPU devices in Appendix G. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 24}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: This paper evaluates the quality of Socratic teaching by human annotators. In order to ensure the consistency of annotators, we calculate the Kappa score and the result is 0.70, which ensures the credibility of our results. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 24}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 25}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We present the computation resources in Appendix G. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 25}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: This paper conforms with the NeurIPS Code of Ethics. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 25}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We present a \"Border Impacts\" section in Appendix I to discuss the potential positive/negative societal impacts of our work. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 25}, {"type": "text", "text": "\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 26}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: This paper poses no such risks. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 26}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The assets including data and baseline models used in this paper are properly cited. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We clearly introduce the new dataset in our paper and provide its documentation in the link https://github.com/Ljyustc/SocraticLM. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 27}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: We include the full template given to the human annotators in Appendix F. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 27}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: In this paper, we invite human annotators only to assess LLMs\u2019 outputs (i.e., give ratings). The annotators themselves are not the subjects of the evaluation and are not being tested. Besides, as shown our annotation template in Appendix F, this evaluation process does not collect personal information or privacy of the annotators, and the annotators are fully aware of the purpose of the evaluation and have consented to its use. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 28}]