[{"figure_path": "ZtTWKr51yH/figures/figures_6_1.jpg", "caption": "Figure 1: Visualization of the complementarity of CAPGD, CPGD, and LowProFool with the number of successful adversarial examples.", "description": "This figure shows a Venn diagram illustrating the number of successful adversarial examples generated by three different gradient-based attacks: CAPGD, CPGD, and LowProFool.  The largest circle represents CAPGD, indicating it produced the most successful adversarial examples.  The smaller circles for CPGD and LowProFool are mostly contained within the CAPGD circle, showing that CAPGD generated all the successful examples produced by the other two methods and a substantial number of additional, unique successful attacks.  This visually demonstrates the superior performance of CAPGD compared to its predecessors.", "section": "4 Our Constrained Adaptive PGD"}, {"figure_path": "ZtTWKr51yH/figures/figures_6_2.jpg", "caption": "Figure 2: Visualization of the complementarity of CAPGD, MOEVA, and BF* with the number of successful adversarial examples.", "description": "This figure is a Venn diagram showing the number of successful adversarial examples generated by three different attacks: CAPGD, MOEVA, and BF*.  The overlapping areas show the number of examples successfully attacked by combinations of the attacks, illustrating their complementary strengths and the overall number of unique successful attacks achieved by combining CAPGD and MOEVA.", "section": "5.1 Design of CAA"}, {"figure_path": "ZtTWKr51yH/figures/figures_8_1.jpg", "caption": "Figure 3: Impact of CAA budget on the robust accuracy for CTU dataset.", "description": "This figure shows how the robust accuracy of different models on the CTU dataset is affected by varying the budget allocated to the different components of the CAA attack. Specifically, it explores the impact of maximum epsilon perturbation, the number of CAPGD iterations (gradient attack), and the number of MOEVA iterations (search attack). The results illustrate how the effectiveness of CAA changes based on these different resource allocations.", "section": "5.3 Impact of attack budget"}, {"figure_path": "ZtTWKr51yH/figures/figures_18_1.jpg", "caption": "Figure 4: Visualization of the utility of CAA's components. For attack A (respectively B) we compute the set of clean examples CA (respectively CB)) on which the attack is successful. The percentage represents the proportion of the set CA UCB is covered by CB. CAPGD-NADA is CAPGD without adaptive step, CAPGD-NRAN is CAPGD without the random start, CAPGD-NINI is CAPGD without the clean example initialization and CAPGD NREP is CAPGD without repair at each iteration.", "description": "This figure shows a heatmap visualizing the complementarity of different components within the CAPGD attack.  Each cell represents the percentage of successful adversarial examples generated by one CAPGD variant (covered attack, A) that are also generated by another variant (covering attack, B).  The darker the cell, the higher the overlap and thus the stronger complementarity between the components.  This analysis reveals that removing any single component diminishes the overall effectiveness of the CAPGD attack.", "section": "B.1 Components of CAPGD"}, {"figure_path": "ZtTWKr51yH/figures/figures_20_1.jpg", "caption": "Figure 5: Robust accuracy with CAA with varying maximum perturbation \u03b5 budget.", "description": "This figure displays the impact of varying the maximum perturbation (epsilon) on the robust accuracy of different models using the Constrained Adaptive Attack (CAA).  Each subplot represents a different dataset (URL, LCLD, CTU, WIDS). The x-axis shows the epsilon values, and the y-axis shows the robust accuracy.  Different colored lines represent different model architectures (TabTr, RLN, VIME, STG, TabNet). The figure demonstrates how changes in the maximum allowable perturbation affect the models' robustness to adversarial attacks.", "section": "5.2 Effectiveness and efficiency of CAA"}, {"figure_path": "ZtTWKr51yH/figures/figures_21_1.jpg", "caption": "Figure 3: Impact of CAA budget on the robust accuracy for CTU dataset.", "description": "The figure analyzes how the robust accuracy of models on the CTU dataset changes when varying different aspects of the CAA attack budget.  Three subplots show the effect of adjusting the maximum perturbation (epsilon) allowed for adversarial examples, the number of iterations for the CAPGD (gradient-based) attack component, and the number of iterations for the MOEVA (search-based) attack component.  The results illustrate the tradeoffs between these different parameters in determining the effectiveness of the CAA attack.", "section": "5 CAA: an ensemble of gradient and search attacks"}, {"figure_path": "ZtTWKr51yH/figures/figures_22_1.jpg", "caption": "Figure 7: MOEVA success rate (LCLD - TabTransformer).", "description": "This figure shows the success rate of the MOEVA algorithm over generations for two different population sizes: the baseline population size (203) and a population size 10 times larger (2030).  The plot demonstrates how increasing the population size affects the convergence speed and overall success rate of finding adversarial examples for the LCLD dataset using a TabTransformer model.  The larger population converges more slowly but ultimately achieves a higher success rate.", "section": "5.3 Impact of attack budget"}, {"figure_path": "ZtTWKr51yH/figures/figures_22_2.jpg", "caption": "Figure 3: Impact of CAA budget on the robust accuracy for CTU dataset.", "description": "This figure shows the impact of different budget allocations on the robustness of the CAA attack against the CTU dataset.  It consists of four sub-figures: (a) shows the effect of varying the maximum perturbation (epsilon); (b) shows the effect of varying the number of iterations for the gradient attack component (CAPGD); (c) shows the effect of varying the number of iterations for the search attack component (MOEVA); and (d) shows the number of iterations for both CAPGD and MOEVA.", "section": "5.3 Impact of attack budget"}]