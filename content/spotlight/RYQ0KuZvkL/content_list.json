[{"type": "text", "text": "Sample Complexity Reduction via Policy Difference Estimation in Tabular Reinforcement Learning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Adhyyan Narang Andrew Wagenmaker Lillian J. Ratliff University of Washington University of California, Berkeley University of Washington adhyyan@uw.edu ajwagen@berkeley.edu ratliffl@uw.edu ", "page_idx": 0}, {"type": "text", "text": "Kevin Jamieson University of Washington jamieson@cs.washington.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In this paper, we study the non-asymptotic sample complexity for the pure exploration problem in contextual bandits and tabular reinforcement learning (RL): identifying an $\\epsilon$ -optimal policy from a set of policies $\\Pi$ with high probability. Existing work in bandits has shown that it is possible to identify the best policy by estimating only the difference between the behaviors of individual policies- which can be substantially cheaper than estimating the behavior of each policy directly \u2014yet the best-known complexities in RL fail to take advantage of this, and instead estimate the behavior of each policy directly. Does it suffice to estimate only the differences in the behaviors of policies in RL? We answer this question positively for contextual bandits, but in the negative for tabular RL, showing a separation between contextual bandits and RL. However, inspired by this, we show that it almost suffices to estimate only the differences in RL: if we can estimate the behavior of a single reference policy, it suffices to only estimate how any other policy deviates from this reference policy. We develop an algorithm which instantiates this principle and obtains, to the best of our knowledge, the tightest known bound on the sample complexity of tabular RL. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Online platforms, such as AirBnB, often try to improve their services by A/B testing different marketing strategies. Based on the inventory, their strategy could include emphasizing local listings versus tourist destinations, providing discounts for longer stays, or de-prioritizing homes that have low ratings. In order to choose the best strategy, the standard approach would be to apply each strategy sequentially and measure outcomes. However, recognize that the choice of strategy (policy) affects the future inventory (state) of the platform. This complex interaction between different strategies makes it difficult to estimate the impact of any strategy, if it were to be applied independently. To address this, we can model the platform as an Markov Decision Process (MDP) with an observed state [17, 15] and a finite set of policies $\\Pi$ corresponding to possible strategies. We wish to collect data by playing exploratory actions which will enable us to estimate the true value of each policy $\\pi\\in\\Pi$ , and identify the best policy from $\\Pi$ as quickly as possible. ", "page_idx": 0}, {"type": "text", "text": "In addition to $\\mathrm{A}/\\mathrm{B}$ testing, similar challenges arise in complex medical trials, learning robot policies to pack totes, and autonomous navigation in unfamiliar environments. All of these problems can be formally modeled as the PAC (Probably Approximately Correct) policy identification problem in reinforcement learning (RL). An algorithm is said to be $(\\epsilon,\\delta)$ -PAC if, given a set of policies $\\Pi$ ,it returns a policy $\\pi\\in\\Pi$ that performs within $\\epsilon$ of the optimal policy in $\\Pi$ , with probability $1-\\delta$ . The goal is to satisfy this condition whilst minimizing the number of interactions with the environment (the samplecomplexity). ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Traditionally, prior work has aimed to obtain minimax or worst-case guarantees for this problemguarantees that hold across all environments within a problem class. Such worst-case guarantees typically scale with the \u201csize\u201d of the environment, for example, scaling as $\\mathcal{O}(\\mathrm{poly}(S,A,\\bar{H})/\\epsilon^{2})$ ,for environments with $S$ states, $A$ actions, horizon $H$ . While guarantees of this form quantify which classes of problems are efficiently learnable, they fail to characterize the difficulty of particular problem instances-\u2014-producing the same complexity on both \u201ceasy\u201d and \u201chard\" problems that share the same \u201csize\". This is not simply a failure of analysis\u2014recent work has shown that algorithms that achieve the minimax-optimal rate could be very suboptimal on particular problem instances [46]. Motivated by this, a variety of recent work has sought to obtain instance-dependent complexity measures that capture the hardness of learning each particular problem instance. However, despite progress in this direction, the question of the optimal instance-dependent complexity has remained elusive, even in tabular settings. ", "page_idx": 1}, {"type": "text", "text": "Towards achieving instance-optimality in RL, the key question is: what aspects of a given environment must be learned, in order to choose a near-optimal policy? In the simpler bandit setting, this question has been settled by showing that it is sufficient to learn the differences between values of actions rather than learning the value of each individual action: it is only important whether a given action's value is greater or lesser than that of other actions. This observation can yield significant improvements in sample efficiency [37, 16, 13, 30]. Precisely, the best-known complexity measures in the bandit settingscale as: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi^{\\pi}-\\phi^{\\star}\\|_{\\Lambda(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\Delta(\\pi)^{2}},\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\phi^{\\pi}$ is the feature vector of action $\\pi$ $\\phi^{\\star}$ the feature vector of the optimal action, $\\Delta(\\pi)$ is the suboptimality of action $\\pi$ . Here, $\\Lambda(\\pi_{\\mathrm{exp}})$ are the covariates induced by $\\pi_{\\mathrm{exp}}$ , our distribution of exploratory actions. The denominator of this expression measures the performance gap between action $\\pi$ and the optimal action. The numerator measures the variance of the estimated (from data collected by $\\pi_{\\mathrm{exp.}}$ ) difference in values between $(\\pi,\\pi^{\\star})$ . The max over actions follows because to choose the best action, we have to rule out every sub-optimal action from the set of candidates $\\Pi$ the infimum optimizes over data collection strategies. ", "page_idx": 1}, {"type": "text", "text": "In contrast, in RL, instead of estimating the difference between policy values directly, the best known algorithms simply estimate the value of each individual policy separately and then take the difference. This obtains instance-dependent complexities which scale as follows [42]: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}+\\|\\phi_{h}^{\\star}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\Delta(\\pi)^{2}}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\phi_{h}^{\\pi}$ is the state-action visitation of policy $\\pi$ at step $h$ . Since now the difference is calculated after estimation, the variance of the difference is the sum of the individual variances of the estimates of each policy, captured in the numerator of (1.2). Comparing the numerator of (1.2) to that of (1.1) begs the question: in RL can we estimate the difference of policies directly to reduce the sample complexity of RL? ", "page_idx": 1}, {"type": "text", "text": "To motivate why this distinction is important, consider the tabular MDP example of Figure 1. In this example, the agent starts in state $s_{1}$ , takes one of three actions, and then transitions to one of states $s_{2},s_{3},s_{4}$ . Consider the policy set $\\Pi=\\{\\pi_{1},\\pi_{2}\\}$ , where $\\pi_{1}$ always plays action $a_{1}$ , and $\\pi_{2}$ is identical, except plays actions $a_{2}$ in the red states. If $\\phi_{h}^{\\tilde{\\pi}_{i}}\\in\\triangle_{S\\times A}$ denotes the state-action visitations of policy $\\pi_{i}$ at time $h=1,2$ thenwesee that $\\phi_{1}^{\\pi_{1}}=\\overline{{\\phi}}_{1}^{\\pi_{2}}$ since $\\pi_{1}$ and $\\pi_{2}$ agree on the action in $s_{1}$ But $\\phi_{2}^{\\pi_{1}}\\neq\\phi_{2}^{\\pi_{2}}$ as their actions differ on the red states. ", "page_idx": 1}, {"type": "text", "text": "Since these red states will be reached with probability at most 3e, the norm of the difference ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\|\\phi_{2}^{\\pi}-\\phi_{2}^{\\star}\\|_{\\Lambda_{2}(\\pi_{\\mathrm{exp}})^{-1}}^{2}=\\sum_{s,a}\\frac{(\\phi_{2}^{\\pi}(s,a)-\\phi_{2}^{\\star}(s,a))^{2}}{\\phi_{2}^{\\pi_{\\mathrm{exp}}}(s,a)}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "is significantly less than the sum of the individual norms ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\Vert\\phi_{2}^{\\pi}\\Vert_{\\Lambda_{2}(\\pi_{\\mathrm{exp}})^{-1}}^{2}+\\Vert\\phi_{2}^{\\star}\\Vert_{\\Lambda_{2}(\\pi_{\\mathrm{exp}})^{-1}}^{2}=\\sum_{s,a}\\frac{\\phi_{2}^{\\pi}(s,a)^{2}+\\phi^{\\star}(s,a)^{2}}{\\phi_{2}^{\\pi_{\\mathrm{exp}}}(s,a)}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "image", "img_path": "RYQ0KuZvkL/tmp/3bf85b36feddea9e55d1a75eb9302bf1bac021e3dd127c27f7f8ff4e7f8f517c.jpg", "img_caption": [], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "Figure 1: A motivating example for differences. The rewards for all actions other than the ones specified in the figure are O. Define policy set $\\Pi=\\{\\pi_{1},\\pi_{2}\\}$ so that $\\pi_{1}$ always plays $a_{1}$ , whereas $\\pi_{2}$ plays $a_{1}$ Ongreenstatesbut $a_{2}$ on red states. The difference of their state-action visitation probabilities is only non-zero in states $s_{3},s_{4}$ and are just $O(\\epsilon)$ apart. ", "page_idx": 2}, {"type": "text", "text": "Intuitively, to minimize differences $\\pi_{\\mathrm{exp}}$ can explore just states $s_{3},s_{4}$ where the policies differ, whereas minimizing the individual norms requires wasting lots of energy in state $s_{2}$ wherethetwo policies and the difference is zero. Formally: ", "page_idx": 2}, {"type": "text", "text": "Proposition 1. On the MDP and policy set II from Figure 1, we have that ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\pi\\exp}\\operatorname*{max}_{\\pi\\in\\Pi}\\|\\phi_{2}^{\\pi}\\|_{\\Lambda_{2}(\\pi_{\\mathrm{exp}})^{-1}}^{2}\\geq1\\quad a n d\\quad\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}\\ \\pi\\in\\Pi}\\|\\phi_{2}^{\\star}-\\phi_{2}^{\\pi}\\|_{\\Lambda_{2}(\\pi_{\\mathrm{exp}})^{-1}}^{2}\\leq15\\epsilon^{2}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Proposition 1 shows that indeed, the complexity of the form Equation (1.1) (generalized to RL) in terms of differences could be significantly tighter than Equation (1.2); in this case, it is a factor of $\\epsilon^{2}$ better. But achieving a sample complexity that depends on the differences requires more than just a better analysis: it requires a new estimator and an algorithm to exploit it. ", "page_idx": 2}, {"type": "text", "text": "Contributions. In this work, we aim to understand whether such a complexity is achievable in RL. Leting $\\rho_{\\Pi}$ denote the generalization of 1 1) to the RL case--that is, (1.2 but with $\\lVert\\phi_{h}^{\\pi}\\rVert_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}$ replacedby $\\|\\phi_{h}^{\\pi}-\\phi_{h}^{\\pi^{\\star}}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}$ our contributions are as folows: ", "page_idx": 2}, {"type": "text", "text": "1. In the Tabular RL case, [2] recently showed that $\\rho_{\\Pi}$ is a lower bound on the sample complexity of RL by characterizing the difficulty of learning the unknown reward function; however, they did not resolve whether it is achievable when the state-transitions are unknown as well. We provide a lower bound which demonstrates that $\\mathcal{O}(\\rho_{\\Pi})$ is not sufficient for learning with state transitions.   \n2. We provide an algorithm PERP, which first learns the behavior a particular reference policy $\\bar{\\pi}$ and then estimates the difference in behavior between $\\bar{\\pi}$ and every other policy $\\pi$ , rather than estimating the behavior of each $\\pi$ directly.   \n3. In the case of tabular RL, we show that PERP obtains a complexity that scales with $\\mathcal{O}(\\rho_{\\Pi})$ , in addition to an extra term which measures the cost of learning the behavior of the reference policy $\\bar{\\pi}$ . We argue that this additional term is critical to achieving instance-optimal guarantees in RL, and that PERP leads to improved complexities over existing work.   \n4. In the contextual bandit setting, we provide an upper bound that scales (up to lower order terms) as $\\mathcal{O}(\\rho_{\\Pi})$ for the unknown-context distribution case. This matches the lower bound from [30] for the known context distribution case, thus showing that $\\rho_{\\Pi}$ is necessary and sufficient in contextual bandits even when the context distribution is unknown. Hence, we observe a qualitative information-theoretic separation between contextual bandits and RL. ", "page_idx": 2}, {"type": "text", "text": "The key insight from our work is that it does not suffice to only learn the differences between policy values in RL, but it almost suffices to\u2014if we can learn how a single policy behaves, it suffices to learn the difference between this policy and every other policy. ", "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The reinforcement learning literature is vast, and here we focus on results in tabular RL and instancedependent guarantees in RL. ", "page_idx": 2}, {"type": "text", "text": "Minimax Guarantees Tabular RL. Finite-time minimax-style results on policy identification in tabular MDPs go back to at least the late 90s and early 2000s [24, 26, 25,8, 21]. This early work was built upon and refined by a variety of other works over the following decade [38, 4, 34, 39], leading up to works such as [28, 9], which establish sample complexity bounds of $\\mathcal{O}(S^{2}A\\cdot\\mathrm{poly}(H)/\\epsilon^{2}\\bar{)}$ More recently, [10, 11, 33] have proposed algorithms which achieve the optimal dependence of $\\mathcal{O}(S A\\cdot\\mathrm{poly}(H)/\\epsilon^{2})$ , with [11, 33] also achieving the optimal $H$ dependence. The question of regret minimization is intimately related to that of policy identification\u2014any low-regret algorithm can be used to obtain a near-optimal policy via an online-to-batch conversion [19]. Early examples of low-regret algorithms in tabular MDPs are [3, 4, 5, 48], with more recent works removing the horizon dependence or achieving the optimal lower-order terms as well [50, 51]. Recently, [6, 7] provide minimax guarantees in the multi-task RL setting as well. ", "page_idx": 3}, {"type": "text", "text": "Instance-Dependence in RL. While the problem of obtaining worst-case optimal guarantees in tabular RL is nearly closed, we are only beginning to understand what types of instance-dependent guarantees are possible. In the setting of regret minimization, [35, 14] achieve instance-optimal regret for tabular RL asymptotically. Simchowitz and Jamieson [36] show that standard optimistic algorithms achieve regret bounded as O(s,a.h \u25b3,cea), , a result later refined by [47, 12]. In setings of RL with linear function approximation, several works achieve instance-dependent regret guarantees [18, 44]. Recently, Wagenmaker and Foster [45] achieved finite-time guarantees on instance-optimal regret in general decision-making settings, a setting encompassing much of RL. ", "page_idx": 3}, {"type": "text", "text": "On the policy identification side, early works obtaining instance-dependent guarantees for tabular MDPs include [49, 20, 31, 32], but they all exhibit shortcomings such as requiring access to a generative model or lacking finite-time results. The work of Wagenmaker et al. [46] achieves a finite-time instance-dependent guarantee for tabular RL, introducing a new notion of complexity, the gap-visitation complexity. In the special case of deterministic, tabular MDPs, Tirinzoni et al. [41] show matching finite-time instance-dependent upper and lower bounds. For RL with linear function approximation, [42, 43] achieve instance-dependent guarantees on policy identification, in particular, the complexity given in (1.2), and propose an algorithm, PEDEL, which directly inspires our algorithmic approach. On the lower bound side, Al-Marjani et al. [2] show that $\\rho_{\\Pi}$ isnecessary for tabular RL, but fail to close the aforementioned gap between $\\rho_{\\Pi}$ and (1.2). We will show instead that this gap is real and both the lower bound of Al-Marjani et al. [2] and upper bound of Wagenmaker and Jamieson [42] are loose. ", "page_idx": 3}, {"type": "text", "text": "Several works on linear and contextual bandits are also relevant. In the seminal work, [37] posed the best-arm identification problem for linear bandits and beautifully argued\u2014without proof\u2014that estimating differences were crucial and that (1.1) ought to be the true sample complexity of the problem. Over time, this conjecture was affirmed and generalized [16, 13, 22]. This improved understanding of pure-exploration directly led to instance-dependent optimal linear bandit algorithms for regret [29, 27]. More recently, contextual bandits have also been given a similar treatment [40, 30]. ", "page_idx": 3}, {"type": "text", "text": "3  Preliminaries and Problem Setting ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Let $\\|x\\|_{\\Lambda}^{2}=x^{\\top}\\Lambda x$ for any $(x,\\Lambda)$ . We let $\\mathbb{E}_{\\pi}$ denote the probability measure induced by playing policy $\\pi$ in our MDP. ", "page_idx": 3}, {"type": "text", "text": "Tabular Markov Decision Processes. We study episodic, finite-horizon, time inhomogenous and tablaMrMentdb $(\\mathcal{S},\\mathring{A},H,\\{P_{h}\\}_{h=1}^{H},\\{\\nu_{h}\\}_{h=1}^{H})$ where the state space $\\boldsymbol{S}$ and action space $\\boldsymbol{\\mathcal{A}}$ are finite, $H$ is the horizon, $P_{h}\\in\\mathbb{R}^{S\\times S A}$ denote the transition matrix at stage $h$ where $[P_{h}]_{s^{\\prime},s a}=\\mathbb{P}(s_{h+1}=s^{\\prime}|s_{h}=s,a_{h}=a)$ , and $\\nu_{h}(s,a)\\in\\triangle_{[0,1]}$ denote the distribution over reward at stage $h$ when the state of the system is $s$ and action $a$ is chosen. Let $r_{h}(s,a)$ be the expectation of a reward drawn from $\\nu_{h}(s,a)$ . We assume that every episode starts in state $s_{1}$ , and that $\\nu_{h}$ and $P_{h}$ are initially unknown and must be estimated over time. ", "page_idx": 3}, {"type": "text", "text": "Let $\\pi\\,=\\,\\{\\pi_{h}\\}_{h=1}^{H}$ denote a policymapping statesto actions, so that $\\pi_{h}(s)\\;\\in\\;\\triangle_{{\\mathcal A}}$ denotes the distribution over actions for thepolicy at $(s,h)$ ; when the policy is deterministic, $\\pi_{h}(s)\\in{\\mathcal{A}}$ outputs a single action. An episode begins in state $s_{1}$ , the agent takes action $a_{1}\\sim\\pi_{1}(s_{1})$ and receives reward $R_{1}\\sim\\nu_{1}(s_{1},a_{1})$ with expectation $r_{1}(s_{1},a_{1})$ ; the environment transitions to state $s_{2}\\sim P_{h}(s_{1},a_{1})$ The process repeats until timestep $H$ , at which point the episode ends and the agent returns to state $s_{1}$ . Let $\\begin{array}{r}{V_{h}^{\\pi}(s)=\\mathbb{E}_{\\pi}[\\sum_{h^{\\prime}=h}^{H}r_{h^{\\prime}}(s_{h^{\\prime}},a_{h^{\\prime}})|s_{h}=s],}\\end{array}$ $V_{0}^{\\pi}$ the total expected reward, $V_{0}^{\\pi}:=V_{1}^{\\pi}(s_{0})$ \uff0c ", "page_idx": 3}, {"type": "text", "text": "$\\begin{array}{r}{Q_{h}^{\\pi}(s,a)=\\mathbb{E}_{\\pi}[\\sum_{h^{\\prime}=h}^{H}r_{h^{\\prime}}(s_{h^{\\prime}},a_{h^{\\prime}})|s_{h}=s,a_{h}=a]}\\end{array}$ $s$ $h$ $a$ $\\pi$ Note that we can understand these functions as $S$ and $S A$ -dimensional vectors respectively. We use $V^{\\pi}=V_{0}^{\\pi}$ when clear from context. ", "page_idx": 4}, {"type": "text", "text": "We call $w_{h}^{\\pi}\\in\\,\\triangle_{S}$ the state visitation vector at step $h$ for policy $\\pi$ , so that $w_{h}^{\\pi}(s)$ captures the probability that policy $\\pi$ would land in state $s$ at step $h$ during an episode. Let $\\pi_{h}\\in\\mathbb{R}^{S A\\times S}$ denote the policy matrix for policy $\\pi$ , that maps states to state-actions as follows ", "page_idx": 4}, {"type": "equation", "text": "$$\n[\\pi_{h}]_{(s,a),s^{\\prime}}=\\mathbb{I}(s=s^{\\prime})[\\pi_{h}(s)]_{a}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Denote $\\phi_{h}^{\\pi}\\,\\in\\,\\triangle_{S A}$ as $\\phi_{h}^{\\pi}:=\\pi_{h}w_{h}^{\\pi}$ as the state-action visitation vector: $\\phi_{h}^{\\pi}(s,a)$ measures the the probability that policy. $\\pi$ would land in state $s$ and play action $a$ at step $h$ during an episode. From these definitions, it follows that $[P_{h}\\phi_{h}^{\\pi}]_{s}=[P_{h}\\pi_{h}\\bar{w}_{h}^{\\pi}]_{s}=w_{h+1}^{\\pi}(s)$ . For policy $\\pi$ denote the covariance matrix at timestep h as An(\u03c0T) = >s,a (s, a)e(s,a)(s,\u03bca) ", "page_idx": 4}, {"type": "text", "text": "$(\\epsilon,\\delta)$ -PAC Best Policy Identification. For a collection of policies $\\Pi$ define $\\pi^{\\star}:=\\arg\\operatorname*{max}_{\\pi\\in\\Pi}V^{\\pi}$ as the optimal policy, $V^{\\star}$ its value, and $\\phi_{h}^{\\star}$ as its state-action visitation vector._ Let $\\Delta_{\\operatorname*{min}}\\ :=$ $\\mathrm{min}_{\\pi\\in\\Pi\\backslash\\{\\pi^{\\star}\\}}\\,V^{\\star}-V^{\\pi}$ in the case when $\\pi^{\\star}$ is unique, and otherwise $\\Delta_{\\mathrm{min}}:=0$ . Define $\\Delta(\\pi):=$ $\\operatorname*{max}\\{V^{\\star}-V^{\\pi},\\Delta_{\\operatorname*{min}}\\}$ Given $\\epsilon\\geq0$ $\\delta\\in(0,1)$ an algorithm is said to be $(\\epsilon,\\delta)$ -PAC if at a stopping time $\\tau$ of its choosing, it returns a policy $\\widehat{\\pi}$ which satisfies $\\Delta(\\pi)\\leq\\epsilon$ with probability $1-\\delta$ . Our goal is to obtain an $(\\epsilon,\\delta)$ -PAC algorithm that minimizes $\\tau$ . A fundamental complexity measure used throughout this work is defined as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\rho_{\\Pi}:=\\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi_{h}^{\\star}-\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})}^{2}-1}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}\\quad\\mathrm{for}\\quad\\|\\phi_{h}^{\\star}-\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}:=\\sum_{s,a}\\frac{(\\phi_{h}^{\\star}(s,a)-\\phi_{h}^{\\pi}(s,a))^{2}}{\\phi_{h}^{\\pi_{\\mathrm{exp}}}(s,a)}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where the infimum is over all exploration policies $\\pi_{\\mathrm{exp}}$ (not necessarily just those in $\\Pi$ ). Recall that for $\\epsilon=0$ , [2] showed any $(\\epsilon,\\delta)$ -PAC algorithm satisfies $\\begin{array}{r}{\\mathbb{E}[\\tau]\\ge\\rho_{\\Pi}\\log(\\frac{1}{2.4\\delta})}\\end{array}$ ", "page_idx": 4}, {"type": "text", "text": "4 What is the Sample Complexity of Tabular RL? ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we seek to understand the complexity of tabular RL. We start by showing that $\\rho_{\\Pi}$ is not sufficient. We have the following result. ", "page_idx": 4}, {"type": "text", "text": "Lemma 1. For the MDP $\\mathcal{M}$ and policy set $\\Pi$ from Figure $^{l}$ ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{I.~\\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\lVert\\phi_{h}^{\\star}-\\phi_{h}^{\\pi}\\rVert_{\\boldsymbol{\\Lambda}_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}\\le15,}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Where does the additional complexity arise on the instance of Figure 1? As described in the introduction, $\\pi_{1}$ and $\\pi_{2}$ differ only on the red states, and a complexity scaling as $\\rho_{\\Pi}$ quantifies only the difficulty of distinguishing $\\dot{\\{\\pi_{1},\\pi_{2}\\}}$ on these states. Note that on this example $\\pi_{1}$ plays the optimal action in state $s_{3}$ and a suboptimal action in state $s_{4}$ , and $\\pi_{2}$ plays a suboptimal action in $s_{3}$ and the optimal action in $s_{4}$ . The total reward of policy $\\pi_{1}$ is therefore equal to the reward achieved at state $s_{3}$ times the probability it reaches state $s_{3}$ , and the total reward of policy $\\pi_{2}$ is the reward achieved at state $s_{4}$ times the probability it reaches state $s_{4}$ . Here, $\\rho_{\\Pi}$ would quantify the difficulty of learning the reward achieved at each state. However, it fails to quantify the probability of reaching each state, since this depends on the behavior at step 1, not step 2. ", "page_idx": 4}, {"type": "text", "text": "Thus, on this example, to determine whether $\\pi_{1}$ Or $\\pi_{2}$ is optimal, we must pay some additional complexity to learn the outgoing transitions from the initial state, giving rise to the lower bound in Lemma 1. Inspecting the lower bound of [2], one realizes that the construction of this lower bound only quantifies the cost of learning the reward distributions $\\{\\nu_{h}\\}_{h}$ and not the state transition matrices $\\{P_{h}\\}_{h}$ . On examples such as Figure 1, this lower bound then does not quantify the cost of learning the probability of visiting each state, which we've argued is necessary. We therefore conclude that, while $\\rho_{\\Pi}$ may be enough for learning the rewards, it is not sufficient for solving the full tabular RL problem. Our main algorithm builds on this intuition, and, in addition to estimating the rewards, aims to estimate where policies visit as efficiently as possible. ", "page_idx": 4}, {"type": "text", "text": "4.1 Main Result ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "If $\\rho_{\\Pi}$ is not achievable as the sample complexity for Tabular RL, what is the best that we can do? In this section, we answer this question with our sample complexity bound; we later describe the algorithmic insights that enable us to achieve this result in the following section. First, for any $\\pi,\\bar{\\pi}\\in\\Pi$ ,wedefine ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{U(\\pi,\\bar{\\pi}):=\\sum_{h=1}^{H}\\!\\mathbb{E}_{s_{h}\\sim w_{h}^{\\bar{\\pi}}}[(Q_{h}^{\\pi}(s_{h},\\pi_{h}(s_{h}))-Q_{h}^{\\pi}(s_{h},\\bar{\\pi}_{h}(s_{h})))^{2}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Now, we state our main result. ", "page_idx": 5}, {"type": "text", "text": "Theorem 1. There exists an algorithm (Algorithm $I$ ) which, with probability at least 1 - 28, finds an $\\epsilon$ -optimal policy and terminates after collecting at most ", "page_idx": 5}, {"type": "text", "text": "$\\sum_{\\substack{1=1}}^{H}\\operatorname*{inf}_{\\tau\\in\\mathrm{N}}\\operatorname*{max}_{\\pi\\in\\mathrm{II}}\\frac{H^{4}\\|\\phi_{h}^{\\star}-\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi\\mathrm{exp})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}\\cdot\\iota\\beta^{2}+\\operatorname*{max}_{\\pi\\in\\mathrm{II}}\\frac{H U(\\pi,\\pi^{\\star})}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}\\log\\frac{H|\\Pi|\\iota}{\\delta}+\\frac{C_{\\mathrm{poly}}}{\\operatorname*{max}\\{\\epsilon^{5},\\Delta_{\\operatorname*{min}}^{5}\\}}$ episodes, for $\\begin{array}{r}{C_{\\mathrm{poly}}:=\\mathrm{poly}(S,A,H,\\log1/\\delta,\\iota,\\log|\\Pi|),\\beta:=C\\sqrt{\\log(\\frac{S H|\\Pi|}{\\delta}\\cdot\\frac{1}{\\Delta_{\\operatorname*{min}}\\vee\\epsilon})}}\\end{array}$ $\\begin{array}{r}{\\iota:=\\log\\frac{1}{\\Delta_{\\operatorname*{min}}\\vee\\epsilon}}\\end{array}$ ", "page_idx": 5}, {"type": "text", "text": "Theorem 1 shows that, up to terms lower-order in $\\epsilon$ and $\\Delta_{\\mathrm{min}}$ $\\rho_{\\Pi}$ is almost sufficient, if we are willing to pay for an additional term scaling as $U(\\pi,\\pi^{\\star})/{\\Delta(\\pi)^{2}}$ . Recognize the similarity of this term to the that from the performance difference lemma: if there were no square inside the expectation, the quantity $U(\\pi,\\pi^{\\star})$ would be equal to $\\Delta(\\pi)$ . However, the square may change the scaling in some instances. Below, Lemma 2 shows that there exist settings where the complexity of Theorem 1 could be significantly tighter than Equation (1.2), the complexity achieved by the PEDEL algorithm of [42]. We revisit the instance from Figure 1 to show this; recall from Lemma 1 that the first term from Theorem 1 is a universal constant for this instance. ", "page_idx": 5}, {"type": "text", "text": "Lemma 2. On MDP $\\mathcal{M}$ and policy set II from Figure $^{\\,l}$ , we have: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{l.\\ \\operatorname*{max}_{\\pi\\in\\Pi}\\frac{H U(\\pi,\\pi^{\\star})}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}=\\frac{3H}{\\epsilon},}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{2.\\ \\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\lVert\\phi_{h}^{\\pi}\\rVert_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}\\geq\\frac{H}{\\epsilon^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Furthermore, the complexity of Theorem 1 is never worse than Equation (1.2). ", "page_idx": 5}, {"type": "text", "text": "Lemma 3. For any MDP instance and policy set $\\Pi$ wehave that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname*{max}\\bigg\\{\\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi\\in\\Phi}\\frac{\\|\\phi_{h}^{\\star}-\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}},\\frac{H U(\\pi,\\pi^{\\star})}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}\\bigg\\}\\leq\\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi\\in\\Phi}\\frac{\\|\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\pi\\mathrm{fI}}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We briefy remark on the lower-order term for Theorem 1, $\\frac{C_{\\mathrm{poly}}}{\\operatorname*{max}\\{\\epsilon^{5/3},\\Delta_{\\operatorname*{min}}^{5/3}\\}}$ Note that for small $\\epsilon$ or $\\Delta_{\\mathrm{min}}$ this temwildminatdbythlaingrdrtmwhchcale $\\operatorname*{min}\\{\\epsilon^{-2},\\Delta_{\\operatorname*{min}}^{-2}\\}$ While we make no claims on the tightness of this term, we note that recent work has shown that some lower-order terms are necessary for achieving instance-optimality [45]. ", "page_idx": 5}, {"type": "text", "text": "4.2 The Main Algorithmic Insight: The Reduced- Variance Difference Estimator ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we describe how we can estimate the difference between the values of policies directly, and provide intuition for why this results in the two main terms in Theorem 1. Fix any reference policy $\\bar{\\pi}$ and logging policy $\\mu$ (neither are necessarily in $\\Pi$ ). Here $\\mu$ can be thought of as playing the role of $\\pi_{\\mathrm{exp}}$ . Or, we can consider the $\\mathrm{A}/\\mathrm{B}$ testing scenario from the introduction, where a policy $\\mu$ is taking random actions and one wishes to perform off-policy estimation over some set of policies $\\Pi$ [17, 15]. For any $s\\in S$ , we define ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\delta_{h}^{\\pi}(s):=w_{h}^{\\pi}(s)-w_{h}^{\\bar{\\pi}}(s)\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "as the difference in state-visitations of policy $\\pi$ from reference policy $\\bar{\\pi}$ ,and $\\delta_{h}^{\\pi}\\,\\in\\,\\mathbb{R}^{S}$ as the vectorization of $\\delta_{h}^{\\pi}(s^{\\prime})$ ", "page_idx": 5}, {"type": "text", "text": "Policy selection rule. First, we describe our procedure of data collection and estimation. We collect $K_{\\bar{\\pi}}$ trajectories from $\\bar{\\pi}$ and $K_{\\mu}$ trajectories from $\\mu$ and let $\\{\\widehat{w}_{h}^{\\bar{\\pi}}(s)\\}_{s,h}$ denote the empirical state visitations from playing $\\bar{\\pi}$ . From the data collected by playing $\\mu$ we construct estimates $\\{\\widehat{P}_{h}(s^{\\prime}|s,a)\\}_{s,a,s^{\\prime},h}$ of the transition matrices. Note that $\\widehat{w}_{h}^{\\bar{\\pi}}(s)$ simply counts visitations, so that $\\begin{array}{r}{\\mathbb{E}[(\\widehat{w}_{h}^{\\bar{\\pi}}(s)-w_{h}^{\\bar{\\pi}}(s))^{2}]\\leq\\frac{w_{h}^{\\bar{\\pi}}(s)}{K_{\\bar{\\pi}}}}\\end{array}$ for all $h,s$ Defne estd stevisitaons foy $\\pi$ in termsof deviations from $\\bar{\\pi}$ as $\\widehat{w}_{h}^{\\pi}:=\\widehat{w}_{h}^{\\bar{\\pi}}+\\widehat{\\delta}_{h}^{\\pi}$ . Here, $\\widehat{\\delta}_{h}^{\\pi}$ is defined recursively as: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\widehat{\\delta}_{h+1}^{\\pi}:=\\widehat{P}_{h}\\pi_{h}\\widehat{\\delta}_{h}^{\\pi}+\\widehat{P}_{h}(\\pi_{h}-\\bar{\\pi}_{h})\\widehat{w}_{h}^{\\bar{\\pi}}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Then, assuming, for simplicity, that rewards are known, we recommend the following policy: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat{\\pi}=\\arg\\underset{\\pi\\in\\Pi}{\\operatorname*{max}}\\,\\widehat{D}^{\\pi}\\qquad\\mathrm{~where~}\\qquad\\widehat{D}^{\\pi}:=\\sum_{h=1}^{H}\\langle r_{h},\\pi_{h}\\widehat{\\delta}_{h}^{\\pi}\\rangle-\\langle r_{h},(\\bar{\\pi}_{h}-\\pi_{h})\\widehat{w}_{h}^{\\pi}\\rangle}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Sufficient condition for $\\epsilon$ -optimality. Here, we show that if ", "text_level": 1, "page_idx": 6}, {"type": "equation", "text": "$$\n\\forall\\pi\\in\\Pi,\\qquad|\\widehat{D}^{\\pi}-D^{\\pi}|\\leq\\frac13\\operatorname*{max}\\{\\epsilon,\\Delta(\\pi)\\}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "then $\\widehat{\\pi}$ is $\\epsilon$ -optimal. First, write the difference between values of policies $\\pi$ and $\\bar{\\pi}$ as: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{D^{\\pi}:=V_{0}^{\\pi}-V_{0}^{\\bar{\\pi}}=\\sum_{h=1}^{H}\\langle r_{h},\\pi_{h}w_{h}^{\\pi}\\rangle-\\sum_{h=1}^{H}\\langle r_{h},\\bar{\\pi}_{h}w_{h}^{\\bar{\\pi}}\\rangle}\\\\ {=\\sum_{h=1}^{H}\\langle r_{h},\\pi_{h}\\delta_{h}^{\\pi}\\rangle-\\langle r_{h},(\\bar{\\pi}_{h}-\\pi_{h})w_{h}^{\\bar{\\pi}}\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Then, it is easy to verify that if $|\\widehat{D}^{\\pi}-D^{\\pi}|\\leq1/3\\,\\Delta(\\pi)$ then $\\widehat{D}^{\\pi^{\\star}}-\\widehat{D}^{\\pi}\\geq0$ hence, $\\widehat{\\pi}\\neq\\pi$ . Hence, under Condition (4.2), either $\\widehat{\\pi}=\\pi^{\\star}$ or or $|\\widehat{D}^{\\pi}-D^{\\pi}|\\leq\\epsilon$ In the first case, clearly $\\widehat{\\pi}$ is $\\epsilon$ -optimal. In the second case, we can add and subtract terms to write ", "page_idx": 6}, {"type": "equation", "text": "$$\nV^{\\star}-V^{\\widehat{\\pi}}\\leq|D^{\\pi^{\\star}}-\\widehat{D}^{\\pi^{\\star}}|+\\widehat{D}^{\\pi^{\\star}}-\\widehat{D}^{\\widehat{\\pi}}+|\\widehat{D}^{\\widehat{\\pi}}-D^{\\widehat{\\pi}}|\\leq\\frac{2\\epsilon}{3}+\\widehat{D}^{\\pi^{\\star}}-\\widehat{D}^{\\widehat{\\pi}}\\leq\\frac{2\\epsilon}{3}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The last inequality follows since $\\widehat{\\pi}$ maximizes ${\\widehat{D}}^{\\pi}$ . Hence, $\\widehat{\\pi}$ would be $\\epsilon$ -optimal in this case as well. ", "page_idx": 6}, {"type": "text", "text": "Sample complexity. Now, we characterize how many samples must be collected from $\\mu$ and $\\bar{\\pi}$ in order to meet Condition (4.2). After dropping some lower-order terms and unrolling the recursion (see Section A for details), we observe that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{\\delta}_{h+1}^{\\pi}-\\delta_{h+1}^{\\pi}\\approx(\\widehat{P}_{h}-P_{h})(\\phi_{h}^{\\pi}-\\phi_{h}^{\\bar{\\pi}})+P_{h}(\\pi_{h}-\\bar{\\pi}_{h})(\\widehat{w}_{h}^{\\bar{\\pi}}-w_{h}^{\\bar{\\pi}})+P_{h}\\pi_{h}(\\widehat{\\delta}_{h}^{\\pi}-\\delta_{h}^{\\pi})}\\\\ &{\\qquad\\qquad\\qquad=\\sum_{k=0}^{h}\\bigl(\\prod_{j=k+1}^{h}P_{j}\\pi_{j}\\bigr)\\bigl((\\widehat{P}_{k}-P_{k})(\\phi_{k}^{\\pi}-\\phi_{k}^{\\bar{\\pi}})+P_{k}(\\pi_{k}-\\bar{\\pi}_{k})(\\widehat{w}_{k}^{\\bar{\\pi}}-w_{k}^{\\bar{\\pi}})\\bigr).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "After manipulating this expression a bit more, we observe that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\sum_{h=1}^{H}\\langle r_{h},\\pi_{h}(\\widehat{\\delta}_{h}^{\\pi}-\\delta_{h}^{\\pi})\\rangle=\\sum_{k=0}^{H-1}\\langle V_{k+1}^{\\pi},(\\widehat{P}_{k}-P_{k})(\\phi_{k}^{\\pi}-\\phi_{k}^{\\bar{\\pi}})+P_{k}(\\pi_{k}-\\bar{\\pi}_{k})(\\widehat{w}_{k}^{\\bar{\\pi}}-w_{k}^{\\bar{\\pi}})\\rangle\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Recognizing $Q_{h}^{\\pi}=r_{h}+P_{h}^{\\top}V_{h+1}^{\\pi}$ ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\widehat{D}^{\\pi}-D^{\\pi}|=\\displaystyle\\left|\\sum_{h=1}^{H}\\langle r_{h},\\pi_{h}(\\widehat{\\delta}_{h}^{\\pi}-\\delta_{h}^{\\pi})\\rangle+\\langle r_{h},(\\pi_{h}-\\bar{\\pi}_{h})(\\widehat{w}_{h}^{\\bar{\\pi}}-w_{h}^{\\bar{\\pi}})\\rangle\\right|}\\\\ &{\\quad\\quad=\\displaystyle\\left|\\sum_{h=0}^{H-1}\\langle V_{h+1}^{\\pi},(\\widehat{P}_{h}-P_{h})(\\phi_{h}^{\\pi}-\\phi_{h}^{\\bar{\\pi}})\\rangle+\\langle r_{h}+P_{h}^{\\top}V_{h+1}^{\\pi},(\\pi_{h}-\\bar{\\pi}_{h})(\\widehat{w}_{h}^{\\bar{\\pi}}-w_{h}^{\\bar{\\pi}})\\rangle\\right|}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "We can bound this as: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\lesssim\\sqrt{H^{2}\\displaystyle\\sum_{h=0}^{H-1}\\sum_{s,a}\\frac{(\\phi_{h}^{\\pi}(s,a)-\\phi_{h}^{\\bar{\\pi}}(s,a))^{2}}{K_{\\mu}\\mu_{h}(s,a)}}+\\sqrt{\\displaystyle\\sum_{h=0}^{H-1}\\sum_{s}\\left(Q_{h}^{\\pi}(s,\\pi_{h}(s))-Q_{h}^{\\pi}(s,\\bar{\\pi}_{h}(s))\\right)^{2}\\frac{w_{h}^{\\bar{\\pi}}(s)}{K_{\\bar{\\pi}}}}}\\\\ &{=\\sqrt{H^{2}\\displaystyle\\sum_{h=0}^{H-1}\\frac{\\|\\phi_{h}^{\\pi}-\\phi_{h}^{\\bar{\\pi}}\\|_{\\Lambda_{h}(\\mu)}^{2}-1}{K_{\\mu}}}+\\sqrt{\\displaystyle\\frac{U(\\pi,\\bar{\\pi})}{K_{\\bar{\\pi}}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Here, we applied Bernstein's inequality and observed that $\\begin{array}{r}{\\sum_{s^{\\prime}}V_{h+1}^{\\pi}(s^{\\prime})^{2}P_{h}(s^{\\prime}|s,a)\\le H^{2}}\\end{array}$ .Now, we have that if ", "page_idx": 7}, {"type": "equation", "text": "$$\nK_{\\mu}\\gtrsim\\operatorname*{max}_{\\pi\\in\\Pi}\\sum_{h=0}^{H-1}\\frac{H^{2}\\|\\phi_{h}^{\\pi}-\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\mu)^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}\\qquad\\mathrm{and}\\qquad K_{\\overline{{\\pi}}}\\gtrsim\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{U(\\pi,\\bar{\\pi})}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "then Condition (4.2) holds. Notice that up to $H$ and $\\log(\\cdot)$ factors, this is precisely the sample complexity of Theorem 1 if we set ${\\bar{\\pi}}\\,=\\,\\pi^{\\star}$ and minimize over all logging/exploration policies $\\mu/\\pi_{\\mathrm{exp}}$ . Note that, if $\\bar{V}$ denotes the average reward collected from rolling out $K_{\\bar{\\pi}}$ times, then $\\begin{array}{r}{|\\bar{V}-V_{0}^{\\bar{\\pi}}|\\leq\\sqrt{\\frac{H^{2}}{K_{\\bar{\\pi}}}}}\\end{array}$ by Hoeffding's iequality Thus one could use $\\widehat{V}^{\\pi}=\\widehat{D}^{\\pi}+\\bar{V}$ as an efetive off-policy estimator. Likewise, $\\widehat{D}^{\\pi}-\\widehat{D}^{\\pi^{\\prime}}$ is an effective estimator for $V_{0}^{\\pi}-V_{0}^{\\pi^{\\prime}}$ ", "page_idx": 7}, {"type": "text", "text": "This calculation (elaborated on in Appendix A) suggests that our analysis is tight, and clearly illustrates that the $U(\\pi,\\bar{\\pi})$ term arises due to estimating the behavior of the reference policy $w_{h}^{\\bar{\\pi}}$ The $U(\\pi,\\bar{\\pi})$ term is, to the best of our knowledge, novel in the literature. More precisely, this term corresponds to the cost of estimating where $\\bar{\\pi}$ visits, if our goal is to estimate the difference in value between policy $\\pi$ and $\\bar{\\pi}$ . If, for a given state, the actions taken by $\\pi$ and $\\bar{\\pi}$ achieve the same long-term reward, then it is not critical that the frequency with which $\\bar{\\pi}$ visits this state is estimated, as it does not affect the difference in values between $\\pi$ and $\\bar{\\pi}$ ; if the actions take by $\\pi$ and $\\bar{\\pi}$ do achieve different long-term reward at $s$ , then we must estimate the behavior of each policy at this state. This is refected by the term inside the expectation of $U(\\pi,\\bar{\\pi})$ ; this will be O in the former case, and scale with the difference between long-term action reward in the latter case. ", "page_idx": 7}, {"type": "text", "text": "Additionally, note that if we had offine data from some policy $\\bar{\\pi}$ , that had been played for a long time, so that $K_{\\bar{\\pi}}\\approx\\infty$ , then we would only incur the $K_{\\mu}$ term; this is precisely $\\rho_{\\Pi}$ , but with $\\pi^{\\star}$ replaced with our reference policy $\\bar{\\pi}$ in the numerator. ", "page_idx": 7}, {"type": "text", "text": "5 Achieving Theorem 1: PERP Algorithm ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "While the above section provides intuition for where the terms in Theorem 1 come from, it does not lead to a practical algorithm. This is because the desired number of samples in Equation (4.4) are in terms of unknown quantities: $\\{||\\phi_{h}^{\\pi}-\\phi_{h}^{\\bar{\\pi}}||_{\\Lambda_{h}(\\mu)^{-1}}^{2},\\Delta(\\pi),U(\\pi,\\bar{\\pi})\\}$ ,which depend on our unknown environmentvariables $\\nu_{h},P_{h}$ ; hence, we would not know how many samples to collect. In this section, we propose an algorithm that will proceed in rounds, successively improving our estimates of these quantities. Define ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\widehat{U}_{\\ell,h}(\\pi,\\pi^{\\prime}):=\\widehat{\\mathbb{E}}_{\\pi^{\\prime},\\ell}[(\\widehat{Q}_{\\ell,h}^{\\pi}(s_{h},\\pi_{h}(s))-\\widehat{Q}_{\\ell,h}^{\\pi}(s_{h},\\pi_{h}^{\\prime}(s)))^{2}],\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\widehat{\\mathbb{E}}_{\\pi^{\\prime},\\ell}$ denotes the expectation induced playing policy $\\pi^{\\prime}$ on the MDP with transitions $\\widehat{P}_{\\ell,h}$ , and $\\widehat{Q}_{\\ell,h}^{\\pi}$ denotes the $Q$ -function of policy $\\pi$ on this same MDP. To compute $\\widehat{P}_{\\ell,h}$ , we use the standard estimator: $\\begin{array}{r}{\\widehat{P}_{\\ell,h}(s^{\\prime}\\mid s,a)=\\frac{N_{\\ell,h}(s,a,s^{\\prime})}{N_{\\ell,h}(s,a)}}\\end{array}$ 0 $N_{\\ell,h}(s,a)$ and $N_{\\ell,h}(s,a,s^{\\prime})$ the visitation countsin $\\mathfrak{D}_{\\ell,h}^{\\mathrm{ED}}$ We set $\\widehat{P}_{\\ell,h}(s^{\\prime}\\mid s,a)=\\operatorname{unif}(S)$ $N_{\\ell,h}(s,a)=0$ . The analogous estimator is used to estimate $\\widehat{r}_{\\ell,h}$ The quantity $\\phi_{h}^{\\pi}-\\phi_{h}^{\\bar{\\pi}}$ is estimated as in the previous section: $(\\pi_{h}-\\bar{\\pi}_{\\ell,h})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}+\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}$ ", "page_idx": 7}, {"type": "text", "text": "Algorithm 1 proceeds in epochs. It begins with a policy set $\\Pi_{1}$ , which contains all policies of interest, $\\Pi$ . It then gradually begins to refine this policy set, seeking to estimate the difference in values between policies in the set up to tolerance $\\epsilon_{\\ell}=2^{-\\ell}$ . To achieve this, it instantiates the intuition above. First, it chooses a reference policy $\\bar{\\pi}_{\\ell}$ , then running this estimate a sufficient number of times to estimate $\\boldsymbol{w}_{h}^{\\bar{\\pi}_{\\ell}}$ Given this estimate, it then seeks to estimae $\\delta_{h}^{\\pi}$ for each $\\pi$ in the active set of policies, $\\Pi_{\\ell}$ by colleting data covering the directions $(\\pi_{h}-{\\bar{\\pi}}_{\\ell,h}){\\widehat w}_{\\ell,h}^{\\bar{\\pi}}+\\pi_{h}{\\widehat\\delta}_{\\ell,h}^{\\pi}$ for all $\\pi\\in\\Pi_{\\ell}$ To efficiently collect this covering data, on line 12, we run a data collection procedure first developed in [42]. Finally, after estimating each $\\delta_{h}^{\\pi}$ , it estimates the differences between policy values as in (4.3), and eliminates suboptimal policies. ", "page_idx": 7}, {"type": "text", "text": "The computational complexity of PERP is poly $(S,A,H,1/\\epsilon,|\\Pi|,\\log(1/\\delta))$ .The primary contributor to the computational complexity is the the use of the Franke-Wolfe algorithm for experiment design in the OpTCoV subroutine. Lemma 37 from Wagenmaker and Pacchiano [43] shows that the number of iterations of the Franke-Wolfe algorithm is bounded polynomially in the problem parameters, ", "page_idx": 7}, {"type": "text", "text": "Algorithm 1 PERP: Policy Elimination with Reference Policy (informal) ", "page_idx": 8}, {"type": "text", "text": "Require: tolerance $\\epsilon$ , confidence $\\delta$ , policies $\\Pi$ ", "page_idx": 8}, {"type": "text", "text": "1: $\\Pi_{1}\\leftarrow\\Pi$ $\\widehat{P}_{0}\\gets$ arbitrary transition matrix   \n2: for $\\begin{array}{r}{\\ell=1,2,3,\\dots,\\lceil\\log_{2}^{\\cdot}\\frac{16}{\\epsilon}\\rceil}\\end{array}$ do   \n3: Set $\\epsilon\\ell\\gets2^{-\\ell}$   \n4: $//$ Compute new reference policy   \n5: Compute $\\widehat{U}_{\\ell-1,h}(\\pi,\\pi^{\\prime})$ as in (5.1) for all $(\\pi,\\pi^{\\prime})\\in\\Pi_{\\ell}$   \n6: Choose $\\begin{array}{r}{\\bar{\\pi}_{\\ell}\\leftarrow\\operatorname*{min}_{\\bar{\\pi}\\in\\Pi_{\\ell}}\\operatorname*{max}_{\\pi\\in\\Pi_{\\ell}}\\sum_{h=1}^{H}\\widehat{U}_{\\ell-1,h}\\big(\\pi,\\bar{\\pi}\\big)}\\end{array}$   \n7: Collect the following number of episodes from $\\bar{\\pi}_{\\ell}$ and store in dataset $\\mathfrak{D}_{\\ell}^{\\mathrm{ref}}$ ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\bar{n}_{\\ell}=\\mathcal{O}\\Big(\\operatorname*{max}_{\\pi\\in\\Pi_{\\ell}}c\\cdot\\frac{H\\widehat{U}_{\\ell-1}\\left(\\pi,\\bar{\\pi}_{\\ell}\\right)}{\\epsilon_{\\ell}^{2}}\\cdot\\log\\frac{H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}\\Big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "8: Compute $\\{\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}(s)\\}_{h=1}^{H}$ using empirical state visitation fequencies n $\\mathfrak{D}_{\\ell}^{\\mathrm{ref}}$   \n9: // Estimate Policy Differences   \n10: Initialize $\\widehat\\delta_{1}^{\\pi}\\gets0$   \n11: for $h=1,\\ldots,H$ do   \n12: Run OPTCov (Algorithm 3) to collect dataset $\\mathfrak{D}_{\\ell,h}^{\\mathrm{ED}}$ such that:   \n$\\begin{array}{r}{\\underset{\\pi\\in\\Pi_{\\ell}}{\\operatorname*{sup}}\\Vert(\\pi_{h}-\\bar{\\pi}_{\\ell,h})\\hat{w}_{\\ell,h}^{\\bar{\\pi}}+\\pi_{h}\\hat{\\delta}_{\\ell,h}^{\\pi}\\Vert_{\\Lambda_{\\ell,h}^{-1}}^{2}\\le\\epsilon_{\\ell}^{2}/H^{4}\\beta_{\\ell}^{2}\\quad\\mathrm{for}\\quad\\Lambda_{\\ell,h}=\\sum_{(s,a)\\in\\mathfrak{D}_{\\ell,h}^{\\mathrm{ED}}}e_{s a}e_{s a}^{\\top}}\\end{array}$   \nand $\\beta_{\\ell}\\leftarrow\\mathcal{O}(\\sqrt{\\log S H\\ell^{2}|\\Pi_{\\ell}|/\\delta})$   \n13: Use $\\mathfrak{D}_{\\ell,h}^{\\mathrm{ED}}$ to compute $\\widehat{P}_{\\ell,h}(s^{\\prime}|s,a)$ and $\\widehat{r}_{\\ell,h}$   \n14: Compute $\\widehat{\\delta}_{\\ell,h+1}^{\\pi}\\leftarrow\\widehat{P}_{\\ell,h}(\\pmb{\\pi}_{h}-\\bar{\\pmb{\\pi}}_{\\ell,h})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}+\\widehat{P}_{\\ell,h}\\pmb{\\pi}_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi})$   \n15: end for   \n16: // Eliminate suboptimal policies   \n17: Compute $\\begin{array}{r}{\\widehat{D}_{\\bar{\\pi}_{\\ell}}(\\pi)\\gets\\sum_{h}\\langle\\widehat{r_{\\ell,h}},\\pi_{h}\\widehat{\\delta}_{\\ell,h}\\rangle+\\sum_{h}\\langle\\widehat{r}_{\\ell,h},(\\pi_{h}-\\bar{\\pi}_{\\ell,h})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}\\rangle}\\end{array}$   \n18: Update $\\Pi_{\\ell+1}=\\Pi_{\\ell}\\backslash\\{\\pi\\in\\Pi_{\\ell}:\\operatorname*{max}_{\\pi^{\\prime}}\\widehat{D}_{\\bar{\\pi}_{\\ell}}(\\pi^{\\prime})-\\widehat{D}_{\\bar{\\pi}_{\\ell}}(\\pi)>8\\epsilon_{\\ell}\\ \\}$   \n19: if $|\\boldsymbol{\\Pi}_{\\ell+1}|=1$ then return $\\pi\\in\\Pi_{\\ell+1}$   \n20: end for   \n21: return any $\\pi\\in\\Pi_{\\ell+1}$ ", "page_idx": 8}, {"type": "text", "text": "and from the definition of this procedure given in Wagenmaker and Pacchiano [43], we see that each iteration of Franke- Wolfe has computational complexity polynomial in problem parameters. We omit several technical details from Algorithm 1 for simplicity, but present the full definition in Algorithm 2. ", "page_idx": 8}, {"type": "text", "text": "6 When is $\\rho_{\\Pi}$ Sufficient? ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Our results so far show that $\\rho_{\\Pi}$ is not in general sufficient for tabular RL. In this section, we consider several special cases where it is sufficient. ", "page_idx": 8}, {"type": "text", "text": "Tabular Contextual Bandits.  The tabular contextual bandit setting is the special case of the RL setting with $H=1$ and where the initial action does not affect the next-state transition. Theorem 2.2 of Li et al. [30] show that if the rewards distributions $\\nu(s,a)$ are Gaussian for each $(s,a)$ , where here $s$ denotes the context, any $(0,\\delta)$ -PAC algorithm requires at least $\\rho_{\\Pi}$ samples. Crucially, however, they assume that the context distribution\u2014in this case corresponding to the initial transition $P_{1}$ is known. Their algorithm makes explicit use of this fact, using this to estimate the value of $\\phi^{\\pi}$ . The following result shows that knowing the context distribution is not criticalwe can achieve a complexity of $\\mathcal{O}(\\rho_{\\Pi})$ without this prior knowledge. ", "page_idx": 8}, {"type": "text", "text": "Corollary 1. For the setting of tabular contextual bandits, there exists an algorithm such that with probabilityatleast $1-2\\delta$ aslongas $\\Pi$ contains only deterministic policies,itfinds an $\\epsilon$ -optimal policy and terminates after collecting at most the following number of samples: ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\pi_{\\mathrm{exp}}}{\\mathrm{inf}}\\underset{\\pi\\in\\Pi}{\\mathrm{max}}\\,\\frac{\\|\\phi^{\\star}-\\phi^{\\pi}\\|_{\\Lambda(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\mathrm{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}\\cdot\\beta^{2}\\log\\frac{1}{\\Delta_{\\operatorname*{min}}\\vee\\epsilon}+\\frac{C_{\\mathrm{poly}}}{\\mathrm{max}\\{\\epsilon^{5/3},\\Delta_{\\operatorname*{min}}^{5/3}\\}},}\\\\ &{\\cdot C_{\\mathrm{poly}}=\\mathrm{poly}(|\\mathcal{S}|,A,\\log1/\\delta,\\log1/(\\Delta_{\\operatorname*{min}}\\vee\\epsilon),\\log|\\Pi|)\\,a n d\\,\\beta=C\\sqrt{\\log(\\frac{S|\\Pi|}{\\delta}\\cdot\\frac{1}{\\Delta_{\\operatorname*{min}}\\vee\\epsilon})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "The theorem is proved in Appendix D, and follows from the application of our algorithm PERP to the contextual bandit problem. The key intuition behind this result is that, in the contextual case: ", "page_idx": 9}, {"type": "text", "text": "It is then possible to show that, since $\\pi_{\\mathrm{exp}}$ only has choices of which actions are taken (and cannot affethe contetdisribution, this can efurther bounded by $\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\,\\|\\phi^{\\pi}-\\phi^{\\bar{\\pi}}\\|_{\\Lambda(\\pi_{\\mathrm{exp}})^{-1}}^{2}.$ This is not true in the full MDP case, where our choice of exploration policy in $\\pi_{\\mathrm{exp}}$ could make $\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\|\\phi^{\\pi}-$ $\\phi^{\\bar{\\pi}}\\|_{\\Lambda(\\pi_{\\mathrm{exp}})^{-1}}^{2}$ $U(\\pi,\\bar{\\pi})$ bandits. This is the opposite of tabular RL, where our complexity from Theorem 1 is unchanged (as seen in Section 4.2) even if we knew the reward distribution. This shows that there is a distinct separation between instance-optimal learning in tabular RL vs contextual bandits. ", "page_idx": 9}, {"type": "text", "text": "MDPs with Action-Independent Transitions. In the special case of MDPs where the transitions do not depend on the actions selected, the complexity simplifies to $\\mathcal{O}(\\rho_{\\Pi})$ . Note that this exactly matches (up to lower order terms) the lower bound from [2]. ", "page_idx": 9}, {"type": "text", "text": "Corollary 2. Assume that all $P_{h}$ aresuchthat $P_{h}(s^{\\prime}|s,a)=P_{h}(s^{\\prime}|s,a^{\\prime})$ forall $(a,a^{\\prime})\\in A$ Then, with probability at least $1-2\\delta$ PERP (Algorithm 2) finds an e-optimal policy and terminates after collecting at most the following number of episodes: ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi\\exp}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi_{h}^{\\star}-\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}\\cdot\\iota H^{4}\\beta^{2}+\\frac{C_{\\mathrm{poly}}}{\\operatorname*{max}\\{\\epsilon^{5/3},\\Delta_{\\operatorname*{min}}^{5/3}\\}}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "for $C_{\\mathrm{poly}},\\beta$ as defined in Theorem $^{\\,l}$ ", "page_idx": 9}, {"type": "text", "text": "The intuition for Corollary 2 is similar to that of Corollary 1, and proved in Appendix E. ", "page_idx": 9}, {"type": "text", "text": "7 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we performed a fine-grained study of the instance-dependent complexity of tabular RL. We proposed a new off-policy estimator that estimates the value relative to a reference policy. We leveraged this insight to close the instance-dependent contextual bandits problem and obtained the tightest known upper bound for tabular MDPs. ", "page_idx": 9}, {"type": "text", "text": "Limitations and Future work One limitation of the present work is that PERP, in it's current form, would be too computationally expensive to run for most practical applications; enumerating the policy set $\\Pi$ is often intractable, but works in contextual bandits have avoided this issue by only relying on argmax oracles over this set [1, 30]; an interesting direction of future work would be to extend this technique to tabular RL. Extending the results from this paper to obtain refined instance-dependent bounds for linear MDPs and general function approximation is an exciting direction as well. ", "page_idx": 9}, {"type": "text", "text": "The new estimator and its improved sample complexity raise additional theoretical questions. Our upper bound has unfortunate low order terms;can these be removed? Can one show that $\\frac{U(\\pi,\\bar{\\pi})}{\\operatorname*{max}\\{\\Delta(\\pi)^{2},\\epsilon^{2}\\}}$ is unavoidable for all MDPs in general, thereby matching our upper bound? As discussed above, a few works have proven gap-dependent regret upper bounds, but we are unaware of any matching lower bounds besides over restricted classes of MDPs; can our estimator involving the differences result in even tighter instance-dependent regret bounds for MDPs? ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "AN and LJR are supported in part by ONR YIP N000142012571 and NSF CAREER 1844729. AN was supported, in part by the Amazon Hub Fellowship at the University of Washington. KJ and AW were funded in part by NSF CAREER 2141511 and NSF TRIPODS 2023239. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1]  Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, and Robert Schapire. Taming the monster: A fast and simple algorithm for contextual bandits. In International Conference on Machine Learning, pages 1638-1646. PMLR, 2014. [2]  Aymen Al-Marjani, Andrea Tirinzoni, and Emilie Kaufmann. Towards instance-optimality in online pac reinforcement learning. arXiv preprint arXiv:2311.05638, 2023. [3]  Peter Auer and Ronald Ortner. Logarithmic online regret bounds for undiscounted reinforcement learning. Advances in neural information processing systems, 19, 2006. [4]  Peter Auer, Thomas Jaksch, and Ronald Ortner. Near-optimal regret bounds for reinforcement learning. Advances in neural information processing systems, 21, 2008.   \n[5] Mohammad Gheshlaghi Azar, Ian Osband, and Remi Munos. Minimax regret bounds for reinforcement learning. In International Conference on Machine Learning, pages 263-272. PMLR, 2017.   \n[6]  Avinandan Bose, Mihaela Curmei, Daniel L. Jiang, Jamie Morgenstern, Sarah Dean, Lillian J. Ratliff, and Maryam Fazel. Initializing Services in Interactive ML Systems for Diverse Users. arXiv preprint arXiv:2312.11846, 2023. [7]  Avinandan Bose, Simon Shaolei Du, and Maryam Fazel. Offline Multi-task Transfer RL with Representational Penalization. arXiv preprint arXiv:2402.12570, 2024.   \n[8]  Ronen I Brafman and Moshe Tennenholtz. R-max-a general polynomial time algorithm for near-optimal reinforcement learning. Journal of Machine Learning Research, 3(Oct):213-231, 2002. [9]  Christoph Dann and Emma Brunskill. Sample complexity of episodic fixed-horizon reinforcement learning. Advances in Neural Information Processing Systems, 2015.   \n[10] Christoph Dann, Tor Lattimore, and Emma Brunskill. Unifying pac and regret: Uniform pac bounds for episodic reinforcement learning. Advances in Neural Information Processing Systems, 2017.   \n[11] Christoph Dann, Lihong Li, Wei Wei, and Emma Brunskill. Policy certificates: Towards accountarefrcntainItionlConferencnMachLain 1507-1516. PMLR, 2019.   \n[12] Christoph Dann, Teodor Vanislavov Marinov, Mehryar Mohri, and Julian Zimmert. Beyond value-function gaps: Improved instance-dependent regret bounds for episodic reinforcement learning. Advances in Neural Information Processing Systems, 34, 2021.   \n[13] R\u00e9my Degenne, Pierre M\u00e9nard, Xuedong Shang, and Michal Valko. Gamification of pure exploration for linear bandits. In International Conference on Machine Learning, pages 2432- 2442. PMLR, 2020.   \n[14]  Kefan Dong and Tengyu Ma. Asymptotic instance-optimal algorithms for interactive decision making. arXiv preprint arXiv:2206.02326, 2022.   \n[15] Vivek Farias, Andrew Li, Tianyi Peng, and Andrew Zheng. Markovian interference in experiments. Advances in Neural Information Processing Systems, 35:535-549, 2022.   \n[16]  Tanner Fiez, Lalit Jain, Kevin G Jamieson, and Lillian Ratliff. Sequential experimental design for transductive linear bandits. Advances in neural information processing systems, 32, 2019.   \n[17] Peter W Glynn, Ramesh Johari, and Mohammad Rasouli. Adaptive experimental design with temporal interference: A maximum likelihood approach. Advances in Neural Information Processing Systems, 33:15054-15064, 2020.   \n[18]  Jiafan He, Dongruo Zhou, and Quanquan Gu. Logarithmic regret for reinforcement learning with linear function approximation. International Conference on Machine Learning, 2021.   \n[19]  Chi Jin, Zeyuan Allen-Zhu, Sebastien Bubeck, and Michael I Jordan. Is q-learning provably efficient?InProceedingsofthe32nd International ConferenceonNeural InformationProcessing Systems, pages 4868-4878, 2018.   \n[20] Anders Jonsson, Emilie Kaufmann, Pierre Menard, Omar Darwiche Domingues, Edouard Leurent, and Michal Valko. Planning in markov decision processes with gap-dependent samle complexity. Advances in Neural Information Processing Systems, 2020.   \n[21] Sham Machandranath Kakade. On the sample complexity of rinforcement learning. PhD thesis, UCL (University College London), 2003.   \n[22]  Julian Katz-Samuels, Lalit Jain, and Kevin G Jamieson. An empirical process approach to the union bound: Practical algorithms for combinatorial and linear bandits. Advances in Neural Information Processing Systems, 33:10371-10382, 2020.   \n[23] Emilie Kaufmann, Olivier Cappe, and Aurelien Garivier. On the complexity of best-arm identification in multi-armed bandit models. The Journal of Machine Learning Research, 17(1): 1-42, 2016.   \n[24] Michael Kearns and Satinder Singh. Finite-sample convergence rates for q-learning and indirect algorithms. Advances in neural information processing systems, 11, 1998.   \n[25]  Michael Kearns and Satinder Singh. Near-optimal reinforcement learning in polynomial time. Machine learning, 49(2):209-232, 2002.   \n[26] Michael Kearns, Yishay Mansour, and Andrew Ng. Approximate planning in large pomdps via reusable trajectories. Advances in Neural Information Processing Systems, 12, 1999.   \n[27] Johannes Kirschner, Tor Lattimore, Claire Vernade, and Csaba Szepesvari. Asymptotically optimal information-directed sampling. In Conference on Learning Theory, pages 2777-2821. PMLR, 2021.   \n[28]  Tor Lattimore and Marcus Hutter. Pac bounds for discounted mdps. In International Conference on Algorithmic Learning Theory, pages 320-334. Springer, 2012.   \n[29]  Tor Lattimore and Csaba Szepesvari. The end of optimism? an asymptotic analysis of finitearmed linear bandits. In Artificial Intelligence and Statistics, pages 728-737. PMLR, 2017.   \n[30]  Zhaoqi Li, Lillian Ratliff, Houssam Nassif, Kevin Jamieson, and Lalit Jain. Instance-optimal PAC algorithms for contextual bandits. Advances in Neural Information Processing Systems, 2022.   \n[31]  Aymen Al Marjani and Alexandre Proutiere. Adaptive sampling for best policy identification in markov decision processes. International Conference on Machine Learning, 2021.   \n[32]  Aymen Al Marjani, Aur\u00e9lien Garivier, and Alexandre Proutiere. Navigating to the best policy in markov decision processes. Neural Information Processing Systems, 2021.   \n[33] Pierre Menard, Omar Darwiche Domingues, Anders Jonsson, Emilie Kaufmann, Edouard Leurent, and Michal Valko. Fast active learning for pure exploration in reinforcement learning. International Conference on Machine Learning, 2021.   \n[34]  Remi Munos and Csaba Szepesvari. Finite-time bounds for ftted value iteration. Journal of Machine Learning Research, 9(5), 2008.   \n[35] Jungseul Ok, Alexandre Proutiere, and Damianos Tranos. Exploration in structured reinforcement learning. arXiv preprint arXiv: 1806.00775, 2018.   \n[36]  Max Simchowitz and Kevin G Jamieson. Non-asymptotic gap-dependent regret bounds for tabular mdps. Advances in Neural Information Processing Systems, 32, 2019.   \n[37] Marta Soare, Alessandro Lazaric, and Remi Munos. Best-arm identification in linear bandits. Advances in Neural Information Processing Systems, 27, 2014.   \n[38]  Alexander L Strehl, Lihong Li, Eric Wiewiora, John Langford, and Michael L Littman. Pac model-free reinforcement learning. In Proceedings of the 23rd international conference on Machine learning, pages 881-888, 2006.   \n[39]  Alexander L Strehl, Lihong Li, and Michael L Littman. Reinforcement learning in finite mdps: Pac analysis. Journal of Machine Learning Research, 10(11), 2009.   \n[40]  Andrea Tirinzoni, Matteo Pirotta, Marcello Restelli, and Alessandro Lazaric. An asymptotically optimal primal-dual incremental algorithm for contextual linear bandits. Neural Information Processing Systems, 2020.   \n[41]  Andrea Tirinzoni, Aymen Al-Marjani, and Emilie Kaufmann. Near instance-optimal pac reinforcement learning for deterministic mdps. Neural Information Processing Systems, 2022.   \n[42]  Andrew Wagenmaker and Kevin G Jamieson. Instance-dependent near-optimal policy identification in linear mdps via online experiment design. Advances in Neural Information Processing Systems, 35:5968-5981, 2022.   \n[43]  Andrew Wagenmaker and Aldo Pacchiano. Leveraging offline data in online reinforcement learning. International Conference of Machine Learning, 2023.   \n[44]  Andrew Wagenmaker, Yifang Chen, Max Simchowitz, Simon S Du, and Kevin Jamieson. Firstorder regret in reinforcement learning with linear function approximation: A robust estimation approach. International Conference of Machine Learning, 2022.   \n[45]  Andrew J Wagenmaker and Dylan J Foster. Instance-optimality in interactive decision making: Toward a non-asymptotic theory. In The Thirty Sixth Annual Conference on Learning Theory, pages 1322-1472. PMLR, 2023.   \n[46]  Andrew J Wagenmaker, Max Simchowitz, and Kevin Jamieson. Beyond no regret: Instancedependent pac reinforcement learning. In Conference on Learning Theory, pages 358-418. PMLR, 2022.   \n[47] Haike Xu, Tengyu Ma, and Simon S Du. Fine-grained gap-dependent bounds for tabular mdps via adaptive multi-step bootstrap. Conference on Learning Theory, 2021.   \n[48]  Andrea Zanette and Emma Brunskill. Tighter problem-dependent regret bounds in reinforcement learning without domain knowledge using value function bounds. In International Conference on Machine Learning, pages 7304-7312. PMLR, 2019.   \n[49]  Andrea Zanette, Mykel J Kochenderfer, and Emma Brunskill. Almost horizon-free structureaware best policy identification with a generative model. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.   \n[50] Zihan Zhang, Xiangyang Ji, and Simon S Du. Is reinforcement learning more diffcult than bandits? a near-optimal algorithm escaping the curse of horizon. Conference on Learning Theory, 2021.   \n[51] Zihan Zhang, Yuxin Chen, Jason D Lee, and Simon S Du. Settling the sample complexity of online reinforcement learning. arXiv preprint arXiv:2307.13586, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Contents ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "1Introduction ", "page_idx": 13}, {"type": "text", "text": "2Related Work 3 ", "page_idx": 13}, {"type": "text", "text": "3  Preliminaries and Problem Setting ", "page_idx": 13}, {"type": "text", "text": "What is the Sample Complexity of Tabular RL? 5   \n4.1Main Result 6   \n4.2 The Main Algorithmic Insight: The Reduced-Variance Difference Estimator 6 ", "page_idx": 13}, {"type": "text", "text": "5 Achieving Theorem 1: PERP Algorithm 8 ", "page_idx": 13}, {"type": "text", "text": "6 When is $\\rho_{\\Pi}$ Sufficient? 9 ", "page_idx": 13}, {"type": "text", "text": "7Discussion 10 ", "page_idx": 13}, {"type": "text", "text": "A   Understanding the origins of $U(\\pi,\\bar{\\pi})$ 15 ", "page_idx": 13}, {"type": "text", "text": "BTabular MDPs: Comparison with Prior Work and Lower Bounds 17   \nB.1 Comparison with complexities from prior work 18   \nB.2Lower bound 20   \nC Tabular MDP Upper Bound 20   \nC.1Notation 20   \nC.2 Technical Results 22   \nC.3 Concentration Arguments and Good Events 24   \nC.4 Estimation of Reference Policy and Values . 30   \nC.5 Correctness and Sample Complexity 35 ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "D Tabular Contextual Bandits: Upper Bound 37 ", "page_idx": 13}, {"type": "text", "text": "E MDPs with Action-Independent Transitions 40 ", "page_idx": 13}, {"type": "text", "text": "FTabularFrankeWolfe 41   \nF.1 Data Conditioning . 44   \nF.2 Online Frank-Wolfe 47   \nF.3Pruning Hard-to-Reach States 49 ", "page_idx": 13}, {"type": "table", "img_path": "RYQ0KuZvkL/tmp/ed54f16e9d2bbf5c124e1686fd6e35f0ba471deb2d98b4508d4d8ab46cc01da9.jpg", "table_caption": ["Table 1: Table of notation used in the paper "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "A  Understanding the origins of $U(\\pi,\\bar{\\pi})$ ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "This section is inspired by the exposition of Soare et al. [37] for justifying the sample complexity of linear bandits. Fix a reference policy $\\bar{\\pi}$ and some (stochastic) logging policy $\\mu$ . For $K\\,\\in\\,\\mathbb{N}$ to be determined later, roll out $\\bar{\\pi}~K$ times and compute the empirical state visitations $\\widehat{w}_{h}^{\\bar{\\pi}}(s)\\,=$ $\\begin{array}{r}{\\frac{1}{K}\\sum_{k=1}^{K}\\sum_{s,h}{\\mathbf{1}\\{s_{h}^{k}=s\\}}}\\end{array}$ Also rll out $\\mu\\,K$ times andcmput tempirical ransition probabiies $\\begin{array}{r}{\\widehat{P}_{h}(s^{\\prime}|s,a)=\\frac{\\sum_{k=1}^{K}\\mathbf{1}\\{(s_{h}^{k},a_{h}^{k},s_{h+1}^{k})=(s,a,s^{\\prime})\\}}{\\sum_{k=1}^{K}\\mathbf{1}\\{(s_{h}^{k},a_{h}^{k})=(s,a)\\}}}\\end{array}$ For auy $\\pi\\neq\\bar{\\pi}$ $\\{\\widehat{P}_{h}(s^{\\prime}|s,a)\\}_{s,a,s^{\\prime},h}$ to compute $\\widehat{w}_{h}^{\\pi}(s)$ .With $\\delta_{h+1}^{\\pi}:=\\bar{w}_{h+1}^{\\pi}-\\bar{w}_{h+1}^{\\bar{\\pi}}=P_{h}\\pi_{h}w_{h}^{\\pi}-P_{h}\\bar{\\pi}_{h}w_{h}^{\\bar{\\pi}}=P_{h}\\pi_{h}\\delta_{h}^{\\pi}+P_{h}(\\pi_{h}-\\bar{\\pi}_{h})w_{h}^{\\bar{\\pi}}$ set ", "page_idx": 14}, {"type": "equation", "text": "$$\nD(\\pi)=V_{0}^{\\pi}-V_{0}^{\\bar{\\pi}}=\\sum_{h=1}^{H}\\langle r_{h},\\pi_{h}w_{h}^{\\pi}-\\bar{\\pi}_{h}w_{h}^{\\bar{\\pi}}\\rangle=\\sum_{h=1}^{H}\\langle r_{h},\\pi_{h}\\delta_{h}^{\\pi}\\rangle+\\langle r_{h},(\\pi_{h}-\\bar{\\pi}_{h})w_{h}^{\\bar{\\pi}}\\rangle\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and also defne the empirical counterparts $\\widehat{\\delta}_{h+1}^{\\pi}:=\\widehat{P}_{h}\\pi_{h}\\widehat{\\delta}_{h}^{\\pi}+\\widehat{P}_{h}(\\pi_{h}-\\bar{\\pi}_{h})\\widehat{w}_{h}^{\\bar{\\pi}}$ with ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\widehat{D}(\\pi)=\\sum_{h=1}^{H}\\langle r_{h},\\pi_{h}\\widehat{\\delta}_{h}^{\\pi}\\rangle+\\langle r_{h},(\\pi_{h}-\\bar{\\pi}_{h})\\widehat{w}_{h}^{\\bar{\\pi}}\\rangle.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "If $\\widehat{\\pi}=\\arg\\operatorname*{max}_{\\pi\\in\\Pi}\\widehat{D}(\\pi)$ , how large must $K$ be to ensure that $\\widehat{\\pi}=\\pi^{\\star}:=\\arg\\operatorname*{max}_{\\pi\\in\\Pi}D(\\pi)=$ arg $\\operatorname*{max}_{\\pi\\in\\Pi}V_{0}^{\\pi}?$ ", "page_idx": 15}, {"type": "text", "text": "Assume at time $h\\,=\\,0$ all policies are initialized arbitrarily in some state $s_{0}$ so that $\\widehat{P}_{0}\\big(s^{\\prime}|s_{0},a\\big)$ simply defines the initial empirical state distribution at time $h=1$ . Let $\\widehat{w}_{0}^{\\pi}(s_{0})=w_{0}^{\\pi}(s_{0})=1$ We can then unroll the recursion for $h=0,\\ldots,H-1$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\delta}_{h+1}^{\\pi}-\\delta_{h+1}^{\\pi}=\\hat{P}_{h}\\pi_{h}\\hat{\\delta}_{h}^{\\pi}+\\hat{P}_{h}(\\pi_{h}-\\pi_{h})\\hat{w}_{h}^{\\pi}-\\delta_{h+1}^{\\pi}}\\\\ &{\\quad=(\\hat{P}_{h}-P_{h})\\pi_{h}\\hat{\\delta}_{h}^{\\pi}+(\\hat{P}_{h}-P_{h})(\\pi_{h}-\\pi_{h})w_{h}^{\\pi}+P_{h}(\\pi_{h}-\\pi_{h})(\\hat{w}_{h}^{\\pi}-w_{h}^{\\pi})+P_{h}\\pi_{h}(\\hat{\\delta}_{h}^{\\pi}-\\delta_{h}^{\\pi})}\\\\ &{\\quad\\quad\\quad+(\\frac{\\hat{P}_{h}-P_{h})\\pi_{h}(\\hat{\\delta}_{h}^{\\pi}-\\delta_{h}^{\\pi})+(\\hat{P}_{h}-P_{h})(\\pi_{h}-\\pi_{h})(\\hat{w}_{h}^{\\pi}-w_{h}^{\\pi})}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad}\\\\ &{\\approx(\\hat{P}_{h}-P_{h})(\\phi_{k}^{\\pi}-\\phi_{k}^{\\pi})+P_{h}(\\pi_{h}-\\pi_{h})(\\hat{w}_{h}^{\\pi}-w_{h}^{\\pi})+P_{h}\\pi_{h}(\\hat{\\delta}_{h}^{\\pi}-\\delta_{h}^{\\pi})}\\\\ &{\\approx\\displaystyle\\sum_{i=0}^{h}\\binom{h}{j=h-i}P_{j}\\pi_{j})\\big((\\hat{P}_{h-i}-P_{h-i})(\\phi_{h-i}^{\\pi}-\\phi_{h-i}^{\\pi})+P_{h-i}(\\pi_{h-i}-\\pi_{h-i})(\\hat{w}_{h-i}^{\\pi}-w_{h-i}^{\\pi})\\big)}\\\\ &{\\quad=\\displaystyle\\sum_{k=0}^{h}\\binom{h}{j=k+1}P_{j}\\pi_{j}\\big((\\hat{P}_{k}-P_{k})(\\phi_{k}^{\\pi}-\\phi_{k}^{\\pi})+P_{k}(\\pi_{k}-\\pi_ \n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where we recall $\\phi_{k}^{\\pi}=\\pi_{k}w_{k}^{\\pi}$ If $\\epsilon_{k+1}:=(\\widehat{P}_{k}-P_{k})(\\pmb{\\pi}_{h}w_{k}^{\\pi}-\\bar{\\pmb{\\pi}}w_{k}^{\\bar{\\pi}})+P_{k}(\\pmb{\\pi}_{k}-\\bar{\\pmb{\\pi}}_{k})(\\widehat{w}_{k}^{\\bar{\\pi}}-w_{k}^{\\bar{\\pi}})$ then ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{h=1}^{H}\\langle r_{h},\\pi_{h}(\\widehat{\\delta}_{h}^{\\pi}-\\delta_{h}^{\\pi})\\rangle=\\displaystyle\\sum_{h=1}^{H}\\displaystyle\\sum_{k=0}^{h-1}\\langle r_{h},\\pi_{h}\\Big(\\displaystyle\\prod_{j=k+1}^{h-1}P_{j}\\pi_{j}\\Big)\\epsilon_{k+1}\\rangle}\\\\ &{\\displaystyle=\\sum_{k=0}^{H-1}\\displaystyle\\sum_{h=k+1}^{H}\\langle r_{h},\\pi_{h}\\Big(\\displaystyle\\prod_{j=k+1}^{h-1}P_{j}\\pi_{j}\\Big)\\epsilon_{k+1}\\rangle=\\displaystyle\\sum_{k=0}^{H-1}\\langle V_{k+1}^{\\pi},\\epsilon_{k+1}\\rangle}\\\\ &{\\displaystyle=\\sum_{k=0}^{H-1}\\langle V_{k+1}^{\\pi},(\\widehat{P}_{k}-P_{k})(\\phi_{k}^{\\pi}-\\phi_{k}^{\\pi})+P_{k}(\\pi_{k}-\\bar{\\pi}_{k})(\\widehat{w}_{k}^{\\bar{\\pi}}-w_{k}^{\\bar{\\pi}})\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Finally, we use these calculations to compute the deviation ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\widehat{D}(\\tau)-D(\\tau)=}&{\\frac{\\tau}{\\displaystyle\\int_{\\tau}}\\Big(r_{1},\\pi_{1}(\\widehat{\\delta}_{u}^{t}-\\widehat{\\delta}_{u}^{t})+\\Big\\langle r_{1},(r_{1}-\\widehat{\\delta}_{u})(\\widehat{\\delta}_{u}^{t}-\\kappa_{1}^{*})\\Big\\rangle\\Big)}\\\\ &{=}&{\\frac{\\tau}{\\displaystyle\\int_{\\tau}}\\Big[\\widehat{V}_{u,\\tau}^{t}\\big(\\widehat{\\delta}_{u}^{t}-r_{1}\\big)(\\widehat{\\delta}_{u}^{t})\\Big]+\\Big\\langle r_{1}+\\widehat{P}_{u}^{t}\\big\\rangle_{\\displaystyle{\\mathbb{R}_{\\tau}^{t}}^{2}+\\widehat{\\delta}_{u}^{t}}\\Big\\rangle}\\\\ &{\\quad-\\frac{\\tau}{\\displaystyle\\int_{\\tau}}\\Big(\\widehat{V}_{u,\\tau}^{t}\\big)\\Big(\\widehat{\\delta}_{u}^{t}-r_{1}\\big)(\\widehat{\\delta}_{u}^{t})\\Big\\langle\\sigma_{1}^{*}-\\widehat{\\delta}_{u}^{t}\\big\\rangle+}\\\\ &{\\quad\\quad\\sum_{k=1}^{M}\\Big(\\widehat{V}_{u,\\tau}^{t}\\big)\\Big(\\widehat{\\delta}_{u}^{t}-r_{k,1}\\big)(\\widehat{\\delta}_{u}^{t})\\Big\\langle\\sigma_{1}^{*}-r_{k,1}\\big(\\widehat{\\delta}_{u}^{t}-r_{1}\\big)\\Big\\rangle}\\\\ &{=\\displaystyle\\sum_{k=0}^{M}\\sum_{\\sigma\\in\\mathcal{N}_{s}}\\Big\\langle\\widehat{V}_{u,\\tau}^{t}\\big(\\widehat{\\delta}_{u}^{t}\\big)\\Big\\rangle\\Big(\\widehat{\\delta}_{u}^{t}\\Big)\\Big(\\widehat{\\delta}_{u}^{t}\\Big)-\\frac{\\sigma^{*}}{\\displaystyle\\int_{\\tau}}\\Big(\\widehat{V}_{u,\\tau}^{t}\\big)\\Big\\rangle}\\\\ &{\\quad-\\frac{\\tau}{\\displaystyle\\int_{\\tau}}\\sum_{k=0}^{M}\\Big(\\widehat{\\delta}_{u}^{t}\\big)\\Big(\\widehat{\\delta}_{u,\\tau}^{t}\\big(\\delta}\\big)-\\widehat{V}_{u}^{t}\\big(\\widehat{\\delta}_{u}^{t}\\big)\\Big)(\\widehat{\\delta}_{u}^{t})\\Big(-r_{k,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "image", "img_path": "RYQ0KuZvkL/tmp/56bed4119c2882518da785cd39807b136e0e1702627e3ce01a0bfa003c25d833.jpg", "img_caption": [], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "Figure 2: A motivating example for differences. All rewards other than the ones specified in the figure are O. ", "page_idx": 16}, {"type": "text", "text": "Applying $\\begin{array}{r}{\\sum_{s^{\\prime}}V_{h+1}^{\\pi}(s^{\\prime})^{2}P_{h}(s^{\\prime}|s,a)\\le H^{2}}\\end{array}$ , we observe that if ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{K\\geq\\underset{\\mu,\\bar{\\pi}}{\\operatorname*{min}}\\operatorname*{max}_{\\pi}H^{2}\\displaystyle\\sum_{h=1}^{H-1}\\frac{\\sum_{s,a}(\\phi_{h}^{\\pi}(s,a)-\\phi_{h}^{\\bar{\\pi}}(s,a))^{2}/\\mu_{h}(s,a)}{\\Delta(\\pi)^{2}}}\\\\ &{\\qquad+\\displaystyle\\sum_{h=1}^{H-1}\\frac{\\sum_{s}\\left(Q_{h}^{\\pi}(s,\\pi_{h}(s))-Q_{h}^{\\pi}(s,\\bar{\\pi}_{h}(s))\\right)^{2}w_{h}^{\\bar{\\pi}}(s)}{\\Delta(\\pi)^{2}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and we employ the minimizers $\\mu,{\\bar{\\pi}}$ to collect data, then $\\widehat{D}(\\pi)\\,-\\,D(\\pi)\\,\\,<\\,\\,\\Delta(\\pi)$ and $\\widehat{\\pi}\\ =$ arg $\\mathrm{max}_{\\pi\\in\\Pi}\\,\\widehat{D}(\\pi)\\,=\\,\\mathrm{arg}\\,\\mathrm{max}_{\\pi\\in\\Pi}\\,D(\\pi)$ . Notice that up to $H$ and log factors, this is precisely the sample complexity of our algorithm. A natural candidate for $\\bar{\\pi}$ is $\\pi^{\\star}$ so that the first term matches the lower bound of [2]. ", "page_idx": 16}, {"type": "text", "text": "On the other hand, suppose we used the data from the logging policy $\\mu$ to compute the empirical state visitations $\\widehat{w}_{h}^{\\pi}$ for all $\\pi\\in\\Pi$ and set $\\begin{array}{r}{\\widehat{\\boldsymbol{\\pi}}=\\arg\\operatorname*{max}_{\\boldsymbol{\\pi}\\in\\Pi}\\sum_{h=1}^{H}\\langle\\boldsymbol{r}_{h},\\boldsymbol{\\pi}\\widehat{w}_{h}^{\\pi}\\rangle=:\\widehat{V}_{0}^{\\pi}}\\end{array}$ Using the same techniques as above, it is straightforward to show that if ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{w}_{h+1}^{\\pi}-w_{h+1}^{\\pi}=\\hat{P}_{h}\\pi_{h}\\hat{w}_{h}^{\\pi}-P_{h}\\pi_{h}w_{h}^{\\pi}}\\\\ &{\\qquad\\qquad\\qquad=(\\hat{P}_{h}-P_{h}+P_{h})\\pi_{h}(\\hat{w}_{h}^{\\pi}-w_{h}^{\\pi}+w_{h}^{\\pi})-P_{h}\\pi_{h}w_{h}^{\\pi}}\\\\ &{\\qquad\\qquad\\qquad=(\\hat{P}_{h}-P_{h})\\pi_{h}w_{h}^{\\pi}+P_{h}\\pi_{h}(\\hat{w}_{h}^{\\pi}-w_{h}^{\\pi})+\\underbrace{(\\hat{P}_{h}-P_{h})\\pi_{h}(\\hat{w}_{h}^{\\pi}-w_{h}^{\\pi})}_{\\mathrm{Low~order~terms~}\\approx0}}\\\\ &{\\qquad\\qquad\\approx\\displaystyle\\sum_{i=0}^{h}\\Big(\\prod_{j=h-i+1}^{h}P_{j}\\pi_{j})(\\hat{P}_{h-i}-P_{h-i})\\pi_{h-i}w_{h-i}^{\\pi}}\\\\ &{\\qquad\\qquad\\qquad\\displaystyle\\sum_{i=0}^{h}\\Big(\\prod_{j=k+1}^{h}P_{j}\\pi_{j})(\\hat{P}_{k}-P_{k})\\pi_{k}w_{k}^{\\pi}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and we employ the minimizer $\\mu$ to collect data, then $\\widehat{V}_{0}^{\\pi}-V_{0}^{\\pi}\\le\\Delta(\\pi)$ and $\\widehat{\\pi}=\\arg\\operatorname*{max}_{\\pi\\in\\Pi}\\widehat{V}_{0}^{\\pi}=$ arg $\\operatorname*{max}_{\\pi\\in\\Pi}V_{0}^{\\pi}$ ", "page_idx": 16}, {"type": "text", "text": "B Tabular MDPs: Comparison with Prior Work and Lower Bounds ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "lustrative Family of MDP Instances  Recall the family of MDP instances in the introduction (visualized in Figure 2 for ease of reference). The family of MDPs is parameterized by $\\epsilon,\\epsilon_{1},\\epsilon_{2}>0$ with $H=2$ $\\bar{S}=\\{s_{1},s_{2},s_{3},s_{4}\\}$ , and $\\pmb{\\mathcal{A}}=\\{a_{1},a_{2},a_{3}\\}$ , which start in state $s_{0}$ and are defined as: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P_{1}(s_{2}\\mid s_{1},a_{1})=1-3\\epsilon,\\quad P_{1}(s_{3}\\mid s_{1},a_{1})=\\epsilon_{1},\\quad P_{1}(s_{4}\\mid s_{1},a_{1})=\\epsilon_{2}}\\\\ &{P_{1}(s_{3}\\mid s_{1},a_{2})=P_{1}(s_{4}\\mid s_{1},a_{3})=1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We define the reward function so that all rewards are O except $r_{1}(s_{1},a_{1})=r_{2}(s_{3},a_{1})=r_{2}(s_{4},a_{2})=$ 1 for all $a$ ", "page_idx": 16}, {"type": "text", "text": "Let $\\mathcal{M}$ denote the MDP above with $\\epsilon_{1}=2\\epsilon,\\epsilon_{2}=\\epsilon$ , and $\\mathcal{M}^{\\prime}$ the MDP above with $\\epsilon_{1}=\\epsilon,\\epsilon_{2}=2\\epsilon$ ", "page_idx": 16}, {"type": "text", "text": "Let $\\Pi=\\{\\pi_{1},\\pi_{2}\\}$ denote some set of policies. Let $\\pi_{1}$ denote the policy which always plays $a_{1}$ and $\\pi_{2}$ the policy which plays $a_{1}$ at green states and $a_{2}$ at red states i.e $\\bar{\\pi_{2}}(s_{1})=\\pi_{2}(s_{2})\\bar{=}\\,a_{1}$ and $\\pi_{2}(s_{3})=\\pi_{2}(s_{4})=a_{2}$ ", "page_idx": 17}, {"type": "text", "text": "Now note that $V_{0}^{\\mathcal{M},\\pi_{1}}=1+2\\epsilon,V_{0}^{\\mathcal{M},\\pi_{2}}=1+\\epsilon,V_{0}^{\\mathcal{M}^{\\prime},\\pi_{1}}=1+\\epsilon,\\mathrm{and}\\,V_{0}^{\\mathcal{M}^{\\prime},\\pi_{2}}=1+2$ ", "page_idx": 17}, {"type": "text", "text": "B.1  Comparison with complexities from prior work ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "The lemma below shows that the upper bound presented in Theorem 1 is smaller than that of PEDEL from Theorem 1 of [42] for all MDP instances. ", "page_idx": 17}, {"type": "text", "text": "Lemma 4. For any MDP instance and policy set $\\Pi$ wehave that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{I.}&{\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})}^{2}-1}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\\geq\\frac{1}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\nH^{4}\\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi\\mathrm{exp}}\\,\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi_{h}^{\\star}-\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi\\mathrm{exp})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\\le4H^{4}\\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi\\mathrm{exp}}\\,\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi\\mathrm{exp})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{{3}.}&{\\frac{H U(\\pi,\\pi^{\\star})}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\\leq H^{4}\\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})}^{2}-1}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. Proof of Claim 1. Note that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\Vert\\phi_{h}^{\\pi}\\Vert_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}=\\sum_{s,a}\\frac{\\phi_{h}^{\\pi}(s,a)^{2}}{\\phi_{h}^{\\pi_{\\mathrm{exp}}}(s,a)}\\geq\\operatorname*{inf}_{\\lambda\\in\\Delta_{S A}}\\sum_{s,a}\\frac{\\phi_{h}^{\\pi}(s,a)^{2}}{\\lambda_{s,a}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "In order to solve this optimization problem, we can consider the KKT conditions. We can verify from stationarity that atotimality, $\\begin{array}{r}{\\bar{\\lambda}_{s,a}=\\frac{\\phi_{h}^{\\pi}(s,a)}{\\sqrt{\\beta}}}\\end{array}$ for some constant $\\beta>0$ But since $\\lambda_{s,a}$ mus live in the simplex $\\Delta_{S A}$ , and since $\\phi_{h}^{\\pi}(s,a)$ is itself a distribution over ${\\mathcal{S}}\\times{\\mathcal{A}}$ it follows that $\\beta=1$ must be true. Plugging this optimal value into the above, we obtain that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\|\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}\\geq\\operatorname*{inf}_{\\lambda\\in\\Delta_{S A}}\\sum_{s,a}\\frac{\\phi_{h}^{\\pi}(s,a)^{2}}{\\lambda_{s,a}}=1\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\\geq\\frac{1}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "directly follows from the above. ", "page_idx": 17}, {"type": "text", "text": "Proof of Claim 2. From the triangle inequality, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{inf}\\displaystyle\\operatorname*{max}_{\\pi\\exp\\pi\\in\\Pi}\\displaystyle\\frac{\\|\\phi_{h}^{\\star}-\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}}^{2}(\\pi_{\\exp})^{-1}}{\\mathrm{~max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}}\\\\ &{\\le2\\displaystyle\\operatorname*{inf}_{\\pi\\exp\\pi\\in\\Pi}\\displaystyle\\operatorname*{max}_{\\operatorname*{max}\\left\\{\\frac{\\|\\phi_{h}^{\\star}\\|_{\\Lambda_{h}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}+\\frac{\\|\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}}^{2}(\\pi_{\\exp})^{-1}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\\right\\}}\\\\ &{\\le2\\displaystyle\\operatorname*{inf}_{\\pi\\exp\\pi\\in\\Pi}\\displaystyle\\operatorname*{max}_{\\operatorname*{max}\\left\\{\\frac{\\|\\phi_{h}^{\\star}\\|_{\\Lambda_{h}}^{2}(\\pi_{\\exp})^{-1}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi^{\\star})^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}+\\frac{\\|\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}}^{2}(\\pi_{\\exp})^{-1}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\\right\\}}\\\\ &{\\le4\\displaystyle\\operatorname*{inf}_{\\pi\\exp\\pi\\in\\Pi}\\displaystyle\\frac{\\|\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}}^{2}(\\pi_{\\exp})^{-1}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}+\\frac{\\|\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}}^{2}(\\pi_{\\exp})^{-1}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where we have used that $\\Delta(\\pi)\\geq\\Delta(\\pi^{\\star})$ for all $\\pi$ . Plugging this bound into the expression from (2) from the Lemma statement completes the proof. ", "page_idx": 17}, {"type": "text", "text": "Proof of Claim 3. We have that ", "text_level": 1, "page_idx": 18}, {"type": "equation", "text": "$$\nH U(\\pi,\\pi^{\\star})=H\\sum_{h=1}^{H}\\mathbb{E}_{s_{h}\\sim w_{h}^{\\pi^{\\star}}}[(Q_{h}^{\\pi}(s_{h},\\pi_{h}(s))-Q_{h}^{\\pi}(s_{h},\\pi_{h}^{\\star}(s)))^{2}]\\le H\\sum_{h=1}^{H}H^{2}\\le H^{4}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{H U(\\pi,\\pi^{\\star})}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\\le\\frac{H^{4}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\le H^{4}\\displaystyle\\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi\\in\\Pi}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Where the final inequality follows from Claim 1 above. ", "page_idx": 18}, {"type": "text", "text": "The lemma below shows that there are some instances where the complexity from Theorem 1 is strictly smaller in terms of $\\epsilon$ dependence than that from Theorem 1 from [42] for PEDEL. ", "page_idx": 18}, {"type": "text", "text": "Lemma 5. On MDP $\\mathcal{M}$ defined above, we have: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I.\\ \\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi_{h}^{\\star}-\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}}^{2}(\\pi_{\\mathrm{exp}})^{-1}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\\leq15}\\\\ &{2.\\ \\operatorname*{max}_{\\pi\\in\\Pi}\\frac{H U(\\pi,\\pi^{\\star})}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}=\\frac{3H}{\\epsilon}}\\\\ &{3.\\ \\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\\geq\\frac{H}{\\epsilon^{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. Proof of 1. In this case we have that $\\pi^{*}=\\pi_{1}$ , and the only other $\\pi$ of interest is $\\pi_{2}$ . Note that $\\pi_{1}$ and $\\pi_{2}$ differ only at state $s_{3}$ and $s_{4}$ at $h=2$ . Let $\\pi_{\\mathrm{exp}}$ be the policy that plays actions uniformly at random. Then, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{h=1}^{H}\\operatorname*{inf}_{\\mathrm{\\sigma{mexp}}\\ \\pi\\in\\Pi}\\operatorname*{max}_{\\mathrm{max}\\left\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\mathrm{min}}^{2}\\right\\}}<\\operatorname*{inf}_{\\pi\\in\\mathrm{xp}}\\frac{\\|\\phi_{2}^{\\pi_{1}}-\\phi_{2}^{\\pi_{2}}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\epsilon^{2}}}\\\\ &{\\displaystyle=\\frac{1}{\\epsilon^{2}}\\left(\\frac{w_{2}^{\\pi_{1}}(s_{3})^{2}}{w_{2}^{\\pi_{\\mathrm{exp}}}(s_{3})}+\\frac{w_{2}^{\\pi_{1}}(s_{4})^{2}}{w_{2}^{\\pi_{\\mathrm{exp}}}(s_{4})}\\right)}\\\\ &{\\displaystyle\\le\\frac{1}{\\epsilon^{2}}\\left(\\frac{4\\epsilon^{2}}{1/3}+\\frac{\\epsilon^{2}}{1/3}\\right)}\\\\ &{\\displaystyle=15.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof of 2. Note that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{H U(\\pi,\\pi^{\\star})}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}=\\frac{H U(\\pi_{2},\\pi_{1})}{\\epsilon^{2}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{U(\\pi_{2},\\pi_{1})=\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{s\\sim w_{h}^{\\pi_{1}}}[(Q_{h}^{\\pi_{1}}(s,\\pi_{1,h}(s))-Q_{h}^{\\pi_{1}}(s,\\pi_{2,h}(s)))^{2}]}\\\\ &{\\quad=\\mathbb{E}_{s\\sim w_{2}^{\\pi_{1}}}[(Q_{2}^{\\pi_{1}}(s,\\pi_{1,2}(s))-Q_{2}^{\\pi_{1}}(s,\\pi_{2,2}(s)))^{2}]}\\\\ &{\\quad=2\\epsilon+\\epsilon=3\\epsilon.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Combining these proves the result ", "page_idx": 18}, {"type": "text", "text": "Proof of 3. By Claim 1 in Lemma 4, the stated result then follows by recognizing that $\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\mathbf{\\dot{\\Delta}}_{\\operatorname*{min}}^{2}\\}\\leq\\epsilon^{2}$ ", "page_idx": 18}, {"type": "text", "text": "B.2 Lower bound ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Lemma 6. On MDP M defined above, any $(\\epsilon,\\delta)$ -PAC algorithm must collect ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}^{\\mathcal{M}}[\\tau]\\ge\\frac{1}{\\epsilon}\\cdot\\log\\frac{1}{2.4\\delta}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "samples. ", "page_idx": 19}, {"type": "text", "text": "Proof. Consider $\\Pi,\\mathcal{M}$ , and $\\mathcal{M}^{\\prime}$ defined above. Let $\\mathcal{E}$ denote the event $\\{\\widehat{\\pi}=\\pi_{1}\\}$ . By the above observations, we have that $\\pi_{1}$ is $\\epsilon$ -optimal on $\\mathcal{M}$ while $\\pi_{2}$ is not, and that $\\pi_{2}$ is $\\epsilon_{}$ -optimal on $\\mathcal{M}^{\\prime}$ while $\\pi_{1}$ is not. Then by the definition of an $(\\epsilon,\\delta)$ -PAC algorithm, $\\mathbb{P}^{\\mathcal{M}}[\\mathcal{E}]\\ge1-\\delta$ and $\\mathbb{P}^{\\mathcal{M}^{\\prime}}[\\mathcal{E}]\\le\\delta$ ", "page_idx": 19}, {"type": "text", "text": "Let $\\gamma_{h}(s,a)$ denote the distribution of $(r_{h},s_{h+1})$ given $(s,a,h)$ on $\\mathcal{M}$ , and $\\gamma_{h}^{\\prime}(s,a)$ is the same on $\\mathcal{M}^{\\prime}$ . Then, letting $\\nu_{h}\\leftarrow\\gamma_{h},\\nu_{h}^{\\prime}\\leftarrow\\gamma_{h}^{\\prime}$ and otherwise adopting the same notation as in Lemma F.1 of [46], we have from Lemma F.1 of [46] that: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{s,a,h}\\mathbb{E}^{\\mathcal{M}}[N_{h}^{\\tau}(s,a)]\\mathrm{KL}(\\gamma_{h}(s,a),\\gamma_{h}^{\\prime}(s,a))\\ge\\operatorname*{sup}_{\\mathcal{E}^{\\prime}\\in\\mathcal{F}_{\\tau}}d(\\mathbb{P}^{\\mathcal{M}}[\\mathcal{E}^{\\prime}],\\mathbb{P}^{\\mathcal{M}^{\\prime}}[\\mathcal{E}^{\\prime}])}}\\\\ &{\\ge d(\\mathbb{P}^{\\mathcal{M}}[\\mathcal{E}],\\mathbb{P}^{\\mathcal{M}^{\\prime}}[\\mathcal{E}])}\\\\ &{\\ge\\log\\frac{1}{2.4\\delta}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the last inequality follows from [23]. ", "page_idx": 19}, {"type": "text", "text": "Note that $\\mathcal{M}$ and $\\mathcal{M}^{\\prime}$ differ only at $(s_{1},a_{1})$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sum_{\\textit{s},\\textit{h}}\\mathbb{E}^{M}[N_{h}^{\\tau}(s,a)]\\mathrm{KL}(\\gamma_{h}(s,a),\\gamma_{h}^{\\prime}(s,a))=\\mathbb{E}^{M}[N_{1}^{\\tau}(s_{1},a_{1})]\\mathrm{KL}(\\gamma_{1}(s_{1},a_{1}),\\gamma_{1}^{\\prime}(s_{1},a_{1})).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Furthermore, we see that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathrm{KL}(\\gamma_{1}(s_{1},a_{1}),\\gamma_{1}^{\\prime}(s_{1},a_{1}))=2\\epsilon\\log\\frac{2\\epsilon}{\\epsilon}+\\epsilon\\log\\frac{\\epsilon}{2\\epsilon}\\leq\\epsilon.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "So it follows that we must have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}^{\\mathcal{M}}[N_{1}^{\\tau}(s_{1},a_{1})]\\ge\\frac{1}{\\epsilon}\\cdot\\log\\frac{1}{2.4\\delta}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Noting that $\\mathbb{E}^{\\mathcal{M}}[N_{1}^{\\tau}(s_{1},a_{1})]\\le\\mathbb{E}^{\\mathcal{M}}[\\tau]$ completes the proof. ", "page_idx": 19}, {"type": "text", "text": "C Tabular MDP Upper Bound ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "C.1  Notation ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Covariance matrices. We use ", "text_level": 1, "page_idx": 19}, {"type": "equation", "text": "$$\n\\Lambda_{h}(\\pi_{\\mathrm{exp}})=\\mathbb{E}_{\\pi_{\\mathrm{exp}}}[e_{s_{h}a_{h}}e_{s_{h}a_{h}}^{\\top}]\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "to denote the expected covariance matrix and $\\widehat{\\Lambda}_{\\ell,h}$ to denote the empirical covariance matrix collected from ED. ", "page_idx": 19}, {"type": "text", "text": "State visitations. Let $\\delta_{\\ell,h}^{\\pi}(s^{\\prime}):=w_{h}^{\\pi}(s^{\\prime})-w_{h}^{\\bar{\\pi}_{\\ell}}(s^{\\prime})$ for $\\bar{\\pi}_{\\ell}$ the reference policy, $\\delta_{\\ell,h}^{\\pi}$ the vectorization of $\\delta_{\\ell,h}^{\\pi}(s^{\\prime})$ , and $w_{h}^{\\pi}(s)=\\mathbb{P}_{\\pi}[s_{h}=s]$ the visitation probability, and $\\begin{array}{r}{W_{h}^{\\star}(s)=\\operatorname*{sup}_{\\pi}w_{h}^{\\pi}(s)}\\end{array}$ Then, we can recursively define ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\delta_{\\ell,h+1}^{\\pi}=P_{h}(\\pi_{h}-\\bar{\\pi}_{\\ell,h})w_{\\ell,h}^{\\bar{\\pi}}+P_{h}\\pi_{h}\\delta_{\\ell,h}^{\\pi}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Similarly, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\widetilde{\\delta}_{\\ell,h+1}^{\\pi}=M_{h}\\left(P_{h}(\\pi_{h}-\\bar{\\pi}_{\\ell,h})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}+P_{h}\\pi_{h}\\widetilde{\\delta}_{\\ell,h}^{\\pi}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "And ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\widehat{\\delta}_{\\ell,h+1}^{\\pi}=M_{h}\\left(\\widehat{P}_{\\ell,h}(\\pi_{h}-\\bar{\\pi}_{\\ell,h})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}+\\widehat{P}_{\\ell,h}\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Algorithm 2 PERP: Policy Elimination with Reference Policy ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Require: tolerance $\\epsilon$ , confidence $\\delta$ , policies $\\Pi$ ", "page_idx": 20}, {"type": "text", "text": "1: $\\Pi_{1}\\leftarrow\\Pi$ $\\widehat{P}_{0}\\gets$ arbitrary transition matrix   \n2: for $\\begin{array}{r}{\\ell=1,2,3,\\dots,\\lceil\\log_{2}^{\\cdot}\\frac{16}{\\epsilon}\\rceil}\\end{array}$ do ", "page_idx": 20}, {"type": "text", "text": "3: Set $\\epsilon\\ell\\gets2^{-\\ell}$ \uff0c $\\begin{array}{r}{\\epsilon_{\\mathrm{unif}}^{\\ell}\\leftarrow\\frac{\\epsilon_{\\ell}}{64S^{3/2}H^{2}}}\\end{array}$ 64S3/2 H2 , Kun $\\begin{array}{r}{K_{\\mathrm{unif}}^{\\ell}\\leftarrow\\frac{\\epsilon_{\\ell}^{-2/3}}{\\epsilon_{\\mathrm{unif}}^{\\ell}}}\\end{array}$ ", "page_idx": 20}, {"type": "text", "text": "4: $S_{\\ell}^{\\mathrm{keep}}=\\mathrm{PRUNE}(\\epsilon_{\\mathrm{unif}}^{\\ell},\\delta/3\\ell^{2})$ (Algrihm 5) $//$ Prun states that ae hard to reach ", "page_idx": 20}, {"type": "text", "text": "5: Use $\\{\\widehat{P}_{\\ell-1,h}\\}_{h=1}^{H}$ to compute $\\widehat{U}_{\\ell-1,h}(\\pi,\\pi^{\\prime})$ for all $(\\pi,\\pi^{\\prime})\\in\\Pi_{\\ell}\\ //$ Compute new reference policy   \n6. Chonse $\\begin{array}{r}{\\bar{\\pi}_{\\ell}\\leftarrow\\operatorname*{min}_{\\bar{\\pi}\\in\\Pi_{\\ell}}\\operatorname*{max}_{\\pi\\in\\Pi_{\\ell}}\\sum_{h=1}^{H}\\widehat{U}_{\\ell-1,h}\\big(\\pi,\\bar{\\pi}\\big)}\\end{array}$ ", "page_idx": 20}, {"type": "text", "text": "7:  Collect the following number of episodes from $\\bar{\\pi}_{\\ell}$ and store in dataset $\\mathfrak{D}_{\\ell}^{\\mathrm{ref}}$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\bar{n}_{\\ell}=\\operatorname*{max}_{\\pi\\in\\Pi_{\\ell}}c\\cdot\\frac{H\\widehat U_{\\ell-1}(\\pi,\\bar{\\pi}_{\\ell})+H^{4}S^{3/2}\\sqrt{A}\\log\\frac{S A H\\ell^{2}}{\\delta}\\cdot\\epsilon_{\\ell}^{1/3}+S^{2}H^{4}\\epsilon_{\\mathrm{unif}}^{\\ell}}{\\epsilon_{\\ell}^{2}}\\cdot\\log\\frac{60H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "8: Compute $\\{\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}(s)\\}_{h=1}^{H}$ using empirical state visitation frequenci i $\\mathfrak{D}_{\\ell}^{\\mathrm{ref}}$   \n9: Initialize $\\widehat\\delta_{1}^{\\pi}\\gets0$ // Exploration via experiment desig   \n10: for $h=1,\\ldots,H$ do   \n11: Define $M_{\\ell,h}\\in\\mathbb{R}^{S A\\times S A}$ $M_{\\ell,h}\\gets\\mathrm{diag}(\\alpha_{s_{1},a_{1}}\\cdot\\cdot\\cdot\\alpha_{s_{S},a_{A}})$ where $\\alpha_{s,a}=\\mathbf{1}(s\\in S_{\\ell,h}^{\\mathrm{keep}})$   \n12: $\\Phi^{\\ell}\\leftarrow\\left\\{M_{\\ell,h}\\left((\\pmb{\\pi}_{h}-\\bar{\\pmb{\\pi}}_{\\ell,h})\\widehat{\\pmb{w}}_{\\ell,h}^{\\bar{\\pi}}+\\pmb{\\pi}_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}\\right)\\,:\\,\\pi\\in\\Pi_{\\ell}\\right\\}$   \n13: $\\begin{array}{r}{\\epsilon_{\\mathrm{exp}}^{\\ell}\\leftarrow\\epsilon_{\\ell}^{2}/H^{4}\\beta_{\\ell}^{2}\\mathrm{~for~}\\beta_{\\ell}\\leftarrow\\left(\\sqrt{2\\log\\left(\\frac{60S H^{2}\\ell^{2}|\\Pi_{\\ell}|}{\\delta}\\right)}+\\frac{4}{3}\\sqrt{\\frac{S A}{\\epsilon_{\\mathrm{mif}}^{\\ell}K_{\\mathrm{unif}}^{\\ell}}}\\log\\left(\\frac{60H^{2}\\ell^{2}|\\Pi_{\\ell}|}{\\delta}\\right)\\right)}\\end{array}$   \n14: $\\begin{array}{r}{\\textmd{m}\\mathfrak{D}_{\\ell,h}^{\\mathrm{ED}}\\leftarrow\\mathrm{OPTCOv}\\left(\\Phi^{\\ell},\\epsilon_{\\mathrm{exp}}^{\\ell},\\frac{\\delta}{6H\\ell^{2}},\\epsilon_{\\mathrm{unif}}^{\\ell},K_{\\mathrm{unif}}^{\\ell},S_{\\ell,h}^{\\mathrm{keep}},h\\right)}\\end{array}$ (Algorithm 3)   \n15: Use $\\mathfrak{D}_{\\ell,h}^{\\mathrm{ED}}$ to compute $\\begin{array}{r}{\\widehat{P}_{\\ell,h}(s^{\\prime}|s,a)\\:\\leftarrow\\:\\frac{N_{\\ell,h}(s^{\\prime},s,a)}{N_{\\ell,h}(s,a)}}\\end{array}$ N if Ne,h(s,a) > 0, unif(S) othewise,   \nand $\\begin{array}{r}{\\widehat{r}_{\\ell,h}(s,a)=\\frac{1}{N_{\\ell,h}(s,a)}\\sum_{(s^{\\prime},a^{\\prime},r^{\\prime},s^{\\prime\\prime})\\in{\\mathfrak{D}}_{\\ell,h}^{\\mathrm{ED}}}r^{\\prime}\\cdot\\mathbb{I}\\{(s,a)=(s^{\\prime},a^{\\prime})\\}}\\end{array}$ $N_{\\ell,h}(s,a)>0,0$   \notherwise   \n16: Compute $\\widehat{\\delta}_{\\ell,h+1}^{\\pi}\\leftarrow M_{\\ell,h}(\\widehat{P}_{\\ell,h}(\\pi_{h}-\\bar{\\pi}_{\\ell,h})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}+\\widehat{P}_{\\ell,h}\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi})$   \n17: end for   \n18: Compute $\\begin{array}{r}{\\widehat{D}_{\\bar{\\pi}_{\\ell}}(\\pi)\\gets\\sum_{h}\\langle\\widehat{r}_{\\ell,h},\\pi_{h}\\widehat{\\delta}_{\\ell,h}\\rangle+\\sum_{h}\\langle\\widehat{r}_{\\ell,h},(\\pi_{h}-\\bar{\\pi}_{\\ell,h})\\widehat{w}_{\\ell,}^{\\bar{\\pi}}}\\end{array}$   \n19: Update $\\Pi_{\\ell+1}=\\Pi_{\\ell}\\backslash\\{\\pi\\in\\Pi_{\\ell}:\\operatorname*{max}_{\\pi^{\\prime}}\\widehat{D}_{\\bar{\\pi}_{\\ell}}(\\pi^{\\prime})-\\widehat{D}_{\\bar{\\pi}_{\\ell}}(\\pi)>8\\epsilon_{\\ell}\\ \\}$   \n20: if $|\\boldsymbol{\\Pi}_{\\ell+1}|=1$ then return $\\pi\\in\\Pi_{\\ell+1}$ ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "21: end for 22: return any $\\pi\\in\\Pi_{\\ell+1}$ ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "Value functions. Note that we can express the value function as: ", "page_idx": 20}, {"type": "equation", "text": "$$\nV_{h}^{\\pi}=\\sum_{k=h}^{H}\\left(\\prod_{j=h+1}^{k}P_{j}\\pi_{j}\\right)^{\\top}\\pi_{k}^{\\top}r_{k}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "On the \u201cpruned\" MDP, define ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\widetilde{r}_{\\ell,h}=M_{\\ell,h}r_{h},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\widetilde{V}_{\\ell,h}:=\\sum_{k=h}^{H}\\left(\\prod_{j=h+1}^{k}M_{\\ell,j+1}P_{j}\\pi_{j}\\right)^{\\top}\\pi_{k}^{\\top}\\widetilde{r}_{\\ell,k}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Reward difference term. Define ", "page_idx": 20}, {"type": "equation", "text": "$$\nU_{h}(\\pi,\\pi^{\\prime}):=\\mathbb{E}_{\\pi^{\\prime}}[(Q_{h}^{\\pi}(s_{h},\\pi_{h}(s))-Q_{h}^{\\pi}(s_{h},\\pi_{h}^{\\prime}(s)))^{2}]\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and $\\begin{array}{r}{U(\\pi,\\pi^{\\prime}):=\\sum_{h=1}^{H}U_{h}(\\pi,\\pi^{\\prime})}\\end{array}$ . Additionally, define ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\widehat{U}_{\\ell,h}(\\pi,\\pi^{\\prime}):=\\mathbb{E}_{\\pi^{\\prime},\\ell}[(\\widehat{Q}_{\\ell,h}^{\\pi}(s_{h},\\pi_{h}(s))-\\widehat{Q}_{\\ell,h}^{\\pi}(s_{h},\\pi_{h}^{\\prime}(s)))^{2}]\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\mathbb{E}_{\\pi^{\\prime},\\ell}$ denotes the expectation induced playing $\\pi^{\\prime}$ on the MDP with transitions $\\widehat{P}_{\\ell}$ and $\\widehat{Q}_{\\ell,h}^{\\pi}$ denotes the $Q$ function for policy $\\pi$ on this same MDP. Let $\\begin{array}{r}{\\widehat{U}_{\\ell}(\\pi,\\pi^{\\prime}):=\\sum_{h=1}^{H}\\widehat{U}_{\\ell,h}(\\pi,\\pi^{\\prime})}\\end{array}$ ", "page_idx": 21}, {"type": "text", "text": "C.2  Technical Results ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Lemma 7. Let $\\mathfrak{D}=\\{(s_{1},a_{1},s_{1}^{\\prime}),\\dots(s_{T},a_{T},s_{T}^{\\prime})\\}$ be any dataset of transitions collected from level $h$ Let $\\widehat{P}\\in\\mathbb{R}^{S\\times S A}$ denote the empirical transition matrix with $\\begin{array}{r}{[\\widehat{P}]_{s^{\\prime},s a}=\\frac{N(s^{\\prime}|s,a)}{N(s,a)}}\\end{array}$ Na jfN(s,a) >0, and $\\boldsymbol{O}$ otherwise, for $\\begin{array}{r}{N(s^{\\prime}\\mid s,a)=\\sum_{t}\\mathbb{I}\\{(s_{t},a_{t},s_{t}^{\\prime})=(s,a,s^{\\prime})\\}}\\end{array}$ and $\\begin{array}{r}{N(s,a)=\\sum_{t}\\mathbb{I}\\{(s_{t},a_{t})=}\\end{array}$ $(s,a)\\}$ .Consider any $v~\\in~[0,1]^{S}$ and $u~\\in~\\mathbb{R}^{S A}$ and assumethat $N(s,a)\\;>\\;\\underline{{{\\lambda}}}\\;>\\;0$ for all $(s,a)\\in\\mathrm{support}(u)$ . Then, for $P$ the true transition matrix, we have that with probability at least $1-\\delta$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left|v^{\\top}(P-\\widehat{P})u\\right|\\leq\\sqrt{\\sum_{s,a}\\frac{[u]_{s,a}^{2}}{N(s,a)}}\\cdot\\left(\\sqrt{2\\log\\left(\\frac{1}{\\delta}\\right)}+\\frac{4}{3\\sqrt{\\underline{{\\lambda}}}}\\log\\left(\\frac{1}{\\delta}\\right)\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. First write ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{v^{\\top}(P-\\widehat{P})u=\\displaystyle\\sum_{s^{\\prime}}\\sum_{s,a}v_{s^{\\prime}}\\left(P(s^{\\prime}\\mid s,a)-\\frac{N(s^{\\prime}\\mid s,a)}{N(s,a)}\\right)u_{s a}}\\\\ {=\\displaystyle\\sum_{t}\\sum_{s^{\\prime}}\\frac{v_{s^{\\prime}}\\left(P(s^{\\prime}\\mid s_{t},a_{t})-\\mathbb{I}\\{s_{t}^{\\prime}=s^{\\prime}\\}\\right)u_{s_{t}a_{t}}}{N(s_{t},a_{t})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the second equality follows from some simple manipulations. Note that, for any $t$ wehave ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{v_{s^{\\prime}}\\left(P(s^{\\prime}\\mid s_{t},a_{t})-\\mathbb{I}\\{s_{t}^{\\prime}=s^{\\prime}\\}\\right)u_{s_{t}a_{t}}}{N(s_{t},a_{t})}\\mid s_{t},a_{t}\\right]=0\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "and can bound ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\left|\\sum_{s^{\\prime}}\\frac{v_{s^{\\prime}}\\left(P(s^{\\prime}\\mid s_{t},a_{t})-\\mathbb{I}\\{s_{t}^{\\prime}=s^{\\prime}\\}\\right)u_{s_{t}a_{t}}}{N\\left(s_{t},a_{t}\\right)}\\right|\\leq\\frac{2u_{s_{t}a_{t}}}{N\\left(s_{t},a_{t}\\right)}\\leq\\frac{2}{\\sqrt{\\underline{{\\lambda}}}}\\cdot\\frac{u_{s_{t}a_{t}}}{\\sqrt{N\\left(s_{t},a_{t}\\right)}}}}\\\\ &{}&{\\leq\\frac{2}{\\sqrt{\\underline{{\\lambda}}}}\\cdot\\sqrt{\\displaystyle\\sum_{s,a}\\frac{u_{s a}^{2}}{N\\left(s,a\\right)}}\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where we have used the fact that $N(s,a)\\geq\\lambda$ for $(s,a)\\in\\mathrm{support}(u)$ , and since $v$ has entries in $[0,1]$ and $P(s^{\\prime}\\mid s_{t},a_{t})$ and $\\mathbb{I}\\{s_{t}^{\\prime}=s^{\\prime}\\}$ are valid distributions, so $\\begin{array}{r l}{\\sum_{s^{\\prime}}v_{s^{\\prime}}(P(s^{\\prime}\\mid s_{t},a_{t})-\\mathbb{I}\\{s_{t}^{\\prime}=}&{{}}\\end{array}$ $\\bar{s}^{\\prime}\\}\\bar{\\in}\\left[-1,1\\right]$ . Furthermore, we have that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}_{s_{t}^{\\prime}}\\left[\\left(\\sum_{s^{\\prime}}\\frac{v_{s^{\\prime}}\\left(P(s^{\\prime}\\mid s_{t},a_{t})-\\mathbb{I}\\{s_{t}^{\\prime}=s^{\\prime}\\}\\right)u_{s_{t}a_{t}}}{N(s_{t},a_{t})}\\right)^{2}\\right]\\leq\\mathbb{E}_{s_{t}^{\\prime}}\\left[\\left(\\frac{u_{s_{t}a_{t}}}{N(s_{t},a_{t})}\\right)^{2}\\right]=\\left(\\frac{u_{s_{t}a_{t}}}{N(s_{t},a_{t})}\\right)^{2}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where we have again used that $\\begin{array}{r}{\\sum_{s^{\\prime}}v_{s^{\\prime}}(P(s^{\\prime}\\mid s_{t},a_{t})-\\mathbb{I}\\{s_{t}^{\\prime}=s^{\\prime}\\})\\in[-1,1].}\\end{array}$ ", "page_idx": 21}, {"type": "text", "text": "By Bernstein's inequality, we therefore have that with probability at least $1-\\delta$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|v^{\\top}(P-\\widehat{P})u\\right|\\leq\\sqrt{2\\sum_{t}\\left(\\frac{u_{s_{t}a_{t}}}{N(s_{t},a_{t})}\\right)^{2}\\cdot\\log\\frac{2}{\\delta}}+\\frac{4}{3\\sqrt{\\underline{{\\lambda}}}}\\cdot\\sqrt{\\sum_{t}\\frac{u_{s_{t}a_{t}}^{2}}{N(s_{t},a_{t})}}\\cdot\\log\\frac{2}{\\delta}}\\\\ &{\\qquad\\qquad=\\left(\\sqrt{2\\log\\frac{2}{\\delta}}+\\frac{4}{3\\sqrt{\\underline{{\\lambda}}}}\\log\\frac{2}{\\delta}\\right)\\cdot\\sqrt{\\sum_{s,a}\\frac{u_{s_{a}}^{2}}{N(s,a)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Lemma 8. Let $\\mathfrak{D}\\,=\\,\\{(s_{1},a_{1},r_{1}),..\\,.\\,(s_{T},a_{T},r_{T})\\}$ be any dataset of state-action-reward tuples collected from level h. Let T E IRSA denote the empirical reward estimation with [\u4e2a]sa = N(s,a) $\\begin{array}{r}{\\sum_{t=1}^{T}r_{t}\\,\\cdot\\,\\mathbb{I}\\{(s_{t},a_{t})\\,=\\,(s,a)\\}}\\end{array}$ $N(s,a)\\,>\\,0,$ and $\\boldsymbol{O}$ otherwise,for $\\begin{array}{r}{N(s,a)\\,=\\,\\sum_{t}\\mathbb{I}\\{(s_{t},a_{t})\\,=\\,}\\end{array}$ $(s,a)\\}$ Consider any $u\\in\\mathbb{R}^{S A}$ and assumethat $N(s,a)>\\underline{{{\\lambda}}}>0$ for all $(s,a)\\in\\mathrm{support}(u)$ .Then, for $r$ the truerewardmean,we have that with probability at least $1-\\delta$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left|(r-\\widehat{r})^{\\top}u\\right|\\leq\\sqrt{\\sum_{s,a}\\frac{[u]_{s,a}^{2}}{N(s,a)}}\\cdot\\left(\\sqrt{2\\log\\left(\\frac{1}{\\delta}\\right)}+\\frac{4}{3\\sqrt{\\underline{{\\lambda}}}}\\log\\left(\\frac{1}{\\delta}\\right)\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. First write ", "page_idx": 22}, {"type": "equation", "text": "$$\n(r-\\widehat{r})^{\\top}u=\\sum_{t}\\frac{(r(s_{t},a_{t})-r_{t})\\,u_{s_{t}a_{t}}}{N(s_{t},a_{t})}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Note that, for any $t$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{\\left(r(s_{t},a_{t})-r_{t}\\right)u_{s_{t}a_{t}}}{N(s_{t},a_{t})}\\mid s_{t},a_{t}\\right]=0\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "and can bound ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left|\\frac{\\left(r(s_{t},a_{t})-r_{t}\\right)u_{s_{t}a_{t}}}{N(s_{t},a_{t})}\\right|\\leq\\frac{u_{s_{t}a_{t}}}{N(s_{t},a_{t})}\\leq\\frac{1}{\\sqrt{\\underline{{\\lambda}}}}\\cdot\\frac{u_{s_{t}a_{t}}}{\\sqrt{N(s_{t},a_{t})}}\\leq\\frac{1}{\\sqrt{\\underline{{\\lambda}}}}\\cdot\\sqrt{\\sum_{s,a}\\frac{u_{s_{a}}^{2}}{N(s,a)}}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where we have used the fact that $N(s,a)\\geq\\lambda$ for $(s,a)\\in\\mathrm{support}(u)$ , and since we assume our rewards are in $[0,1]$ . Furthermore, we have that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}_{r_{t}}\\left[\\left(\\frac{\\left(r\\left(s_{t},a_{t}\\right)-r_{t}\\right)u_{s_{t}a_{t}}}{N(s_{t},a_{t})}\\right)^{2}\\right]\\le\\mathbb{E}_{r_{t}}\\left[\\left(\\frac{u_{s_{t}a_{t}}}{N(s_{t},a_{t})}\\right)^{2}\\right]=\\left(\\frac{u_{s_{t}a_{t}}}{N(s_{t},a_{t})}\\right)^{2}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "By Bernstein's inequality, we therefore have that with probability at least $1-\\delta$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|(r-\\widehat{r})^{\\top}u\\right|\\leq\\sqrt{2\\sum_{t}\\left(\\frac{u_{s_{t}a_{t}}}{N\\left(s_{t},a_{t}\\right)}\\right)^{2}\\cdot\\log\\frac{2}{\\delta}}+\\frac{4}{3\\sqrt{\\underline{{\\lambda}}}}\\cdot\\sqrt{\\sum_{t}\\frac{u_{s_{t}a_{t}}^{2}}{N\\left(s_{t},a_{t}\\right)}}\\cdot\\log\\frac{2}{\\delta}}\\\\ &{\\qquad\\qquad=\\left(\\sqrt{2\\log\\frac{2}{\\delta}}+\\frac{4}{3\\sqrt{\\underline{{\\lambda}}}}\\log\\frac{2}{\\delta}\\right)\\cdot\\sqrt{\\sum_{s,a}\\frac{u_{s_{a}}^{2}}{N\\left(s,a\\right)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Lemma 9. Let $u\\in\\mathbb{R}^{S}$ be any vector such that $\\forall s,|u_{s}|\\leq M$ Then, for any $(\\ell,h)$ , the following holds with probability $(1-\\delta)$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left|\\mathbb{E}_{s\\sim w_{\\ell,h}^{\\bar{\\pi}}}[u_{s}]-\\mathbb{E}_{s\\sim\\hat{w}_{\\ell,h}^{\\bar{\\pi}}}[u_{s}]\\right|\\le\\sqrt{\\frac{2\\mathbb{E}_{s\\sim w_{\\ell,h}^{\\bar{\\pi}}}[u_{s}^{2}]}{\\bar{n}_{\\ell}}\\log\\left(\\frac{2}{\\delta}\\right)}+\\frac{2M}{3\\bar{n}_{\\ell}}\\log\\left(\\frac{2}{\\delta}\\right)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. The left side of the inequality above takes the form of the deviation between an empirical and true mean of the random variable $u_{s}$ . Hence, the result follows directly from Bernstein's inequality sinceweknow $|u_{s}|\\leq M$ isbounded. \u53e3 ", "page_idx": 22}, {"type": "text", "text": "Lemma 10.Assume that $A$ and $B$ are matrices with entries in [O, 1] and whose rows sum to a value $\\leq1$ Then $A B$ also satisfies this. ", "page_idx": 22}, {"type": "text", "text": "Proof. To see this, consider the $i$ th row of $A B$ , and note that the sum of the elements in this row can be written as, for $a_{i}^{\\top}$ the $i$ th row of $A$ , and $b_{j}$ the $j$ th column of $B$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{j}a_{i}^{\\top}b_{j}=\\sum_{k}\\sum_{j}a_{i k}b_{j k}=\\sum_{k}a_{i k}(\\sum_{j}b_{j k}).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Now note that $\\sum_{j}b_{j k}$ is the sum across the $k$ th row of $B$ , so this is $\\leq1$ by assumption. Furthermore, $\\textstyle\\sum_{k}a_{i k}\\leq1$ for the same reason. Thus, the $i$ th row of $A B$ sums to a value $\\leq1$ . Furthermore, it is easy to see $a_{i}^{\\top}b_{j}\\leq1$ for each $j$ . Thus, $A B$ has values in $[0,1]$ and rows that sum to a value $\\leq1$ .\u53e3 ", "page_idx": 22}, {"type": "text", "text": "Lemma 11. We have that $\\|\\Pi_{h=i}^{j}M_{h+1}P_{h}\\pi_{h}\\|_{2},\\|\\Pi_{h=i}^{j}P_{h}\\pi_{h}\\|_{2}\\le\\sqrt{S}\\,f o r\\,a n y\\,i,j,h.$ ", "page_idx": 23}, {"type": "text", "text": "Proof. By definition $P_{h}\\pi_{h}$ is a transition matrix\u2014each row has values in $[0,1]$ and sums to 1\u2014and $M_{h+1}$ is diagonal with diagonal elements either O or 1. Thus, each matrix $M_{h}P_{h}\\pi_{h}$ has values in $[0,1]$ and rows that sum to a value $\\leq1$ , so Lemma 10 implies that $\\Pi_{h=i}^{j}M_{h+1}P_{h}\\pi_{h}$ does as well. Denote $A:=\\|\\Pi_{h=i}^{j}M_{h}P_{h}\\pi_{h}\\|_{2}$ . We can then bound ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\|\\Pi_{h=i}^{j}M_{h+1}P_{h}\\pi_{h}\\|_{2}^{2}=\\|A\\|_{2}^{2}\\le\\|A\\|_{\\mathrm{F}}^{2}=\\sum_{i}\\sum_{j}A_{i j}^{2}\\le\\sum_{i}1\\le S,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "which proves the result. The bound on $\\|\\Pi_{h=i}^{j}P_{h}\\pi_{h}\\|_{2}$ follows from the same argument. ", "page_idx": 23}, {"type": "text", "text": "Lemma 12. We have ", "text_level": 1, "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\stackrel{\\widehat{\\omega}_{R,h+1}^{\\prime}}{=}\\widehat{\\delta}_{\\ell,h+1}^{\\overline{{\\ell}}}}\\\\ {=\\displaystyle\\sum_{i=0}^{h-2}\\left(\\prod_{j=h-i+1}^{h}M_{\\ell,j+1}P_{j}\\pi_{j}\\right)(P_{h-i}-\\widehat{P}_{\\ell,h-i})M_{\\ell,h-i}\\Big[(\\pi_{h-i}-\\overline{{\\pi}}_{\\ell,h-i})\\widehat{w}_{\\ell,h-i}^{\\bar{\\pi}}+\\pi_{h-i}\\widehat{\\delta}_{\\ell,h-i}^{\\pi}\\Big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof. This follows immediately from the definition of $\\widetilde{\\delta}_{\\ell,h+1}^{\\pi},\\widehat{\\delta}_{\\ell,h+1}^{\\pi}$ , and simple manipulations. ", "page_idx": 23}, {"type": "text", "text": "C.3   Concentration Arguments and Good Events ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Lemma 13. Let Eprune be the event forwhich the call to PRUNE in epoch l inAlgoritm 2 will terminate after running for at most ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathrm{poly}(S,A,H,\\log\\frac{S A H\\ell}{\\delta\\epsilon_{\\ell}})\\cdot\\frac{1}{\\epsilon_{\\mathrm{unif}}^{\\ell}}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "episodes and il reurn a set $S_{\\ell}^{\\mathrm{keep}}$ such that, forevery $(s,h)\\in{\\cal S}_{\\ell}^{\\mathrm{keep}}$ Skeep, we have W(s)\u2265nir and, $i f\\left(s,h\\right)\\notin S_{\\ell}^{\\mathrm{keep}}$ then $W_{h}^{\\star}(s)\\leq32\\epsilon_{\\mathrm{unif}}^{\\ell}$ Then $\\begin{array}{r}{\\mathbb{P}(\\mathcal{E}_{\\mathrm{prune}}^{\\ell})\\geq1-\\frac{\\delta}{3\\ell^{2}}}\\end{array}$ ", "page_idx": 23}, {"type": "text", "text": "Proof. FromLmma38, this event follws directlywithprobabilty $\\begin{array}{r}{(1-\\frac{\\delta}{3\\ell^{2}})}\\end{array}$ ", "page_idx": 23}, {"type": "text", "text": "Lemma 14. Let $\\mathcal{E}_{\\exp}^{\\ell,h}$ be the event for which: ", "page_idx": 23}, {"type": "text", "text": "1. The exploration procedure in Algorithm 3 will produce $\\mathfrak{D}_{\\ell,h}^{\\mathrm{ED}}$ suchthat ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\pi\\in\\Pi_{\\ell}}\\|M_{\\ell,h}\\big((\\pi_{h}-\\bar{\\pi}_{\\ell,h})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}+\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}\\big)\\|_{\\widehat{\\Lambda}_{\\ell,h}^{-1}}^{2}\\leq\\epsilon_{\\exp}^{\\ell}\\quad f o r\\quad\\widehat{\\Lambda}_{\\ell,h}=\\sum_{(s,a)\\in\\mathfrak{D}_{\\ell,h}^{\\mathrm{ED}}}e_{s a}e_{s a}^{\\top},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and will collect at most ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{C\\cdot\\frac{\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi_{\\ell}}\\|M_{\\ell,h}\\left(\\left(\\pi_{h}-\\bar{\\pi}_{\\ell,h}\\right)\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}+\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}\\right)\\|_{\\Lambda_{h}\\left(\\pi_{\\mathrm{exp}}\\right)^{-1}}^{2}}{\\epsilon_{\\mathrm{exp}}^{\\ell}}+\\frac{C_{\\mathrm{fw}}^{\\ell}}{\\left(\\epsilon_{\\mathrm{exp}}^{\\ell}\\right)^{4/5}}}\\\\ &{+\\left.\\frac{C_{\\mathrm{fw}}^{\\ell}}{\\epsilon_{\\mathrm{unif}}^{\\ell}}+\\log(C_{\\mathrm{fw}}^{\\ell})\\cdot K_{\\mathrm{unif}}^{\\ell}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "episodes. ", "page_idx": 23}, {"type": "text", "text": "Above, $C$ is a universal constant and $C_{\\mathrm{fw}}^{\\ell}\\ =\\ \\mathrm{poly}(S,A,H,\\log\\ell/\\delta,\\log1/\\epsilon,\\log|\\Pi|)$ \uff1aThen $\\begin{array}{r}{\\mathbb{P}[(\\mathscr{E}_{\\mathrm{exp}}^{\\ell,h})^{c}\\cap\\mathcal{E}_{\\mathrm{prune}}^{\\ell}\\cap\\bar{\\mathcal{E}}_{\\mathrm{ext}}^{\\ell}\\cap(\\cap_{h^{\\prime}\\le h-1}\\mathcal{E}_{\\mathrm{est}}^{\\ell,h^{\\prime}})\\cap(\\cap_{h^{\\prime}\\le h-1}\\mathcal{E}_{\\mathrm{exp}}^{\\ell,h^{\\prime}})]\\le\\frac{\\delta}{6H\\ell^{2}}}\\end{array}$ ", "page_idx": 23}, {"type": "text", "text": "Proof. Since the event $\\mathcal{E}_{\\mathrm{prune}}^{\\ell}$ holds, fo each $s\\in S_{\\ell}^{\\mathrm{keep}}$ Skeep we have W(s)\u2265nir Nw oere that, $s\\in S_{\\ell}^{\\mathrm{keep}}$ andany $a$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|[(\\pi_{h}-\\bar{\\pi}_{\\ell,h^{\\prime}})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}+\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}]_{(s,a)}|}\\\\ &{\\le[\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}]_{s}+|[\\widehat{\\delta}_{\\ell,h}^{\\pi}]_{s}|\\le[w_{\\ell,h}^{\\bar{\\pi}}]_{s}+|[\\delta_{\\ell,h}^{\\pi}]_{s}|+|[\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}-w_{\\ell,h}^{\\bar{\\pi}}]_{(s)}|+|[\\delta_{\\ell,h}^{\\pi}]_{s}-|[\\widehat{\\delta}_{\\ell,h}^{\\pi}]_{s}||.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "By construction, we have $[w_{\\ell,h}^{\\bar{\\pi}}]_{s},|[\\delta_{\\ell,h}^{\\pi}]_{s}|\\le W_{h}^{\\star}(s)$ By Lemma 19, o0n $\\bar{\\mathcal{E}}_{\\mathrm{est}}^{\\ell}$ , we can bound $|[\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}-$ $w_{\\ell,h}^{\\bar{\\pi}}]_{(s)}|\\le\\sqrt{8S\\epsilon_{\\ell}^{5/3}}$ By Lemma 18. n $\\mathcal{E}_{\\mathrm{prune}}^{\\ell}\\cap\\big(\\cap_{h^{\\prime}\\le h-1}\\mathcal{E}_{\\mathrm{est}}^{\\ell,h^{\\prime}}\\big)\\cap\\big(\\cap_{h^{\\prime}\\le h-1}\\mathcal{E}_{\\mathrm{exp}}^{\\ell,h^{\\prime}}\\big)$ , we can bound $|[\\delta_{\\ell,h}^{\\pi}]_{s}-|[\\widehat{\\delta}_{\\ell,h}^{\\pi}]_{s}||\\leq\\sqrt{S H\\beta_{\\ell}\\epsilon_{\\mathrm{exp}}^{\\ell}}+S H(\\sqrt{8\\epsilon_{\\ell}^{5/3}}+32\\epsilon_{\\mathrm{unif}}^{\\ell}).$ ", "page_idx": 24}, {"type": "text", "text": "Altogether then, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|[(\\pi_{h}-\\bar{\\pi}_{\\ell,h^{\\prime}})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}+\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}]_{(s,a)}|}\\\\ &{\\leq2W_{h}^{\\star}(s)+\\sqrt{S H\\beta_{\\ell}\\epsilon_{\\mathrm{exp}}^{\\ell}}+S H(\\sqrt{8\\epsilon_{\\ell}^{5/3}}+32\\epsilon_{\\mathrm{unif}}^{\\ell})+\\sqrt{8S\\epsilon_{\\ell}^{5/3}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "By our choice of $\\epsilon_{\\mathrm{exp}}^{\\ell}$ and Eunif, we can bound all of this as ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\leq C_{\\phi}\\cdot(W_{h}^{\\star}(s)+\\sqrt{K_{\\mathrm{unif}}^{\\ell}\\epsilon_{\\mathrm{unif}}^{\\ell}}\\epsilon_{\\mathrm{exp}}^{\\ell})\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "for $C_{\\phi}=c S H\\beta_{\\ell}$ . This is the condition required by Theorem 2, so the result follows from Theorem 2. ", "page_idx": 24}, {"type": "text", "text": "Lemma 15. Let $\\ensuremath{\\mathcal{E}}_{\\mathrm{est}}^{\\ell,h}$ be the event at epoch $\\ell$ for step h on which: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\left\\langle\\pi_{h}^{\\top}\\widetilde{r}_{\\ell,h,}\\left(\\prod_{i=h^{\\prime}+1}^{h}M_{\\ell,i+1}P_{i}\\pi_{i}\\right)(P_{h^{\\prime}}-\\widehat{P}_{\\ell,h^{\\prime}})M_{\\ell,h^{\\prime}}\\left[(\\pi_{h^{\\prime}}-\\bar{\\pi}_{\\ell,h^{\\prime}})\\widehat{w}_{\\ell,h^{\\prime}}^{\\bar{\\pi}}+\\pi_{h^{\\prime}}\\widehat{\\delta_{\\ell,h^{\\prime}}^{\\pi}}\\right]\\right\\rangle\\right|}\\\\ &{\\leq\\beta_{\\ell}\\sqrt{\\displaystyle\\sum_{s,a}\\frac{\\left[M_{\\ell,h^{\\prime}}\\left((\\pi_{h^{\\prime}}-\\bar{\\pi}_{\\ell,h^{\\prime}})\\widehat{w}_{\\ell,h^{\\prime}}^{\\bar{\\pi}}+\\pi_{h^{\\prime}}\\widehat{\\delta_{\\ell,h^{\\prime}}^{\\pi}}\\right)\\right]_{(s,a)}^{2}}{N_{\\ell,h^{\\prime}}(s,a)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "(2) For all canonical vectors $e_{s^{\\prime}}$ in $\\mathbb{R}^{S},\\pi\\in\\Pi_{\\ell}$ and $h^{\\prime}\\leq h$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\left\\langle e_{s^{\\prime}},\\left(\\prod_{i=h^{\\prime}+1}^{h}M_{\\ell,i+1}P_{i}\\pi_{i}\\right)(P_{h^{\\prime}}-\\widehat{P}_{\\ell,h^{\\prime}})M_{\\ell,h^{\\prime}}\\left[(\\pi_{h^{\\prime}}-\\bar{\\pi}_{\\ell,h^{\\prime}})\\widehat{w}_{\\ell,h^{\\prime}}^{\\bar{\\pi}}+\\pi_{h^{\\prime}}\\widehat{\\delta}_{\\ell,h^{\\prime}}^{\\pi}\\right]\\right\\rangle\\right|}\\\\ &{\\leq\\beta\\ell\\sqrt{\\displaystyle\\sum_{s,a}\\frac{\\left[M_{\\ell,h^{\\prime}}\\left((\\pi_{h^{\\prime}}-\\bar{\\pi}_{\\ell,h^{\\prime}})\\widehat{w}_{\\ell,h^{\\prime}}^{\\bar{\\pi}}+\\pi_{h^{\\prime}}\\widehat{\\delta}_{\\ell,h^{\\prime}}^{\\bar{\\pi}}\\right)\\right]_{s,a}^{2}}{N_{\\ell,h^{\\prime}}(s,a)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "(3) For each $(s,a)$ , we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\sum_{s^{\\prime}}|\\widehat{P}_{\\ell,h}(s^{\\prime}\\mid s,a)-P_{h}(s^{\\prime}\\mid s,a)|\\leq S\\sqrt{\\frac{\\log\\frac{48S^{2}A H\\ell^{2}}{\\delta}}{N_{\\ell,h}(s,a)}}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "(4) For each $\\pi\\in\\Pi_{\\ell}$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\langle\\widehat{r}_{\\ell,h}-\\widetilde{r}_{\\ell,h},\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}+(\\pi_{h}-\\bar{\\pi}_{\\ell,h})\\widehat{w}_{\\ell,h}^{\\pi}\\rangle|}\\\\ &{\\leq\\beta_{\\ell}\\sqrt{\\displaystyle\\sum_{s,a}\\frac{\\left[M_{\\ell,h}\\left((\\pi_{h}-\\bar{\\pi}_{\\ell,h^{\\prime}})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}+\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}\\right)\\right]_{(s,a)}^{2}}{N_{\\ell,h}(s,a)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Then $\\begin{array}{r}{\\mathbb{P}[(\\mathcal{E}_{\\mathrm{est}}^{\\ell,h})^{c}\\cap\\mathcal{E}_{\\mathrm{prune}}^{\\ell}\\cap(\\cap_{h^{\\prime}\\le h}\\mathcal{E}_{\\mathrm{exp}}^{\\ell,h})]\\le\\frac{\\delta}{6H\\ell^{2}}.}\\end{array}$ ", "page_idx": 24}, {"type": "text", "text": "Proof. We prove each of the events sequentially. ", "page_idx": 24}, {"type": "text", "text": "Proof of Event (1).Consider any fixed choice of $(\\pi,h^{\\prime})$ . By Lemma 10 and since our rewards are in $[0,1]$ , we have that $\\begin{array}{r}{\\left(\\prod_{i=h^{\\prime}+1}^{h}M_{\\ell,i+1}P_{i}\\pi_{i}\\right)^{\\top}\\pi_{h}^{\\top}\\widetilde{r}_{\\ell,h}}\\end{array}$ is a vector in $[0,1]$ .Let $\\begin{array}{r}{v\\leftarrow\\left(\\prod_{i=h^{\\prime}+1}^{h}M_{\\ell,i+1}P_{i}\\pi_{i}\\right)^{\\top}\\pi_{h}^{\\top}\\widetilde{r}_{\\ell,h}\\mathrm{~and~}u\\leftarrow M_{\\ell,h^{\\prime}}\\left[(\\pi_{h^{\\prime}}-\\bar{\\pi}_{\\ell,h^{\\prime}})\\widehat{w}_{\\ell,h^{\\prime}}^{\\bar{\\pi}}+\\pi_{h^{\\prime}}\\widehat{\\delta}_{\\ell,h^{\\prime}}^{\\pi}\\right].}\\end{array}$ Note that by construction we have that $u_{s a}=0$ for $s\\notin S_{\\ell,h^{\\prime}}^{\\mathrm{keep}}$ , and so on $\\mathcal{E}_{\\mathrm{exp}}^{\\ell,h^{\\prime}}$ , we have $\\begin{array}{r}{N_{\\ell,h^{\\prime}}(s,\\bar{a})\\ge\\frac{K_{\\mathrm{unif}}^{\\ell}\\epsilon_{\\mathrm{unif}}^{\\ell}}{2S A}}\\end{array}$ for all $(s,a)\\in\\mathrm{support}(u)$ On $\\mathscr{E}_{\\mathrm{prune}}^{\\ell}\\cap\\mathcal{E}_{\\mathrm{exp}}^{\\ell,h^{\\prime}}$ , we can then apply Lemma 7 with $u$ and $v$ as defined above to get that the bound fails with probability at most 30H2(e|l Union bounding over h and \u03c0 we get that the stated result fails with probability at most $\\frac{\\delta}{30H\\ell^{2}}$ ", "page_idx": 25}, {"type": "text", "text": "Proof of Event (2). Choose ", "text_level": 1, "page_idx": 25}, {"type": "equation", "text": "$$\nv=e_{i}^{\\top}\\left(\\prod_{i=h^{\\prime}+1}^{h}M_{\\ell,i}P_{i}\\pi_{i}\\right)~~~\\mathrm{and}~~~u=M_{h^{\\prime},\\ell}\\left((\\pi_{h^{\\prime}}-\\bar{\\pi}_{\\ell,h^{\\prime}})w_{\\ell,h^{\\prime}}^{\\bar{\\pi}}+\\pi_{h^{\\prime}}\\widehat{\\delta}_{\\ell,h^{\\prime}}^{\\pi}\\right).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Note that by construction of $w_{\\ell,h^{\\prime}}^{\\bar{\\pi}}$ and $\\widehat{\\delta}_{\\ell,h^{\\prime}}^{\\pi}$ we have that $u_{s a}=0$ for $s\\notin S_{\\ell,h^{\\prime}}^{\\mathrm{keep}}$ SkhePp, and so on Seb', Cexp\uff0cwe have $\\begin{array}{r}{N_{\\ell,h^{\\prime}}(s,a)\\ge\\frac{K_{\\mathrm{unif}}^{\\ell}\\epsilon_{\\mathrm{unif}}^{\\ell}}{2S A}}\\end{array}$ for all $(s,a)\\in\\mathrm{support}(u)$ . Furthermore, we have that $v\\in[0,1]^{S}$ by Lemma 10. Then, the event follows by invoking Lemma 7. ", "page_idx": 25}, {"type": "text", "text": "Proof of Event (3). By Hoeffding's inequality, for any $(s,a)$ , we have, with probability at least $1-{\\frac{\\delta}{24S^{2}A H\\ell^{2}}}$ 24S2AHC2: ", "page_idx": 25}, {"type": "equation", "text": "$$\n|\\widehat{P}_{\\ell,h}(s^{\\prime}\\mid s,a)-P_{h}(s^{\\prime}\\mid s,a)|\\leq\\sqrt{\\frac{\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}{N_{\\ell,h}(s,a)}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Thus, we have that with probability at least $1-\\frac{\\delta}{24S A H\\ell^{2}}$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\sum_{s^{\\prime}}|\\widehat{P}_{\\ell,h}(s^{\\prime}\\mid s,a)-P_{h}(s^{\\prime}\\mid s,a)|\\leq S\\sqrt{\\frac{\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}{N_{\\ell,h}(s,a)}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Union bounding over all $(s,a)$ , we obtain that this holds with probability at least $\\begin{array}{r}{1-\\frac{\\delta}{24H\\ell^{2}}}\\end{array}$ ", "page_idx": 25}, {"type": "text", "text": "Proof of Event (4). Note first that $\\begin{array}{r c l}{\\langle\\widehat{r}_{\\ell,h}\\;-\\;\\widetilde{r}_{\\ell,h},\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}\\;+\\;(\\pi_{h}\\;-\\;\\bar{\\pi}_{\\ell,h})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}\\rangle}&{=}&{\\langle\\widehat{r}_{\\ell,h}\\;-\\;\\widehat{r}_{\\ell,h}\\;\\cdots\\rangle}\\end{array}$ $\\widetilde{r}_{\\ell,h},M_{\\ell,h}(\\pmb{\\pi}_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}+(\\pmb{\\pi}_{h}-\\bar{\\pi}_{\\ell,h})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}})\\rangle$ The resulthen fllows on $\\mathcal{E}_{\\mathrm{prune}}^{\\ell}$ by direct aplication of Lemma 8. ", "page_idx": 25}, {"type": "text", "text": "The final result then holds by a union bound. ", "page_idx": 25}, {"type": "text", "text": "Lemma 16. Let $\\bar{\\mathcal{E}}_{\\mathrm{est}}^{\\ell}$ denote the event that at epoch $\\ell$ and for each $h$ ", "page_idx": 25}, {"type": "text", "text": "$(I)$ For all $\\pi\\in\\Pi_{\\ell}$ and $h\\in[H]$ ,we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\vert\\langle P_{h}^{\\top}M_{\\ell,h+1}\\widetilde V_{\\ell,h+1}+r_{h},(\\pmb{\\pi}_{h}-\\bar{\\pi}_{\\ell,h})(w_{\\ell,h}^{\\bar{\\pi}}-\\widehat{w}_{\\ell,h}^{\\bar{\\pi}})\\rangle\\right\\vert\\leq\\frac{2H}{3\\bar{n}_{\\ell}}\\log\\frac{60H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}}\\\\ &{+\\sqrt{\\frac{2\\mathbb E_{s\\sim w_{\\ell,h}^{\\pi}}\\left[\\langle P_{h}^{\\top}M_{\\ell,h+1}\\widetilde V_{\\ell,h+1}^{\\pi}+r_{h},(\\pmb{\\pi}_{h}-\\bar{\\pi}_{\\ell,h})e_{s}\\rangle^{2}\\right]}{\\bar{n}_{\\ell}}\\cdot\\log\\frac{60H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "(2\uff09 For all canonical vectors $\\boldsymbol{e}_{s}\\in\\mathbb{R}^{S}$", "page_idx": 25}, {"type": "equation", "text": "$$\n|\\langle e_{s},\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}-w_{\\ell,h}^{\\bar{\\pi}}\\rangle|\\leq\\sqrt{\\frac{2\\log\\left(\\frac{30H\\ell^{2}S}{\\delta}\\right)}{\\bar{n}_{\\ell}}}+\\frac{2\\log\\left(\\frac{30H\\ell^{2}S}{\\delta}\\right)}{\\bar{n}_{\\ell}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Then $\\begin{array}{r}{\\mathbb{P}[(\\bar{\\mathcal{E}}_{\\mathrm{est}}^{\\ell})^{c}]\\leq\\frac{\\delta}{15\\ell^{2}}}\\end{array}$ ", "page_idx": 25}, {"type": "text", "text": "Proof. Proof of Event (1). Consider  a fixed  choice of $\\pi$ \uff0cand let $\\begin{array}{r l r l}{u_{s}^{\\pi}}&{{}}&{=}\\end{array}$ $\\left\\langle P_{h}^{\\top}\\widetilde{V}_{\\ell,h+1}^{\\pi}+r_{h},(\\pi_{h}-\\bar{\\pi}_{\\ell,h})e_{s}\\right\\rangle$ ad note that $|u_{s}^{\\pi}|\\ \\ \\leq\\ H$ for all $s$ Lemma 9 then gives that with probability at least 30H(2-nl we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle P_{h}^{\\top}M_{\\ell,h+1}\\widetilde{V}_{\\ell,h+1}+r_{h},(\\pi_{h}-\\bar{\\pi}_{\\ell,h})(w_{\\ell,h}^{\\bar{\\pi}}-\\widehat{w}_{\\ell,h}^{\\bar{\\pi}})\\rangle\\Big|}\\\\ &{\\leq\\sqrt{\\frac{2\\mathbb{E}_{s\\sim w_{\\ell,h}^{\\ast}}[\\langle P_{h}^{\\top}M_{\\ell,h+1}\\widetilde{V}_{\\ell,h+1}^{\\pi}+r_{h},(\\pi_{h}-\\bar{\\pi}_{\\ell,h})e_{s}\\rangle^{2}]}{\\bar{n}_{\\ell}}\\cdot\\log\\frac{60H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}}+\\frac{2H}{3\\bar{n}_{\\ell}}\\log\\frac{60H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Proof of Event (2). For a fixed choice of $s\\in[S]$ , the event follows from Lemma 9 with $u=e_{s}$ with probability $1-\\delta$ ,where $\\begin{array}{r}{\\delta=\\frac{\\delta}{30H\\ell^{2}S}}\\end{array}$ . Once we take the union bound over all $s\\in[S]$ , then the event follows with probability $\\begin{array}{r}{1-\\frac{\\delta}{30H\\ell^{2}}}\\end{array}$ ", "page_idx": 26}, {"type": "text", "text": "The result then holds by union bounding over each of these for all $h$ ", "page_idx": 26}, {"type": "text", "text": "Lemma 17. On prune for all h and T we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\delta_{\\ell,h+1}^{\\pi}-\\widetilde{\\delta}_{\\ell,h+1}^{\\pi}}\\\\ {\\displaystyle=\\sum_{i=0}^{h-2}\\left(\\prod_{j=h-i+1}^{h}M_{\\ell,j+1}P_{j}\\pi_{j}\\right)M_{\\ell,h-i+1}P_{h-i}(\\pi_{h-i}-\\bar{\\pi}_{h-i})(w_{\\ell,h-i}^{\\bar{\\pi}_{\\ell}}-\\widehat{w}_{\\ell,h-i}^{\\bar{\\pi}_{\\ell}})+\\Delta_{\\ell,h+1}^{\\pi}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "for some $\\Delta_{\\ell,h}^{\\pi}\\in\\mathbb{R}^{S}$ with $\\|\\Delta_{\\ell,h}^{\\pi}\\|_{2}\\leq32S H\\epsilon_{\\mathrm{unif}}^{\\ell}$ Furthermore, for any $\\pi$ and any $i,k$ satisying $0\\leq i\\leq k\\leq H,$ we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\left\\|\\left(\\prod_{j=i}^{k}M_{\\ell,j+1}P_{j}\\pi_{j}-\\prod_{j=i}^{k}P_{j}\\pi_{j}\\right)w_{i}^{\\pi}\\right\\|_{2}\\leq32S H\\epsilon_{\\mathrm{unif}}^{\\ell}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Proof. By definition, we have that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\delta_{\\ell,h+1}^{\\pi}-\\widetilde{\\delta}_{\\ell,h+1}^{\\pi}}\\\\ &{=P_{h}(\\pi_{h}-\\bar{\\pi}_{\\ell,h})w_{\\ell,h}^{\\bar{\\pi}_{\\ell}}+P_{h}\\pi_{h}\\delta_{\\ell,h}^{\\pi}-M_{\\ell,h+1}P_{h}(\\pi_{h}-\\bar{\\pi}_{\\ell,h})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}-M_{\\ell,h+1}P_{h}\\pi_{h}\\widetilde{\\delta}_{\\ell,h}^{\\pi}}\\\\ &{=(I-M_{\\ell,h+1})P_{h}(\\pi_{h}-\\bar{\\pi}_{\\ell,h})w_{\\ell,h}^{\\bar{\\pi}_{\\ell}}+M_{\\ell,h+1}P_{h}(\\pi_{h}-\\bar{\\pi}_{\\ell,h})(w_{\\ell,h}^{\\bar{\\pi}_{\\ell}}-\\widehat{w}_{\\ell,h}^{\\bar{\\pi}})}\\\\ &{\\qquad+\\,(I-M_{\\ell,h+1})P_{h}\\pi_{h}\\delta_{\\ell,h}^{\\pi}+M_{\\ell,h+1}P_{h}\\pi_{h}(\\delta_{\\ell,h}^{\\pi}-\\widetilde{\\delta}_{\\ell,h}^{\\pi})}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{i=0}^{h-2}\\left(\\prod_{j=h-i+1}^{h}M_{\\ell,j+1}P_{j}\\pi_{j}\\right)\\bigg[(I-M_{\\ell,h-i+1})P_{h-i}(\\pi_{h-i}-\\bar{\\pi}_{h-i})w_{\\ell,h-i}^{\\bar{\\pi}_{\\ell}}}}\\\\ &{\\quad+\\,M_{\\ell,h-i+1}P_{h-i}(\\pi_{h-i}-\\bar{\\pi}_{h-i})(w_{\\ell,h-i}^{\\bar{\\pi}_{\\ell}}-\\widehat{w}_{\\ell,h-i}^{\\bar{\\pi}_{\\ell}})+(I-M_{\\ell,h-i+1})P_{h-i}\\pi_{h-i}\\delta_{\\ell,h-i}^{\\bar{\\pi}}\\bigg]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Note that $[P_{h-i}(\\pi_{h-i}\\;-\\;\\bar{\\pi}_{h-i})w_{\\ell,h^{\\prime}}^{\\bar{\\pi}_{\\ell}}]_{s}\\;\\;\\le\\;\\;W_{h-i+1}^{\\star}(s)$ .and similarly $\\begin{array}{r l}{[P_{h-i}\\pmb{\\pi}_{h-i}\\delta_{\\ell,h-i}^{\\pi}]_{s}}&{{}\\le}\\end{array}$ $W_{h-i+1}^{\\star}(s)$ . On the event $\\mathcal{E}_{\\mathrm{prune}}^{\\ell}$ , we have that if $[M\\ell,h{-}i{+}1]s,s\\,=\\,0$ then $W_{h-i+1}^{\\star}(s)\\leq32\\epsilon_{\\mathrm{unif}}^{\\ell}$ It follows from this that every non-zero element in $(I-M_{\\ell,h-i+1})P_{h-i}(\\pi_{h-i}-\\bar{\\pi}_{h-i})w_{\\ell,h-i}^{\\bar{\\pi}_{\\ell}}$ and $(I-M_{\\ell,h-i+1})P_{h-i}\\pi_{h-i}\\delta_{\\ell,h-i}^{\\pi}$ is bounded by $32\\epsilon_{\\mathrm{unif}}^{\\ell}$ .So: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|(I-M_{\\ell,h-i+1})P_{h-i}(\\pi_{h-i}-\\bar{\\pi}_{h-i})w_{\\ell,h-i}^{\\bar{\\pi}_{\\ell}}\\|_{2}\\leq32\\sqrt{S}\\epsilon_{\\mathrm{unif~}}^{\\ell}\\mathrm{and}}\\\\ &{\\|(I-M_{\\ell,h-i+1})P_{h-i}\\pi_{h-i}\\delta_{\\ell,h-i}^{\\pi}\\|_{2}\\leq32\\sqrt{S}\\epsilon_{\\mathrm{unif}}^{\\ell}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "By Lemma 11, we can bound ", "page_idx": 26}, {"type": "equation", "text": "$$\n||\\prod_{j=h-i+1}^{h}M_{\\ell,j+1}P_{j}\\pi_{j}||_{2}\\leq\\sqrt{S}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Combining these gives the result. ", "page_idx": 27}, {"type": "text", "text": "We now prove the second part of the result. Denote $A_{j}:=M_{\\ell,j+1}P_{j}\\pmb{\\pi}_{j}$ and $B_{j}:=P_{j}\\pmb{\\pi}_{j}$ . Then ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{c l}{{\\displaystyle\\prod_{j=i}^{k}{M_{\\ell,j+1}P_{j}\\pi_{j}}-\\prod_{j=i}^{k}{P_{j}\\pi_{j}}=\\displaystyle\\prod_{j=i}^{k}{A_{j}}-\\prod_{j=i}^{k}{B_{j}}}}\\\\ {{\\displaystyle}}&{{\\qquad=A_{k}\\left(\\prod_{j=i}^{k-1}{A_{j}}-\\prod_{j=i}^{k-1}{B_{j}}\\right)+(A_{k}-B_{k})\\prod_{j=i}^{k-1}{B_{j}}}}\\\\ {{\\displaystyle}}&{{\\vdots}}\\\\ {{\\displaystyle}}&{{\\displaystyle=\\sum_{s=i}^{k}\\left(\\prod_{j=s+1}^{k}A_{j}\\right)(A_{s}-B_{s})\\left(\\prod_{j^{\\prime}=i}^{s-1}B_{j^{\\prime}}\\right).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "By Lemma 11 we have $\\begin{array}{r}{\\|\\prod_{j=s+1}^{k}A_{j}\\|_{2}\\leq\\sqrt{S}}\\end{array}$ . Furthermore, note that $\\begin{array}{r}{\\prod_{j^{\\prime}=i}^{s-1}B_{j^{\\prime}}w_{i}^{\\pi}=w_{s}^{\\pi}}\\end{array}$ So it follows that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\left\\|(\\prod_{j=i}^{k}M_{\\ell,j+1}P_{j}\\pi_{j}-\\prod_{j=i}^{k}P_{j}\\pi_{j})w_{i}^{\\pi}\\right\\|_{2}\\leq\\sum_{s=i}^{k}\\sqrt{S}\\|(A_{s}-B_{s})w_{s}^{\\pi}\\|_{2}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "By the same argument as above, we can bound $\\|(A_{s}-B_{s})w_{s}^{\\pi}\\|_{2}\\leq32\\sqrt{S}\\epsilon_{\\mathrm{unif}}^{\\ell}$ ", "page_idx": 27}, {"type": "text", "text": "Lemma 18. On thevent $\\begin{array}{r}{\\mathcal{E}_{\\mathrm{prune}}^{\\ell}\\cap\\big(\\cap_{h^{\\prime}\\leq h}\\mathcal{E}_{\\mathrm{est}}^{\\ell,h^{\\prime}}\\big)\\cap\\big(\\cap_{h^{\\prime}\\leq h}\\mathcal{E}_{\\mathrm{exp}}^{\\ell,h^{\\prime}}\\big)}\\end{array}$ we have fo al $\\pi\\in\\Pi_{\\ell}$ ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\|\\widehat{\\delta}_{\\ell,h+1}^{\\pi}-\\delta_{\\ell,h+1}^{\\pi}\\|_{2}\\leq\\sqrt{S H\\beta_{\\ell}\\epsilon_{\\mathrm{exp}}^{\\ell}}+S H(\\sqrt{8\\epsilon_{\\ell}^{5/3}}+32\\epsilon_{\\mathrm{unif}}^{\\ell}).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Proof. We can write ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\widehat{\\delta}_{\\ell,h+1}^{\\pi}-\\delta_{\\ell,h+1}^{\\pi}\\|_{2}\\leq\\|\\widehat{\\delta}_{\\ell,h+1}^{\\pi}-\\widetilde{\\delta}_{\\ell,h+1}^{\\pi}\\|_{2}+\\|\\widetilde{\\delta}_{\\ell,h+1}^{\\pi}-\\delta_{\\ell,h+1}^{\\pi}\\|_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "From Lemma 12 we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\stackrel{\\widehat{\\omega}_{R,h+1}^{\\prime\\prime}}{\\omega_{h+1}}-\\widehat{\\delta}_{\\ell,h+1}^{\\overline{{\\ell}}}}\\\\ {=\\displaystyle\\sum_{i=0}^{h-2}\\left(\\prod_{j=h-i+1}^{h}M_{\\ell,j+1}P_{j}\\pi_{j}\\right)(P_{h-i}-\\widehat{P}_{\\ell,h-i})M_{\\ell,h-i}\\Big[\\big(\\pi_{h-i}-\\overline{{\\pi}}_{\\ell,h-i}\\big)\\widehat{w}_{\\ell,h-i}^{\\overline{{\\ell}}}+\\pi_{h-i}\\widehat{\\delta}_{\\ell,h-i}^{\\overline{{\\ell}}}\\Big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "From Event (2) of $\\ensuremath{\\mathcal{E}^{\\ell,h}}_{\\mathrm{est}}$ in Lemma 15, we have that for all canonical vectors $e_{s}$ and $\\pi\\in\\Pi_{\\ell}$ ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\langle e_{s},\\left(\\prod_{j=h-i+1}^{h}M_{\\ell,j+1}P_{j}\\pi_{j}\\right)(P_{h-i}-\\widehat{P}_{\\ell,h-i})M_{\\ell,h-i}\\Big[(\\pi_{h-i}-\\bar{\\pi}_{h-i})\\widehat{w}_{\\ell,h-i}^{\\bar{\\pi}}+\\pi_{h-i}\\widehat{\\delta}_{\\ell,h-i}^{\\pi}\\Big]\\right\\rangle}\\\\ &{\\leq\\beta_{\\ell}\\sqrt{\\displaystyle{\\sum_{s,a}\\frac{[M_{\\ell,h-i}((\\pi_{h-i}-\\bar{\\pi}_{\\ell,h-i})\\widehat{w}_{\\ell,h-i}^{\\bar{\\pi}}+\\pi_{h-i}\\widehat{\\delta}_{\\ell,h-i}^{\\pi})]_{s,a}^{2}}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Now, summing over the bound above for all canonical vectors, and applying this for each $i$ ,it follows that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\|\\widehat{\\delta}_{\\ell,h+1}^{\\pi}-\\widetilde{\\delta}_{\\ell,h+1}^{\\pi}\\|_{2}^{2}\\le S\\beta_{\\ell}^{2}\\sum_{h^{\\prime}=1}^{h}\\sum_{s,a}\\frac{[M_{\\ell,h^{\\prime}}((\\pi_{h^{\\prime}}-\\pi_{\\ell,h^{\\prime}})\\widehat{w}_{\\ell,h^{\\prime}}^{\\pi}+\\pi_{h^{\\prime}}\\widehat{\\delta}_{\\ell,h^{\\prime}}^{\\pi})]_{s,a}^{2}}{N_{\\ell,h^{\\prime}}(s,a)}\\le S H\\beta_{\\ell}\\epsilon_{\\mathrm{exp}}^{\\ell}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the last inequality holds on n<hp ", "page_idx": 27}, {"type": "text", "text": "We now turn to bounding $||\\widetilde{\\delta}_{\\ell,h+1}^{\\pi}-\\delta_{\\ell,h+1}^{\\pi}||_{2}$ By Lemma 17 we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\delta_{\\ell,h+1}^{\\pi}-\\widetilde{\\delta}_{\\ell,h+1}^{\\pi}}\\\\ {\\displaystyle=\\sum_{i=0}^{h-2}\\left(\\prod_{j=h-i+1}^{h}M_{\\ell,j+1}P_{j}\\pi_{j}\\right)M_{\\ell,h-i+1}P_{h-i}(\\pi_{h-i}-\\bar{\\pi}_{h-i})(w_{\\ell,h-i}^{\\bar{\\pi}_{\\ell}}-\\widehat{w}_{\\ell,h-i}^{\\bar{\\pi}_{\\ell}})+\\Delta_{\\ell,h+1}^{\\pi}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "for some $\\Delta_{\\ell,h}^{\\pi}\\in\\mathbb{R}^{S}$ With $\\|\\Delta_{\\ell,h}^{\\pi}\\|_{2}\\leq32S H\\epsilon_{\\mathrm{unif}}^{\\ell}$ Furthermore, on $\\ensuremath{\\mathcal{E}}_{\\mathrm{est}}^{\\ell,h-i}$ , by Lemma 19 we can bound ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\|w_{\\ell,h-i}^{\\bar{\\pi}_{\\ell}}-\\widehat{w}_{\\ell,h-i}^{\\bar{\\pi}_{\\ell}}\\|_{2}\\leq\\sqrt{8S\\epsilon_{\\ell}^{5/3}}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Combining this with Lemma 11 gives the result. ", "page_idx": 28}, {"type": "text", "text": "Lemma 19. On event $\\bar{\\mathcal{E}}_{\\mathrm{est}}^{\\ell}$ we have: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\lVert\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}-w_{\\ell,h}^{\\bar{\\pi}}\\rVert_{2}^{2}\\leq8S\\epsilon_{\\ell}^{5/3}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof. From Event (2) of Lemma 16, we have that for all canonical vectors $e_{i}\\in\\mathbb{R}^{S}$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n|\\langle e_{i},\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}-w_{\\ell,h}^{\\bar{\\pi}}\\rangle|\\leq\\sqrt{\\frac{2\\log\\left(\\frac{30H\\ell^{2}S}{\\delta}\\right)}{\\bar{n}_{\\ell}}}+\\frac{2\\log\\left(\\frac{30H\\ell^{2}S}{\\delta}\\right)}{\\bar{n}_{\\ell}}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Then, combining these bounds together for all $s$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\|\\hat{w}_{\\ell,h}^{\\bar{\\pi}}-w_{\\ell,h}^{\\bar{\\pi}}\\|_{2}^{2}\\le\\frac{4S\\log\\left(\\frac{30H\\ell^{2}S}{\\delta}\\right)}{\\bar{n}_{\\ell}}+\\frac{4S\\log^{2}\\left(\\frac{30H\\ell^{2}S}{\\delta}\\right)}{\\bar{n}_{\\ell}^{2}}\\le4S\\epsilon_{\\ell}^{5/3}+4S\\epsilon_{\\ell}^{10/3}\\le8S\\epsilon_{\\ell}^{5/3},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the last inequality follows from our choice of $\\bar{n}_{\\ell}$ in Algorithm 2. ", "page_idx": 28}, {"type": "text", "text": "Lema2o. Let $\\begin{array}{r}{\\mathcal{E}_{\\mathrm{good}}:=(\\cap_{\\ell=1}^{\\infty}\\mathcal{E}_{\\mathrm{prune}}^{\\ell})\\cap(\\cap_{\\ell=1}^{\\infty}\\bar{\\mathcal{E}}_{\\mathrm{est}}^{\\ell})\\cap(\\cap_{\\ell=1}^{\\infty}\\cap_{h\\in[H]}\\mathcal{E}_{\\mathrm{est}}^{\\ell,h})\\cap(\\cap_{\\ell=1}^{\\infty}\\cap_{h\\in[H]}\\mathcal{E}_{\\mathrm{exp}}^{\\ell,h}).}\\end{array}$ Then $\\mathbb{P}[\\mathcal{E}_{\\mathrm{good}}]\\geq1-2\\delta$ ", "page_idx": 28}, {"type": "text", "text": "Proof. By a union bound and basic set manipulations, we have: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{P}[\\mathcal{E}_{\\mathrm{good}}^{c}]\\leq\\sum_{\\ell=1}^{\\infty}\\mathbb{P}[(\\mathcal{E}_{\\mathrm{prune}}^{\\ell})^{c}]+\\sum_{\\ell=1}^{\\infty}\\mathbb{P}[(\\bar{\\mathcal{E}}_{\\mathrm{est}}^{\\ell})^{c}]}}\\\\ &{}&{\\quad+\\sum_{\\ell=1}^{\\infty}\\sum_{h=1}^{H}\\mathbb{P}[(\\mathcal{E}_{\\mathrm{exp}}^{\\ell,h})^{c}\\cap\\mathcal{E}_{\\mathrm{prune}}^{\\ell}\\cap\\bar{\\mathcal{E}}_{\\mathrm{est}}^{\\ell}\\cap(\\cap_{h^{\\prime}\\leq h-1}\\mathcal{E}_{\\mathrm{est}}^{\\ell,h^{\\prime}})\\cap(\\cap_{h^{\\prime}\\leq h-1}\\mathcal{E}_{\\mathrm{exp}}^{\\ell,h^{\\prime}})]}\\\\ &{}&{\\quad+\\sum_{\\ell=1}^{\\infty}\\sum_{h=1}^{H}\\mathbb{P}[(\\mathcal{E}_{\\mathrm{est}}^{\\ell,h})^{c}\\cap\\mathcal{E}_{\\mathrm{prune}}^{\\ell}\\cap(\\cap_{h^{\\prime}\\leq h}\\mathcal{E}_{\\mathrm{exp}}^{\\ell,h})].}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "By Lemma 13, we have $\\mathbb{P}[(\\mathcal{E}_{\\mathrm{prune}}^{\\ell})^{c}]\\leq\\delta/3\\ell^{2}$ .By By Lemma 16, we have $\\begin{array}{r}{\\mathbb{P}[(\\bar{\\mathcal{E}}_{\\mathrm{est}}^{\\ell})^{c}]\\,\\leq\\,\\frac{\\delta}{15\\ell^{2}}}\\end{array}$ By Lemma 14, we have $\\begin{array}{r}{\\mathbb{P}[(\\mathscr{E}_{\\mathrm{exp}}^{\\ell,h})^{c}\\cap\\mathscr{E}_{\\mathrm{prune}}^{\\ell}\\cap\\bar{\\mathscr{E}}_{\\mathrm{ext}}^{\\ell}\\cap(\\cap_{h^{\\prime}\\le h-1}\\mathscr{E}_{\\mathrm{est}}^{\\ell,h^{\\prime}})\\cap(\\cap_{h^{\\prime}\\le h-1}\\mathscr{E}_{\\mathrm{exp}}^{\\ell,h^{\\prime}})]\\le\\frac{\\delta}{6H\\ell^{2}}}\\end{array}$ By Lemma 15 we have $\\begin{array}{r}{\\mathbb{P}[(\\mathscr{E}_{\\mathrm{est}}^{\\ell,h})^{c}\\cap\\mathscr{E}_{\\mathrm{prune}}^{\\ell}\\cap(\\cap_{h^{\\prime}\\leq h}\\mathscr{E}_{\\mathrm{exp}}^{\\ell,h})]\\leq\\frac{\\delta}{6H\\ell^{2}}}\\end{array}$ Putting tistoghwea the above as ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\leq\\sum_{\\ell=1}^{\\infty}(\\frac{\\delta}{3\\ell^{2}}+\\frac{\\delta}{15\\ell^{2}})+\\sum_{\\ell=1}^{\\infty}\\sum_{h=1}^{H}\\frac{2\\delta}{6H\\ell^{2}}\\leq2\\delta.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "C.4  Estimation of Reference Policy and Values ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Lemma 21. On $\\mathcal{E}_{\\mathrm{good}}$ we have that: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\left|\\sum_{h=1}^{H}\\langle\\widetilde{r}_{\\ell,h},\\pi_{h}(\\widetilde{\\delta}_{\\ell,h}^{\\pi}-\\widehat{\\delta}_{\\ell,h}^{\\pi})\\rangle\\right|\\leq\\epsilon_{\\ell}\\quad a n d\\quad\\sum_{h=1}^{H}|\\langle\\widehat{r}_{\\ell,h}-\\widetilde{r}_{\\ell,h},\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}+(\\pi_{h}-\\bar{\\pi}_{\\ell,h})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}\\rangle|\\leq\\epsilon_{\\ell}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Proof. From Lemma 12 we have: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{\\delta}_{\\ell,h+1}^{\\pi}-\\widehat{\\delta}_{\\ell,h+1}^{\\pi}}\\\\ &{=\\displaystyle\\sum_{i=0}^{h-2}\\left(\\prod_{j=h-i+1}^{h}M_{\\ell,j+1}P_{j}\\pi_{j}\\right)(P_{h-i}-\\widehat{P}_{\\ell,h-i})M_{\\ell,h-i}\\Big[\\big(\\pi_{h-i}-\\bar{\\pi}_{\\ell,h-i}\\big)\\widehat{w}_{\\ell,h-i}^{\\bar{\\pi}}+\\pi_{h-i}\\widehat{\\delta}_{\\ell,h-i}^{\\pi}\\Big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "A sufficient condition for (C.5) is that, for each $i$ ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\left|\\left\\langle\\pi_{h}^{\\top}\\widetilde{r}_{\\ell,h},\\left(\\prod_{j=h-i+1}^{h}M_{\\ell,j+1}P_{j}\\pi_{j}\\right)(P_{h-i}-\\widehat{P}_{\\ell,h-i})\\right.\\right.}}\\\\ &{}&{\\left.\\left.M_{\\ell,h-i}\\left[(\\pi_{h-i}-\\bar{\\pi}_{\\ell,h-i})\\widehat{w}_{\\ell,h-i}^{\\bar{\\pi}}+\\pi_{h-i}\\widehat{\\delta}_{\\ell,h-i}^{\\pi}\\right]\\right\\rangle\\right|\\leq\\epsilon_{\\ell}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "On $\\mathcal{E}_{\\mathrm{good}}$ and i prticular $\\ensuremath{\\mathcal{E}}_{\\mathrm{est}}^{\\ell,h}$ (Lemma 5), wanboud th fhand sieothis ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\beta_{\\ell}\\sqrt{\\displaystyle\\sum_{s,a}\\frac{\\left[M_{\\ell,h-i}\\left((\\pi_{h-i}-\\bar{\\pi}_{\\ell,h-i})\\widehat{w}_{\\ell,h-i}^{\\bar{\\pi}}+\\pi_{h-i}\\widehat{\\delta}_{\\ell,h-i}^{\\pi}\\right)\\right]_{(s,a)}^{2}}{N_{\\ell,h-i}(s,a)}}}\\\\ &{\\leq\\beta_{\\ell}\\sqrt{\\epsilon_{\\ell}^{2}/H^{4}\\beta_{\\ell}^{2}}}\\\\ &{\\leq\\epsilon_{\\ell}/H^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the second inequality holds on $\\mathcal{E}_{\\mathrm{good}}$ (in particular $\\mathcal{E}_{\\mathrm{exp}}^{\\ell,h-i}$ ). This proves the first inequality. On Sest we can also bound ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\langle\\widehat{r}_{\\ell,h}-\\widetilde{r}_{\\ell,h},\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}+(\\pi_{h}-\\bar{\\pi}_{\\ell,h})\\widehat{w}_{\\ell,h}^{\\pi}\\rangle|}\\\\ &{\\leq\\beta_{\\ell}\\sqrt{\\displaystyle\\sum_{s,a}\\frac{\\left[M_{\\ell,h}\\left((\\pi_{h}-\\bar{\\pi}_{\\ell,h^{\\prime}})\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}+\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}\\right)\\right]_{(s,a)}^{2}}{N_{\\ell,h}(s,a)}}}\\\\ &{\\leq\\epsilon_{\\ell}/H^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "This proves the second inequality. ", "page_idx": 29}, {"type": "text", "text": "Lemma 22. On event $\\mathcal{E}_{\\mathrm{good}}$ for any timestep $h,$ policies $\\pi,\\pi^{\\prime}$ , and action $a$ we have: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\pi^{\\prime}}[\\big|\\widehat{Q}_{\\ell,h}^{\\pi}(s_{h},a)-Q_{h}^{\\pi}(s_{h},a)\\big|]\\leq H^{2}S^{3/2}\\sqrt{A\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}\\cdot\\epsilon_{\\ell}^{1/3}+64H^{2}S\\epsilon_{\\mathrm{unif}}^{\\ell}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Proof. By Lemma E.15 of [10], we have that: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{Q}_{\\ell,h}^{\\pi}(s,a)-Q_{h}^{\\pi}(s,a)}\\\\ &{\\ =\\mathbb{E}_{\\pi}\\left[\\displaystyle\\sum_{h^{\\prime}=h}^{H}\\sum_{s^{\\prime}}(\\widehat{P}_{\\ell,h^{\\prime}}(s^{\\prime}\\mid s_{h^{\\prime}},a_{h^{\\prime}})-P_{h}(s^{\\prime}\\mid s_{h^{\\prime}},a_{h^{\\prime}}))\\widehat{V}_{\\ell,h^{\\prime}+1}^{\\pi}(s_{h^{\\prime}})\\mid s_{h}=s,a_{h}=a\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "On Egood, in particular 8est', est' , we can bound, for s ES $s\\in\\mathcal{S}_{\\ell,h^{\\prime}}^{\\mathrm{keep}}$ and any $a$ ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{s^{\\prime}}(\\widehat{P}_{\\ell,h^{\\prime}}(s^{\\prime}\\,|\\,s,a)-P_{h}(s^{\\prime}\\,|\\,s,a))\\widehat{V}_{\\ell,h^{\\prime}+1}^{\\pi}(s^{\\prime})\\Bigg|}\\\\ &{\\le S H\\sqrt{\\frac{\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}{N_{\\ell,h^{\\prime}}(s,a)}}\\le S H\\sqrt{\\frac{S A\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}{K_{\\mathrm{unif}}^{\\ell}\\epsilon_{\\mathrm{unif}}^{\\ell}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "and where the last nqualty folwsn $\\mathcal{E}_{\\mathrm{exp}}^{\\ell,h^{\\prime}}$ . By our choice of $K_{\\mathrm{unif}}^{\\ell}$ and $\\epsilon_{\\mathrm{unif}}^{\\ell}$ we can further bound this as ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\leq S H\\sqrt{S A\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}\\cdot\\epsilon_{\\ell}^{1/3}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "For sePp, wecanbou |(Pe,h(sIs,a)- P(sI s,a)V(s)\u22642H. Wetherefore have that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\pi^{\\prime}}[\\widehat{\\bigotimes}_{\\ell,h}^{\\pi}(s_{h},a)-Q_{h}^{\\pi}(s_{h},a)]\\big[}\\\\ &{\\le\\mathbb{E}_{\\pi^{\\prime}}\\Bigg[\\mathbb{E}_{\\pi}\\Bigg[\\frac{W}{\\Lambda_{\\ell}^{\\pi}-\\mathbf{\\xi}_{h}^{S H}\\sqrt{S A\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}\\cdot\\epsilon_{\\ell}^{1/3}\\cdot\\mathbb{I}\\{s_{h^{\\prime}}\\in S_{\\ell,h^{\\prime}}^{\\mathrm{keep}}\\}}}\\\\ &{\\qquad\\qquad\\quad+2H\\mathbb{I}\\{s_{h^{\\prime}}\\notin S_{\\ell,h^{\\prime}}^{\\mathrm{keep}}\\}\\mid s_{h}=s,a_{h}=a\\Bigg]\\Bigg]}\\\\ &{=\\displaystyle\\sum_{h^{\\prime}=h}^{H}\\mathbb{E}_{\\boldsymbol{\\pi}}\\left[S H\\sqrt{S A\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}\\cdot\\epsilon_{\\ell}^{1/3}\\cdot\\mathbb{I}\\{s_{h^{\\prime}}\\in S_{\\ell,h^{\\prime}}^{\\mathrm{keep}}\\}+2H\\mathbb{I}\\{s_{h^{\\prime}}\\notin S_{\\ell,h^{\\prime}}^{\\mathrm{keep}}\\}\\right]}\\\\ &{\\le H^{2}S^{3/2}\\sqrt{A\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}\\cdot\\epsilon_{\\ell}^{1/3}+64H^{2}S\\epsilon_{\\mathrm{unt}}^{\\ell},}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where the last inequality follows by definition of $S_{\\ell,h^{\\prime}}^{\\mathrm{keep}}$ , and $\\pi^{\\prime}$ is the policy which plays $\\bar{\\pi}_{\\ell}$ for the first $h$ steps and then plays $\\pi$ . This proves the result. \u53e3 ", "page_idx": 30}, {"type": "text", "text": "Lemma 23. On event $\\mathcal{E}_{\\mathrm{good}}$ for all $h$ and any $\\pi$ and $\\pi^{\\prime}$ , we have that ", "page_idx": 30}, {"type": "equation", "text": "$$\n|\\widehat{U}_{\\ell,h}(\\pi,\\pi^{\\prime})-U_{h}(\\pi,\\pi^{\\prime})|\\leq9H^{3}S^{3/2}\\sqrt{A\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}\\cdot\\epsilon_{\\ell}^{1/3}+576H^{3}S\\epsilon_{\\mathrm{unif}}^{\\ell}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Proof. We have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\widehat{U}_{\\ell,h}(\\pi,\\pi^{\\prime})=\\mathbb{E}_{\\pi^{\\prime},\\ell}\\left[\\left(\\widehat{Q}_{\\ell,h}^{\\pi}(s_{h},\\pi_{h}(s_{h}))-\\widehat{Q}_{\\ell,h}^{\\pi}(s_{h},\\pi_{h}^{\\prime}(s_{h}))\\right)^{2}\\right]\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where $\\mathbb{E}_{\\pi^{\\prime},\\ell}$ denotes the expectation induced playing policy $\\pi^{\\prime}$ on the MDP with transition $\\widehat{P}_{\\ell}$ .We can think of this as simply a value function for policy $\\pi$ on the reward $\\check{r}_{h}(s,a)\\;=\\;$ $\\left(\\widehat{Q}_{\\ell,h}^{\\pi}(s,\\pi_{h}(s))-\\widehat{Q}_{\\ell,h}^{\\pi}(s,a)\\right)^{2}$ . Let $\\check{V}$ denote the value function on this reward on $\\widehat{P}_{\\ell}$ , and note that $\\check{V}_{h}(s)\\in[0,H^{2}]$ for all $(s,h)$ . By Lemma E.15 of [10], we then have that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\widehat{U}_{\\ell,h}(\\pi,\\pi^{\\prime})-\\mathbb{E}_{\\pi^{\\prime}}\\left[\\left(\\widehat{Q}_{\\ell,h}^{\\pi}(s_{h},\\pi_{h}(s_{h}))-\\widehat{Q}_{\\ell,h}^{\\pi}(s_{h},\\pi_{h}^{\\prime}(s_{h}))\\right)^{2}\\right]}\\\\ {\\displaystyle=\\mathbb{E}_{\\pi^{\\prime}}\\left[\\displaystyle\\sum_{h=1}^{H}\\sum_{s^{\\prime}}(\\widehat{P}_{\\ell,h}(s^{\\prime}\\mid s_{h},a_{h})-P_{h}(s^{\\prime}\\mid s_{h},a_{h}))\\check{V}_{h+1}(s^{\\prime})\\right]}\\\\ {\\displaystyle\\leq H^{2}\\sum_{h=1}^{H}\\mathbb{E}_{\\pi^{\\prime}}\\left[\\displaystyle\\sum_{s^{\\prime}}|\\widehat{P}_{\\ell,h}(s^{\\prime}\\mid s_{h},a_{h})-P_{h}(s^{\\prime}\\mid s_{h},a_{h})|\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Note that we always have $\\begin{array}{r}{\\sum_{s^{\\prime}}|\\widehat{P}_{\\ell,h}(s^{\\prime}\\mid s_{h},a_{h})-P_{h}(s^{\\prime}\\mid s_{h},a_{h})|\\le2}\\end{array}$ Furthermore, on $\\mathcal{E}_{\\mathrm{good}}$ we also have $\\begin{array}{r}{\\sum_{s^{\\prime}}|\\widehat{P}_{\\ell,h}(s^{\\prime}\\mid s_{h},a_{h})-P_{h}(s^{\\prime}\\mid s_{h},a_{h})|\\le S\\sqrt{\\frac{\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}{N_{\\ell,h}(s_{h},a_{h})}}}\\end{array}$ Ne,(sh,a) . We can therefore bound the above as ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq H^{2}\\underset{h=1}{\\overset{H}{\\sum}}\\mathbb{E}_{\\pi^{\\prime}}\\left[\\operatorname*{min}\\left\\{2,S\\sqrt{\\frac{\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}{N_{\\ell,h}(s_{h},a_{h})}}\\right\\}\\right]}\\\\ &{\\leq H^{2}\\underset{h=1}{\\overset{H}{\\sum}}\\mathbb{E}_{\\pi^{\\prime}}\\left[2\\cdot\\mathbb{I}\\{s_{h}\\notin S_{\\ell,h}^{\\mathrm{keep}}\\}+S\\sqrt{\\frac{\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}{N_{\\ell,h}(s_{h},a_{h})}}\\cdot\\mathbb{I}\\{s_{h}\\in S_{\\ell,h}^{\\mathrm{keep}}\\}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "$s\\,\\in\\,\\mathcal{S}_{\\ell,h}^{\\mathrm{keep}}$ $\\mathcal{E}_{\\mathrm{good}}$ $\\begin{array}{r}{N_{\\ell,h}(s_{h},a_{h})\\:\\geq\\:\\frac{K_{\\mathrm{unif}}^{\\ell}\\epsilon_{\\mathrm{unif}}^{\\ell}}{S A}\\:=\\:\\epsilon_{\\ell}^{2/3}/S A}\\end{array}$ $s_{h}\\notin\\mathcal{S}_{\\ell,h}^{\\mathrm{keep}}$ $W_{h}^{\\star}(s)\\leq32\\epsilon_{\\mathrm{unif}}^{\\ell}$ ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq H^{2}\\displaystyle\\sum_{h=1}^{H}\\left[64S\\epsilon_{\\mathrm{unif}}^{\\ell}+S\\sqrt{S A\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}\\cdot\\epsilon_{\\ell}^{1/3}\\right]}\\\\ &{\\leq64S H^{3}\\epsilon_{\\mathrm{unif}}^{\\ell}+H^{3}S^{3/2}\\sqrt{A\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}\\cdot\\epsilon_{\\ell}^{1/3}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Furthermore, ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\mathbb{E}_{\\pi^{\\prime}}\\left[\\left(\\widehat{Q}_{\\ell,h}^{\\pi}(s,\\pi_{h}(s))-\\widehat{Q}_{\\ell,h}^{\\pi}(s,\\pi_{h}^{\\prime}(s))\\right)^{2}\\right]-\\mathbb{E}_{\\pi^{\\prime}}\\left[(Q_{h}^{\\pi}(s,\\pi_{h}(s))-Q_{h}^{\\pi}(s,\\pi_{h}^{\\prime}(s)))^{2}\\right]\\right|}\\\\ &{=\\bigg|\\mathbb{E}_{\\pi^{\\prime}}\\left[\\left(\\widehat{Q}_{\\ell,h}^{\\pi}(s,\\pi_{h}(s))-Q_{h}^{\\pi}(s,\\pi_{h}(s))+Q_{h}^{\\pi}(s,\\pi_{h}^{\\prime}(s))-\\widehat{Q}_{\\ell,h}^{\\pi}(s,\\pi_{h}^{\\prime}(s))\\right)^{2}\\right]}\\\\ &{\\qquad+\\mathbb{E}_{\\pi^{\\prime}}\\bigg[\\left(\\widehat{Q}_{\\ell,h}^{\\pi}(s,\\pi_{h}(s))-Q_{h}^{\\pi}(s,\\pi_{h}(s))+Q_{h}^{\\pi}(s,\\pi_{h}^{\\prime}(s))-\\widehat{Q}_{\\ell,h}^{\\pi}(s,\\pi_{h}^{\\prime}(s))\\right)}\\\\ &{\\qquad\\qquad\\qquad(Q_{h}^{\\pi}(s,\\pi_{h}(s))-Q_{h}^{\\pi}(s,\\pi_{h}^{\\prime}(s)))\\bigg]\\bigg|}\\\\ &{\\leq4H\\mathbb{E}_{\\pi^{\\prime}}[\\widehat{Q}_{\\ell,h}^{\\pi}(s,\\pi_{h}(s))-Q_{h}^{\\pi}(s,\\pi_{h}(s))]\\|+4H\\mathbb{E}_{\\pi^{\\prime}}[|Q_{h}^{\\pi}(s,\\pi_{h}^{\\prime}(s))-\\widehat{Q}_{\\ell,h}^{\\pi}(s,\\pi_{h}^{\\prime}(s))|]}\\\\ &{\\leq8H^{3}S^{3/2}\\sqrt{A\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}\\cdot\\epsilon_{\\ell}^{1/3}+512H^{3}S_{\\ell}^{\\ell}\\mathrm{u}_{h}^{\\ell}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where the final inequality follows from Lemma 22. Combining this with the above bound completes the argument. \u53e3 ", "page_idx": 31}, {"type": "text", "text": "Lemma 24. On event $\\mathcal{E}_{\\mathrm{good}}$ for all epochs $\\ell$ we have that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\left|\\sum_{h=1}^{H}\\langle\\widetilde{r}_{\\ell,h},\\pi_{h}(\\delta_{\\ell,h}^{\\pi}-\\widetilde{\\delta}_{\\ell,h}^{\\pi})\\rangle+\\langle\\widetilde{r}_{\\ell,h},(\\pi_{h}-\\bar{\\pi}_{\\ell,h})(w_{\\ell,h}^{\\bar{\\pi}}-\\widehat{w}_{\\ell,h}^{\\bar{\\pi}})\\rangle\\right|\\leq\\epsilon_{\\ell}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. We first bound $|\\langle M_{\\ell,h}r_{h},\\pi_{h}(\\delta_{\\ell,h}^{\\pi}-\\widetilde{\\delta}_{\\ell,h}^{\\pi})\\rangle|$ . By Lemma 17 we have that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\delta_{\\ell,h+1}^{\\pi}-\\widetilde\\delta_{\\ell,h+1}^{\\pi}}\\\\ &{=\\displaystyle\\sum_{i=0}^{h-2}\\left(\\prod_{j=h-i+1}^{h}M_{\\ell,j+1}P_{j}\\pi_{j}\\right)M_{\\ell,h-i+1}P_{h-i}(\\pi_{h-i}-\\bar\\pi_{\\ell,h-i})(w_{h-i}^{\\bar{\\pi}}-\\widehat w_{\\ell,h-i}^{\\bar{\\pi}})+\\Delta_{\\ell,h+1}^{\\pi}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "forsome $\\Delta_{\\ell,h}^{\\pi}\\in\\mathbb{R}^{S}$ With $\\|\\Delta_{\\ell,h}^{\\pi}\\|_{2}\\leq32S H\\epsilon_{\\mathrm{unif}}^{\\ell}$ Eunif\u00b7Furthermore, note that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{h=1}^{H}\\sum_{i=0}^{h-2}\\left<\\widetilde{r}_{\\ell,h},\\pi_{h}\\left(\\prod_{j=h-i+1}^{h}M_{\\ell,j+1}P_{j}\\pi_{j}\\right)M_{\\ell,h-i+1}P_{h-i}(\\pi_{h-i}-\\pi_{\\ell,h-i})(w_{h-i}^{\\mp}-\\widehat{w}_{\\ell,h-i}^{\\mp})\\right>}\\\\ {\\displaystyle=\\sum_{h=1}^{H}\\sum_{k=2}^{h}\\left<\\widetilde{r}_{\\ell,h},\\pi_{h}\\left(\\prod_{j=k+1}^{h}M_{\\ell,j+1}P_{j}\\pi_{j}\\right)M_{\\ell,k+1}P_{k}(\\pi_{k}-\\bar{\\pi}_{\\ell,k})(w_{h}^{\\mp}-\\widehat{w}_{\\ell,k}^{\\mp})\\right>}\\\\ {\\displaystyle=\\sum_{k=2}^{H}\\sum_{k=2}^{H}\\left<\\widetilde{r}_{\\ell,h},\\pi_{h}\\left(\\prod_{j=k+1}^{h}M_{\\ell,j+1}P_{j}\\pi_{j}\\right)M_{\\ell,k+1}P_{k}(\\pi_{k}-\\bar{\\pi}_{\\ell,k})(w_{k}^{\\mp}-\\widehat{w}_{\\ell,k}^{\\mp})\\right>}\\\\ {\\displaystyle=\\sum_{k=2}^{H}\\langle P_{k}^{\\top}M_{\\ell,k+1}\\widetilde{V}_{\\ell,k+1},(\\pi_{k}-\\bar{\\pi}_{\\ell,k})(w_{k}^{\\mp}-\\widehat{w}_{\\ell,k}^{\\mp})\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "It follows that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{h=1}^{H}\\langle\\widetilde{r}_{\\ell,h},\\pi_{h}(\\delta_{\\ell,h}^{\\pi}-\\widetilde{\\delta}_{\\ell,h}^{\\pi})\\rangle+\\langle\\widetilde{r}_{\\ell,h},(\\pi_{h}-\\bar{\\pi}_{\\ell,h})(w_{h}^{\\bar{\\pi}}-\\widehat{w}_{\\ell,h}^{\\bar{\\pi}})\\rangle}\\\\ &{\\displaystyle=\\sum_{h=2}^{H}\\langle P_{h}^{\\top}M_{\\ell,h+1}\\widetilde{V}_{\\ell,h+1}+\\widetilde{r}_{\\ell,h},(\\pi_{h}-\\bar{\\pi}_{\\ell,h})(w_{\\ell,h}^{\\bar{\\pi}}-\\widehat{w}_{\\ell,h}^{\\bar{\\pi}})\\rangle+\\Delta}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "for some $\\Delta$ satisfying $|\\Delta|\\leq32S^{3/2}H^{2}\\epsilon_{\\mathrm{unif}}^{\\ell}$ On $\\mathcal{E}_{\\mathrm{good}}$ (specifically $\\bar{\\mathcal{E}}_{\\mathrm{est}}^{\\ell})$ , we can bound ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{h=2}^{H}|\\langle P_{h}^{\\top}M_{\\ell,h+1}\\tilde{V}_{\\ell,h+1}+\\tilde{r}_{\\ell,h},(\\pi_{h}-\\bar{\\pi}_{\\ell,h})(w_{\\ell,h}^{\\bar{\\pi}}-\\widehat{w}_{\\ell,h}^{\\bar{\\pi}})\\rangle|}\\\\ &{\\le\\displaystyle\\sum_{h=2}^{H}\\sqrt{\\frac{2\\mathbb{E}_{s\\sim w_{\\ell,h}^{\\top}}[\\langle P_{h}^{\\top}M_{\\ell,h+1}\\tilde{V}_{\\ell,h+1}^{\\pi}+\\widetilde{r}_{\\ell,h},(\\pi_{h}-\\bar{\\pi}_{\\ell,h})e_{s}\\rangle^{2}]}{\\bar{n}_{\\ell}}\\cdot\\log\\frac{60H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}}}\\\\ &{\\quad\\quad+\\displaystyle\\frac{2H}{3\\bar{n}_{\\ell}}\\log\\frac{60H^{2}\\ell^{2}|\\Pi_{\\ell}|}{\\delta}}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "We can also bound ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{\\bar{\\Xi}}_{s\\sim w_{\\ell,h}^{\\pi}}[\\langle P_{h}^{\\top}M_{\\ell,h+1}\\widetilde{V}_{\\ell,h+1}^{\\pi}+\\widetilde{r}_{\\ell,h},(\\pi_{h}-\\bar{\\pi}_{\\ell,h})e_{s}\\rangle^{2}]}\\\\ &{\\leq2\\mathbb{E}_{s\\sim w_{\\ell,h}^{\\pi}}[\\langle P_{h}^{\\top}V_{h+1}^{\\pi}+r_{h},(\\pi_{h}-\\bar{\\pi}_{\\ell,h})e_{s}\\rangle^{2}]+2H\\mathbb{E}_{s\\sim w_{\\ell,h}^{\\pi}}[\\|\\pi_{h}^{\\top}P_{h}^{\\top}(M_{\\ell,h+1}\\widetilde{V}_{\\ell,h+1}^{\\pi}-V_{h+1}^{\\pi})]_{s}\\|}\\\\ &{\\mathrm{~\\~\\}+2H\\mathbb{E}_{s\\sim w_{\\ell,h}^{\\pi}}[\\|\\overline{{\\pi}}_{\\ell,h}^{\\top}P_{h}^{\\top}(M_{\\ell,h+1}\\widetilde{V}_{\\ell,h+1}^{\\pi}-V_{h+1}^{\\pi})]_{s}\\|+4\\mathbb{E}_{s\\sim w_{\\ell,h}^{\\pi}}[\\operatorname*{sup}_{h}|r_{h}(s,a)-\\widetilde{r}_{\\ell,h}(s,a)|]}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Furthermore, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{s\\sim w_{\\ell,h}^{\\pi}}[|[\\pi_{h}^{\\top}P_{h}^{\\top}(M_{\\ell,h+1}\\widetilde{V}_{\\ell,h+1}^{\\pi}-V_{h+1}^{\\pi})]_{s}|]}\\\\ &{=\\displaystyle\\sum_{s}|[\\pi_{h}^{\\top}P_{h}^{\\top}(M_{\\ell,h+1}\\widetilde{V}_{\\ell,h+1}^{\\pi}-V_{h+1}^{\\pi})]_{s}|w_{\\ell,h}^{\\pi}(s)}\\\\ &{\\le\\sqrt{S}\\|(M_{\\ell,h+1}\\widetilde{V}_{\\ell,h+1}^{\\pi}-V_{h+1}^{\\pi})^{\\top}P_{h}\\pi_{h}w_{\\ell,h}^{\\pi}\\|_{2}}\\\\ &{\\le\\sqrt{S}\\|(\\widetilde{V}_{\\ell,h+1}^{\\pi}-V_{h+1}^{\\pi})^{\\top}P_{h}\\pi_{h}w_{\\ell,h}^{\\pi}\\|_{2}+\\sqrt{S}\\|(M_{\\ell,h+1}\\widetilde{V}_{\\ell,h+1}^{\\pi}-\\widetilde{V}_{\\ell,h+1}^{\\pi})^{\\top}P_{h}\\pi_{h}w_{\\ell,h}^{\\pi}\\|_{2}}\\\\ &{\\le64S^{2}H^{2}\\epsilon_{\\mathrm{unif}}^{\\ell}}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the last inequality follows from the definition of $\\widetilde{V}$ and Lemma 17. A similar bound can be shown for $\\mathbb{E}_{s\\sim w_{\\ell,h}^{\\bar{\\pi}}}[|[\\bar{\\pi}_{\\ell,h}^{\\top}P_{h}^{\\top}(M_{\\ell,h+1}\\widetilde{V}_{\\ell,h+1}^{\\pi}-V_{h+1}^{\\pi})]_{s}|]$ . In addition, by definition of $\\widetilde{r}_{\\ell,h}$ wehave ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{s\\sim w_{\\ell,h}^{\\pi}}[\\underset{a}{\\operatorname*{sup}}\\,|r_{h}(s,a)-\\widetilde{r}_{\\ell,h}(s,a)|]\\le\\mathbb{E}_{s\\sim w_{\\ell,h}^{\\pi}}[\\mathbb{I}\\{s\\notin S_{\\ell,h}^{\\mathrm{keep}}\\}]\\le32S\\epsilon_{\\mathrm{unif}}^{\\ell}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Thus, we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{h=2}^{H}\\big|\\langle P_{h}^{\\top}M_{\\ell,h+1}\\widetilde{V}_{\\ell,h+1}+r_{h},(\\pi_{h}-\\bar{\\pi}_{\\ell,h})(w_{\\ell,h}^{\\bar{\\pi}}-\\hat{w}_{\\ell,h}^{\\bar{\\pi}})\\rangle\\big|}\\\\ &{\\le\\displaystyle\\sum_{h=2}^{H}\\sqrt{\\frac{2\\mathbb{E}_{s\\sim w_{\\ell,h}^{*}}\\big[\\langle P_{h}^{\\top}M_{\\ell,h+1}\\widetilde{V}_{\\ell,h+1}^{\\pi}+r_{h},(\\pi_{h}-\\bar{\\pi}_{\\ell,h})e_{s}\\rangle^{2}\\big]}{\\bar{n}_{\\ell}}\\cdot\\log\\frac{60H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}}}\\\\ &{\\qquad+\\displaystyle\\frac{2H}{3\\bar{n}_{\\ell}}\\log\\frac{60H^{2}\\ell^{2}|\\Pi_{\\ell}|}{\\delta}}\\\\ &{\\le\\displaystyle\\sum_{h=2}^{H}\\sqrt{\\frac{4U_{h}(\\pi,\\bar{\\pi}_{\\ell})+384S^{2}H^{3}\\ell_{\\mathrm{mid}}^{\\ell}}{\\bar{n}_{\\ell}}\\cdot\\log\\frac{60H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}}+\\frac{2H}{3\\bar{n}_{\\ell}}\\log\\frac{60H^{2}\\ell^{2}|\\Pi_{\\ell}|}{\\delta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "By Lemma 23 and Jensen's inequality, this can be further bounded as ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\displaystyle\\sum_{h=2}^{H}c\\sqrt{\\frac{\\hat{U}_{\\ell-1,h}(\\pi,\\bar{\\pi}_{\\ell})+S^{3/2}H^{3}\\sqrt{A\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}\\cdot\\epsilon_{\\ell}^{1/3}+S^{2}H^{3}\\epsilon_{\\mathrm{unif}}^{\\ell}}{\\bar{n}_{\\ell}}\\cdot\\log\\frac{60H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}}}\\\\ &{\\qquad+\\displaystyle\\frac{2H}{3\\bar{n}_{\\ell}}\\log\\frac{60H^{2}\\ell^{2}|\\Pi_{\\ell}|}{\\delta}}\\\\ &{\\leq c\\sqrt{\\frac{H\\hat{U}_{\\ell-1}(\\pi,\\bar{\\pi}_{\\ell})+S^{3/2}H^{4}\\sqrt{A\\log\\frac{24S^{2}A H\\ell^{2}}{\\delta}}\\cdot\\epsilon_{\\ell}^{1/3}+S^{2}H^{4}\\epsilon_{\\mathrm{unif}}^{\\ell}}{\\bar{n}_{\\ell}}\\cdot\\log\\frac{60H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}}}\\\\ &{\\qquad+\\frac{2H}{3\\bar{n}_{\\ell}}\\log\\frac{60H^{2}\\ell^{2}|\\Pi_{\\ell}|}{\\delta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "The result then follows from this, our choice of $\\bar{n}_{\\ell}$ and Eunif and the bound on \u25b3 above. ", "page_idx": 33}, {"type": "text", "text": "Lemma 25. On $\\mathcal{E}_{\\mathrm{good}}$ we can bound ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi_{\\ell}}\\|M_{\\ell,h}\\left(\\left(\\pi_{h}-\\bar{\\pi}_{\\ell,h}\\right)\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}+\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}\\right)\\|_{\\Lambda_{h}}^{2}\\left(\\pi_{\\mathrm{exp}}\\right)^{-1}}{\\epsilon_{\\mathrm{exp}}^{\\ell}}}\\\\ &{\\leq\\frac{\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi_{\\ell}}4\\left\\|\\bar{\\pi}_{\\ell,h}w_{\\ell,h}^{\\pi}-\\pi_{h}w_{h}^{\\pi}\\right\\|_{\\Lambda_{h}\\left(\\pi_{\\mathrm{exp}}\\right)^{-1}}^{2}}{\\epsilon_{\\mathrm{exp}}^{\\ell}}}\\\\ &{\\ \\ +\\frac{\\left(8S^{2}A+32S^{3}A H^{2}\\right)\\epsilon_{\\ell}^{5/3}+2S^{2}A H\\beta_{\\ell}\\epsilon_{\\mathrm{exp}}^{\\ell}+4096S^{3}A H^{2}\\left(\\epsilon_{\\mathrm{unif}}^{\\ell}\\right)^{2}}{\\epsilon_{\\mathrm{unif}}^{\\ell}\\epsilon_{\\mathrm{exp}}^{\\ell}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Proof. We can bound: ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\pi_{\\mathrm{exp}}}{\\mathrm{inf}}\\underset{\\pi\\in\\Pi_{\\ell}}{\\mathrm{max}}\\,\\|M_{\\ell,h}\\big(\\big(\\pi_{h}-\\bar{\\pi}_{\\ell,h}\\big)\\widehat{w}_{\\ell,h}^{\\pi}+\\pi_{h}\\widehat{\\delta}_{\\ell,h}^{\\pi}\\big)\\|_{\\Lambda_{h}}^{2}(\\boldsymbol{\\pi}_{\\mathrm{exp}})^{-1}}\\\\ &{\\leq\\underset{\\pi_{\\mathrm{exp}}}{\\mathrm{inf}}\\underset{\\pi\\in\\Pi_{\\ell}}{\\mathrm{max}}\\,4\\|M_{\\ell,h}\\big(\\big(\\pi_{h}-\\bar{\\pi}_{\\ell,h}\\big)w_{\\ell,h}^{\\bar{\\pi}}+\\pi_{h}\\delta_{\\ell,h}^{\\pi}\\big)\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}}\\\\ &{\\qquad+\\underset{\\pi_{\\mathrm{exp}}^{\\prime}\\pi\\in\\Pi_{\\ell}}{\\mathrm{inf}}\\underset{\\pi\\in\\Pi_{\\ell}}{\\mathrm{max}}\\,\\Big[8\\|M_{\\ell,h}\\big(\\pi_{h}-\\bar{\\pi}_{\\ell,h}\\big)(w_{\\ell,h}^{\\bar{\\pi}}-\\widehat{w}_{\\ell,h}^{\\bar{\\pi}})\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}}^{\\prime})^{-1}}^{2}}\\\\ &{\\qquad+8\\|M_{\\ell,h}\\pi_{h}\\big(\\delta_{\\ell,h}^{\\pi}-\\widehat{\\delta}_{\\ell,h}^{\\pi}\\big)\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}}^{\\prime})^{-1}}^{2}\\Big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "We can write ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|M_{\\ell,h}(\\pi_{h}-\\bar{\\pi}_{\\ell,h})(w_{\\ell,h}^{\\bar{\\pi}}-\\widehat{w_{\\ell,h}^{\\bar{\\pi}}})\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}}^{\\prime})^{-1}}^{2}}\\\\ &{=\\displaystyle\\sum_{s,a}\\frac{(\\pi_{h}(a\\mid s)-\\bar{\\pi}_{\\ell,h}(a\\mid s))^{2}(w_{\\ell,h}^{\\bar{\\pi}}(s)-\\widehat{w_{\\ell,h}^{\\bar{\\pi}}}(s))^{2}}{[\\Lambda_{h}(\\pi_{\\mathrm{exp}}^{\\prime})]_{s a,s a}}\\cdot\\mathbb{I}\\{(s,a)\\in S_{\\ell,h}^{\\mathrm{keep}}\\}}\\\\ &{\\le\\displaystyle\\sum_{s,a}\\frac{(w_{\\ell,h}^{\\bar{\\pi}}(s)-\\widehat{w_{\\ell,h}^{\\bar{\\pi}}}(s))^{2}}{[\\Lambda_{h}(\\pi_{\\mathrm{exp}}^{\\prime})]_{s a,s a}}\\cdot\\mathbb{I}\\{(s,a)\\in S_{\\ell,h}^{\\mathrm{keep}}\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "$\\mathcal{E}_{\\mathrm{good}}$ foreach $(s,a)\\in\\ensuremath{\\mathcal{S}}_{\\ell,h}^{\\mathrm{keep}}$ we have $W_{h}^{\\star}(s)\\geq\\epsilon_{\\mathrm{unif}}^{\\ell}$ Let $\\pi^{s h}$ denote he poley hich eches $w_{h}^{\\pi^{s h}}(s)=W_{h}^{\\star}(s)$ ndaatly $(s,h)$ Let $\\pi_{\\mathrm{exp}}^{\\prime}=\\operatorname{unif}(\\{\\pi^{s h}\\}_{s})$ Then we have $[\\Lambda_{h}(\\pi_{\\mathrm{exp}}^{\\prime})]_{s a,s a}\\geq W_{h}^{\\star}(s)/S A\\geq\\epsilon_{\\mathrm{unif}}^{\\ell}/S A$ for each $(s,a)\\in\\ensuremath{\\mathcal{S}}_{\\ell,h}^{\\mathrm{keep}}$ Sk,heP, so we can bound the above as ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\leq\\frac{S A}{\\epsilon_{\\mathrm{unif}}^{\\ell}}\\sum_{s,a}(w_{\\ell,h}^{\\bar{\\pi}}(s)-\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}(s))^{2}=\\frac{S A}{\\epsilon_{\\mathrm{unif}}^{\\ell}}\\|w_{\\ell,h}^{\\bar{\\pi}}-\\widehat{w}_{\\ell,h}^{\\bar{\\pi}}\\|_{2}^{2}\\leq\\frac{8S^{2}A\\epsilon_{\\ell}^{5/3}}{\\epsilon_{\\mathrm{unif}}^{\\ell}},\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where the last inequality follows from Lemma 19. ", "page_idx": 34}, {"type": "text", "text": "We can obtain a bound on $\\|M_{\\ell,h}\\pmb{\\pi}_{h}(\\delta_{\\ell,h}^{\\pi}\\,-\\,\\widehat{\\delta}_{\\ell,h}^{\\pi})\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}}^{\\prime})^{-1}}^{2}$ using a similar argument but now applying Lemma 18 to get that: ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\|M_{\\ell,h}\\pi_{h}(\\delta_{\\ell,h}^{\\pi}-\\widehat\\delta_{\\ell,h}^{\\pi})\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}}^{\\prime})^{-1}}^{2}\\le\\frac{2S^{2}A H\\beta_{\\ell}\\epsilon_{\\mathrm{exp}}^{\\ell}}{\\epsilon_{\\mathrm{unif}}^{\\ell}}+\\frac{32S^{3}A H^{2}\\epsilon_{\\ell}^{5/3}}{\\epsilon_{\\mathrm{unif}}^{\\ell}}+4096S^{3}A H^{2}\\epsilon_{\\mathrm{unif}}^{\\ell}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Finally, note that ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|M_{\\ell,h}((\\boldsymbol{\\pi}_{h}-\\bar{\\boldsymbol{\\pi}}_{\\ell,h})w_{\\ell,h}^{\\bar{\\boldsymbol{\\pi}}}+\\boldsymbol{\\pi}_{h}\\delta_{\\ell,h}^{\\pi})\\|_{\\Lambda_{h}(\\boldsymbol{\\pi}_{\\mathrm{exp}})^{-1}}^{2}=\\|M_{\\ell,h}(\\bar{\\boldsymbol{\\pi}}_{\\ell,h}w_{\\ell,h}^{\\bar{\\boldsymbol{\\pi}}}+\\boldsymbol{\\pi}_{h}w_{h}^{\\pi})\\|_{\\Lambda_{h}(\\boldsymbol{\\pi}_{\\mathrm{exp}})^{-1}}^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\le\\|\\bar{\\boldsymbol{\\pi}}_{\\ell,h}w_{\\ell,h}^{\\bar{\\boldsymbol{\\pi}}}-\\boldsymbol{\\pi}_{h}w_{h}^{\\pi}\\|_{\\Lambda_{h}(\\boldsymbol{\\pi}_{\\mathrm{exp}})^{-1}}^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where the equality holds by definition, and the inequality by simply manipulations. Combining these bounds gives the result. \u25a0 ", "page_idx": 34}, {"type": "text", "text": "C.5  Correctness and Sample Complexity ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Lemma 26. On the event $\\mathcal{E}_{\\mathrm{good}}$ , for all $\\pi\\in\\Pi_{\\ell+1}$ , we have $V_{0}^{\\star}(\\Pi)-V_{0}^{\\pi}\\le16\\epsilon_{\\ell}$ and $\\pi^{\\star}\\in\\Pi_{\\ell}$ ", "page_idx": 34}, {"type": "text", "text": "Proof. Recall $D_{\\bar{\\pi}_{\\ell}}(\\pi)=V_{0}^{\\pi}-V_{0}^{\\bar{\\pi}_{\\ell}}$ . For $\\pi\\in\\Pi_{\\ell}$ , we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle\\widehat{D}_{\\mu_{t}}(\\pi)-D_{\\mu_{t}}(\\pi)|}\\\\ &{=\\left|\\displaystyle\\sum_{h=1}^{H}\\left[\\langle\\widehat{\\gamma}_{h},\\pi_{h}\\widehat{\\delta}_{t,h}^{\\nu}+(\\pi_{h}-\\widehat\\pi_{t,h})\\widehat{\\delta}_{t,h}^{\\nu}\\rangle-\\langle r_{h},\\pi_{h}\\widehat{\\delta}_{t,h}^{\\nu}+(\\pi_{h}-\\widehat\\pi_{t,h})w_{t,h}^{\\nu}\\rangle\\right]\\right|}\\\\ &{\\le\\displaystyle\\sum_{h=1}^{H}\\vert\\langle\\widehat{\\gamma}_{t,h}-\\widehat\\gamma_{t,h},\\pi_{h}\\widehat{\\delta}_{t,h}^{\\nu}+(\\pi_{h}-\\pi_{t,h})\\widehat\\pi_{t,h}^{\\nu}\\rangle\\vert+\\displaystyle\\sum_{h=1}^{H}\\vert\\langle\\widetilde{\\gamma}_{t,h},\\pi_{h}(\\widehat{\\delta}_{t,h}^{\\nu}-\\widehat\\delta_{t,h}^{\\nu})\\rangle\\vert}\\\\ &{\\quad\\quad+\\displaystyle\\prod_{h=1}^{H}\\langle\\widehat\\gamma_{t,h},\\pi_{h}(\\widehat{\\delta}_{t,h}^{\\nu}-\\widehat\\delta_{t,h}^{\\nu})\\rangle+\\langle r_{h},(\\pi_{h}-\\pi_{t,h})(w_{t,h}^{\\nu}-\\widehat\\delta_{t,h}^{\\nu})\\rangle\\right|}\\\\ &{\\qquad\\quad+\\displaystyle\\sum_{h=1}^{H}\\vert\\langle\\widehat\\gamma_{t,h}-r_{h},\\pi_{h}\\widehat{\\delta}_{t,h}^{\\nu}+(\\pi_{h}-\\pi_{t,h})w_{t,h}^{\\nu}\\rangle\\vert\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "By Lemma 21, on $\\mathcal{E}_{\\mathrm{good}}$ we have $(a)\\leq\\epsilon_{\\ell}$ and $(b)\\leq\\epsilon_{\\ell}$ , and by Lemma 24, $(c)\\leq\\epsilon_{\\ell}$ . To bound $(d)$ we note that $\\pmb{\\pi}_{h}\\delta_{\\ell,h}^{\\pi}\\dot{+}(\\pmb{\\pi}_{h}-\\bar{\\pmb{\\pi}}_{\\ell,h})w_{\\ell,h}^{\\bar{\\pi}}=\\pmb{\\pi}_{h}w_{h}^{\\pi}-\\bar{\\pmb{\\pi}}_{\\ell,h}w_{\\ell,h}^{\\bar{\\pi}}$ , and so, on $\\mathcal{E}_{\\mathrm{good}}$ and by definition of re,h, ", "page_idx": 35}, {"type": "equation", "text": "$$\n(d)\\leq\\sum_{h=1}^{H}\\sum_{s\\notin S_{\\ell,h}^{\\mathrm{keep}}}(w_{h}^{\\pi}(s)+w_{\\ell,h}^{\\bar{\\pi}}(s))\\leq64H S\\epsilon_{\\mathrm{unif}}^{\\ell}\\leq\\epsilon_{\\ell}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Note that we only eliminate policy $\\pi\\in\\Pi_{\\ell}$ at round $\\ell$ if $\\mathrm{max}_{\\pi^{\\prime}}\\,\\widehat{D}_{\\bar{\\pi}_{\\ell}}(\\pi^{\\prime})-\\widehat{D}_{\\bar{\\pi}_{\\ell}}(\\pi)>8\\epsilon_{\\ell}$ .Assume that $\\pi^{\\star}\\in\\Pi_{\\ell}$ . By what we have just shown, if policy $\\pi$ is eliminated, we then have ", "page_idx": 35}, {"type": "equation", "text": "$$\n8\\epsilon_{\\ell}<\\operatorname*{max}_{\\pi^{\\prime}\\in\\Pi_{\\ell}}D_{\\bar{\\pi}_{\\ell}}(\\pi^{\\prime})-D_{\\bar{\\pi}_{\\ell}}(\\pi)+8\\epsilon_{\\ell}=V_{0}^{\\star}-V_{0}^{\\pi}+8\\epsilon_{\\ell}\\implies V_{0}^{\\pi}<V_{0}^{\\star}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "It follows that $\\pi^{\\star}$ will not be eliminated at round $\\ell$ . as long as $\\pi^{\\star}\\in\\Pi_{\\ell}$ . By a simple inductive argument, since $\\pi^{\\star}\\in\\Pi_{0}$ , it follows that on $\\mathcal{E}_{\\mathrm{good}}$ \uff0c $\\pi^{\\star}\\in\\Pi_{\\ell}$ for all $\\ell$ ", "page_idx": 35}, {"type": "text", "text": "Furthermore, for each $\\pi\\in\\Pi_{\\ell+1}$ , we have $\\operatorname*{max}_{\\pi^{\\prime}}\\widehat{D}_{\\bar{\\pi}_{\\ell}}(\\pi^{\\prime})-\\widehat{D}_{\\bar{\\pi}_{\\ell}}(\\pi)\\leq8\\epsilon_{\\ell}$ Which, again by what we have just shown, implies that ", "page_idx": 35}, {"type": "equation", "text": "$$\n8\\epsilon_{\\ell}\\geq\\operatorname*{max}_{\\pi^{\\prime}\\in\\Pi_{\\ell}}D_{\\bar{\\pi}_{\\ell}}(\\pi^{\\prime})-D_{\\bar{\\pi}_{\\ell}}(\\pi)-8\\epsilon_{\\ell}=V_{0}^{\\star}-V_{0}^{\\pi}-8\\epsilon_{\\ell}\\implies V_{0}^{\\star}-V_{0}^{\\pi}\\leq16\\epsilon_{\\ell}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Theorem 1. There exists an algorithm (Algorithm 1) which, with probability at least 1 - 28, finds an $\\epsilon$ -optimal policy and terminates after collecting at most ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\sum_{\\iota=1}^{H}\\operatorname*{inf}_{\\pi\\exp\\ \\pi\\in\\Pi}\\frac{H^{4}\\|\\phi_{h}^{\\star}-\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi\\exp)^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}\\cdot\\iota\\beta^{2}+\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{H U(\\pi,\\pi^{\\star})}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}\\log\\frac{H|\\Pi|\\iota}{\\delta}+\\frac{C_{\\mathrm{poly}}}{\\operatorname*{max}\\{\\epsilon^{5},\\Delta_{\\operatorname*{min}}^{\\frac{5}{3}}\\}}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "epiode. or $\\begin{array}{r}{C_{\\mathrm{poly}}:=\\mathrm{poly}(S,A,H,\\log1/\\delta,\\iota,\\log|\\Pi|),\\beta:=C\\sqrt{\\log(\\frac{S H|\\Pi|}{\\delta}\\cdot\\frac{1}{\\Delta_{\\operatorname*{min}}\\vee\\epsilon})}\\;a n d}\\end{array}$ t := log \u25b3minVe ", "page_idx": 35}, {"type": "text", "text": "Proof. First, by Lemma 20, we have that $\\mathbb{P}[\\mathcal{E}_{\\mathrm{good}}]\\,\\geq\\,1-\\,2\\delta$ . For the remainder of the proof we assume we are on $\\mathcal{E}_{\\mathrm{good}}$ ", "page_idx": 35}, {"type": "text", "text": "By Lemma 26, we have that on $\\mathcal{E}_{\\mathrm{good}}$ , for every $\\pi\\in\\Pi_{\\ell+1}$ \uff0c $V_{0}^{\\star}-V_{0}^{\\pi}\\,\\leq\\,16\\epsilon_{\\ell}$ and that $\\pi^{\\star}\\in\\Pi_{\\ell}$ for all $\\ell$ It follows that, since we run for $\\ell_{\\epsilon}=\\lceil\\log_{2}16/\\epsilon\\rceil$ epochs, when we terminate each policy $\\pi\\in\\Pi_{\\ell_{\\epsilon}}$ satisfies $V_{0}^{\\star}-V_{0}^{\\pi}\\le16\\epsilon_{\\ell_{\\epsilon}}=16\\cdot2^{-\\ell_{\\epsilon}}\\le\\epsilon$ Furthermore, if we terminate early on Line 20, then we know that $|\\boldsymbol{\\Pi}_{\\ell+1}|=1$ , and since $\\pi^{\\star}\\in\\Pi_{\\ell+1}$ , we have that the algorithm returns $\\pi^{\\star}$ . Thus, the policy returned by Algorithm 2 is always $\\epsilon$ -optimal. ", "page_idx": 35}, {"type": "text", "text": "It therefore remains to bound the sample complexity of Algorithm 2. At round $\\ell$ of Algorithm 2, we collect $\\bar{n}_{\\ell}$ samples plus the number of samples collected from OPTCov. On $\\mathcal{E}_{\\mathrm{good}}$ , we have that the number of samples collected by OPTCov at round $\\ell$ step $h$ is bounded by ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{O}:\\frac{\\operatorname*{inf}_{n\\in\\mathbb{N}}\\operatorname*{max}_{{\\mathbf{c}}\\in[1]}|M_{t}^{\\varepsilon}((\\pi_{1}-\\pi_{t},\\pi_{\\delta})|\\overline{{\\theta}}_{t,\\Delta}^{\\varepsilon}+\\pi_{\\mathcal{O}}^{\\varepsilon}\\Delta_{t,\\delta}^{\\varepsilon})||_{\\Delta}^{2}(\\mathbb{r}_{\\infty})^{-1}}{\\varepsilon_{n\\in\\mathbb{N}}}}\\\\ &{\\quad\\quad+\\frac{C_{e}^{\\varepsilon}}{(\\varepsilon_{2})^{n}}+\\frac{C_{e}^{\\varepsilon}}{6\\pi}+\\log(C_{e}^{\\varepsilon}),\\quad k_{\\mathrm{e}}^{\\varepsilon}=\\alpha_{u}^{\\varepsilon}}\\\\ &{\\stackrel{(a)}{\\leq}C:\\frac{\\operatorname*{inf}_{n\\in\\mathbb{N}}\\operatorname*{max}_{{\\mathbf{c}}\\in[1]}|\\mathbb{P}_{n\\in\\mathbb{N}}\\nu_{t}^{\\varepsilon}-\\pi_{u}||^{2}}{\\varepsilon_{n\\in\\mathbb{N}}}}\\\\ &{\\quad\\quad+\\frac{(\\Delta^{\\varepsilon}\\Delta^{2}+\\Delta^{2}+\\Delta^{2}+4\\pi^{2})^{3}\\varepsilon_{n\\in\\mathbb{N}}^{2}}{\\varepsilon_{n\\in\\mathbb{N}}^{2}}:\\frac{-f_{\\Delta}^{\\varepsilon}\\Delta\\mathbb{I}_{N}^{2}(\\varepsilon_{n}^{\\varepsilon})-1}{\\varepsilon_{n\\in\\mathbb{N}}^{2}}+\\frac{C_{e}^{\\varepsilon}}{(\\varepsilon_{2})^{n}}+\\log(C_{e}^{\\varepsilon})\\cdot K_{n\\in\\mathbb{N}}^{\\varepsilon}}\\\\ &{\\stackrel{(b)}{\\leq}C:\\frac{\\operatorname*{inf}_{n\\in\\mathbb{N}}\\operatorname*{max}_{{\\mathbf{c}}\\in[1]}|\\mathbb{P}_{n\\in\\mathbb{N}}\\nu_{t}^{\\varepsilon}-\\pi_{n}||^{2}|\\Delta_{}^{2}(\\pi_{3}^{\\varepsilon})||_{\\Delta}^{2}(\\mathbb{r}_{\\infty}^{\\varepsilon})+\\frac{4\\pi^{2}}{\\varepsilon_{n\\in\\mathbb{N}}^{2}}\\mathbb{I}_{N}^{2}(\\varepsilon_{n}^{\\varepsilon})}{\\varepsilon_{n\\in\\mathbb{N}}^{2}}}\\\\ &{\\stackrel{(c)}{\\leq}C:\\frac{\\operatorname*\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where the initial bound holds from Lemma 14, the $(a)$ follows from Lemma 25, and $(b)$ follows plugging in our choice of $\\epsilon_{\\mathrm{unif}}^{\\ell}$ and $\\epsilon_{\\mathrm{exp}}^{\\ell}$ , and with Cpoly = poly(S, A,H, log e/8,log 1/e,log I), $(c)$ holds by the triangle inequality and since $\\bar{\\pi}_{\\ell}\\in\\Pi_{\\ell}$ , and $(d)$ holds because, for all $\\pi\\in\\Pi_{\\ell}$ ,we have $\\Delta(\\pi)\\leq32\\epsilon\\ell$ . Furthermore, we can bound $\\bar{n}_{\\ell}$ as ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bar{n}_{\\ell}=\\underset{\\bar{\\pi}\\in\\Pi_{\\ell}\\pi\\in\\Pi_{\\ell}}{\\operatorname*{min}}\\le c\\cdot\\frac{H\\widehat{U}_{\\ell-1}(\\pi,\\bar{\\pi})+H^{4}S^{3/2}\\sqrt{A}\\log\\frac{S A H\\ell^{2}}{\\delta}\\cdot\\epsilon_{\\ell}^{1/3}+S^{2}H^{4}\\epsilon_{\\mathrm{unif}}^{\\ell}}{\\epsilon_{\\ell}^{2}}\\cdot\\log\\frac{60H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}}\\\\ &{\\overset{(a)}{\\le}\\frac{\\operatorname*{min}}{\\bar{\\pi}\\in\\Pi_{\\ell}\\pi\\in\\Pi_{\\ell}}\\le-\\frac{H U(\\pi,\\bar{\\pi})+H^{4}S^{3/2}\\sqrt{A}\\log\\frac{S A H\\ell^{2}}{\\delta}\\cdot\\epsilon_{\\ell}^{1/3}+S^{2}H^{4}\\epsilon_{\\mathrm{unif}}^{\\ell}}{\\epsilon_{\\ell}^{2}}\\cdot\\log\\frac{60H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}}\\\\ &{\\overset{(b)}{\\le}\\underset{\\pi\\in\\Pi}{\\operatorname*{max}}\\,c\\cdot\\frac{H U(\\pi,\\pi^{\\star})}{\\operatorname*{max}}\\cdot\\log\\frac{60H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}+\\frac{C_{\\mathrm{poly}}^{\\ell}}{\\epsilon_{\\ell}^{5/3}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where $(a)$ follows from Lemma 23, and $(b)$ since $\\pi^{\\star}\\in\\Pi_{\\ell}$ , and by a similar argument as above. ", "page_idx": 36}, {"type": "text", "text": "Thus, if we run for a total of $L$ rounds, the sample complexity is bounded as ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{\\ell=1}^{L}\\Bigg(C\\cdot\\displaystyle\\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi\\in\\mathbb{N}}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\pi_{h}^{\\star}w_{h}^{\\pi^{\\star}}-\\pi_{h}w_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon_{\\ell}^{2},\\Delta(\\pi)^{2}\\}}\\cdot H^{4}\\beta_{\\ell}^{2}}}\\\\ &{\\quad+\\operatorname*{max}_{\\pi\\in\\Pi}\\cdot\\displaystyle\\frac{H U(\\pi,\\pi^{\\star})}{\\operatorname*{max}\\{\\epsilon_{\\ell}^{2},\\Delta(\\pi)^{2}\\}}\\cdot\\log\\frac{60H\\ell^{2}|\\Pi_{\\ell}|}{\\delta}\\Bigg)+\\frac{L C_{\\mathrm{poly}}^{L}}{\\epsilon_{L}^{5/3}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "By construction, we have that $L\\leq\\lceil\\log_{2}16/\\epsilon\\rceil$ . However, we terminate early if $|\\boldsymbol{\\Pi}_{\\ell+1}|=1$ and $\\pi\\in\\Pi_{\\ell+1}$ $\\begin{array}{r}{\\ell\\geq\\lceil\\log_{2}\\frac{1}{\\Delta_{\\operatorname*{min}}}\\rceil+1}\\end{array}$ $\\Delta(\\pi)\\leq\\epsilon_{\\ell}$ $|\\boldsymbol{\\Pi}_{\\ell+1}|=1$ once $\\epsilon_{\\ell}<\\Delta_{\\operatorname*{min}}$ ", "page_idx": 36}, {"type": "equation", "text": "$$\nL\\leq\\operatorname*{min}\\{\\lceil\\log_{2}16/\\epsilon\\rceil,\\lceil\\log_{2}1/\\Delta_{\\operatorname*{min}}\\rceil+1\\},\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "and so for all $\\epsilon_{\\ell},\\ell\\leq L$ wehave $\\epsilon_{\\ell}\\geq c\\cdot\\operatorname*{max}\\{\\epsilon,\\Delta_{\\operatorname*{min}}\\}$ . Plugging this into the above gives the final complexity. ", "page_idx": 36}, {"type": "text", "text": "D Tabular Contextual Bandits: Upper Bound ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Setting and notation. We study stochastic tabular contextual bandits, denoted by the tuple $(\\mathcal{C},\\mathcal{A},\\mu^{\\star},\\nu)$ .At each episode, a context $c\\sim\\mu^{\\star}$ arrives, the agent chooses an action $a\\ \\in\\ A$ and receives reward $r(c,a)\\sim\\nu(c,a)$ in $\\mathbb{R}$ . Note that this is a special case of the Tabular MDP when $H=1$ . In this setting, we use the terminology \u201ccontexts\" instead of \u201cstates\" to highlight that the agent has no impact on these. The vector $\\mu^{\\star}$ plays the same role as the state visitation vectors $w_{h}^{\\pi}$ previously, except this is now policy-independent. The notation for policy matrix $\\pi$ , values $V^{\\pi}$ features $\\phi^{\\pi}(c,a)$ are inherited directly from the general case. ", "page_idx": 36}, {"type": "text", "text": "", "page_idx": 37}, {"type": "text", "text": "Define $\\theta^{\\star}\\in R^{|\\mathcal{C}|A}$ as the vector of reward means so that $[\\theta^{\\star}]_{(c,a)}=\\mathbb{E}_{\\nu}[r(c,a)]$ . Then, we can write the value of $\\pi$ as: ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\nu,\\mu^{\\star}}[r(c,\\pi(c))]=\\sum_{c,a}\\theta_{c,a}^{\\star}[\\mu^{\\star}]_{c}[\\pi(c)]_{a}=(\\theta^{\\star})^{\\top}\\pi\\mu^{\\star}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "For any $(\\theta,\\mu)$ define ${\\mathsf{O P T}}(\\theta,\\mu)\\;:=\\;\\arg\\operatorname*{max}_{\\pi\\in\\Pi}\\theta^{\\top}\\pi\\mu$ where $\\theta$ is any hypothetical vector of reward-means and $\\mu\\in\\Delta_{|\\mathcal{C}|}$ is a hypothetical context distribution. ", "page_idx": 37}, {"type": "text", "text": "Recall that we use $\\pmb{\\pi}\\in\\mathbb{R}^{|\\mathcal{C}|A\\times|\\mathcal{C}|}$ to refer to the policy matrix. The vector $\\pi\\mu\\in\\mathbb{R}^{|c|A}$ contains context-action visitations for policy $\\pi$ under context distribution $\\mu$ . Define function $G(\\mu,\\pi)\\,=$ $\\mathbb{E}_{\\mu,\\pi}[(\\pmb{\\pi}\\mu)(\\pmb{\\pi}\\mu)^{\\top}]$ which returns the expected covariance matrix of policy $\\pi$ under context distribution $\\mu$ For shorthand, we refer to $\\hat{A}(\\pi)=G(\\widehat{\\mu}\\ell,\\pi_{\\mathrm{exp}})$ and $A(\\pi)=G(\\mu^{\\star},\\pi_{\\mathrm{exp}})$ for any $\\pi$ ", "page_idx": 37}, {"type": "text", "text": "Lemma 27. Define the experimental design objective ", "page_idx": 37}, {"type": "equation", "text": "$$\nF(\\pi_{\\mathrm{exp}},\\mu,\\pi,\\pi^{\\prime})=\\|(\\pi^{\\prime}-\\pi)\\mu\\|_{G(\\mu,\\pi_{\\mathrm{exp}})^{-1}}^{2}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Then, for any $\\mu\\in\\Delta_{\\mathcal{C}}$ ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\pi_{\\exp}\\pi,\\pi^{\\prime}\\in\\Pi_{\\ell}}F(\\pi_{\\exp},\\mu,\\pi,\\pi^{\\prime})=\\operatorname*{max}_{\\pi,\\pi^{\\prime}\\in\\Pi_{\\ell}}\\operatorname*{min}_{\\pi_{\\exp}}F(\\pi_{\\exp},\\mu,\\pi,\\pi^{\\prime})\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Proof. We can rewrite the maximization problem to be over the simplex $\\Delta_{\\Pi_{\\ell}\\times\\Pi_{\\ell}}$ instead: ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\lambda\\in\\Delta\\Pi_{\\ell}\\times\\Pi_{\\ell}}\\sum_{\\pi,\\pi^{\\prime}\\in\\Pi_{\\ell}\\times\\Pi_{\\ell}}\\lambda_{\\pi,\\pi^{\\prime}}F(\\pi_{\\mathrm{exp}},\\mu,\\pi,\\pi^{\\prime})\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "This does not change the objective value. To see this, note that for any selection $(\\pi_{1},\\pi_{2})$ in the original problem, the same objective value can be obtained by setting $\\lambda=e_{\\pi_{1},\\pi_{2}}$ hence, the modification to the optimization cannot reduce the value. Further if $F(\\pi_{\\mathrm{exp}},\\mu,\\pi,\\pi^{\\prime})$ is maximized by $(\\pi_{1},\\pi_{2})$ \uff0c setting $\\lambda$ as anything other than $e_{\\pi_{1},\\pi_{2}}$ cannot increase the objective value. ", "page_idx": 37}, {"type": "text", "text": "Now, note that both the minimization and maximization problems are over simplices, which are compact and convex sets. The objective is linear in the maximization variable, and hence concave. The objective can be rewritten as ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\sum_{c\\in S}\\sum_{a\\in\\mathcal{A}}\\frac{(\\pi-\\pi^{\\prime})^{\\top}e_{a,c}e_{a,c}^{\\top}(\\pi-\\pi^{\\prime})}{p_{c,a}}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Here, $p_{c,a}$ as the probability that $\\pi_{\\mathrm{exp}}$ plays action $a$ , given that we are in context $c$ From this representation, we can clearly see that the objective is convex in each $p_{c,a}$ . Hence, since we are optimizing over finite-dimensional spaces $(|\\mathcal{A}|$ and $|{\\mathcal{C}}|$ are finite), Von Neumann's minimax theorem applies and the proof is complete. \u53e3 ", "page_idx": 37}, {"type": "text", "text": "Lemma 28. For the contextual bandit problem, define the experimental design objective ", "page_idx": 37}, {"type": "equation", "text": "$$\nF(\\pi_{\\mathrm{exp}},\\mu,\\pi,\\pi^{\\prime})=\\|(\\pi^{\\prime}-\\pi)\\mu\\|_{G(\\mu,\\pi_{\\mathrm{exp}})^{-1}}^{2}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Then, for any $\\mu$ and assuming that all policies in $\\Pi_{\\ell}$ are deterministic, we have: ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\pi\\mathrm{exp}}\\operatorname*{max}_{\\pi,\\pi^{\\prime}\\in\\Pi_{\\ell}}F(\\pi_{\\mathrm{exp}},\\mu,\\pi,\\pi^{\\prime})=\\operatorname*{max}_{\\pi,\\pi^{\\prime}\\in\\Pi_{\\ell}}\\mathbb{E}_{c\\sim\\mu}[4\\mathbb{I}[\\pi(c)\\neq\\pi^{\\prime}(c)]],\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Proof. Below, we refer to $p_{c,a}$ as the probability that $\\pi_{\\mathrm{exp}}$ plays action $a$ given that we are in context $c$ . We have: ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\pi\\in\\mathrm{P},\\pi,\\nu^{\\prime}\\in\\mathrm{I}_{\\ell}}{\\mathrm{min}}\\:\\mathrm{max}_{\\ell}\\:\\mathrm{\\ensuremath{\\lVert{\\boldsymbol{\\pi}}(\\pi^{\\prime}-\\pi)/{\\boldsymbol{\\mu}}\\rVert}}_{G(\\mu,\\pi_{\\mathrm{exp}})^{-1}}}\\\\ &{=\\underset{\\pi,\\pi^{\\prime}\\in\\mathrm{I}\\mathrm{I}_{\\ell}}{\\mathrm{max}}\\:\\mathrm{min}\\:\\mathrm{\\lVert{\\boldsymbol{(\\pi^{\\prime}-\\pi)}}/{\\boldsymbol{\\mu}}\\rVert}_{G(\\mu,\\pi_{\\mathrm{exp}})^{-1}}^{2}}\\\\ &{=\\underset{\\pi,\\pi^{\\prime}\\in\\mathrm{I}\\mathrm{I}_{\\ell}}{\\mathrm{max}}\\:\\mathrm{min}\\:\\sum_{\\ell=\\mathrm{A}}\\sum_{\\ell}\\mu_{c}^{2}\\frac{\\left(\\pi-\\pi^{\\prime}\\right)^{\\top}\\boldsymbol{\\nabla}_{\\alpha_{\\alpha},c}\\boldsymbol{\\mathrm{e}}_{\\alpha,c}^{\\top}\\left(\\pi-\\pi^{\\prime}\\right)}{\\mu_{c}\\boldsymbol{\\mathcal{P}}_{\\alpha,a}}}\\\\ &{=\\underset{\\pi,\\pi^{\\prime}\\in\\mathrm{I}\\mathrm{I}_{\\ell}}{\\mathrm{max}}\\:\\sum_{\\ell}\\mu_{c}\\underset{p_{\\ell}}{\\mathrm{min}}\\:\\sum_{\\ell}\\frac{\\left(\\pi-\\pi^{\\prime}\\right)^{\\top}\\boldsymbol{\\nabla}_{\\alpha_{\\alpha},c}\\boldsymbol{\\mathrm{e}}_{\\alpha,c}^{\\top}\\left(\\pi-\\pi^{\\prime}\\right)}{\\mu_{c,a}}}\\\\ &{=\\underset{\\pi,\\pi^{\\prime}\\in\\mathrm{I}\\mathrm{I}_{\\ell}}{\\mathrm{max}}\\:\\sum_{\\ell}\\mu_{c}\\left(\\underset{q\\in\\mathrm{A}}{\\sum_{\\ell}\\sqrt{(\\pi-\\pi^{\\prime})^{\\top}\\boldsymbol{e}_{\\alpha,c}\\boldsymbol{\\mathrm{e}}_{\\alpha,c}^{\\top}\\left(\\pi-\\pi^{\\prime}\\right)}}\\right)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Here the first equality follows from Lemma 27, and the last from Lemma D.6 of [30]. ", "page_idx": 38}, {"type": "text", "text": "We have assumed that the policies in $\\Pi_{\\ell}$ are deterministic. Hence, the only two actions in the summation over $\\boldsymbol{\\mathcal{A}}$ above that are relevant are $\\pi(c)$ and $\\pi^{\\prime}(c)$ . For all other $a\\in A$ , the term in the square root evaluates to 0. If $\\pi(c)=\\pi^{\\prime}(c)$ , then the entire summation over $\\boldsymbol{\\mathcal{A}}$ evaluates to O; else, the terms indexed by $\\pi(c)$ and $\\pi^{\\prime}(c)$ are both 1, and the summation evalutes to 2. Hence, we can simplify the expression to exactly the form of Equation (D.2) from the lemma statement, and the proof is complete. \u53e3 ", "page_idx": 38}, {"type": "text", "text": "Lemma 29. For the contextual bandits problem, we have that ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\pi\\in\\Pi}\\mathbb{E}_{c\\sim\\mu^{\\star}}[\\mathbb{E}_{\\nu^{\\star}}[(r(c,\\pi(c))-r(c,\\pi^{\\star}(c)))^{2}|c]]\\le\\operatorname*{inf}_{\\pi\\in\\Pi}\\operatorname*{max}_{\\pi\\in\\Pi}\\|\\phi^{\\star}-\\phi^{\\pi}\\|_{\\Lambda(\\pi_{\\mathrm{exp}})^{-1}}^{2}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Proof. Observe that $r(c,\\pi(c))\\!-\\!r(c,\\pi^{\\star}(c))=0$ $\\pi(c)=\\pi^{\\star}(c)$ ; else, $|r(c,\\pi(c))\\!-\\!r(c,\\pi^{\\star}(c))|\\le2$ Then, it follows that ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\pi\\in\\Pi}{\\mathrm{max}}\\,\\mathbb{E}_{c\\sim\\mu^{\\star}}[\\mathbb{E}_{\\nu^{\\star}}[(r(c,\\pi(c))-r(c,\\pi^{\\star}(c)))^{2}|c]]}\\\\ &{\\leq\\underset{\\pi\\in\\Pi}{\\mathrm{max}}\\,4\\mathbb{E}_{c\\sim\\mu^{\\star}}\\mathbb{I}(\\pi(c)\\neq\\pi^{\\star}(c))}\\\\ &{=\\underset{\\pi_{\\mathtt{e x p}}}{\\mathrm{inf}}\\,\\underset{\\pi\\in\\Pi}{\\mathrm{max}}\\,\\|\\phi^{\\star}-\\phi^{\\pi}\\|_{\\Lambda(\\pi_{\\mathrm{exp}})^{-1}}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where the equality follows from Lemma 28. ", "page_idx": 38}, {"type": "text", "text": "Now, we state our main upper bound for contextual bandits. ", "page_idx": 38}, {"type": "text", "text": "Corollary 1. For the setting of tabular contextual bandits, there exists an algorithm such that with probabilityatleast $1-2\\delta$ aslongas $\\Pi$ contains only deterministic policies, it finds an e-optimal policy and terminates aftercollecting atmost thefollowingnumber of samples: ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\pi_{\\exp}\\pi\\in\\Pi}\\frac{\\|\\phi^{\\star}-\\phi^{\\pi}\\|_{\\Lambda(\\pi_{\\exp})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}\\cdot\\beta^{2}\\log\\frac{1}{\\Delta_{\\operatorname*{min}}\\vee\\epsilon}+\\frac{C_{\\mathrm{poly}}}{\\operatorname*{max}\\{\\epsilon^{5/3},\\Delta_{\\operatorname*{min}}^{5/3}\\}},\n$$", "text_format": "latex", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\cdot C_{\\mathrm{poly}}=\\mathrm{poly}(|\\mathcal{S}|,A,\\log1/\\delta,\\log1/(\\Delta_{\\operatorname*{min}}\\vee\\epsilon),\\log|\\Pi|)\\,a n d\\,\\beta=C\\sqrt{\\log(\\frac{S|\\Pi|}{\\delta}\\cdot\\frac{1}{\\Delta_{\\operatorname*{min}}\\vee\\epsilon})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Proof. In the special case of contextual bandits, $U(\\pi,\\pi^{\\star})$ defined in Theorem 1 can be written more simply as $\\begin{array}{r}{\\mathbb{E}_{c\\sim\\tilde{\\mu}^{\\star}}[\\mathbb{E}_{\\nu^{\\star}}[(r(c,\\pi(c))-r(c,\\pi^{\\star}(c)))^{2}|c]]}\\end{array}$ . Then, by Lemma 29, we have that: ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\frac{U(\\pi,\\pi^{\\star})}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\\leq\\operatorname*{inf}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi^{\\star}-\\phi^{\\pi}\\|_{\\Lambda(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Plugging this into Theorem 1 completes the proof. ", "page_idx": 38}, {"type": "text", "text": "E MDPs with Action-Independent Transitions ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "We consider here a special class of MDPs where the transitions only depend on the states and are independent of the actions selected i.e all $P_{h}$ are such that $P_{h}(s,a)\\stackrel{.}{=}P_{h}^{\\bar{}}(s,a^{\\prime})$ for all $(a,a^{\\prime})\\in A$ In this special case, we prove in this subsection that the (leading order) complexity of PERP reduces to $O(\\rho_{\\Pi})$ ", "page_idx": 39}, {"type": "text", "text": "Lemma 30. For the ergodic MDP problem, ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\pi\\in\\Pi}\\|\\phi_{h}^{\\pi}-\\phi_{h}^{\\star}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})-1}^{2}=\\operatorname*{max}_{\\pi\\in\\Pi}\\operatorname*{min}_{\\pi_{\\mathrm{exp}}}\\|\\phi_{h}^{\\pi}-\\phi_{h}^{\\star}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})-1}^{2}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Proof. We can rewrite the maximization problem to be over the simplex $\\Delta_{\\Pi}$ instead: ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\pi_{\\mathrm{exp}}}\\operatorname*{max}_{\\lambda\\in\\Delta_{\\Pi}}\\sum_{\\pi\\in\\Pi}\\lambda_{\\pi}\\|\\phi_{h}^{\\pi}-\\phi_{h}^{\\star}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})-1}^{2}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "This does not change the objective value. To see this, note that for any selection $\\pi\\in\\Pi$ in the original problem, the same objective value can be obtained by setting $\\lambda\\,=\\,e_{\\pi}$ in Equation (E.1); hence, the modifcation to the optimization cannot reduce the alue. Furtherif $\\lVert\\phi_{h}^{\\pi}-\\phi_{h}^{\\star}\\rVert_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})-1}^{2}$ is maximized by $\\pi$ for any fixed $\\pi_{\\mathrm{exp}}$ , setting $\\lambda$ as anything other than $e_{\\pi}$ cannot increase the objective value. ", "page_idx": 39}, {"type": "text", "text": "Now, note that both the minimization and maximization problems are over simplices, which are compact and convex sets. The objective is linear in the maximization variable, and hence concave. The objective can be rewritten as ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\sum_{a}\\frac{(\\pmb{\\pi}_{h}-\\pmb{\\pi}_{h}^{\\star})^{\\top}e_{s,a}e_{s,a}^{\\top}(\\pmb{\\pi}_{h}-\\pmb{\\pi}_{h}^{\\star})}{p_{s,a}}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Here, $p_{s,a}$ is the probability that $\\pi_{\\mathrm{exp}}$ plays action $a$ , given that it is in context $s$ From this representation, we can clearly see that the objective is convex in each $p_{s,a}$ . Hence, Von Neumann's minimax theorem applies and the proof is complete. \u53e3 ", "page_idx": 39}, {"type": "text", "text": "Lemma 31. For the setting of ergodic MDPs ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\pi\\in\\mathrm{xp}}\\operatorname*{max}_{\\pi\\in\\Pi}\\|\\phi_{h}^{\\pi}-\\phi_{h}^{\\star}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})-1}^{2}=\\operatorname*{max}_{\\pi\\in\\Pi}2\\mathbb{E}_{s\\sim w_{h}^{\\star}}\\mathbb{I}[\\pi_{h}(s)\\neq\\pi_{h}^{\\prime}(s)],\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Proof. Below, we refer to $p_{s,a}$ as the probability that $\\pi_{\\mathrm{exp}}$ plays action $a$ , given that it is in context $s$ The second equality follows from Lemma 30. ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\pi\\rightarrow\\pi}{\\operatorname*{min}}\\quad\\|\\phi_{h}^{n}-\\phi_{h}^{*}\\|_{\\mathcal{A}_{h}}^{2}(\\pi_{\\infty})\\rightarrow1}\\\\ &{=\\underset{\\pi\\rightarrow\\pi}{\\operatorname*{max}}\\|(\\pi_{h}-\\pi_{h}^{*})w_{h}^{*}\\|_{\\Lambda_{h}}^{2}(\\pi_{\\infty})-1}\\\\ &{=\\underset{\\pi\\rightarrow\\Pi}{\\operatorname*{max}}\\|(\\pi_{h}-\\pi_{h}^{*})w_{h}^{*}\\|_{\\Lambda_{h}}^{2}(\\pi_{\\infty})-1}\\\\ &{=\\underset{\\pi\\rightarrow\\Pi}{\\operatorname*{max}}\\frac{1}{n_{h}}\\mathrm{in}\\,{\\biggr(}\\pi_{h}\\biggr*{\\biggr)}\\frac{(\\pi_{h}-\\pi_{h}^{*})}{n_{h}}{\\biggr|}^{2}\\frac{\\Gamma_{\\phi_{h}}}{e_{h}\\biggr(8\\pi_{h}^{*}\\biggr)}\\,}\\\\ &{=\\underset{\\pi\\rightarrow\\Pi}{\\operatorname*{max}}\\sum_{\\pi}\\phi_{\\Delta,h}^{*}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{\\biggr|}\\,{ \n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "The optimization problems in the final line were solved using KKT conditions. We assume that the two policies are deterministic. Hence, the only two actions in the summation over $\\boldsymbol{\\mathcal{A}}$ abovethatare relevant are $\\pi_{h}(s)$ and $\\pi_{h}^{\\prime}(s)$ . For all other $a\\in{\\mathcal{A}}$ , the term in the square root evaluates to 0. If $\\pi_{h}(s)=\\pi_{h}^{\\prime}(s)$ , then the entire summation over $\\boldsymbol{\\mathcal{A}}$ evaluates to O; else, the terms indexed by $\\pi(c)$ and $\\pi^{\\prime}(c)$ are both 1, and the summation evalutes to 2. Hence, we can simplify the expression to exactly the form of Equation (E.2) from the lemma statement, and the proof is complete. \u53e3 ", "page_idx": 39}, {"type": "text", "text": "Lemma 32. For the ergodic MDP problem, we have that ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{H U(\\pi,\\pi^{\\star})}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\\leq2H^{4}\\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi\\mathrm{exp}}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi_{h}^{\\star}-\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi_{\\mathrm{exp}})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2},\\Delta_{\\operatorname*{min}}^{2}\\}}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Proof. Recall the definition of $U(\\pi,\\pi^{\\star})$ ", "page_idx": 40}, {"type": "equation", "text": "$$\nU(\\pi,\\pi^{\\star})=\\sum_{h=1}^{H}\\mathbb{E}_{s_{h}\\sim w_{h}^{\\pi^{\\star}}}[(Q_{h}^{\\pi}(s_{h},\\pi_{h}(s))-Q_{h}^{\\pi}(s_{h},\\pi_{h}^{\\star}(s)))^{2}].\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Then, we have that ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\operatorname*{max}}{\\pi\\in\\Pi}\\frac{H U(\\pi,\\pi^{*})}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)\\}}}\\\\ &{=\\frac{H}{\\pi\\in\\Pi}\\frac{H}{h}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "The final equality follows from Lemma 31. ", "page_idx": 40}, {"type": "text", "text": "Corollary 2. Assume that all $P_{h}$ aresuchthat $P_{h}(s^{\\prime}|s,a)=P_{h}(s^{\\prime}|s,a^{\\prime})$ for all $(a,a^{\\prime})\\in A$ .Then, with probability at least $1-2\\delta$ PERP (Algorithm 2) finds an e-optimal policy and terminates after collecting at most the following number of episodes: ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\sum_{h=1}^{H}\\operatorname*{inf}_{\\pi\\mathrm{exp}}\\operatorname*{max}_{\\pi\\in\\Pi}\\frac{\\|\\phi_{h}^{\\star}-\\phi_{h}^{\\pi}\\|_{\\Lambda_{h}(\\pi\\mathrm{exp})^{-1}}^{2}}{\\operatorname*{max}\\{\\epsilon^{2},\\Delta(\\pi)^{2}\\}}\\cdot\\iota H^{4}\\beta^{2}+\\frac{C_{\\mathrm{poly}}}{\\operatorname*{max}\\{\\epsilon^{5/3},\\Delta_{\\operatorname*{min}}^{5/3}\\}}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "for $C_{\\mathrm{poly}},\\beta$ as defined in Theorem $^{\\,l}$ ", "page_idx": 40}, {"type": "text", "text": "Proof. The proof follows directly from Theorem 1 and Lemma 32. ", "page_idx": 40}, {"type": "text", "text": "F Tabular Franke Wolfe ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Theorem 2. Fix parameters $K_{\\mathrm{unif}}>0$ $\\epsilon_{\\mathrm{{exp}}}>0$ and consider some $\\Phi\\subseteq\\mathbb{R}^{S A}$ and set $S_{0}\\subseteq S$ Let $\\epsilon_{\\mathrm{unif}}>0$ be some value satisfying ", "page_idx": 40}, {"type": "equation", "text": "$$\nW_{h}^{\\star}(s)>\\epsilon_{\\mathrm{unif}}\\,,\\forall s\\in\\mathcal{S}_{0},\\quad a n d\\quad K_{\\mathrm{unif}}\\,\\geq\\epsilon_{\\mathrm{unif}}^{-1}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Assume that $|[\\phi]_{(s,a)}|\\leq C_{\\phi}\\cdot(W_{h}^{\\star}(s)+\\sqrt{\\epsilon_{\\phi}})$ for all $s\\in S_{0}$ $\\phi\\in\\Phi$ ,and some $C_{\\phi}>0$ and that $[\\phi]_{(s,a)}=0\\,f o r\\,s\\not\\in{\\cal S}_{0}$ .Additionally, let the parameters be such that $\\epsilon_{\\phi}/(K_{\\mathrm{unif}}\\epsilon_{\\mathrm{unif}})\\le\\epsilon_{\\mathrm{exp}}$ Then with probability at least $1-\\delta$ algorithmAlgorithm $3$ run with these parameters will collect at most $\\operatorname*{min}\\left\\{C\\cdot\\frac{\\operatorname*{inf}_{\\Lambda\\in\\Omega_{h}}\\operatorname*{max}_{\\phi\\in\\Phi}\\|\\phi\\|_{\\Lambda^{-1}}^{2}}{\\epsilon_{\\mathrm{exp}}}+\\frac{C_{\\mathrm{fw}}}{\\epsilon_{\\mathrm{exp}}^{4/5}},C_{\\mathrm{fw}}(\\frac{1}{\\epsilon_{\\mathrm{exp}}}+K_{\\mathrm{unif}})\\right\\}+\\frac{C_{\\mathrm{fw}}}{\\epsilon_{\\mathrm{unif}}}+\\log(C_{\\mathrm{fw}})\\cdot K_{\\mathrm{unif}}$ episodes, for $C$ a universal constant and $C_{\\mathrm{fw}}=\\mathrm{poly}(S,A,H,C_{\\phi},\\log1/\\delta,\\log1/\\epsilon_{\\mathrm{exp}},\\log|\\Phi|)$ and will produce covariates  such that ", "page_idx": 40}, {"type": "text", "text": "", "page_idx": 40}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\phi\\in\\Phi}\\|\\phi\\|_{\\widehat{\\Sigma}^{-1}}^{2}\\leq\\epsilon_{\\mathrm{exp}}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "and, for all $s\\in S_{0}$ ", "page_idx": 40}, {"type": "equation", "text": "$$\n[\\widehat\\Sigma]_{(s,a)}\\geq\\frac{\\epsilon_{\\mathrm{unif}}}{2S A}\\cdot K_{\\mathrm{unif}}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "1: input: directions $\\Phi$ , tolerance $\\epsilon_{\\mathrm{exp}}$ , confidence $\\delta$ , minimum reachability $\\epsilon_{\\mathrm{unif}}$ , minimum exploration $K_{\\mathrm{unif}}$ , pruned states ${\\mathcal{S}}_{0}$ , step $h$   \n2: $i\\gets1$   \n3: while $T_{i}K_{i}\\le\\mathrm{poly}(S,A,H,C_{\\phi},\\log{1/\\delta},\\log{1/\\epsilon_{\\mathrm{exp}}},\\log{|\\Phi|})\\cdot\\epsilon_{\\mathrm{exp}}^{-1}\\,\\mathbf{do}$   \n4 $\\mathfrak{D}_{\\mathrm{unif}}^{i}\\leftarrow\\mathrm{UNIFEXP}(\\epsilon_{\\mathrm{unif}},K_{i}T_{i}+K_{\\mathrm{unif}},\\delta/8i^{2})$   \n5: $\\begin{array}{r}{\\mathbf{A}_{0}^{i}\\leftarrow\\frac{1}{T_{i}K_{i}}\\mathrm{diag}(v^{i})}\\end{array}$ where $\\begin{array}{r}{[v^{i}]_{s a}=\\sum_{(s^{\\prime},a^{\\prime})\\in\\mathfrak{D}_{\\mathrm{unif}}^{i}}\\mathbb{I}\\{(s^{\\prime},a^{\\prime})=(s,a)\\}}\\end{array}$ for $s\\in S_{0}$ and $T_{i}K_{i}$ otherwise   \n6: Run iteration $i$ of Algorithm 4 of [43] on objective ", "page_idx": 41}, {"type": "equation", "text": "$$\nf_{i}(\\mathbf{A})\\gets\\frac{1}{\\eta_{i}}\\log\\left(\\sum_{\\phi\\in\\Phi}e^{\\eta_{i}\\|\\phi\\|_{\\mathbf{A}(\\mathbf{A})}^{2}-1}\\right)\\quad\\mathrm{for}\\quad\\mathbf{A}(\\mathbf{A})=\\mathbf{A}+\\mathbf{A}_{0}^{i},\\eta_{i}=2^{2i/5}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "${\\mathfrak{D}}^{i}$ ", "page_idx": 41}, {"type": "text", "text": "toobtaindata   \n7: if Algorithm 4 reaches termination condition then   \n8: return $\\mathfrak{D}^{i}\\cup\\mathfrak{D}_{\\mathrm{unif}}^{i}$   \n9: end if   \n10: $i\\gets i+1$   \n11: end while   \n12: $\\begin{array}{r}{\\mathfrak{D}\\gets\\mathrm{UNIFEXP}(\\epsilon_{\\mathrm{unif}},\\frac{8S^{2}A^{2}C_{\\phi}^{2}}{\\epsilon_{\\mathrm{exp}}}+(8S^{2}A^{2}C_{\\phi}^{2}+1)K_{\\mathrm{unif}},\\delta/4)}\\end{array}$ ", "page_idx": 41}, {"type": "text", "text": "Proof. To prove this result, we apply Lemma 37 combined with Lemma 36. ", "page_idx": 41}, {"type": "text", "text": "Let $\\mathcal{E}_{\\exp}^{i}$ denote the success event of running Algorithm 4 at epoch $i$ . as defined in Lemma 36. On this event, and under the assumption that $W_{h}^{\\star}(s)\\;>\\;\\epsilon_{\\mathrm{unif}}$ for each $s~\\in~S_{0}$ , we have that W (TKa +Kunit) foreach (s, a) with s E So and\u2265; the covariates induced by $\\mathfrak{D}_{\\mathrm{unif}}^{i}$ , which implies that ", "page_idx": 41}, {"type": "equation", "text": "$$\n[\\Lambda_{0}^{i}]_{(s,a)}\\geq\\frac{1}{T_{i}K_{i}}\\frac{W_{h}^{\\star}(s)}{2S A}\\cdot(T_{i}K_{i}+K_{\\mathrm{unif}})\\geq\\frac{W_{h}^{\\star}(s)}{2S A}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "for each $(s,a)$ With $s\\in S_{0}$ , and, furthermore, Algorithm 4 collects at most ", "page_idx": 41}, {"type": "equation", "text": "$$\nT_{i}K_{i}+K_{\\mathrm{unif}}+\\mathrm{poly}(S,A,H,\\log\\frac{T_{i}K_{i}i^{2}}{\\delta\\epsilon_{\\mathrm{unif}}})\\cdot\\frac{1}{\\epsilon_{\\mathrm{unif}}}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "episodes. Furthermore, by Lemma 36, we have $\\mathbb{P}[\\mathcal{E}_{\\mathrm{exp}}^{i}]\\ge\\delta/2i^{2}$ , so it follows that ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\mathbb{P}[\\cup_{i\\geq1}(\\mathcal{E}_{\\mathrm{exp}}^{i})^{c}]\\leq\\sum_{i=1}^{\\infty}\\frac{\\delta}{8i^{2}}\\leq\\delta/4.\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Henceforth, we therefore assume that $\\mathcal E_{\\mathrm{exp}}^{i}$ holds for each $i$ . This immediately implies that (F.2) holds. ", "page_idx": 41}, {"type": "text", "text": "It remains to show that (F.1) is satisfied, and that our sample complexity guarantee is met. To this end we apply Lemma 37 with $\\Lambda_{0}$ a diagonal matrix, with $\\begin{array}{r}{\\bigl[\\bar{\\mathbf{A}}_{0}\\bigr]_{(s,a)}=\\frac{W_{h}^{\\star}(\\bar{s})}{2S A}}\\end{array}$ for $s\\in S_{0}$ , and otherwise $[\\mathbf{A}_{0}]_{(s,a)}=1$ . Note that with this choice of $\\pmb{\\Lambda}_{0}$ , by what we just showed above, we have $\\mathbf{A}_{0}^{i}\\succeq\\mathbf{A}_{0}$ as required by Lemma 37. ", "page_idx": 41}, {"type": "text", "text": "We next turn to bounding the smoothness constants, $\\beta$ and $M$ . First, note that by Lemma 34, at epoch $i$ we have that all iterates of FWREGRET live in the set $\\widehat{\\Omega}_{h,T_{i}K_{i}}(\\delta/8i^{2})$ with probability $1-\\delta/8i^{2}$ Union bounding over this event for all $i$ , with probability at least $1-\\delta/4$ , we have that for each $i$ all iterates of FWREGRET live in the set $\\widehat{\\Omega}_{h,T_{i}K_{i}}(\\delta/8i^{2})$ . By Lemma 35, since we have assumed that $|[\\phi]_{(s,a)}|\\leq C_{\\phi}\\cdot(W_{h}^{\\star}(s)+\\sqrt{\\epsilon_{\\phi}})$ for all $(s,a)$ with $s\\in S_{0}$ and otherwise $[\\phi]_{(s,a)}=0$ for all ", "page_idx": 41}, {"type": "text", "text": "$\\phi\\in\\Phi$ , we can then bound ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{M_{i}\\leq\\underset{s\\in S_{0}}{\\operatorname*{max}}\\left(\\frac{2S A C_{\\phi}^{2}}{C^{\\prime}}+\\frac{2S A C_{\\phi}^{2}\\epsilon_{\\phi}}{C^{\\prime}\\cdot W_{h}^{\\star}(s)}\\right)\\cdot\\left(\\frac{2}{C^{\\prime}}+\\frac{2}{C^{\\prime}T_{i}K_{i}W_{h}^{\\star}(s)}\\cdot\\log\\frac{S A H}{\\delta}\\right)}\\\\ &{\\beta_{i}\\leq\\underset{s\\in S_{0}}{\\operatorname*{max}}(2\\eta_{i}+2)\\left(\\frac{2S A C_{\\phi}^{2}}{C^{\\prime}}+\\frac{2S A C_{\\phi}^{2}\\epsilon_{\\phi}}{C^{\\prime}\\cdot W_{h}^{\\star}(s)}\\right)^{2}\\cdot\\left(\\frac{2}{C^{\\prime}}+\\frac{2}{C^{\\prime}T_{i}K_{i}W_{h}^{\\star}(s)}\\cdot\\log\\frac{S A H}{\\delta}\\right)^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "On the event $\\mathcal E_{\\mathrm{exp}}^{i}$ as noed above we have $\\begin{array}{r}{[\\mathbf{A}_{0}^{i}]_{(s,a)}\\ge\\frac{W_{h}^{\\star}(s)}{2S A}(1+\\frac{K_{\\mathrm{unif}}}{T_{i}K_{i}})}\\end{array}$ $s\\in S_{0}$ o we can take $\\begin{array}{r}{C^{\\prime}=\\frac{1}{2S A}(1+\\frac{K_{\\mathrm{unif}}}{T_{i}K_{i}})}\\end{array}$ . We can then bound ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{max}_{s\\in S_{0}}\\left(\\frac{2S A C_{\\phi}^{2}}{C^{\\prime}}+\\frac{2S A C_{\\phi}^{2}\\epsilon_{\\phi}}{C^{\\prime}\\cdot W_{h}^{\\star}(s)}\\right)\\cdot\\left(\\frac{2}{C^{\\prime}}+\\frac{2}{C^{\\prime}T_{i}K_{i}W_{h}^{\\star}(s)}\\cdot\\log\\frac{S A H}{\\delta}\\right)}\\\\ &{\\leq\\left(4S^{2}A^{2}C_{\\phi}+\\frac{4S^{2}A^{2}C_{\\phi}^{2}\\epsilon_{\\phi}\\cdot T_{i}K_{i}}{K_{\\mathrm{unif}}\\epsilon_{\\mathrm{unif}}}\\right)\\cdot\\left(4S A+\\frac{4S A}{K_{\\mathrm{unif}}\\epsilon_{\\mathrm{unif}}}\\log\\frac{S A H}{\\delta}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "where we have used that $W_{h}^{\\star}(s)\\,\\geq\\,\\epsilon_{\\mathrm{unif}}$ for all $s\\,\\in\\,{\\cal S}_{0}$ , by assumption. By assumption we have $\\frac{\\epsilon_{\\phi}}{K_{\\mathrm{unif}}\\,\\epsilon_{\\mathrm{unif}}}\\le\\epsilon_{\\mathrm{exp}}$ Note thatbyconstrution, thewhile statent onLin3willensure that weawa have $\\begin{array}{r}{\\widetilde{T_{i}K}_{i}\\le\\mathrm{poly}(S,A,H,C_{\\phi},\\log{1/\\delta},\\log{1/\\epsilon_{\\mathrm{exp}}},\\log{|\\Phi|})\\cdot\\epsilon_{\\mathrm{exp}}^{-1}.}\\end{array}$ so we can bound ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\epsilon_{\\mathrm{exp}}\\cdot T_{i}K_{i}\\leq\\mathrm{poly}(S,A,H,C_{\\phi},\\log{1/\\delta},\\log{1/\\epsilon_{\\mathrm{exp}}},\\log{|\\Phi|}).\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "It follows that it suffices to take ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\beta,M\\leq\\mathrm{poly}(S,A,H,C_{\\phi},\\log1/\\delta,\\log1/\\epsilon_{\\mathrm{exp}},\\log|\\Phi|).\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "We now consider two cases. In the first case, when the termination criteria on Line 7 is met, we can apply Lemma 37, to get that with probability at least $1-\\delta/4$ we have that the procedure terminates after running for at most ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\operatorname*{max}\\bigg\\{\\operatorname*{min}\\ 16N\\quad\\mathrm{s.t.}\\quad\\operatorname*{inf}_{\\stackrel{\\mathrm{max}}{\\kappa\\in\\Omega}\\phi\\in\\Phi}\\boldsymbol{\\phi}^{\\top}(N\\mathbf{A}+\\mathbf{A}_{0})^{-1}\\boldsymbol\\phi\\leq\\frac{\\epsilon_{\\mathrm{exp}}}{6},}\\\\ &{}&{\\frac{\\mathrm{poly}\\left(\\boldsymbol\\beta,R,d,H,M,\\log1/\\delta,\\log1/\\epsilon_{\\mathrm{exp}},\\log|\\Phi|\\right)}{\\epsilon_{\\mathrm{exp}}^{4/5}}\\bigg\\}}\\\\ &{}&{\\leq\\operatorname*{max}\\bigg\\{\\operatorname*{min}\\ 16N\\quad\\mathrm{s.t.}\\quad\\operatorname*{inf}_{\\stackrel{\\mathrm{max}}{\\kappa\\in\\Omega}\\phi\\in\\Phi}\\boldsymbol\\phi^{\\top}(N\\mathbf{A}+\\mathbf{A}_{0})^{-1}\\boldsymbol\\phi\\leq\\frac{\\epsilon_{\\mathrm{exp}}}{6},}\\\\ &{}&{\\frac{\\mathrm{poly}(\\boldsymbol{S},\\boldsymbol{A},H,C_{\\phi},\\log1/\\delta,\\log1/\\epsilon_{\\mathrm{exp}},\\log|\\Phi|)}{\\epsilon_{\\mathrm{exp}}^{4/5}}\\bigg\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "episodes, and returns data $\\widehat{\\Sigma}_{N}$ such that ", "page_idx": 42}, {"type": "equation", "text": "$$\nf_{\\widehat{i}}(N^{-1}\\widehat{\\pmb{\\Sigma}}_{N})\\leq N\\epsilon_{\\mathrm{exp}},\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "where $\\widehat{\\dot{i}}$ is the index of the epoch on which it terminates. By Lemma D.1 of [42], we have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\phi\\in\\Phi}\\|\\phi\\|_{\\mathbf{A}(N^{-1}\\widehat{\\Sigma}_{N})^{-1}}^{2}\\le f_{\\widehat{i}}(N^{-1}\\widehat{\\Sigma}_{N})\\le N\\epsilon_{\\mathrm{exp}}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "which implies ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\phi\\in\\Phi}\\|\\phi\\|_{(\\widehat{\\Sigma}_{N}+\\Sigma_{\\widehat{i}})^{-1}}^{2}\\leq\\epsilon_{\\exp},\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "which proves (F1). Furthermore, (F2) holds since as noted [\u2265a]s,a) \u2265A $\\begin{array}{r}{[\\Sigma_{i}]_{(s,a)}\\geq\\frac{W_{h}^{\\star}(s)}{2S A}\\cdot(T_{i}K_{i}+K_{\\mathrm{unif}})}\\end{array}$ each $(s,a)$ with $s\\in S_{0}$ , and since $W_{h}^{\\star}(s)\\geq\\epsilon_{\\mathrm{unif}}$ for all $s\\in S_{0}$ ", "page_idx": 42}, {"type": "text", "text": "In the second case, when the while loop on Line 3 terminates since $\\begin{array}{r l}{T_{i}K_{i}}&{{}\\leq}\\end{array}$ $\\mathrm{poly}(S,A,H,C_{\\phi},\\log1/\\delta,\\log1/\\epsilon_{\\mathrm{exp}},\\log|\\Phi|)\\,\\,\\,\\cdot\\,\\,\\bar{\\epsilon}_{\\mathrm{exp}}^{-1}$ we canbound the tal number of episodes collected within the calls to Algorithm 4 of [43] within the while loop by ", "page_idx": 42}, {"type": "text", "text": "$\\operatorname{poly}(S,A,H,C_{\\phi},\\log1/\\delta,\\log1/\\epsilon_{\\mathrm{exp}},\\log|\\Phi|)\\cdot\\epsilon_{\\mathrm{exp}}^{-1}$ Furthermore, by Lemma 36, with probability at least $1-\\delta/4$ , we have that the call to UNIFExP on Line 12 terminates after running for at most ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\frac{8S^{2}A^{2}C_{\\phi}^{2}}{\\epsilon_{\\mathrm{exp}}}+(8S^{2}A^{2}C_{\\phi}^{2}+1)K_{\\mathrm{unif}}+\\mathrm{poly}(S,A,H,\\log\\frac{T_{i}K_{i}i^{2}}{\\delta\\epsilon_{\\mathrm{unif}}})\\cdot\\frac{1}{\\epsilon_{\\mathrm{unif}}}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "episodes, and that the returned data atisfies Nn(s, a) \u2265 Ws'a) $\\begin{array}{r}{N_{h}(s,a)\\,\\geq\\,\\frac{W_{h}^{\\star}(s)}{2S A}\\cdot(\\frac{8S^{2}A^{2}C_{\\phi}^{2}}{\\epsilon_{\\mathrm{exp}}}+8S^{2}A^{2}C_{\\phi}^{2}K_{\\mathrm{unif}}\\,+\\,}\\end{array}$ $K_{\\mathrm{unif}})$ . Since $|[\\phi]_{(s,a)}|\\leq C_{\\phi}\\cdot(W_{h}^{\\star}(s)+\\sqrt{\\epsilon_{\\phi}})$ and $\\epsilon_{\\phi}/(K_{\\mathrm{unif}}\\epsilon_{\\mathrm{unif}})\\le\\dot{\\epsilon_{\\mathrm{exp}}}$ by assumption, some manipulation shows that ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\frac{[\\phi]_{(s,a)}^{2}}{N_{h}(s,a)}\\le\\frac{C_{\\phi}^{2}\\cdot(W_{h}^{\\star}(s)+\\sqrt{\\epsilon_{\\phi}})^{2}}{\\frac{W_{h}^{\\star}(s)}{2S A}\\cdot(\\frac{8S^{2}A^{2}C_{\\phi}^{2}}{\\epsilon_{\\mathrm{exp}}}+8S^{2}A^{2}C_{\\phi}^{2}K_{\\mathrm{unif}}+K_{\\mathrm{unif}})}\\le\\frac{\\epsilon_{\\mathrm{exp}}}{S A}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "It follows then that, letting $\\widehat{\\boldsymbol{\\Sigma}}$ denote the covariance obtained by the call to UNIFEXP on Line 12, ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\phi\\in\\Phi}\\|\\phi\\|_{\\widehat{\\Sigma}^{-1}}^{2}\\leq\\epsilon_{\\mathrm{exp}}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "as desired. Furthermore,it is straightforward to see that $\\begin{array}{r}{[\\widehat\\Sigma]_{(s,a)}\\,\\geq\\,\\frac{\\epsilon_{\\mathrm{unif}}}{2S A}\\,\\cdot K_{\\mathrm{unif}}}\\end{array}$ for $s\\in S_{0}$ as well. To complete the proof, we union bound over these events holding, and take the minimum of the sample complexity bounds from either case. ", "page_idx": 43}, {"type": "text", "text": "F.1  Data Conditioning ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Lemma 33. Consider running any algorithm for $K$ episodes. Let $K_{h}(s,a)$ denote the number of visits to $(s,a,h)$ . Then with probability at least $1-\\delta,$ forall $(s,a,h)$ simultaneously, we have ", "page_idx": 43}, {"type": "equation", "text": "$$\nK_{h}(s,a)\\leq W_{h}^{\\star}(s)K+\\sqrt{2W_{h}^{\\star}(s)K\\cdot\\log\\frac{S A H}{\\delta}}+\\log\\frac{S A H}{\\delta}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Proof. By definition, we have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{\\pi}w_{h}^{\\pi}(s)=W_{h}^{\\star}(s).\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "This implies that any policy will reach $(s,h)$ with probability at most $W_{h}^{\\star}(s)$ . We can therefore think of this as the sum of Bernoullis with parameter at most $W_{h}^{\\star}(s)$ , so the bound follows by applying Bernstein's inequality and a union bound. ", "page_idx": 43}, {"type": "text", "text": "Lemma 34. Consider the set ", "text_level": 1, "page_idx": 43}, {"type": "equation", "text": "$$\n\\widehat{\\sf1}_{h,K}(\\delta):=\\left\\{\\operatorname{diag}({\\boldsymbol{v}})\\,:\\,{\\boldsymbol{v}}\\in\\mathbb{R}_{+}^{S A},[{\\boldsymbol{v}}]_{(s,a)}\\le W_{h}^{\\star}(s)+\\sqrt{\\frac{2W_{h}^{\\star}(s)}{K}\\cdot\\log\\frac{S A H}{\\delta}}+\\frac{1}{K}\\log\\frac{S A H}{\\delta}\\right\\}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Consider running some set of policies for $K$ episodes, and let K be defined as ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\widehat{\\mathbf{A}}_{h}=\\mathrm{diag}(\\widehat{\\boldsymbol{v}}),\\quad[\\boldsymbol{v}]_{(s,a)}=\\frac{K_{h}(s,a)}{K}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Then with probability at least $1-\\delta$ we have that $\\widehat{\\mathbf{A}}_{h}\\in\\widehat{\\Omega}_{h,K}(\\delta)$ for all $h\\in[H]$ simultaneously. ", "page_idx": 43}, {"type": "text", "text": "Proof. This is an immediate consequence of Lemma 33. ", "page_idx": 43}, {"type": "text", "text": "We will denote $\\widehat{\\Omega}_{h,K}:=\\widehat{\\Omega}_{h,K}(\\delta)$ when the choice of $\\delta$ is clear from context. Lemma 35. Consider the function ", "page_idx": 43}, {"type": "equation", "text": "$$\nf(\\mathbf{\\boldsymbol{\\Lambda}})=\\frac{1}{\\eta}\\log\\left(\\sum_{\\phi\\in\\Phi}e^{\\eta\\|\\phi\\|_{\\mathbf{A}(\\Lambda)^{-1}}^{2}}\\right)\\quad f o r\\quad\\mathbf{\\boldsymbol{A}}(\\mathbf{\\boldsymbol{\\Lambda}})=\\mathbf{\\boldsymbol{\\Lambda}}+\\mathbf{\\boldsymbol{\\Lambda}}_{0}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Assume thatforall $\\phi\\in\\Phi$ we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\phi\\in\\Phi}\\left|[\\phi]_{(s,a)}\\right|\\le C_{\\phi}\\cdot(W_{h}^{\\star}(s)+\\epsilon),\\quad\\forall s\\in S_{0}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "for some ${\\mathcal S}_{0}$ and some $C_{\\phi},\\epsilon>0$ , and otherwise $[\\phi]_{(s,a)}=0$ .Assume that $\\mathbf{A}_{0}=\\mathrm{diag}(\\pmb{v})$ for some $\\pmb{v}$ satisfying ", "page_idx": 44}, {"type": "equation", "text": "$$\n[\\pmb{v}]_{(s,a)}\\geq C^{\\prime}\\cdot W_{h}^{\\star}(s),\\quad\\forall s\\in S_{0}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "and otherwise $[{\\pmb v}]_{(s,a)}\\geq\\lambda,$ for some $C^{\\prime},\\lambda>0$ Then we can bound ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{sup}_{\\hat{\\Lambda},\\hat{\\Lambda}^{\\prime}\\in\\hat{\\Omega}_{h,K}}|\\nabla_{\\Lambda}f(\\Lambda)|_{\\Lambda=\\hat{\\Lambda}}[\\widehat{\\Lambda}^{\\prime}]|}\\\\ &{\\displaystyle\\le\\operatorname*{max}_{s\\in S_{0}}\\left(\\frac{2S A C_{\\phi}^{2}}{C^{\\prime}}+\\frac{2S A C_{\\phi}^{2}\\epsilon^{2}}{C^{\\prime}\\cdot W_{h}^{\\star}(s)}\\right)\\cdot\\left(\\frac{2}{C^{\\prime}}+\\frac{2}{C^{\\prime}K W_{h}^{\\star}(s)}\\cdot\\log\\frac{S A H}{\\delta}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "and ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{sup}_{\\hat{\\Lambda},\\hat{\\Lambda}^{\\prime},\\hat{\\Lambda}^{\\prime\\prime}\\in\\hat{\\Omega}_{h,K}}\\vert\\nabla_{\\Lambda}^{2}f(\\Lambda)\\vert_{\\Lambda=\\hat{\\Lambda}}[\\hat{\\Lambda}^{\\prime},\\hat{\\Lambda}^{\\prime\\prime}]\\vert}\\\\ &{\\displaystyle\\le\\operatorname*{max}_{s\\in S_{0}}(2+2\\eta)\\left(\\frac{2S A C_{\\phi}^{2}}{C^{\\prime}}+\\frac{2S A C_{\\phi}^{2}\\epsilon^{2}}{C^{\\prime}\\cdot W_{h}^{\\star}(s)}\\right)^{2}\\cdot\\left(\\frac{2}{C^{\\prime}}+\\frac{2}{C^{\\prime}K W_{h}^{\\star}(s)}\\cdot\\log\\frac{S A H}{\\delta}\\right)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Proof. By Lemma D.5 of [42], we have that ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\nabla_{\\mathbf{A}}f(\\mathbf{A})\\vert_{\\mathbf{A}=\\hat{\\mathbf{A}}}[\\widehat{\\mathbf{A}}^{\\prime}]=-\\left(\\sum_{\\phi\\in\\Phi}e^{\\eta\\|\\phi\\|_{\\mathbf{A}(\\hat{\\mathbf{A}})^{-1}}^{2}}\\right)\\cdot\\sum_{\\phi\\in\\Phi}e^{\\eta\\|\\phi\\|_{\\mathbf{A}(\\hat{\\mathbf{A}})^{-1}}^{2}}\\phi^{\\top}\\mathbf{A}(\\widehat{\\mathbf{A}})^{-1}\\widehat{\\mathbf{A}}^{\\prime}\\mathbf{A}(\\widehat{\\mathbf{A}})^{-1}\\phi.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "We have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\phi^{\\top}\\mathbf{A}(\\widehat{\\mathbf{A}})^{-1}\\widehat{\\mathbf{A}}^{\\prime}\\mathbf{A}(\\widehat{\\mathbf{A}})^{-1}\\phi=\\sum_{s,a}\\frac{[\\phi]_{(s,a)}^{2}\\cdot[\\widehat{\\mathbf{A}}^{\\prime}]_{(s,a)}}{[\\mathbf{A}(\\widehat{\\mathbf{A}})]_{(s,a)}^{2}}=\\sum_{s\\in S_{0}}\\sum_{a}\\frac{[\\phi]_{(s,a)}^{2}\\cdot[\\widehat{\\mathbf{A}}^{\\prime}]_{(s,a)}}{[\\mathbf{A}(\\widehat{\\mathbf{A}})]_{(s,a)}^{2}}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where the last equality follows since, for $s\\not\\in S_{0}$ , we have assumed $[\\phi]_{(s,a)}=0$ ", "page_idx": 44}, {"type": "text", "text": "Now consider some $s\\in\\mathcal S_{0}$ . By asumption we have $[\\phi]_{(s,a)}^{2}\\leq2C_{\\phi}^{2}\\cdot(W_{h}^{\\star}(s)^{2}+\\epsilon^{2})$ and by our assumption on $\\mathbf{A}_{0}$ we can lower bound $[\\mathbf{A}(\\widehat{\\mathbf{A}})]_{(s,a)}\\geq C^{\\prime}\\cdot W_{h}^{\\star}(s)$ . Furthermore, since $\\widehat{\\mathbf{A}}^{\\prime}\\in\\widehat{\\Omega}_{h,K}$ we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{[\\widehat{\\mathbf{A}}^{\\prime}]_{(s,a)}\\leq W_{h}^{\\star}(s)+\\sqrt{\\frac{2W_{h}^{\\star}(s)}{K}\\cdot\\log\\frac{S A H}{\\delta}}+\\frac{1}{K}\\log\\frac{S A H}{\\delta}}\\\\ &{\\qquad\\qquad\\leq2W_{h}^{\\star}(s)+\\frac{2}{K}\\log\\frac{S A H}{\\delta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Putting this together, we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{[\\phi]_{(s,a)}^{2}\\cdot[\\widehat{\\mathbf{A}}^{\\prime}]_{(s,a)}}{[\\mathbf{A}(\\widehat{\\mathbf{A}})]_{(s,a)}^{2}}\\leq\\frac{4C_{\\phi}^{2}\\cdot(W_{h}^{\\star}(s)^{2}+\\epsilon^{2})\\cdot(W_{h}^{\\star}(s)+\\frac{1}{K}\\log\\frac{S A H}{\\delta})}{(C^{\\prime}\\cdot W_{h}^{\\star}(s))^{2}}}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\leq\\left(\\frac{2C_{\\phi}^{2}}{C^{\\prime}}+\\frac{2C_{\\phi}^{2}\\epsilon^{2}}{C^{\\prime}W_{h}^{\\star}(s)}\\right)\\cdot\\left(\\frac{2}{C^{\\prime}}+\\frac{2}{C^{\\prime}K W_{h}^{\\star}(s)}\\log\\frac{S A H}{\\delta}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "It follows that ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\sum_{s\\in S_{0}}\\sum_{a}\\frac{[\\phi]_{(s,a)}^{2}\\cdot[\\widehat{\\Lambda}^{\\prime}]_{(s,a)}}{[\\mathbf{A}(\\widehat{\\Lambda})]_{(s,a)}^{2}}\\leq\\operatorname*{max}_{s\\in S_{0}}\\left(\\frac{2S A C_{\\phi}^{2}}{C^{\\prime}}+\\frac{2S A C_{\\phi}^{2}\\epsilon^{2}}{C^{\\prime}W_{h}^{\\star}(s)}\\right)\\cdot\\left(\\frac{2}{C^{\\prime}}+\\frac{2}{C^{\\prime}K W_{h}^{\\star}(s)}\\log\\frac{S A H}{\\delta}\\right).\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "The second bound follows in an analogous fashion, using the expression for the second derivative given in Lemma D.5 of [42]. ", "page_idx": 44}, {"type": "text", "text": "input: tolerance $\\epsilon_{\\mathrm{unif}}$ , reruns $K$ , confidence $\\delta$ , step $h$   \n$\\mathfrak{D}\\leftarrow\\emptyset$   \nfor $(s,a)\\in S\\times A$ do I/ LEARN2EXPLORE is as defined in [46] $\\begin{array}{r}{\\{(\\mathcal{X}_{j},\\Pi_{j},N_{j})\\}_{j=1}^{\\lceil\\log_{2}1/\\epsilon_{\\mathrm{unif}}\\rceil}\\leftarrow\\mathrm{LEARN2EXPLORE}(\\{(s,a)\\},h,\\frac{\\delta}{2S A},\\frac{\\delta}{2K S A},\\epsilon_{\\mathrm{unif}})}\\end{array}$ if $\\exists j_{s a}$ such that $(s,a)\\in\\mathcal{X}_{j_{s a}}$ then Rerun every poliyin $\\begin{array}{r}{\\Pi_{j_{s a}}^{\\ \u3001\\,-}\\,K_{s a}:=\\lceil\\frac{K}{S A|\\Pi_{j_{s a}}|}\\rceil}\\end{array}$ times, stor bserve ransitions n $\\mathfrak{D}$ end if   \nend for   \nreturn $\\mathfrak{D}$ ", "page_idx": 45}, {"type": "text", "text": "Lemma 36. With probability at least $1-\\delta$ Algorithm 4 will terminate after running for at most ", "page_idx": 45}, {"type": "equation", "text": "$$\nK+\\mathrm{poly}(S,A,H,\\log\\frac{K}{\\delta\\epsilon_{\\mathrm{unif}}})\\cdot\\frac{1}{\\epsilon_{\\mathrm{unif}}}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "episodes andwill collect at least $\\frac{W_{h}^{\\star}(s)K}{2S A}$ samples from each $(s,a)$ such that $W_{h}^{\\star}(s)>\\epsilon_{\\mathrm{unif}}$ ", "page_idx": 45}, {"type": "text", "text": "Proof. By Theorem 13 of [46], with probability at least $1-\\delta/2S A$ , for any $(s,a)$ ", "page_idx": 45}, {"type": "text", "text": "\u00b7 LEARN2ExPLORE willrunfo at most poly $\\begin{array}{r}{\\cdot(S,A,H,\\log\\frac{K}{\\delta\\epsilon_{\\mathrm{unif}}})\\cdot\\frac{1}{\\epsilon_{\\mathrm{unif}}}}\\end{array}$ episodes. \u00b7 Rerunning every policy in $\\Pi_{j_{s a}}$ once, with probability at least $1-\\delta/K$ we will collect $\\begin{array}{r}{N=2^{-j_{s a}}|\\Pi_{j_{s a}}|}\\end{array}$ samples from $(s,a)$ , for $|\\Pi_{j_{s a}}|=\\mathcal{O}(2^{j_{s a}}\\cdot S^{3}A^{2}H^{4}\\log^{3}{1/\\delta})$ \uff1a \u00b7 We have that $W_{h}^{\\star}(s)\\leq2^{-j_{s a}+1}$ \u00b7 IF $(s,a)\\not\\in\\mathcal{X}_{j}$ for all $j=1,2,\\dots,\\lceil\\log1/\\epsilon_{\\mathrm{unif}}\\rceil$ , then $W_{h}^{\\star}(s)\\leq\\epsilon_{\\mathrm{unif}}$ ", "page_idx": 45}, {"type": "text", "text": "By the above conclusions, rerunning policies in $\\Pi_{j_{s a}}$ on Line 7, with probability at least $1-\\delta/2S A$ we will collect ", "page_idx": 45}, {"type": "equation", "text": "$$\nN\\cdot K_{s a}\\geq N\\cdot{\\frac{K}{S A|\\Pi_{j_{s a}}|}}={\\frac{2^{-j_{s a}}K}{S A}}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "samles fom (sa)oteW(s)2 ssimlies tat we wil ollcta east samples from $(s,a)$ . Union bounding over this holding for all $(s,a)$ , and noting that we only fail to collect this many samples if $W_{h}^{\\star}(s)\\leq\\epsilon_{\\mathrm{unif}}$ gives the collection guarantee. ", "page_idx": 45}, {"type": "text", "text": "To bound the total number of episodes, we note that the procedure on Line 7 will, in total collect at most ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\sum_{s,a:j_{s a}\\mathrm{\\;exists}}\\left|\\Pi_{j_{s a}}|\\left[K_{s a}\\right]\\leq\\sum_{s,a:j_{s a}\\mathrm{\\;exists}}|\\Pi_{j_{s a}}|+\\sum_{s,a}\\frac{K}{S A}=\\sum_{s,a}|\\Pi_{j_{s a}}|+K\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "episodes.IF $\\r_{j_{s a}}$ exists, this implies that $|\\Pi_{j_{s a}}|\\,\\le\\,\\mathcal{O}(2^{j_{s a}}\\cdot S^{3}A^{2}H^{4}\\log^{3}1/\\delta)$ ,and since $\\scriptstyle j_{s a}\\ \\in$ $\\{1,2,\\dots,\\lceil\\log1/\\epsilon_{\\mathrm{unif}}\\rceil\\}$ , this implies that the above is bounded by ", "page_idx": 45}, {"type": "equation", "text": "$$\nK+\\mathcal{O}(\\epsilon_{\\mathrm{unif}}^{-1}\\cdot S^{3}A^{2}H^{4}\\log^{3}{1/\\delta}).\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Combining this with our bound on the total number of episodes collected by LEARN2EXPLORE, we have that the number of episodes collected by Algorithm 4 is bounded by ", "page_idx": 45}, {"type": "equation", "text": "$$\nK+\\mathrm{poly}(S,A,H,\\log\\frac{K}{\\delta\\epsilon_{\\mathrm{unif}}})\\cdot\\frac{1}{\\epsilon_{\\mathrm{unif}}}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "F.2Online Frank-Wolfe ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Lemma 37. Let ", "page_idx": 46}, {"type": "equation", "text": "$$\nf_{i}(\\mathbf{A})=\\frac{1}{\\eta_{i}}\\log\\left(\\sum_{\\phi\\in\\Phi}e^{\\eta_{i}\\|\\phi\\|_{\\mathbf{A}_{i}(\\Lambda)}^{2}-1}\\right),\\quad\\mathbf{A}_{i}(\\mathbf{A})=\\mathbf{A}+\\frac{1}{T_{i}K_{i}}\\mathbf{A}_{0,i}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "for some $\\mathbf{\\Lambda}_{\\Lambda_{0,i}}$ satisfying $\\mathbf{A}_{0,i}\\succeq\\mathbf{A}_{0}$ for all $i$ ,and $\\eta_{i}=2^{2i/5}$ . Let $(\\beta_{i},M_{i})$ denote the smoothness and magnitude constants for $f_{i}$ . Let $(\\beta,M)$ be some values such that $\\beta_{i}\\leq\\eta_{i}\\beta,M_{i}\\leq M$ for all $i$ and $R$ the diameter of the domain of possiblevalues of $\\Lambda$ ", "page_idx": 46}, {"type": "text", "text": "Then, if we run Algorithm $^{4}$ of [43] on $(f_{i})_{i}$ with constraint tolerance e and confidence $\\delta$ and $K_{i}=T_{i}=2^{i}$ , we have that with probability at least $1-\\delta$ it will run for at most ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\operatorname*{max}\\left\\{\\operatorname*{min}_{N}16N\\;s.t.\\;\\operatorname*{inf}_{\\Lambda\\in\\Omega}\\operatorname*{max}_{\\phi\\in\\Phi}\\phi^{\\top}(N\\Lambda+\\Lambda_{0})^{-1}\\phi\\le\\frac{\\epsilon}{6},\\frac{\\mathrm{poly}(\\beta,R,d,H,M,\\log1/\\delta,\\log|\\Phi|)}{\\epsilon^{4/5}}\\right\\},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "episodes, and will return data $\\{\\phi_{\\tau}\\}_{\\tau=1}^{N}$ with covariance $\\begin{array}{r}{\\widehat{\\Sigma}_{N}=\\sum_{\\tau=1}^{N}\\phi_{\\tau}\\phi_{\\tau}^{\\top}}\\end{array}$ such that ", "page_idx": 46}, {"type": "equation", "text": "$$\nf_{\\widehat{i}}(N^{-1}{\\widehat{\\Sigma}}_{N})\\leq N\\epsilon,\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where $\\widehat{i}$ is the iteration on which OPTCov terminates. ", "page_idx": 46}, {"type": "text", "text": "Proof. Our goal is to simply find a setting of $i$ that is sufficiently large to guarantee the condition $f_{i}(\\widehat{\\pmb{\\Lambda}}_{i})\\leq K_{i}T_{i}\\epsilon$ is met. By Lemma C.1 of [43], we have with probability at least $1-\\delta/(2i^{2})$ ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f_{i}(\\widehat{\\Lambda}_{i})\\leq\\underset{\\Lambda\\in\\Omega}{\\operatorname*{inf}}\\;f_{i}(\\Lambda)+\\frac{\\beta_{i}R^{2}(\\log T_{i}+3)}{2T_{i}}+\\sqrt{\\frac{4M^{2}\\log(8i^{2}T_{i}/\\delta)}{K_{i}}}}\\\\ &{\\qquad\\qquad+\\sqrt{\\frac{c_{1}M^{2}d^{4}H^{4}\\log^{3}(8i^{2}H K_{i}T_{i}/\\delta)}{K_{i}}}+\\frac{c_{2}M d^{4}H^{3}\\log^{7/2}(4i^{2}H K_{i}T_{i}/\\delta)}{K_{i}}}\\\\ &{\\qquad\\leq3\\operatorname*{max}\\Bigg\\{\\underset{\\Lambda\\in\\Omega}{\\operatorname*{inf}}\\;f_{i}(\\Lambda),\\frac{\\beta_{i}R^{2}(\\log T_{i}+3)}{2T_{i}},\\sqrt{\\frac{4M^{2}\\log(8i^{2}T_{i}/\\delta)}{K_{i}}}}\\\\ &{\\qquad\\qquad\\qquad+\\sqrt{\\frac{c_{1}M^{2}d^{4}H^{4}\\log^{3}(8i^{2}H K_{i}T_{i}/\\delta)}{K_{i}}}+\\frac{c_{2}M d^{4}H^{3}\\log^{7/2}(4i^{2}H K_{i}T_{i}/\\delta)}{K_{i}}\\Bigg\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "So a sufficient condition for $f_{i}(\\widehat{\\mathbf{A}}_{i})\\leq K_{i}T_{i}\\epsilon$ is that ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{K_{i}T_{i}\\ge\\!\\!\\frac{3}{\\epsilon}\\operatorname*{max}\\Bigg\\{\\operatorname*{inf}_{\\Lambda\\in\\Omega}f_{i}(\\Lambda),\\frac{\\beta_{i}R^{2}(\\log T_{i}+3)}{2T_{i}},\\sqrt{\\frac{4M^{2}\\log(8i^{2}T_{i}/\\delta)}{K_{i}}}}\\\\ &{\\quad\\quad\\quad\\quad+\\sqrt{\\frac{c_{1}M^{2}d^{4}H^{4}\\log^{3}(8i^{2}H K_{i}T_{i}/\\delta)}{K_{i}}}+\\frac{c_{2}M d^{4}H^{3}\\log^{7/2}(4i^{2}H K_{i}T_{i}/\\delta)}{K_{i}}\\Bigg\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Recall that ", "page_idx": 46}, {"type": "equation", "text": "$$\nf_{i}(\\mathbf{A})=\\frac{1}{\\eta_{i}}\\log\\left(\\sum_{\\phi\\in\\Phi}e^{\\eta_{i}\\|\\phi\\|_{\\mathbf{A}_{i}(\\mathbf{A})}^{2}-1}\\right),\\quad\\mathbf{A}_{i}(\\mathbf{A})=\\mathbf{A}+\\frac{1}{T_{i}K_{i}}\\mathbf{A}_{0,i}.\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "By Lemma D.1 of [42], we can bound ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\phi\\in\\Phi}\\|\\phi\\|_{\\mathbf{A}_{i}(\\mathbf{A})^{-1}}^{2}\\leq f_{i}(\\mathbf{A})\\leq\\operatorname*{max}_{\\phi\\in\\Phi}\\|\\phi\\|_{\\mathbf{A}_{i}(\\mathbf{A})^{-1}}^{2}+\\frac{\\log|\\Phi|}{\\eta_{i}}.\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Thus, ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{inf}_{\\boldsymbol{\\Lambda}\\in\\Omega}f_{i}(\\boldsymbol{\\Lambda})\\leq\\displaystyle\\operatorname*{inf}_{\\boldsymbol{\\Lambda}\\in\\Omega}\\displaystyle\\operatorname*{max}_{\\phi\\in\\Phi}\\|\\phi\\|_{\\mathbf{A}_{i}(\\boldsymbol{\\Lambda})^{-1}}^{2}+\\displaystyle\\frac{\\log|\\Phi|}{\\eta_{i}}}\\\\ &{\\quad\\quad\\quad\\quad=\\displaystyle\\operatorname*{inf}_{\\boldsymbol{\\Lambda}\\in\\Omega}\\displaystyle\\operatorname*{max}_{\\phi\\in\\Phi}T_{i}K_{i}\\phi^{\\top}(T_{i}K_{i}\\mathbf{A}+\\mathbf{A}_{0,i}+\\mathbf{A}_{\\mathrm{off}})^{-1}\\phi+\\displaystyle\\frac{\\log|\\Phi|}{\\eta_{i}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "By our choice of $\\eta_{i}=2^{2i/5}$ , and $K_{i}=2^{i}$ \uff0c $T_{i}=2^{i}$ , we can ensure that ", "page_idx": 47}, {"type": "equation", "text": "$$\nK_{i}T_{i}\\ge\\frac{6}{\\epsilon}\\frac{\\log|\\Phi|}{\\eta_{i}}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "as long as $\\begin{array}{r}{i\\geq\\frac{2}{5}\\log_{2}[\\frac{6\\log|\\Phi|}{\\epsilon}]}\\end{array}$ . To ensure that ", "page_idx": 47}, {"type": "equation", "text": "$$\nT_{i}K_{i}\\ge\\frac{6}{\\epsilon}\\operatorname*{inf}_{\\epsilon}\\operatorname*{max}_{\\phi\\in\\Phi}T_{i}K_{i}\\phi^{\\top}(T_{i}K_{i}\\mathbf{A}+\\mathbf{A}_{0,i})^{-1}\\phi\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "it suffices to take ", "page_idx": 47}, {"type": "equation", "text": "$$\ni\\geq\\arg\\operatorname*{min}_{i}i\\quad{\\mathrm{s.t.}}\\quad\\operatorname*{inf}_{\\Lambda\\in\\Omega}\\operatorname*{max}_{\\phi\\in\\Phi}\\phi^{\\top}(2^{3i}\\Lambda+\\Lambda_{0,i})^{-1}\\phi\\leq{\\frac{\\epsilon}{6}}.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Since we assume that we can lower bound $\\mathbf{A}_{0,i}\\succeq\\mathbf{A}_{0}$ for each $i$ , o this can be further simplified to ", "page_idx": 47}, {"type": "equation", "text": "$$\ni\\geq\\arg\\operatorname*{min}_{i}i\\quad{\\mathrm{s.t.}}\\quad\\operatorname*{inf}_{\\Lambda\\in\\Omega}\\operatorname*{max}_{\\phi\\in\\Phi}\\phi^{\\top}(2^{3i}\\Lambda+\\Lambda_{0})^{-1}\\phi\\leq{\\frac{\\epsilon}{6}}.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "We next want to show that ", "page_idx": 47}, {"type": "equation", "text": "$$\nT_{i}K_{i}\\geq\\frac{3}{\\epsilon}\\cdot\\frac{\\beta_{i}R^{2}(\\log T_{i}+3)}{2T_{i}}.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Bounding $\\beta_{i}\\leq\\eta_{i}\\beta$ , a sufficient condition for this is that ", "page_idx": 47}, {"type": "equation", "text": "$$\ni\\geq\\frac{2}{5}\\left(\\log_{2}(12\\beta R^{2}i)+\\log_{2}\\frac{1}{\\epsilon}\\right).\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "By Lemma A.1 of [43], it suffices to take ", "page_idx": 47}, {"type": "equation", "text": "$$\ni\\ge\\frac{6}{5}\\log_{2}(9\\beta R^{2}\\log_{2}\\frac{1}{\\epsilon})+\\frac{2}{5}\\log_{2}\\frac{1}{\\epsilon}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "to meet this condition (this assumes that $12\\beta R^{2}\\geq1$ and $\\frac{2}{5}\\log_{2}\\frac{1}{\\epsilon}\\geq1$ if either of these is not the case we can just replace them with 1 without changing the validity of the final result). ", "page_idx": 47}, {"type": "text", "text": "Finally, we want to ensure that ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{T_{i}K_{i}\\geq\\frac{3}{\\epsilon}\\Bigg(\\sqrt{\\frac{4M^{2}\\log(8i^{2}T_{i}/\\delta)}{K_{i}}}}\\\\ &{\\qquad\\qquad+\\sqrt{\\frac{c_{1}M^{2}d^{4}H^{4}\\log^{3}(8i^{2}H K_{i}T_{i}/\\delta)}{K_{i}}}+\\frac{c_{2}M d^{4}H^{3}\\log^{7/2}(4i^{2}H K_{i}T_{i}/\\delta)}{K_{i}}\\Bigg).}\\end{array}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "To guarantee this, it suffices that ", "page_idx": 47}, {"type": "equation", "text": "$$\n2^{5i/2}\\geq\\frac{c}{\\epsilon}\\sqrt{M^{2}d^{4}H^{4}i^{3}\\log^{3}(i H/\\delta)},\\quad2^{3i}\\geq\\frac{c}{\\epsilon}\\cdot M d^{4}H^{3}i^{7/2}\\log^{7/2}(i H/\\delta).\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "or ", "page_idx": 47}, {"type": "equation", "text": "$$\ni\\geq\\frac{4}{5}\\log_{2}(c M d H i\\log(H/\\delta))+\\frac{2}{5}\\log_{2}\\frac{1}{\\epsilon},\\quad i\\geq\\frac{4}{3}\\log_{2}(c M d H\\log(H/\\delta))+\\frac{1}{3}\\log_{2}\\frac{1}{\\epsilon}.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "By Lemma A.1 of [43], it then suffices to take ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle i\\geq\\frac{12}{5}\\log(c M d H\\log(H/\\delta)\\log_{2}1/\\epsilon)+\\frac{2}{5}\\log_{2}\\frac{1}{\\epsilon},}\\\\ {\\displaystyle i\\geq4\\log_{2}(c M d H\\log(H/\\delta)\\log_{2}1/\\epsilon)+\\frac{1}{3}\\log_{2}\\frac{1}{\\epsilon}}\\end{array}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "$i$ $\\begin{array}{r}{i\\geq\\frac{2}{5}\\log_{2}[\\frac{6\\log|\\Phi|}{\\epsilon}]}\\end{array}$ ", "page_idx": 47}, {"type": "text", "text": "$\\widehat{\\dot{i}}$ is the final round, the total complexity scales as ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{\\widehat{i}}T_{i}K_{i}=\\sum_{i=1}^{\\widehat{i}}2^{2i}\\leq2\\cdot2^{2\\widehat{i}}.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Using the sufficient condition on $i$ given above, we can bound the total complexity as ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\mathfrak{c}\\left\\{\\underset{N}{\\mathrm{min~16}N}\\;\\mathrm{s.t.}\\;\\underset{\\Lambda\\in\\Omega}{\\mathrm{inf}}\\;\\underset{\\phi\\in\\Phi}{\\mathrm{max}}\\,\\phi^{\\top}(N\\mathbf{A}+\\Lambda_{0})^{-1}\\phi\\leq\\frac{\\epsilon}{6},\\frac{\\mathrm{poly}(\\beta,R,d,H,M,\\log1/\\delta,\\log|\\Phi|)}{\\epsilon^{4/5}}\\right\\}.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "table", "img_path": "RYQ0KuZvkL/tmp/6e9927691ed34715775dd741b822c70240b28dff7b79666eae2f14785251650f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 48}, {"type": "text", "text": "Lemma 38. With probability at least $1-\\delta_{i}$ .Algorithm 5 will terminate after running for at most ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\operatorname{poly}(S,A,H,\\log{\\frac{1}{\\delta\\epsilon_{\\mathrm{unif}}}})\\cdot{\\frac{1}{\\epsilon_{\\mathrm{unif}}}}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "episodes and willreturn a set $S^{\\mathrm{keep}}$ such that, for every $(s,h)\\in S^{\\mathrm{keep}}$ we have $W_{h}^{\\star}(s)\\geq\\epsilon_{\\mathrm{unif}}$ and, $i f\\left(s,h\\right)\\notin S^{\\mathrm{keep}}$ then $W_{h}^{\\star}(s)\\leq32\\epsilon_{\\mathrm{unif}}$ ", "page_idx": 48}, {"type": "text", "text": "Proof. As in Lemma 36, by Theorem 13 of [46], with probability at least $1-\\delta/S H$ , for any $(s,h)$ ", "page_idx": 48}, {"type": "text", "text": "\u00b7 LEARN2ExPLORE willrunfor at most po $\\begin{array}{r}{\\mathrm{ly}(S,A,H,\\log\\frac{1}{\\delta\\epsilon_{\\mathrm{unif}}})\\cdot\\frac{1}{\\epsilon_{\\mathrm{unif}}}}\\end{array}$ episodes. \u00b7 Rerunning every policy in $\\Pi_{j_{s}}$ once, with probability at least $1/2$ we will collect $N=$ $2^{-j_{s}}|\\Pi_{j_{s}}|$ samples from $(s,a,h)$ \u00b7 If $(s,a)\\not\\in\\mathcal{X}_{j}$ for all $j=1,2,\\dots,\\lceil\\log1/\\epsilon_{\\mathrm{unif}}\\rceil$ , then $W_{h}^{\\star}(s)\\leq32\\epsilon_{\\mathrm{unif}}$ ", "page_idx": 48}, {"type": "text", "text": "We union bound over this event holding for all $(s,h)$ , which occurs with probability at least $1-\\delta$ ", "page_idx": 48}, {"type": "text", "text": "It is immediate by the last property that, if $(s,h)\\not\\in{\\cal S}^{\\mathrm{keep}}$ then $W_{h}^{\\star}(s)\\leq32\\epsilon_{\\mathrm{unif}}$ ", "page_idx": 48}, {"type": "text", "text": "We next show that if $(s,h)\\,\\in\\,S^{\\mathrm{keep}}$ , then this implies that $W_{h}^{\\star}(s)\\,\\geq\\,\\epsilon_{\\mathrm{unif}}$ .Let $X$ be a random variable denoting the total number of samples we collect from $(s,a,h)$ when rerunning all policies in $\\Pi_{j_{s}}$ . Then by Markov's Inequality, by the above properties we have ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\le\\mathbb{P}[X\\ge N_{j_{s}}/2]\\le\\frac{2\\mathbb{E}[X]}{N_{j_{s}}}\\le\\frac{2|\\Pi_{j_{s}}|W_{h}^{\\star}(s)}{N_{j_{s}}}=8\\cdot2^{j_{s}}W_{h}^{\\star}(s).\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "It follows that ", "page_idx": 48}, {"type": "equation", "text": "$$\nW_{h}^{\\star}(s)\\geq\\frac{1}{16\\cdot2^{j_{s}}}\\geq\\frac{1}{16\\cdot2^{\\lceil\\log_{2}\\frac{1}{32\\epsilon_{\\mathrm{unif}}}\\rceil}}\\geq\\frac{1}{32\\cdot2^{\\log_{2}\\frac{1}{32\\epsilon_{\\mathrm{unif}}}}}=\\epsilon_{\\mathrm{unif}}.\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "This completes the proof. ", "page_idx": 48}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Claims   \nQuestion: Do the main claims made in the abstract and introduction accurately reflect the   \npaper's contributions and scope?   \nAnswer: [Yes] ", "page_idx": 48}, {"type": "text", "text": "Justification: These can be found in the abstract and the contributions section of the introduction. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 49}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 49}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Justification: These can be found in the Discussion section of the main body of the paper. Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 49}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 49}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 49}, {"type": "text", "text": "Justification: All proofs are found in the Appendix. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results. \u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced. ", "page_idx": 49}, {"type": "text", "text": "\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems. \u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. \u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. \u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 50}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 50}, {"type": "text", "text": "Answer: [NA]   \nJustification: The contributions of this paper are entirely theoretical. Guidelines:   \n\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 50}, {"type": "text", "text": "", "page_idx": 50}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 50}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 50}, {"type": "text", "text": "Justification: The contributions of this paper are entirely theoretical. Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code. ", "page_idx": 50}, {"type": "text", "text": "\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so ^\u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : / /nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 51}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 51}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 51}, {"type": "text", "text": "Justification: The contributions of this paper are entirely theoretical. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 51}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 51}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Justification: The contributions of this paper are entirely theoretical. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified. ", "page_idx": 51}, {"type": "text", "text": "\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative errorrates). \u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 52}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce theexperiments? ", "page_idx": 52}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 52}, {"type": "text", "text": "Justification: The contributions of this paper are entirely theoretical. ", "page_idx": 52}, {"type": "text", "text": "Guidelines: ", "page_idx": 52}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 52}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 52}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 52}, {"type": "text", "text": "Justification: There are no human subjects and we discuss the ethical consequences in the \"Broader Impact\" section of the discussion. ", "page_idx": 52}, {"type": "text", "text": "Guidelines: ", "page_idx": 52}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 52}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 52}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 52}, {"type": "text", "text": "Justification: This theoretical paper poses minimal public concerns but holds significant potential to inspire advancements in algorithm development, contributing positively to the field of machine learning. ", "page_idx": 52}, {"type": "text", "text": "Guidelines: ", "page_idx": 52}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to ", "page_idx": 52}, {"type": "text", "text": "generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 53}, {"type": "text", "text": "\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 53}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 53}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 53}, {"type": "text", "text": "Justification: The contributions are theoretical. ", "page_idx": 53}, {"type": "text", "text": "Guidelines: ", "page_idx": 53}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safetyfilters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 53}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properlyrespected? ", "page_idx": 53}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 53}, {"type": "text", "text": "Justification: The contributions are theoretical, and we do not use any such assets. For prior theoretical work, we have credited the authors appropriately. ", "page_idx": 53}, {"type": "text", "text": "Guidelines: ", "page_idx": 53}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 53}, {"type": "text", "text": "13. New Assets ", "page_idx": 53}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 54}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 54}, {"type": "text", "text": "Justification: The contributions are theoretical. Guidelines: ", "page_idx": 54}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose assetisused.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 54}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 54}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 54}, {"type": "text", "text": "Justification: No human subjects. ", "page_idx": 54}, {"type": "text", "text": "Guidelines: ", "page_idx": 54}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 54}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 54}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 54}, {"type": "text", "text": "Justification: No human subjects. ", "page_idx": 54}, {"type": "text", "text": "Guidelines: ", "page_idx": 54}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with humansubjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 54}]