[{"figure_path": "Ib2iHIJRTh/figures/figures_0_1.jpg", "caption": "Figure 1: Weather performance (x-axis) is not a strong indicator of climate performance (y-axis). Each dot corresponds to a distinct sample or checkpoint epoch.", "description": "This figure shows the divergence between medium-range weather forecasting skill and longer-term climate performance.  The x-axis represents the average RMSE of 5-day weather forecasts, while the y-axis shows the RMSE of the 10-year time-mean climate simulations. Each point represents a distinct model sample or checkpoint epoch.  The lack of correlation between the two metrics highlights that good short-term weather forecasts do not necessarily guarantee good long-term climate simulations.  Small, systematic errors in short-term predictions can accumulate over time and lead to large biases in long-term climate statistics.", "section": "Introduction"}, {"figure_path": "Ib2iHIJRTh/figures/figures_2_1.jpg", "caption": "Figure 2: RMSE of 10-year time-means for a subset of important fields. The leftmost bar in the first two subplots shows the reference noise floor, determined by comparing ten independent 10-year reference FV3GFS simulations with the validation simulation. The scores computed using the mean over these ten simulations (a proxy for an \"ensemble prediction\") are shown in light shade. The subsequent bars show the corresponding scores for our method and the deep-learning baselines, using a 25-member ensemble for the probabilistic methods (all except ACE, which only reports scores for its single deterministic prediction). Scores computed using the ensemble-mean prediction are shown in light shade. The dark shaded bar on top indicates the performance drop when using a single member's prediction only, with error bars representing the standard deviation over the 25 different member choices. The rightmost subplot displays the average time-mean RMSE of the ML-based emulators relative to the reference across all 34 variables. On average, our method's time-mean RMSEs are 50% higher than the noise floor, which is less than half the average RMSE of the next best method, ACE. When using the 25-member ensemble mean prediction, this reduces to 29.28%.", "description": "The figure displays a comparison of the 10-year time-mean RMSE for various fields between the proposed model and multiple baselines, including the reference FV3GFS simulations. It highlights the reduction in climate biases achieved by the proposed model compared to existing methods, especially when using ensemble predictions.", "section": "5.3 Climate Biases"}, {"figure_path": "Ib2iHIJRTh/figures/figures_4_1.jpg", "caption": "Figure 3: The diagram shows how our proposed approach functions at inference time. Given an initial condition xt and forcings ft:t+h, our method uses the DYffusion framework, integrated with two SFNO backbone networks, to generate predictions for the next h time steps based on an alternation of direct multi-step forecasts and temporal interpolations. To simplify the visualization, we exclude the facts that the interpolator network, SFNO, is conditioned on xt and ft in addition to an estimate of xt+h. We also exclude the time-conditioning of both networks. To forecast more time steps beyond t + h, our method is applied autoregressively.", "description": "This figure illustrates the inference process of the Spherical DYffusion model.  It starts with an initial condition (xt) and forcing data (ft:t+h). The model alternates between a direct multi-step forecast using SFNO\u03b8 and temporal interpolation using SFNO\u03c6 to generate predictions for the next h time steps. The process repeats recursively to make long-term predictions.", "section": "3.2 Diffusion Models and DYffusion"}, {"figure_path": "Ib2iHIJRTh/figures/figures_4_2.jpg", "caption": "Figure 4: Diagram of one of the blocks of the modified SFNO architecture for our proposed method. The full architecture consists of a sequence of 8 such blocks. Our newly introduced time-conditioning modules correspond to the Time Embedding, followed by the MLP on the right, and the scale-shift operation. Our method relies on dropout, which is part of the two-layer MLP on the top. SFNO-based baselines use the same architecture and hyperparameters without the time embedding module.", "description": "This figure shows the architecture of one block of the modified Spherical Fourier Neural Operator (SFNO) used in the proposed Spherical DYffusion model.  The full model uses 8 of these blocks sequentially.  The diagram highlights the addition of a new time-conditioning module, consisting of a time embedding followed by a multi-layer perceptron (MLP) that modifies the scale and shift parameters.  The use of dropout within a two-layer MLP is also shown.  This is compared to a standard SFNO which lacks the time embedding.", "section": "3 Background"}, {"figure_path": "Ib2iHIJRTh/figures/figures_7_1.jpg", "caption": "Figure 5: Global maps of the 10-year time-mean biases of a single sample from the reference noise floor simulation, our model, and the ACE baseline for the total water path field. Each subplot reports the global mean RMSE and bias of the respective bias map. Our model reproduces biases of similar location and magnitude to the reference noise floor, suggesting they are mainly due to internal climate variability rather than model bias, while the baseline exhibits larger climate biases.", "description": "This figure displays global maps of 10-year time-mean biases for the total water path (TWP) variable, comparing the reference noise floor simulation, the proposed Spherical DYffusion model, and the ACE baseline model.  The maps show spatial patterns of biases, with numerical values (RMSE and bias) provided for each model. The key finding is that Spherical DYffusion produces biases similar in location and magnitude to the noise floor, implying that the model's errors mainly stem from inherent climate variability rather than systematic biases. In contrast, ACE demonstrates larger and more significant biases.", "section": "5.3 Climate Biases"}, {"figure_path": "Ib2iHIJRTh/figures/figures_9_1.jpg", "caption": "Figure 6: Comparison of 100-year global mean simulations between Spherical DYffusion and ACE. From top to bottom: near-surface air temperature (T7), total water path (TWP), and surface pressure (ps). Both models are driven by identical annually repeating forcings. Spherical DYffusion demonstrates more stable trajectories, particularly evident in the surface pressure predictions, while maintaining physically realistic variability patterns. The consistent behavior across all variables indicates the model's robustness for long-term climate simulations.", "description": "This figure compares the 100-year global mean simulations of Spherical DYffusion and ACE, driven by identical annually repeating forcings.  It displays time series of near-surface air temperature (T7), total water path (TWP), and surface pressure (ps). Spherical DYffusion shows more stable trajectories than ACE, particularly in surface pressure, while maintaining realistic variability. The figure highlights Spherical DYffusion's robustness for long-term climate simulations.", "section": "Conclusion"}, {"figure_path": "Ib2iHIJRTh/figures/figures_21_1.jpg", "caption": "Figure 2: RMSE of 10-year time-means for a subset of important fields. The leftmost bar in the first two subplots shows the reference noise floor, determined by comparing ten independent 10-year reference FV3GFS simulations with the validation simulation. The scores computed using the mean over these ten simulations (a proxy for an \"ensemble prediction\") are shown in light shade. The subsequent bars show the corresponding scores for our method and the deep-learning baselines, using a 25-member ensemble for the probabilistic methods (all except ACE, which only reports scores for its single deterministic prediction). Scores computed using the ensemble-mean prediction are shown in light shade. The dark shaded bar on top indicates the performance drop when using a single member's prediction only, with error bars representing the standard deviation over the 25 different member choices. The rightmost subplot displays the average time-mean RMSE of the ML-based emulators relative to the reference across all 34 variables. On average, our method's time-mean RMSEs are 50% higher than the noise floor, which is less than half the average RMSE of the next best method, ACE. When using the 25-member ensemble mean prediction, this reduces to 29.28%.", "description": "This figure compares the root mean square error (RMSE) of 10-year time-means for several important climate variables.  It shows the performance of the proposed Spherical DYffusion model against several baselines (ACE, DYffusion, ACE-STO), with the reference noise floor also included.  The figure highlights that Spherical DYffusion achieves lower RMSE values than the baselines, particularly when using an ensemble prediction, demonstrating its superior skill in emulating long-term climate statistics.", "section": "5.3 Climate Biases"}, {"figure_path": "Ib2iHIJRTh/figures/figures_23_1.jpg", "caption": "Figure 10: Zonal means of the simulated 10-year time-mean climatologies for a representative subset of four temperature fields. Level 7 represents near-surface conditions, while Level 0 corresponds to the highest altitude. Our method generally provides the closest emulation to the reference data. The most notable biases in the emulations occur at Levels 2 and 0, indicating greater discrepancies at higher altitudes. Emulation challenges are also significant near the poles, including at near-surface levels, particularly for DYffusion.", "description": "This figure compares zonal means of simulated 10-year time-mean climatologies for four temperature levels (7, 5, 2, 0) across different methods: the proposed method, ACE, and DYffusion, against a reference model.  The results show that the proposed model's zonal means generally align best with the reference model, particularly at lower altitudes.  However, all methods demonstrate biases, especially at higher altitudes and near the poles.  The biases are more pronounced for DYffusion.", "section": "E.1.1 Zonal time-means"}, {"figure_path": "Ib2iHIJRTh/figures/figures_23_2.jpg", "caption": "Figure 1: Weather performance (x-axis) is not a strong indicator of climate performance (y-axis). Each dot corresponds to a distinct sample or checkpoint epoch.", "description": "This figure illustrates the discrepancy between a model's skill in short-term weather forecasting and its long-term climate simulation accuracy.  The x-axis represents the average RMSE (Root Mean Square Error) of 5-day weather forecasts, a measure of short-term forecasting skill. The y-axis shows the RMSE of the 10-year time-mean, indicating long-term climate simulation accuracy.  Each point represents a distinct model sample or training checkpoint. The scatter plot demonstrates that good short-term weather forecasting skill (low x-axis values) does not guarantee accurate long-term climate simulation (low y-axis values).  This highlights the challenge of transferring success in short-term weather forecasting to long-term climate modeling.", "section": "1 Introduction"}, {"figure_path": "Ib2iHIJRTh/figures/figures_24_1.jpg", "caption": "Figure 12: Global maps of the standard deviation of the 10-year time-mean of the reference ensemble and a 25-member ensemble of our method. The climate variability of our method is consistent with the reference model, and largely follows similar spatial patterns with adequate magnitudes. The global mean standard deviation is reported in Table 2.", "description": "This figure displays global maps visualizing the standard deviation of 10-year time-means for five key climate variables: surface pressure, total water path, near-surface temperature, zonal wind at near-surface level, and meridional wind at near-surface level.  Both the reference ensemble and a 25-member ensemble from the proposed Spherical DYffusion model are shown. The maps illustrate that the model's simulated climate variability closely matches the reference in terms of both spatial patterns and magnitudes. The numerical values are summarized in Table 2.", "section": "5.3 Climate Biases"}, {"figure_path": "Ib2iHIJRTh/figures/figures_25_1.jpg", "caption": "Figure 13: Comparison of medium-range weather forecasting skill between Spherical DYffusion (25-member ensemble and single forecast), DYffusion (25-member ensemble and single forecast), and ACE (single, deterministic forecast). Our method generates competitive probabilistic ensemble weather forecasts, a necessary but not sufficient prerequisite for achieving good climate simulations.", "description": "This figure compares the medium-range weather forecasting skill of three different models: Spherical DYffusion, DYffusion, and ACE.  For each model, it shows the performance of both a 25-member ensemble and a single forecast.  The results highlight that Spherical DYffusion produces competitive probabilistic ensemble weather forecasts. However, it also emphasizes that good ensemble weather forecasting is a necessary, but not sufficient, condition for achieving good climate simulations.", "section": "5.3 Climate Biases"}, {"figure_path": "Ib2iHIJRTh/figures/figures_25_2.jpg", "caption": "Figure 1: Weather performance (x-axis) is not a strong indicator of climate performance (y-axis). Each dot corresponds to a distinct sample or checkpoint epoch.", "description": "This figure shows the divergence between medium-range weather forecasting skill and long-term climate performance.  The x-axis represents the average root mean square error (RMSE) on 5-day weather forecasts, a measure of weather forecasting skill. The y-axis represents the RMSE of the 10-year time-mean, a measure of climate performance. Each point represents a distinct sample or checkpoint epoch from a machine learning model.  The lack of correlation highlights that good short-term weather forecasting skill does not guarantee accurate long-term climate simulation.", "section": "1 Introduction"}, {"figure_path": "Ib2iHIJRTh/figures/figures_26_1.jpg", "caption": "Figure 5: Global maps of the 10-year time-mean biases of a single sample from the reference noise floor simulation, our model, and the ACE baseline for the total water path field. Each subplot reports the global mean RMSE and bias of the respective bias map. Our model reproduces biases of similar location and magnitude to the reference noise floor, suggesting they are mainly due to internal climate variability rather than model bias, while the baseline exhibits larger climate biases.", "description": "This figure shows global maps of 10-year time-mean biases for the total water path (TWP) for three different models: the reference model (noise floor), the proposed Spherical DYffusion model, and the ACE baseline model.  The maps show the spatial distribution of biases. The accompanying text provides the global mean RMSE and bias values for each model, demonstrating that Spherical DYffusion produces biases very close to the noise floor (i.e., biases explained by inherent climate variability), while ACE shows larger biases indicating systematic model errors.", "section": "5.3 Climate Biases"}, {"figure_path": "Ib2iHIJRTh/figures/figures_27_1.jpg", "caption": "Figure 13: Comparison of medium-range weather forecasting skill between Spherical DYffusion (25-member ensemble and single forecast), DYffusion (25-member ensemble and single forecast), and ACE (single, deterministic forecast). Our method generates competitive probabilistic ensemble weather forecasts, a necessary but not sufficient prerequisite for achieving good climate simulations.", "description": "This figure compares the medium-range weather forecasting skill of three different models: Spherical DYffusion, DYffusion, and ACE.  It shows that Spherical DYffusion produces competitive probabilistic ensemble weather forecasts.  The figure displays various metrics (RMSE, CRPS, spread-skill ratio) over time (in days) for multiple fields (surface pressure, total water path, temperature, wind speed). While achieving good weather forecasts is necessary, it's not sufficient for accurate climate simulations, which is a key point highlighted by this figure.", "section": "5.3 Climate Biases"}, {"figure_path": "Ib2iHIJRTh/figures/figures_27_2.jpg", "caption": "Figure 2: RMSE of 10-year time-means for a subset of important fields. The leftmost bar in the first two subplots shows the reference noise floor, determined by comparing ten independent 10-year reference FV3GFS simulations with the validation simulation. The scores computed using the mean over these ten simulations (a proxy for an \"ensemble prediction\") are shown in light shade. The subsequent bars show the corresponding scores for our method and the deep-learning baselines, using a 25-member ensemble for the probabilistic methods (all except ACE, which only reports scores for its single deterministic prediction). Scores computed using the ensemble-mean prediction are shown in light shade. The dark shaded bar on top indicates the performance drop when using a single member's prediction only, with error bars representing the standard deviation over the 25 different member choices. The rightmost subplot displays the average time-mean RMSE of the ML-based emulators relative to the reference across all 34 variables. On average, our method's time-mean RMSEs are 50% higher than the noise floor, which is less than half the average RMSE of the next best method, ACE. When using the 25-member ensemble mean prediction, this reduces to 29.28%.", "description": "This figure compares the root mean square error (RMSE) of 10-year time-mean predictions for several key climate variables across different models: the proposed Spherical DYffusion model, several baselines (ACE, DYffusion, ACE with stochasticity), and a reference model (FV3GFS).  It highlights the superior performance of Spherical DYffusion in reducing climate biases, particularly when using ensemble predictions.", "section": "5.3 Climate Biases"}]