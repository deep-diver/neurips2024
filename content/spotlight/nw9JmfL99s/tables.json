[{"figure_path": "nw9JmfL99s/tables/tables_2_1.jpg", "caption": "Figure 8: (Top) Four initializations trained on NLGP(g = 100) with \u03be\u03bf = 0.3 and \u03be\u2081 = 0.7. As expected, weights always localize. In (Left, First) we plot IPR for empirical and analytical receptive fields (RFs) across time (defined as (# of gradient steps) \u00d7 \u03c4, the learning rate). In (Left, Second) we plot the time-evolution of l\u2082 distance between the empirical and analytical RFs. In (Left, Third) we zoom in on (Left, First), restricting the range to [0, 0.1] to more closely see divergence in IPR early in training. In (Right, First) and (Right, Second), we snapshot the empirical and analytical RFs at a time before and just after, respectively, the analytical model breaks down (according to IPR and l\u2082 distance) due to localization. Finally, in (Right, Third), we snapshot at the end of the training period. (Bottom) Same initialization as first row in top, but trained on NLGP(g = 0.01) data, again with \u03be\u03bf = 0.3 and \u03be\u2081 = 0.7. As expected, weights do not localize. We plot the same quantities as above, but here the predictions of our analytical model hold throughout the entire training process as localization never emerges and so assumption (A3) is not violated as above.", "description": "This figure validates the analytical model by comparing its predictions with empirical results from simulations. It shows that the model accurately predicts localization in weights for appropriate data distributions, and that the model's limitations arise when the assumptions underlying it are violated.", "section": "4 Experimental results"}]