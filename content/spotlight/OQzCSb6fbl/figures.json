[{"figure_path": "OQzCSb6fbl/figures/figures_0_1.jpg", "caption": "Figure 1: Why does this object image activate IT neurons that are selective for bodies? Our goal is to visually explain responses of category-selective neurons to outside-of-category (ooc.) stimuli. We start with an ooc. stimulus (object), that strongly activates a neuron which primarily fires for a specific category (bodies). We compute latent CNN activations for the image, as well as for a set of within-category reference images. A neuron-specific similarity metric operating on the latent activations finds the reference image most similar to the ooc. stimulus. The proposed parallel backpropagation method then highlights the shared features driving the neural response.", "description": "This figure illustrates the workflow of the proposed method. It starts with an out-of-category image that strongly activates a neuron selective for a specific category (e.g., bodies).  The method computes the latent CNN activations for this image and compares it to a set of within-category reference images to find the most similar one. Finally, a parallel backpropagation method highlights the shared features between the out-of-category image and the most similar within-category image, visually explaining why the neuron responds to the out-of-category stimulus.", "section": "Introduction"}, {"figure_path": "OQzCSb6fbl/figures/figures_4_1.jpg", "caption": "Figure 2: Sketch of the parallel backpropagation method. A pre-trained CNN cut off at a predetermined layer computes latent feature activations. These are backpropagated to obtain the Jacobians of the two activation vectors w.r.t. to the respective images. We then calculate the normalized Hadamard product of the activation vectors and the element-wise square of the learned linear readout vector for the considered neuron. The pixel saliency map is then computed as the sum of gradients of each feature, weighted by the feature's entry in the Hadamard product.", "description": "This figure illustrates the parallel backpropagation method used in the paper to visualize shared features between two images.  First, a pre-trained Convolutional Neural Network (CNN) extracts latent feature activations from both images.  These activations are then backpropagated to the pixel level, resulting in gradient maps for each image.  A weighted Hadamard product, incorporating the neuron's specific readout weights, combines these gradient maps.  Finally, a weighted sum of the resulting gradients generates the final pixel saliency maps highlighting the shared features driving the neuron's response.", "section": "Methods"}, {"figure_path": "OQzCSb6fbl/figures/figures_6_1.jpg", "caption": "Figure 3: a) Correlation between predicted and recorded neural responses for held-out monkey body images (blue) and object images (orange). Significant positive correlation for object images demonstrates that the visual features predictive of responses to body images are also predictive of responses to objects. Brown dots show the correlation between responses to the same stimuli in the first and second recording phase. Dashed lines show the average across channels (colored) and the .05 confidence interval for the correlation coefficient under the null hypothesis that p = 0 (black). b) Neural responses to the objects for which features are visualized in Figs. 4 and 5. Responses to visualized objects are higher than mean responses to objects and bodies in the vast majority of cases.", "description": "Figure 3 shows the results of testing how well the model generalizes from body images to object images. Part (a) shows a strong positive correlation between predicted and recorded neural responses for object images, demonstrating that the features predictive of body image responses also predict object image responses.  The correlation is higher for body images, and the consistency of responses across recording sessions is demonstrated. Part (b) shows that neural responses to the objects are higher than average for body and object images in most cases.", "section": "Results"}, {"figure_path": "OQzCSb6fbl/figures/figures_7_1.jpg", "caption": "Figure 4: Results obtained by applying the proposed method to multi-unit recordings from body-selective cells in macaque STS (posterior region). Each subplot corresponds to one recording channel. The object on the left is among the most highly activating objects for the channel. The image on the right corresponds to the most similar preferred body.", "description": "This figure shows the results of applying the parallel backpropagation method to visualize shared features between out-of-category objects and within-category body images for multi-unit recordings from the posterior region of the macaque STS.  Each subplot displays a pair of images: an out-of-category object image (left) that strongly activates a particular neuron, and the most similar within-category body image (right) based on a neuron-specific similarity metric. The overlayed heatmaps highlight the shared image regions that contribute to the neural response.", "section": "Results"}, {"figure_path": "OQzCSb6fbl/figures/figures_8_1.jpg", "caption": "Figure 4: Results obtained by applying the proposed method to multi-unit recordings from body-selective cells in macaque STS (posterior region). Each subplot corresponds to one recording channel. The object on the left is among the most highly activating objects for the channel. The image on the right corresponds to the most similar preferred body.", "description": "This figure displays the results of applying the parallel backpropagation method to visualize shared features between out-of-category objects and within-category body images for neurons in the macaque STS posterior region. Each subplot represents a different recording channel.  The left image in each subplot shows an object that strongly activates the neuron, while the right image shows the most similar body image based on a neuron-specific similarity metric. The heatmaps overlayed on the images highlight the shared features driving the neural response.", "section": "5 Results"}, {"figure_path": "OQzCSb6fbl/figures/figures_12_1.jpg", "caption": "Figure 6: Results of applying the parallel backpropagation method to six synthetic, category-selective neurons. Each row corresponds to one neuron, with the preferred category indicated above. We observe that the visualizations clearly mark features that are common among within-class images, showing why the ooc. stimuli drive the otherwise category-selective neurons.", "description": "This figure shows the results of applying the parallel backpropagation method on six synthetic, category-selective neurons. Each row represents a different neuron, with its preferred category labeled above. The visualizations highlight features shared between within-category and out-of-category (ooc) images, explaining why ooc images activate the neuron.", "section": "A.1 Additional Results"}, {"figure_path": "OQzCSb6fbl/figures/figures_13_1.jpg", "caption": "Figure 7: Results for computing the Jacobian using the Integrated Gradient method (top row). Bottom row shows the results for the standard gradient computation from the main text for reference.", "description": "This figure compares the results of using two different methods for computing the Jacobian of the latent features with respect to image pixels: Integrated Gradients and the standard gradient method. The top row displays visualizations generated using Integrated Gradients, while the bottom row shows visualizations obtained using the standard gradient method. Both methods aim to highlight image regions that are highly relevant for predicting neural responses. The similarity in the visualizations suggests that the choice of method has a minimal effect on the overall results.", "section": "A.1.2 Integrated Gradients"}]