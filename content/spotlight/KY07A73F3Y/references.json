{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "This paper introduces CLIP, a foundational vision-language model that is extensively used and compared against in the current research."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This paper introduces the foundation for diffusion models, which are central to the current research's methodology."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper details Stable Diffusion, a key model used for generating representations in the current research."}, {"fullname_first_author": "Suraj Nair", "paper_title": "R3M: A universal visual representation for robot manipulation", "publication_date": "2022-00-00", "reason": "This paper introduces R3M, a strong baseline model for comparison in the robotic manipulation tasks."}, {"fullname_first_author": "Arjun Majumdar", "paper_title": "Where are we in the search for an artificial visual cortex for embodied intelligence?", "publication_date": "2023-00-00", "reason": "This paper provides a comprehensive overview of recent work in embodied AI and establishes several strong baselines for comparison in the current research."}]}