[{"figure_path": "hS1jvV3Dk3/tables/tables_6_1.jpg", "caption": "Table 1: Average test accuracy with standard error (3 runs) for different methods on 20 instruction induction tasks. We bold the highest accuracy when comparing ZOPO with baselines, and use green cell to highlight the highest accuracy when comparing ZOPOGPT with baselines.", "description": "This table presents the average test accuracy, along with standard errors, achieved by various prompt optimization methods on 20 instruction induction tasks.  The highest accuracy for each task is highlighted, differentiating between comparisons of ZOPO against baselines and ZOPOGPT against baselines.", "section": "5.1 Instruction Induction"}, {"figure_path": "hS1jvV3Dk3/tables/tables_8_1.jpg", "caption": "Table 1: Average test accuracy with standard error (3 runs) for different methods on 20 instruction induction tasks. We bold the highest accuracy when comparing ZOPO with baselines, and use green cell to highlight the highest accuracy when comparing ZOPOGPT with baselines.", "description": "This table presents the average test accuracy and standard error for various prompt optimization methods across 20 instruction induction tasks.  The results compare ZOPO and ZOPOGPT against several baselines (APE, InstructZero, INSTINCT, EvoPrompt, PB, OPRO).  The highest accuracy for each task is highlighted, with the best results for ZOPO and ZOPOGPT indicated using bold and green highlighting, respectively. The table showcases the superior performance of ZOPO and ZOPOGPT compared to the other baselines on a majority of tasks.", "section": "5.1 Instruction Induction"}, {"figure_path": "hS1jvV3Dk3/tables/tables_20_1.jpg", "caption": "Table 1: Average test accuracy with standard error (3 runs) for different methods on 20 instruction induction tasks. We bold the highest accuracy when comparing ZOPO with baselines, and use green cell to highlight the highest accuracy when comparing ZOPOGPT with baselines.", "description": "This table presents a comparison of the average test accuracy achieved by various prompt optimization methods on 20 instruction induction tasks.  The results are reported with standard error across three runs.  The table highlights the highest accuracy achieved by ZOPO compared to the baselines for each task, and also highlights the best performance of ZOPOGPT against baselines using green cells. The results showcase the superior performance of ZOPO and ZOPOGPT compared to the other methods.", "section": "5.1 Instruction Induction"}, {"figure_path": "hS1jvV3Dk3/tables/tables_22_1.jpg", "caption": "Table 4: Test accuracy achieved by different methods on GLUE tasks.", "description": "This table presents the performance of various prompt optimization methods on the GLUE benchmark.  The GLUE benchmark consists of several natural language understanding tasks.  The table shows the test accuracy achieved by each method on each task, highlighting the relative performance of ZOPO compared to established baselines. The \"#best-performing tasks\" and \"performance profile p(5)\" rows provide a summary of the overall comparative performance.", "section": "5 Experiments"}, {"figure_path": "hS1jvV3Dk3/tables/tables_22_2.jpg", "caption": "Table 5: Test accuracy achieved by ZOPO under zero-shot and few-shot settings on instruction induction tasks.", "description": "This table compares the performance of ZOPO under zero-shot and few-shot (5 examples) settings on various instruction induction tasks.  It demonstrates the impact of providing a small number of examples to guide the LLM (few-shot learning) on the final accuracy.  The table allows one to see whether providing in-context examples improves performance.", "section": "5 Experiments"}, {"figure_path": "hS1jvV3Dk3/tables/tables_23_1.jpg", "caption": "Table 6: Test accuracy on instruction induction tasks with different black-box LLMs f(\u00b7) considered in the objective function in Eq. 1.", "description": "This table shows the test accuracy results for different combinations of prompt generation models (Vicuna-13B and WizardLM-13B) and black-box LLMs used for prompt evaluation (GPT-3.5, PaLM2, and GPT-4) on instruction induction tasks.  It demonstrates the generalizability of ZOPO across various LLMs and shows that Vicuna generally performs better than WizardLM for prompt generation and representation in this context.  The best-performing LLM for each task is highlighted. The performance profile (p(5)) is also included to provide a summary of the overall performance.", "section": "D.5 Results of Different Combinations of Generation and Foundation Models"}, {"figure_path": "hS1jvV3Dk3/tables/tables_24_1.jpg", "caption": "Table 7: Fair comparison of the optimization performance of ZOPO with different generated prompts but the same embedding model (i.e., SBERT).", "description": "This table compares the performance of ZOPO when using prompts generated by Vicuna-13B and ChatGPT, while keeping the embedding model (SBERT) consistent.  It demonstrates how the choice of prompt generation model affects the optimization results, highlighting the impact of the input domain on the ZOPO's performance. The results are presented for 20 instruction induction tasks, allowing for a comprehensive comparison of the two prompt generation methods.", "section": "5.3 Ablation Study"}, {"figure_path": "hS1jvV3Dk3/tables/tables_25_1.jpg", "caption": "Table 8: Average test accuracy with standard error (3 runs) for the best prompt found by ZOPO with four different embeddings on 20 instruction induction tasks.", "description": "This table presents the average test accuracy achieved by the ZOPO algorithm using four different embedding methods (Last Token, OpenAI, SBERT, and Random) on 20 instruction induction tasks.  The standard error across 3 runs is also provided.  The results show the impact of different embedding choices on the algorithm's performance.", "section": "5.3 Ablation Study"}, {"figure_path": "hS1jvV3Dk3/tables/tables_26_1.jpg", "caption": "Table 8: Average test accuracy with standard error (3 runs) for the best prompt found by ZOPO with four different embeddings on 20 instruction induction tasks.", "description": "This table presents a comparison of the performance of the ZOPO algorithm across four different embedding methods (Last Token, OpenAI, SBERT, and Random) when applied to 20 instruction induction tasks.  The goal is to investigate how the choice of embedding impacts the algorithm's ability to find high-performing prompts.  Each row represents a task, and the columns show the average test accuracy and standard error for each embedding method. The final two rows summarize the number of tasks where each embedding method achieved the highest accuracy and the performance profile (p(5)), a metric that assesses the algorithm's overall performance.", "section": "D.6 Verifying the Essence of Input Domain"}, {"figure_path": "hS1jvV3Dk3/tables/tables_26_2.jpg", "caption": "Table 8: Average test accuracy with standard error (3 runs) for the best prompt found by ZOPO with four different embeddings on 20 instruction induction tasks.", "description": "This table presents the average test accuracy achieved by the ZOPO algorithm using four different embedding methods on 20 instruction induction tasks. The embeddings used are: Last Token embedding from Vicuna-13B, OpenAI embedding, SBERT embedding, and Random embedding.  The table shows the average test accuracy and standard error (across 3 runs) for each embedding method on each of the 20 tasks, and also provides the number of times each method achieved the highest accuracy, and the performance profile p(5) which reflects the overall ranking of each method across the 20 tasks.", "section": "5.3 Ablation Study"}, {"figure_path": "hS1jvV3Dk3/tables/tables_27_1.jpg", "caption": "Table 1: Average test accuracy with standard error (3 runs) for different methods on 20 instruction induction tasks. We bold the highest accuracy when comparing ZOPO with baselines, and use green cell to highlight the highest accuracy when comparing ZOPOGPT with baselines.", "description": "This table compares the performance of the proposed ZOPO method against several strong baseline methods on 20 instruction induction tasks.  The average test accuracy and standard error are provided for each method and task.  The best performing method for each task is highlighted.  The table also highlights the highest accuracy achieved by ZOPO and ZOPOGPT (a variant using ChatGPT) compared to the baselines.", "section": "5.1 Instruction Induction"}, {"figure_path": "hS1jvV3Dk3/tables/tables_28_1.jpg", "caption": "Table 1: Average test accuracy with standard error (3 runs) for different methods on 20 instruction induction tasks. We bold the highest accuracy when comparing ZOPO with baselines, and use green cell to highlight the highest accuracy when comparing ZOPOGPT with baselines.", "description": "This table presents the average test accuracy of several prompt optimization methods on 20 instruction induction tasks.  The results are averaged over three runs, with standard errors reported.  The highest accuracy for each task is bolded when comparing ZOPO against the baselines.  Additionally, the highest accuracy when comparing ZOPOGPT against baselines is highlighted in green.  This table allows for a direct comparison of the performance of ZOPO and ZOPOGPT against existing approaches on various instruction induction tasks.", "section": "5.1 Instruction Induction"}, {"figure_path": "hS1jvV3Dk3/tables/tables_28_2.jpg", "caption": "Table 1: Average test accuracy with standard error (3 runs) for different methods on 20 instruction induction tasks. We bold the highest accuracy when comparing ZOPO with baselines, and use green cell to highlight the highest accuracy when comparing ZOPOGPT with baselines.", "description": "This table presents the average test accuracy, along with standard errors, achieved by different prompt optimization methods across 20 instruction induction tasks.  The highest accuracy for each task is highlighted, differentiating between the ZOPO and ZOPOGPT models. ZOPO represents the Localized Zeroth-Order Prompt Optimization model, while ZOPOGPT uses ChatGPT to generate prompts. The table allows comparison of ZOPO's performance against other established methods in the field of prompt optimization.", "section": "5.1 Instruction Induction"}, {"figure_path": "hS1jvV3Dk3/tables/tables_29_1.jpg", "caption": "Table 1: Average test accuracy with standard error (3 runs) for different methods on 20 instruction induction tasks. We bold the highest accuracy when comparing ZOPO with baselines, and use green cell to highlight the highest accuracy when comparing ZOPOGPT with baselines.", "description": "This table presents the average test accuracy achieved by different prompt optimization methods on 20 instruction induction tasks.  The results are shown for several baselines (APE, InstructZero, INSTINCT, EvoPrompt, PB, OPRO) and the proposed methods (ZOPO, ZOPOGPT).  The highest accuracy for each task is highlighted, allowing for a comparison of the relative performance of the different approaches.  ZOPO and ZOPOGPT represent variations of the proposed method, indicating different implementations or modifications applied.", "section": "5 Experiments"}, {"figure_path": "hS1jvV3Dk3/tables/tables_30_1.jpg", "caption": "Table 1: Average test accuracy with standard error (3 runs) for different methods on 20 instruction induction tasks. We bold the highest accuracy when comparing ZOPO with baselines, and use green cell to highlight the highest accuracy when comparing ZOPOGPT with baselines.", "description": "This table presents the average test accuracy achieved by different prompt optimization methods across 20 instruction induction tasks.  The results are averaged across three runs and include standard errors.  The table highlights the best performing method for each task by bolding the highest accuracy when comparing against traditional methods and using a green cell to highlight the best performance for ZOPOGPT (a variant of ZOPO). This allows for a direct comparison of ZOPO and ZOPOGPT against several state-of-the-art methods.", "section": "5.1 Instruction Induction"}]