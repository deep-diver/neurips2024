[{"figure_path": "7arAADUK6D/tables/tables_5_1.jpg", "caption": "Table 1: Main results. The best individual model is highlighted in red, and the best ensemble method is highlighted in green, except for the results of the combined method (i.e., the last row). The top-4 models on each benchmark are underlined. '-' indicates that the method does not apply to the task.", "description": "This table presents the main results of the experiments comparing different ensemble methods (LLM-BLENDER, MINED, DEEPEN-Avg, DEEPEN-Adapt, VOTING, MBR) on six benchmark datasets, categorized into comprehensive examination, reasoning capabilities and knowledge capacities.  It shows the performance of individual models and different ensemble methods. The best performing individual model and the best performing ensemble method are highlighted. The table also demonstrates the effectiveness of combining different ensemble methods, particularly VOTING/MBR with DEEPEN.", "section": "4.2 Main Results"}, {"figure_path": "7arAADUK6D/tables/tables_6_1.jpg", "caption": "Table 1: Main results. The best individual model is highlighted in red, and the best ensemble method is highlighted in green, except for the results of the combined method (i.e., the last row). The top-4 models on each benchmark are underlined. \u2018\u2014\u2019 indicates that the method does not apply to the task.", "description": "This table presents the main experimental results comparing different models and ensemble methods across six benchmark datasets.  The benchmarks are categorized into comprehensive examination, reasoning capabilities, and knowledge capacities.  Results are shown for individual models, top-2 model ensembles, and top-4 model ensembles.  The table highlights the best performing individual model and the best performing ensemble method for each benchmark.  It also shows the performance improvements achieved by different ensemble methods compared to the best individual model.", "section": "4 Experiments"}, {"figure_path": "7arAADUK6D/tables/tables_7_1.jpg", "caption": "Table 4: Ablation study of normalization on the relative representation matrix to the ensembling performance on the development sets. Baseline refers to as the best single model on each benchmark. DEEPEN refers the performance of ensembling top-2 models in the benchmark.", "description": "This table presents the ablation study results on the impact of normalization in the relative representation matrix on the model's performance. It compares the performance of DEEPEN with and without normalization against the baseline (best single model) on the development sets for MMLU and TriviaQA.", "section": "5.2 Analysis on Relative Transformation"}, {"figure_path": "7arAADUK6D/tables/tables_8_1.jpg", "caption": "Table 5: Sensitivity analysis of relative ensemble learning rate (RELR). We report the improvements of ensembling top-2 models over the best individual models.", "description": "This table shows the impact of different relative ensemble learning rates (\u03b7) on the performance of the DEEPEN model.  The improvements are calculated as the difference between the performance of the top-2 model ensemble using DEEPEN and the best performing individual model across two different datasets (MMLU and TriviaQA).  The highlighted values indicate the best-performing RELR for each dataset, showing the model's sensitivity to this hyperparameter.", "section": "5.3 Analysis of Reverse Transformation"}, {"figure_path": "7arAADUK6D/tables/tables_12_1.jpg", "caption": "Table 1: Main results. The best individual model is highlighted in red, and the best ensemble method is highlighted in green, except for the results of the combined method (i.e., the last row). The top-4 models on each benchmark are underlined. \u2018\u2014\u2019 indicates that the method does not apply to the task.", "description": "This table presents the main results of the experiments conducted in the paper. It compares the performance of individual language models and several ensemble methods across six benchmarks. The benchmarks cover different aspects of language understanding, including comprehensive examination, reasoning capabilities, and knowledge capacities.  The table highlights the best-performing individual model and ensemble method for each benchmark, indicating the effectiveness of the proposed DEEPEN framework compared to existing ensemble approaches.", "section": "4 Experiments"}, {"figure_path": "7arAADUK6D/tables/tables_13_1.jpg", "caption": "Table 1: Main results. The best individual model is highlighted in red, and the best ensemble method is highlighted in green, except for the results of the combined method (i.e., the last row). The top-4 models on each benchmark are underlined. \u201c\u2014\u201d indicates that the method does not apply to the task.", "description": "This table presents the main results of the paper, comparing the performance of different models and ensemble methods on six benchmarks.  The benchmarks are categorized into comprehensive examination, reasoning capabilities, and knowledge capacities.  The table shows the performance of individual models and several ensemble techniques, including LLM-BLENDER, MINED, DEEPEN-Avg, and DEEPEN-Adapt,  across all benchmarks.  It highlights the best-performing individual model and ensemble method for each benchmark and indicates where methods were not applicable. The top 4 models for each benchmark are also identified.", "section": "4 Experiments"}, {"figure_path": "7arAADUK6D/tables/tables_14_1.jpg", "caption": "Table 1: Main results. The best individual model is highlighted in red, and the best ensemble method is highlighted in green, except for the results of the combined method (i.e., the last row). The top-4 models on each benchmark are underlined. \u2018\u2014\u2019 indicates that the method does not apply to the task.", "description": "This table presents the main experimental results, comparing the performance of individual LLMs and different ensemble methods (LLM-BLENDER, MINED, DEEPEN-Avg, DEEPEN-Adapt, VOTING, MBR) across six benchmark datasets categorized into comprehensive examination, reasoning capabilities, and knowledge capacities.  The best-performing individual model and ensemble method are highlighted for each benchmark.  The table also shows results for ensembles of two and four models, indicating the impact of ensemble size.", "section": "4.2 Main Results"}, {"figure_path": "7arAADUK6D/tables/tables_14_2.jpg", "caption": "Table 8: Inference Latency of DEEPEN with different search steps T.", "description": "This table shows the inference latency of the DEEPEN model with different numbers of search steps (T) in the inverse transformation process.  The baseline latency is 0.19 seconds, and the latency increases with increasing T, reaching 0.24 seconds at T=10. The relative change in latency is shown as a percentage increase compared to the baseline.", "section": "5.3 Analysis of Reverse Transformation"}, {"figure_path": "7arAADUK6D/tables/tables_15_1.jpg", "caption": "Table 1: Main results. The best individual model is highlighted in red, and the best ensemble method is highlighted in green, except for the results of the combined method (i.e., the last row). The top-4 models on each benchmark are underlined. '-' indicates that the method does not apply to the task.", "description": "This table presents the main results of the experiments comparing different ensemble methods on six benchmark datasets.  It shows the performance of individual models and various ensemble techniques, highlighting the best-performing individual model and ensemble method for each benchmark.  The table categorizes the benchmarks into comprehensive examination, reasoning capabilities, and knowledge capacities.  The results show the improvements achieved by different ensemble methods compared to individual models.", "section": "4.2 Main Results"}]