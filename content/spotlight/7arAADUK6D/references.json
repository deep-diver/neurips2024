{"references": [{"fullname_first_author": "Z. Allen-Zhu", "paper_title": "Towards understanding ensemble, knowledge distillation and self-distillation in deep learning", "publication_date": "2020-12-00", "reason": "This paper provides theoretical foundations for the effectiveness of ensemble learning and knowledge distillation, which are central concepts used in DEEPEN."}, {"fullname_first_author": "Y. Bisk", "paper_title": "PiQA: Reasoning about physical commonsense in natural language", "publication_date": "2020-04-00", "reason": "This paper introduces the PIQA benchmark dataset, which is used to evaluate the reasoning capabilities of DEEPEN."}, {"fullname_first_author": "P. Clark", "paper_title": "Think you have solved question answering? Try ARC, the AI2 reasoning challenge", "publication_date": "2018-00-00", "reason": "This paper introduces the ARC benchmark dataset, which is used to evaluate the reasoning capabilities of DEEPEN."}, {"fullname_first_author": "K. Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-00-00", "reason": "This paper introduces the GSM8K benchmark dataset, which is used to evaluate the mathematical reasoning capabilities of DEEPEN."}, {"fullname_first_author": "D. Hendrycks", "paper_title": "Measuring massive multitask language understanding", "publication_date": "2021-00-00", "reason": "This paper introduces the MMLU benchmark dataset, which is used to evaluate the comprehensive language understanding capabilities of DEEPEN."}]}