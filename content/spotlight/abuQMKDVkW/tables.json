[{"figure_path": "abuQMKDVkW/tables/tables_3_1.jpg", "caption": "Table 1: Image and instance level statistics of SARDet-100K dataset. *: Origin datasets are cropped into 512 x 512 patches. Ins: Instances, Img: Images.", "description": "This table presents a statistical summary of the SARDet-100K dataset, broken down by source dataset.  It shows the number of images and instances (objects) in the training, validation, and testing sets for each source dataset, as well as the overall dataset.  The \"Ins/Img\" column indicates the average number of instances per image. The asterisk (*) indicates that the original datasets were cropped into 512x512 pixel patches.", "section": "3 A New Benchmark Dataset for SAR Object Detection"}, {"figure_path": "abuQMKDVkW/tables/tables_3_2.jpg", "caption": "Table 2: SARDet-100K source datasets information. GF-3: Gaofen-3, S-1: Sentinel-1. Target categories S: ship, A: aircraft, C: car, B: bridge, H: harbour, T: tank.", "description": "This table lists the ten datasets used to create the SARDet-100K dataset, specifying for each dataset the target categories of objects, the resolution, the frequency band used, the polarization, the satellite or platform used for image acquisition and the license.", "section": "3 A New Benchmark Dataset for SAR Object Detection"}, {"figure_path": "abuQMKDVkW/tables/tables_6_1.jpg", "caption": "Table 3: Comparison of different Filter Augmented Inputs using Faster R-CNN and ResNet50 as the detection model.", "description": "This table presents the results of experiments comparing different handcrafted feature descriptors used as Filter Augmented Inputs in a Faster R-CNN object detection model with a ResNet50 backbone.  The table shows mean Average Precision (mAP) and mAP at IoU threshold of 0.5 (mAP50) for each input type: SAR (as RGB), SAR with Canny edge detection, SAR with Histogram of Oriented Gradients (HOG), SAR with Haar-like features, SAR with Wavelet Scattering Transform (WST), SAR with Gradient by Ratio Edge (GRE), and SAR with a combination of HOG, Haar, and WST.  The results indicate the impact of the different handcrafted features on the object detection performance.", "section": "5.1 Filter Augmented Input"}, {"figure_path": "abuQMKDVkW/tables/tables_6_2.jpg", "caption": "Table 4: Pearson Correlation Coefficients (PCC) of ImageNet and SARDet-100k on RGB and handcrafted feature spaces.", "description": "This table presents the Pearson Correlation Coefficients (PCC) between ImageNet and SARDet-100k datasets in different feature spaces: pixel space, Canny space, HOG space, Haar space, WST space, and GRE space.  The PCC values indicate the correlation between the feature distributions of the two datasets. A higher PCC value suggests a stronger correlation and better transferability of knowledge from ImageNet to SARDet-100k during pretraining.", "section": "5 Experiments and Analysis"}, {"figure_path": "abuQMKDVkW/tables/tables_7_1.jpg", "caption": "Table 5: Comparison of different pretrain strategies using Faster-RCNN and ResNet50 as the detection model.", "description": "This table compares different pretraining strategies for a Faster-RCNN object detection model using ResNet50 as the backbone.  It shows the mean Average Precision (mAP) achieved using different combinations of pretraining datasets (ImageNet, DIOR, DOTA) and whether the entire framework or just the backbone was finetuned.  The results highlight the impact of multi-stage pretraining and demonstrate the effectiveness of using the proposed method. ", "section": "5.2 Multi-stage Pretrain"}, {"figure_path": "abuQMKDVkW/tables/tables_8_1.jpg", "caption": "Table 6: Comparison of the proposed MSFA with previous state-of-the-art methods on SSDD and HRSID datasets.", "description": "This table compares the performance of the proposed MSFA method against previous state-of-the-art (SOTA) methods on two benchmark datasets for SAR object detection: SSDD and HRSID.  It shows the mAP50 scores achieved by each method, indicating the improvement offered by MSFA.", "section": "5.4 Comparison with SOTAs"}, {"figure_path": "abuQMKDVkW/tables/tables_18_1.jpg", "caption": "Table 3: Comparison of different Filter Augmented Inputs using Faster R-CNN and ResNet50 as the detection model.", "description": "This table presents the mean Average Precision (mAP) and mAP@50 results for different filter augmented inputs using Faster R-CNN and ResNet-50 as the detection model.  It shows how the addition of various handcrafted feature descriptors (Canny, HOG, Haar, WST, GRE) impacts performance, demonstrating the benefits of incorporating such features as auxiliary information for the detection task. The results highlight the superior performance of the Wavelet Scattering Transform (WST).", "section": "5.1 Filter Augmented Input"}, {"figure_path": "abuQMKDVkW/tables/tables_18_2.jpg", "caption": "Table 5: Comparison of different pretrain strategies using Faster-RCNN and ResNet50 as the detection model.", "description": "This table compares the performance of different pretraining strategies on the SAR object detection task using Faster-RCNN and ResNet50 as the detection models.  It shows the mean Average Precision (mAP) achieved using different combinations of ImageNet and other datasets (DIOR, DOTA) for pretraining the backbone or entire framework, before finetuning on the SARDet-100K dataset.  The results highlight the impact of multi-stage pretraining and the choice of which model components to pretrain on overall performance.", "section": "5 Experiments and Analysis"}, {"figure_path": "abuQMKDVkW/tables/tables_19_1.jpg", "caption": "Table 5: Comparison of different pretrain strategies using Faster-RCNN and ResNet50 as the detection model.", "description": "This table compares different pretraining strategies for object detection using Faster-RCNN and ResNet50. It shows the mean Average Precision (mAP) achieved with different pretraining methods such as ImageNet pretraining only, adding DIOR or DOTA datasets and combinations for pretraining, using the SAR dataset only for pretraining, and using Filter Augmented Input in combination with DIOR or DOTA. This allows for a comparison of the impact of different pretraining strategies on the final detection performance.", "section": "5.2 Multi-stage Pretrain"}, {"figure_path": "abuQMKDVkW/tables/tables_20_1.jpg", "caption": "Table 1: Image and instance level statistics of SARDet-100K dataset. *: Origin datasets are cropped into 512 x 512 patches. Ins: Instances, Img: Images.", "description": "This table presents a statistical summary of the SARDet-100K dataset. It shows the number of images and instances for each of the datasets included, as well as the number of instances per image. The table also notes that the original datasets were cropped into 512x512 patches before inclusion in SARDet-100K. Abbreviations used include \"Ins\" for instances and \"Img\" for images.", "section": "3 A New Benchmark Dataset for SAR Object Detection"}, {"figure_path": "abuQMKDVkW/tables/tables_20_2.jpg", "caption": "Table 5: Comparison of different pretrain strategies using Faster-RCNN and ResNet50 as the detection model.", "description": "This table compares the performance of different pretraining strategies for a Faster-RCNN object detection model using a ResNet50 backbone.  It contrasts using only ImageNet pretraining versus a multi-stage approach that includes pretraining on both ImageNet and additional datasets (DIOR or DOTA), with and without filter augmentation. The results show mAP (mean Average Precision) values for each strategy, highlighting the benefits of the multi-stage pretraining method.", "section": "5.2 Multi-stage Pretrain"}, {"figure_path": "abuQMKDVkW/tables/tables_22_1.jpg", "caption": "Table S12: Hyper-parameter of pretrain and finetune settings. Cls.: Classification, Det.: Detection, B.S.: Batch Size, L.R.: Learning Rate.", "description": "This table details the hyperparameters used for different training stages in the SAR object detection experiments. It shows the optimizer (AdamW), batch size (B.S.), learning rate (L.R.), and number of epochs for classification pretraining (Cls. Pretrain) on ImageNet, detection pretraining (Det. Pretrain) on DOTA and DIOR datasets, and detection finetuning (Det. Finetune) on SARDet-100k, SSDD, and HRSID datasets.  It also includes hyperparameters for DETR, Deformable-DETR, Dab-DETR, and Sparse-RCNN.", "section": "A.6 Implementaion Details"}, {"figure_path": "abuQMKDVkW/tables/tables_22_2.jpg", "caption": "Table S13: ConvNext-B MSFA", "description": "This table presents a detailed breakdown of the performance of the ConvNext-B model with MSFA (Multi-Stage with Filter Augmentation) pretraining.  It shows the mean Average Precision (mAP) and Average Precision (AP) at different Intersection over Union (IoU) thresholds (0.5, 0.75, small, medium, large) for each object category in the SAR object detection task. The categories include ship, aircraft, car, tank, bridge, and harbor.  The results highlight the model's performance variations across different object types and sizes, indicating strengths and weaknesses in the model's ability to accurately detect specific classes within the SAR images.", "section": "A.8 Failure Scenarios"}]