[{"figure_path": "VFpXYBqMSU/tables/tables_7_1.jpg", "caption": "Table 2: ControlNet personalization results of IN-100 using LDMs pre-trained with perturbation. CEP achieves the best results (in bold).", "description": "This table presents the results of personalizing pre-trained diffusion models on the ImageNet-100 dataset using the ControlNet method.  The models were pre-trained with different types of conditional embedding perturbations (CEP), including uniform and Gaussian noise, as well as a baseline with no perturbation (IP). The table shows the FID (Fr\u00e9chet Inception Distance), IS (Inception Score), Precision, and Recall metrics for each model and perturbation type.  Canny edge detection and Segment Anything (SAM) segmentation masks were used as spatial controls.  The results demonstrate that models pre-trained with CEP generally achieve better personalization performance than those pre-trained without perturbations, suggesting that introducing controlled noise during pre-training can enhance the quality and diversity of generated images.", "section": "Downstream Personalization Evaluation"}, {"figure_path": "VFpXYBqMSU/tables/tables_33_1.jpg", "caption": "Table 3: Hyper-parameters of IN-1K class-conditional and CC3M text-conditional LDMs.", "description": "This table lists the hyperparameters used for training both IN-1K class-conditional and CC3M text-conditional Latent Diffusion Models (LDMs).  It details settings such as downsampling factor, latent space shape, vocabulary size, number of diffusion steps, noise schedule, U-Net parameter size, condition network type, number of channels, channel multiplier, number of attention heads, batch size, number of training iterations, and the learning rate.  These hyperparameters were crucial in controlling the training process and ultimately the performance of the generated images.", "section": "3.1 Pre-training Evaluation"}, {"figure_path": "VFpXYBqMSU/tables/tables_34_1.jpg", "caption": "Table 4: Hyper-parameters of IN-1K class-conditional DiT-XL/2.", "description": "This table lists the hyperparameters used for training the DiT-XL/2 model on the ImageNet-1K dataset.  It includes details such as the down-sampling factor used for the VQ-VAE, the dimensions of the latent space, the vocabulary size, the number of parameters in the model, the number of training iterations, the batch size used during training, and the learning rate.", "section": "B.4 DiT Pre-training Setup"}, {"figure_path": "VFpXYBqMSU/tables/tables_39_1.jpg", "caption": "Table 5: FID and IS along training of LDM IN-1K with guidance scale 2.5.", "description": "This table presents the FID and IS scores of a Latent Diffusion Model (LDM) trained on ImageNet-1K (IN-1K) at various training iterations (10K, 25K, 50K, 75K, 100K, 125K, 150K).  The results are shown for two conditions: a clean dataset (\u03b7=0) and a dataset with a 2.5% corruption ratio (\u03b7=2.5).  The guidance scale is fixed at 2.5.  This data illustrates the performance of the LDM over training iterations in terms of both fidelity (FID) and diversity (IS) in the presence and absence of data corruption.", "section": "5.2 Experiments"}, {"figure_path": "VFpXYBqMSU/tables/tables_40_1.jpg", "caption": "Table 6: Comparison of CEP with dropout and label smoothing on LDM IN-1K.", "description": "This table presents a comparison of the performance of Latent Diffusion Models (LDMs) trained on ImageNet-1K (IN-1K) using different methods: clean training, adding dropout, applying label smoothing, and using Conditional Embedding Perturbation (CEP) with uniform and Gaussian noise.  The metrics used for comparison are FID (Fr\u00e9chet Inception Distance), a measure of image quality, and IS (Inception Score), a measure of image quality and diversity.  The results demonstrate the effectiveness of CEP in enhancing the quality and diversity of generated images compared to other regularization methods.", "section": "5.2 Experiments"}, {"figure_path": "VFpXYBqMSU/tables/tables_40_2.jpg", "caption": "Table 7: Comparison of fixed and random corruption on LDM IN-1K.", "description": "This table presents the FID and IS scores for ImageNet-1K LDM-4 models trained with different corruption methods: clean, CEP-U (conditional embedding perturbation with uniform distribution), fixed CEP-U (fixed locations for adding uniform noise), random data corruption (randomly corrupting the data), and fixed data corruption (fixed locations for data corruption).  The results show that CEP-U achieves the best performance, highlighting its effectiveness in improving the quality and diversity of generated images.", "section": "E.4 Comparison with Fixed and Random Corruption"}]