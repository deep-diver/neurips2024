[{"type": "text", "text": "Online Convex Optimisation: The Optimal Switching Regret for all Segmentations Simultaneously ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Stephen Pasteris Chris Hicks Vasilios Mavroudis The Alan Turing Institute The Alan Turing Institute The Alan Turing Institute London UK London UK London UK spasteris@turing.ac.uk c.hicks@turing.ac.uk vmavroudis@turing.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Mark Herbster University College London London UK m.herbster@cs.ucl.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We consider the classic problem of online convex optimisation. Whereas the notion of static regret is relevant for stationary problems, the notion of switching regret is more appropriate for non-stationary problems. A switching regret is defined relative to any segmentation of the trial sequence, and is equal to the sum of the static regrets of each segment. In this paper we show that, perhaps surprisingly, we can achieve the asymptotically optimal switching regret on every possible segmentation simultaneously. Our algorithm for doing so is very efficient: having a space and per-trial time complexity that is logarithmic in the time-horizon. Our algorithm also obtains novel bounds on its dynamic regret: being adaptive to variations in the rate of change of the comparator sequence. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We consider the classic problem of online convex optimisation: a problem with numerous real-world applications. In this problem we have an action set which is a bounded convex subset of some euclidean space. On each trial we select an action from this set and then receive a convex function of bounded gradient, which associates the action with a loss. The aim is to minimise the cumulative loss. The static regret is defined as the cumulative loss of the algorithm minus that of the best constant action in retrospect. It has been shown that the minimax static regret is $\\Theta({\\sqrt{T}})$ where $T$ is the time horizon, and that it is achieved by the classic mirror descent family of algorithms [2]. However, in dynamic environments a more sensible notion of regret is the switching regret, which is defined relative to any segmentation of the trial sequence and is equal to the sum of the static regrets over all segm\u221aents. Clearly, if the segmentation is known a-priori then the minimax switching regret is $\\Theta({\\sum}_{k}^{-}\\,\\sqrt{\\Lambda_{k}})$ where $\\Lambda_{k}$ is the length of the $k$ -th segment, and it is obtained by running mirror descent independently on each segment. Tracking algorithms, instead, attempt to bound the switching regret on every possible segmentation of the trial sequence simultaneously. However, as far as we are aware, the best such bound until now was $\\begin{array}{r}{\\mathcal{O}(\\sum_{k}\\sqrt{\\Lambda_{k}\\ln(T)})}\\end{array}$ which is a factor of $O(\\sqrt{\\ln(T)})$ higher than the optimal if we knew the segmentation a-priori. In this paper we (quite remarka\u221ably) get rid of this factor: hence obtaining the asymptotically optimal switching regret of $O(\\sum_{k}\\sqrt{\\Lambda_{k}})$ for every possible segmentation simultaneously. Not only is our algorithm optimal, but it is also parameter-free and efficient: having both a space and per-trial time complexity of ${\\mathcal{O}}(\\ln(T))$ . ", "page_idx": 0}, {"type": "text", "text": "In fact, our algorithm RESET is a meta-algorithm which utilises any base algorithm for the online convex optimisation p\u221aroblem at hand. Using online gradient descent [9] as our base algorithm gives us the above $\\mathcal{O}(\\sum_{k}\\sqrt{\\Lambda_{k}})$ switching regret bound. However, the constant under the $\\scriptscriptstyle\\mathcal{O}$ is dependent on the action set and the possible gradients. By choosing a more appropriate base algorithm that is tailored to the specific problem we can achieve lower constant factors. In particular, when faced with the classic problem of prediction with expert advice with $N$ experts, using Hedge [4] as our base algorithm yields the asymptotically optimal $\\begin{array}{r}{\\mathcal{O}(\\ln(N)\\sum_{k}\\sqrt{\\Lambda_{k}})}\\end{array}$ switching regret (a novel result in itself). ", "page_idx": 1}, {"type": "text", "text": "We note that although, like strongly adaptive algorithms [3], we are adaptive to heterogeneous segment lengths, we are not necessarily strongly adaptive: in that we do not bound the static regret on any particular segment. ", "page_idx": 1}, {"type": "text", "text": "Whilst switching regret models discrete changes in the environment, a continuously changing environment is better modeled by the notion of dynamic regret, which is the difference between the loss of the algorithm and that of any comparator sequence of actions. It is known that algorithms exist which bound the dynamic regret by $\\bar{\\mathcal{O}}(\\sqrt{(1+P)T})$ where $P$ is the path length of the comparator sequence. However, this bound is not adaptive to variations in the rate that the comparator sequence is changing. RESET, with online gradient descent as the base algorithm, rectifies this: improving the dynamic regret to $\\mathcal{O}(\\sum_{k}\\sqrt{(1+P_{k})\\Lambda_{k}})$ for any seg\u221amentation in which the path length in the $k$ -th segment is $P_{k}$ . We note that this implies the ${\\mathcal{O}}(\\sum_{k}{\\sqrt{\\Lambda_{k}}})$ bound on switching regret. However, since we are forced to use online gradient descent as our base algorithm here, this result is not strictly more general than our switching regret result. ", "page_idx": 1}, {"type": "text", "text": "Related works: Mirror descent was introduced in [2] to find minimisers of convex functions in convex sets. The same algorithm, however, can also be applied to online convex optimisation: the Hedge algorithm of [4] implementing a special case when the co\u221anvex set is a simplex and the convex functions are linear (the so-called experts problem). The $\\mathcal{O}(\\sqrt{T})$ static regret of Mirror descent was shown to be optimal in [1]. The work [5] studied the non-stationary case in the experts setting: modifying Hedge to give an algorithm Fixed share which takes a parameter $\\Phi$ and has a switching regret of $\\mathcal{O}(\\sqrt{\\Phi T\\ln(T/\\Phi)})$ for any segmentation with $\\Phi$ segments. One issue with Fixed share, however, is that it does not adapt to heterogeneous segment lengths. In ord\u221aer to remedy this, [3] gave a strongly adaptive algorithm which achieved a static regret of $\\mathcal{O}(\\ln(T)\\sqrt{\\Lambda})$ on any segment of length $\\Lambda$ . This was improved to $O(\\sqrt{\\ln(T)\\Lambda})$ in [6]. The work [7] took parameters $a,b\\in\\mathbb{N}$ and achieved a static regret of $\\mathcal{O}(\\sqrt{(1+\\ln(b/a))\\Lambda})$ for any segment of length $\\Lambda\\in[a,b]$ . However, this still leads to a switching regr\u221aet of $\\begin{array}{r}{\\mathcal{O}(\\sum_{k}\\sqrt{\\Lambda_{k}\\ln(T)})}\\end{array}$ for general segmentations. Our work finally achieves the op\u221atimal ${\\mathcal{O}}(\\sum_{k}{\\sqrt{\\Lambda_{k}}})$ . The work [9]\u221a showed that gradient descent achieves a dynamic regret of ${\\mathcal{O}}(P{\\sqrt{T}})$ , which was improved to $\\mathcal{O}(\\sqrt{P T})$ in [8]. Our work dramatically improves on this bound by being adaptive to variations in the rate of change of the comparator sequence. ", "page_idx": 1}, {"type": "text", "text": "Notation: Let $\\mathbb{N}$ be the set of natural numbers excluding 0. Given $A\\in\\mathbb{N}$ we define $[A]:=\\{a\\in$ $\\mathbb{N}\\mid a\\leq A\\}$ , we define $\\begin{array}{r}{\\Delta_{A}:=\\{\\pmb{a}\\in[0,1]^{A}\\,|\\,\\sum_{i\\in[A]}a_{i}\\,\\,\\overline{{=}}\\,1\\}}\\end{array}$ , and we define $A\\mathbb{N}$ to be the set of natural numbers that are multiples of $A$ . Given a predicate $P$ we define $\\[P]:=0$ if $P$ is false and define $[\\![P]\\!]:=1$ if $P$ is true. ", "page_idx": 1}, {"type": "text", "text": "2 Problem and Results ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In this section we introduce the online convex optimisation problem and state the results of this paper. In particular we define and compare the notions of switching and dynamic regret, giving the bounds obtained by our algorithm RESET. Another common notion of regret, not necessarily bounded by RESET, is strongly adaptive regret which we discuss in Section 3.3. ", "page_idx": 1}, {"type": "text", "text": "2.1 Online Convex Optimisation ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Here we describe the classic problem of online convex optimisation, which our algorithm RESET solves. In this problem we have known bounded convex subsets $\\chi,\\mathcal{G}$ of some euclidean space. We define $\\mathcal{L}$ to be the set of all convex functions that map $\\mathcal{X}$ into $\\mathbb{R}$ and whose sub-gradients lie in $\\mathcal{G}$ . The problem proceeds in $T$ trials. On each trial $t\\in[T]$ the following happens: ", "page_idx": 1}, {"type": "text", "text": "1. We choose some action $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}$ . ", "page_idx": 2}, {"type": "text", "text": "2. We receive some loss function $\\ell_{t}\\in\\mathcal{L}$ . ", "page_idx": 2}, {"type": "text", "text": "Our aim is to minimise the cumulative loss: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\sum_{t\\in[T]}\\ell_{t}(\\mathbf{x}_{t})\\,.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Without loss of generality we shall assume that for all $t\\in[T]$ and all $\\pmb{x}\\in\\mathcal{X}$ we have $\\ell_{t}(\\pmb{x})\\in[0,1]$ . This is without loss of generality as both $\\mathcal{X}$ and the sub-gradients of $\\ell_{t}$ are bounded and our algorithm RESET, when using mirror descent as the base algorithm, is invariant to any constant addition to any loss function. Also, without loss of generality, assume that $T$ is an integer power of two. ", "page_idx": 2}, {"type": "text", "text": "An example of online convex optimisation is prediction with expert advice. Here we have some $N\\in\\mathbb{N}$ and a set of $N$ experts: where on each trial each expert is associated with a loss in $[0,1]$ . On each trial we must select an expert (incurring the loss associated with that expert) and then observe the vector of losses for that trial. For this problem we choose $\\mathcal{X}:=\\Delta_{N}$ and $\\stackrel{\\r}{\\mathcal{G}}:=[0,1]^{N}$ . On each trial $t$ we draw our expert from the probability vector $\\pmb{x}_{t}$ and define the loss function $\\ell_{t}$ to be the linear function such that for all $i\\in[N]$ we have that $\\ell_{t}(e_{i})$ (that is, the loss of the $i$ -th basis element of $\\mathbb{R}^{N}$ ) is the loss associated with expert $i$ on trial $t$ . Note that $\\ell_{t}(\\pmb{x}_{t})$ is our expected loss on trial $t$ . ", "page_idx": 2}, {"type": "text", "text": "2.2 Switching Regret ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We now define the notion of switching regret. Given any pair of trials $q,s\\in[T]$ with $q\\leq s$ we define the static regret on the segment of trials $[q,s]$ by: ", "page_idx": 2}, {"type": "equation", "text": "$$\nR(q,s):=\\operatorname*{max}_{{\\pmb x}^{*}\\in\\mathcal{X}}\\sum_{t=q}^{s}(\\ell_{t}(\\pmb x_{t})-\\ell_{t}(\\pmb x^{*}))\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "which is the total loss incurred on the segment minus that which would have been obtained by always choosing the best constant action in retrospect. A segmentation $\\boldsymbol{S}$ is defined as any sequence of the form: ", "page_idx": 2}, {"type": "equation", "text": "$$\nS=\\left\\langle\\sigma_{k}\\,|\\,k\\in[\\Phi+1]\\right\\rangle\\subseteq[T+1]\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\sigma_{1}=1\\quad;\\quad\\forall k\\in[\\Phi]\\,,\\,\\sigma_{k+1}>\\sigma_{k}\\quad;\\quad\\sigma_{\\Phi+1}=T+1\\,.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Given such a segmentation $\\boldsymbol{S}$ , we define, for all $k\\ \\in\\ [\\Phi]$ , the $k$ -th segment of $\\boldsymbol{S}$ to be the set $[\\sigma_{k},\\sigma_{k+1}-1]$ , noting that the segments partition the set of trials $[T]$ . The switching regret with respect to such a segmentation $\\boldsymbol{S}$ is defined as: ", "page_idx": 2}, {"type": "equation", "text": "$$\nR^{\\dagger}({\\cal S}):=\\sum_{k\\in[\\Phi]}R(\\sigma_{k},\\sigma_{k+1}-1)\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "which is the sum of the static regrets on each segment of $\\boldsymbol{S}$ . Note that $R^{\\dagger}(S)$ is the total loss of the algorithm minus that which would have been obtained by the best sequence of actions which is constant over each segment of $\\boldsymbol{S}$ . The following theorem establishes a lower bound on the switching regret with respect to any fixed segmentation, even in the special case in which all the loss functions are linear: ", "page_idx": 2}, {"type": "text", "text": "Theorem 2.1. For any segmentation: ", "page_idx": 2}, {"type": "equation", "text": "$$\nS=\\langle\\sigma_{k}\\,|\\,k\\in[\\Phi+1]\\rangle\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "and any algorithm for the online convex optimisation problem, there exists (except in trivial cases) a sequence: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\langle\\ell_{t}\\,|\\,t\\in[T]\\rangle\\subseteq\\mathcal{L}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "of linear functions, in which: ", "page_idx": 2}, {"type": "equation", "text": "$$\nR^{\\dagger}({\\cal S})\\in\\Omega\\left(\\sum_{k\\in[\\Phi]}\\sqrt{\\sigma_{k+1}-\\sigma_{k}}\\right)\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where the constant under the $\\Omega$ is dependent only on $\\mathcal{X}$ and $\\mathcal{G}$ . ", "page_idx": 2}, {"type": "text", "text": "In this paper we develop an algorithm RESET which has an upper-bound that matches this lower bound for every possible segmentation $\\boldsymbol{S}$ simultaneously. RESET utilises any algorithm (called the base algorithm) for the online convex optimisation pr\u221aoblem at hand. The base algorithm must take a parameter $\\Lambda\\in[T]$ and guarantee that $R(1,\\Lambda)\\in\\mathcal{O}(\\sqrt{\\Lambda})$ if it were used directly. We note that online gradient descent [9] is always one such possibility. Computationally, to use online gradient descent, we must be able to compute subgradients of the loss functions and euclidean projections into the set $\\mathcal{X}$ . ", "page_idx": 3}, {"type": "text", "text": "Theorem 2.2. Suppose $\\gamma\\in\\mathbb{R}$ is such that for all $\\Lambda\\in[T]$ , when the base algorithm is run with parameter $\\Lambda$ , it is guaranteed that: ", "page_idx": 3}, {"type": "equation", "text": "$$\nR(1,\\Lambda)\\leq\\gamma\\sqrt{\\Lambda}\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Then for any segmentation: ", "page_idx": 3}, {"type": "equation", "text": "$$\nS=\\langle\\sigma_{k}\\,|\\,k\\in[\\Phi+1]\\rangle\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "RESET achieves a switching regret of: ", "page_idx": 3}, {"type": "equation", "text": "$$\nR^{\\dagger}({\\mathcal{S}})\\leq(c\\gamma+d)\\sum_{k\\in[\\Phi]}\\sqrt{\\sigma_{k+1}-\\sigma_{k}}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where: ", "page_idx": 3}, {"type": "equation", "text": "$$\nc:=\\sqrt{2}/(\\sqrt{2}-1)\\quad;\\quad d:=\\sqrt{8\\ln(2)}/(3-2\\sqrt{2})\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Proof. See Section 4. ", "page_idx": 3}, {"type": "text", "text": "Clearly, theorems 2.1 and 2.2 show that, for any fixed pair $(\\mathcal{X},\\mathcal{G})$ , RESET has the asymptotically optimal switching regret for every segmentation simultaneously. However, our result is stronger in that if, for some family of pairs $(\\mathcal{X},\\mathcal{G})$ , the base algorithm has asymptotically optimal static regret (for the entire family) then RESET has the asymptotically optimal switching regret for the entire family at once. An example is prediction with expert advice (described above) where utilising HEDGE [4] as the base algorithm gives us $\\gamma\\in{\\mathcal{O}}(\\ln(N))$ which is asymptotically optimal (as proved in [1]). ", "page_idx": 3}, {"type": "text", "text": "RESET is also very efficient, as shown in the following theorem. ", "page_idx": 3}, {"type": "text", "text": "Theorem 2.3. Given that the base algorithm runs in a time of $\\xi$ per trial and requires a space of $\\xi^{\\prime}$ , RESET has a per-trial time complexity of $O(\\xi\\ln(T))$ and space complexity of $\\bar{\\mathcal{O}}(\\xi^{\\prime}\\ln(T\\bar{)})$ ", "page_idx": 3}, {"type": "text", "text": "Proof. Immediate from the RESET algorithm. ", "page_idx": 3}, {"type": "text", "text": "2.3 Dynamic Regret ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Switching regret measures the performance of the algorithm against the best comparator sequence of actions that is constant in each segment. Dynamic regret, on the other hand, measures the performance of the algorithm against any comparator sequence. Specifically, given any sequence of actions: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{E}=\\langle\\epsilon_{t}\\:|\\:t\\in[T]\\rangle\\subseteq\\mathcal{X}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "then the dynamic regret with respect to $\\mathcal{E}$ is defined as: ", "page_idx": 3}, {"type": "equation", "text": "$$\nR^{*}(\\mathcal{E}):=\\sum_{\\boldsymbol{t}\\in[T]}\\left(\\ell_{t}(\\mathbf{x}_{t})-\\ell_{t}(\\mathbf{\\epsilon}_{t})\\right).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "To bound the dynamic regret of RESET we introduce the following notion of path length. Specifically, given the above sequence $\\mathcal{E}$ and trials $q,s\\in[T]$ with $q\\leq s$ , the path length of $\\mathcal{E}$ in the segment $[q,s]$ is defined as: ", "page_idx": 3}, {"type": "equation", "text": "$$\nP(\\mathcal{E},q,s)=\\sum_{t=q}^{s-1}\\|\\pmb{\\epsilon}_{t+1}-\\pmb{\\epsilon}_{t}\\|_{2}\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The current state of the art for dynamic regret is the algorithm ADER [8] which achieves a dynamic regret of: ", "page_idx": 3}, {"type": "equation", "text": "$$\nR^{*}({\\mathcal{E}})\\in{\\mathcal{O}}\\left(\\sqrt{(1+P({\\mathcal{E}},1,T))T}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In this paper we significantly improve on this result, as shown in the following theorem. ", "page_idx": 3}, {"type": "text", "text": "Theorem 2.4. When using online gradient descent $I^{g}J$ as the base algorithm, RESET achieves, for any comparator sequence $\\mathcal{E}$ and any segmentation: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\langle\\sigma_{k}\\mid k\\in[\\Phi+1]\\rangle\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "a dynamic regret of: ", "page_idx": 4}, {"type": "equation", "text": "$$\nR^{*}(\\mathcal{E})\\in\\mathcal{O}\\left(\\sum_{k\\in[\\Phi]}\\sqrt{(1+P(\\mathcal{E},\\sigma_{k},\\sigma_{k+1}))(\\sigma_{k+1}-\\sigma_{k})}\\right)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where the constant under the $\\scriptscriptstyle\\mathcal{O}$ is dependent only on $\\mathcal{X}$ and $\\mathcal{G}$ . ", "page_idx": 4}, {"type": "text", "text": "Proof. See Section 4 ", "page_idx": 4}, {"type": "text", "text": "Note that, for any segmentation, the dynamic regret bound of RESET is asymptotically equal to that of running ADER on each segment independently. To achieve this with ADER one would need to know the specific segmentation a-priori. As for the switching regret, RESET achieves this for every segmentation simultaneously. We note that our bound is a significant improvement on that of ADER since it is adaptive to variation in the rate of change of the comparator sequence. ", "page_idx": 4}, {"type": "text", "text": "We note that, given a segmentation $S\\,=\\,\\langle\\sigma_{k}\\,|\\,k\\,\\in\\,[\\Phi\\,+\\,1]\\rangle$ , the switching regret $R^{\\dagger}({\\mathcal{S}})$ is equal to the maximum dynamic regret $R^{*}({\\mathcal{E}})$ across all sequences $\\mathcal{E}$ that are constant in each segment. For all $k\\in[\\Phi]$ , the fact that such an $\\mathcal{E}$ is constant on $[\\sigma_{k},\\sigma_{k+1}-1]$ implies that the path length $P(\\mathcal{E},\\sigma_{k},\\sigma_{k+1})$ is in $O(1)$ . This means that Theorem 2.4 implies the switching regret bound of Theorem 2.2 up to a constant factor (dependent on $\\gamma,\\chi$ and $\\mathcal{G}$ ). However, to obtain Theorem 2.4 we must use online gradient descent as our base algorithm. For some families of pairs $(\\mathcal{X},\\mathcal{G})$ online gradient descent is not asymptotically optimal for the entire family at once. An example is prediction with expert advice, where Theorem 2.2 shows that we are asymptotically optimal for the entire family at once when using HEDGE as the base algorithm. Hence, when concerned only with switching regret, Theorem 2.2 is a stronger result. ", "page_idx": 4}, {"type": "text", "text": "3 The Algorithm ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section we describe our algorithm RESET (Recursion over Segment Tree). We first introduce the notation that we will use to describe the base algorithm. ", "page_idx": 4}, {"type": "text", "text": "3.1 The Base Algorithm ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We now define the notation that we use to describe our base algorithm. The base algorithm utilises a data-structure $\\mathcal{D}$ (which contains the parameter) and is composed of the following three subrountines: ", "page_idx": 4}, {"type": "text", "text": "\u2022 Given $\\Lambda\\in[T]$ , the subroutine INITIALISE $(\\Lambda)$ returns the initial data-structure with parameter $\\Lambda$ .   \n\u2022 At the start of a trial, given the current data-structure $\\mathcal{D}$ , the subroutine $\\operatorname{QUERY}\\!\\left({\\mathcal{D}}\\right)$ returns the output action of the base algorithm for that trial.   \n\u2022 At the end of a trial $t$ , given the current data-structure $\\mathcal{D}$ and the loss function $\\ell_{t}$ , the subroutine UPDATE $(\\mathcal D,\\ell_{t})$ returns the updated data-structure (ready for the next trial). ", "page_idx": 4}, {"type": "text", "text": "The assumption in Theorem 2.2 implies the following. Suppose we have trials $q,s\\in[T]$ with $s\\geq q$ , and on each trial $t\\in[s,q]$ we do the following: ", "page_idx": 4}, {"type": "text", "text": "Then we have: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\pmb{x}^{\\ast}\\in\\mathcal{X}}\\sum_{t=q}^{s}(\\ell_{t}(\\pmb{w}_{t})-\\ell_{t}(\\pmb{x}^{\\ast}))\\leq\\gamma\\sqrt{q-s+1}\\,.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "3.2 RESET ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We now introduce our algorithm RESET. First let $\\tau:=\\log_{2}(T)$ and define the function $\\psi:\\mathbb{R}\\times\\mathbb{R}\\times\\mathbb{R}\\times\\mathbb{N}\\to\\mathbb{R}$ by: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\psi(\\rho,a,b,\\Lambda):=\\frac{\\rho\\exp(-a\\sqrt{2\\ln(2)/\\Lambda})}{\\rho\\exp(-a\\sqrt{2\\ln(2)/\\Lambda})+(1-\\rho)\\exp(-b\\sqrt{2\\ln(2)/\\Lambda})}\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The pseudocode of RESET is given in Algorithm 1. ", "page_idx": 5}, {"type": "table", "img_path": "u6XxyuD3Ro/tmp/ac354dbedb447b79bf2d4a2473d66998681baf42fec1a5209496cc14f0c923e2.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "We now describe RESET. We have a set of $\\tau+1$ levels, where each level $i\\in[\\tau]\\cup\\{0\\}$ hosts an instance of the base algorithm, with parameter $2^{i}$ . On each trial $t$ , we denote the data-structure of the base algorithm associated with level $i$ by $\\mathcal{D}_{t}^{i}$ . Each level also has an associated number in $[0,1]$ called the mixing weight. On each trial $t$ , we denote the mixing weight associated with level $i$ by $\\mu_{t}^{i}$ . We note that the mixing weight $\\mu_{t}^{0}$ is not necessary. ", "page_idx": 5}, {"type": "text", "text": "We now describe the creation of the action $\\pmb{x}_{t}$ on trial $t$ . Note first that each level $i\\in[\\tau]\\cup\\{0\\}$ has an associated action $\\pmb{w}_{t}^{i}$ which is defined as the output of QUERY $(\\mathcal{D}_{t}^{i})$ , so is the action selected by the base algorithm for level $i$ on trial $t$ . We call these actions the base actions. The action $\\pmb{x}_{t}$ is created by the following recursive process. For each level $i$ in order we construct an action $\\boldsymbol{z}_{t}^{i}$ called the propagating action. This action is constructed by a convex combination of the preceding propagating action zit $z_{t}^{i-1}$ and the base action $\\pmb{w}_{t}^{i}$ . Specifically, we start by setting: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\pmb{z}_{t}^{0}\\gets\\pmb{w}_{t}^{0}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "and then, for all levels $i\\in[\\tau]$ , once $z_{t}^{i-1}$ has been constructed we set: ", "page_idx": 5}, {"type": "equation", "text": "$$\nz_{t}^{i}\\leftarrow\\mu_{t}^{i}w_{t}^{i}+(1-\\mu_{t}^{i})z_{t}^{i-1}\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Finally, we output: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\pmb{x}_{t}\\gets z_{t}^{\\tau}\\;.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We now turn to the update at the end of trial $t$ . For all levels $i\\in[\\tau]\\cup\\{0\\}$ we have the following two cases. ", "page_idx": 5}, {"type": "text", "text": "If $t\\in2^{i}\\mathbb{N}$ then we set: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mu_{t+1}^{i}\\leftarrow1/2\\quad;\\quad\\mathcal{D}_{t+1}^{i}\\leftarrow\\mathrm{INITIALISE}\\big(\\,2^{i}\\,\\big)\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "so that the mixing weight and instance of the base algorithm hosted by level $i$ are reset. Note that the parameter of the base algorithm is $2^{i}$ . This is since it is reset every $2^{i}$ trials. ", "page_idx": 6}, {"type": "text", "text": "On the other hand, if $t\\notin2^{i}\\mathbb{N}$ then we set: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\boldsymbol{\\mu}_{t+1}^{i}\\leftarrow\\boldsymbol{\\psi}(\\boldsymbol{\\mu}_{t}^{i}\\,,\\,\\ell_{t}(\\boldsymbol{w}_{t}^{i})\\,,\\,\\ell_{t}(z_{t}^{i-1})\\,,\\,2^{i}\\,)\\quad;\\quad\\mathcal{D}_{t+1}^{i}\\leftarrow\\boldsymbol{\\mathrm{UPDATE}}(\\mathcal{D}_{t}^{i}\\,,\\,\\ell_{t}\\,)\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Note that the update of the mixing weight is based on the losses of $\\pmb{w}_{t}^{i}$ and $z_{t}^{i-1}$ . If $z_{t}^{i-1}$ has a higher loss than $\\pmb{w}_{t}^{i}$ , in that the base action performs better than the lower-level propagating action, then the mixing weight increases. This means that the weight of the base action, in the convex combination forming the propagating action of level $i$ , increases. If $\\pmb{w}_{t}^{i}$ has a higher loss than $z_{t}^{i-1}$ then the opposite happens. ", "page_idx": 6}, {"type": "text", "text": "Figure 1 illustrates RESET. ", "page_idx": 6}, {"type": "image", "img_path": "u6XxyuD3Ro/tmp/720bfb842be7f805954024a52af35313bf2465a186d3dac0349eced00749505c.jpg", "img_caption": [], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Figure 1: The RESET algorithm with 8 trials. ", "page_idx": 6}, {"type": "text", "text": "Left: The generation of the base actions and mixing weights. Purple numbers denote levels and black numbers denote trials. Each segment (rectangle) in the figure runs an instance of the base algorithm (generating the base actions). The mixing weights for each segment in the figure reset at the start of each segment. Mixing weight updates are dependent on the segment length. ", "page_idx": 6}, {"type": "text", "text": "Right: The computation of the action $\\pmb{x}_{t}$ on trial $t$ . Purple numbers denote levels. Blue balls denote base actions, red balls denote mixing weights, and black balls denote propagating actions. The final black arrow is the output $\\pmb{x}_{t}$ . ", "page_idx": 6}, {"type": "text", "text": "3.3 Comparison to Strongly Adaptive Online Learner ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "RESET has some similarities to the SAOL algorithm of [3]. Unlike RESET, SAOL is strongly adaptive, in that it bounds the static regret on any segment. Specifically, for any pair of trials $q,s\\in[T]$ with $q\\leq s$ , SAOL achieves: ", "page_idx": 6}, {"type": "equation", "text": "$$\nR(q,s)\\in{\\mathcal{O}}\\left(\\ln(T){\\sqrt{q-s+1}}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "This, however, leads to a switching regret bound that is a factor $\\mathcal{O}(\\ln(T))$ off the optimal. This additional factor was improved to $O(\\sqrt{\\ln(T)})$ by [6]. ", "page_idx": 6}, {"type": "text", "text": "Like RESET, SAOL has $\\tau$ levels and utilises a base algorithm which constructs, for every trial $t$ and level $i$ , a base action $\\pmb{w}_{t}^{i}$ in exactly the same way as RESET. It then generates, for each trial $t$ , the final action $\\pmb{x}_{t}$ as a convex combination of the base actions. We note that in RESET, the action $\\pmb{x}_{t}$ is also a convex combination of the base actions, where for each level $i\\in[\\tau]$ , the coefficient of $\\pmb{w}_{t}^{i}$ is equal to: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mu_{t}^{i}\\prod_{j=i+1}^{\\tau}(1-\\mu_{t}^{j})\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The crucial difference between SAOL and RESET is that, whilst SAOL updates each coefficient in the convex combination directly, the coefficients in RESET are updated by updating each mixing weight directly. It is due to this, and the particular way that the mixing weights are updated, that RESET attains, unlike SAOL, the optimal switching regret. ", "page_idx": 6}, {"type": "text", "text": "4 Analysis ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Here we prove Theorem 2.2. We show how to modify this proof in order to prove Theorem 2.4 at the end of this section. All lemmas stated in this section are proved in Appendix A. ", "page_idx": 6}, {"type": "text", "text": "Choose any segmentation $S=\\langle\\sigma_{k}\\mid k\\in[\\Phi\\!+\\!1]\\rangle$ . We first define a comparator sequence $\\langle\\epsilon_{t}\\mid t\\in[T]\\rangle$ as follows. For all $k\\in[\\Phi]$ define the action: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\widetilde{\\pmb{\\epsilon}}_{k}:=\\mathrm{argmin}_{\\pmb{x}^{*}\\in\\mathcal{X}}\\sum_{t=\\sigma_{k}}^{\\sigma_{k+1}-1}\\ell_{t}(\\pmb{x}^{*})\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "and then, for all $t\\in[\\sigma_{k},\\sigma_{k+1}-1]$ , define $\\epsilon_{t}:=\\tilde{\\epsilon}_{k}$ . Note that: ", "page_idx": 7}, {"type": "equation", "text": "$$\nR^{\\dagger}(S)=\\sum_{t\\in[T]}\\left(\\ell_{t}(\\pmb{x}_{t})-\\ell_{t}(\\pmb{\\epsilon}_{t})\\right).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "In addition let $\\alpha:=2\\sqrt{\\ln(2)}/(\\sqrt{2}-1)$ . With these definitions in hand we now begin the analysis. ", "page_idx": 7}, {"type": "text", "text": "4.1 Hedge ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The updates for our mixing weights follow the classic algorithm HEDGE [4]. In particular, for each level $\\bar{i}\\in[\\tau]$ we maintain an instance of HEDGE (which restarts every $2^{i}$ trials) with two experts. On each trial $t$ , the weight of the first expert is $\\mu_{t}^{i}$ and the weight of the second is $\\mathrm{1}-\\mu_{t}^{i}$ . The loss of the first expert is $\\ell_{t}(\\pmb{w}_{t}^{i})$ and the loss of the second is $\\ell_{t}(z_{t}^{i-1})$ . The action of the function $\\psi$ is then to update the weights according to the HEDGE algorithm. The following lemma is a classic result about HEDGE. ", "page_idx": 7}, {"type": "text", "text": "Lemma 4.1. Given trials $q,s\\in[T]$ with $q\\leq s$ , and a sequence $\\langle(a_{t},b_{t})\\mid t\\in[q,s]\\rangle$ such that for all $t\\in[q,s]$ we have $a_{t},b_{t}\\in[0,1]$ , and a sequence $\\langle\\rho_{t}\\,|\\,t\\in[q,s]\\rangle$ defined recursively such that for all $t\\in[q,s-1]$ we have: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\rho_{q}:=1/2\\quad;\\quad\\rho_{t+1}:=\\psi(\\rho_{t},a_{t},b_{t},s-q+1)\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "then we have: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\sum_{t=q}^{s}(\\rho_{t}a_{t}+(1-\\rho_{t})b_{t})\\leq\\operatorname*{min}\\left\\{\\sum_{t=q}^{s}a_{t}\\;,\\sum_{t=q}^{s}b_{t}\\right\\}+{\\sqrt{2\\ln(2)(s-q+1)}}\\,.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "4.2 The Segment Tree ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this subsection we define the segment tree, which is the geometrical structure that our analysis is based on. The segment tree is a full, balanced, binary tree $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ whose leaves are the elements of $[T]$ in order from left to right. Given any internal vertex $v\\,\\in\\,B$ , let $\\triangleleft(v\\right)$ and $\\mathsf{\\Gamma}_{\\mathsf{P}}(v)$ be its left and right child respectively. Given any vertex $v\\in B$ , let $\\blacktriangleleft(v)$ and $\\mapsto\\!(v)$ be its left-most and right-most descendent respectively (noting that these are both elements of $\\left[T\\right].$ ). Let $r$ be the root of $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ . Given a vertex $v\\in B\\setminus\\{r\\}$ , let $\\uparrow(v)$ be the parent of $v$ . Given a vertex $v\\in B$ , let $h(v)$ be equal to the height of $v$ (that is, the height of the tree $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ minus the depth of $v$ , so that leaves have height 0). ", "page_idx": 7}, {"type": "text", "text": "Each vertex $v\\;\\in\\;B$ represents the segment of trials $[\\bullet(v),\\bullet(v)]$ . i.e. Each vertex represents a segment in the left hand side of Figure 1 (when $t=8$ ). We call a vertex $v\\in B$ stationary iff there exists $k\\in[\\Phi]$ with $\\sigma_{k}\\leq\\mathsf{\\pmb{\\mathscr{A}}}(v)$ and $\\boldsymbol{\\succ}(\\boldsymbol{v})<\\sigma_{k+1}$ . Let $\\mathcal{H}$ be the set of all stationary vertices. We call a vertex $v\\in{\\boldsymbol{B}}$ fundamental iff both: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bullet\\,\\,v\\in\\mathcal{H}\\,.}\\\\ &{\\bullet\\,\\,v=r\\,\\,\\mathrm{or}\\,\\uparrow(v)\\notin\\mathcal{H}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Let $\\mathcal{F}$ be the set of all fundamental vertices. We call a vertex $v\\in{\\boldsymbol{B}}$ relevant iff it is an ancestor of a fundamental vertex. Let $\\boldsymbol{\\mathcal{A}}$ be the set of all relevant vertices. For all relevant vertices $v\\in A$ we define $\\boldsymbol{\\mathcal{Q}}(\\boldsymbol{v})$ to be the set of descendants of $v$ that are contained in $\\mathcal{F}$ . ", "page_idx": 7}, {"type": "text", "text": "We have, from the algorithm, the following lemma about vertices in the segment tree: ", "page_idx": 7}, {"type": "text", "text": "Lemma 4.2. Given any vertex $v\\in B$ we have: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\star(v)-\\star(v)+1=2^{h(v)}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "and: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mu_{\\P(v)}^{h(v)}=1/2\\quad;\\quad\\mathcal{D}_{\\P(v)}^{h(v)}=\\mathrm{INITIALISE}\\big(\\,2^{h(v)}\\,\\big)\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "and for all $t\\in[\\blacktriangleleft(v),\\blacktriangleleft(v)-1\\right]$ we have: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mu_{t+1}^{h(v)}=\\psi\\left(\\mu_{t}^{h(v)}\\,,\\,\\ell_{t}\\left(w_{t}^{h(v)}\\right)\\,,\\,\\ell_{t}\\left(z_{t}^{h(v)-1}\\right)\\,,\\,2^{h(v)}\\right)\\quad;\\quad\\mathcal{D}_{t+1}^{h(v)}=\\mathrm{UPDATE}\\left(\\mathcal{D}_{t}^{h(v)}\\,,\\,\\ell_{t}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Note that this lemma shows that for all $v\\in{\\boldsymbol{B}}$ we run a single instance of both the base algorithm and HEDGE over the segment $[\\bullet(v),\\bullet(v)]$ , as illustrated in Figure 1. ", "page_idx": 8}, {"type": "text", "text": "4.3 The Recursive Equations ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We now derive the recursive equations that our analysis is based on. First note that for all $v\\in{\\mathcal{F}}$ there exists $\\pmb{u}\\in\\mathcal{X}$ such that $\\epsilon_{t}=u$ for all $t\\in[\\blacktriangleleft(v),\\blacktriangleleft(v)\\right]$ . Hence, Lemma 4.2 and Equation (1), and the fact that $\\pmb{w}_{t}^{h(v)}$ is the output of QUERY $(\\mathcal{D}_{t}^{h(v)})$ , lead to the following lemma. ", "page_idx": 8}, {"type": "text", "text": "Lemma 4.3. For all $v\\in{\\mathcal{F}}$ we have: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\sum_{t=\\pm(v)}^{\\pm(v)}\\ell_{t}\\left(\\pmb{w}_{t}^{h(v)}\\right)\\leq\\sum_{t=\\pm(v)}^{\\pmb{\\triangleright}(v)}\\ell_{t}(\\pmb{\\epsilon}_{t})+\\gamma\\sqrt{2^{h(v)}}\\,.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Note that, from the algorithm and the convexity of the loss functions, we have, for all $t\\in[T]$ and all $v\\in B$ with $h(v)\\neq0$ , that: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\ell_{t}\\left(z_{t}^{h(v)}\\right)\\leq\\mu_{t}^{h(v)}\\ell_{t}\\left(w_{t}^{h(v)}\\right)+\\left(1-\\mu_{t}^{h(v)}\\right)\\ell_{t}\\left(z_{t}^{h(v)-1}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "So, by lemmas 4.2 and 4.1, we have the following lemma. ", "page_idx": 8}, {"type": "text", "text": "Lemma 4.4. For all vertices $v\\in B$ with $h(v)\\neq0$ we have: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\sum_{t=\\pm(v)}^{\\pm(v)}\\ell_{t}\\left(z_{t}^{h(v)}\\right)\\leq\\operatorname*{min}\\left\\{\\sum_{t=\\pm(v)}^{\\pm(v)}\\ell_{t}\\left(w_{t}^{h(v)}\\right)\\;\\;,\\sum_{t=\\pm(v)}^{\\pm(v)}\\ell_{t}\\left(z_{t}^{h(v)-1}\\right)\\right\\}+\\sqrt{2\\ln(2)2^{h(v)}}\\,.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Noting that $\\pmb{z}_{t}^{0}=\\pmb{w}_{t}^{0}$ for all $t\\in[T]$ , lemmas 4.3 and 4.4 immediately imply the following recursive equations. For all $v\\in{\\mathcal{F}}$ we have: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\sum_{t=\\pm(v)}^{\\pm(v)}\\ell_{t}\\left(z_{t}^{h(v)}\\right)\\leq\\sum_{t=\\pm(v)}^{\\pm(v)}\\ell_{t}(\\epsilon_{t})+\\left(\\gamma+\\sqrt{2\\ln(2)}\\right)\\sqrt{2^{h(v)}}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "and for all $v\\in A\\setminus F$ we have: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\sum_{t=\\pm(v)}^{\\pm(v)}\\ell_{t}\\left(z_{t}^{h(v)}\\right)\\leq\\sum_{t=\\pm(v)}^{\\pm(v)}\\ell_{t}\\left(z_{t}^{h(v)-1}\\right)+\\sqrt{2\\ln(2)2^{h(v)}}\\,.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "4.4 Performing the Recursion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We now utilise equations (3) and (4) to perform the recursion. Specifically, we have the following inductive hypothesis for vertices in $\\boldsymbol{\\mathcal{A}}$ , which is proved by induction up the tree $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ from the vertices in $\\mathcal{F}$ to the root. The reason it holds for vertices in $\\mathcal{F}$ comes direct from Equation (3). For a vertex in ${\\mathcal{A}}\\setminus{\\mathcal{F}}$ , once the inductive hypothesis has been shown to hold for both its children, it is then shown to hold for the vertex itself by Equation (4). The inductive hypothesis is given in the following lemma. Lemma 4.5. For all $v\\in A$ we have: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\sum_{t=\\pm(v)}^{\\pm(v)}\\ell_{t}(z_{t}^{h(v)})\\leq\\sum_{t=\\pm(v)}^{\\pm(v)}\\ell_{t}(\\epsilon_{t})+\\sum_{q\\in\\mathcal{Q}(v)}\\left(\\gamma+\\sqrt{2\\ln(2)}\\sum_{k=0}^{h(v)-h(q)}\\sqrt{2^{-k}}\\right)\\sqrt{2^{h(q)}}\\,.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "In particular, this inductive hypothesis holds for $v=r$ . By Equation (2) this gives us the following. Lemma 4.6. We have: ", "page_idx": 8}, {"type": "equation", "text": "$$\nR^{\\dagger}({\\cal{S}})\\leq(\\gamma+\\alpha)\\sum_{q\\in\\mathcal{F}}\\sqrt{2^{h(q)}}\\,.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "We now have a bound on the switching regret. It is, however, not yet written in terms of the segment lengths. To write it in terms of the segment lengths we partition $\\mathcal{F}$ into a sequence of sets $\\langle{\\bar{\\mathcal{F}}}_{k}\\mid k\\in[{\\Phi}]\\rangle$ such that, for all $k\\in[\\Phi]$ , we define $\\mathcal{F}_{k}$ to be equal to the set of all $v\\in{\\mathcal{F}}$ such that $\\sigma_{k}\\leq\\mathsf{\\pmb{\\mathscr{A}}}(v)$ and $\\boldsymbol{\\succ}(\\boldsymbol{v})<\\sigma_{k+1}$ . We now have the following lemma. ", "page_idx": 8}, {"type": "text", "text": "Lemma 4.7. For all $k\\in[\\Phi]$ we have: ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\sum_{v\\in\\mathcal{F}_{k}}\\sqrt{2^{h(v)}}\\leq c\\sqrt{\\sigma_{k+1}-\\sigma_{k}}\\,.\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "Combining lemmas 4.6 and 4.7 gives us: ", "page_idx": 9}, {"type": "equation", "text": "$$\nR^{\\dagger}(S)\\leq(\\gamma+\\alpha)\\sum_{v\\in\\mathcal{F}}\\sqrt{2^{h(v)}}=(\\gamma+\\alpha)\\sum_{k\\in[\\Phi]}\\sum_{v\\in\\mathcal{F}_{k}}\\sqrt{2^{h(v)}}=c(\\gamma+\\alpha)\\sum_{k\\in[\\Phi]}\\sqrt{\\sigma_{k+1}-\\sigma_{k}}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "as required. This completes the proof of Theorem 2.2. ", "page_idx": 9}, {"type": "text", "text": "4.5 Dynamic Regret Analysis ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We now prove Theorem 2.4. Let the base algorithm be online gradient descent as in [9]. Take any segmentation $\\left\\langle\\hat{\\sigma}_{j}\\mid j\\in\\left[\\Psi+1\\right]\\right\\rangle$ and any comparator sequence $\\mathcal{E}$ . Given any $j\\in[\\Psi]$ , note that we can choose a natural number: ", "page_idx": 9}, {"type": "equation", "text": "$$\nN_{j}\\leq1+P(\\mathcal{E},\\hat{\\sigma}_{j},\\hat{\\sigma}_{j+1})\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "and a sequence $\\langle\\varphi_{j,i}\\mid i\\in[N_{j}+1]\\rangle$ of trials such that $\\varphi_{j,1}=\\hat{\\sigma}_{j}$ and $\\varphi_{j,N_{j}+1}=\\hat{\\sigma}_{j+1}$ and for all $i\\in[N_{j}]$ , we have $\\varphi_{j,i+1}>\\varphi_{j,i}$ and: ", "page_idx": 9}, {"type": "equation", "text": "$$\nP(\\mathcal{E},\\varphi_{j,i},\\varphi_{j,i+1})\\in\\mathcal{O}(1)\\,.\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "Now concatenate the sequences $\\langle\\varphi_{j,i}\\mid i\\in[N_{j}]\\rangle$ for each $j\\in[\\Psi]$ in order, to make a segmentation $\\langle\\sigma_{k}\\mid k\\in[\\Phi+1]\\rangle$ . Note that Equation (5) implies that for all $k\\in[\\Phi]$ we have: ", "page_idx": 9}, {"type": "equation", "text": "$$\nP(\\mathcal{E},\\sigma_{k},\\sigma_{k+1})\\in\\mathcal{O}(1)\\,.\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "We now modify the analysis of the switching regret as follows. In the analysis of the switching regret we defined a comparator sequence $\\langle\\epsilon_{t}\\mid t\\in[T]\\rangle$ . In this analysis we instead define this comparator sequence as equal to $\\mathcal{E}$ . Using the segmentation $\\langle\\sigma_{k}\\mid k\\in[\\Phi+1]\\rangle$ , construct the segment tree and the sets $\\boldsymbol{\\mathcal{A}}$ and $\\mathcal{F}$ as in the analysis of the switching regret. Since our base algorithm is gradient descent we have, direct from [9], the following lemma. ", "page_idx": 9}, {"type": "text", "text": "Lemma 4.8. Suppose we have trials $q,s\\in[T]$ with $s\\geq q$ , and on each trial $t\\in[s,q]$ we do the following: ", "page_idx": 9}, {"type": "text", "text": "Then we have: ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\sum_{t=q}^{s}(\\ell_{t}(w_{t})-\\ell_{t}(\\epsilon_{t}))\\in\\mathcal{O}\\left((1+P(\\mathcal{E},q,s))\\sqrt{q-s+1}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "This lemma, along with Lemma 4.2 and Equation (6), gives us the following. ", "page_idx": 9}, {"type": "text", "text": "Lemma 4.9. For all $v\\in{\\mathcal{F}}$ we have: ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\sum_{t=\\pmb{\\mathscr{A}}(v)}^{\\pmb{\\mathscr{b}}(v)}\\ell_{t}\\left(\\pmb{\\mathscr{w}}_{t}^{h(v)}\\right)\\leq\\sum_{t=\\pmb{\\mathscr{A}}(v)}^{\\pmb{\\mathscr{b}}(v)}\\ell_{t}(\\pmb{\\epsilon}_{t})+\\mathcal{O}\\left(\\sqrt{2^{h(v)}}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "This lemma is essentially identical to Lemma 4.3. Following the rest of the analysis of the switching regret gives us: ", "page_idx": 9}, {"type": "equation", "text": "$$\nR^{*}(\\mathcal{E})\\in\\mathcal{O}\\left(\\sum_{k\\in[\\Phi]}\\sqrt{\\sigma_{k+1}-\\sigma_{k}}\\right)=\\mathcal{O}\\left(\\sum_{\\substack{j\\in[\\Psi]\\,i\\in[N_{j}]}}\\sqrt{\\varphi_{j,i+1}-\\varphi_{j,i}}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "Since: ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\sum_{i\\in[N_{j}]}\\sqrt{\\varphi_{j,i+1}-\\varphi_{j,i}}\\leq\\sqrt{N_{j}\\sum_{i\\in[N_{j}]}(\\varphi_{j,i+1}-\\varphi_{j,i})}=\\sqrt{N_{j}(\\hat{\\sigma}_{j+1}-\\hat{\\sigma}_{j})}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "we have proved Theorem 2.4. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Research funded by the Defence Science and Technology Laboratory (Dstl) which is an executive agency of the UK Ministry of Defence providing world class expertise and delivering cutting-edge science and technology for the benefti of the nation and allies. The research supports the Autonomous Resilient Cyber Defence (ARCD) project within the Dstl Cyber Defence Enhancement programme. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Jacob D. Abernethy, Alekh Agarwal, Peter L. Bartlett, and Alexander Rakhlin. A stochastic view of optimal regret through minimax duality. ArXiv, abs/0903.5328, 2009.   \n[2] Charles E. Blair. Problem complexity and method efficiency in optimization (a. s. nemirovsky and d. b. yudin). Siam Review, 27:264\u2013265, 1985.   \n[3] Amit Daniely, Alon Gonen, and Shai Shalev-Shwartz. Strongly adaptive online learning. ArXiv, abs/1502.07073, 2015.   \n[4] Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. In European Conference on Computational Learning Theory, 1997.   \n[5] Mark Herbster and Manfred K. Warmuth. Tracking the best expert. Machine Learning, 32:151\u2013 178, 1995.   \n[6] Kwang-Sung Jun, Francesco Orabona, Stephen J. Wright, and Rebecca M. Willett. Improved strongly adaptive online learning using coin betting. In International Conference on Artificial Intelligence and Statistics, 2016.   \n[7] Yuanyu Wan, TU Wei-Wei, and Lijun Zhang. Strongly adaptive online learning over partial intervals. Science China Information Sciences, 65, 2022.   \n[8] Lijun Zhang, Shiyin Lu, and Zhi-Hua Zhou. Adaptive online learning in dynamic environments. ArXiv, abs/1810.10815, 2018.   \n[9] Martin A. Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In International Conference on Machine Learning, 2003. ", "page_idx": 10}, {"type": "text", "text": "A Proofs ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Here we prove, in order, all the lemmas in the analysis. ", "page_idx": 10}, {"type": "text", "text": "A.1 Lemma 4.1 ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Direct from [4] using only two experts, were, on each trial $t$ , we have that: ", "page_idx": 10}, {"type": "text", "text": "\u2022 The loss of the first expert is $a_{t}$ and the loss of the second is $b_{t}$ .   \n\u2022 The weight of the first expert is $\\rho_{t}$ and the weight of the second is $1-\\rho_{t}$ . ", "page_idx": 10}, {"type": "text", "text": "A.2 Lemma 4.2 ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "The equality: ", "page_idx": 10}, {"type": "equation", "text": "$$\n\\star(v)-\\star(v)+1=2^{h(v)}\n$$", "text_format": "latex", "page_idx": 10}, {"type": "text", "text": "comes directly from the definition of $h(v)$ . We also have that: ", "page_idx": 10}, {"type": "equation", "text": "$$\n\\mathsf{\\Omega}^{\\bullet}(v)-1\\in2^{h(v)}\\mathbb{N}\n$$", "text_format": "latex", "page_idx": 10}, {"type": "text", "text": "and for all $t\\in[\\blacktriangleleft(v),\\blacktriangleleft(v)-1\\right]$ we have: ", "page_idx": 10}, {"type": "equation", "text": "$$\nt\\notin2^{h(v)}\\mathbb{N}\\,.\n$$", "text_format": "latex", "page_idx": 10}, {"type": "text", "text": "Hence, by the algorithm, the lemma holds. ", "page_idx": 10}, {"type": "text", "text": "A.3 Lemma 4.3 ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "Note first that, since wth(v)is the output of QUERY(Dth(v)) , Lemma 4.2 and Equation (1) immediately give us: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\pmb{x}^{*}\\in\\mathcal{X}}\\sum_{t=\\pmb{\\4}(v)}^{\\pmb{\\nu}(v)}\\left(\\ell_{t}\\left(\\pmb{w}_{t}^{h(v)}\\right)-\\ell_{t}(\\pmb{x}^{*})\\right)\\leq\\gamma\\sqrt{2^{h(v)}}\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Since $v\\in{\\mathcal{F}}$ we have that $v\\in\\mathcal H$ so there exists $k\\in[\\Phi]$ with $\\sigma_{k}\\leq\\mathsf{\\pmb{\\mathscr{A}}}(v)$ and $\\boldsymbol{\\succ}(\\boldsymbol{v})<\\sigma_{k+1}$ . This implies that for all $t\\in[\\blacktriangleleft(v),\\blacktriangleleft(v)\\right]$ we have $t\\in[\\sigma_{k},\\sigma_{k+1}-1]$ so that $\\epsilon_{t}:=\\tilde{\\epsilon}_{k}$ . Hence, we have: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{x^{*}\\in\\mathcal{X}}\\sum_{t=\\pmb{\\4}(v)}^{\\pmb{\\nu}(v)}\\ell_{t}(\\pmb{x}^{*})\\leq\\sum_{t=\\pmb{4}(v)}^{\\pmb{\\nu}(v)}\\ell_{t}(\\tilde{\\pmb{\\epsilon}}_{k})=\\sum_{t=\\pmb{4}(v)}^{\\pmb{\\nu}(v)}\\ell_{t}(\\pmb{\\epsilon}_{t})\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Substituting into Equation (7) gives us the result. ", "page_idx": 11}, {"type": "text", "text": "A.4 Lemma 4.4 ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "Consider Lemma 4.1. In this lemma choose $q:=\\bullet(v)$ and $s:={\\bullet}(v)$ . For all $t\\in[q,s]$ choose: ", "page_idx": 11}, {"type": "equation", "text": "$$\na_{t}:=\\ell_{t}\\left(\\pmb{w}_{t}^{h(v)}\\right)\\quad;\\quad b_{t}:=\\ell_{t}\\left(\\pmb{z}_{t}^{h(v)-1}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Then by Lemma 4.2 we have, for all $t\\in[q,s]$ , that: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\rho_{t}=\\mu_{t}^{h(v)}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "so that, by the algorithm and the convexity of the loss functions we have, for all $t\\in[q,s]$ , that: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\ell_{t}\\left(z_{t}^{h(v)}\\right)\\leq\\mu_{t}^{h(v)}\\ell_{t}\\left(w_{t}^{h(v)}\\right)+\\left(1-\\mu_{t}^{h(v)}\\right)\\ell_{t}\\left(z_{t}^{h(v)-1}\\right)=\\rho_{t}a_{t}+(1-\\rho_{t})b_{t}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "and hence, by Lemma 4.1, we have: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\sum_{t=q}^{s}\\ell_{t}\\left(z_{t}^{h(v)}\\right)\\leq\\operatorname*{min}\\left\\{\\sum_{t=q}^{s}a_{t}\\cdot\\sum_{t=q}^{s}b_{t}\\right\\}+{\\sqrt{2\\ln(2)(s-q+1)}}\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "The result then follows from the fact that, by Lemma 4.2, we have $s-q+1=2^{h(v)}$ ", "page_idx": 11}, {"type": "text", "text": "A.5 Lemma 4.5 ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "For $i,j\\in\\mathbb{N}\\cup\\{0\\}$ with $j\\geq i$ we define: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\lambda_{i}^{j}:=\\sum_{k=0}^{j-i}\\sqrt{2^{-k}}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "so our inductive hypothesis is that for all $v\\in A$ we have: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\sum_{t=\\pm(v)}^{\\pm(v)}\\ell_{t}\\left(z_{t}^{h(v)}\\right)\\leq\\sum_{t=\\pm(v)}^{\\pm(v)}\\ell_{t}(\\epsilon_{t})+\\sum_{q\\in\\mathcal{Q}(v)}\\left(\\gamma+\\lambda_{h(q)}^{h(v)}\\sqrt{2\\ln(2)}\\right)\\sqrt{2^{h(q)}}\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "If $v\\,\\in\\,{\\mathcal{F}}$ then, by the definition of $\\mathcal{F}$ , we have $\\mathcal{Q}(v)=\\{v\\}$ so the inductive hypothesis holds by Equation (3). Now suppose we have some $\\tilde{v}\\in A\\setminus F$ . Note that, by the definition of $\\mathcal{F}$ , we have $\\triangle(\\tilde{v}),\\triangleright(\\tilde{v})\\in A$ so all that is left to prove the inductive hypothesis is to prove that, if the inductive hypothesis holds for both $v=\\triangleleft(\\tilde{v})$ and $v=\\mathsf{\\mathsf{P}}(\\tilde{v})$ , then it also holds for $v=\\tilde{v}$ . So suppose that the inductive hypothesis holds for $v=\\triangleleft(\\tilde{v})$ and $v=\\mathsf{\\mathsf{P}}(\\tilde{v})$ . First note that: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\sum_{t=\\pm(\\tilde{v})}^{\\pm(\\tilde{v})}\\ell_{t}\\left(z_{t}^{h(\\tilde{v})-1}\\right)=\\sum_{t=\\pm(\\tilde{\\mathrm{\\boldmath~d~}}\\left(\\tilde{v}\\right))}^{\\pm(\\tilde{\\mathrm{\\boldmath~d~}}\\left(\\tilde{v}\\right))}\\ell_{t}\\left(z_{t}^{h(\\tilde{\\mathrm{\\boldmath~d~}}\\left(\\tilde{v}\\right))}\\right)+\\sum_{t=\\pm(\\tilde{v}(\\tilde{v}))}^{\\pm(\\tilde{\\mathrm{\\boldmath~v~}}\\left(\\tilde{v}\\right))}\\ell_{t}\\left(z_{t}^{h(\\tilde{v}(\\tilde{v}))}\\right)\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "and, by the definition of $\\mathcal{F}$ , we have: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sum_{q\\in\\mathcal{Q}(\\tilde{v})}2^{h(q)}=2^{h(\\tilde{v})}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "so that: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sum_{q\\in\\mathcal{Q}(\\tilde{v})}\\sqrt{2^{h(q)}}\\sqrt{2^{h(q)-h(\\tilde{v})}}=\\sqrt{2^{-h(\\tilde{v})}}\\sum_{q\\in\\mathcal{Q}(\\tilde{v})}2^{h(q)}=2^{h(\\tilde{v})}\\sqrt{2^{-h(\\tilde{v})}}=\\sqrt{2^{h(\\tilde{v})}}\\,.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Equations (4), (8) and (9), imply: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\displaystyle\\sum_{t=\\pm(\\tilde{v})}^{\\pm(\\tilde{v})}\\ell_{t}\\left(z_{t}^{h(\\tilde{v})}\\right)\\leq\\sum_{t=\\pm(\\tilde{\\mathrm{d}}(\\tilde{v}))}^{\\pm(\\tilde{\\mathrm{d}}(\\tilde{v}))}\\ell_{t}\\left(z_{t}^{h(\\tilde{\\mathrm{d}}(\\tilde{v}))}\\right)+\\sum_{t=\\pm(\\tilde{v}(\\tilde{v}))}^{\\pm(\\tilde{v}(\\tilde{v}))}\\ell_{t}\\left(z_{t}^{h(\\tilde{v}(\\tilde{v}))}\\right)}\\\\ &{}&{\\displaystyle+\\,\\sqrt{2\\ln(2)}\\sum_{q\\in{\\mathcal Q}(\\tilde{v})}\\sqrt{2^{h(q)}}\\sqrt{2^{h(q)-h(\\tilde{v})}}\\,.\\qquad\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Applying the inductive hypothesis to the terms: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sum_{t=\\pm(\\mathfrak{d}(\\tilde{v}))}^{\\pm(\\mathfrak{d}(\\tilde{v}))}\\ell_{t}\\left(\\boldsymbol{z}_{t}^{h(\\mathfrak{d}(\\tilde{v}))}\\right)\\quad\\mathrm{~:~}\\quad\\sum_{t=\\pm(\\mathfrak{d}(\\tilde{v}(\\tilde{v}))}^{\\pm(\\mathfrak{d}(\\tilde{v}(\\tilde{v}))}\\ell_{t}\\left(\\boldsymbol{z}_{t}^{h(\\mathfrak{d}(\\tilde{v}))}\\right)\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "and noting that $\\mathcal{Q}(\\tilde{v})=\\mathcal{Q}(\\triangle(\\tilde{v}))\\cup\\mathcal{Q}(\\triangleright(\\tilde{v}))$ and for all $q\\in\\mathcal{Q}(\\tilde{v})$ we have: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\lambda_{h(q)}^{h(\\tilde{v})}=\\lambda_{h(q)}^{h(\\triangleleft(\\tilde{v}))}+\\sqrt{2^{h(q)-h(\\tilde{v})}}=\\lambda_{h(q)}^{h(\\triangleright(\\tilde{v}))}+\\sqrt{2^{h(q)-h(\\tilde{v})}}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "shows the inductive hypothesis holds for $v=\\tilde{v}$ . We have hence proved that the inductive hypothesis holds for all $v\\in A$ . ", "page_idx": 12}, {"type": "text", "text": "A.6 Lemma 4.6 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "For all $q\\in\\mathcal{Q}(r)$ we have: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sum_{k=0}^{h(r)-h(q)}\\sqrt{2^{-k}}\\leq\\sum_{k=0}^{\\infty}\\sqrt{2^{-k}}=\\sqrt{2}/(\\sqrt{2}-1)=\\alpha/\\sqrt{2\\ln(2)}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "so, since $r\\in A$ and $\\mathcal{Q}(r)=\\mathcal{F}$ , Lemma 4.5 gives us: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sum_{t=\\pm(r)}^{\\pm(r)}\\ell_{t}(z_{t}^{h(r)})\\leq\\sum_{t=\\pm(r)}^{\\pm(r)}\\ell_{t}(\\pmb{\\epsilon}_{t})+(\\gamma+\\alpha)\\sum_{q\\in\\mathcal{F}}\\sqrt{2^{h(q)}}\\,.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Since $\\mathbf{\\delta}\\mathbf{d}(r)=1$ , $\\begin{array}{r}{\\pmb{\\triangleright}(r)=T}\\end{array}$ and, by the algorithm, zth(r)= zt\u03c4 = xt for all t \u2208[T], we then have, by Equation (2), that: ", "page_idx": 12}, {"type": "equation", "text": "$$\nR^{\\dagger}({\\mathcal{S}})\\leq(\\gamma+\\alpha)\\sum_{q\\in{\\mathcal{F}}}{\\sqrt{2^{h(q)}}}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "as required. ", "page_idx": 12}, {"type": "text", "text": "A.7 Lemma 4.7 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "First let: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\xi:=1/(\\sqrt{2}-1)\\,.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "We take the inductive hypothesis that for all non-empty finite sets ${\\mathcal{Z}}\\subseteq\\mathbb{N}\\cup\\{0\\}$ we have: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sum_{k\\in\\mathcal{Z}}\\sqrt{2^{k}}\\leq\\xi\\sqrt{\\sum_{k\\in\\mathcal{Z}}2^{k}}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "and we prove by induction on $|\\mathcal{Z}|$ . In the case that $|\\mathcal{Z}|=1$ we have $\\mathcal{Z}=\\{i\\}$ for some $i\\in\\mathbb{N}\\cup\\{0\\}$ and hence: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sum_{k\\in\\mathcal{Z}}\\sqrt{2^{k}}=\\sqrt{2^{i}}<\\xi\\sqrt{2^{i}}=\\xi\\sqrt{\\sum_{k\\in\\mathcal{Z}}2^{k}}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "so the inductive hypothesis holds for $|\\mathcal{Z}|=1$ . Now suppose we have some $j\\,\\in\\,\\mathbb N$ and that the inductive hypothesis holds for $|\\mathcal{Z}|=j$ . We now show that it holds for $|\\mathcal{Z}|=j+1$ which will prove that the inductive hypothesis holds always. Specifically, let $i:=\\operatorname*{max}\\mathcal{Z}$ , let $\\mathcal{Z}^{\\prime}:=\\mathcal{Z}\\setminus\\{i\\}$ and let $i^{\\prime}:=\\operatorname*{max}\\mathcal{Z}^{\\prime}$ . Define: ", "page_idx": 13}, {"type": "equation", "text": "$$\ny:=2^{-i}\\sum_{k\\in\\mathcal{Z}^{\\prime}}2^{k}\\,.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Note that: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sum_{k\\in\\mathcal{Z}^{\\prime}}2^{k}\\leq\\sum_{k=0}^{i^{\\prime}}2^{k}<2^{i^{\\prime}+1}\\leq2^{i}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "so that $y<1$ and hence: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sqrt{1+y}-\\sqrt{y}\\geq\\sqrt{1+1}-\\sqrt{1}=\\sqrt{2}-1=1/\\xi\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "since the term on the left is monotonic decreasing with $y$ . This implies that: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sqrt{\\sum_{k\\in\\mathcal{Z}}2^{k}}=\\sqrt{2^{i}+\\sum_{k\\in\\mathcal{Z}^{\\prime}}2^{k}}=\\sqrt{2^{i}}\\sqrt{1+y}\\geq\\sqrt{2^{i}}\\left(\\sqrt{y}+\\frac{1}{\\xi}\\right)=\\sqrt{\\sum_{k\\in\\mathcal{Z}^{\\prime}}2^{k}}+\\frac{\\sqrt{2^{i}}}{\\xi}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "so that, by the inductive hypothesis (applied to the set ${\\mathcal{Z}}^{\\prime}$ ), we have: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sqrt{\\sum_{k\\in\\mathcal{Z}}2^{k}}\\ge\\frac{1}{\\xi}\\sum_{k\\in\\mathcal{Z}^{\\prime}}\\sqrt{2^{k}}+\\frac{\\sqrt{2^{i}}}{\\xi}=\\frac{1}{\\xi}\\sum_{k\\in\\mathcal{Z}}\\sqrt{2^{k}}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "so the inductive hypothesis holds for $|\\mathcal{Z}|=j+1$ . We have hence proved that the inductive hypothesis holds always. ", "page_idx": 13}, {"type": "text", "text": "Now note that, by the definition of $\\mathcal{F}$ , we have: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sum_{v\\in\\mathcal{F}_{k}}2^{h(v)}=\\sigma_{k+1}-\\sigma_{k}\\,.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Assume, for contradiction, that there exists three distinct vertices $v,v^{\\prime},v^{\\prime\\prime}\\in\\mathcal{F}_{k}$ with $h(v)=h(v^{\\prime})=$ $h(v^{\\prime\\prime})$ . Without loss of generality assume that $v$ and $v^{\\prime\\prime}$ are the leftmost and rightmost of the three vertices respectively. Also without loss of generality assume that $v^{\\prime}$ is the right child of its parent $\\uparrow(v^{\\prime})$ . Then $v$ must either be equal to or lie to the left of the left child of $\\uparrow(v^{\\prime})$ and hence: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\bullet(\\uparrow(v^{\\prime}))\\geq\\bullet(v)\\geq\\sigma_{k}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "and ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\bullet(\\uparrow(v^{\\prime}))=\\bullet(v^{\\prime})<\\sigma_{k+1}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "so that $\\uparrow(v^{\\prime})\\in\\mathcal{H}$ . But this contradicts the fact that $v^{\\prime}\\in\\mathcal{F}$ . ", "page_idx": 13}, {"type": "text", "text": "We have hence shown that for any $i\\in[\\tau]\\cup\\{0\\}$ there are at most two distinct vertices $v,v^{\\prime}\\in\\mathcal{F}_{k}$ with $h(v)=h(v^{\\prime})=i$ . This means that we can partition $\\mathcal{F}_{k}$ into two disjoint sets $\\mathcal{U}_{k}$ and $\\mathcal{V}_{k}$ such that for all $i\\in[\\tau]\\cup\\{0\\}$ there exists at most one element $v$ of $\\mathcal{U}_{k}$ with $h(v)=i$ and at most one element $v^{\\prime}$ of $\\mathcal{V}_{k}$ with $h(v^{\\prime})=i$ . By Equation (10) we then have: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sum_{v\\in\\mathcal{U}_{k}}\\sqrt{2^{h(v)}}\\le\\xi\\sqrt{\\sum_{v\\in\\mathcal{U}_{k}}2^{h(v)}}\\quad;\\qquad\\sum_{v\\in\\mathcal{V}_{k}}\\sqrt{2^{h(v)}}\\le\\xi\\sqrt{\\sum_{v\\in\\mathcal{V}_{k}}2^{h(v)}}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "so that: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sum_{v\\in\\mathcal{F}_{k}}\\sqrt{2^{h(v)}}\\leq\\xi\\sqrt{\\sum_{v\\in\\mathcal{U}_{k}}2^{h(v)}}+\\xi\\sqrt{\\sum_{v\\in\\mathcal{V}_{k}}2^{h(v)}}\\,.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Noting that for all $y,y^{\\prime}>0$ we have $\\sqrt{y}+\\sqrt{y^{\\prime}}\\leq\\sqrt{2}\\sqrt{y+y^{\\prime}}$ and $c=\\xi\\sqrt{2}$ , the above inequality, along with Equation (11), gives us: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sum_{v\\in\\mathcal{F}_{k}}\\sqrt{2^{h(v)}}\\leq c\\sqrt{\\sum_{v\\in\\mathcal{F}_{k}}2^{h(v)}}=c\\sqrt{\\sigma_{k+1}-\\sigma_{k}}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "as required. ", "page_idx": 13}, {"type": "text", "text": "A.8 Lemma 4.8 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Direct from [9]. ", "page_idx": 14}, {"type": "text", "text": "A.9 Lemma 4.9 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "By lemmas 4.2 and 4.8 we immediately have that: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\sum_{t=\\pm(v)}^{\\pm(v)}\\left(\\ell_{t}\\left(\\pmb{w}_{t}^{h(v)}\\right)-\\ell_{t}(\\pmb{\\epsilon}_{t})\\right)\\in\\mathcal{O}\\left((1+P(\\mathcal{E},\\pmb{\\bullet}(v),\\pmb{\\bullet}(v)))\\sqrt{2^{h(v)}}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Since $v\\in{\\mathcal{F}}$ we have that there exists $k\\in[\\Phi]$ such that $\\mathbf{\\sigma}\\bullet(v)\\geq\\sigma_{k}$ and $\\boldsymbol{\\succ}(\\boldsymbol{v})<\\sigma_{k+1}$ . Hence, by Equation (6) , we have that: ", "page_idx": 14}, {"type": "equation", "text": "$$\nP(\\mathcal{E},\\bullet(v),\\bullet(v))\\leq P(\\mathcal{E},\\sigma_{k},\\sigma_{k+1})\\in\\mathcal{O}(1)\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Substituting into Equation (12) gives us the result. ", "page_idx": 14}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 15}, {"type": "text", "text": "Justification: The main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope. ", "page_idx": 15}, {"type": "text", "text": "Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 15}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 15}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 15}, {"type": "text", "text": "Justification: Our algorithm always achieves the stated bounds on regret and time-complexity and (when using the doubling trick) is parameter free. ", "page_idx": 15}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 15}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: All theorems are either referenced or proved. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 16}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 16}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 16}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 16}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 17}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 17}, {"type": "text", "text": "Justification: This paper does not include experiments. Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 17}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 17}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 17}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 17}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 17}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 17}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 18}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: This paper conforms to the code of ethics. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 18}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: This work is theoretical in nature and we cannot foresee any societal impacts. Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 19}, {"type": "text", "text": "Justification: This work is theoretical in nature and we cannot foresee any risks. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 19}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 19}, {"type": "text", "text": "Justification: This paper does not use existing assets. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 19}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 20}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 20}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 20}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 20}]