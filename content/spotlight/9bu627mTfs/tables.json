[{"figure_path": "9bu627mTfs/tables/tables_7_1.jpg", "caption": "Table 3: Ablation study of the architectural components on SemanticKITTI [1] validation set. CGVT: context and geometry aware voxel transformer. LGE: local and global encoder. 3D-DCA: 3D deformable cross attention. CAQG: context aware query generator. LB: local voxel-based branch. Txy,Tyz,Txz: planes of the TPV-based branch. DF: dynamic fusion. There are 32M predefined parameters.", "description": "This ablation study analyzes the impact of different components of the CGFormer model on the SemanticKITTI validation set.  It systematically removes or modifies components (context and geometry aware voxel transformer (CGVT), local and global encoder (LGE), 3D deformable cross-attention (3D-DCA), context-aware query generator (CAQG), local voxel-based branch (LB), TPV-based branches (Txy, Tyz, Txz), dynamic fusion (DF)) to isolate their individual effects on model performance (measured by IoU and mIoU). The baseline represents the model without any of the modifications. Each row shows the results with a specific combination of components, clearly showing the effect of each feature on performance.", "section": "4.2 Ablation Study"}, {"figure_path": "9bu627mTfs/tables/tables_7_2.jpg", "caption": "Table 4: Ablation on the choices of context aware query generator.", "description": "This ablation study analyzes the impact of different context-aware query generator designs on the model's performance.  It compares a model without a context-aware query generator, a model with more attention layers, a model using the FLOSP module, and a model using voxel pooling. The results show the impact of the choice of context-aware query generator on IoU and mIoU metrics, as well as model parameters and memory usage.", "section": "4.2 Ablation Study"}, {"figure_path": "9bu627mTfs/tables/tables_7_3.jpg", "caption": "Table 5: Ablation on the depth refinement block of the depth net.", "description": "This table presents the ablation study on the depth refinement block. It compares the performance of the model with and without different components of the depth refinement block, including removing the stereo feature, removing the neighborhood attention, replacing with StereoScene [16], and the full model. The results show that each component contributes to the improvement of the accuracy.", "section": "4.2 Ablation Study"}, {"figure_path": "9bu627mTfs/tables/tables_13_1.jpg", "caption": "Table 6: The performance of the CGFormer with more lightweight backbone networks.", "description": "This table presents an ablation study on the impact of using different backbone networks on the performance of CGFormer. It compares the results obtained using EfficientNetB7 with Swin Block, ResNet50 with Swin Block, and ResNet50 with ResBlock.  The table shows that while using lighter backbone networks reduces parameters and training memory, the performance (IoU and mIoU) remains relatively stable.", "section": "A.3 Results Using Monocular Inputs"}, {"figure_path": "9bu627mTfs/tables/tables_14_1.jpg", "caption": "Table 7: Comparison of the performance using monocular inputs. For stereo-based methods, we replace the MobileStereoNet [39] with Adabins [2].", "description": "This table compares the performance of several semantic scene completion methods when only using monocular RGB images as input.  The methods compared include VoxFormer-S, VoxFormer-T, Symphonize, OccFormer, and the authors' proposed CGFormer.  For fair comparison, stereo-based methods (those using depth information) replace their original depth estimation network (MobileStereoNet) with Adabins to ensure a consistent monocular input setting. The table shows that CGFormer achieves the best results in terms of both IoU and mIoU metrics, indicating improved performance on semantic scene completion when leveraging only monocular information.", "section": "4.2 Ablation Study"}, {"figure_path": "9bu627mTfs/tables/tables_14_2.jpg", "caption": "Table 8: Comparison of training memory and inference time with SOTA methods on the and SemanticKITTI test set. These metrics were measured on the NVIDIA 4090 GPU.", "description": "This table compares the training memory and inference time of CGFormer with other state-of-the-art (SOTA) methods on the SemanticKITTI test set. The metrics were measured using an NVIDIA 4090 GPU.  The table provides a quantitative comparison of resource usage and computational efficiency.", "section": "4.1 Quantitative Results"}, {"figure_path": "9bu627mTfs/tables/tables_15_1.jpg", "caption": "Table 1: Quatitative results on SemanticKITTI [1] test set. * represents the reproduced results in [13, 59]. The best and the second best results are in bold and underlined, respectively.", "description": "This table presents quantitative results on the SemanticKITTI test set, comparing the performance of CGFormer against other state-of-the-art methods.  The results are measured using the Intersection over Union (IoU) metric for each of the 20 semantic classes present in the dataset, along with the mean IoU (mIoU).  The best and second-best results for each class are highlighted.  The asterisk (*) indicates that some results are reproduced from other publications.", "section": "4.1 Quantitative Results"}, {"figure_path": "9bu627mTfs/tables/tables_15_2.jpg", "caption": "Table 1: Quatitative results on SemanticKITTI [1] test set. * represents the reproduced results in [13, 59]. The best and the second best results are in bold and underlined, respectively.", "description": "This table presents quantitative results of the proposed CGFormer model and other state-of-the-art methods on the SemanticKITTI test set.  The results are evaluated using Intersection over Union (IoU) and mean IoU (mIoU) metrics for 19 semantic classes and one free class.  The best and second-best results for each class are highlighted, showcasing CGFormer's performance compared to other methods.", "section": "4.1 Quantitative Results"}]