[{"figure_path": "PfOeAKxx6i/tables/tables_8_1.jpg", "caption": "Table 2: Experimental results and baselines across the tasks considered.", "description": "This table presents a comparison of the performance of different positional encoding schemes across various tasks, including machine translation, synthetic sequence transduction, tree transduction, and image recognition.  It shows the BLEU score for machine translation, perplexity scores (PPL) for sequence tasks, and accuracy scores for image recognition.  The results are broken down by positional encoding method (Sinusoidal, Absolute, Relative, Rotary, Algebraic) and, in some cases, further by initialization method (with or without initialization) and trainability of parameters (frozen or tuned).  The table highlights the best performing method for each task and indicates when the confidence intervals overlap with the top performer. The results demonstrate that algebraic positional encodings consistently outperform or match the state-of-the-art, even without hyperparameter optimization.", "section": "4 Experiments"}, {"figure_path": "PfOeAKxx6i/tables/tables_8_2.jpg", "caption": "Table 2: Experimental results and baselines across the tasks considered.", "description": "This table presents the quantitative results of the experiments conducted in the paper, comparing the performance of Algebraic Positional Encodings (APE) against several strong baselines across various tasks involving sequences, trees, and images.  For each task and method, the table reports the performance metric (BLEU for machine translation and sequence transduction tasks, perplexity for algorithmic tree manipulation, and accuracy for image recognition).  The results show APE achieving competitive or superior performance in most cases, highlighting its robustness and generalizability.", "section": "4 Experiments"}, {"figure_path": "PfOeAKxx6i/tables/tables_8_3.jpg", "caption": "Table 2: Experimental results and baselines across the tasks considered.", "description": "This table presents a comparison of the performance of different positional encoding methods across various tasks, including machine translation, synthetic sequence transduction, tree transduction, and image recognition.  For each task, multiple metrics (BLEU score for machine translation, perplexity for synthetic tasks, and accuracy for image recognition) and methods (Sinusoidal, Absolute, Relative, Rotary, Algebraic with and without initialization) are shown, with their performance and confidence intervals. The best-performing model for each task is highlighted.", "section": "4 Experiments"}, {"figure_path": "PfOeAKxx6i/tables/tables_13_1.jpg", "caption": "Table 3: Hyperparameter setups, grouped by experiment.", "description": "This table lists the hyperparameters used in the experiments described in the paper, broken down by experiment type (NMT, Transduction, Image).  It shows the specific values used for parameters such as convolution size, embedding size, feedforward size (for encoder and decoder), activation function, number of layers and heads, normalization method, and the position of normalization (pre or post). These settings were chosen to enable a fair and comparable evaluation across the different tasks.", "section": "4 Experiments"}]