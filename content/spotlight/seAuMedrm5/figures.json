[{"figure_path": "seAuMedrm5/figures/figures_2_1.jpg", "caption": "Figure 1: Information flow through an Aligner-Encoder versus traditional audio encoders.", "description": "This figure illustrates the difference in information flow between traditional encoders (used in CTC, RNN-T, and AED) and the proposed Aligner-Encoder. Traditional encoders process audio frames and produce audio-aligned embeddings that are then passed to the decoder.  In contrast, the Aligner-Encoder internally performs text alignment during the forward pass, resulting in text-aligned embeddings that are fed to the decoder. This difference is visually represented by the different directions of the arrows.", "section": "2 Model"}, {"figure_path": "seAuMedrm5/figures/figures_7_1.jpg", "caption": "Figure 2: Self-attention probabilities from a single head at different layers in a 17-layer Aligner-Encoder performing audio-to-text alignment.", "description": "This figure visualizes the self-attention probabilities within a single head across different layers (4, 13, 14, 15, 16, 17) of a 17-layer Aligner-Encoder model. Each subplot represents a layer, showing the attention weights as a heatmap. The x-axis represents the input positions (audio frames), and the y-axis represents the output positions (word-pieces). The heatmap's intensity indicates the strength of attention between input and output positions.  The figure aims to demonstrate how the alignment process evolves across the layers, showing a shift from local to global alignment as the network progresses.", "section": "4.5 Alignments"}, {"figure_path": "seAuMedrm5/figures/figures_8_1.jpg", "caption": "Figure 3: Decoding lattice probabilities (U vs T) from RNN-T-on-Aligner and self-attention weights exhibiting successful alignment, within a specific layer.", "description": "This figure compares the decoding lattice probabilities generated by a standard RNN-T model and two RNN-T models trained on top of Aligner-Encoders with different numbers of layers (14 and 15).  It also shows the self-attention weights from layer 15 of the Aligner-Encoder. The comparison highlights how the Aligner-Encoder progressively learns to align audio and text information, with layer 15 showing a clear diagonal alignment pattern in its self-attention weights, indicating a direct mapping between audio frames and output tokens. This contrasts with the more diffuse alignment patterns in the RNN-T models, which need to explicitly use dynamic programming to find the optimal alignment during inference. The figure demonstrates the Aligner-Encoder's ability to implicitly perform alignment within its encoder, simplifying the overall ASR model.", "section": "4.5 Alignments"}, {"figure_path": "seAuMedrm5/figures/figures_8_2.jpg", "caption": "Figure 3: Decoding lattice probabilities (U vs T) from RNN-T-on-Aligner and self-attention weights exhibiting successful alignment, within a specific layer.", "description": "This figure visualizes the alignment process in two different ways. The top two subplots show the decoding lattices generated by RNN-T models trained on top of different numbers of Aligner-Encoder layers. The bottom subplot shows the self-attention weights from the 15th layer of the Aligner-Encoder. These visualizations demonstrate how the Aligner-Encoder gradually learns to align audio and text embeddings, culminating in a clear alignment in the self-attention weights of Layer 15. The successful alignment is indicated by the diagonal concentration of probability mass.", "section": "4.5 Alignments"}, {"figure_path": "seAuMedrm5/figures/figures_15_1.jpg", "caption": "Figure 2: Self-attention probabilities from a single head at different layers in a 17-layer Aligner-Encoder performing audio-to-text alignment.", "description": "This figure visualizes the self-attention probabilities at different layers of a 17-layer Aligner-Encoder during audio-to-text alignment.  Each subplot represents a different layer of the network. The x-axis represents the input positions (audio frames), and the y-axis represents the output positions (text tokens). The color intensity represents the strength of the attention weight between the input and output positions. The figure demonstrates how the alignment is gradually formed from layer to layer, starting with largely local connections and ultimately leading to a monotonic alignment in later layers.", "section": "4.5 Alignments"}]