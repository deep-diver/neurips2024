[{"figure_path": "vt2qkE1Oax/figures/figures_4_1.jpg", "caption": "Figure 1: Illustrative 2D example for the low-rank nature of Pk. A triangle undergoes rigid rotation over three frames. As the rate of rotation is not constant, the flow vectors and point positions are difficult to model. However, the point p is part of the triangle and can be expressed as a combination of the three vertices at an appropriate time. Thus, the last column of Pk is linearly dependent, and Pk is rank deficient. Any points in the triangle could be included in Pk without increasing its rank.", "description": "This figure illustrates how the motion of points belonging to the same object can be linearly dependent and represented in a low-rank matrix. A triangle rotating over three frames is used as an example. Although the rotation speed is not constant, and therefore, individual point positions and flow vectors are complex and hard to model, each point's motion within the triangle is still a linear combination of the three vertices' motions.  This demonstrates the principle behind the low-rank assumption made for trajectory-based loss calculation in the paper.", "section": "3 Method"}, {"figure_path": "vt2qkE1Oax/figures/figures_5_1.jpg", "caption": "Figure 2: Overview of our approach. We self-supervise a segmentation network, i.e., without access to mask annotations, using both short-term motion information (optical flow) and long-term motion (point trajectories). We design a loss function that encourages the segmentation network to cluster regions where trajectories form low-rank-r groups, which should align well with objects. Off-the-shelf methods are used to estimate optical flow and point trajectories given a dataset of videos.", "description": "This figure illustrates the overall architecture of the proposed approach for self-supervised video object segmentation.  It uses both optical flow (short-term motion) and point trajectories (long-term motion) to supervise a segmentation network.  The optical flow and trajectories are processed separately, feeding into their respective loss functions (flow loss and trajectory loss).  The combined loss guides the segmentation network to produce masks that align with the motion patterns of objects.  The network outputs a segmentation mask, and the loss functions measure the accuracy of the segmentation against the motion information. Off-the-shelf methods are used to extract optical flow and track points.", "section": "3 Method"}, {"figure_path": "vt2qkE1Oax/figures/figures_6_1.jpg", "caption": "Figure 3: Feasibility analysis of Lt. Using a synthetic sequence (left), we vary the amount of noise \u03b7 injected into the mask, the temperature \u03c4 of the mask logits and plot the loss value as a function of the mask under/over segmentation. The plots show that the loss is reduced in low-noise, low-entropy settings and penalises both over- and under-segmentation.", "description": "This figure shows the results of a feasibility study on the proposed trajectory loss (Lt).  Using a synthetic video sequence, the authors varied three factors: noise added to the segmentation masks (\u03b7), temperature of the mask logits (\u03c4), and the degree of under/over-segmentation (number of objects merged or split). The plots show how the trajectory loss changes with these alterations, demonstrating that the loss is minimized when masks have low noise and entropy (\u03c4 = 0, \u03b7 = 0) and penalizes deviations such as merging or splitting object masks.", "section": "Feasibility study"}, {"figure_path": "vt2qkE1Oax/figures/figures_8_1.jpg", "caption": "Figure 4: Qualitative comparison of our results on DAVIS with RCF which uses higher resolution and multi-stage training. Our method contains slightly better boundaries, does not segment shadows and separates water ripples from the swan.", "description": "This figure compares the qualitative results of the proposed method against the state-of-the-art RCF method on the DAVIS dataset.  The comparison highlights that the proposed method, despite using lower resolution, achieves slightly better boundary segmentation and avoids incorrectly segmenting shadows or water ripples, demonstrating its effectiveness in unsupervised video object segmentation.", "section": "5.2 Unsupervised video object segmentation"}, {"figure_path": "vt2qkE1Oax/figures/figures_15_1.jpg", "caption": "Figure 4: Qualitative comparison of our results on DAVIS with RCF which uses higher resolution and multi-stage training. Our method contains slightly better boundaries, does not segment shadows and separates water ripples from the swan.", "description": "This figure compares the qualitative results of the proposed method with the state-of-the-art multi-stage method RCF on the DAVIS dataset. The comparison shows that the proposed method achieves better segmentation results, particularly in terms of boundary precision and the ability to avoid segmenting irrelevant elements such as shadows and water ripples.", "section": "5.2 Unsupervised video object segmentation"}, {"figure_path": "vt2qkE1Oax/figures/figures_15_2.jpg", "caption": "Figure 3: Feasibility analysis of Lt. Using a synthetic sequence (left), we vary the amount of noise \u03b7 injected into the mask, the temperature \u03c4 of the mask logits and plot the loss value as a function of the mask under/over segmentation. The plots show that the loss is reduced in low-noise, low-entropy settings and penalises both over- and under-segmentation.", "description": "This figure shows the results of a feasibility study on the proposed trajectory loss (Lt).  Using a synthetic dataset with ground truth trajectories and segmentation masks, the authors systematically introduced noise and structural errors into the masks (under/over-segmentation).  The plots illustrate how the trajectory loss changes with varying levels of noise (\u03b7), temperature (\u03c4), and structural errors in the masks, demonstrating its sensitivity to these factors and preference for accurate segmentations.", "section": "Feasibility study"}, {"figure_path": "vt2qkE1Oax/figures/figures_16_1.jpg", "caption": "Figure 8: Example mask structural mask alteration showing modification used to approximate under-segmentation. The parameter s controls the number of objects set to the background.", "description": "This figure shows example masks with structural alterations that simulate under-segmentation. The parameter 's' controls how many objects are removed from the mask and set to the background. The alteration is applied in a systematic way.  's = -4' represents significant under-segmentation, while 's = 0' shows the original mask. This visualization helps demonstrate the impact of under-segmentation on the loss function in the context of object segmentation using trajectory data.", "section": "4 Feasibility study"}, {"figure_path": "vt2qkE1Oax/figures/figures_16_2.jpg", "caption": "Figure 9: Example structural mask alteration modelling over-segmentation. The parameter s controls the number if objects split into two at random.", "description": "This figure shows an example of a structural mask alteration used to simulate over-segmentation.  The alteration splits existing object masks into two parts along either the x or y-axis at random.  The parameter 's' controls the number of such splits, with s=0 representing no alteration and increasing values of 's' resulting in increasingly fragmented masks.", "section": "Feasibility study"}]