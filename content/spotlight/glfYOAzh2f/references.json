{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Language models are unsupervised multitask learners", "publication_date": "2019-00-00", "reason": "This paper introduces the foundational concept of generative language models (GLMs) as unsupervised multitask learners, which is the basis of the current research on GLMs."}, {"fullname_first_author": "Tom B. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-00-00", "reason": "This paper demonstrates the few-shot learning capabilities of large language models, which is a key property exploited in many GLM applications and is relevant to controlling the uncertainty of GLM outputs."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "publication_date": "2023-00-00", "reason": "This paper introduces LLaMA, a family of open and efficient foundation language models, which provides a practical and efficient alternative to existing closed-source GLMs and advances the research on controlling the uncertainty of GLM outputs."}, {"fullname_first_author": "Yonatan Geifman", "paper_title": "Selective classification for deep neural networks", "publication_date": "2017-00-00", "reason": "This paper introduces the concept of selective prediction which is a key method to control the false discovery rate by abstaining from returning answers when a model is uncertain of its prediction, which is highly relevant to mitigating the hallucination problem in GLMs."}, {"fullname_first_author": "Vladimir Vovk", "paper_title": "Algorithmic learning in a random world", "publication_date": "2005-00-00", "reason": "This book introduces conformal prediction, a fundamental theoretical framework for quantifying model uncertainty and providing prediction sets with probabilistic guarantees, which is used in this paper to control the false discovery rate of GLM outputs."}]}