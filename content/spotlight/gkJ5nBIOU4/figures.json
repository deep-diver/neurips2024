[{"figure_path": "gkJ5nBIOU4/figures/figures_4_1.jpg", "caption": "Figure 1: Experiments on the quadratic optimization problem from Section 6. We plot the norm of the gradient w.r.t. # of coordinates sent from the server to the workers.", "description": "This figure displays the results of experiments on a quadratic optimization problem.  Three different scenarios with varying numbers of workers (n=10, n=100, n=1000) are compared.  The y-axis represents the squared norm of the gradient (||\u2207f(x)||\u00b2), a measure of the algorithm's convergence. The x-axis shows the number of coordinates transmitted from the server to the workers, representing the communication cost. Multiple algorithms (GD, EF21-P, and various versions of MARINA-P) are plotted for comparison, illustrating the efficiency of the proposed MARINA-P in reducing communication complexity, especially as the number of workers increases.", "section": "6 Experimental Highlights"}, {"figure_path": "gkJ5nBIOU4/figures/figures_9_1.jpg", "caption": "Figure 1: Experiments on the quadratic optimization problem from Section 6. We plot the norm of the gradient w.r.t. # of coordinates sent from the server to the workers.", "description": "This figure shows the results of experiments on a quadratic optimization problem.  The y-axis represents the squared norm of the gradient (||\u2207f(x)||\u00b2), a measure of how far the current solution is from a stationary point. The x-axis shows the number of bits per worker sent from the server to the workers (bits/n (s-to-w)).  Different lines represent different algorithms: GD (Gradient Descent), EF21-P (a previous compressed gradient method), and MARINA-P (the proposed method) with various compression techniques (SameRandK, RandK, and PermK). The three subplots (n=10, n=100, n=1000) show how the performance of the algorithms change with the number of workers (n).  The figure demonstrates that MARINA-P, especially with PermK compressors, achieves faster convergence using significantly fewer bits per worker, particularly as the number of workers increases.", "section": "Experimental Highlights"}, {"figure_path": "gkJ5nBIOU4/figures/figures_50_1.jpg", "caption": "Figure 2: Experiments on the quadratic optimization problem from Section F.1. We plot the norm of the gradient w.r.t. # of coordinates sent from the server (s-to-w) and from the workers (w-to-s).", "description": "The figure shows the convergence performance of the M3 and CORE algorithms on a quadratic optimization problem.  Two plots are presented: one showing the norm of the gradient against the number of bits transmitted from the server to the workers, and another showing the same metric against bits transmitted from workers to the server.  Different curves represent different numbers of workers (10, 100, and 1000) for each algorithm. The plots illustrate the communication complexity of each method.  M3 shows consistently better convergence than CORE, and demonstrates that the efficiency of M3 improves with increasing number of workers.", "section": "F.1 Experiments with M3 on quadratic optimization tasks"}, {"figure_path": "gkJ5nBIOU4/figures/figures_50_2.jpg", "caption": "Figure 1: Experiments on the quadratic optimization problem from Section 6. We plot the norm of the gradient w.r.t. # of coordinates sent from the server to the workers.", "description": "This figure presents experimental results on a quadratic optimization problem.  It compares the convergence rate of several distributed optimization algorithms (GD, MARINA-P with various compressors (SameRand, Rand, Perm), and EF21-P) in terms of the norm of the gradient against the number of bits communicated from the server to the workers (bits/n s-to-w). The results are shown for different numbers of workers (n=10, 100, 1000) to illustrate how communication complexity scales with the number of workers.  The x-axis represents the communication cost in bits per worker, while the y-axis shows the norm of the gradient at each iteration. This allows for evaluating the convergence speed of each algorithm under different communication constraints.", "section": "Experimental Highlights"}, {"figure_path": "gkJ5nBIOU4/figures/figures_52_1.jpg", "caption": "Figure 1: Experiments on the quadratic optimization problem from Section 6. We plot the norm of the gradient w.r.t. # of coordinates sent from the server to the workers.", "description": "This figure displays the results of experiments on a quadratic optimization problem.  Three different worker counts (n = 10, 100, 1000) are used, with various compression techniques compared against gradient descent (GD).  The y-axis represents the norm of the gradient, indicating the convergence speed. The x-axis shows the number of coordinates sent from the server to the workers, which directly relates to communication complexity.  The goal is to illustrate how different methods achieve faster convergence with reduced communication.", "section": "Experimental Highlights"}, {"figure_path": "gkJ5nBIOU4/figures/figures_52_2.jpg", "caption": "Figure 1: Experiments on the quadratic optimization problem from Section 6. We plot the norm of the gradient w.r.t. # of coordinates sent from the server to the workers.", "description": "This figure shows the results of experiments on a quadratic optimization problem.  The y-axis represents the norm of the gradient, which measures how close the algorithm is to a solution. The x-axis represents the number of coordinates sent from the server to the workers, indicating the communication cost.  Multiple lines are presented, each representing a different algorithm (GD, EF21-P, and MARINA-P with various compression strategies). This allows for a comparison of the convergence speed and communication efficiency of each algorithm.", "section": "Experimental Highlights"}, {"figure_path": "gkJ5nBIOU4/figures/figures_53_1.jpg", "caption": "Figure 4: Experiments on the quadratic optimization problem from Section F.3 with n = 10 for L \u2208 {0, 1, 10, 100} and L\u00b2 \u2208 {100, 1000, 10000, 100000}.", "description": "The figure shows the results of experiments on a quadratic optimization problem.  Different algorithms (GD, EF21-P, MARINA-P with various compressors) are compared based on the norm of the gradient against the number of bits sent from the server to the workers.  The experiments are conducted with 10 workers, varying the smoothness parameter (L) and heterogeneity parameter (L\u00b2) across different experimental settings. The goal is to show the impact of different parameters and algorithms on the optimization process, particularly highlighting the performance of MARINA-P with PermK compressors.", "section": "F Experiments"}, {"figure_path": "gkJ5nBIOU4/figures/figures_53_2.jpg", "caption": "Figure 1: Experiments on the quadratic optimization problem from Section 6. We plot the norm of the gradient w.r.t. # of coordinates sent from the server to the workers.", "description": "This figure presents the results of experiments on a quadratic optimization problem.  It compares the convergence speed (measured by the norm of the gradient) of several distributed optimization algorithms against the number of bits communicated from the server to the workers.  The algorithms include gradient descent (GD), EF21-P with different TopK compressors (Top1, Top3, Top30), and MARINA-P with various compressor types (Rand1, Rand3, Rand30, Perm3, Perm30, SameRand1, SameRand3, SameRand30).  Different numbers of workers (n=10, n=100, n=1000) are tested to demonstrate how scaling impacts the communication complexity.", "section": "6 Experimental Highlights"}]