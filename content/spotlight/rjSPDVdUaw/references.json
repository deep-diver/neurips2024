{"references": [{"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-00-00", "reason": "This paper introduced the Vision Transformer (ViT), a foundational model for many of the visual tasks discussed in the target paper, establishing transformers as a viable architecture for image processing."}, {"fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-00-00", "reason": "This paper details DINO, a self-supervised learning method for vision transformers that serves as a key baseline and comparison point for the proposed MooG method."}, {"fullname_first_author": "Nicolas Carion", "paper_title": "End-to-end object detection with transformers", "publication_date": "2020-00-00", "reason": "This work introduced DETR, demonstrating the effectiveness of transformers for object detection, which is relevant to the object-centric aspect of MooG."}, {"fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-00-00", "reason": "This paper introduced MAE, a masked image modeling technique that is highly influential in self-supervised visual representation learning, impacting the design choices and benchmarks within the target paper."}, {"fullname_first_author": "Andrew Jaegle", "paper_title": "Perceiver: General perception with iterative attention", "publication_date": "2021-00-00", "reason": "The Perceiver model, introduced in this paper, shares conceptual similarities with MooG in its use of a large set of latent tokens to represent scenes, making it a relevant comparison and source of inspiration."}]}