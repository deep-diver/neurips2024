[{"figure_path": "OycU0bAus6/figures/figures_1_1.jpg", "caption": "Figure 1: A brief description of our idea. (a) A typical denoising model for generative tasks recursively applies a denoising layer. (b) A naive idea that applies a denoising strategy to a discriminative model is applying a recursive denoise layer on the feature of a backbone and taking extra inference latency. (c,d) Our DenoiseRep first unifies the frameworks of feature extraction and denoising in a backbone pipeline, then merges parameters of the denoising layers into embedding layers, making the feature more discriminative without extra latency cost.", "description": "This figure illustrates the core idea of DenoiseRep. (a) shows a standard denoising model used in generative tasks. (b) demonstrates a naive approach of applying denoising to discriminative models, which introduces extra computational cost. (c) and (d) present the DenoiseRep approach, which integrates feature extraction and denoising within the backbone, making the features more discriminative without additional computational overhead. DenoiseRep merges the parameters of the denoising layers into the embedding layers.", "section": "1 Introduction"}, {"figure_path": "OycU0bAus6/figures/figures_4_1.jpg", "caption": "Figure 2: Pipeline of our proposed DenoiseRep. ViT consists of N cascaded transformer encoder layers. During the training phase (see the right side \u201cTrain Only\u201d process), we freeze the backbone parameters and only train the extra denoising layers. In the inference stage (see the left side \"Infer Only\" process), we merge the parameters of denoising layers to corresponding encoder layers. So there is no extra inference latency cost. Please find definitions of W, b, WD, W', i and b' in Algorithm 2.", "description": "This figure illustrates the architecture of DenoiseRep, a model that integrates feature extraction and denoising.  During training, the backbone (ViT) is frozen, and only the added denoising layers are trained.  During inference, the parameters from these denoising layers are merged with the backbone's parameters, resulting in a computation-free improvement in feature discrimination. The figure highlights the \"Train Only\" and \"Infer Only\" pathways for the separate training and inference stages.", "section": "3 DenoiseRep: Denoising Model for Representation Learning"}]