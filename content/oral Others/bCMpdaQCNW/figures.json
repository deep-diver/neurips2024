[{"figure_path": "bCMpdaQCNW/figures/figures_1_1.jpg", "caption": "Figure 1: We introduce YESBUT dataset for comic understanding of juxtaposed comic panels. Given a two-panel comic with a contradictory narrative, we propose several tasks including narrative understanding, underlying philosophy selection and title matching, tackling different levels of comic understanding. (Comic by Anton Gudim).", "description": "This figure introduces the YESBUT dataset, a benchmark for evaluating AI's ability to understand comics with contradictory narratives.  It shows an example comic with two panels creating a humorous contradiction (a driver stops for ducks but then goes to a Peking Duck restaurant).  The caption highlights that the dataset includes tasks assessing different levels of understanding: literal comprehension, narrative reasoning, philosophy identification, and title matching.", "section": "1 Introduction"}, {"figure_path": "bCMpdaQCNW/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of the data construction pipeline. Pos represents the positive options, and Neg stands for the negative options.", "description": "This figure illustrates the data annotation pipeline used in the YESBUT dataset creation.  It details the three steps involved: 1) Narrative Description Writing (including literal description and contradiction identification), 2) Deep Content Writing (including underlying philosophies and title generation), and 3) Quality Check (ensuring bias reduction, length control, style consistency and readability). The figure shows example annotations for each component, highlighting positive (Pos) and negative (Neg) options for the underlying philosophy and title selection tasks.  This visual representation clearly outlines the multi-stage process of generating high-quality annotations for the YESBUT dataset, emphasizing both human and AI collaboration.", "section": "3.2 Data Annotation"}, {"figure_path": "bCMpdaQCNW/figures/figures_6_1.jpg", "caption": "Figure 3: Human Evaluation on literal description and contradiction generation.", "description": "This figure presents the results of a human evaluation assessing the quality of literal descriptions and contradiction generations produced by different vision language models.  The evaluation metrics used were Correctness, Completeness, and Faithfulness for literal descriptions, and Correctness and Faithfulness for contradiction generation.  The bars represent the average scores for each model across these metrics.  The figure visually demonstrates the relative performance of various models on these two tasks, indicating variations in their ability to accurately and comprehensively capture the narrative nuances and contradictory elements in comic strips.", "section": "5.1 Narrative Understanding Tasks"}, {"figure_path": "bCMpdaQCNW/figures/figures_7_1.jpg", "caption": "Figure 4: LLMs using different image description as input.", "description": "This figure displays the results of experiments using different Large Language Models (LLMs) with varying image descriptions as input.  The x-axis shows the different LLMs used: Mistral-7B, Llama3-8B, and ChatGPT. The y-axis represents the accuracy percentages for both Philosophy Selection and Title Matching tasks.  The bars for each LLM represent three conditions: using the LLaVA1.6-7B generated descriptions, the LLaVA1.6-13B generated descriptions, and finally, using human-written oracle descriptions. The figure demonstrates how the quality of the input description affects the performance of LLMs in the deep reasoning tasks.", "section": "6.1 How Does Literal Understanding of the Comic Influence Deep Reasoning?"}, {"figure_path": "bCMpdaQCNW/figures/figures_7_2.jpg", "caption": "Figure 5: VLMs with image only input and image + oracle description as inputs.", "description": "This figure displays the results of experiments evaluating the performance of various Vision-Language Models (VLMs) on two tasks: Underlying Philosophy Selection and Title Matching.  Two sets of results are shown for each model. The first uses only the image as input to the model. The second uses both the image and a human-written, 'oracle', description of the comic's literal narrative as input.  The bar chart shows that in both tasks, augmenting the model input with the oracle description significantly improves the model's accuracy.", "section": "5.1 Narrative Understanding Tasks"}, {"figure_path": "bCMpdaQCNW/figures/figures_8_1.jpg", "caption": "Figure 1: We introduce YESBUT dataset for comic understanding of juxtaposed comic panels. Given a two-panel comic with a contradictory narrative, we propose several tasks including narrative understanding, underlying philosophy selection and title matching, tackling different levels of comic understanding. (Comic by Anton Gudim).", "description": "This figure introduces the YESBUT dataset, a benchmark for evaluating AI models' ability to understand comics with contradictory narratives.  It shows an example comic with two panels creating a humorous contradiction (a driver stopping for ducks, then going to a Peking Duck restaurant).  The caption highlights that the dataset includes tasks assessing different levels of comprehension, from literal understanding to deeper narrative reasoning.  These tasks include writing a literal description, identifying the contradiction, selecting the underlying philosophy, and matching the comic with an appropriate title.", "section": "3 The YESBUT Dataset"}, {"figure_path": "bCMpdaQCNW/figures/figures_15_1.jpg", "caption": "Figure 1: We introduce YESBUT dataset for comic understanding of juxtaposed comic panels. Given a two-panel comic with a contradictory narrative, we propose several tasks including narrative understanding, underlying philosophy selection and title matching, tackling different levels of comic understanding. (Comic by Anton Gudim).", "description": "This figure introduces the YESBUT dataset, which contains comics with two panels that create humorous contradictions.  The dataset is designed to assess AI's ability to understand humor through juxtaposition.  The example comic shows a driver stopping for ducks to cross the road (Yes), then going to a Peking Duck restaurant (But), highlighting the contradiction between showing compassion for live ducks and consuming them as food.  Three tasks evaluate AI performance: understanding the narrative, selecting the underlying philosophy, and matching a title to the comic.", "section": "3 The YESBUT Dataset"}, {"figure_path": "bCMpdaQCNW/figures/figures_16_1.jpg", "caption": "Figure 1: We introduce YESBUT dataset for comic understanding of juxtaposed comic panels. Given a two-panel comic with a contradictory narrative, we propose several tasks including narrative understanding, underlying philosophy selection and title matching, tackling different levels of comic understanding. (Comic by Anton Gudim).", "description": "The figure shows a sample comic from the YESBUT dataset, which is used to evaluate AI models' ability to understand humor in comics using juxtaposition.  The comic consists of two panels that present a contradictory narrative, creating a humorous effect. The figure also illustrates the different tasks included in the YESBUT benchmark. These tasks assess AI capabilities in recognizing and interpreting the humor in the comic, at varying levels of difficulty, from literal content comprehension to deep narrative reasoning.  The tasks range from generating a description of the literal content to identifying the underlying philosophical theme or title that best fits the comic's overall meaning.", "section": "3 The YESBUT Dataset"}, {"figure_path": "bCMpdaQCNW/figures/figures_18_1.jpg", "caption": "Figure 1: We introduce YESBUT dataset for comic understanding of juxtaposed comic panels. Given a two-panel comic with a contradictory narrative, we propose several tasks including narrative understanding, underlying philosophy selection and title matching, tackling different levels of comic understanding. (Comic by Anton Gudim).", "description": "This figure introduces the YESBUT dataset, which is a benchmark for evaluating AI models' ability to understand humor in comics. The dataset consists of two-panel comics with contradictory narratives. The figure shows an example comic, along with descriptions of tasks designed to assess different levels of comprehension\u2014from literal understanding to deeper narrative reasoning.", "section": "3 The YESBUT Dataset"}, {"figure_path": "bCMpdaQCNW/figures/figures_18_2.jpg", "caption": "Figure 1: We introduce YESBUT dataset for comic understanding of juxtaposed comic panels. Given a two-panel comic with a contradictory narrative, we propose several tasks including narrative understanding, underlying philosophy selection and title matching, tackling different levels of comic understanding. (Comic by Anton Gudim).", "description": "This figure introduces the YESBUT dataset, which contains comics with two panels that present contradictory narratives.  The example comic shows a driver stopping for ducks to cross the road (panel 1, \"Yes\") and then going to a Peking Duck restaurant (panel 2, \"But\"), highlighting a humorous contradiction. The dataset is used to assess AI models' ability to understand humor from juxtaposition in comics.  The figure also details three tasks designed to evaluate different levels of comprehension: narrative understanding, underlying philosophy selection and title matching. Each task requires a different level of deep reasoning and understanding of the comic.", "section": "3 The YESBUT Dataset"}, {"figure_path": "bCMpdaQCNW/figures/figures_19_1.jpg", "caption": "Figure 1: We introduce YESBUT dataset for comic understanding of juxtaposed comic panels. Given a two-panel comic with a contradictory narrative, we propose several tasks including narrative understanding, underlying philosophy selection and title matching, tackling different levels of comic understanding. (Comic by Anton Gudim).", "description": "This figure introduces the YESBUT dataset, which contains comics with two panels that create a humorous contradiction.  The dataset is used to assess AI models' ability to understand this type of humor. The caption highlights that the dataset is used for evaluating AI's capabilities in various tasks, including narrative understanding, selecting the underlying philosophy, and title matching, thus testing different levels of comic comprehension.", "section": "3 The YESBUT Dataset"}]