[{"figure_path": "TFZlFRl9Ks/figures/figures_0_1.jpg", "caption": "Figure 1: CAT3D enables 3D scene creation from any number of generated or real images.", "description": "This figure shows three examples of 3D scene generation using CAT3D. The first example shows a text-to-image-to-3D pipeline where a text prompt (\"a shiny silver robot cat\") is used to generate an image, which is then used to generate a 3D model. The second example shows a real image to 3D pipeline where a single real image of a dog is used to generate a 3D model. The third example shows a sparse multi-view to 3D pipeline where multiple real images of a bonsai tree are used to generate a 3D model. Each example shows the input images and the resulting 3D model.", "section": "1 Introduction"}, {"figure_path": "TFZlFRl9Ks/figures/figures_2_1.jpg", "caption": "Figure 2: Qualitative results (renders): CAT3D can create high-quality 3D objects or scenes from a number of input modalities: an input image generated by a text-to-image model (top row), a single captured real image (middle row), and multiple captured real images (bottom row).", "description": "This figure showcases the qualitative results of 3D models generated by CAT3D from different input modalities. The top row demonstrates the generation from a text-to-image model, showcasing the ability to create 3D objects from textual descriptions. The middle row presents the results from a single captured real image, highlighting the system's capability in reconstructing 3D scenes from limited input. Finally, the bottom row illustrates the generation from multiple captured real images, demonstrating the system's robustness and ability to produce high-quality 3D models even with dense input data.", "section": "3 Method"}, {"figure_path": "TFZlFRl9Ks/figures/figures_4_1.jpg", "caption": "Figure 3: Illustration of the method. Given one to many views, CAT3D creates a 3D representation of the scene in as little as one minute. CAT3D has two stages: (1) generate a large set of synthetic views with a multi-view latent diffusion model conditioned on the input views and target poses; (2) run a robust 3D reconstruction pipeline on the observed and generated views. This decoupling of the generative prior and 3D reconstruction process results in efficiency improvements and reduced methodological complexity relative to prior work [7, 8, 42], while also improving visual quality.", "description": "This figure illustrates the two-stage process of CAT3D for 3D scene creation.  Stage 1 uses a multi-view latent diffusion model to generate a large number of synthetic views consistent with the input views (one or more).  These generated views, along with the original observed views, are then fed into a robust 3D reconstruction pipeline (stage 2) to produce a final 3D model. The separation of the generation and reconstruction steps improves efficiency and reduces complexity compared to previous methods.", "section": "3 Method"}, {"figure_path": "TFZlFRl9Ks/figures/figures_6_1.jpg", "caption": "Figure 4: Qualitative comparison, few-view reconstruction (renders). A comparison of rendered reconstructions on scenes from mip-NeRF 36 (top row) and CO3D (bottom row), given 3 input captured views. Compared to ReconFusion [7], CAT3D better aligns with ground-truth in seen regions, while hallucinating plausible content in unseen regions. See supplemental website for additional comparisons.", "description": "This figure compares the 3D reconstruction results of CAT3D with those of ReconFusion [7], a state-of-the-art method, using three input views. The top row shows scenes from the mip-NeRF 36 dataset, while the bottom row shows scenes from the CO3D dataset.  CAT3D demonstrates improved accuracy in reconstructing visible parts of the scenes and better hallucination of unseen areas compared to ReconFusion. ", "section": "4 Experiments"}, {"figure_path": "TFZlFRl9Ks/figures/figures_7_1.jpg", "caption": "Figure 4: Qualitative comparison, few-view reconstruction (renders). A comparison of rendered reconstructions on scenes from mip-NeRF 36 (top row) and CO3D (bottom row), given 3 input captured views. Compared to ReconFusion [7], CAT3D better aligns with ground-truth in seen regions, while hallucinating plausible content in unseen regions. See supplemental website for additional comparisons.", "description": "This figure compares the 3D reconstruction results of CAT3D with ReconFusion on two datasets (mip-NeRF 36 and CO3D) using only 3 input views.  It showcases CAT3D's ability to produce more accurate reconstructions in visible areas of the scene while also generating plausible details in unseen areas, surpassing the performance of the ReconFusion method.", "section": "4 Experiments"}, {"figure_path": "TFZlFRl9Ks/figures/figures_8_1.jpg", "caption": "Figure 5: 3D creation from single input images. Renderings of 3D models from CAT3D (middle row) are higher quality than baselines (bottom row) for scenes, and competitive for objects. Note that scale ambiguity amplifies the differences in renderings between methods. See supplemental website for additional comparisons.", "description": "This figure compares the 3D reconstruction results of CAT3D against several baselines (RealmDreamer, ZeroNVS, ImageDream, and DreamCraft3D) when using a single input image.  The top row shows the input images. The middle row displays the results generated by CAT3D, showcasing its ability to generate high-quality 3D models for both scenes and objects. The bottom row presents the results from the baseline methods, highlighting the superior quality of CAT3D's output, especially in the scene reconstructions. The differences are amplified by the scale ambiguity that can exist when generating 3D objects from single images. More comparisons can be found on the supplemental website.", "section": "4.2 Single image to 3D"}, {"figure_path": "TFZlFRl9Ks/figures/figures_17_1.jpg", "caption": "Figure 6: Qualitative comparison of 3D reconstruction design choices. Rendered images (left) and depth maps (right) of a Mip-NeRF 360 scene under different settings: (a) 720 generated views along multiple orbital paths, (b) 80 generated views on a single orbital path, and (c) 720 views, without the perceptual (LPIPS) loss.", "description": "This figure shows a qualitative comparison of the 3D reconstruction results obtained using different numbers of generated views and with/without the perceptual loss.  The left column displays rendered images, while the right shows depth maps.  It highlights how increasing the number of generated views (from 80 to 720) and including the perceptual loss improves the quality of 3D reconstruction.", "section": "A Ablations"}, {"figure_path": "TFZlFRl9Ks/figures/figures_18_1.jpg", "caption": "Figure 3: Illustration of the method. Given one to many views, CAT3D creates a 3D representation of the scene in as little as one minute. CAT3D has two stages: (1) generate a large set of synthetic views with a multi-view latent diffusion model conditioned on the input views and target poses; (2) run a robust 3D reconstruction pipeline on the observed and generated views. This decoupling of the generative prior and 3D reconstruction process results in efficiency improvements and reduced methodological complexity relative to prior work [7, 8, 42], while also improving visual quality.", "description": "This figure illustrates the two-stage process of CAT3D. First, a multi-view diffusion model generates a large number of synthetic views from one or more input views and their camera poses. Second, a robust 3D reconstruction pipeline processes both the original and generated views to produce a 3D representation of the scene.  The decoupling of generation and reconstruction improves efficiency and reduces complexity compared to previous methods.", "section": "3 Method"}, {"figure_path": "TFZlFRl9Ks/figures/figures_19_1.jpg", "caption": "Figure 8: Camera trajectories for generating novel views. Within each panel, left shows the side view and right shows the top view of the trajectories, colored by indices of views. (a)-(b): two types of trajectories used by single image to 3D. Observed view is highlighted in red, while anchor views are highlighted in orange. (c)-(g): trajectories used by 3D reconstruction. 3 input views are highlighted in red.", "description": "This figure visualizes the camera trajectories used for generating novel views in the CAT3D model. Different camera paths are used depending on the input type (single image vs. multiple views) and dataset.  The left and right subplots of each panel show side and top views of the trajectories, respectively, with colors representing the view indices. The observed input views are highlighted in red, and anchor views (for single-image scenarios) are shown in orange.", "section": "3.2 Generating Novel Views"}]