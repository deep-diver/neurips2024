[{"figure_path": "135eKqDoRR/tables/tables_5_1.jpg", "caption": "Table 1: Performance comparison of gradient-free output LM methods (mean % \u00b1 std %). Ours are highlighted and the highest accuracy is in bold (with deep learning-based LM in gray for reference)", "description": "This table compares the performance of different gradient-free output label mapping methods, including the proposed BLM and BLM+, against existing methods (RLM, FLM, ILM) and a deep learning-based approach.  The results are shown for various datasets and for both ResNet-18 (pretrained on ImageNet) and ResNeXt-101-32x8d (pretrained on Instagram) as the pretrained models.  The table highlights the accuracy and standard deviation for each method on each dataset, indicating the superior performance of BLM and BLM+ in many cases.", "section": "5 Experiments"}, {"figure_path": "135eKqDoRR/tables/tables_6_1.jpg", "caption": "Table 1: Performance comparison of gradient-free output LM methods (mean % \u00b1 std %). Ours are highlighted and the highest accuracy is in bold (with deep learning-based LM in gray for reference)", "description": "This table presents the comparison results of different gradient-free output label mapping methods. The table shows the performance (mean accuracy \u00b1 standard deviation) of different methods on twelve different datasets using two different pretrained models (ResNet-18 and ResNeXt-101-32x8d).  The results are shown separately for padding-based input VR.  The highest accuracy for each dataset is shown in bold.  The results for a deep learning-based method are shown in gray for comparison.", "section": "5 Experiments"}, {"figure_path": "135eKqDoRR/tables/tables_6_2.jpg", "caption": "Table 1: Performance comparison of gradient-free output LM methods (mean % \u00b1 std %). Ours are highlighted and the highest accuracy is in bold (with deep learning-based LM in gray for reference)", "description": "This table presents a comparison of different gradient-free output label mapping methods for visual reprogramming, including the proposed BLM and BLM+ methods.  It shows the average accuracy and standard deviation across twelve benchmark datasets for padding-based visual reprogramming using ResNet-18 and ResNeXt-101-32x8d pretrained models. The table highlights the superior performance of the proposed BLM and BLM+ methods compared to existing methods (RLM, FLM, ILM) and also includes results from deep learning-based methods for comparison.", "section": "5 Experiments"}, {"figure_path": "135eKqDoRR/tables/tables_7_1.jpg", "caption": "Table 1: Performance comparison of gradient-free output LM methods (mean % \u00b1 std %). Ours are highlighted and the highest accuracy is in bold (with deep learning-based LM in gray for reference)", "description": "This table presents a comparison of different gradient-free output label mapping methods for visual reprogramming.  It shows the mean accuracy (with standard deviation) achieved by various methods (RLM, FLM, ILM, BLM, and BLM+) on 12 different datasets using ResNet-18 and ResNeXt-101-32x8d pretrained models.  The results are shown separately for padding-based and watermarking-based visual reprogramming. The highest accuracy for each dataset and method is highlighted in bold. For comparison, results using deep learning-based methods are also included in gray.", "section": "5 Experiments"}, {"figure_path": "135eKqDoRR/tables/tables_16_1.jpg", "caption": "Table 1: Performance comparison of gradient-free output LM methods (mean % \u00b1 std %). Ours are highlighted and the highest accuracy is in bold (with deep learning-based LM in gray for reference)", "description": "This table compares the performance of different gradient-free output label mapping methods, including the proposed BLM and BLM+, against existing methods like RLM, FLM, and ILM.  The comparison is done across various datasets using two different input visual reprogramming methods (padding and watermarking) and two different pretrained vision models (ResNet-18 and ResNeXt-101-32x8d).  The table shows the mean accuracy and standard deviation for each method on each dataset, highlighting the best-performing method in bold. Deep learning-based methods are also included for a comparative reference, shown in gray.", "section": "5 Experiments"}, {"figure_path": "135eKqDoRR/tables/tables_17_1.jpg", "caption": "Table 1: Performance comparison of gradient-free output LM methods (mean % \u00b1 std %). Ours are highlighted and the highest accuracy is in bold (with deep learning-based LM in gray for reference)", "description": "This table compares the performance of different gradient-free output label mapping methods, including RLM, FLM, ILM, BLM, and BLM+, on various downstream tasks using ResNet-18 and ResNeXt-101-32x8d pretrained models.  The results are presented as mean accuracy \u00b1 standard deviation across multiple runs. The table highlights the superior performance of the proposed BLM and BLM+ methods, with the highest accuracy values shown in bold.  Deep learning based methods are also included for comparison.", "section": "5 Experiments"}, {"figure_path": "135eKqDoRR/tables/tables_23_1.jpg", "caption": "Table 1: Performance comparison of gradient-free output LM methods (mean % \u00b1 std %). Ours are highlighted and the highest accuracy is in bold (with deep learning-based LM in gray for reference)", "description": "This table compares the performance of different gradient-free output label mapping methods for visual reprogramming.  It shows the average accuracy (mean \u00b1 standard deviation) across twelve different datasets for both ResNet-18 and ResNeXt-101 pretrained models. The methods compared include Random Label Mapping (RLM), Frequent Label Mapping (FLM), Iterative Label Mapping (ILM), Bayesian-guided Label Mapping (BLM), and Bayesian-guided Label Mapping+ (BLM+).  The table highlights the superior performance of BLM and BLM+ compared to existing methods. Deep learning-based methods are included in grey for additional context.", "section": "5 Experiments"}, {"figure_path": "135eKqDoRR/tables/tables_23_2.jpg", "caption": "Table 1: Performance comparison of gradient-free output LM methods (mean % \u00b1 std %). Ours are highlighted and the highest accuracy is in bold (with deep learning-based LM in gray for reference)", "description": "This table presents the performance comparison of different gradient-free output label mapping methods, including the proposed BLM and BLM+, against existing methods like RLM, FLM, and ILM.  The results are shown for two different pretrained models (ResNet-18 and ResNeXt-101-32x8d) and two input VR methods (padding and watermarking) across 12 benchmark datasets. The highest accuracy for each dataset and method is highlighted in bold, providing a clear view of the relative performance improvements achieved by BLM and BLM+. Deep learning based methods are also shown for comparison.", "section": "5 Experiments"}, {"figure_path": "135eKqDoRR/tables/tables_24_1.jpg", "caption": "Table 1: Performance comparison of gradient-free output LM methods (mean % \u00b1 std %). Ours are highlighted and the highest accuracy is in bold (with deep learning-based LM in gray for reference)", "description": "This table compares the performance of different gradient-free output label mapping methods (RLM, FLM, ILM, BLM, BLM+) for visual reprogramming on 12 datasets using ResNet-18 and ResNeXt-101-32x8d pretrained models.  The table shows the average accuracy and standard deviation for each method on each dataset, highlighting the proposed BLM and BLM+ methods in bold when they achieve the highest accuracy.  A comparison to deep learning-based methods is also included in gray.", "section": "5 Experiments"}, {"figure_path": "135eKqDoRR/tables/tables_26_1.jpg", "caption": "Table 1: Performance comparison of gradient-free output LM methods (mean % \u00b1 std %). Ours are highlighted and the highest accuracy is in bold (with deep learning-based LM in gray for reference)", "description": "This table compares the performance of different gradient-free output label mapping methods, including the proposed BLM and BLM+, against existing methods like RLM, FLM, and ILM.  The results are presented as the mean accuracy and standard deviation across twelve different datasets, using two different pretrained models (ResNet-18 and ResNeXt-101-32x8d). The table is split to show results with padding-based input visual reprogramming and watermarking-based input visual reprogramming.  The highest accuracy for each dataset is highlighted in bold, providing a clear comparison of the effectiveness of the proposed BLM and BLM+ methods compared to the baselines. Deep learning-based methods are included in gray for additional context.", "section": "5 Experiments"}, {"figure_path": "135eKqDoRR/tables/tables_26_2.jpg", "caption": "Table 1: Performance comparison of gradient-free output LM methods (mean % \u00b1 std %). Ours are highlighted and the highest accuracy is in bold (with deep learning-based LM in gray for reference)", "description": "This table compares the performance of various gradient-free output label mapping (LM) methods, including the proposed Bayesian-guided Label Mapping (BLM) and its enhanced version (BLM+), against existing methods like Random Label Mapping (RLM), Frequent Label Mapping (FLM), and Iterative Label Mapping (ILM).  The results are shown for two different pretrained models (ResNet-18 and ResNeXt-101) across twelve different downstream datasets, using the padding-based visual reprogramming (VR) method. The table highlights the superior performance of BLM and BLM+ compared to the baselines, demonstrating their effectiveness in improving visual reprogramming performance.", "section": "5 Experiments"}, {"figure_path": "135eKqDoRR/tables/tables_31_1.jpg", "caption": "Table 1: Performance comparison of gradient-free output LM methods (mean % \u00b1 std %). Ours are highlighted and the highest accuracy is in bold (with deep learning-based LM in gray for reference)", "description": "This table compares the performance of different gradient-free output label mapping (LM) methods for visual reprogramming (VR) on 12 different datasets.  The methods compared include Random Label Mapping (RLM), Frequent Label Mapping (FLM), Iterative Label Mapping (ILM), and the proposed Bayesian-guided Label Mapping (BLM) and BLM+.  Results are shown for both padding-based and watermarking-based VR methods, using ResNet-18 and ResNeXt-101-32x8d pretrained models.  The table highlights the superior performance of BLM and BLM+ compared to existing methods across most datasets. Deep learning-based LM results are included for reference, showing that BLM and BLM+ bridge the gap in performance between gradient-free and deep learning-based approaches.", "section": "5 Experiments"}]