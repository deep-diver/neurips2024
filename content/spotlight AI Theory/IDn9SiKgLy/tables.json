[{"figure_path": "IDn9SiKgLy/tables/tables_6_1.jpg", "caption": "Table 1: Kernel-specific bounds (fixed \u03b7 is hidden) where v is the smoothness parameter of the Mat\u00e9rn kernel that is assumed to satisfy v > (3 + d + \u221ad\u00b2 + 14d + 17) = \u0398(d\u00b2).", "description": "This table presents the theoretical upper bounds on cumulative regret (R<sub>Q<sup>f</sup></sub>) and cumulative number of expert queries (Q<sup>g</sup><sub>T</sub>) for different kernel functions used in the Bayesian Optimization algorithm.  The bounds depend on the kernel type (Linear, Squared Exponential, Mat\u00e9rn), the dimension (d) of the problem, and the number of iterations (T).  The Mat\u00e9rn kernel bound additionally depends on the smoothness parameter (v). The table shows how the theoretical convergence rates vary based on the kernel choice, highlighting the trade-offs involved.", "section": "4.3 Related Works"}, {"figure_path": "IDn9SiKgLy/tables/tables_30_1.jpg", "caption": "Table 2: Comparisons between our algorithm with the existing baseline methods.", "description": "This table compares the proposed algorithm with several existing baseline methods across various criteria such as whether they model human experts, the assumptions they make, and the guarantees they provide (no-harm, handover, etc.).  It highlights the unique features of the proposed method, which include considering the no-rankability assumption, providing a continuous domain guarantee, and offering both data-driven trust and handover guarantees.", "section": "Related Works"}, {"figure_path": "IDn9SiKgLy/tables/tables_34_1.jpg", "caption": "Table 3: The complete list of hyperparameters and their settings.", "description": "This table lists all hyperparameters used in the paper, their initial values, whether they are tuned using a data-driven approach, and the tuning method used.  It provides details for hyperparameters related to the Gaussian processes for both the objective function and the expert belief, regularization terms, confidence bounds, and the primal-dual algorithm. This level of detail is important for reproducibility of the results.", "section": "J Experiments"}]