[{"figure_path": "HN05DQxyLl/tables/tables_3_1.jpg", "caption": "Table 1: Adam optimizer parameters used in LMI.", "description": "This table lists the hyperparameters used for the Adam optimizer in the Latent Mutual Information (LMI) approximation method.  It shows the values used for the learning rate, beta1, beta2, and epsilon.", "section": "A.1.2 Implementation of the representation learning architecture"}, {"figure_path": "HN05DQxyLl/tables/tables_15_1.jpg", "caption": "Table 1: Adam optimizer parameters used in LMI.", "description": "This table lists the hyperparameters used for the Adam optimizer in the Latent Mutual Information (LMI) approximation method.  It shows the values used for the learning rate (alpha), beta1, beta2, and epsilon.", "section": "A.1.2 Implementation of the representation learning architecture"}, {"figure_path": "HN05DQxyLl/tables/tables_25_1.jpg", "caption": "Table 2: LMI estimates with varying latent space size, with k dimensions per variable denoted as LMI-k. Data is multivariate Gaussian, generated as in Figure 2, with d = 103, k = 4, and N = 5\u00b7103.", "description": "This table presents the LMI estimates obtained using different latent space sizes (2, 4, 6, and 8 dimensions) for a multivariate Gaussian dataset.  The dataset is generated with 1000 ambient dimensions, 4 intrinsic dimensions, and a ground truth mutual information (MI) of 1 bit, using the method described in Figure 2 of the paper.  The results are compared with MINE and InfoNCE estimates for the same dataset, showcasing how the LMI approximation's accuracy varies with latent space size.", "section": "A.5.2 Heuristic approach to choosing latent space size"}]