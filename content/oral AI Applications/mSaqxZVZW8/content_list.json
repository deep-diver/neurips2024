[{"type": "text", "text": "SeeA\u2217: Efficient Exploration-Enhanced $\\mathbf{A}^{*}$ Search by Selective Sampling ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Dengwei Zhao1, Shikui ${\\mathbf{T}}{\\mathbf{u}}^{1*},$ , Lei $\\mathbf{X}\\mathbf{u}^{1,2*}$ ", "page_idx": 0}, {"type": "text", "text": "1Department of Computer Science and Engineering, Shanghai Jiao Tong University 2Guangdong Institute of Intelligence Science and Technology {zdwccc, tushikui, leixu}@sjtu.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Monte-Carlo tree search (MCTS) and reinforcement learning contributed crucially to the success of AlphaGo and AlphaZero, and $\\mathbf{A}^{*}$ is a tree search algorithm among the most well-known ones in the classical AI literature. MCTS and $\\mathbf{A}^{*}$ both perform heuristic search and are mutually beneficial. Efforts have been made to the renaissance of $\\mathbf{A}^{*}$ from three possible aspects, two of which have been confirmed by studies in recent years, while the third is about the OPEN list that consists of open nodes of $\\mathbf{A}^{*}$ search, but still lacks deep investigation. This paper aims at the third, i.e., developing the Sampling-exploration enhanced $\\mathbf{A}^{*}$ $(\\mathrm{SeeA^{*}})$ search by constructing a dynamic subset of OPEN through a selective sampling process, such that the node with the best heuristic value in this subset instead of in the OPEN is expanded. Nodes with the best heuristic values in OPEN are most probably picked into this subset, but sometimes may not be included, which enables $\\mathrm{{SeeA^{*}}}$ to explore other promising branches. Three sampling techniques are presented for comparative investigations. Moreover, under the assumption about the distribution of prediction errors, we have theoretically shown the superior efficiency of $\\mathrm{{SeeA^{*}}}$ over $\\mathbf{A}^{*}$ search, particularly when the accuracy of the guiding heuristic function is insufficient. Experimental results on retrosynthetic planning in organic chemistry, logic synthesis in integrated circuit design, and the classical Sokoban game empirically demonstrate the efficiency of SeeA\u2217, in comparison with the state-of-the-art heuristic search algorithms. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In recent years, combining heuristic search algorithms with deep neural networks has demonstrated remarkable performance across a wide range of practical applications, such as board games [48, 50, 49, 66], video games [46, 64, 67], traveling salesman problem [8, 59], de novo drug design [42], retrosynthetic planning [6, 47, 68], logic synthesis [9], and so on. The search algorithm is a slow reasoning process, and heuristic functions serve as counselors to narrow down the search space [2]. Therefore, the effectiveness of search algorithms is significantly influenced by the quality of the guiding functions. ", "page_idx": 0}, {"type": "text", "text": "Monte-Carlo tree search (MCTS) is a widely-used, effective algorithm for combinatorial problems. However, if the backup value in MCTS is provided by a heuristic estimator rather than actual rewards, the convergence to the true state value is not guaranteed, leading to compromised search performance. In single-agent problems such as combinatorial puzzles, neural-guided MCTS tends to have a relatively long runtime and often generates solutions that are considerably longer than the shortest path [1]. ", "page_idx": 0}, {"type": "text", "text": "$\\mathbf{A}^{*}$ search [26] is a best-first search algorithm that expands nodes with the minimum total path value $f$ at each step. The evaluation function $f(n)$ on a node $n$ is defined as the summation of $g(n)$ , the accumulated cost from the initial node $n_{0}$ to $n$ , and $h(n)$ , the expected cost from $n$ to the goal, i.e., ", "page_idx": 1}, {"type": "equation", "text": "$$\nf(n)=g(n)+h(n).\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Notice that $g(n)$ computes the cost from the known searching trajectory, whereas $h(n)$ is a heuristic function to estimate the cost of the future path from $n$ to the goal. In practice, it is usually difficult to obtain an accurate $h(n)$ . $\\mathbf{A}^{*}$ search is guaranteed to find the optimal solution if $h(n)$ is admissible, i.e., $h(n)$ never overestimates the real cost to the goal. However, due to its best-first expansion strategy, $\\mathbf{A}^{*}$ has limited exploration capability. If $f(n)$ deviates from the true cost function $f^{*}(n)$ too much, $\\mathbf{A}^{*}$ search may become trapped in local optimal branches, and significant efforts are required to resume expansion within the optimal branch. Consequently, the computational efficiency of $\\mathbf{A}^{*}$ search is compromised in practical applications, even though the optimality of $\\mathbf{A}^{*}$ might still hold under the guidance of $f(n)$ . ", "page_idx": 1}, {"type": "text", "text": "MCTS and $\\mathbf{A}^{*}$ both perform heuristic search. MCTS and reinforcement learning with the help of deep learning contributed crucially to the successes of AlphaGo and AlphaZero, which aroused the interest of comparing MCTS and $\\mathbf{A}^{*}$ for possible mutual benefits. Deep learning is also able to contribute to the renaissance of $\\mathbf{A}^{*}$ , three possible aspects are addressed with a family of possible improvements proposed under the name of Deep IA-search [61]. The first and also straightforward aspect is estimating $f(n)$ with the help of deep learning, which makes current studies on $\\mathbf{A}^{*}$ including this paper into the era of learning aided $\\mathbf{A}^{*}$ . The second aspect is seeking a better estimation of $f(n)$ with the help of global or future information, featured by two typical mechanisms. One is lookahead or scouting before expanding the current node to collect future information to revise $f(n)$ of the current node, which takes a crucial rule for the success of AlphaGo [48] and also used more than 30 years ago in Algorithm CNneim-A [62]. The other is path consistency, that is, $f(n)$ values on one optimal path should be identical, which has been further confirmed in recent studies [66, 67, 68]. This third aspect is about selecting nodes among the OPEN list that consists of open nodes of $\\mathbf{A}^{*}$ . It is an old tune even in the classical era of $\\mathbf{A}^{*}$ , e.g., one suggestion is dividing OPEN into two sublists OPEN and WAIT according to a priori and a posteriori in a Bayesian evaluation [61]. However, investigation is seldom made on what are effective and efficient ways for selecting among OPEN. ", "page_idx": 1}, {"type": "text", "text": "In this paper, SeeA\u2217search (short for Sampling-exploration enhanced $\\mathbf{A}^{*}$ ) algorithm is proposed by incorporating exploration behavior into $\\mathbf{A}^{*}$ search to target at the third aspect. The main contributions are summarized below.2 ", "page_idx": 1}, {"type": "text", "text": "\u2022 SeeA\u2217search employs a selective sampling process to screen a dynamic candidate subset $\\mathcal{D}$ from the set $\\scriptscriptstyle\\mathcal{O}$ of open nodes that are awaiting expansion. The next expanding node is selected from $\\mathcal{D}$ , and it may not be the node that has the best heuristic value in $\\scriptscriptstyle\\mathcal{O}$ and will be selected by $\\mathbf{A}^{*}$ , enabling $\\mathrm{\\mathbf{S}e e A^{*}}$ to explore other promising branches. To reduce the excessive expansion of unnecessary nodes during exploration, only the candidate node with the best heuristic value is expanded. Three sampling strategies are introduced to strike a balance between exploitation and exploration. The search efficiency is improved especially when the guiding heuristic function is not accurate enough. ", "page_idx": 1}, {"type": "text", "text": "\u2022 We theoretically prove that $\\mathrm{{SeeA^{*}}}$ has superior efficiency over $\\mathbf{A}^{*}$ search when the heuristic value function deviates substantially from the true state value function. SeeA\u2217achieves a reduced number of node expansions to identify the optimal path. This performance improvement becomes more pronounced as the complexity of the problems increases and the reliability of the guiding heuristics decreases. ", "page_idx": 1}, {"type": "text", "text": "\u2022 Experiments are conducted on two real-world applications, i.e., the retrosynthetic planning problem in organic chemistry and the logic synthesis problem in integrated circuit design, as well as the classical Sokoban game. SeeA\u2217outperforms the state-of-the-art heuristic search algorithms in terms of the problem-solving success rate and solution quality while maintaining a low level of node expansions. ", "page_idx": 1}, {"type": "text", "text": "2 Related work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "MCTS [5, 13] utilizes random sampling and tree-based search to efficiently explore search space. Upper Confidence bounds applied to Trees with predictor (PUCT) have been employed by AlphaZero [49], achieving super-human performance in board games. $\\mathbf{A}^{*}$ search is widely employed for solving optimization problems, such as route planning [54, 53], cubic and puzzle games [1], robotics [17], and so on. Many variants of $\\mathbf{A}^{*}$ search have been proposed for performance improvement. Weighted $\\mathbf{A}^{*}$ search $(\\mathrm{WA^{*}})$ [18] biased the expanding policy towards states closer to the goal by ", "page_idx": 2}, {"type": "equation", "text": "$$\nn^{*}=\\arg\\operatorname*{min}_{n}g(n)+\\varepsilon h(n),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\varepsilon$ is a hyperparameter to adjust the weight of the heuristic estimation $h$ . WA\u2217with iteratively decreasing weights is employed by the LAMA planner [27, 44], achieving promising results in various domains including Sokoban. DeepCubeA [1] trained heuristic functions by reversing solution pathways from the goal state to guiding the search process of $\\mathrm{{WA^{*}}}$ . Commonly, $\\mathrm{{WA^{*}}}$ traded optimality for speed, and increasing $\\varepsilon$ was assumed to result in faster searches. Additionally, the greedy search based on $h$ values was considered the fastest search. However, empirical observations revealed that increasing $\\varepsilon$ slowed down the search in some domains. Greedy search is fast if and only if there is a strong correlation between the heuristic estimations and the true distance-to-go, or if the heuristic is extremely accurate [55]. However, constructing a reliable heuristic function for complicated problems is challenging attributed to the vast search space and the difficulties associated with sample collection in real-world applications. Poor generalization performance also remains a pervasive issue across diverse practical domains, such as retrosynthetic planning. This paper sets out to develop an efficient search algorithm designed to minimize the adverse effects of inaccurate predictions by heuristic functions. ", "page_idx": 2}, {"type": "text", "text": "There have been some preliminary studies on the integration of exploration into the $\\mathbf{A}^{*}$ search. $\\varepsilon-$ greedy node selection was incorporated into LAMA, suggesting that exploration can improve the coverage of search algorithms even multiple enhancements were already employed [52]. Type-WA\u2217 [11] augments $\\mathrm{WA^{*}}$ with type-based exploration [57] in the focal list [40]. The search space nodes are divided into $T$ distinct groups, and one of these groups is randomly chosen to determine the expanded node. Levin tree search (LevinTS) [38] combined a penalization mechanism based on node depth to encourage exploration for $\\mathbf{A}^{*}$ search. Policy-guided heuristic search (PHS) [39] generalized LevinTS by introducing a heuristic factor, guided by both a value function and a policy. When the guiding heuristics are sufficiently accurate, the best-first search achieves optimal efficiency without the need for exploration. Insufficient exploration leads the search algorithm to be trapped in local optima guided by inaccurate heuristics. As the accuracy of the guiding heuristic diminishes, the importance of exploration becomes more pronounced in order to mitigate the potential misguidance. ", "page_idx": 2}, {"type": "text", "text": "Search algorithms have played a crucial role in solving diverse real-world problems, such as retrosynthetic planning and logic synthesis. Retrosynthetic planning aims to identify a feasible synthetic route using known available building block molecules for a given target molecule. Considering that the synthesis of target molecules typically requires multiple steps and each step encompasses a substantial number of potential chemical reactions, retrosynthetic planning is formulated as a search problem to identify the optimal synthetic pathway. Both MCTS [28, 47, 65] and $\\mathbf{A}^{*}$ search, such as Retro\u2217[6] and its descendants [24, 30, 33, 58], have demonstrated promising results in retrosynthetic planning. Logic synthesis (LS) is a crucial step in the design of integrated circuits, mapping the high-level logic circuit description into gate-level implementation. In recent years, reinforcement learning algorithms [10, 29, 34, 41, 69] and search methods [9, 37] have shown promising results in the field of LS. Besides, Sokoban is an NP-hard [16] and PSPACE-complete [14] problem, which is a benchmark problem for evaluating the performance of artificial intelligence planning algorithms. Recently, combining reinforcement learning algorithms with search-based methods has demonstrated remarkable performance in effectively solving the Sokoban problem [19, 20, 22, 31, 43]. ", "page_idx": 2}, {"type": "text", "text": "3 Preliminaries and limitations on $\\mathbf{A}^{*}$ search ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Single-agent problems solved in this paper are formulated as Markov decision processes. Let $\\mathcal{N}$ represent the set of nodes in the search tree, where each node $n\\,\\in\\,{\\mathcal{N}}$ corresponds to a state $s$ in the state space $\\boldsymbol{S}$ . The set of $n$ \u2019s children is represented as $C H(n)$ . The root of the tree and the initial state are denoted as $n_{0}$ and $s_{0}$ respectively. At each interactive step, action $a_{t}\\,\\in\\,A$ is applied to the current state $s_{t}$ , resulting in the subsequent state $s_{t+1}=\\mathcal{T}(s_{t},a_{t})$ and transition cost $\\bar{c_{t+1}}=c(s_{t},a_{t})$ , where $\\tau$ is the state transition function to obtain the following state $s_{t+1}$ when taking action $a_{t}$ at state $s_{t}$ , and $c$ is the cost function giveing the received cost when taking action $a_{t}$ at state $s_{t}$ .. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "The search tree of $\\mathbf{A}^{*}$ contains two distinct types of nodes: closed nodes, which have already been expanded, and open nodes, which are waiting to be expanded [26]. Let $\\scriptscriptstyle\\mathcal{O}$ and $\\mathcal{C}$ denote the set of open nodes and closed nodes respectively. The search process of $\\mathbf{A}^{*}$ can be summarized as follows: ", "page_idx": 3}, {"type": "text", "text": "\u2022 Step 1: Initialize $n_{0}$ with $s_{0}$ , and mark it as open node by setting $O\\gets\\{n_{0}\\}$ , $\\mathcal{C}\\gets\\emptyset$ . \u2022 Step 2: Select the node $n$ with the lowest total path cost $f(n)$ from the open set $\\scriptscriptstyle\\mathcal{O}$ , i.e., $n=\\arg\\operatorname*{min}_{n^{\\prime}\\in{\\mathcal O}}f(n^{\\prime})$ . \u2022 Step 3: If the node $n$ is the goal, terminate the search process successfully. Otherwise, expand the node $n$ , and update ${\\mathcal{C}}\\gets{\\mathcal{C}}\\cup\\{n\\}$ , $\\mathcal{O}\\leftarrow\\mathcal{O}\\cup\\bar{C}H(n)\\setminus\\{n\\}$ . \u2022 Step 4: Repeat step 2 and 3 until $\\scriptscriptstyle\\mathcal{O}$ becomes empty, or exceeding the predetermined maximum runtime or the number of expanded nodes, terminating with failure. ", "page_idx": 3}, {"type": "text", "text": "$\\mathbf{A}^{*}$ search always selects the node with the best heuristic value from the open set without exploration. When the heuristic function $f$ can accurately estimate the true cost $f^{*}$ , this best-first search is the most efficient. However, if the estimation by $f$ is not accurate enough, the node with the minimum $f$ value may not correspond to the optimal one, which instead has the lowest $f^{*}$ value. The search process might be trapped in a local optimal branch, and substantial computational efforts are required to resume expansion on the optimal branch, which diminishes the efficiency of the search algorithm. Considering an example in Figure 1(a), suppose the cost for each step (or edge) on the optimal path is 100, and on the non-optimal path is only 1. The true total path cost at any node $n$ is given by $f^{*}(n)=g(n)+h^{*}(n)$ , where $g(n)$ is given by adding the costs from the root to the node $n$ , and the real future cost $h^{*}(n)$ is a summation of all costs from $n$ to the end (or terminal state). Suppose the evaluation function $f(n)=g(n)+h(n)$ by Equation 1 is exact on the optimal path but underestimates the real cost otherwise. Specifically, define the heuristic function $h(n)$ as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\nh(n)={\\left\\{\\begin{array}{l l}{h^{*}(n),}&{{\\mathrm{if~}}n{\\mathrm{~is~on~the~optimal~path}}}\\\\ {0,}&{{\\mathrm{Otherwise}}}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Then, $h(n)$ satisfies the admissible assumption as it never overestimates the cost, and $h(n)\\leq h^{*}(n)$ is established for all nodes. Therefore, $\\mathbf{A}^{*}$ is guaranteed to find the optimal solution guided by $h(n)$ in Equation 3. However, as illustrated in Figure 1(b), guided by the defined heuristic $h$ , the nodes on the optimal path will not be expanded until all nodes on non-optimal branches with depths less than 200 have been expanded. The optimal solution is achieved within two steps under the guidance of $f^{*}$ , and the search efficiency of $\\mathbf{A}^{*}$ search is largely compromised when $f(n)$ is not accurate enough. ", "page_idx": 3}, {"type": "text", "text": "4 Method ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "$\\mathrm{{SeeA^{*}}}$ search is proposed on the basis of $\\mathbf{A}^{*}$ search by introducing a candidate set $\\mathcal{D}$ of open nodes to provide exploration behavior. Three selective sampling strategies are presented for constructing the candidate set. Moreover, we present a theoretical analysis on the efficiency of SeeA\u2217. ", "page_idx": 3}, {"type": "text", "text": "4.1 SeeA\u2217search algorithm ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "$\\mathrm{\\mathbf{S}e e A^{*}}$ employs the following two steps to replace the Step 2 in $\\mathbf{A}^{*}$ search. First, a selective strategy is employed to sample a set of candidate nodes $\\mathcal{D}$ from the opening set $\\scriptscriptstyle\\mathcal{O}$ . Then, the node $n$ with the lowest $f$ -value from the candidate set $\\mathcal{D}$ , instead of $\\scriptscriptstyle\\mathcal{O}$ , is chosen to be expanded in Step 3. The details of SeeA\u2217are summarized in Algorithm 1 in Appendix A. ", "page_idx": 3}, {"type": "text", "text": "\u2022 Step $2a$ : Sample a candidate subset $\\mathcal{D}$ from $\\scriptscriptstyle\\mathcal{O}$ .   \n\u2022 Step $2b$ : Select the node $n$ with the lowest $f$ -value from the candidate set $\\mathcal{D}$ . ", "page_idx": 3}, {"type": "text", "text": "As illustrated in Figure $1(\\mathrm{c})\\&(\\mathrm{d})$ , if the node with minimum $f$ -value is not sampled into the candidate set $\\mathcal{D}$ in Step $2a$ , the node selected to be expanded later is not the same as the one by $\\mathbf{A}^{*}$ search, which activates exploration on other branches. Step $2b$ excludes the unpromising nodes by the $f$ -value. ", "page_idx": 3}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/2af32bfe7e139acc1a59220d013a2c05d0ed916a30977436b62530c4319a381e.jpg", "img_caption": ["Figure 1: An illustration of how $\\mathrm{{SeeA^{*}}}$ overcomes the $\\mathbf{A}^{*}$ search\u2019s limitation. (a) An example of the search tree is guided by the true optimal value $f^{*}(n)=g(n)+h^{*}(n)$ . Values on the edge denote the cost of each step. (b) On the same example, the $\\mathbf{A}^{*}$ search is trapped in a suboptimal branch misled by the unreliable heuristics, i.e., $f(n)={\\bar{g}}(n)+h(n)$ . (d) When the candidate set does not contain the node $n_{1}^{*}$ with the best $f$ value, $n_{2}^{*}$ will be selected and explored, where $n_{2}^{*}\\neq n_{1}^{*}$ . "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "4.1.1 Uniform sampling strategy ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Uniform sampling guarantees an equal selection probability for each node, thereby generating a representative subset that has the same distribution of the population. The procedure is given in Algorithm 2 in Appendix A. If the desired number of candidate nodes, denoted as $K$ , is greater than the number of open nodes, the open set $\\scriptscriptstyle\\mathcal{O}$ is used as $\\mathcal{D}$ . Otherwise, $K$ nodes are randomly selected from the open nodes as $\\mathcal{D}$ . It should be noted that $\\mathrm{{SeeA^{*}}}$ with uniform sampling is different from the $\\varepsilon$ -Greedy method. The $\\varepsilon$ -Greedy activates exploration with probability $\\varepsilon$ and then uniformly samples a node for expansion, which may expand low-quality nodes. In Step $2a$ of $\\mathrm{{SeeA^{*}}}$ , uniform sampling is very likely to include at least one high-quality node with a reasonably low $f$ -value and the node will be selected to expand in Step $2b$ . More discussions are referred to Appendix P. ", "page_idx": 4}, {"type": "text", "text": "4.1.2 Clustering sampling strategy ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In the uniform sampling strategy, each node is selected with equal probability. However, there is a non-negligible probability that all sampled nodes are of low quality, leading to the exclusion of nodes along the optimal expansion path from the candidate set $\\mathcal{D}$ . Therefore, a clustering sampling strategy is proposed, and it partitions open nodes into multiple clusters and subsequently sampling nodes from each cluster, as illustrated in Figure 2 in Appendix B. At least one node from each cluster is sampled compulsorily. Consequently, the probability of including nodes on the optimal branch is increased, thereby facilitating search efficiency. On the other hand, uniform sampling strategy is equivalent to assume that the nodes follow a Gaussian distribution, whereas clustering sampling strategy assumes that the nodes follow a Gaussian mixture distribution from multiple clusters, which provides a more descriptive representation for sampling. ", "page_idx": 4}, {"type": "text", "text": "To reduce computational costs, competitive learning [51] is utilized for node clustering. After each node expansion, the incorporation of newly generated nodes into the set $\\scriptscriptstyle\\mathcal{O}$ resembles the process of online sample acquisition in competitive learning. A clustering process is conducted simultaneously with the search process. Offilne clustering algorithms, such as K-means or Gaussian mixture model, require recalculating the clustering when incorporating new nodes, thereby imposing additional computational overhead. Each node is represented by a vector extracted by a function $f_{h}$ . $N_{c}$ cluster centers are randomly initialized as vectors with the same dimension of node embedding. During each expansion, the newly generated nodes are assigned to the cluster with the closest center separately, and the cluster center is updated by moving toward the position of the freshly added node. While preparing the candidate set $\\mathcal{D}$ , nodes are sampled evenly from each cluster, and uniform sampling is employed to select nodes from each cluster. Details are displayed in Algorithm $3\\ \\&\\ 5$ in Appendix A. ", "page_idx": 4}, {"type": "text", "text": "4.1.3 UCT-like sampling strategy ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In AlphaZero [49], PUCT achieved a good balance between exploitation and exploration with promising results. In light of this, a UCT-like sampling strategy is proposed. Due to the absence of Monte Carlo simulations, estimated $f$ values are employed to substitute the $Q$ value in PUCT, which is the average backup value obtained from multiple MCTS simulations. The depth of the node is employed as the penalization for exploration [38]. Each node is evaluated by ", "page_idx": 5}, {"type": "equation", "text": "$$\nE(n)=f(n)-c_{b}\\times\\frac{\\sqrt{d_{m a x}}}{1+d(n)},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $c_{b}$ is an adjustable hyperparameter, $d(n)$ is the depth of node $n$ , and $d_{m a x}$ is the maximum depth of the open nodes. Nodes with smaller $d(n)$ are more likely to be included in the candidate set for exploration. Despite potential errors in $f$ value estimation, it remains a viable node evaluation metric to sample high-quality nodes, and the exploration term is beneficial in mitigating misleading of prediction errors. The $K$ nodes with the smallest $E$ values are chosen to constitute the candidate set $\\mathcal{D}$ . The details are summarized in Algorithm 4 in Appendix A. ", "page_idx": 5}, {"type": "text", "text": "4.2 Efficiency of SeeA\u2217search ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We further provide a theoretical analysis on the efficiency of $\\mathrm{{SeeA^{*}}}$ , demonstrating that $\\mathrm{\\mathbf{S}e e A^{*}}$ is superior to $\\mathbf{A}^{*}$ when the guiding heuristic function $f$ does not estimate the true cost $f^{*}$ accurately enough. It was claimed in $\\mathbf{A}^{*}$ search [26] that the $f^{*}$ values of all nodes on the optimal path are equal to the same cost $\\mu_{0}^{f}$ and lower than the $f^{*}$ value of nodes outside the optimal path, which was assumed to be sampled from a Gaussian distribution in [62]. In this paper, the prediction error for $f^{*}$ is assumed to follow a uniform distribution. Here, Gaussian distribution is denoted as $\\mathcal{G}(\\cdot,\\cdot)$ and uniform distribution is denoted as $\\mathcal{U}(\\cdot,\\cdot)$ . Formally, an assumption is made as follows. ", "page_idx": 5}, {"type": "text", "text": "Assumption 4.1 For each node n on the optimal path, $f(n)\\sim\\mathcal{U}(\\mu_{0}^{f}-\\sigma,\\mu_{0}^{f}+\\sigma)$ . For nodes not on the optimal path, $f(n)\\sim\\mathcal{U}(f^{*}(n)-\\sigma,f^{*}(n)+\\dot{\\sigma}).$ , and $\\{f^{*}(n)\\}$ are independently and identically sampled from $\\mathcal{G}(\\mu_{1}^{f},\\sigma_{s}^{2})$ . ", "page_idx": 5}, {"type": "text", "text": "The $\\mu_{0}^{f}$ and $\\mu_{1}^{f}$ are the expected total cost for optimal and non-optimal solutions, respectively. The inequality $\\mu_{0}^{f}<\\mu_{1}^{f}$ holds because the optimal path has a lower cost. The $\\sigma$ represents the magnitude of the prediction error, and the $\\sigma_{s}^{2}$ is a constant as the variance. Under Assumption 4.1, we can derive: ", "page_idx": 5}, {"type": "text", "text": "Corollary 4.2 For a node n on the optimal path and a node $n^{\\prime}$ off the optimal path, the probability ", "page_idx": 5}, {"type": "equation", "text": "$$\np_{\\sigma}=P\\left(f(n)\\leq f(n^{\\prime})|\\sigma\\right)\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "decreases as the prediction error $\\sigma$ increases. ", "page_idx": 5}, {"type": "text", "text": "It is worth noting that the establishment of Corollary 4.2 is not limited by the assumption of a uniform noise distribution in Assumption 4.1. When the noise follows a Gaussian distribution, Corollary 4.2 is still established. Refer to Appendix C for more detailed derivations. ", "page_idx": 5}, {"type": "text", "text": "Without loss of generality, assume the open set $\\scriptscriptstyle\\mathcal{O}$ contains $N_{o}$ nodes, $\\{n_{1},n_{2},\\cdot\\cdot\\cdot\\,,n_{N_{o}}\\}$ , and $n_{1}$ is the optimal node. The probability of $\\mathbf{A}^{*}$ search expanding node $n_{1}$ is ", "page_idx": 5}, {"type": "equation", "text": "$$\nP_{A}(\\sigma)=P\\left(n_{1}=\\arg\\operatorname*{min}_{n^{\\prime}\\in\\mathcal{O}}f(n^{\\prime})\\big|\\sigma\\right)=\\prod_{n^{\\prime}\\in\\mathcal{O}\\setminus\\{n_{1}\\}}P\\left(f(n)\\leq f(n^{\\prime})|\\sigma\\right)=p_{\\sigma}^{N_{\\sigma}-1}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "SeeA\u2217expands $n_{1}$ with probability ", "page_idx": 5}, {"type": "equation", "text": "$$\nP_{S}(\\sigma)=P\\left(n_{1}\\in\\mathcal{D},n_{1}=\\arg\\operatorname*{min}_{n^{\\prime}\\in\\mathcal{D}}f(n^{\\prime})|\\sigma\\right)=P(n_{1}\\in\\mathcal{D})\\prod_{n^{\\prime}\\in\\mathcal{D}\\backslash\\{n_{1}\\}}p_{\\sigma}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "If the uniform sampling strategy is used to select $K$ candidates, ", "page_idx": 5}, {"type": "equation", "text": "$$\nP_{S}(\\sigma)=\\frac{K}{N_{o}}p_{\\sigma}^{K-1}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Based on Equation 6 & 8, when the prediction error $\\sigma$ is large, $\\mathrm{\\mathbf{S}e e A^{*}}$ expands the optimal node with a higher probability than $\\mathbf{A}^{*}$ search at each step, which is given by the following theorem. ", "page_idx": 5}, {"type": "text", "text": "Theorem 4.3 $P_{S}(\\sigma)>P_{A}(\\sigma)$ holds if and only if ", "page_idx": 6}, {"type": "equation", "text": "$$\np_{\\sigma}<H(N_{o}),\\ \\ \\ \\,w h e r e\\;H(N_{o})=\\left(\\frac{K}{N_{o}}\\right)^{\\frac{1}{N_{o}-K}},N_{o}>K\\geq1.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "$H(N_{o})$ is a monotonically increasing function with respect to $N_{o}$ which is the size of the open set. With increasing branching factors and longer solution paths for more complex problems, $N_{o}$ grows and $H(N_{o},K)$ monotonically increases with respect to $N_{o}$ . Especially, we have ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{N_{o}\\to+\\infty}H(N_{o})=1.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "In this situation, Inequality 9 holds. SeeA\u2217tends to demonstrate superior performance compared to $\\mathbf{A}^{*}$ in solving complex problems. ", "page_idx": 6}, {"type": "text", "text": "Notice that if the heuristic function $f$ predicts the true cost $f^{*}$ without error, it leads to $p_{\\sigma}=1$ in Equation 5. Then, Equation 9 does not hold, and in this case, $\\mathbf{A}^{*}$ search becomes more efficient than SeeA\u2217. However, learning an accurate heuristic function for complex real-world problems is quite challenging, and large prediction errors usually exist, which leads to small $p_{\\sigma}$ and the establishment of Equation 9. The number of candidate nodes $K$ is a key hyperparameter to balance the exploitation $\\mathbf{A}^{*}$ and the exploration introduced by SeeA . $P_{S}(\\sigma)$ in Equation 8 reaches its maximum value when $K^{*}=-1/\\log p_{\\sigma}$ . When $p_{\\sigma}$ approaches 1, $K^{*}$ will be the largest $\\infty$ . In this situation, the candidate set is the same as the open set, and $\\mathrm{{SeeA^{*}}}$ degenerates into best-first $\\mathbf{A}^{*}$ . For small $p_{\\sigma}$ , the optimal $K^{*}$ is the smallest value 1 and $\\mathrm{{SeeA^{*}}}$ becomes random sampling. An appropriate value of $K$ should be selected according to the specific situation. According to Equation 7, $P_{S}(\\sigma)$ is related to both $p_{\\sigma}$ and $P(n_{1}\\in\\mathcal{D})$ . Utilizing more efficient sampling algorithms than uniform sampling is also capable to enhance the performance of $\\mathrm{\\mathbf{S}e e A^{*}}$ . The clustering sampling and UCT-like sampling aim to achieve a higher $P(n_{1}\\in\\mathcal{D})$ by constructing a more diverse candidate set, thereby enhancing the likelihood of expanding the optimal node. ", "page_idx": 6}, {"type": "text", "text": "For simplicity, suppose the probability of selecting the optimal node in a single expansion is $P$ , and the probability for expanding the optimal node becomes $1-(1-P)^{\\tau}$ after $\\tau$ expansions. To achieve a probability level of $P_{m i n}$ for expanding the optimal node, we have ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\tau\\geq\\frac{\\log\\{1-P_{m i n}\\}}{\\log\\{1-P\\}}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Based on Theorem 4.3 and Equation 11, SeeA\u2217is more efficient than $\\mathbf{A}^{*}$ search as it requires fewer expansions to find the optimal solution. It is noted that Equation 9 is derived on the uniform sampling strategy. For a more effective sampling strategy with a higher probability $P(n_{1}\\in\\mathcal{D})$ , SeeA\u2217will become more efficient as $P_{S}(\\sigma)$ increases. ", "page_idx": 6}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Real-world problems are usually complicated, and the amount of available samples for training the heuristic functions is typically small.Two real-world applications, i.e., retrosynthetic planning in organic chemistry and logic synthesis in integrated circuit (IC) design, are considered to evaluate the effectiveness of the proposed method. Since the molecular structures have enormous diversity but in contrast the available experimental data are very limited, the heuristic function to estimate the synthesis cost in retrosynthetic planning suffers from noticeable overftiting problems [68]. Furthermore, the vast chemical reaction space gives rise to a substantial number of branching factors in the search tree, leading to a rapid growth in the quantity of open nodes throughout the search process. Logic synthesis is another practical problem where it is challenging to train a reliable heuristic function to evaluate the solution\u2019s quality, due to the immense diversity of circuit functionalities and variations in design methodologies. Therefore, the above two real-world problems are suitable benchmarks to verify the efficiency of SeeA\u2217when the heuristic function is not accurate enough. In addition, Sokoban is a widely-used benchmark for combinatorial optimization solvers. It only permits a maximum of four legal actions at each step, and simulations can be leveraged to generate a substantial amount of data for training high-quality heuristic value estimators. Sokoban is included to verify the impact of an accurate heuristic function on the searching performance. All experiments are conducted using NVIDIA Tesla V100 GPUs and an Intel(R) Xeon(R) Gold 6238R CPU. ", "page_idx": 6}, {"type": "text", "text": "5.1 Results on retrosynthetic planning ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Chemical synthetic pathways are transformed into search trees following the literature [47]. A state is a set of molecules that are able to synthesize the target molecule. The initial state contains only the target molecule. The edges in the search tree represent the chemical reactions that enable state transitions between the connected nodes. The retrosynthetic planning problem is solved if all molecules within a state are available building blocks. A single-step retrosynthetic prediction model is utilized as the policy model to generate potential chemical reactions yielding the input molecule. The 50 chemical reaction templates with the highest probabilities constitute the set of valid actions for the current state. A heuristic function is employed to estimate the synthesis cost of the molecule, given the available building blocks. Each molecule is encoded using a 2048-dimensional Morgan Fingerprint vector [45] as the input for the heuristic functions. Both the single-step retrosynthetic prediction model and the cost estimator are provided by Ret $\\mathbf{[o^{*}+\\left[30\\right]}$ and used to guide the search algorithm. Details about the guiding heuristics are in Appendix D. The last hidden layer\u2019s output of the cost estimator is employed as the embedding representation of the input molecule. ", "page_idx": 7}, {"type": "text", "text": "Experiments are conducted on the widely-used USPTO benchmark, comprising 190 molecules [6]. Commercially available molecules in eMolecules3 are used as building blocks. Since the invocation of the single-step retrosynthetic prediction model contributes the majority of the computational cost, all search algorithms are limited to a maximum of 500 single-step model calls, or 10 minutes of real-time, following previous works [6, 30]. The outputs of the single-step model are cached to avoid duplicate computation when the same molecule is encountered again [36]. The size of the candidate set is set to $K=50$ . In the clustering sampling, the parameter $\\eta$ is set to 0.15, and the number of clusters is 5. In the UCT-like sampling, the parameter $c_{b}$ is set to 0.35. Additional pruning is not considered. Since the prior policy is already clipped at a minimum value of 0.001, Bayes mixing with a uniform policy to avoid zero-probability is not used in LevinTS [38] and PHS [39]. ", "page_idx": 7}, {"type": "text", "text": "The results on the USPTO benchmark are reported in Table $1^{4}$ . Due to the exploration induced by selective sampling, the three $\\mathrm{{SeeA^{*}}}$ variants achieve superior performance in terms of the percentage of solved molecules and the average solution length while utilizing minimal wall-clock runtime. Among the three sampling strategies, the UCT-like sampling strategy achieves the best balance between exploration and exploitation. As in the literature [47], predicting the synthetic cost of molecules is challenging, and the cost estimator is not accurate with a non-negligible prediction error $\\sigma$ . Then, it is expected and consistent with Theorem 4.3 that best-first search algorithms, including $\\mathrm{WA^{*}}$ and PHS, are less efficient because they excessively rely on the values of the heuristic function. MCTS requires more node expansions for problem-solving and generates solutions with longer lengths, which is consistent with the findings in the resolution of combinatorial puzzles [1]. The $\\varepsilon$ -Greedy node selection [52] achieves a success rate of $92.11\\%$ , surpassing the performance of $\\mathbf{A}^{*}$ search and demonstrating the practical benefits of introducing exploration when the reliability of guidance heuristics is compromised. ", "page_idx": 7}, {"type": "text", "text": "Six additional datasets are collected from the literature for further comparisons. These datasets comprise 4719 molecules, much more than the USPTO dataset. Details of the datasets are referred to the Appendix E. According to the results in Table 3& 4 in Appendix G, SeeA\u2217maintains its superiority over other search algorithms, and SeeA (Cluster) has the highest mean success rate of $63.56\\%$ . The clustering sampling and UCT-like sampling are better than uniform sampling in terms of the solved rate and the route length, indicating that the utilization of a superior sampling strategy is beneficial for the performance of SeeA\u2217. ", "page_idx": 7}, {"type": "text", "text": "5.2 Results on logic synthesis ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "For the logic synthesis problem, a Verilog-based hardware design is first converted into an andinverter-graph (AIG) representation, and then the AIG is optimized to have the lowest area-delay product (ADP) through a sequence of functionality-preserving transformations. The optimization is combinatorial because the sequence is constructed by selecting transformations one-by-one in order from a set. Following the literature, here the set is formed by seven legal transformations, and the sequence length is fixed at 10. The resyn2 transformation sequence is used as a baseline for comparisons [9, 10, 37]. More details about logic synthesis are in Appendix H. During the search process, the immediate reward is set to be 0, and the reward of the terminal step is the final AIG\u2019s ADP reduction rate against the baseline resyn2. The ADP score is approximately computed by ABC [4]. A heuristic function is employed to predict the accumulated reward of a sequence when only a front part of the sequence is available as input in the search process. This function serves as a guiding heuristic for the search algorithms. Following ABC-RL [9], the training dataset consists of 23 circuits, while the test dataset comprises 12 MCNC circuits denoted as $\\{\\bar{C_{1}}\\sim C_{12}\\}$ [63] (See Appendix I for more details.). The architecture of the heuristic function, the training and test details are referred to Appendix J. WA\u2217is equivalent to $\\mathbf{A}^{*}$ search because $g=0$ in Equation 2. ", "page_idx": 7}, {"type": "table", "img_path": "mSaqxZVZW8/tmp/4945f3fbf8055c0553be6b581716fb1b06fae493b9b822c05539668e6a2a886f.jpg", "table_caption": ["Table 1: Test results on the USPTO benchmark for retrosynthetic planning problem. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "The results on the MCNC benchmark are presented in Table $2^{5}$ . All three $\\mathrm{{SeeA^{*}}}$ variants outperform the existing methods in terms of the mean ADP reduction rates against the baseline resyn2. SeeA\u2217(Cluster) achieves the highest ADP reduction (i.e., $23.5\\%$ ), obviously surpassing the stateof-the-art ABC-RL\u2019s $20.9\\%$ . Guided by the same heuristic, $\\mathrm{\\mathbf{S}e e A^{*}}$ (Cluster) outperforms the $\\mathbf{A}^{*}$ search in 11 out of the 12 testing circuits. As illustrated by an example of the search process in Appendix K, the nodes expanded by $\\mathbf{A}^{*}$ tend to concentrate on a specific branch, whereas MCTS expands across multiple branches excessively due to its enforced exploration. $\\mathrm{{SeeA^{*}}}$ achieves a good balance between $\\mathbf{A}^{*}$ search and MCTS, ensuring that irrelevant branches are not unduly explored. ", "page_idx": 8}, {"type": "table", "img_path": "mSaqxZVZW8/tmp/7995c11ad9eecfbceac8f7162973f1fda1034ca7d8d5649732c99c8ab1d7f683.jpg", "table_caption": ["Table 2: The ADP reduction $(\\%)$ rates against the resyn2 baseline on the MCNC testing datasets. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "5.3 Results on Sokoban and path finding ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "The first 50000 training problems and the 1000 test problems are collected from Boxoban [23]. They are utilized to train a cost estimator and evaluate the search algorithms, respectively. More training details are provided in Appendix L. During testing, the search process is terminated with failure if the running time exceeds 10 minutes. SeeA\u2217has successfully solved all 1000 test Sokoban cases. Notably, the solutions generated by $\\mathrm{{SeeA^{*}}}$ exhibit not only shorter lengths compared to other search algorithms such as $\\mathbf{A}^{*}$ search, $\\mathrm{{WA^{*}}}$ , LevinTS, and PHS but also shorter lengths than the state-of-the-art DeepCubeA [1] algorithm. Detailed results are summarized in Appendix M. To illustrate the effectiveness of $\\mathrm{\\mathbf{S}e e A^{*}}$ on problems where accurate heuristics could exist but the guiding heuristic used is unreliable, experiments on path finding are conducted. $\\mathbf{A}^{*}$ and $\\mathrm{{SeeA^{*}}}$ exhibit similar performance when the guidance heuristic is reliable enough. However, $\\mathrm{{SeeA^{*}}}$ demonstrates significant advantages over $\\mathbf{A}^{*}$ when the heuristic is unreliable. More details are available in Appendix N. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "5.4 The impact of the hyperparameters on the performance ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The effects of three hyperparameters in $\\mathrm{\\mathbf{S}e e A^{*}}$ are empirically investigated below, i.e., the number of candidate nodes $K$ , the number of clusters $N_{c}$ , and the adjustable weight $c_{b}$ in Equation 4. Experiments are conducted on the USPTO benchmark for the retrosynthesis planning problem. The number $K$ is a critical parameter controlling the extent of exploration of $\\mathrm{\\mathbf{S}e e A^{*}}$ . When $K=1$ , the node to be expanded is solely determined by the selective sampling strategy, where the heuristic function has no impact on the selection. When $K$ is too large, all opening nodes will be finally chosen as candidates because every node has a positive chance to be selected by the sampling strategy. In this case, $\\mathrm{{SeeA^{*}}}$ degenerates back to $\\mathbf{A}^{*}$ which highly depends on the heuristic function. When $K$ is at an appropriate range, the sampling scheme endows SeeA\u2217with helpful exploratory capability. It is observed from Figure 11 in Appendix $\\mathrm{o}$ that a wide range of $K$ enables $\\mathrm{\\mathbf{S}e e A^{*}}$ to obtain superior performance. For the extreme cases, ${\\mathrm{SeeA}}^{*}(K=1)$ has the lowest success rate and longest solution length, and the performance of ${\\mathrm{SeeA}}^{*}(K=\\infty)$ , which is equivalent to $\\mathbf{A}^{*}$ , is also discounted. ", "page_idx": 9}, {"type": "text", "text": "According to the results in Figure 12 in Appendix O, the performance of the clustering sampling strategy is generally very robust against the choices of $N_{c}$ . An inadequate number of clusters makes it towards uniform sampling by ignoring the differences among the nodes, while an excessive cluster number will distract the sampling process by noise in the node representation learning. The hyperparameter $c_{b}$ controls the balance between exploration and exploitation in the UCT-like sampling strategy. A large $c_{b}$ favors exploration during the selection of candidate nodes. From Figure 13 in Appendix O, either too large or too small $c_{b}$ are detrimental to the efficiency of $\\mathrm{{SeeA^{*}}}$ , and the UCT-like sampling strategy achieves excellent results when $c_{b}$ is in the range of [0.15, 0.4]. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, the SeeA\u2217search is proposed to enhance the exploration behavior of the $\\mathbf{A}^{*}$ search by selecting expanded nodes from the sampled candidate nodes, rather than the entire set of open nodes. A node that is evaluated not to have the best estimated heuristic value may be selected and explored, thereby jumping out of the local optimum induced by inaccuracies in the heuristic function. Three sampling strategies are presented in the paper. Furthermore, we have theoretically established that SeeA\u2217is more efficient than $\\mathbf{A}^{*}$ search when the estimation of heuristic functions is not accurate enough. Experiments on two diverse real-world applications in chemistry and circuit design and one puzzle-solving game demonstrate the efficiency of $\\mathrm{{SeeA^{*}}}$ . ", "page_idx": 9}, {"type": "text", "text": "If the model exhibits precise state evaluation, the incorporation of exploration into $\\mathbf{A}^{*}$ search becomes redundant. However, in practical applications, where problems tend to be intricate or lack sufficient training data, obtaining accurately predictive heuristic functions is challenging. As suggested in Equation 7, in addition to reducing the prediction error $\\sigma$ , the probability of expanding the optimal nodes is also improved by using a smaller number of candidate nodes $K$ to include the optimal node in the candidate set with a greater likelihood $P(n_{1}\\in\\mathcal{D})$ . Screening candidate nodes reduces the search space, thereby enhancing search efficiency. Investigations on more effective sampling strategies will be conducted in future work. $\\mathrm{{SeeA^{*}}}$ will contribute to solving practical problems with limited samples. However, this work is still in the nascent stages without further applications related to people\u2019s daily lives currently, and thus there are no immediate ethical or harmful social impacts. ", "page_idx": 9}, {"type": "text", "text": "7 Acknowledgement ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported by the National Natural Science Foundation of China (grants No.   \n62172273) and the Shanghai Municipal Science and Technology Major Project, China (Grant No.   \n2021SHZDZX0102). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Forest Agostinelli, Stephen McAleer, Alexander Shmakov, and Pierre Baldi. Solving the rubik\u2019s cube with deep reinforcement learning and search. Nature Machine Intelligence, 1(8):356\u2013363, 2019.   \n[2] Thomas Anthony, Zheng Tian, and David Barber. Thinking fast and slow with deep learning and tree search. Advances in neural information processing systems, 30, 2017. [3] Mohak Bhardwaj, Sanjiban Choudhury, and Sebastian Scherer. Learning heuristic search via imitation. In Conference on Robot Learning, pages 271\u2013280. PMLR, 2017.   \n[4] Robert Brayton and Alan Mishchenko. Abc: An academic industrial-strength verification tool. In Computer Aided Verification: 22nd International Conference, CAV 2010, Edinburgh, UK, July 15-19, 2010. Proceedings 22, pages 24\u201340. Springer, 2010. [5] Hyeong Soo Chang, Michael C Fu, Jiaqiao Hu, and Steven I Marcus. An adaptive sampling algorithm for solving markov decision processes. Operations Research, 53(1):126\u2013139, 2005.   \n[6] Binghong Chen, Chengtao Li, Hanjun Dai, and Le Song. Retro\\*: learning retrosynthetic planning with neural guided $\\mathbf{a}^{*}$ search. In International Conference on Machine Learning, pages 1608\u20131616. PMLR, 2020.   \n[7] Tiejun Cheng, Yuan Zhao, Xun Li, Fu Lin, Yong Xu, Xinglong Zhang, Yan Li, Renxiao Wang, and Luhua Lai. Computation of octanol- water partition coefficients by guiding an additive model with knowledge. Journal of chemical information and modeling, 47(6):2140\u20132148, 2007. [8] Jinho Choo, Yeong-Dae Kwon, Jihoon Kim, Jeongwoo Jae, Andr\u00e9 Hottung, Kevin Tierney, and Youngjune Gwon. Simulation-guided beam search for neural combinatorial optimization. Advances in Neural Information Processing Systems, 35:8760\u20138772, 2022. [9] Animesh Basak Chowdhury, Marco Romanelli, Benjamin Tan, Ramesh Karri, and Siddharth Garg. Retrieval-guided reinforcement learning for boolean circuit minimization. In The Twelfth International Conference on Learning Representations, 2023.   \n[10] Animesh Basak Chowdhury, Benjamin Tan, Ryan Carey, Tushit Jain, Ramesh Karri, and Siddharth Garg. Bulls-eye: Active few-shot learning guided logic synthesis. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 2022.   \n[11] Eldan Cohen, Richard Anthony Valenzano, and Sheila A McIlraith. Type-wa\\*: Using exploration in bounded suboptimal planning. In IJCAI, pages 4047\u20134053, 2021.   \n[12] Connor W Coley, William H Green, and Klavs F Jensen. Rdchiral: An rdkit wrapper for handling stereochemistry in retrosynthetic template extraction and application. Journal of chemical information and modeling, 59(6):2529\u20132537, 2019.   \n[13] R\u00e9mi Coulom. Efficient selectivity and backup operators in monte-carlo tree search. In International conference on computers and games, pages 72\u201383. Springer, 2006.   \n[14] Joseph Culberson. Sokoban is pspace-complete. 1997.   \n[15] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirectional transformers for language understanding. CoRR, abs/1810.04805, 2018.   \n[16] Dorit Dor and Uri Zwick. Sokoban and other motion planning problems. Computational Geometry, 13(4):215\u2013228, 1999.   \n[17] Franti\u0161ek Duchon\u02c7, Andrej Babinec, Martin Kajan, Peter Ben\u02c7o, Martin Florek, Tom\u00e1\u0161 Fico, and Ladislav Juri\u0161ica. Path planning with modified a star algorithm for a mobile robot. Procedia engineering, 96:59\u201369, 2014.   \n[18] R\u00fcdiger Ebendt and Rolf Drechsler. Weighted a search unifying view and application. Artificial Intelligence, 173(14):1310\u20131342, 2009.   \n[19] Dieqiao Feng, Carla P Gomes, and Bart Selman. A novel automated curriculum strategy to solve hard sokoban planning instances. Advances in Neural Information Processing Systems, 33:3141\u20133152, 2020.   \n[20] Dieqiao Feng, Carla P Gomes, and Bart Selman. Solving hard ai planning instances using curriculum-driven deep reinforcement learning. arXiv preprint arXiv:2006.02689, 2020.   \n[21] Kaitlyn M Gayvert, Neel S Madhukar, and Olivier Elemento. A data-driven approach to predicting successes and failures of clinical trials. Cell chemical biology, 23(10):1294\u20131301, 2016.   \n[22] Edward Groshev, Maxwell Goldstein, Aviv Tamar, Siddharth Srivastava, and Pieter Abbeel. Learning generalized reactive policies using deep neural networks. In Proceedings of the International Conference on Automated Planning and Scheduling, volume 28, pages 408\u2013416, 2018.   \n[23] Arthur Guez, Mehdi Mirza, Karol Gregor, Rishabh Kabra, Sebastien Racaniere, Theophane Weber, David Raposo, Adam Santoro, Laurent Orseau, Tom Eccles, et al. An investigation of model-free planning: boxoban levels, 2018.   \n[24] Peng Han, Peilin Zhao, Chan Lu, Junzhou Huang, Jiaxiang Wu, Shuo Shang, Bin Yao, and Xiangliang Zhang. Gnn-retro: Retrosynthetic planning with graph neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 4014\u20134021, 2022.   \n[25] Katja Hansen, Sebastian Mika, Timon Schroeter, Andreas Sutter, Antonius Ter Laak, Thomas Steger-Hartmann, Nikolaus Heinrich, and Klaus-Robert Muller. Benchmark data set for in silico prediction of ames mutagenicity. Journal of chemical information and modeling, 49(9):2077\u2013 2081, 2009.   \n[26] Peter E Hart, Nils J Nilsson, and Bertram Raphael. A formal basis for the heuristic determination of minimum cost paths. IEEE transactions on Systems Science and Cybernetics, 4(2):100\u2013107, 1968.   \n[27] Malte Helmert. The fast downward planning system. Journal of Artificial Intelligence Research, 26:191\u2013246, 2006.   \n[28] Siqi Hong, Hankz Hankui Zhuo, Kebing Jin, Guang Shao, and Zhanwen Zhou. Retrosynthetic planning with experience-guided monte carlo tree search. Communications Chemistry, 6(1):120, 2023.   \n[29] Abdelrahman Hosny, Soheil Hashemi, Mohamed Shalan, and Sherief Reda. Drills: Deep reinforcement learning for logic synthesis. In 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC), pages 581\u2013586. IEEE, 2020.   \n[30] Junsu Kim, Sungsoo Ahn, Hankook Lee, and Jinwoo Shin. Self-improved retrosynthetic planning. In International Conference on Machine Learning, pages 5486\u20135495. PMLR, 2021.   \n[31] Peter Kissmann and Stefan Edelkamp. Improving cost-optimal domain-independent symbolic planning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 25, pages 992\u2013997, 2011.   \n[32] Greg Landrum. RDKit: Open-source cheminformatics software. http://www.rdkit.org. Accessed Nov 20, 2016.   \n[33] Guoqing Liu, Di Xue, Shufang Xie, Yingce Xia, Austin Tripp, Krzysztof Maziarz, Marwin Segler, Tao Qin, Zongzhang Zhang, and Tie-Yan Liu. Retrosynthetic planning with dual value networks. In Proceedings of the 40th International Conference on Machine Learning, ICML\u201923. JMLR.org, 2023.   \n[34] Chenyang Lv, Ziling Wei, Weikang Qian, Junjie Ye, Chang Feng, and Zhezhi He. Gpt-ls: Generative pre-trained transformer with offline reinforcement learning for logic synthesis. In 2023 IEEE 41st International Conference on Computer Design (ICCD), pages 320\u2013326. IEEE, 2023.   \n[35] Ines Filipa Martins, Ana L Teixeira, Luis Pinheiro, and Andre O Falcao. A bayesian approach to in silico blood-brain barrier penetration modeling. Journal of chemical information and modeling, 52(6):1686\u20131697, 2012.   \n[36] Krzysztof Maziarz, Austin Tripp, Guoqing Liu, Megan Stanley, Shufang Xie, Piotr Gai\u00b4nski, Philipp Seidl, and Marwin Segler. Re-evaluating retrosynthesis algorithms with syntheseus. arXiv preprint arXiv:2310.19796, 2023.   \n[37] Walter Lau Neto, Yingjie Li, Pierre-Emmanuel Gaillardon, and Cunxi Yu. Flowtune: End-toend automatic logic optimization exploration via domain-specific multi-armed bandit. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 2022.   \n[38] Laurent Orseau, Levi Lelis, Tor Lattimore, and Th\u00e9ophane Weber. Single-agent policy tree search with guarantees. Advances in Neural Information Processing Systems, 31, 2018.   \n[39] Laurent Orseau and Levi HS Lelis. Policy-guided heuristic search with guarantees. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 12382\u201312390, 2021.   \n[40] Judea Pearl and Jin H Kim. Studies in semi-admissible heuristics. IEEE transactions on pattern analysis and machine intelligence, (4):392\u2013399, 1982.   \n[41] Yasasvi V Peruvemba, Shubham Rai, Kapil Ahuja, and Akash Kumar. Rl-guided runtimeconstrained heuristic exploration for logic synthesis. In 2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD), pages 1\u20139. IEEE, 2021.   \n[42] Hao Qian, Cheng Lin, Dengwei Zhao, Shikui Tu, and Lei Xu. Alphadrug: protein target specific de novo molecular generation. PNAS nexus, 1(4):pgac227, 2022.   \n[43] S\u00e9bastien Racani\u00e8re, Th\u00e9ophane Weber, David Reichert, Lars Buesing, Arthur Guez, Danilo Jimenez Rezende, Adri\u00e0 Puigdom\u00e8nech Badia, Oriol Vinyals, Nicolas Heess, Yujia Li, et al. Imagination-augmented agents for deep reinforcement learning. Advances in neural information processing systems, 30, 2017.   \n[44] Silvia Richter and Matthias Westphal. The lama planner: Guiding cost-based anytime planning with landmarks. Journal of Artificial Intelligence Research, 39:127\u2013177, 2010.   \n[45] David Rogers and Mathew Hahn. Extended-connectivity fingerprints. Journal of chemical information and modeling, 50(5):742\u2013754, 2010.   \n[46] Julian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen Simonyan, Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis Hassabis, Thore Graepel, et al. Mastering atari, go, chess and shogi by planning with a learned model. Nature, 588(7839):604\u2013609, 2020.   \n[47] Marwin HS Segler, Mike Preuss, and Mark P Waller. Planning chemical syntheses with deep neural networks and symbolic ai. Nature, 555(7698):604\u2013610, 2018.   \n[48] David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. Mastering the game of go with deep neural networks and tree search. nature, 529(7587):484\u2013489, 2016.   \n[49] David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, et al. A general reinforcement learning algorithm that masters chess, shogi, and go through self-play. Science, 362(6419):1140\u20131144, 2018.   \n[50] David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, et al. Mastering the game of go without human knowledge. nature, 550(7676):354\u2013359, 2017.   \n[51] Toshio Uchiyama and Michael A Arbib. An algorithm for competitive learning in clustering problems. Pattern Recognition, 27(10):1415\u20131421, 1994.   \n[52] Richard Valenzano, Nathan Sturtevant, Jonathan Schaeffer, and Fan Xie. A comparison of knowledge-based gbfs enhancements and knowledge-free exploration. In Proceedings of the International Conference on Automated Planning and Scheduling, volume 24, pages 375\u2013379, 2014.   \n[53] Jiankun Wang, Wenzheng Chi, Chenming Li, Chaoqun Wang, and Max Q-H Meng. Neural rrt\\*: Learning-based optimal path planning. IEEE Transactions on Automation Science and Engineering, 17(4):1748\u20131758, 2020.   \n[54] Jingyuan Wang, Ning Wu, Wayne Xin Zhao, Fanzhang Peng, and Xin Lin. Empowering a\\* search algorithms with neural networks for personalized route recommendation. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining, pages 539\u2013547, 2019.   \n[55] Christopher Wilt and Wheeler Ruml. When does weighted a\\* fail? In Proceedings of the International Symposium on Combinatorial Search, volume 3, pages 137\u2013144, 2012.   \n[56] Kedi Wu and Guo-Wei Wei. Quantitative toxicity prediction using topology based multitask deep neural networks. Journal of chemical information and modeling, 58(2):520\u2013531, 2018.   \n[57] Fan Xie, Martin M\u00fcller, Robert Holte, and Tatsuya Imai. Type-based exploration with multiple search queues for satisficing planning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 28, 2014.   \n[58] Shufang Xie, Rui Yan, Peng Han, Yingce Xia, Lijun Wu, Chenjuan Guo, Bin Yang, and Tao Qin. Retrograph: Retrosynthetic planning with graph search. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 2120\u20132129, 2022.   \n[59] Zhihao Xing and Shikui Tu. A graph neural network assisted monte carlo tree search approach to traveling salesman problem. IEEE Access, 8:108418\u2013108428, 2020.   \n[60] Guoli Xiong, Zhenxing Wu, Jiacai Yi, Li Fu, Zhijiang Yang, Changyu Hsieh, Mingzhu Yin, Xiangxiang Zeng, Chengkun Wu, Aiping Lu, et al. Admetlab 2.0: an integrated online platform for accurate and comprehensive predictions of admet properties. Nucleic Acids Research, 49(W1):W5\u2013W14, 2021.   \n[61] Lei Xu. Deep bidirectional intelligence: Alphazero, deep ia-search, deep ia-infer, and tpc causal learning. Applied Informatics, 5(1), 2018.   \n[62] Lei Xu, Pingfan Yan, and Tong Chang. Algorithm cnneim-a and its mean complexity. In Proc. of 2nd international conference on computers and applications. IEEE Press, Beijing, pages 494\u2013499, 1987.   \n[63] Saeyang Yang. Logic synthesis and optimization benchmarks user guide: version 3.0. Citeseer, 1991.   \n[64] Weirui Ye, Shaohuai Liu, Thanard Kurutach, Pieter Abbeel, and Yang Gao. Mastering atari games with limited data. Advances in Neural Information Processing Systems, 34:25476\u201325488, 2021.   \n[65] Yemin Yu, Ying Wei, Kun Kuang, Zhengxing Huang, Huaxiu Yao, and Fei Wu. Grasp: Navigating retrosynthetic planning with goal-driven policy. Advances in Neural Information Processing Systems, 35:10257\u201310268, 2022.   \n[66] Dengwei Zhao, Shikui Tu, and Lei Xu. Efficient learning for alphazero via path consistency. In International Conference on Machine Learning, pages 26971\u201326981. PMLR, 2022.   \n[67] Dengwei Zhao, Shikui Tu, and Lei Xu. Generalized weighted path consistency for mastering atari games. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[68] Dengwei Zhao, Shikui Tu, and Lei Xu. Efficient retrosynthetic planning with mcts exploration enhanced a\\* search. Communications Chemistry, 7(1):52, 2024.   \n[69] Keren Zhu, Mingjie Liu, Hao Chen, Zheng Zhao, and David Z Pan. Exploring logic optimizations with reinforcement learning and graph convolutional network. In Proceedings of the 2020 ACM/IEEE Workshop on Machine Learning for CAD, pages 145\u2013150, 2020. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Pseudocodes for SeeA\u2217and its sampling strategies ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this section, pseudocode for the $\\mathrm{{SeeA^{*}}}$ search algorithm, and three sampling strategies: uniform sampling strategy, clustering sampling strategy, and UCT-like sampling strategy, are given. Algorithm 1 provides a comprehensive summary of the computational process of $\\mathrm{\\mathbf{SeeA^{*}}}$ . The algorithm begins by initializing the Open set $\\scriptscriptstyle\\mathcal{O}$ with the initial node $n_{0}$ . In each step, a candidate set $\\mathcal{D}$ is obtained using the sampling strategy $F$ . The node with the minimum $f$ value from the candidate set is selected to be expanded. If the algorithm reaches a goal state, it successfully finds a solution and terminates. Otherwise, the expanded node is moved to the Closed set $\\mathcal{C}$ , and its child nodes are added to the Open set $\\scriptscriptstyle\\mathcal{O}$ . This process is repeated until the $\\scriptscriptstyle\\mathcal{O}$ becomes empty. ", "page_idx": 14}, {"type": "text", "text": "The uniform sampling strategy is presented in Algorithm 2. If the size of the open set $|\\mathcal{O}|$ does not exceed the required number of candidate nodes to be sampled, all nodes in the open set are considered as candidate nodes. However, if the size exceeds the required number, $K$ nodes are uniformly sampled from the open set to serve as candidate nodes. ", "page_idx": 14}, {"type": "table", "img_path": "mSaqxZVZW8/tmp/da5c92e698f52529e247e739d31a9b890004601e2467792db51311eb24787622.jpg", "table_caption": [], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "The clustering sampling strategy is summarized in Algorithm 3. The open nodes are divided into $N_{c}$ clusters, and an equal number of candidate nodes are sampled from each cluster. To sample $K$ candidate nodes, each cluster requires sampling $\\begin{array}{r}{K_{c}=\\lceil\\frac{K}{|S^{c}|}\\rceil}\\end{array}$ nodes. For each cluster, if the number of open nodes within this cluster does not exceed $K_{c}$ , all nodes are selected as candidate nodes. Otherwise, $K_{c}$ nodes are uniformly sampled as candidate nodes. To reduce computational overhead, competitive learning is employed for clustering, enabling avoidance of the need for re-clustering when new open nodes are added after each expansion. The algorithm for this competitive clustering process is displayed in Algorithm 5. $N_{c}$ clustering centers are initialized randomly. When a new node is added to the open set, it is assigned to the cluster whose center is closest to it, and the coordinates of that cluster center are updated by moving toward the position of the newly added node. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "UCT-like sampling strategy is provided in Algorithm 4, respectively. Each node $n$ is evaluated by a statistic $E(n)$ in Equation 4, which can achieve a balance between exploitation and exploration. The $f$ value of the node is used to evaluate the quality and the depth $d(n)$ is used to encourage exploration. If the size of the open set $|\\mathcal{O}|$ does not exceed the required number of candidate nodes to be sampled, all nodes in the open set are considered as candidate nodes. Otherwise, the $K$ nodes with the smallest $E$ values are selected as the candidate nodes. ", "page_idx": 15}, {"type": "table", "img_path": "mSaqxZVZW8/tmp/96d3a66c43f8631ac802474ccaa637b00561ba8e9825fbcf0488d871b458dd05.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "Algorithm 5: Node expanding for competitive clustering Input: clusters $S^{c}=\\{S_{1}^{c},S_{2}^{c},\\cdot\\cdot\\cdot,S_{N_{c}}^{c}\\}$ and their centers $W^{c}=\\{w_{1}^{c},w_{2}^{c},\\cdot\\cdot\\cdot,w_{N_{c}}^{c}\\}$ , expanded node $n$ , feature extraction function $f_{h}$ , and weight $\\eta$ . for $n\\in{\\mathcal{C H}}(n)$ do $w\\leftarrow f_{h}(n)$ $j\\gets\\arg\\operatorname*{min}_{w_{i}^{c}\\in W^{c}}||w-w_{i}^{c}||$ Sjc \u2190Sjc \u222a{n} $w_{j}^{c}\\leftarrow w_{j}^{c}+\\eta\\times(w-w_{j}^{c})$ end for return $S^{c}$ , W c ", "page_idx": 15}, {"type": "text", "text": "B An example of the clustering sampling strategy ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "As shown in Figure 2 (a), the sampled nodes exhibit a uniform distribution overall, resulting in a proportional relationship between the number of sampled nodes within each cluster and the total number of nodes within each class. Clusters with fewer nodes are highly susceptible to the occurrence of no nodes being sampled as candidate nodes under limited sampling size. Therefore, this sampling strategy cannot effectively explore the various potential expansion directions. As depicted in Figure 2 (b), at least one node from each cluster is sampled compulsorily. Consequently, the probability of including nodes on the optimal branch is increased, thereby facilitating search efficiency. ", "page_idx": 15}, {"type": "text", "text": "C Monotonicity of $p_{\\sigma}$ ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "$p_{\\sigma}$ is the probability of $P$ $\\left(f(n)<f(n^{\\prime})\\right)$ , in which $n$ is the node on the optimal path and $n^{\\prime}$ is the node on the non-optimal path. According to Assumption 4.1: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{P\\left(f(n)|\\sigma\\right)\\sim\\mathcal{U}(\\mu_{0}^{f}-\\sigma,\\mu_{0}^{f}+\\sigma)}}\\\\ {{P\\left(f(n^{\\prime})|\\mu_{s},\\sigma\\right)\\sim\\mathcal{U}(f^{*}(n^{\\prime})-\\sigma,f^{*}(n^{\\prime})+\\sigma)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Selected open node Unselected open node ............. Optimal node cluster ", "page_idx": 16}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/f50a787ce51dbb593ca7cff094193727a8f4ea74f1366827f6610bcc8b8d9d29.jpg", "img_caption": [], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "Figure 2: Set of selected candidate nodes $\\mathcal{D}$ obtained by (a) uniform sampling strategy; (b) clustering sampling strategy. ", "page_idx": 16}, {"type": "equation", "text": "$$\nf^{*}(n^{\\prime})\\sim\\mathcal{G}(\\mu_{1}^{f},\\sigma_{s}^{2}),\\mu_{1}^{f}>\\mu_{0}^{f}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "If $\\mu_{0}^{f}+\\sigma\\leq f^{*}(n^{\\prime})-\\sigma$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\nP\\left(f(n)\\leq f(n^{\\prime})|f^{*}(n^{\\prime})\\geq\\mu_{0}^{f}+2\\sigma,\\sigma\\right)=1\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "If $\\mu_{0}^{f}-\\sigma\\ge f^{\\ast}(n^{\\prime})+\\sigma$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\nP\\left(f(n)\\leq f(n^{\\prime})|f^{*}(n^{\\prime})\\leq\\mu_{0}^{f}-2\\sigma,\\sigma\\right)=0\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "If $\\mu_{0}-2\\sigma\\leq f^{*}(n^{\\prime})<\\mu_{0}$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\nP\\left(f(n)\\leq f(n^{\\prime})|f^{*}(n^{\\prime}),\\sigma\\right)=\\int_{\\mu_{0}^{f}-\\sigma}^{f^{*}(n^{\\prime})+\\sigma}\\frac{1}{2\\sigma}\\int_{f(n)}^{f^{*}(n^{\\prime})+\\sigma}\\frac{1}{2\\sigma}d f(n^{\\prime})d f(n)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n=\\!\\frac{1}{4\\sigma^{2}}\\int_{\\mu_{0}^{f}-\\sigma}^{f^{\\ast}(n^{\\prime})+\\sigma}\\!\\left(f^{\\ast}(n^{\\prime})+\\sigma-f(n)\\right)\\!d f(n)=\\frac{\\left(f^{\\ast}(n^{\\prime})-\\mu_{0}^{f}+2\\sigma\\right)^{2}}{8\\sigma^{2}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "If $\\mu_{0}^{f}\\leq f^{*}(n^{\\prime})<\\mu_{0}^{f}+2\\sigma$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{P\\left(f(n)\\leq f(n^{\\prime})|f^{*}(n^{\\prime}),\\sigma\\right)=\\displaystyle\\int_{\\mu_{0}^{f}-\\sigma}^{f^{*}(n^{\\prime})-\\sigma}\\frac{1}{2\\sigma}\\int_{f^{*}(n^{\\prime})-\\sigma}^{f^{*}(n^{\\prime})+\\sigma}\\frac{1}{2\\sigma}d f(n^{\\prime})d f(n)}\\\\ {+\\displaystyle\\int_{f^{*}(n^{\\prime})-\\sigma}^{\\mu_{0}^{f}+\\sigma}\\frac{1}{2\\sigma}\\int_{f(n)}^{f^{*}(n^{\\prime})+\\sigma}\\frac{1}{2\\sigma}d f(n^{\\prime})d f(n)}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\int_{\\mu_{0}^{f}-\\sigma}^{f^{*}(n^{\\prime})-\\sigma}\\frac{1}{2\\sigma}\\int_{f^{*}(n^{\\prime})-\\sigma}^{f^{*}(n^{\\prime})+\\sigma}\\frac{1}{2\\sigma}d f(n^{\\prime})d f(n)}}\\\\ {{\\displaystyle\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad=\\frac{1}{4\\sigma^{2}}(f^{*}(n^{\\prime})+\\sigma-f^{*}(n^{\\prime})+\\sigma)(f^{*}(n^{\\prime})-\\sigma-\\mu_{0}^{f}+\\sigma)}}\\\\ {{\\displaystyle\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad=\\frac{2\\sigma\\left(f^{*}(n^{\\prime})-\\mu_{0}^{f}\\right)}{4\\sigma^{2}}=\\frac{f^{*}(n^{\\prime})-\\mu_{0}^{f}}{2\\sigma}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\displaystyle\\int_{f^{*}(n^{\\prime})-\\sigma}^{\\mu_{0}^{f}+\\sigma}\\frac{1}{2\\sigma}\\int_{f(n)}^{f^{*}(n^{\\prime})+\\sigma}\\frac{1}{2\\sigma}d f(n^{\\prime})d f(n)}}\\\\ {{=\\displaystyle\\int_{f^{*}(n^{\\prime})-\\sigma}^{\\mu_{0}^{f}+\\sigma}\\frac{f^{*}(n^{\\prime})+\\sigma-f(n)}{4\\sigma^{2}}d f(n)=\\frac{1}{2}-\\frac{\\left(f^{*}(n^{\\prime})-\\mu_{0}^{f}\\right)^{2}}{8\\sigma^{2}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{P\\left(f(n)\\leq f(n^{\\prime})|f^{*}(n^{\\prime}),\\sigma\\right)=\\displaystyle\\frac{f^{*}(n^{\\prime})-\\mu_{0}^{f}}{2\\sigma}+\\displaystyle\\frac{1}{2}-\\frac{\\Big(f^{*}(n^{\\prime})-\\mu_{0}^{f}\\Big)^{2}}{8\\sigma^{2}}}}\\\\ {{=1-\\displaystyle\\frac{\\Big(f^{*}(n^{\\prime})-\\mu_{0}^{f}-2\\sigma\\Big)^{2}}{8\\sigma^{2}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "In summary: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{P\\left(f(n)\\leq f(n^{\\prime})|f^{*}(n^{\\prime}),\\sigma\\right)=\\left\\{1-\\frac{\\left(f^{*}(n^{\\prime})-\\mu_{0}^{f}-2\\sigma\\right)^{2}}{8\\sigma^{2}},\\;\\;\\;\\mu_{0}^{f}\\leq f^{*}(n^{\\prime})<\\mu_{0}^{f}+2\\sigma}\\\\ {\\xrightarrow{\\left(f^{*}(n^{\\prime})-\\mu_{0}^{f}+2\\sigma\\right)^{2}},\\;\\;\\;\\mu_{0}^{f}-2\\sigma\\leq f^{*}(n^{\\prime})<\\mu_{0}^{f}}\\\\ {0,\\;\\;\\;f^{*}(n^{\\prime})\\leq\\mu_{0}^{f}-2\\sigma}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We have that: ", "page_idx": 17}, {"type": "equation", "text": "$$\nP\\left(f(n)\\leq f(n^{\\prime})|\\,\\sigma\\right)=\\int P\\left(f(n)\\leq f(n^{\\prime})|f^{*}(n^{\\prime}),\\sigma\\right)P(f^{*}(n^{\\prime}))d f^{*}(n^{\\prime}),\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\nf^{*}(n^{\\prime})\\sim\\mathcal{G}(\\mu_{1}^{f},\\sigma_{s}^{2})\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "then we want to prove that $P\\left(f(n)\\leq f(n^{\\prime})\\right)$ decreases with $\\sigma$ . Let $\\begin{array}{r l}{m(f^{*}(n^{\\prime})|\\sigma)}&{{}=}\\end{array}$ $P\\left(f(n)\\leq f(n^{\\prime})|f^{*}(n^{\\prime}),\\sigma\\right)$ , we first prove that $m(f^{*}(n^{\\prime})|\\sigma)$ centrally symmetric about $\\left(\\mu_{0}^{f},{\\frac{1}{2}}\\right)$ by proving that $m\\left(f^{*}(n^{\\prime})|\\sigma\\right)=1-m\\left(2\\mu_{0}^{f}-f^{*}(n^{\\prime})|\\sigma\\right)$ : ", "page_idx": 17}, {"type": "text", "text": "If $f^{*}(n^{\\prime})\\geq\\mu_{0}^{f}+2\\sigma$ : ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{m(f^{*}(n^{\\prime})|\\sigma)=1}}\\\\ {{2\\mu_{0}^{f}-f^{*}(n^{\\prime})\\le\\mu_{0}^{f}-2\\sigma}}\\\\ {{m\\left(2\\mu_{0}^{f}-f^{*}(n^{\\prime})|\\sigma\\right)=0=1-m\\left(f^{*}(n^{\\prime})|\\sigma\\right)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "If $\\mu_{0}^{f}\\leq f^{*}(n^{\\prime})<\\mu_{0}^{f}+2\\sigma$ : ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{m(\\mu_{s}^{f}|\\sigma)=1-\\displaystyle\\frac{\\left(f^{*}(n^{\\prime})-\\mu_{0}^{f}-2\\sigma\\right)^{2}}{8\\sigma^{2}}}}\\\\ {{\\mu_{0}^{f}-2\\sigma<2\\mu_{0}^{f}-f^{*}(n^{\\prime})\\leq\\mu_{0}^{f}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{{}m\\left(2\\mu_{0}^{f}-f^{*}(n^{\\prime})|\\sigma\\right)=\\frac{\\displaystyle\\left(2\\mu_{0}^{f}-f^{*}(n^{\\prime})-\\mu_{0}^{f}+2\\sigma\\right)^{2}}{8\\sigma^{2}}}}\\\\ {{{}=\\frac{\\displaystyle\\left(f^{*}(n^{\\prime})-\\mu_{0}^{f}-2\\sigma\\right)^{2}}{8\\sigma^{2}}=1-m(f^{*}(n^{\\prime})|\\sigma)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "If $\\mu_{0}^{f}-2\\sigma\\le f^{\\ast}(n^{\\prime})<\\mu_{0}^{f}$ : ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{m(f^{*}(n^{\\prime})|\\sigma)=\\displaystyle\\frac{\\left(f^{*}(n^{\\prime})-\\mu_{0}^{f}+2\\sigma\\right)^{2}}{8\\sigma^{2}}}}\\\\ {{\\mu_{0}^{f}<2\\mu_{0}^{f}-f^{*}(n^{\\prime})\\le\\mu_{0}^{f}+2\\sigma}}\\\\ {{m\\left(2\\mu_{0}^{f}-f^{*}(n^{\\prime})|\\sigma\\right)=1-\\displaystyle\\frac{\\left(2\\mu_{0}^{f}-f^{*}(n^{\\prime})-\\mu_{0}^{f}-2\\sigma\\right)^{2}}{8\\sigma^{2}}}}\\\\ {{=1-\\displaystyle\\frac{\\left(f^{*}(n^{\\prime})-\\mu_{0}^{f}+2\\sigma\\right)^{2}}{8\\sigma^{2}}=1-m(f^{*}(n^{\\prime})|\\sigma)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "If $f^{*}(n^{\\prime})\\leq\\mu_{0}^{f}-2\\sigma$ : ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{m(f^{*}(n^{\\prime})|\\sigma)=0}}\\\\ {{2\\mu_{0}^{f}-f^{*}(n^{\\prime})\\geq\\mu_{0}^{f}+2\\sigma}}\\\\ {{m\\left(2\\mu_{0}^{f}-f^{*}(n^{\\prime})|\\sigma\\right)=1=1-m(f^{*}(n^{\\prime})|\\sigma)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Therefore, $m(f^{*}(n^{\\prime})|\\sigma)$ centrally symmetric about $\\left(\\mu_{0}^{f},{\\frac{1}{2}}\\right)$ . Then we want to illustrate the monotonicity of the function $m(\\mu_{s}^{f}|\\sigma)$ about the variable $\\sigma$ , and $\\sigma>0$ ", "page_idx": 18}, {"type": "text", "text": "If $f^{*}(n^{\\prime})\\geq\\mu_{0}^{f}+2\\sigma$ or $f^{*}(n^{\\prime})\\leq\\mu_{0}^{f}-2\\sigma.$ , $m(f^{*}(n^{\\prime})|\\sigma)$ is constant. If $\\mu_{0}^{f}-2\\sigma\\le f^{\\ast}(n^{\\prime})<\\mu_{0}^{f}$ , $m(f^{*}(n^{\\prime})|\\sigma)$ is monotonic increasing, because ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mu_{0}^{f}-2\\sigma\\leq f^{*}(n^{\\prime})<\\mu_{0}^{f}\\Rightarrow\\sigma\\geq\\frac{\\mu_{0}^{f}-\\mu_{s}^{f}}{2}}\\\\ &{\\left[\\frac{\\left(f^{*}(n^{\\prime})-\\mu_{0}^{f}+2\\sigma\\right)^{2}}{8\\sigma^{2}}\\right]^{\\prime}=\\frac{\\left(\\mu_{0}^{f}-f^{*}(n^{\\prime})\\right)\\,\\left(2\\sigma-\\mu_{0}^{f}+f^{*}(n^{\\prime})\\right)}{4\\sigma^{3}}\\geq0}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "If $\\mu_{0}^{f}\\leq f^{*}(n^{\\prime})<\\mu_{0}^{f}+2\\sigma,m(f^{*}(n^{\\prime})|\\sigma)$ is monotonic decreasing, because ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mu_{0}^{f}\\leq f^{*}(n^{\\prime})<\\mu_{0}^{f}+2\\sigma\\Rightarrow\\sigma>\\frac{f^{*}(n^{\\prime})-\\mu_{0}^{f}}{2}}\\\\ {\\displaystyle\\left[1-\\frac{\\left(f^{*}(n^{\\prime})-\\mu_{0}^{f}-2\\sigma\\right)^{2}}{8\\sigma^{2}}\\right]^{\\prime}=\\frac{\\left(f^{*}(n^{\\prime})-\\mu_{0}^{f}\\right)\\left(f^{*}(n^{\\prime})-\\mu_{0}^{f}-2\\sigma\\right)}{4\\sigma^{3}}<0}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Therefore, as shown in Figure 3, $P\\left(f(n)\\leq f(n^{\\prime})|f^{*}(n^{\\prime}),\\sigma\\right)$ is not always decrease with $\\sigma$ . However, on average, $P\\left(f(n)\\leq\\bar{f}(n^{\\prime})|\\sigma\\right)$ will always decrease with $\\sigma$ , and we will prove this. ", "page_idx": 18}, {"type": "text", "text": "For convenience, let $F(\\sigma)=P(f(n)\\leq f(n^{\\prime})|\\sigma)$ . Assume $\\sigma_{1}<\\sigma_{2}$ , then: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{F(\\sigma_{1})-F(\\sigma_{2})=\\displaystyle\\int_{-\\infty}^{\\infty}\\left[m(f^{*}(n^{\\prime})|\\sigma_{1})-m(f^{*}(n^{\\prime})|\\sigma_{2})\\right]P(f^{*}(n^{\\prime}))d f^{*}(n^{\\prime})}}\\\\ {{=\\displaystyle\\int_{-\\infty}^{\\mu_{0}^{f}}\\left[m(f^{*}(n^{\\prime})|\\sigma_{1})-m(f^{*}(n^{\\prime})|\\sigma_{2})\\right]P(f^{*}(n^{\\prime}))d f^{*}(n^{\\prime})}}\\\\ {{+\\displaystyle\\int_{\\mu_{0}^{f}}^{\\infty}\\left[m(f^{*}(n^{\\prime})|\\sigma_{1})-m(f^{*}(n^{\\prime})|\\sigma_{2})\\right]P(f^{*}(n^{\\prime}))d f^{*}(n^{\\prime})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Because the function $m$ is centrally symmetric about $\\left(\\mu_{0}^{f},{\\frac{1}{2}}\\right)$ : ", "page_idx": 18}, {"type": "equation", "text": "$$\nm(f^{*}(n^{\\prime})|\\sigma)=1-m(2\\mu_{0}^{f}-f^{*}(n^{\\prime})|\\sigma)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/6a1747f1c5ed1278d038f67d1d75275f8ceaa35c5f9b7752c0cb323c684bf431.jpg", "img_caption": ["Figure 3: Example for the monotonicity of $P\\left(f(n)\\leq f(n^{\\prime})|f^{*}(n^{\\prime}),\\sigma\\right)$ . "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "Therefore: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\int_{-\\infty}^{\\mu_{0}^{f}}[m(f^{*}(n^{\\prime})|\\sigma_{1})-m(f^{*}(n^{\\prime})|\\sigma_{2})]\\,P(f^{*}(n^{\\prime}))d f^{*}(n^{\\prime})}\\\\ {\\displaystyle=\\int_{-\\infty}^{\\mu_{0}^{f}}\\left[m(2\\mu_{0}^{f}-f^{*}(n^{\\prime})|\\sigma_{2})-m(2\\mu_{0}^{f}-f^{*}(n^{\\prime})|\\sigma_{1})\\right]P(f^{*}(n^{\\prime}))d f^{*}(n^{\\prime})}\\\\ {\\displaystyle=\\int_{\\mu_{0}^{f}}^{\\infty}\\left[m(f^{*}(n^{\\prime})|\\sigma_{2})-m(f^{*}(n^{\\prime})|\\sigma_{1})\\right]P(2\\mu_{0}^{f}-f^{*}(n^{\\prime}))d f^{*}(n^{\\prime})}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle F(\\sigma_{1})-F(\\sigma_{2})}}\\\\ {{\\displaystyle\\qquad=\\int_{\\mu_{0}^{f}}^{\\infty}\\left[m(f^{*}(n^{\\prime})|\\sigma_{1})-m(f^{*}(n^{\\prime})|\\sigma_{2})\\right]\\left(P(f^{*}(n^{\\prime}))-P(2\\mu_{0}^{f}-f^{*}(n^{\\prime}))\\right)d f^{*}(n^{\\prime})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "When $f^{*}(n^{\\prime})>\\mu_{0}^{f},m(f^{*}(n^{\\prime})|\\sigma)$ is monotonic decreasing with $\\sigma$ : ", "page_idx": 19}, {"type": "equation", "text": "$$\nm(f^{*}(n^{\\prime})|\\sigma_{1})-m(f^{*}(n^{\\prime})|\\sigma_{2})>0\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Because $f^{*}(n^{\\prime})\\sim\\mathcal{G}(\\mu_{1}^{f},\\sigma_{s}^{2})$ , if $P(f^{*}(n^{\\prime}))<P(2\\mu_{0}^{f}-f^{*}(n^{\\prime}))$ , ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{|f^{*}(n^{\\prime})-\\mu_{1}^{f}|>|2\\mu_{0}^{f}-f^{*}(n^{\\prime})-\\mu_{1}^{f}|}}\\\\ {{\\left(f^{*}(n^{\\prime})-\\mu_{1}^{f}\\right)^{2}>\\left(2\\mu_{0}^{f}-f^{*}(n^{\\prime})-\\mu_{1}^{f}\\right)^{2}}}\\\\ {{4\\left(\\mu_{0}^{f}-\\mu_{1}^{f}\\right)\\left(f^{*}(n^{\\prime})-\\mu_{0}^{f}\\right)>0}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Assumption 4.1 gives $\\mu_{1}^{f}>\\mu_{0}^{f}$ , and Equation 43 only considers the situation when $f^{*}(n^{\\prime})>\\mu_{0}^{f}$ . Therefore Equation 47 is not established and $P(f^{*}(n^{\\prime}))\\geq P(2\\mu_{0}^{f}-f^{*}(n^{\\prime}))$ . Therefore: ", "page_idx": 19}, {"type": "equation", "text": "$$\nP(f^{*}(n^{\\prime}))-P(2\\mu_{0}^{f}-f^{*}(n^{\\prime}))\\geq0\n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\nF(\\sigma_{1})-F(\\sigma_{2})>0,\\quad\\sigma_{1}<\\sigma_{2}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, $F(\\sigma)$ is monotonic decreasing. The larger the estimation error $\\sigma$ , the less the probability of $P\\left(f(n)<f(n^{\\prime})|\\sigma\\right)$ . ", "page_idx": 19}, {"type": "text", "text": "The assumption in Corollary 4.2 that the prediction error for $f^{*}$ is uniformly distributed is quite strong. To further illustrate the applicability of the algorithm, we also prove that Corollary 4.2 is established if the noise follows a Gaussian distribution. Denoting Gaussian distribution as $\\mathcal{G}(\\cdot,\\cdot)$ , the assumption regarding the distribution of the estimated values will be adjusted to: ", "page_idx": 19}, {"type": "text", "text": "Assumption C.1 For each node n on the optimal path, $f(n)\\sim\\mathcal{G}(\\mu_{0}^{f},\\sigma^{2})$ . For nodes not on the optimal path, $f(n)\\sim{\\mathcal{G}}(f^{*}(n),\\sigma^{2})$ , and $f^{*}(n)$ are independently and identically sampled from $\\mathcal{G}(\\mu_{1}^{f},\\sigma_{s}^{2})$ . $\\mu_{0}^{f}<\\mu_{1}^{f}$ holds because the optimal path has a lower cost. ", "page_idx": 20}, {"type": "text", "text": "For two Gaussian distributions, we have the following lemma [62, 67]: ", "page_idx": 20}, {"type": "text", "text": "Lemma C.2 Assume $x\\sim\\mathcal{G}(\\mu_{1},\\sigma_{1}^{2})$ , $y\\sim\\mathcal{G}(\\mu_{2},\\sigma_{2}^{2})$ . If $x$ , y are independent of each other and $\\mu_{2}>\\mu_{1}$ , then ", "page_idx": 20}, {"type": "equation", "text": "$$\nP(x>y)=\\frac{1}{\\pi}\\int_{0}^{\\frac{\\pi}{2}}\\exp\\left\\{-\\frac{1}{2}\\frac{[(\\mu_{2}-\\mu_{1})/\\sqrt{\\sigma_{1}^{2}+\\sigma_{2}^{2}}]^{2}}{\\cos^{2}\\theta}\\right\\}d\\theta.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "For a node $n$ on the optimal path, $f(n)\\sim\\mathcal{G}(\\mu_{0}^{f},\\sigma^{2})$ . For a node $n^{\\prime}$ off the optimal path, $f(n^{\\prime})\\sim$ $\\mathcal{G}(f^{*}(n^{\\prime}),\\sigma^{2})$ . If $\\mu_{0}^{f}>f^{*}(n^{\\prime})$ : ", "page_idx": 20}, {"type": "equation", "text": "$$\nP(f(n)<f(n^{\\prime})|\\mu_{0}^{f}>f^{*}(n^{\\prime}))=\\frac{1}{\\pi}\\int_{0}^{\\frac{\\pi}{2}}\\exp\\left\\{-\\frac{1}{2}\\frac{(f^{*}(n^{\\prime})-\\mu_{0}^{f})^{2}}{2\\sigma^{2}\\cos^{2}\\theta}\\right\\}d\\theta=m(f^{*}(n^{\\prime})|\\sigma)\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Otherwise: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{P(f(n)<f(n^{\\prime})|\\mu_{0}^{f}<f^{*}(n^{\\prime}))=1-\\displaystyle\\frac{1}{\\pi}\\int_{0}^{\\frac{\\pi}{2}}\\exp\\left\\lbrace-\\displaystyle\\frac{1}{2}\\displaystyle\\frac{(f^{*}(n^{\\prime})-\\mu_{0}^{f})^{2}}{2\\sigma^{2}\\cos^{2}\\theta}\\right\\rbrace d\\theta}}\\\\ {{=1-m(f^{*}(n^{\\prime})|\\sigma).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The probability that the $f$ value of the optimal node is less than the $f$ value of a non-optimal node is ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{F(\\sigma)=P(f(n)<f(n^{\\prime})|\\sigma)=\\displaystyle\\int_{f^{*}(n^{\\prime})<\\mu_{0}^{f}}P(f^{*}(n^{\\prime}))m(f^{*}(n^{\\prime})|\\sigma)d f^{*}(n^{\\prime})}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\displaystyle\\int_{f^{*}(n^{\\prime})\\geq\\mu_{0}^{f}}P(f^{*}(n^{\\prime}))(1-m(f^{*}(n^{\\prime})|\\sigma))d f^{*}(n^{\\prime}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "If $\\sigma_{2}>\\sigma_{1}$ : ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{F(\\sigma_{2})-F(\\sigma_{1})=\\displaystyle\\int_{f^{*}(n^{\\prime})<\\mu_{0}^{f}}P(f^{*}(n^{\\prime}))(m(f^{*}(n^{\\prime})|\\sigma_{2})-m(f^{*}(n^{\\prime})|\\sigma_{1}))d f^{*}(n^{\\prime})}\\\\ {+\\displaystyle\\int_{f^{*}(n^{\\prime})\\geq\\mu_{0}^{f}}P(f^{*}(n^{\\prime}))(m(f^{*}(n^{\\prime})|\\sigma_{1})-m(f^{*}(n^{\\prime})|\\sigma_{2}))d f^{*}(n^{\\prime}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "$m(f^{*}(n^{\\prime})|\\sigma)$ is symmetric about the axis $f^{*}(n^{\\prime})=\\mu_{0}^{f}$ , ", "page_idx": 20}, {"type": "equation", "text": "$$\nm(f^{*}(n^{\\prime})|\\sigma)=m(2\\mu_{0}^{f}-f^{*}(n^{\\prime})|\\sigma).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Equation 54 is equivalent to ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{F(\\sigma_{2})-F(\\sigma_{1})=\\displaystyle\\int_{f^{*}(n^{\\prime})\\geq\\mu_{0}^{f}}(P(2\\mu_{0}^{f}-f^{*}(n^{\\prime}))-P(f^{*}(n^{\\prime})))}\\\\ {\\times\\left(m(f^{*}(n^{\\prime})|\\sigma_{2})-m(f^{*}(n^{\\prime})|\\sigma_{1}))d f^{*}(n^{\\prime})\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "According to the definition, $m$ is monotonically increasing with respect to $\\sigma$ . Therefore, $m(f^{*}(n^{\\prime})|\\sigma_{2})\\,-\\,m(f^{*}(n^{\\prime})|\\sigma_{1})\\;>\\;0$ . Because $f^{*}(n^{\\prime})\\;\\sim\\;{\\mathcal N}(\\mu_{1}^{f},\\sigma_{2}^{2})$ and $\\mu_{0}^{f}~<~\\mu_{1}^{f}$ , we have $P(2\\mu_{0}^{f}-f^{\\ast}(n^{\\prime}))-P(f^{\\ast}(n^{\\prime}))\\,<\\,0$ when $f^{*}(n^{\\prime})\\,\\geq\\,\\mu_{0}^{f}$ . Therefore, $F(\\sigma_{2})\\,-\\,F(\\sigma_{1})\\,<\\,0$ is established, and $P(f(n)<f(n^{\\prime})|\\sigma)$ decreases as the prediction error $\\sigma$ increases when the noise is Gaussian distribution. The above analyses will be added to the revised paper to further elucidate the impact of prediction errors. Under both the uniform error distribution and the Gaussian error distribution, the larger the prediction error, the lower the likelihood of selecting the optimal node. ", "page_idx": 20}, {"type": "text", "text": "D Network architecture of policy and value in retrosynthesis planning ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Each molecule is encoded using a 2048-dimensional Morgan Fingerprint vector [45] as the input for the heuristic functions. The policy network is a multi-class task based on chemical reaction templates. 381302 templates are available. The policy network architecture is summarized as follows: ", "page_idx": 21}, {"type": "text", "text": "\u2022 A fully connected layer with dimensions [2048, 512].   \n\u2022 A batch normalization layer.   \n\u2022 A dropout layer with a dropout rate of 0.3.   \n\u2022 Another fully connected layer with dimensions [512, 381302].   \n\u2022 A softmax layer. ", "page_idx": 21}, {"type": "text", "text": "The top 50 reaction templates with the highest probabilities are retained, and corresponding chemical reactions are generated using rdchiral package [12], an RDKit [32] wrapper for handling stereochemistry in retrosynthetic template extraction and application. ", "page_idx": 21}, {"type": "text", "text": "The output of the value network is a scalar to estimate the synthetic cost of the input molecules. The architecture is summarized as follows: ", "page_idx": 21}, {"type": "text", "text": "\u2022 A fully connected layer with dimensions [2048, 128].   \n\u2022 A ReLU activation layer.   \n\u2022 A dropout layer with a dropout rate of 0.1.   \n\u2022 A fully connected layer with dimensions [128, 1].   \n\u2022 Normalize the output $y$ with $\\mathit{l o g}(1+e^{y})$ . ", "page_idx": 21}, {"type": "text", "text": "Parameters of the policy and value network are the same with Retro $^{*}+$ [30]. No fine-tuning has been performed on the network. ", "page_idx": 21}, {"type": "text", "text": "E Introduction of test molecule datasets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Besides the USPTO benchmark, six additional datasets comprising 4719 molecules are employed for ro- bust validation. The introduction of these datasets is as follows. ", "page_idx": 21}, {"type": "text", "text": "logP [7]: The logarithm of the partition coefficient (logP) is a measure of the solubility of a molecule in a particular solvent. The logS of a molecule can affect the molecule\u2019s pharmacokinetics and pharmacodynamics. ", "page_idx": 21}, {"type": "text", "text": "logS [60]: It is used to evaluate the solubility of molecules, which can affect the absorption, distribution, metabolism, and excretion (ADME) of a drug candidate. ", "page_idx": 21}, {"type": "text", "text": "Toxicity LD50 [56]: Toxicity plays a key role in determining the safety and efficacy of drugs. ", "page_idx": 21}, {"type": "text", "text": "Ames [25]: The Ames test is commonly used in the field of drug development to evaluate the potential mutagenicity of drug candidates, as well as other chemicals that may be used in drug manufacturing or as excipients. ", "page_idx": 21}, {"type": "text", "text": "BBBP [35]: Blood-brain barrier (BBB) is a protective barrier that separates the bloodstream from the brain to prevent harmful substances from entering the brain. BBB penetration (BBBP) is considered when developing new drugs. ", "page_idx": 21}, {"type": "text", "text": "ClinTox [21]: It is a dataset collecting drugs approved by the FDA and drugs that have failed clinical trials for toxicity reasons. ", "page_idx": 21}, {"type": "text", "text": "To clean these datasets, molecules present in either the USPTO database or the building block set are removed. Additionally, molecules that can be solved by Retro\u2217in one step and those that can be easily solved by a heuristic-based BFS planning algorithm within a fixed time limit are also excluded. After processing, 4719 molecules are retained. ", "page_idx": 21}, {"type": "text", "text": "F Search tree representation in retrosynthesis planning ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The search tree employed in this paper in retrosynthesis planning problem is displayed in Figure 4. The initial state contains only the target molecule. The edges in the search tree represent the chemical reactions that enable state transitions between the connected nodes, which decompose the input product into its reactants. A state is a set of molecules that are able to synthesize the target molecule, which is decomposed from the target molecule along the traverse reaction path from the root to this node. The retrosynthetic planning problem is solved if all molecules within a state are available building blocks. For A single-step retrosynthetic prediction model is utilized as the policy model to generate potential chemical reactions yielding the input molecule. For non-terminal intermediate nodes, all molecules within the node are sorted in alphabetical order based on their SMILES representation. The first non-building block molecule in the sorted list is selected as the input molecule of the single-step prediction model. The number of available reactions provided by the policy for a given node corresponds to the number of branching factors within the search tree. ", "page_idx": 22}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/7bd199384487026bca0fec5b308c9139a02d6d993f3f4d1a7ac4665f3fcef8e5.jpg", "img_caption": ["Figure 4: The process involves transforming the representation of the chemical retrosynthetic route into the search tree representation used in this paper. (a) is the real chemical retrosynthetic route, in which the reverse reaction decomposes the input product molecule into several reactant molecules; (b) is the corresponding search tree representation, and each node in the tree contains all molecules decomposed from the target molecule along the traverse reaction path from the root to this node. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Retro\u2217and Retro $^{*}+$ utilize the AND-OR tree as the representation for the planning process. In this representation, a reaction is denoted by an AND node, with its child nodes representing the reactant molecules involved in that reaction. Similarly, a molecule is represented by an OR node, with its child nodes representing the chemical reactions capable of synthesizing that molecule. A chemical reaction can be taken if all of its child reactants can be synthesized, and a chemical molecule can be synthesized if there exists at least one child chemical reaction that can take place. We also applied ", "page_idx": 22}, {"type": "text", "text": "SeeA\u2217to the And-OR Tree framework, and under the same settings, utilizing the uniform sampling strategy to obtain candidate nodes, we observed an increase in success rate from Retro $^{*}+$ \u2019s $91.\\bar{0}5\\bar{\\%}$ to $92.\\bar{11\\%}$ in USPTO benchmark. The averafe siolution length is decreased from Retro $^{*}+$ \u2019s 8.74 to 8.39. This finding demonstrates the effectiveness of the algorithm in the AND-OR tree structure. ", "page_idx": 23}, {"type": "text", "text": "G Test results on each dataset for retrosynthetic planning ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Average test results on the seven molecule datasets and results for the six additional testing molecule datasets are presented in Table 3 and 4 respectively. $\\mathrm{\\mathbf{S}e e A^{*}}$ achieves the maximum number of problem-solving instances and obtains the shortest solution length across all datasets. ", "page_idx": 23}, {"type": "table", "img_path": "mSaqxZVZW8/tmp/fda3d9b5005ea64265ee50834138a56d9ead65a9de8cc18fa16afcbe7054e0a2.jpg", "table_caption": ["Table 3: Test success accuracy on the seven dataset for retrosynthetic planning problem $(\\%)$ . "], "table_footnote": [], "page_idx": 23}, {"type": "table", "img_path": "mSaqxZVZW8/tmp/56f1d2fdc9357ddbf18227a28b5d42e2b03c1357559c033621946863a61222a8.jpg", "table_caption": ["Table 4: Test solution length on the seven dataset for retrosynthetic planning problem. "], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "H Introduction for logic synthesis problem ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Logic synthesis is the process of transforming a hardware design at the register transfer level (RTL) into a Boolean gate-level network, which is represented by an and-inverter-graph (AIG), i.e., a netlist exclusively containing AND and NOT gates. Subsequently, a sequence of functionalitypreserving transformations is applied to generate an optimized AIG. Seven operations are allowed following the work of ABC [4] and other reinforcement learning algorithms [9, 29], including balance, re-substitution, re-substitution -z, rewrite, rewrite -z, refactor, and refactor -z. The number of transformations is limited to 10, which is the same with ABC-RL [9]. Finally, post-technology mapping is performed using a $7\\mathrm{nm}$ technology library to obtain the final netlist, which is also generated using the ABC package. Time delay and area are estimated by ABC to evaluate the solution. An example framework of solving the logic synthesis problem is presented in Figure 5. ", "page_idx": 23}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/67575762d5cbd66514430dff4d2271e41ea4c62706ba2637484115e8a57321fc.jpg", "img_caption": [], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Figure 5: An example of the logic synthesis problem. The design of the hardware is represented by an and-inverter graph. After a series of transformations, a more refined AIG is obtained, while maintaining the same function as the original AIG. While preserving the input and output relationship, the number and connectivity of intermediate nodes are optimized. Post-technology mapping and final evaluation are conducted with the ABC package. ", "page_idx": 24}, {"type": "text", "text": "I Introduction of the MCNC dataset ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "According to the partitioning in ABC-RL [9], A total of 15 circuits from the MCNC dataset [63] are utilized as training circuits, while the remaining 12 circuits from the same dataset are employed to evaluate the performance. The number of nodes in the initial AIG of each circuit ranges from hundreds to thousands. The information about the circuits is summarized in Table $5\\;\\&\\;6$ . The number of input and output nodes varies from a few to several hundred, while the total number of nodes ranges from several hundred to thousands. ", "page_idx": 24}, {"type": "table", "img_path": "mSaqxZVZW8/tmp/fc43e3679341ee3e5053cdd4246ea7a6af3e06132b88cc9cdb9607ec3f77ea8d.jpg", "table_caption": ["Table 5: Characterization of training circuits from MCNC dataset. "], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "J Value estimator for logic synthesis problem ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "The input of the value estimator consists of the initial AIG and the sequence of actions that have been taken. Nodes in the AIG (And-Inverter Graph) are represented by a two-dimensional vector, which records the node type and the number of inverted predecessors. The adjacency matrix is used to capture the node connectivity. Graph convolutional network (GCN) is used to extract the embedding for AIG, and the architecture is summarized as follows: ", "page_idx": 24}, {"type": "table", "img_path": "mSaqxZVZW8/tmp/0939e65605ba901e8be50c4a38d8fbf4df9f900ee8ff16e688102645d8e623a5.jpg", "table_caption": ["Table 6: Characterization of testing circuits from MCNC dataset. "], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "\u2022 A GCN (Graph Convolutional Network) layer with a hidden size of 32.   \n\u2022 A batch normalization layer.   \n\u2022 A LeakyReLU activation layer.   \n\u2022 A GCN layer with a hidden size of 32.   \n\u2022 A batch normalization layer.   \n\u2022 Mean pooling and max pooling are independently applied, and the outputs are concatenated to form the final embedding, which is a 64 dimension vector. ", "page_idx": 25}, {"type": "text", "text": "The sequence of actions and the current number of steps are combined into a string, which serves as the input to the BERT model [15] to obtain a sequence embedding with 768 dimensions. AIG embedding and sequence embedding are concatenated together as the input of the value estimator, and the architecture is: ", "page_idx": 25}, {"type": "text", "text": "\u2022 A fully connected layer with dimensions [832, 256].   \n\u2022 A LeakyReLU activation layer.   \n\u2022 A fully connected layer with dimensions [256, 256].   \n\u2022 A LeakyReLU activation layer.   \n\u2022 A fully connected layer with dimensions [256, 1].   \n\u2022 A Tanh activation layer. ", "page_idx": 25}, {"type": "text", "text": "MCTS simulations are performed on the training circuits to collect samples. During the evaluation of the leaf node before backpropagation, a complete search path is obtained through a fast rollout, which is then stored as a training dataset for the value estimator. 1500 action sequences are collected for each circuit. resyn2 synthesis recipe is used as the baseline during the evaluation. The area-delay product reduction for an action sequence $P$ is defined as ", "page_idx": 25}, {"type": "equation", "text": "$$\nA D P R(A I G,P)=1-\\frac{A D P(A I G,P)}{A D P(A I G,r e s y n2)},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where ADP is $A r e a\\times D e l a y$ . The reward in logic synthesis problem is ", "page_idx": 25}, {"type": "equation", "text": "$$\nR(A I G,P,t)={\\left\\{\\begin{array}{l l}{\\operatorname*{max}\\{-1,A D P R(A I G,P)\\},}&{{\\mathrm{if~}}t=|P|}\\\\ {0,}&{{\\mathrm{Otherwise}}}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $t$ is the index of the current step. The immediate reward is always 0 except for the last step. Therefore, the ground truth value for states in the sequence $P$ are all equal to ", "page_idx": 25}, {"type": "text", "text": "$\\operatorname*{max}\\{-1,A D P R(A I G,P)\\}$ . Mean square error loss is used as the learning target. Adam optimizer is employed to update the parameter with a 0.0001 learning rate. The learning process is presented in Figure 6. ", "page_idx": 26}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/9625358deac1b5300d2e096859de3e54b7752dc5c346d4d131305dc5f9c32158.jpg", "img_caption": ["Figure 6: Training loss of the value estimator for the logic synthesis problem. "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "During testing, the number of the candidate nodes is fixed at $K=5$ in uniform sampling. In the clustering sampling strategy, $N_{c}\\,=\\,5$ clusters are employed and 2 nodes are sampled from each cluster. The parameter $\\eta$ is set to 0.2. In the UCT-like sampling, $K=5$ and $c_{b}=1.38$ . ", "page_idx": 26}, {"type": "text", "text": "K An example of different search algorithms to solve logic synthesis ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "The search trees for $\\mathbf{A}^{*}$ search, MCTS, and $\\mathrm{{SeeA^{*}}}$ when solving the logic synthesis problem for the alu4 circuit are depicted in Figure 7, 8, and 9, respectively. For $\\mathbf{A}^{*}$ search, the initial three actions are consistently $\"113\"$ , indicating that the search process is trapped in a particular branch due to the lack of exploration. Due to the enforced exploratory nature, MCTS expands nodes across excessive branches, which can impede the efficiency of the search algorithm in generating solutions. SeeA\u2217 expands a moderate number of branches, striking a balance between the concentrated exploration of $\\mathbf{A}^{*}$ and the excessive expansion across multiple branches in MCTS. This approach allows for exploratory behavior without being confined to a single branch, while the selection of the candidate node with the minimum $f$ -value prevents excessive expansion into irrelevant branches. As a result, SeeA\u2217exhibits significant improvements in efficiency compared to both MCTS and $\\mathbf{A}^{*}$ . ", "page_idx": 26}, {"type": "text", "text": "L Value estimator for Sokoban problem ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Sokoban is a puzzle video game where the objective is to move the crates strategically to push each crate to its corresponding storage locations. The input of the neural network is a four-dimensional tensor representing the positions of the box, the target, the person, and the walls, respectively. The architecture of the value estimator is summarized as: ", "page_idx": 26}, {"type": "text", "text": "\u2022 A convolutional layer with a kernel size of $64\\times3\\times3$ .   \n\u2022 A batch normalization layer. ", "page_idx": 26}, {"type": "text", "text": "\u2022 A ReLU activation layer. ", "page_idx": 27}, {"type": "text", "text": "\u2022 A ResNet with three residual blocks.   \n\u2022 A convolutional layer with a kernel size of $1\\times1\\times1$ .   \n\u2022 A batch normalization layer.   \n\u2022 A ReLU activation layer.   \n\u2022 A fully connected layer with dimensions [100, 1]. ", "page_idx": 27}, {"type": "text", "text": "\u2022 A ReLU activation layer. ", "page_idx": 27}, {"type": "text", "text": "The DeepCubeA paper provides 50, 000 training Sokoban problems and $1,000$ testing Sokoban problems. The $\\mathbf{A}^{*}$ search guided by a manually designed heuristic is employed to find solutions for the training problems. $g$ is the number of steps arriving at the current state. $h$ is the sum of distances between the boxes and their respective goals, as well as the distance between the person and the nearest box. Under limited search time, 46, 252 training problems are solved. For each collected trajectory $\\{n_{0}^{i},n_{1}^{i},\\cdot\\cdot\\cdot\\,,n_{t}^{i},\\cdot\\cdot\\cdot\\,,n_{T_{i}}^{i}\\}$ , the learning target for state $n_{t}^{i}$ is the number of steps from $n_{t}^{i}$ to the goal state nTi: ", "page_idx": 27}, {"type": "equation", "text": "$$\nz(n_{t}^{i})=T_{i}-t.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Mean square error is employed as the loss function: ", "page_idx": 27}, {"type": "equation", "text": "$$\nL(\\theta)=\\frac{\\sum_{i}\\sum_{t}(v(n_{t}^{i};\\theta)-z(n_{t}^{i}))^{2}}{\\sum_{i}T_{i}}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Adam optimizer with a 0.0001 learning rate is used to update the parameters. ", "page_idx": 27}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/ad2ab0682b387d894423a5c3357053e89542af564bd9887407abd7efe2e855f6.jpg", "img_caption": ["Figure 7: The search tree of $\\mathbf{A}^{*}$ search when solving logic synthesis problem for alu4. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/660f6de560516f34050e5278563cc8e4770b1f1ca10dc936cb43878b6e1512a4.jpg", "img_caption": ["Figure 8: The search tree of MCTS when solving logic synthesis problem for alu4. "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/0b64fc45fc43d92a6d8f586b947cc92b45558c5f541e20888f26584ce33081b4.jpg", "img_caption": ["Figure 9: The search tree of SeeA\u2217search when solving logic synthesis problem for alu4. "], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "M Test results for Sokoban problem ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "The search process allows a maximum of $10^{5}$ expansions. The size of the candidate set in $\\mathrm{\\mathbf{S}e e A^{*}}$ is set to $K=100$ . In the clustering sampling strategy, $N_{c}=2$ clusters are employed and the parameter $\\eta$ is set to 0.1. In the UCT-like sample, $c_{b}$ is set 0.3. Experiment results are summarized in Table 7. With the exploration behavior induced by the selective sampling, $\\mathrm{\\mathbf{S}e e A^{*}}$ yields shorter solutions than $A^{*}$ with a slight increase in the number of expanded nodes. By setting $\\varepsilon=1.5$ , $\\mathrm{WA^{*}}$ identifies feasible solutions using the minimum average number of node expansions. However, the solutions by $\\mathrm{WA^{*}}$ tend to have longer lengths, indicating that excessive reliance on the heuristic function biases the search towards suboptimal solutions. ", "page_idx": 28}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/7fdd1219e48b8206b02eb09bf4841ef4231b99054e2804f617031c4cd93dbe2a.jpg", "img_caption": ["Figure 10: Training loss of the value estimator for the Sokoban problem. "], "img_footnote": [], "page_idx": 29}, {"type": "table", "img_path": "mSaqxZVZW8/tmp/ab7335c70f947c7960e332f1590abab725e958316a61fa6c9cd73dd080ed2d41.jpg", "table_caption": ["Table 7: Test results on 1000 Sokoban cases. (Results of LevinTS, PHS, and DeepCubeA are provided by [38], [39], and [1], respectively. "], "table_footnote": [], "page_idx": 29}, {"type": "text", "text": "N Test results for path finding ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "To illustrate the effectiveness of $\\mathrm{{SeeA^{*}}}$ on problems where accurate heuristics could exist but the guiding heuristic used is unreliable, experiments on path finding are conducted, which is to find the shortest path from a starting point to a destination. The cost for each step is 1. $g$ is the number of steps taken to reach the current position, and $h$ is the Euclidean distance from the current position to the target position, which is reliable enough to guide the $\\mathbf{A}^{*}$ search in early studies. 100 robotic motion planning problems [3] are used to test the performance of $\\mathbf{A}^{*}$ and $\\mathrm{{SeeA^{*}}}$ . Under the guidance of the same reliable $h$ , both $\\mathbf{A}^{*}$ and $\\mathrm{{SeeA^{*}}}$ find the optimal solutions for all testing cases, for which the average length is 400. The number of expansions of ${\\mathrm{SeeA}}^{*}(K=5)$ ) with uniform sampling is 33283.21, slightly less than the 33340.52 of $\\mathbf{A}^{*}$ . To validate the superiority of $\\mathrm{\\mathbf{S}e e A^{*}}$ , an unreliable heuristic function $\\hat{h}$ is designed, which is randomly sampled from $[0,2\\times h]$ . During the search process, nodes are evaluated by $\\hat{f}=g\\!+\\!\\hat{h}$ . In this situation, the average solution length of $\\mathbf{A}^{*}$ is 691.1, much longer than SeeA\u2217\u2019s 438.4. Moreover, $\\mathbf{A}^{*}$ requires 50281.28 expansions, which is significantly more than the 32847.26 expansions needed by $\\mathrm{{SeeA^{*}}}$ . Therefore, guided by an unreliable heuristic, SeeA\u2217finds a better solution than $\\mathbf{A}^{*}$ with fewer expansions, demonstrating the superiority of $\\mathrm{{SeeA^{*}}}$ . ", "page_idx": 29}, {"type": "text", "text": "O Investigations on the hyperparameters ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Success rate and average solution length on the USPTO benchmark for the retrosyhthesis planning problem with different hyperparameter settings are displayed in Figure 11, $12\\,\\&\\,13$ . ", "page_idx": 30}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/0f5e64c158eef9c0a15bfa8983d7922e9559a0d3dfa89cf5af7187e9d4033bab.jpg", "img_caption": ["Figure 11: Success rate and average solution length on the USPTO benchmark with different candidate set sizes $K$ in uniform sampling strategy. "], "img_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/8f2995133ca672fb63867af2a0aa6ae043bb792e0e0ebb0e082b2e44b3578f21.jpg", "img_caption": ["Figure 12: Success rate and average solution length on the USPTO benchmark with different number of clusters in clustering sampling strategy $[K=50]$ ). "], "img_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/e8339ba55e4f5921bdc0d3eae04dffcfce84765f48b9b31971b6962f97b4d69d.jpg", "img_caption": ["Parameter $c_{b}$ "], "img_footnote": [], "page_idx": 31}, {"type": "text", "text": "Figure 13: Success rate and average solution length on the USPTO benchmark with different $c_{b}$ in UCT-like sampling strategy $[K=50]$ ). ", "page_idx": 31}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/3ffcced3fbc7b969ddd58be1039748bb425284bb00d6eb07aea1a5d82834414b.jpg", "img_caption": ["Candidate size K "], "img_footnote": [], "page_idx": 31}, {"type": "text", "text": "Figure 14: Average solution length and average number of node expansions tested on the Sokoban game with different candidate set sizes $K$ in uniform sampling strategy. ", "page_idx": 31}, {"type": "text", "text": "Ablation studies on logic synthesis are summarized below. The performance for different candidate set sizes $K$ for $\\mathrm{\\mathbf{S}e e A^{*}}$ with uniform sampling is displayed in Table 8. The performance is robust against different $K$ , outperforming $\\mathbf{A}^{*}$ ( $K=\\infty$ ) consistently. ", "page_idx": 32}, {"type": "table", "img_path": "mSaqxZVZW8/tmp/807df883d76be31467943fc3b0cb5d851b415aec9ec3900faa73c146f7f22909.jpg", "table_caption": ["Table 8: Test results on logic synthesis with different $K$ in uniform sampling strategy. "], "table_footnote": [], "page_idx": 32}, {"type": "table", "img_path": "mSaqxZVZW8/tmp/d0842773bb7ba2fc56fbd790fac6de5e5a01b12a93bca07365f66ce20dbd2af8.jpg", "table_caption": ["Table 9: Test results on logic synthesis with different $c_{b}$ in UCT-like sampling strategy. "], "table_footnote": [], "page_idx": 32}, {"type": "text", "text": "The performance for different $c_{b}$ for UCT-like sampling is presented in Table 9, which is robust against different $c_{b}$ . enhanced exploration with a larger $c_{b}$ leads to superior performance and longer running time. ", "page_idx": 32}, {"type": "text", "text": "For the sokoban game, the average solution length and the average number of node expansions for uniform sampling strategy with different candidate sizes $K$ are presented in Figure 14. With the exploration behavior induced by the selective sampling, SeeA\u2217yields shorter solutions than $\\mathbf{A}^{*}$ with a slight increase in the number of expanded nodes. The success rate of problem-solving is $100.0\\%$ . The ablation studies on the UCT-like sampling strategy are displayed in Table 10. Under a limited number of expansions, the stronger the exploration with a larger $c_{b}$ , the shorter the identified solution path length, and the greater the number of expansions required to find a feasible solution. Sokoban permits at most four legal actions at each step, which makes the number of open nodes $N_{o}$ grow slowly. What\u2019s more, the state space of Sokoban $(10\\times10)$ is limited, and training a reliable cost function is relatively easier compared to retrosynthetic planning. According to Theorem 4.3, a larger $N_{o}$ and a less accurate cost estimator make the advantage of $\\mathrm{{SeeA^{*}}}$ more evident. Therefore, SeeA\u2217 is only slightly better than $\\mathbf{A}^{*}$ in Sokoban problem. ", "page_idx": 32}, {"type": "text", "text": "Table 10: Test results on Sokoban game with different $c_{b}$ in UCT-like sampling strategy $\\langle K=100\\rangle$ ). ", "page_idx": 32}, {"type": "table", "img_path": "mSaqxZVZW8/tmp/bd6776e5644c50b6684a06384926b1bc3e240bf03c5a60957f6e311ba947191b.jpg", "table_caption": [], "table_footnote": [], "page_idx": 32}, {"type": "text", "text": "P Comparison between $\\varepsilon$ -Greedy and SeeA\u2217 ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Both $\\varepsilon$ -Greedy and SeeA\u2217involve introducing exploration to $\\mathbf{A}^{*}$ search. $\\varepsilon$ -Greedy selects the node with the best $f$ -value with a probability of $1-\\varepsilon$ , and with a probability of $\\varepsilon$ , it randomly selects a node from the remaining nodes. SeeA\u2217with uniform sampling strategy selects a candidate set uniformly and the node with the best $f$ value within this candidate set is expanded. An example of the comparison of these two algorithms is given in Figure 15. There are five nodes $\\{s_{1},s_{2},s_{3},s_{4},s_{5}\\}$ , and the $f$ values estimated by the heuristic value function are in increasing order. In $\\mathbf{A}^{*}$ search, node $s_{1}$ is expanded with a probability of $100\\%$ . In $\\varepsilon$ -Greedy $\\varepsilon=0.5)$ ), there is a $60\\%$ probability of expanding node $s_{1}$ , and each of the remaining nodes has a $10\\%$ probability of being expanded. SeeA\u2217 expands $s_{1}$ (the node with the smallest $f$ value) with a probability of $60\\%$ . It expands $s_{2}$ (the node with the second smallest $f$ value) with a probability of $30\\%$ , and $s_{3}$ (the node with the third smallest $f$ value) with a probability of $10\\%$ . The remaining two nodes with the largest $f$ values are not eligible for expansion. Even though the selection of candidate nodes follows uniform sampling, which is quite random, only the candidate node with the smallest $f$ value is expanded. This guarantees the quality of the expanded nodes, as nodes with significantly worse $f$ values do not have a chance to be expanded, even if they might have been selected as candidates. Assuming there are $N_{o}$ open nodes and the size of the candidate set is $K$ . ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/5eaee52e163e853d827d28b55dea5c1963a73bea3d6ca30a4ee436522bca1ba6.jpg", "img_caption": [], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "mSaqxZVZW8/tmp/c8a7fc40b4a0b8eac1eda12ed9efa0695b0273036c2a1b82f0c0d7fd806248d4.jpg", "img_caption": [], "img_footnote": [], "page_idx": 33}, {"type": "equation", "text": "$$\nP(s_{4}\\;{\\mathrm{is~expanded}})=P(s_{5}\\;{\\mathrm{is~expanded}})=0\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Figure 15: (a) An example of the difference of expansion probability for each node for $\\varepsilon$ -Greedy and $\\mathrm{\\mathbf{S}e e A^{*}}$ (Uniform sampling strategy is employed and the candidate size $K=3$ ). (b) Expanded probability calculation for SeeA\u2217. There are ten possible combinations of the candidate sets, and each combination occurs with equal probability. ", "page_idx": 33}, {"type": "text", "text": "The probability of expanding the node with the $n$ th smallest $f$ value under the uniform sampling strategy can be derived as follows: ", "page_idx": 34}, {"type": "equation", "text": "$$\nP(x^{(n)})=\\left\\{\\begin{array}{l l}{\\frac{\\binom{N_{e}-n}{K-1}}{\\binom{N_{o}}{K}}=\\frac{K(N-n)!(N-K)!}{N_{o}!(N_{o}-K-n+1)!},}&{\\mathrm{if}\\;n\\leq N_{o}-K+1}\\\\ {0,}&{\\mathrm{Otherwise}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "The probability of being selected for expansion decreases gradually as the $f$ value increases. Compared to $\\varepsilon$ -Greedy, $\\mathrm{{SeeA^{*}}}$ utilizes the $f$ value to avoid excessive exploration in its decision process. Even though the estimated $f$ value may be not reliable enough to guarantee that the node with the smallest $f$ value is the real optimal node to be expanded, the $f$ value still can serve as a measure of node quality within a certain range. The heuristic function possesses a certain level of reliability, and it is generally inappropriate to either completely trust, like $\\mathbf{A}^{*}$ search, or completely disregard, like $\\varepsilon$ -Greedy, the evaluations provided by the heuristic function. $\\mathrm{{SeeA^{*}}}$ aims to achieve a balance between fully trusting and fully disregarding the evaluations of the heuristic function. ", "page_idx": 34}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: The main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope, as illustrated in line 7 - 19 in the abstract and the line 47 - 64 in the introduction. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 35}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Justification: The limitation is pointed in the conclusion part in Line $360\\,-\\,367$ . Our algorithm is more efficient when the estimation of the heuristic function is not accurate enough. If the model exhibits precise state evaluation, the incorporation of exploration into $\\mathbf{A}^{*}$ search becomes redundant. Investigations on more efficient sampling strategy is necessary in the future. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 35}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Justification: The assumption and proofs are provided in the section \"Efficient of SeeA\u2217 search\" and Appendix C. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 36}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: The algorithm is well describe in the Method section, and the pseudocode for the algorithm is provided in the Appendix A. What\u2019s more, the source code will be released after acceptance. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 36}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 37}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 37}, {"type": "text", "text": "Answer:[Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: The source code will be published once accepted. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 37}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: The training and test details are included in the Experiments part and Appendix G, J and M. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 37}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 37}, {"type": "text", "text": "Answer: [No] ", "page_idx": 37}, {"type": "text", "text": "Justification: Considering the computation resources required, the error bar is not provided in this paper, but we are trying to make it available in the final version. Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 38}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: As illustrated in the Experiments section, our experiments are conducted using NVIDIA Tesla V100 GPUs and an Intel(R) Xeon(R) Gold 6238R CPU ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 38}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: Research conducted in this paper conform with the NeurIPS code of Ethics. Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 38}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: The discussion on the impacts of the work is provided in the Conclusion section in Line 367 - 369. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 39}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: SeeA\u2217is an efficient search algorithm, and no specific model or dataset are employed. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 39}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 39}, {"type": "text", "text": "Justification: All assets used in this paper are publicly available. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 39}, {"type": "text", "text": "", "page_idx": 40}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: This paper is about a new algorithm without new assets. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 40}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 40}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 40}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 41}]