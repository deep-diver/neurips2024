[{"figure_path": "9O2sVnEHor/tables/tables_7_1.jpg", "caption": "Table 2: Test MAE for homomorphism- and subgraph-counts. Results from (B. Zhang et al., 2024).", "description": "This table compares the performance of various graph neural network models (MPNN, Subgraph GNN, Local 2-GNN, Local 2-FGNN, and r-lGIN) on the SUBGRAPHCOUNT dataset.  The models are evaluated based on their ability to accurately predict homomorphism counts (hom(F, G)) and subgraph counts (sub(F, G)) for different motifs (F). Lower values in the table indicate better performance. The r-lGIN model shows significantly better performance than other models, demonstrating its effectiveness in subgraph counting.", "section": "Counting Power"}, {"figure_path": "9O2sVnEHor/tables/tables_8_1.jpg", "caption": "Table 3: Test MAE (\u2193) on ZINC dataset.", "description": "This table presents the Mean Absolute Error (MAE) achieved by various graph neural network models on the ZINC12K and ZINC250K datasets.  Lower MAE indicates better performance.  The models tested include standard MPNNs (GIN, GCN, GAT), Subgraph GNNs (NestedGNN, GNNAK+, SUN), domain-agnostic GNNs (GSN, CIN), a GNN processing paths (PathNN), and expressive GNNs with provable cycle-counting power (HIMP, SignNet, I2-GNN, DRFWL), as well as the proposed 5-lGIN. The results highlight the performance of 5-lGIN in comparison to other state-of-the-art models.", "section": "7 Experiments"}, {"figure_path": "9O2sVnEHor/tables/tables_8_2.jpg", "caption": "Table 4: Normalized test MAE (\u2193) on QM9 dataset. Top three models as 1st, 2nd, 3rd.", "description": "This table presents the normalized test mean absolute error (MAE) achieved by various models on the QM9 dataset.  The MAE is a common metric to evaluate the performance of regression models, representing the average absolute difference between predicted and actual values. Lower MAE indicates better performance.  The table compares the performance of 5-lGIN against other models, highlighting its performance relative to other approaches on various target properties.", "section": "7 Experiments"}, {"figure_path": "9O2sVnEHor/tables/tables_19_1.jpg", "caption": "Table 5: Hyperparameter configuration for synthetic experiments.", "description": "This table shows the hyperparameter settings used for the synthetic experiments in the paper.  It lists the values used for various parameters, such as the number of epochs, learning rate, early stopping criteria, scheduler type, hidden size, number of layers (encoder and decoder), batch size, dropout rate, and readout method.  These parameters were tuned for different synthetic datasets, namely GRAPH8C, EXP_ISO, COSPECTRAL10, SR16622, EXP, CEXP, CSL, SUBGRAPHCOUNT, and BREC. The values listed represent those used to generate the reported results for those datasets.", "section": "C Experimental Details"}, {"figure_path": "9O2sVnEHor/tables/tables_20_1.jpg", "caption": "Table 7: Hyperparameters configuration for real-world experiments.", "description": "This table presents the hyperparameter settings used for the experiments conducted on real-world datasets.  It includes the number of epochs, learning rate, early stopping criteria, learning rate scheduler, the value of the hyperparameter *r*, hidden size, depth of the network, batch size, dropout rate, readout method, total number of parameters, preprocessing time in seconds, and the run time per seed in hours.  The specific hyperparameters varied across datasets to optimize performance, and the table indicates these variations for each dataset (ZINC12K, ZINC250K, and QM9 for different properties).", "section": "7 Experiments"}, {"figure_path": "9O2sVnEHor/tables/tables_20_2.jpg", "caption": "Table 8: Ablation study on the effect of r in r-lGIN, ZINC12K.", "description": "This table shows the ablation study on the effect of different values of the hyperparameter *r* on the performance of the r-lGIN model on the ZINC12K dataset.  It demonstrates the impact of incorporating paths of varying lengths into the model's architecture, showing how this affects both training and test performance as measured by Mean Absolute Error (MAE).", "section": "7 Experiments"}, {"figure_path": "9O2sVnEHor/tables/tables_21_1.jpg", "caption": "Table 9: Test metrics on long-range graph benchmark datasets (Dwivedi et al., 2022b). The baseline results are obtained from (Dwivedi et al., 2022b, Table 4). Our method is able to enhance performance over standard baselines.", "description": "This table presents the results of experiments conducted on long-range graph benchmark datasets.  It compares the performance of the proposed 7-lGIN model against several baseline models (GCN, GINE, GatedGCN) on two specific tasks: STRUCT (predicting structural properties) and FUNC (predicting functional properties).  The metrics used are Mean Absolute Error (MAE) for STRUCT (lower is better) and Average Precision (AP) for FUNC (higher is better). The baseline results are taken from a previous study by Dwivedi et al. (2022b).", "section": "7 Experiments"}, {"figure_path": "9O2sVnEHor/tables/tables_21_2.jpg", "caption": "Table 10: Empirical time complexity for QM9 dataset; results from (Zhou et al., 2023). In parenthesis the size of the dataset after the computation of r-neighborhoods.", "description": "This table compares the memory usage, preprocessing time, and training time per epoch for different models on the QM9 dataset.  It shows that the proposed r-lGIN models have relatively low memory usage and training time compared to other models, especially as the value of 'r' increases. The numbers in parentheses show the size of the dataset *after* the r-neighborhoods have been computed; this is relevant because computation of these neighborhoods is a preprocessing step, and the table shows that the size of this dataset does not increase dramatically with r.", "section": "7 Experiments"}]