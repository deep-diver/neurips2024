<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/</link><description>Recent content on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Tue, 29 Oct 2024 20:55:37 +0100</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/index.xml" rel="self" type="application/rss+xml"/><item><title>About This Project</title><link>https://deep-diver.github.io/neurips2024/about/</link><pubDate>Tue, 29 Oct 2024 20:55:37 +0100</pubDate><guid>https://deep-diver.github.io/neurips2024/about/</guid><description>&lt;h1 class="relative group">Welcome to AI Paper Reviewer!
&lt;div id="welcome-to-ai-paper-reviewer" class="anchor">&lt;/div>
&lt;/h1>
&lt;p>AI Paper Reviewer is a unique platform dedicated to providing insightful reviews and summaries of artificial intelligence research papers. The content is entirely generated by advanced AI systems, offering a novel approach to understanding and disseminating complex scientific literature.&lt;/p></description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/about/cover.png"/></item><item><title>3D Gaussian Splatting as Markov Chain Monte Carlo</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ucst4gk6ix/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ucst4gk6ix/</guid><description>Researchers rethink 3D Gaussian Splatting as MCMC sampling, improving rendering quality and Gaussian control via a novel relocation strategy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ucst4gk6ix/cover.png"/></item><item><title>3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/p4s6fupcbg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/p4s6fupcbg/</guid><description>3DGS-Enhancer boosts unbounded 3D Gaussian splatting, generating high-fidelity novel views even with sparse input data using view-consistent 2D diffusion priors.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/p4s6fupcbg/cover.png"/></item><item><title>4+3 Phases of Compute-Optimal Neural Scaling Laws</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/avsxwicpak/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/avsxwicpak/</guid><description>Researchers discovered four distinct compute-optimal phases for training neural networks, offering new predictions for resource-efficient large model training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/avsxwicpak/cover.png"/></item><item><title>A generalized neural tangent kernel for surrogate gradient learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/kfdexqu6mc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/kfdexqu6mc/</guid><description>Researchers introduce a generalized neural tangent kernel for analyzing surrogate gradient learning in neural networks with non-differentiable activation functions, providing a strong theoretical foun&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/kfdexqu6mc/cover.png"/></item><item><title>A Geometric View of Data Complexity: Efficient Local Intrinsic Dimension Estimation with Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/nd8q4a8awl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/nd8q4a8awl/</guid><description>Diffusion models power FLIPD, a fast, single-model LID estimator.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/nd8q4a8awl/cover.png"/></item><item><title>A Near-optimal Algorithm for Learning Margin Halfspaces with Massart Noise</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/4aewzkwb5z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/4aewzkwb5z/</guid><description>Near-optimal algorithm achieves computationally efficient learning of margin halfspaces with Massart noise, nearly matching theoretical lower bounds.</description></item><item><title>A Neural Network Approach for Efficiently Answering Most Probable Explanation Queries in Probabilistic Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ufppf9ghzp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ufppf9ghzp/</guid><description>A novel neural network efficiently answers arbitrary Most Probable Explanation (MPE) queries in large probabilistic models, eliminating the need for slow inference algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ufppf9ghzp/cover.png"/></item><item><title>A Pairwise Pseudo-likelihood Approach for Matrix Completion with Informative Missingness</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zgn8dohpi6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zgn8dohpi6/</guid><description>New method recovers low-rank matrices with informative missingness, offering robust, near-optimal performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zgn8dohpi6/cover.png"/></item><item><title>A Phase Transition between Positional and Semantic Learning in a Solvable Model of Dot-Product Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bfwdipplgz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bfwdipplgz/</guid><description>A solvable model reveals a phase transition in dot-product attention, showing how semantic attention emerges from positional attention with increased data, explaining the qualitative improvements in l&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bfwdipplgz/cover.png"/></item><item><title>A Study of Plasticity Loss in On-Policy Deep Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/msuf8kpktf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/msuf8kpktf/</guid><description>On-policy deep RL agents suffer from plasticity loss, but this paper introduces &amp;lsquo;regenerative&amp;rsquo; methods that consistently mitigate this, improving performance in challenging environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/msuf8kpktf/cover.png"/></item><item><title>A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image Analysis</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/strpbhrvt3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/strpbhrvt3/</guid><description>KnoBo enhances deep learning models for medical image analysis by incorporating knowledge priors from medical textbooks, boosting out-of-domain performance by up to 32.4%.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/strpbhrvt3/cover.png"/></item><item><title>A Unified Debiasing Approach for Vision-Language Models across Modalities and Tasks</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/181llen2gw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/181llen2gw/</guid><description>SFID, a novel debiasing method, effectively mitigates bias in vision-language models across various tasks without retraining, improving fairness and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/181llen2gw/cover.png"/></item><item><title>A-FedPD: Aligning Dual-Drift is All Federated Primal-Dual Learning Needs</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/h1imvi2iem/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/h1imvi2iem/</guid><description>A-FedPD tackles federated learning&amp;rsquo;s &amp;lsquo;dual drift&amp;rsquo; problem by aligning global and local dual variables, resulting in faster convergence and enhanced stability for primal-dual methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/h1imvi2iem/cover.png"/></item><item><title>Accelerating Diffusion Models with Parallel Sampling: Inference at Sub-Linear Time Complexity</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/f9ndzhqtol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/f9ndzhqtol/</guid><description>Researchers achieve sub-linear time complexity for diffusion model inference using parallel sampling with poly-logarithmic time complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/f9ndzhqtol/cover.png"/></item><item><title>ACES: Generating a Diversity of Challenging Programming Puzzles with Autotelic Generative Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/l1mmk39z7p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/l1mmk39z7p/</guid><description>Autotelic Code Search (ACES) generates diverse, challenging Python programming puzzles by iteratively using LLM-generated semantic descriptors and measuring puzzle difficulty via LLM solver success ra&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/l1mmk39z7p/cover.png"/></item><item><title>Achieving Optimal Clustering in Gaussian Mixture Models with Anisotropic Covariance Structures</title><link>https://deep-diver.github.io/neurips2024/oral-others/ge8gzn8gtu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/ge8gzn8gtu/</guid><description>This research develops rate-optimal clustering algorithms for Gaussian Mixture Models with anisotropic covariance structures, bridging the gap between theoretical guarantees and practical efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/ge8gzn8gtu/cover.png"/></item><item><title>Acoustic Volume Rendering for Neural Impulse Response Fields</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/yckuxkw6ul/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/yckuxkw6ul/</guid><description>Acoustic Volume Rendering (AVR) revolutionizes realistic audio synthesis by adapting volume rendering to model acoustic impulse responses, achieving state-of-the-art performance in novel pose synthesi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/yckuxkw6ul/cover.png"/></item><item><title>Active Classification with Few Queries under Misspecification</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ma0993kzlq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ma0993kzlq/</guid><description>Learning halfspaces efficiently under noise is cracked! A novel query language enables a polylog query algorithm for Massart noise, overcoming previous limitations.</description></item><item><title>Adaptive Image Quality Assessment via Teaching Large Multimodal Model to Compare</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/mhtoyh5taj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/mhtoyh5taj/</guid><description>Compare2Score: A novel IQA model teaches large multimodal models to translate comparative image quality judgments into continuous quality scores, significantly outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/mhtoyh5taj/cover.png"/></item><item><title>Adaptive Randomized Smoothing: Certified Adversarial Robustness for Multi-Step Defences</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/mn4nt01teo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/mn4nt01teo/</guid><description>Adaptive Randomized Smoothing certifies deep learning model predictions against adversarial attacks by cleverly combining randomized smoothing with adaptive, multi-step input masking for improved accu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/mn4nt01teo/cover.png"/></item><item><title>Advancing Spiking Neural Networks for Sequential Modeling with Central Pattern Generators</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/kqmyidwbog/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/kqmyidwbog/</guid><description>Bio-inspired CPG-PE enhances spiking neural networks&amp;rsquo; sequential modeling by efficiently encoding position information, outperforming conventional methods across various tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/kqmyidwbog/cover.png"/></item><item><title>Adversarial Environment Design via Regret-Guided Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/eezclkwx6t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/eezclkwx6t/</guid><description>Regret-Guided Diffusion Models enhance unsupervised environment design by generating challenging, diverse training environments that improve agent robustness and zero-shot generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/eezclkwx6t/cover.png"/></item><item><title>Algebraic Positional Encodings</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/pfoeakxx6i/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/pfoeakxx6i/</guid><description>Revolutionizing Transformers, Algebraic Positional Encodings (APE) offers a theory-first approach to positional encoding, outperforming state-of-the-art methods without hyperparameter tuning across va&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/pfoeakxx6i/cover.png"/></item><item><title>Aligner-Encoders: Self-Attention Transformers Can Be Self-Transducers</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/seaumedrm5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/seaumedrm5/</guid><description>Transformers can now perform self-alignment, enabling simpler, faster speech recognition models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/seaumedrm5/cover.png"/></item><item><title>Aligner: Efficient Alignment by Learning to Correct</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/kq166jacvp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/kq166jacvp/</guid><description>Aligner efficiently aligns LLMs by learning to correct initial responses, achieving significant improvements in helpfulness and harmlessness across various models with resource efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/kq166jacvp/cover.png"/></item><item><title>An Analysis of Tokenization: Transformers under Markov Data</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/wm9jzq7rce/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/wm9jzq7rce/</guid><description>Tokenization&amp;rsquo;s crucial role in transformer language models is revealed: Transformers struggle on simple Markov data &lt;em>without&lt;/em> tokenization, but achieve near-optimal performance &lt;em>with&lt;/em> appropriate tok&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/wm9jzq7rce/cover.png"/></item><item><title>Analysing Multi-Task Regression via Random Matrix Theory with Application to Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ffw6rpz48z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ffw6rpz48z/</guid><description>This paper presents a novel theoretical framework for multi-task regression using random matrix theory, offering precise performance estimations and a closed-form solution for optimal hyperparameter t&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ffw6rpz48z/cover.png"/></item><item><title>Any2Graph: Deep End-To-End Supervised Graph Prediction With An Optimal Transport Loss</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/tpgagxpvcv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/tpgagxpvcv/</guid><description>Any2Graph: a novel deep learning framework using an Optimal Transport loss for accurate and efficient supervised graph prediction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/tpgagxpvcv/cover.png"/></item><item><title>Approximating mutual information of high-dimensional variables using learned representations</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/hn05dqxyll/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/hn05dqxyll/</guid><description>Latent Mutual Information (LMI) approximation accurately estimates mutual information in high-dimensional data using low-dimensional learned representations, solving a critical problem in various scie&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/hn05dqxyll/cover.png"/></item><item><title>Approximating the Top Eigenvector in Random Order Streams</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/gitgmieinf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/gitgmieinf/</guid><description>Random-order stream data necessitates efficient top eigenvector approximation; this paper presents novel algorithms with improved space complexity, achieving near-optimal bounds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/gitgmieinf/cover.png"/></item><item><title>Approximation-Aware Bayesian Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight-optimization/t7euv5dl5m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-optimization/t7euv5dl5m/</guid><description>Approximation-Aware Bayesian Optimization (AABO) boosts high-dimensional Bayesian optimization by jointly optimizing model approximation and data acquisition, achieving superior efficiency and perform&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-optimization/t7euv5dl5m/cover.png"/></item><item><title>Are Graph Neural Networks Optimal Approximation Algorithms?</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/sxrblm9ams/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/sxrblm9ams/</guid><description>Graph Neural Networks (GNNs) learn optimal approximation algorithms for combinatorial optimization problems, achieving high-quality solutions for Max-Cut, Min-Vertex-Cover, and Max-3-SAT, while also p&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/sxrblm9ams/cover.png"/></item><item><title>Are Language Models Actually Useful for Time Series Forecasting?</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/dv15ubhcy1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/dv15ubhcy1/</guid><description>Popular large language model (LLM)-based time series forecasting methods perform no better than simpler alternatives, often worse, and require vastly more compute.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/dv15ubhcy1/cover.png"/></item><item><title>Association of Objects May Engender Stereotypes: Mitigating Association-Engendered Stereotypes in Text-to-Image Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/shyqxpnblb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/shyqxpnblb/</guid><description>New framework, MAS, effectively mitigates stereotypes in text-to-image generation by aligning the probability distribution of generated images to stereotype-free distributions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/shyqxpnblb/cover.png"/></item><item><title>Assouad, Fano, and Le Cam with Interaction: A Unifying Lower Bound Framework and Characterization for Bandit Learnability</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/hugd1anmrp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/hugd1anmrp/</guid><description>This paper presents a novel unified framework for deriving information-theoretic lower bounds for bandit learnability, unifying classical methods with interactive learning techniques and introducing a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/hugd1anmrp/cover.png"/></item><item><title>Auditing Privacy Mechanisms via Label Inference Attacks</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ai76atrb2y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ai76atrb2y/</guid><description>New metrics audit label privatization, revealing differentially private schemes often outperform heuristic methods in the privacy-utility tradeoff.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ai76atrb2y/cover.png"/></item><item><title>Automated Efficient Estimation using Monte Carlo Efficient Influence Functions</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/2wfd3pti8v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/2wfd3pti8v/</guid><description>MC-EIF automates efficient statistical estimation for high-dimensional models, integrating seamlessly with existing differentiable probabilistic programming systems and achieving optimal convergence r&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/2wfd3pti8v/cover.png"/></item><item><title>Automatically Learning Hybrid Digital Twins of Dynamical Systems</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/sosiobsdu2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/sosiobsdu2/</guid><description>AI autonomously designs highly effective hybrid digital twins by combining neural networks and mechanistic models, significantly advancing digital twin technology.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/sosiobsdu2/cover.png"/></item><item><title>Autoregressive Image Generation without Vector Quantization</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vnbif0gmkb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vnbif0gmkb/</guid><description>Autoregressive image generation is revolutionized by eliminating vector quantization, achieving strong results with increased speed using a novel diffusion procedure.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vnbif0gmkb/cover.png"/></item><item><title>Axioms for AI Alignment from Human Feedback</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/cmbjkpruvw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/cmbjkpruvw/</guid><description>This paper revolutionizes AI alignment by applying social choice theory axioms to RLHF, exposing flaws in existing methods and proposing novel, axiomatically guaranteed reward learning rules.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/cmbjkpruvw/cover.png"/></item><item><title>BackTime: Backdoor Attacks on Multivariate Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/kl13lipxtw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/kl13lipxtw/</guid><description>BACKTIME unveils effective backdoor attacks on multivariate time series forecasting, highlighting vulnerabilities and offering novel defense strategies.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/kl13lipxtw/cover.png"/></item><item><title>Barely Random Algorithms and Collective Metrical Task Systems</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/oajhfvrtbq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/oajhfvrtbq/</guid><description>Randomness-efficient algorithms are developed for online decision making, requiring only 2log n random bits and achieving near-optimal competitiveness for metrical task systems.</description></item><item><title>Bayesian-guided Label Mapping for Visual Reprogramming</title><link>https://deep-diver.github.io/neurips2024/oral-others/135ekqdorr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/135ekqdorr/</guid><description>Bayesian-guided Label Mapping (BLM) enhances visual reprogramming!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/135ekqdorr/cover.png"/></item><item><title>Benign overfitting in leaky ReLU networks with moderate input dimension</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/88tzdgypt6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/88tzdgypt6/</guid><description>Leaky ReLU networks exhibit benign overfitting under surprisingly relaxed conditions: input dimension only needs to linearly scale with sample size, challenging prior assumptions in the field.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/88tzdgypt6/cover.png"/></item><item><title>Bigger, Regularized, Optimistic: scaling for compute and sample efficient continuous control</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/fu0xdh4aej/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/fu0xdh4aej/</guid><description>BRO (Bigger, Regularized, Optimistic) achieves state-of-the-art sample efficiency in continuous control by scaling critic networks and using strong regularization with optimistic exploration.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/fu0xdh4aej/cover.png"/></item><item><title>BMRS: Bayesian Model Reduction for Structured Pruning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ktpg37dzh5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ktpg37dzh5/</guid><description>BMRS: Bayesian Model Reduction for Structured Pruning offers a principled, threshold-free approach to neural network compression, achieving high accuracy and competitive efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ktpg37dzh5/cover.png"/></item><item><title>Boosting Vision-Language Models with Transduction</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/go4zzxbwvs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/go4zzxbwvs/</guid><description>TransCLIP significantly boosts vision-language model accuracy by efficiently integrating transduction, a powerful learning paradigm that leverages the structure of unlabeled data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/go4zzxbwvs/cover.png"/></item><item><title>BPQP: A Differentiable Convex Optimization Framework for Efficient End-to-End Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vkky3uv7vi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vkky3uv7vi/</guid><description>BPQP: A new differentiable convex optimization framework accelerates end-to-end learning by an order of magnitude, achieving significant efficiency gains over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vkky3uv7vi/cover.png"/></item><item><title>Brain-JEPA: Brain Dynamics Foundation Model with Gradient Positioning and Spatiotemporal Masking</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/gtu2elsamo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/gtu2elsamo/</guid><description>Brain-JEPA: a novel brain dynamics foundation model leverages fMRI data via innovative gradient positioning and spatiotemporal masking to achieve state-of-the-art performance in diverse brain activity&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/gtu2elsamo/cover.png"/></item><item><title>Breaking Long-Tailed Learning Bottlenecks: A Controllable Paradigm with Hypernetwork-Generated Diverse Experts</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/wppnvpaeyv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/wppnvpaeyv/</guid><description>Controllable long-tailed learning achieved via hypernetwork-generated diverse experts, adapting to user preferences and distribution shifts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/wppnvpaeyv/cover.png"/></item><item><title>BricksRL: A Platform for Democratizing Robotics and Reinforcement Learning Research and Education with LEGO</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/8iytzcnxiu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/8iytzcnxiu/</guid><description>BricksRL: A low-cost, open-source platform democratizes robotics and reinforcement learning research using LEGO, enabling accessible real-world experiments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/8iytzcnxiu/cover.png"/></item><item><title>Bridge the Points: Graph-based Few-shot Segment Anything Semantically</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/jyyps5vipj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/jyyps5vipj/</guid><description>GF-SAM: A novel graph-based few-shot semantic segmentation method leverages SAM&amp;rsquo;s power efficiently via positive-negative prompt alignment and mask clustering for superior accuracy and speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/jyyps5vipj/cover.png"/></item><item><title>Bridging The Gap between Low-rank and Orthogonal Adaptation via Householder Reflection Adaptation</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lzleaschnj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lzleaschnj/</guid><description>Householder Reflection Adaptation (HRA) bridges low-rank and orthogonal LLM adaptation, achieving superior performance with fewer parameters than existing methods. By using a chain of Householder refl&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lzleaschnj/cover.png"/></item><item><title>Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ano1i9jptb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ano1i9jptb/</guid><description>Buffer of Thoughts (BoT) boosts Large Language Model reasoning by storing and reusing high-level &amp;rsquo;thought-templates&amp;rsquo;, achieving significant accuracy and efficiency gains across diverse tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ano1i9jptb/cover.png"/></item><item><title>Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs</title><link>https://deep-diver.github.io/neurips2024/oral-others/vi8aepaxgy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/vi8aepaxgy/</guid><description>Cambrian-1: Open, vision-centric multimodal LLMs achieve state-of-the-art performance using a novel spatial vision aggregator and high-quality data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/vi8aepaxgy/cover.png"/></item><item><title>Can Learned Optimization Make Reinforcement Learning Less Difficult?</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ybxfwasa9z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ybxfwasa9z/</guid><description>Learned optimizer OPEN tackles RL&amp;rsquo;s non-stationarity, plasticity loss, and exploration using meta-learning, significantly outperforming traditional and other learned optimizers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ybxfwasa9z/cover.png"/></item><item><title>Can Transformers Smell Like Humans?</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3f8i9glbzu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3f8i9glbzu/</guid><description>Pre-trained transformer models can predict human smell perception by encoding odorant chemical structures, aligning with expert labels, continuous ratings, and similarity assessments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3f8i9glbzu/cover.png"/></item><item><title>CAT3D: Create Anything in 3D with Multi-View Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/oral-others/tfzlfrl9ks/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/tfzlfrl9ks/</guid><description>CAT3D: Generate high-quality 3D scenes from as little as one image using a novel multi-view diffusion model, outperforming existing methods in speed and quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/tfzlfrl9ks/cover.png"/></item><item><title>Cell ontology guided transcriptome foundation model</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/aeynvtto7o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/aeynvtto7o/</guid><description>scCello: A Cell Ontology-Guided Transcriptome Foundation Model improves single-cell RNA sequencing analysis by incorporating cell lineage information, significantly boosting accuracy and generalizabil&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/aeynvtto7o/cover.png"/></item><item><title>CLIPLoss and Norm-Based Data Selection Methods for Multimodal Contrastive Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/qvdc0ocx2n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/qvdc0ocx2n/</guid><description>Boosting multimodal contrastive learning, this research introduces negCLIPLoss and NormSim, novel data selection methods surpassing existing techniques by improving data quality and task relevance. Th&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/qvdc0ocx2n/cover.png"/></item><item><title>Cluster-wise Graph Transformer with Dual-granularity Kernelized Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/3j2nasmkkp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/3j2nasmkkp/</guid><description>Cluster-wise Graph Transformer (Cluster-GT) improves graph learning by using a novel Node-to-Cluster Attention mechanism that leverages multiple kernel learning to capture node and cluster-level infor&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/3j2nasmkkp/cover.png"/></item><item><title>Co-occurrence is not Factual Association in Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/xabstwautr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/xabstwautr/</guid><description>Language models struggle to learn facts; this study reveals they prioritize word co-occurrence over true factual associations, proposing new training strategies for improved factual knowledge generali&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/xabstwautr/cover.png"/></item><item><title>Compositional Generalization Across Distributional Shifts with Sparse Tree Operations</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/foqunr2e0t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/foqunr2e0t/</guid><description>Sparse Differentiable Tree Machine (sDTM) improves compositional generalization in neural networks by efficiently representing tree structures in vector space, enabling simultaneous symbolic and neura&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/foqunr2e0t/cover.png"/></item><item><title>Conditioning non-linear and infinite-dimensional diffusion processes</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/fv4an2oufm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/fv4an2oufm/</guid><description>Conditioning infinite-dimensional nonlinear diffusion processes is made possible, enabling analysis of complex data like organism shapes in evolutionary biology.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/fv4an2oufm/cover.png"/></item><item><title>Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/jvqnjwij6m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/jvqnjwij6m/</guid><description>C-JEPA boosts self-supervised visual learning by integrating contrastive learning with a joint-embedding predictive architecture, enhancing stability and representation quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/jvqnjwij6m/cover.png"/></item><item><title>Constrained Adaptive Attack: Effective Adversarial Attack Against Deep Neural Networks for Tabular Data</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zttwkr51yh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zttwkr51yh/</guid><description>Constrained Adaptive Attack (CAA) significantly improves adversarial attacks on deep learning models for tabular data by combining gradient and search-based methods, achieving up to 96.1% accuracy dro&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zttwkr51yh/cover.png"/></item><item><title>Context and Geometry Aware Voxel Transformer for Semantic Scene Completion</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/9bu627mtfs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/9bu627mtfs/</guid><description>CGFormer: a novel voxel transformer boosting semantic scene completion accuracy by using context-aware queries and 3D deformable attention, outperforming existing methods on SemanticKITTI and SSCBench&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/9bu627mtfs/cover.png"/></item><item><title>Continual learning with the neural tangent ensemble</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/qosfijdvkz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/qosfijdvkz/</guid><description>Neural networks, viewed as Bayesian ensembles of fixed classifiers, enable continual learning without forgetting; posterior updates mirror stochastic gradient descent, offering insights into optimizat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/qosfijdvkz/cover.png"/></item><item><title>Convolutional Differentiable Logic Gate Networks</title><link>https://deep-diver.github.io/neurips2024/oral-others/4bkefyuht4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/4bkefyuht4/</guid><description>Convolutional Differentiable Logic Gate Networks achieve state-of-the-art accuracy on CIFAR-10 with 29x fewer gates than existing models, demonstrating highly efficient deep learning inference.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/4bkefyuht4/cover.png"/></item><item><title>CooHOI: Learning Cooperative Human-Object Interaction with Manipulated Object Dynamics</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/iyzytmd3jd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/iyzytmd3jd/</guid><description>CooHOI: A two-phase learning framework enables physically simulated characters to perform cooperative object transportation tasks naturally and efficiently, overcoming the limitations of existing meth&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/iyzytmd3jd/cover.png"/></item><item><title>Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions</title><link>https://deep-diver.github.io/neurips2024/oral-others/bcmpdaqcnw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/bcmpdaqcnw/</guid><description>Can AI understand humor? A new benchmark, YESBUT, reveals that even state-of-the-art models struggle with the nuanced humor of juxtaposed comics, highlighting the need for improved AI in understandin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/bcmpdaqcnw/cover.png"/></item><item><title>Curvature Clues: Decoding Deep Learning Privacy with Input Loss Curvature</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zevdmq6mu5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zevdmq6mu5/</guid><description>Deep learning privacy is enhanced by a new membership inference attack using input loss curvature, exceeding existing methods, especially on large datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zevdmq6mu5/cover.png"/></item><item><title>CycleNet: Enhancing Time Series Forecasting through Modeling Periodic Patterns</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/clbiqugj4w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/clbiqugj4w/</guid><description>CycleNet enhances long-term time series forecasting by explicitly modeling inherent periodic patterns using a novel Residual Cycle Forecasting technique, achieving state-of-the-art accuracy and effici&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/clbiqugj4w/cover.png"/></item><item><title>DapperFL: Domain Adaptive Federated Learning with Model Fusion Pruning for Edge Devices</title><link>https://deep-diver.github.io/neurips2024/oral-others/pezt0xttae/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/pezt0xttae/</guid><description>DapperFL enhances federated learning by introducing a model fusion pruning module and domain adaptive regularization to improve performance and reduce model size for heterogeneous edge devices.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/pezt0xttae/cover.png"/></item><item><title>Decompose, Analyze and Rethink: Solving Intricate Problems with Human-like Reasoning Cycle</title><link>https://deep-diver.github.io/neurips2024/oral-others/npkzf1wdjz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/npkzf1wdjz/</guid><description>DeAR: A novel framework lets LLMs solve complex problems with human-like iterative reasoning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/npkzf1wdjz/cover.png"/></item><item><title>Deep Learning for Computing Convergence Rates of Markov Chains</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/fqmsgk8c0b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/fqmsgk8c0b/</guid><description>Deep learning tackles Markov chain convergence rate analysis! Deep Contractive Drift Calculator (DCDC) provides sample-based bounds in Wasserstein distance, surpassing traditional methods&amp;rsquo; limitations&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/fqmsgk8c0b/cover.png"/></item><item><title>Deep Submodular Peripteral Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/tupcrqnvvm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/tupcrqnvvm/</guid><description>Deep Submodular Peripteral Networks (DSPNs) learn submodular functions efficiently using graded pairwise comparisons, surpassing traditional methods and demonstrating superiority in experimental desig&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/tupcrqnvvm/cover.png"/></item><item><title>DenoiseRep: Denoising Model for Representation Learning</title><link>https://deep-diver.github.io/neurips2024/oral-others/oycu0baus6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/oycu0baus6/</guid><description>DenoiseRep: A novel denoising model enhances feature discrimination in computer vision tasks by integrating feature extraction and denoising within a single backbone, achieving impressive improvements&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/oycu0baus6/cover.png"/></item><item><title>DeSparsify: Adversarial Attack Against Token Sparsification Mechanisms</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/d4yrz3s7ul/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/d4yrz3s7ul/</guid><description>DeSparsify: A stealthy adversarial attack exhausts vision transformer resources by exploiting token sparsification mechanisms&amp;rsquo; dynamic nature, highlighting the need for improved resource management i&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/d4yrz3s7ul/cover.png"/></item><item><title>DeTikZify: Synthesizing Graphics Programs for Scientific Figures and Sketches with TikZ</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bcvlfqcojc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bcvlfqcojc/</guid><description>DeTikZify: AI synthesizes publication-ready scientific figures from sketches and existing figures, automatically generating semantically-preserving TikZ code.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bcvlfqcojc/cover.png"/></item><item><title>Differentiable Task Graph Learning: Procedural Activity Representation and Online Mistake Detection from Egocentric Videos</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/2hvgvb4awq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/2hvgvb4awq/</guid><description>This paper introduces a novel differentiable framework for learning task graphs from video demonstrations of procedural activities. By directly optimizing the weights of a task graph&amp;rsquo;s edges, the mod&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/2hvgvb4awq/cover.png"/></item><item><title>DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/a969oupqes/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/a969oupqes/</guid><description>DiffLight: a novel conditional diffusion model for traffic signal control effectively addresses data-missing scenarios by unifying traffic data imputation and decision-making, demonstrating superior p&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/a969oupqes/cover.png"/></item><item><title>DiffSF: Diffusion Models for Scene Flow Estimation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/nieufguq9x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/nieufguq9x/</guid><description>DiffSF boosts scene flow estimation accuracy and reliability by cleverly combining transformer networks with denoising diffusion models, offering state-of-the-art results and uncertainty quantificatio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/nieufguq9x/cover.png"/></item><item><title>DiffTORI: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/mwj57tchwx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/mwj57tchwx/</guid><description>DiffTORI leverages differentiable trajectory optimization for superior deep reinforcement and imitation learning, outperforming prior state-of-the-art methods on high-dimensional robotic tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/mwj57tchwx/cover.png"/></item><item><title>Diffusion for World Modeling: Visual Details Matter in Atari</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/nadtwtodgc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/nadtwtodgc/</guid><description>DIAMOND, a novel reinforcement learning agent using a diffusion world model, achieves state-of-the-art performance on the Atari 100k benchmark by leveraging visual details often ignored by discrete la&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/nadtwtodgc/cover.png"/></item><item><title>Diffusion Model with Cross Attention as an Inductive Bias for Disentanglement</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/stapcuwm9q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/stapcuwm9q/</guid><description>Diffusion models with cross-attention: a powerful inductive bias for effortless disentanglement!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/stapcuwm9q/cover.png"/></item><item><title>Diffusion Models With Learned Adaptive Noise</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/loma99a4p8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/loma99a4p8/</guid><description>MuLAN, a novel learned diffusion process, achieves state-of-the-art density estimation by adaptively adding multivariate Gaussian noise at varying rates across an image, significantly reducing trainin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/loma99a4p8/cover.png"/></item><item><title>Diffusion Priors for Variational Likelihood Estimation and Image Denoising</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/oukw8cuiuy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/oukw8cuiuy/</guid><description>Adaptive likelihood estimation and MAP inference during reverse diffusion tackles real-world image noise.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/oukw8cuiuy/cover.png"/></item><item><title>Dimension-free deterministic equivalents and scaling laws for random feature regression</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/fbljifw64d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/fbljifw64d/</guid><description>This work delivers dimension-free deterministic equivalents for random feature regression, revealing sharp excess error rates and scaling laws.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/fbljifw64d/cover.png"/></item><item><title>Discrete Flow Matching</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/gtdko3sv9p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/gtdko3sv9p/</guid><description>Discrete Flow Matching (DFM) revolutionizes discrete data generation by introducing a novel flow paradigm that surpasses existing methods. DFM leverages flexible probability paths, enabling efficient &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/gtdko3sv9p/cover.png"/></item><item><title>Disentangling the Roles of Distinct Cell Classes with Cell-Type Dynamical Systems</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/9sp4oejtjb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/9sp4oejtjb/</guid><description>New Cell-Type Dynamical Systems (CTDS) model disentangles neural population dynamics by incorporating distinct cell types, improving prediction accuracy and biological interpretability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/9sp4oejtjb/cover.png"/></item><item><title>Dissecting Query-Key Interaction in Vision Transformers</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/diktpsgk4f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/diktpsgk4f/</guid><description>Vision transformers&amp;rsquo; self-attention mechanism is dissected revealing how early layers focus on similar features for perceptual grouping while later layers integrate dissimilar features for contextuali&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/diktpsgk4f/cover.png"/></item><item><title>Distributed-Order Fractional Graph Operating Network</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/keqfjkqiqm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/keqfjkqiqm/</guid><description>DRAGON: A novel GNN framework using distributed-order fractional calculus surpasses traditional methods by capturing complex graph dynamics with enhanced flexibility and performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/keqfjkqiqm/cover.png"/></item><item><title>Diversity-Driven Synthesis: Enhancing Dataset Distillation through Directed Weight Adjustment</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/uwsadhllyc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/uwsadhllyc/</guid><description>Boosting dataset distillation, a new method, Diversity-Driven Synthesis, uses directed weight adjustment to create diverse, representative synthetic datasets, improving model performance while reducin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/uwsadhllyc/cover.png"/></item><item><title>Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/</guid><description>FUNCODER: a novel code generation framework that uses a divide-and-conquer approach with functional consensus to generate code that meets complex requirements.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/cover.png"/></item><item><title>Do Finetti: On Causal Effects for Exchangeable Data</title><link>https://deep-diver.github.io/neurips2024/oral-ai-theory/4rczeczaon/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-theory/4rczeczaon/</guid><description>Causal inference revolutionized: New framework estimates causal effects from exchangeable data, enabling simultaneous causal discovery and effect estimation via the Do-Finetti algorithm.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-theory/4rczeczaon/cover.png"/></item><item><title>Don't Look Twice: Faster Video Transformers with Run-Length Tokenization</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/b1ggjw00ni/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/b1ggjw00ni/</guid><description>Run-Length Tokenization (RLT) dramatically speeds up video transformer training and inference by efficiently removing redundant video tokens, matching baseline model performance with significant time &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/b1ggjw00ni/cover.png"/></item><item><title>Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition Path Sampling</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/shjwt0n7kx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/shjwt0n7kx/</guid><description>Researchers developed a sample-efficient variational approach for transition path sampling using Doob&amp;rsquo;s h-transform, significantly reducing computational costs while accurately capturing transition pa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/shjwt0n7kx/cover.png"/></item><item><title>Double-Ended Synthesis Planning with Goal-Constrained Bidirectional Search</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ljnqvikscr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ljnqvikscr/</guid><description>Double-Ended Synthesis Planning (DESP) significantly boosts computer-aided synthesis planning by using a bidirectional search, outperforming existing methods on multiple benchmarks, especially when sp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ljnqvikscr/cover.png"/></item><item><title>DuQuant: Distributing Outliers via Dual Transformation Makes Stronger Quantized LLMs</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/mp8u2pcmqz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/mp8u2pcmqz/</guid><description>DuQuant: Dual transformations distribute outliers for stronger quantized LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/mp8u2pcmqz/cover.png"/></item><item><title>Dynamic 3D Gaussian Fields for Urban Areas</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/</guid><description>4DGF, a novel neural scene representation, achieves interactive-speed novel view synthesis for large-scale dynamic urban areas by efficiently combining 3D Gaussians and neural fields.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/cover.png"/></item><item><title>E2E-MFD: Towards End-to-End Synchronous Multimodal Fusion Detection</title><link>https://deep-diver.github.io/neurips2024/oral-others/47loymzxep/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/47loymzxep/</guid><description>E2E-MFD: A novel end-to-end multimodal fusion detection algorithm achieves state-of-the-art performance by synchronously optimizing image fusion and object detection.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/47loymzxep/cover.png"/></item><item><title>ECLipsE: Efficient Compositional Lipschitz Constant Estimation for Deep Neural Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/61yysy078z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/61yysy078z/</guid><description>ECLipsE: A novel compositional approach drastically accelerates Lipschitz constant estimation for deep neural networks, achieving speedups of thousands of times compared to the state-of-the-art while &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/61yysy078z/cover.png"/></item><item><title>Efficient Adversarial Training in LLMs with Continuous Attacks</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/8jb6sgqvgq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/8jb6sgqvgq/</guid><description>Boosting LLM robustness against attacks efficiently: Continuous adversarial training in embedding space outperforms discrete methods, achieving improved robustness with less computation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/8jb6sgqvgq/cover.png"/></item><item><title>EigenVI: score-based variational inference with orthogonal function expansions</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/thuf6zblpp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/thuf6zblpp/</guid><description>EigenVI: a novel score-based variational inference method using orthogonal function expansions, offers closed-form solutions by solving eigenvalue problems, outperforming existing Gaussian BBVI method&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/thuf6zblpp/cover.png"/></item><item><title>Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/owuect6btl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/owuect6btl/</guid><description>Generative models learn hidden capabilities suddenly during training, which can be explained and predicted using a novel &amp;lsquo;concept space&amp;rsquo; framework that analyzes learning dynamics and concept signal.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/owuect6btl/cover.png"/></item><item><title>EMR-Merging: Tuning-Free High-Performance Model Merging</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/lydjzx3dyu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/lydjzx3dyu/</guid><description>EMR-MERGING: A tuning-free model merging technique achieves high performance by electing a unified model and generating lightweight task-specific modulators, eliminating the need for additional data &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/lydjzx3dyu/cover.png"/></item><item><title>Energy-based Epistemic Uncertainty for Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/6vnpptwh1q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/6vnpptwh1q/</guid><description>GEBM: a novel graph-based energy model for robust GNN uncertainty estimation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/6vnpptwh1q/cover.png"/></item><item><title>Energy-Guided Continuous Entropic Barycenter Estimation for General Costs</title><link>https://deep-diver.github.io/neurips2024/spotlight-optimization/jzhfrloqdq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-optimization/jzhfrloqdq/</guid><description>New algorithm approximates continuous Entropic Optimal Transport (EOT) barycenters for any cost function, offering quality bounds and seamless EBM integration.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-optimization/jzhfrloqdq/cover.png"/></item><item><title>Enhancing LLM Reasoning via Vision-Augmented Prompting</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ngugvt7ar2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ngugvt7ar2/</guid><description>Vision-Augmented Prompting (VAP) boosts LLM reasoning by automatically generating images from textual problem descriptions, incorporating visual-spatial clues to significantly improve accuracy across &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ngugvt7ar2/cover.png"/></item><item><title>Enhancing Preference-based Linear Bandits via Human Response Time</title><link>https://deep-diver.github.io/neurips2024/oral-ai-applications/aipwlkdout/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-applications/aipwlkdout/</guid><description>Boosting preference learning, this research uses human response times to improve linear bandit algorithms, significantly accelerating preference identification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-applications/aipwlkdout/cover.png"/></item><item><title>Enhancing Robustness of Graph Neural Networks on Social Media with Explainable Inverse Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zieha15y8k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zieha15y8k/</guid><description>MoE-BiEntIRL: A novel explainable inverse reinforcement learning method enhances GNN robustness against diverse social media attacks by reconstructing attacker policies and generating more robust trai&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zieha15y8k/cover.png"/></item><item><title>Enhancing Zero-Shot Vision Models by Label-Free Prompt Distribution Learning and Bias Correcting</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ojximyclit/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ojximyclit/</guid><description>Frolic: A label-free framework boosts zero-shot vision model accuracy by learning prompt distributions and correcting label bias, achieving state-of-the-art performance across multiple datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ojximyclit/cover.png"/></item><item><title>Ensemble Learning for Heterogeneous Large Language Models with Deep Parallel Collaboration</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/</guid><description>DEEPEN: a training-free LLM ensemble framework fusing probability distributions in a relative space to overcome vocabulary misalignment, improving performance consistently across benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/cover.png"/></item><item><title>Evaluating the World Model Implicit in a Generative Model</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/avk4jfpegy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/avk4jfpegy/</guid><description>New metrics reveal that generative models often possess surprisingly incoherent world models, despite seemingly accurate next-token predictions. This incoherence leads to fragility in solving related &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/avk4jfpegy/cover.png"/></item><item><title>Exclusively Penalized Q-learning for Offline Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/2bdsnxeqcw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/2bdsnxeqcw/</guid><description>EPQ, a novel offline RL algorithm, significantly reduces underestimation bias by selectively penalizing states prone to errors, improving performance over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/2bdsnxeqcw/cover.png"/></item><item><title>Expectile Regularization for Fast and Accurate Training of Neural Optimal Transport</title><link>https://deep-diver.github.io/neurips2024/spotlight-optimization/4da5vaphfb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-optimization/4da5vaphfb/</guid><description>ENOT, a new Neural Optimal Transport training method, achieves 3x quality and 10x speed improvements by using expectile regularization to stabilize the learning process.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-optimization/4da5vaphfb/cover.png"/></item><item><title>Exploitation of a Latent Mechanism in Graph Contrastive Learning: Representation Scattering</title><link>https://deep-diver.github.io/neurips2024/oral-others/r8solcx62k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/r8solcx62k/</guid><description>SGRL, a novel graph contrastive learning framework, significantly boosts performance by leveraging the inherent &amp;lsquo;representation scattering&amp;rsquo; mechanism and integrating graph topology, outperforming exis&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/r8solcx62k/cover.png"/></item><item><title>Exploring Context Window of Large Language Models via Decomposed Positional Vectors</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/zeyyq0gpxo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/zeyyq0gpxo/</guid><description>Researchers extended large language models&amp;rsquo; context windows by training-free methods via analyzing and manipulating positional vectors, improving long-text processing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/zeyyq0gpxo/cover.png"/></item><item><title>Exploring Jacobian Inexactness in Second-Order Methods for Variational Inequalities: Lower Bounds, Optimal Algorithms and Quasi-Newton Approximations</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/uvfdaefr9x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/uvfdaefr9x/</guid><description>VIJI, a novel second-order algorithm, achieves optimal convergence rates for variational inequalities even with inexact Jacobian information, bridging the gap between theory and practice in machine le&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/uvfdaefr9x/cover.png"/></item><item><title>Extensive-Form Game Solving via Blackwell Approachability on Treeplexes</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/8aa3dhlk5h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/8aa3dhlk5h/</guid><description>First algorithmic framework for Blackwell approachability on treeplexes, enabling stepsize-invariant EFG solvers with state-of-the-art convergence rates.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/8aa3dhlk5h/cover.png"/></item><item><title>Fearless Stochasticity in Expectation Propagation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/3kdwoqs2x2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/3kdwoqs2x2/</guid><description>This paper introduces EP-Î· and EP-Î¼, novel EP variants remarkably robust to Monte Carlo noise, achieving improved speed and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/3kdwoqs2x2/cover.png"/></item><item><title>Finding Transformer Circuits With Edge Pruning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/8osy3ra9jy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/8osy3ra9jy/</guid><description>Edge Pruning efficiently discovers sparse, yet accurate, computational subgraphs (circuits) in large language models via gradient-based edge pruning, advancing mechanistic interpretability research.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/8osy3ra9jy/cover.png"/></item><item><title>Fine Tuning Out-of-Vocabulary Item Recommendation with User Sequence Imagination</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/jywafgcjpl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/jywafgcjpl/</guid><description>User Sequence Imagination (USIM) revolutionizes out-of-vocabulary item recommendation by leveraging user sequence imagination and RL fine-tuning, achieving superior performance in real-world e-commerc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/jywafgcjpl/cover.png"/></item><item><title>FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tvconyid20/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tvconyid20/</guid><description>FlashAttention-3: Achieves 1.5-2x faster attention on H100 GPUs using asynchrony and low-precision, reaching 1.3 PFLOPs/s.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tvconyid20/cover.png"/></item><item><title>Flex-MoE: Modeling Arbitrary Modality Combination via the Flexible Mixture-of-Experts</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ihehcbqzex/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ihehcbqzex/</guid><description>Flex-MoE: A novel framework flexibly handles arbitrary modality combinations in multimodal learning, even with missing data, achieving robust performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ihehcbqzex/cover.png"/></item><item><title>Flexible task abstractions emerge in linear networks with fast and bounded units</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/abtpjl7vn6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/abtpjl7vn6/</guid><description>Linear gated neural networks with fast, bounded units self-organize into modular weight structures and unique gating representations, enabling flexible task switching and compositional generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/abtpjl7vn6/cover.png"/></item><item><title>Flipped Classroom: Aligning Teacher Attention with Student in Generalized Category Discovery</title><link>https://deep-diver.github.io/neurips2024/oral-others/c4nbtynyqg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/c4nbtynyqg/</guid><description>FlipClass dynamically updates the teacher model in a teacher-student framework to align with the student&amp;rsquo;s attention, resolving learning inconsistencies and significantly improving generalized categor&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/c4nbtynyqg/cover.png"/></item><item><title>Functional Bilevel Optimization for Machine Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/enlxhlwwff/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/enlxhlwwff/</guid><description>Functional Bilevel Optimization tackles the ambiguity of using neural networks in bilevel optimization by minimizing the inner objective over a function space, leading to scalable &amp;amp; efficient algorith&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/enlxhlwwff/cover.png"/></item><item><title>FuseAnyPart: Diffusion-Driven Facial Parts Swapping via Multiple Reference Images</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/x2umdvcmmo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/x2umdvcmmo/</guid><description>FuseAnyPart: Swap facial parts seamlessly using multiple reference images via diffusion, achieving high-fidelity results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/x2umdvcmmo/cover.png"/></item><item><title>FuseFL: One-Shot Federated Learning through the Lens of Causality with Progressive Model Fusion</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/e7fzooiekl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/e7fzooiekl/</guid><description>FuseFL achieves superior one-shot federated learning performance by leveraging a causal view of data heterogeneity and progressively fusing model blocks, significantly outperforming existing methods w&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/e7fzooiekl/cover.png"/></item><item><title>GenArtist: Multimodal LLM as an Agent for Unified Image Generation and Editing</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ur00bnk1v2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ur00bnk1v2/</guid><description>GenArtist uses a multimodal large language model as an AI agent to unify image generation and editing, achieving state-of-the-art performance by decomposing complex tasks and leveraging a comprehensiv&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ur00bnk1v2/cover.png"/></item><item><title>Generalization Analysis for Label-Specific Representation Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/dtpiuxdjhy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/dtpiuxdjhy/</guid><description>Researchers derived tighter generalization bounds for label-specific representation learning (LSRL) methods, improving understanding of LSRL&amp;rsquo;s success and offering guidance for future algorithm develo&amp;hellip;</description></item><item><title>Generalization Error Bounds for Two-stage Recommender Systems with Tree Structure</title><link>https://deep-diver.github.io/neurips2024/oral-ai-theory/m1a4crrjr7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-theory/m1a4crrjr7/</guid><description>Two-stage recommender systems using tree structures achieve better generalization with more branches and harmonized training data distributions across stages.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-theory/m1a4crrjr7/cover.png"/></item><item><title>Generalized Linear Bandits with Limited Adaptivity</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ftpdbqut4g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ftpdbqut4g/</guid><description>This paper introduces two novel algorithms, achieving optimal regret in generalized linear contextual bandits despite limited policy updates, a significant advancement for real-world applications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ftpdbqut4g/cover.png"/></item><item><title>Generalized Protein Pocket Generation with Prior-Informed Flow Matching</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/wyvtj77kev/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/wyvtj77kev/</guid><description>PocketFlow: a novel generative model designs high-affinity protein pockets using prior-informed flow matching, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/wyvtj77kev/cover.png"/></item><item><title>Generated and Pseudo Content guided Prototype Refinement for Few-shot Point Cloud Segmentation</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tbvlqjdfca/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tbvlqjdfca/</guid><description>LLM-powered prototype refinement boosts few-shot 3D point cloud segmentation accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tbvlqjdfca/cover.png"/></item><item><title>Generative Retrieval Meets Multi-Graded Relevance</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/2xtkeyjfjb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/2xtkeyjfjb/</guid><description>GR2, a novel framework, extends generative retrieval to handle multi-graded relevance, addressing limitations of existing binary-relevance approaches by enhancing docid distinctness and implementing m&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/2xtkeyjfjb/cover.png"/></item><item><title>Geodesic Optimization for Predictive Shift Adaptation on EEG data</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/qtypwxvnja/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/qtypwxvnja/</guid><description>GOPSA: a novel geodesic optimization method significantly improves cross-site age prediction from EEG data by jointly handling shifts in data and predictive variables.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/qtypwxvnja/cover.png"/></item><item><title>Get rich quick: exact solutions reveal how unbalanced initializations promote rapid feature learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/enm94i7r3a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/enm94i7r3a/</guid><description>Unbalanced initializations dramatically accelerate neural network feature learning by modifying the geometry of learning trajectories, enabling faster feature extraction and improved generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/enm94i7r3a/cover.png"/></item><item><title>Get Rid of Isolation: A Continuous Multi-task Spatio-Temporal Learning Framework</title><link>https://deep-diver.github.io/neurips2024/oral-ai-applications/tnh4lk72yj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-applications/tnh4lk72yj/</guid><description>CMuST: a novel continuous multi-task spatiotemporal learning framework tackles urban data limitations by enabling cross-interactions and task-level cooperation for enhanced generalization and adaptabi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-applications/tnh4lk72yj/cover.png"/></item><item><title>GIC: Gaussian-Informed Continuum for Physical Property Identification and Simulation</title><link>https://deep-diver.github.io/neurips2024/oral-others/ssctcq2mh2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/ssctcq2mh2/</guid><description>GIC: Novel hybrid framework leverages 3D Gaussian representation for accurate physical property estimation from visual observations, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/ssctcq2mh2/cover.png"/></item><item><title>Goal Reduction with Loop-Removal Accelerates RL and Models Human Brain Activity in Goal-Directed Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/y0efjjeb4v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/y0efjjeb4v/</guid><description>Goal Reduction with Loop-Removal accelerates Reinforcement Learning (RL) and accurately models human brain activity during goal-directed learning by efficiently deriving subgoals from distant original&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/y0efjjeb4v/cover.png"/></item><item><title>Gradients of Functions of Large Matrices</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/rl4fxrgctw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/rl4fxrgctw/</guid><description>This research presents novel adjoint methods for efficiently differentiating Lanczos and Arnoldi iterations, unlocking accurate gradients for large-matrix functions in machine learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/rl4fxrgctw/cover.png"/></item><item><title>Graph Diffusion Transformers for Multi-Conditional Molecular Generation</title><link>https://deep-diver.github.io/neurips2024/oral-ai-applications/cfrdld1wfo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-applications/cfrdld1wfo/</guid><description>Graph Diffusion Transformer (Graph DiT) masters multi-conditional molecular generation by cleverly integrating property representations into a graph-dependent noise model, achieving superior performan&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-applications/cfrdld1wfo/cover.png"/></item><item><title>Graph-based Uncertainty Metrics for Long-form Language Model Generations</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ygjpqw0lko/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ygjpqw0lko/</guid><description>Graph Uncertainty boosts LLM factuality by 6.8% using graph centrality to estimate claim-level uncertainty and a novel uncertainty-aware decoding process.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ygjpqw0lko/cover.png"/></item><item><title>GREATS: Online Selection of High-Quality Data for LLM Training in Every Iteration</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/232vcn8tsx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/232vcn8tsx/</guid><description>GREATS: a novel online batch selection method significantly speeds up LLM training by greedily selecting high-quality data batches in every iteration, improving both convergence and generalization per&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/232vcn8tsx/cover.png"/></item><item><title>Guiding a Diffusion Model with a Bad Version of Itself</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/bg6fvpvs3s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/bg6fvpvs3s/</guid><description>Boost image quality in diffusion models without reducing variation using Autoguidance: guide a high-quality model with a less-trained version of itself!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/bg6fvpvs3s/cover.png"/></item><item><title>HaloScope: Harnessing Unlabeled LLM Generations for Hallucination Detection</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/nfk0zxffsn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/nfk0zxffsn/</guid><description>HaloScope leverages unlabeled LLM outputs to accurately detect AI hallucinations without human annotation, significantly outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/nfk0zxffsn/cover.png"/></item><item><title>Hardness of Learning Neural Networks under the Manifold Hypothesis</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/dkkgkzmni7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/dkkgkzmni7/</guid><description>Neural network learnability under the manifold hypothesis is hard except for efficiently sampleable manifolds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/dkkgkzmni7/cover.png"/></item><item><title>Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/t56j6av8oc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/t56j6av8oc/</guid><description>Adam&amp;rsquo;s superior performance on language models stems from its resilience to heavy-tailed class imbalance, unlike SGD, which struggles with infrequent word losses.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/t56j6av8oc/cover.png"/></item><item><title>Honor Among Bandits: No-Regret Learning for Online Fair Division</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ocqbc0edjj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ocqbc0edjj/</guid><description>Online fair division algorithm achieves Ã(TÂ²/Â³) regret while guaranteeing envy-freeness or proportionality in expectation, a result proven tight.</description></item><item><title>Human Expertise in Algorithmic Prediction</title><link>https://deep-diver.github.io/neurips2024/oral-ai-applications/wpgj2ax6sz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-applications/wpgj2ax6sz/</guid><description>Boost AI predictions by using human judgment on algorithmically indistinguishable inputs!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-applications/wpgj2ax6sz/cover.png"/></item><item><title>Humanoid Locomotion as Next Token Prediction</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/grmczqgtla/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/grmczqgtla/</guid><description>Humanoid robots now walk in San Francisco zero-shot, thanks to a novel &amp;rsquo;next token prediction&amp;rsquo; approach trained on diverse sensorimotor data, enabling real-world generalization and data efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/grmczqgtla/cover.png"/></item><item><title>HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/qepi8uwx3n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/qepi8uwx3n/</guid><description>HydraLoRA: Asymmetric LoRA boosts LLM fine-tuning efficiency by sharing parameters across tasks while specializing others, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/qepi8uwx3n/cover.png"/></item><item><title>Identification and Estimation of the Bi-Directional MR with Some Invalid Instruments</title><link>https://deep-diver.github.io/neurips2024/oral-ai-theory/s2p6kpltm8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-theory/s2p6kpltm8/</guid><description>PReBiM algorithm accurately estimates bi-directional causal effects from observational data, even with invalid instruments, using a novel cluster fusion approach.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-theory/s2p6kpltm8/cover.png"/></item><item><title>Identifying Causal Effects Under Functional Dependencies</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/oisuwqsvkd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/oisuwqsvkd/</guid><description>Unlocking identifiability of causal effects: This paper leverages functional dependencies in causal graphs to improve identifiability, leading to fewer needed variables in observational data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/oisuwqsvkd/cover.png"/></item><item><title>Identifying Equivalent Training Dynamics</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/boyvesx7pk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/boyvesx7pk/</guid><description>New framework uses Koopman operator theory to identify equivalent training dynamics in deep neural networks, enabling quantitative comparison of different architectures and optimization methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/boyvesx7pk/cover.png"/></item><item><title>Implicit Curriculum in Procgen Made Explicit</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/nzb1fpxuu6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/nzb1fpxuu6/</guid><description>C-Procgen reveals implicit curriculum in Procgen&amp;rsquo;s multi-level training, showing learning shifts gradually from easy to hard contexts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/nzb1fpxuu6/cover.png"/></item><item><title>Improved Distribution Matching Distillation for Fast Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/tqukgcdant/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/tqukgcdant/</guid><description>DMD2 dramatically speeds up image generation by cleverly distilling expensive diffusion models, achieving state-of-the-art results without sacrificing quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/tqukgcdant/cover.png"/></item><item><title>Improving Environment Novelty Quantification for Effective Unsupervised Environment Design</title><link>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/udxpjko2f9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/udxpjko2f9/</guid><description>Boosting AI generalization: CENIE framework quantifies environment novelty via state-action coverage, enhancing unsupervised environment design for robust generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/udxpjko2f9/cover.png"/></item><item><title>Improving robustness to corruptions with multiplicative weight perturbations</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/m8dy0zusb1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/m8dy0zusb1/</guid><description>Boost DNN robustness to corruptions without sacrificing clean image accuracy using Data Augmentation via Multiplicative Perturbations (DAMP)!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/m8dy0zusb1/cover.png"/></item><item><title>Improving the Worst-Case Bidirectional Communication Complexity for Nonconvex Distributed Optimization under Function Similarity</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/gkj5nbiou4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/gkj5nbiou4/</guid><description>MARINA-P and M3 algorithms drastically cut downlink and overall communication costs in nonconvex distributed optimization, scaling efficiently with the number of worker nodes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/gkj5nbiou4/cover.png"/></item><item><title>In-Context Learning with Transformers: Softmax Attention Adapts to Function Lipschitzness</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/lfxiasylxb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/lfxiasylxb/</guid><description>Softmax attention in transformers adapts its attention window to function Lipschitzness and noise, enabling efficient in-context learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/lfxiasylxb/cover.png"/></item><item><title>Induced Model Matching: Restricted Models Help Train Full-Featured Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/iw0wxe0vyr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/iw0wxe0vyr/</guid><description>Restricted models often outperform full-featured models when training data is limited. This paper introduces Induced Model Matching (IMM), a novel technique that uses a restricted model as a guide to&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/iw0wxe0vyr/cover.png"/></item><item><title>Input-to-State Stable Coupled Oscillator Networks for Closed-form Model-based Control in Latent Space</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/kxkrlsr4aj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/kxkrlsr4aj/</guid><description>Stable closed-loop control in latent space is achieved using a novel Coupled Oscillator Network, offering efficient model-based control for complex nonlinear systems directly from image data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/kxkrlsr4aj/cover.png"/></item><item><title>Interpret Your Decision: Logical Reasoning Regularization for Generalization in Visual Classification</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/woiqqi5byv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/woiqqi5byv/</guid><description>This paper introduces L-Reg, a novel logical regularization technique, to improve generalization in visual classification. L-Reg effectively reduces model complexity and improves interpretability by f&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/woiqqi5byv/cover.png"/></item><item><title>Is Behavior Cloning All You Need? Understanding Horizon in Imitation Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/8kpyjm4gt5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/8kpyjm4gt5/</guid><description>Offline imitation learning achieves surprisingly strong performance, matching online methods&amp;rsquo; efficiency under certain conditions, contradicting prior assumptions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/8kpyjm4gt5/cover.png"/></item><item><title>Is Your LiDAR Placement Optimized for 3D Scene Understanding?</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/79q206xswc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/79q206xswc/</guid><description>Place3D optimizes LiDAR placement for superior 3D scene understanding.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/79q206xswc/cover.png"/></item><item><title>Kermut: Composite kernel regression for protein variant effects</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/jm9atrvuii/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/jm9atrvuii/</guid><description>Kermut: A novel Gaussian process regression model achieves state-of-the-art accuracy in predicting protein variant effects and provides reliable uncertainty estimates, crucial for protein engineering &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/jm9atrvuii/cover.png"/></item><item><title>Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3lkuc8rbyv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3lkuc8rbyv/</guid><description>Langevin unlearning offers a novel, privacy-preserving machine unlearning framework based on noisy gradient descent, handling both convex and non-convex problems efficiently.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3lkuc8rbyv/cover.png"/></item><item><title>Language Generation in the Limit</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/fgtde6ea0b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/fgtde6ea0b/</guid><description>This paper proves that language generation in the limit is always possible, even with an adversarial setting, contrasting with the impossibility of language identification in the limit.</description></item><item><title>Latent Diffusion for Neural Spiking Data</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zx6ceo1wtv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zx6ceo1wtv/</guid><description>LDNS: a new generative model for neural spiking data, enabling high-fidelity sampling and low-dimensional latent inference, paving the way for simulating realistic brain activity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zx6ceo1wtv/cover.png"/></item><item><title>Latent Intrinsics Emerge from Training to Relight</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ltndg0ezf9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ltndg0ezf9/</guid><description>A novel data-driven relighting model achieves state-of-the-art accuracy by learning latent intrinsic and extrinsic scene properties, even recovering albedo without explicit supervision.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ltndg0ezf9/cover.png"/></item><item><title>Learn To be Efficient: Build Structured Sparsity in Large Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/isfcwhvega/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/isfcwhvega/</guid><description>Learn-To-be-Efficient (LTE) trains LLMs to achieve structured sparsity, boosting inference speed by 25% at 50% sparsity without sacrificing accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/isfcwhvega/cover.png"/></item><item><title>Learning Better Representations From Less Data For Propositional Satisfiability</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/vmshnv8cvs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/vmshnv8cvs/</guid><description>NeuRes, a novel neuro-symbolic approach, achieves superior SAT solving accuracy using significantly less training data than existing methods by combining certificate-driven learning with expert iterat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/vmshnv8cvs/cover.png"/></item><item><title>Learning diffusion at lightspeed</title><link>https://deep-diver.github.io/neurips2024/oral-ai-theory/y10avdrfnk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-theory/y10avdrfnk/</guid><description>JKOnet* learns diffusion processes at unprecedented speed and accuracy by directly minimizing a simple quadratic loss function, bypassing complex bilevel optimization problems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-theory/y10avdrfnk/cover.png"/></item><item><title>Learning Formal Mathematics From Intrinsic Motivation</title><link>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/unkltq8mbd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/unkltq8mbd/</guid><description>AI agent MINIMO learns to generate challenging mathematical conjectures and prove them, bootstrapping from axioms alone and self-improving in both conjecture generation and theorem proving.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/unkltq8mbd/cover.png"/></item><item><title>Learning Generalized Linear Programming Value Functions</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/vxijl0ioid/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/vxijl0ioid/</guid><description>Learn optimal LP values faster with a novel neural network method!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/vxijl0ioid/cover.png"/></item><item><title>Learning Linear Causal Representations from General Environments: Identifiability and Intrinsic Ambiguity</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/db99jjwx3h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/db99jjwx3h/</guid><description>LiNGCREL, a novel algorithm, provably recovers linear causal representations from diverse environments, achieving identifiability despite intrinsic ambiguities, thus advancing causal AI.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/db99jjwx3h/cover.png"/></item><item><title>Learning Noisy Halfspaces with a Margin: Massart is No Harder than Random</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/enlubvb262/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/enlubvb262/</guid><description>Proper learning of noisy halfspaces with margins is achievable with sample complexity matching random classification noise, defying prior expectations.</description></item><item><title>Learning rigid-body simulators over implicit shapes for large-scale scenes and vision</title><link>https://deep-diver.github.io/neurips2024/oral-ai-applications/qdyts5dygq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-applications/qdyts5dygq/</guid><description>SDF-Sim: A novel learned rigid-body simulator that leverages SDFs to achieve unprecedented scalability, enabling simulations with hundreds of objects and millions of nodes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-applications/qdyts5dygq/cover.png"/></item><item><title>Learning Segmentation from Point Trajectories</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vt2qke1oax/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vt2qke1oax/</guid><description>This paper introduces a novel unsupervised video object segmentation method using long-term point trajectories and optical flow, outperforming prior art by effectively combining sparse, long-term moti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vt2qke1oax/cover.png"/></item><item><title>Learning Social Welfare Functions</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/7o6ktaar8n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/7o6ktaar8n/</guid><description>Learning social welfare functions from past decisions is possible! This paper shows how to efficiently learn power mean functions, a widely used family, using both cardinal and pairwise welfare compar&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/7o6ktaar8n/cover.png"/></item><item><title>Learning to grok: Emergence of in-context learning and skill composition in modular arithmetic tasks</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/avh9krzdrk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/avh9krzdrk/</guid><description>Large language models surprisingly solve unseen arithmetic tasks; this work reveals how they learn to compose simple skills into complex ones through in-context learning, showing a transition from mem&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/avh9krzdrk/cover.png"/></item><item><title>Learning to Mitigate Externalities: the Coase Theorem with Hindsight Rationality</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/omyzrkacme/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/omyzrkacme/</guid><description>Economists learn to resolve externalities efficiently even when players lack perfect information, maximizing social welfare by leveraging bargaining and online learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/omyzrkacme/cover.png"/></item><item><title>Learning to Solve Quadratic Unconstrained Binary Optimization in a Classification Way</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/p43obiwjfw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/p43obiwjfw/</guid><description>Researchers developed Value Classification Model (VCM), a neural solver that swiftly solves quadratic unconstrained binary optimization (QUBO) problems by directly generating solutions using a classif&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/p43obiwjfw/cover.png"/></item><item><title>Leveraging Catastrophic Forgetting to Develop Safe Diffusion Models against Malicious Finetuning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/pr37amwbot/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/pr37amwbot/</guid><description>This paper introduces a novel training policy that leverages catastrophic forgetting to make diffusion models resilient against malicious fine-tuning, effectively preventing the generation of harmful &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/pr37amwbot/cover.png"/></item><item><title>LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and 200+ FPS</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/6aeidnrtn2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/6aeidnrtn2/</guid><description>LightGaussian achieves 15x compression of 3D Gaussian scene representations, boosting rendering speed to 200+ FPS while maintaining visual quality, solving storage and efficiency issues in real-time n&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/6aeidnrtn2/cover.png"/></item><item><title>Linear Regression using Heterogeneous Data Batches</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/4g2dn4kjk1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/4g2dn4kjk1/</guid><description>New algorithm efficiently solves linear regression with heterogeneous data batches, handling diverse input distributions and achieving high accuracy with fewer samples.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/4g2dn4kjk1/cover.png"/></item><item><title>LLM Evaluators Recognize and Favor Their Own Generations</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/4njbv6wp0h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/4njbv6wp0h/</guid><description>LLMs show self-preference bias in evaluations, favoring their own outputs. This study reveals that LLMs surprisingly recognize their own generations, and this self-recognition directly causes the self&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/4njbv6wp0h/cover.png"/></item><item><title>LLM-ESR: Large Language Models Enhancement for Long-tailed Sequential Recommendation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/xojbzsyivs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/xojbzsyivs/</guid><description>LLM-ESR enhances sequential recommendation by integrating semantic information from LLMs, significantly improving performance on long-tail users and items.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/xojbzsyivs/cover.png"/></item><item><title>Localized Zeroth-Order Prompt Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/hs1jvv3dk3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/hs1jvv3dk3/</guid><description>Localized Zeroth-Order Prompt Optimization (ZOPO) efficiently finds high-performing local optima for prompt optimization in black-box LLMs, outperforming existing global optimization methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/hs1jvv3dk3/cover.png"/></item><item><title>Logarithmic Smoothing for Pessimistic Off-Policy Evaluation, Selection and Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/zlclygerk8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/zlclygerk8/</guid><description>Logarithmic Smoothing enhances pessimistic offline contextual bandit algorithms by providing tighter concentration bounds for improved policy evaluation, selection and learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/zlclygerk8/cover.png"/></item><item><title>MambaTree: Tree Topology is All You Need in State Space Model</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/w8rfsakr4m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/w8rfsakr4m/</guid><description>MambaTree: A novel tree-topology-based state space model surpasses existing methods by dynamically generating input-aware topologies for enhanced long-range dependencies in vision and language.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/w8rfsakr4m/cover.png"/></item><item><title>Many-Shot In-Context Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ab6xpmzvqh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ab6xpmzvqh/</guid><description>Scaling up in-context learning using thousands of examples significantly boosts Large Language Model (LLM) performance, particularly for complex tasks. Novel training methods mitigate reliance on hum&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ab6xpmzvqh/cover.png"/></item><item><title>MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/llu9njal7b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/llu9njal7b/</guid><description>MaskLLM learns efficient semi-structured sparsity in LLMs via end-to-end training, achieving significant speedup and memory reduction without sacrificing performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/llu9njal7b/cover.png"/></item><item><title>Maximum Entropy Inverse Reinforcement Learning of Diffusion Models with Energy-Based Models</title><link>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/v0ojalqy4e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/v0ojalqy4e/</guid><description>Boosting diffusion model sample quality, especially with few steps, is achieved via a novel maximum entropy inverse reinforcement learning approach, jointly training the model and an energy-based mode&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/v0ojalqy4e/cover.png"/></item><item><title>MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making</title><link>https://deep-diver.github.io/neurips2024/oral-others/ekdk4vxko4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/ekdk4vxko4/</guid><description>MDAgents: An adaptive multi-agent LLM framework boosts medical decision-making accuracy by dynamically adjusting collaboration structures based on task complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/ekdk4vxko4/cover.png"/></item><item><title>Mean-Field Langevin Dynamics for Signed Measures via a Bilevel Approach</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/oo7hy9kmk6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/oo7hy9kmk6/</guid><description>This paper presents a novel bilevel approach to extend mean-field Langevin dynamics to solve convex optimization problems over signed measures, achieving stronger guarantees and faster convergence rat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/oo7hy9kmk6/cover.png"/></item><item><title>Measuring Goal-Directedness</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/o4codiby7e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/o4codiby7e/</guid><description>New metric, Maximum Entropy Goal-Directedness (MEG), quantifies AI goal-directedness, crucial for assessing AI safety and agency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/o4codiby7e/cover.png"/></item><item><title>MECD: Unlocking Multi-Event Causal Discovery in Video Reasoning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/f8asoovlep/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/f8asoovlep/</guid><description>MECD: A new task and dataset unlocks multi-event causal discovery in videos, enabling a novel framework that outperforms existing models by efficiently identifying causal relationships between chronol&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/f8asoovlep/cover.png"/></item><item><title>Mechanism design augmented with output advice</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ajgks7qozm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ajgks7qozm/</guid><description>Mechanism design enhanced with output advice improves approximation guarantees by using imperfect predictions of the output, not agent types, offering robust, practical solutions.</description></item><item><title>Memorize What Matters: Emergent Scene Decomposition from Multitraverse</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/6qr3932rwe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/6qr3932rwe/</guid><description>3D Gaussian Mapping (3DGM) achieves self-supervised camera-only 3D scene decomposition by leveraging multi-traverse driving data, memorizing permanent structures while filtering out transient objects.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/6qr3932rwe/cover.png"/></item><item><title>MeshFormer : High-Quality Mesh Generation with 3D-Guided Reconstruction Model</title><link>https://deep-diver.github.io/neurips2024/oral-others/x7pjddod6z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/x7pjddod6z/</guid><description>MeshFormer: High-quality 3D mesh generation from sparse views in seconds, using transformers and 3D convolutions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/x7pjddod6z/cover.png"/></item><item><title>MetaLA: Unified Optimal Linear Approximation to Softmax Attention Map</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/y8yvcomepz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/y8yvcomepz/</guid><description>MetaLA: Unified optimal linear approximation to softmax attention map, achieving linear complexity and surpassing existing models in various benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/y8yvcomepz/cover.png"/></item><item><title>Metric Transforms and Low Rank Representations of Kernels for Fast Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/k9pxsryuwg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/k9pxsryuwg/</guid><description>Researchers unveil novel linear-algebraic tools revealing the limits of fast attention, classifying positive definite kernels for Manhattan distance, and fully characterizing metric transforms for Man&amp;hellip;</description></item><item><title>MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fpbacabqsn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fpbacabqsn/</guid><description>MInference 1.0 accelerates LLM pre-filling via dynamic sparse attention, achieving up to 10x speedup on an A100 GPU while maintaining accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fpbacabqsn/cover.png"/></item><item><title>Minimum Entropy Coupling with Bottleneck</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ylmym7shde/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ylmym7shde/</guid><description>A novel lossy compression framework, Minimum Entropy Coupling with Bottleneck (MEC-B), extends existing methods by integrating a bottleneck for controlled stochasticity, enhancing performance in scen&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ylmym7shde/cover.png"/></item><item><title>Mirror and Preconditioned Gradient Descent in Wasserstein Space</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/n12b6wva55/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/n12b6wva55/</guid><description>This paper presents novel mirror and preconditioned gradient descent algorithms for optimizing functionals over Wasserstein space, offering improved convergence and efficiency for various machine lear&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/n12b6wva55/cover.png"/></item><item><title>MKGL: Mastery of a Three-Word Language</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eqmnwxvoqn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eqmnwxvoqn/</guid><description>Researchers taught a large language model (LLM) a three-word &amp;lsquo;Knowledge Graph Language&amp;rsquo; (KGL) to improve knowledge graph (KG) completion, drastically reducing errors compared to other methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eqmnwxvoqn/cover.png"/></item><item><title>Model Fusion through Bayesian Optimization in Language Model Fine-Tuning</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lv4kthtgpj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lv4kthtgpj/</guid><description>Bayesian Optimization Model Fusion (BOMF) significantly boosts language model fine-tuning by optimizing both loss and metrics through multi-objective Bayesian optimization, yielding considerable perfo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lv4kthtgpj/cover.png"/></item><item><title>Molecule Design by Latent Prompt Transformer</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/dg3ti3c2b1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/dg3ti3c2b1/</guid><description>Latent Prompt Transformer (LPT) revolutionizes molecule design by unifying generation and optimization, achieving high efficiency in discovering novel molecules with desired properties.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/dg3ti3c2b1/cover.png"/></item><item><title>Monte Carlo Tree Search based Space Transfer for Black Box Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/t5ufifmdbq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/t5ufifmdbq/</guid><description>MCTS-transfer: Iteratively refining Bayesian optimization via Monte Carlo tree search for efficient black-box optimization using transfer learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/t5ufifmdbq/cover.png"/></item><item><title>Motion Forecasting in Continuous Driving</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/4mxzxyhmun/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/4mxzxyhmun/</guid><description>RealMotion: a novel motion forecasting framework for continuous driving that outperforms existing methods by accumulating historical scene information and sequentially refining predictions, achieving &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/4mxzxyhmun/cover.png"/></item><item><title>MotionBooth: Motion-Aware Customized Text-to-Video Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/1we1v3mahd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/1we1v3mahd/</guid><description>MotionBooth: A new framework enabling precise control over both object and camera movements in customized text-to-video generation, achieving high-quality video while maintaining training efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/1we1v3mahd/cover.png"/></item><item><title>Moving Off-the-Grid: Scene-Grounded Video Representations</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/rjspdvduaw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/rjspdvduaw/</guid><description>MooG: Self-supervised video model learns off-the-grid representations, enabling consistent scene element tracking even with motion; outperforming grid-based baselines on various vision tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/rjspdvduaw/cover.png"/></item><item><title>Multiclass Transductive Online Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3erevfwalz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3erevfwalz/</guid><description>Unbounded label spaces conquered! New algorithm achieves optimal mistake bounds in multiclass transductive online learning.</description></item><item><title>Multilingual Diversity Improves Vision-Language Representations</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/1wteqrecys/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/1wteqrecys/</guid><description>Boosting vision-language models: Multilingual data improves performance on English-centric benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/1wteqrecys/cover.png"/></item><item><title>MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/a5pabdzp2f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/a5pabdzp2f/</guid><description>MultiOOD benchmark and novel A2D &amp;amp; NP-Mix algorithms drastically improve multimodal out-of-distribution detection.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/a5pabdzp2f/cover.png"/></item><item><title>Multistable Shape from Shading Emerges from Patch Diffusion</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/bhsfbjs6j9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/bhsfbjs6j9/</guid><description>A novel diffusion model reconstructs multimodal shape distributions from shading, mirroring human multistable perception.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/bhsfbjs6j9/cover.png"/></item><item><title>Nearly Optimal Approximation of Matrix Functions by the Lanczos Method</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3s8v8qp9xv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3s8v8qp9xv/</guid><description>Lanczos-FA, a simple algorithm for approximating matrix functions, surprisingly outperforms newer methods; this paper proves its near-optimality for rational functions, explaining its practical succes&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3s8v8qp9xv/cover.png"/></item><item><title>Neglected Hessian component explains mysteries in sharpness regularization</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/m6pvpdin0y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/m6pvpdin0y/</guid><description>Deep learning&amp;rsquo;s mysteries surrounding sharpness regularization are solved by uncovering the crucial role of the neglected Hessian component, the Nonlinear Modeling Error (NME).</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/m6pvpdin0y/cover.png"/></item><item><title>NeoRL: Efficient Exploration for Nonepisodic RL</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/zwndgc13aw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/zwndgc13aw/</guid><description>NEORL: Novel nonepisodic RL algorithm guarantees optimal average cost with sublinear regret for nonlinear systems!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/zwndgc13aw/cover.png"/></item><item><title>Neural Assets: 3D-Aware Multi-Object Scene Synthesis with Image Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ednslswqij/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ednslswqij/</guid><description>Neural Assets enables intuitive 3D multi-object scene editing via image diffusion models by using per-object representations to control individual object poses, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ednslswqij/cover.png"/></item><item><title>Neural Krylov Iteration for Accelerating Linear System Solving</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/cqfe9eymdp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/cqfe9eymdp/</guid><description>Neural Krylov Iteration (NeurKItt) accelerates linear system solving by using a neural operator to predict invariant subspaces, drastically reducing iteration counts and computation time.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/cqfe9eymdp/cover.png"/></item><item><title>Neural Pfaffians: Solving Many Many-Electron SchrÃ¶dinger Equations</title><link>https://deep-diver.github.io/neurips2024/oral-ai-theory/hrknicwm3e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-theory/hrknicwm3e/</guid><description>Neural Pfaffians revolutionize many-electron SchrÃ¶dinger equation solutions by using fully learnable neural wave functions based on Pfaffians, achieving unprecedented accuracy and generalizability acr&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-theory/hrknicwm3e/cover.png"/></item><item><title>NeuroClips: Towards High-fidelity and Smooth fMRI-to-Video Reconstruction</title><link>https://deep-diver.github.io/neurips2024/oral-others/8qu52fl1dt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/8qu52fl1dt/</guid><description>NeuroClips: groundbreaking fMRI-to-video reconstruction, achieving high-fidelity smooth video up to 6s at 8FPS by decoding both high-level semantics and low-level perception flows.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/8qu52fl1dt/cover.png"/></item><item><title>No-regret Learning in Harmonic Games: Extrapolation in the Face of Conflicting Interests</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/hw9s9vy5gz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/hw9s9vy5gz/</guid><description>Extrapolated FTRL ensures Nash equilibrium convergence in harmonic games, defying standard no-regret learning limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/hw9s9vy5gz/cover.png"/></item><item><title>Noisy Label Learning with Instance-Dependent Outliers: Identifiability via Crowd Wisdom</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/htljptf7qm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/htljptf7qm/</guid><description>Crowd wisdom solves noisy label learning!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/htljptf7qm/cover.png"/></item><item><title>Non-asymptotic Approximation Error Bounds of Parameterized Quantum Circuits</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/xckii8nct3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/xckii8nct3/</guid><description>New non-asymptotic approximation error bounds show that parameterized quantum circuits can efficiently approximate complex functions, potentially surpassing classical neural networks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/xckii8nct3/cover.png"/></item><item><title>Non-asymptotic Global Convergence Analysis of BFGS with the Armijo-Wolfe Line Search</title><link>https://deep-diver.github.io/neurips2024/spotlight-optimization/mkzpn2t87c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-optimization/mkzpn2t87c/</guid><description>BFGS algorithm achieves global linear and superlinear convergence rates with inexact Armijo-Wolfe line search, even without precise Hessian knowledge.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-optimization/mkzpn2t87c/cover.png"/></item><item><title>Non-Asymptotic Uncertainty Quantification in High-Dimensional Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/rqcmmsszvi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/rqcmmsszvi/</guid><description>Data-driven approach corrects confidence intervals in high-dimensional learning, improving accuracy for various models and bridging theory and practice.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/rqcmmsszvi/cover.png"/></item><item><title>Non-convolutional graph neural networks.</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/jdaqwysfoc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/jdaqwysfoc/</guid><description>RUM neural network, a novel non-convolutional GNN, overcomes limitations of conventional convolution-based models by using RNNs to merge topological and semantic features along random walks, achieving&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/jdaqwysfoc/cover.png"/></item><item><title>Nonlinear dynamics of localization in neural receptive fields</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/nw9jmfl99s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/nw9jmfl99s/</guid><description>Neural receptive fields&amp;rsquo; localization emerges from nonlinear learning dynamics driven by naturalistic data&amp;rsquo;s higher-order statistics, not just sparsity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/nw9jmfl99s/cover.png"/></item><item><title>Nonlocal Attention Operator: Materializing Hidden Knowledge Towards Interpretable Physics Discovery</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/uskzeaj9zj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/uskzeaj9zj/</guid><description>New neural operator, Nonlocal Attention Operator (NAO), simultaneously learns forward and inverse physical models, improving interpretability and generalizability for physics discovery.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/uskzeaj9zj/cover.png"/></item><item><title>Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/7uqvfzw6mo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/7uqvfzw6mo/</guid><description>Unlocking superior discriminative features from diffusion models, this research reveals key activation properties for effective feature selection, surpassing state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/7uqvfzw6mo/cover.png"/></item><item><title>Not All Tokens Are What You Need for Pretraining</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/0nmzbwqaaj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/0nmzbwqaaj/</guid><description>RHO-1, a novel language model, uses selective pretraining focusing on high-value tokens, achieving state-of-the-art results with significantly less data than existing models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/0nmzbwqaaj/cover.png"/></item><item><title>Observational Scaling Laws and the Predictability of Langauge Model Performance</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/on5win7xyd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/on5win7xyd/</guid><description>Researchers predict language model performance by observing existing models, bypassing costly training, revealing surprising predictability in complex scaling phenomena.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/on5win7xyd/cover.png"/></item><item><title>On the Identifiability of Poisson Branching Structural Causal Model Using Probability Generating Function</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/tuwwbljfk9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/tuwwbljfk9/</guid><description>Researchers developed a novel, efficient causal discovery method using Probability Generating Functions to identify causal structures within Poisson Branching Structural Causal Models, overcoming limi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/tuwwbljfk9/cover.png"/></item><item><title>On the Use of Anchoring for Training Vision Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/xymhwyizop/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/xymhwyizop/</guid><description>Boosting vision model training: A new anchored training protocol with a simple regularizer significantly enhances generalization and safety, surpassing standard methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/xymhwyizop/cover.png"/></item><item><title>One-Shot Safety Alignment for Large Language Models via Optimal Dualization</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/da7hum4css/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/da7hum4css/</guid><description>One-shot dualization aligns large language models with safety constraints efficiently, eliminating iterative primal-dual methods for improved stability and reduced computational burden.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/da7hum4css/cover.png"/></item><item><title>Online Bayesian Persuasion Without a Clue</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/xnpvz8e1ty/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/xnpvz8e1ty/</guid><description>Researchers developed a novel online Bayesian persuasion algorithm that achieves sublinear regret without prior knowledge of the receiver or the state distribution, providing tight theoretical guarant&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/xnpvz8e1ty/cover.png"/></item><item><title>Online Convex Optimisation: The Optimal Switching Regret for all Segmentations Simultaneously</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/u6xxyud3ro/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/u6xxyud3ro/</guid><description>Algorithm RESET achieves optimal switching regret simultaneously across all segmentations, offering efficiency and parameter-free operation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/u6xxyud3ro/cover.png"/></item><item><title>Optimal ablation for interpretability</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/opt72tyzwz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/opt72tyzwz/</guid><description>Optimal ablation (OA) improves model interpretability by precisely measuring component importance, outperforming existing methods. OA-based importance shines in circuit discovery, factual recall, and &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/opt72tyzwz/cover.png"/></item><item><title>Optimal Algorithms for Online Convex Optimization with Adversarial Constraints</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/txffvjmnby/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/txffvjmnby/</guid><description>Optimal algorithms for online convex optimization with adversarial constraints are developed, achieving O(âT) regret and Ã(âT) constraint violationâa breakthrough in the field.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/txffvjmnby/cover.png"/></item><item><title>Optimal deep learning of holomorphic operators between Banach spaces</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vblzen37i0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vblzen37i0/</guid><description>Deep learning optimally learns holomorphic operators between Banach spaces, achieving near-optimal generalization bounds with problem-agnostic DNN architectures.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vblzen37i0/cover.png"/></item><item><title>Optimal Parallelization of Boosting</title><link>https://deep-diver.github.io/neurips2024/oral-ai-theory/rtz4df9if1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-theory/rtz4df9if1/</guid><description>This paper closes the performance gap in parallel boosting algorithms by presenting improved lower bounds and a novel algorithm matching these bounds, settling the parallel complexity of sample-optima&amp;hellip;</description></item><item><title>Optimization Algorithm Design via Electric Circuits</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/9jmt1eer9p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/9jmt1eer9p/</guid><description>Design provably convergent optimization algorithms swiftly using electric circuit analogies; a novel methodology automating discretization for diverse algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/9jmt1eer9p/cover.png"/></item><item><title>Optimizing Automatic Differentiation with Deep Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/hvmi98a0ki/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/hvmi98a0ki/</guid><description>Deep reinforcement learning optimizes automatic differentiation, achieving up to 33% improvement in Jacobian computation by finding efficient elimination orders.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/hvmi98a0ki/cover.png"/></item><item><title>Overcoming Common Flaws in the Evaluation of Selective Classification Systems</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/2tktdpgqnm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/2tktdpgqnm/</guid><description>Researchers developed a new evaluation metric, AUGRC, for selective classification systems that overcomes the limitations of existing metrics by providing a more holistic and interpretable assessment &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/2tktdpgqnm/cover.png"/></item><item><title>PACE: marrying the generalization of PArameter-efficient fine-tuning with Consistency rEgularization</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/coulbphot1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/coulbphot1/</guid><description>PACE marries parameter-efficient fine-tuning with consistency regularization to significantly boost model generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/coulbphot1/cover.png"/></item><item><title>Parallel Backpropagation for Shared-Feature Visualization</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/oqzcsb6fbl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/oqzcsb6fbl/</guid><description>Researchers visualized shared visual features driving responses of body-selective neurons to non-body objects, revealing object parts resembling macaque body parts, thus explaining neural preferences.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/oqzcsb6fbl/cover.png"/></item><item><title>Parameter-Inverted Image Pyramid Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/nkzlqrgg45/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/nkzlqrgg45/</guid><description>Parameter-Inverted Image Pyramid Networks (PIIP) boost image pyramid efficiency by using smaller models for higher-resolution images and larger models for lower-resolution ones, achieving superior per&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/nkzlqrgg45/cover.png"/></item><item><title>Parsimony or Capability? Decomposition Delivers Both in Long-term Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/wiehzsv15i/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/wiehzsv15i/</guid><description>SSCNN, a novel decomposition-based model, achieves superior long-term time series forecasting accuracy using 99% fewer parameters than existing methods, proving that bigger isn&amp;rsquo;t always better.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/wiehzsv15i/cover.png"/></item><item><title>Particle Semi-Implicit Variational Inference</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/p3gmgkhmkm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/p3gmgkhmkm/</guid><description>Particle Variational Inference (PVI) revolutionizes semi-implicit variational inference by directly optimizing the ELBO using a novel particle approximation, improving efficiency and expressiveness ov&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/p3gmgkhmkm/cover.png"/></item><item><title>Paths to Equilibrium in Games</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/lxxiiinmuf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/lxxiiinmuf/</guid><description>In n-player games, a satisficing path always exists leading from any initial strategy profile to a Nash equilibrium by allowing unsatisfied players to explore suboptimal strategies.</description></item><item><title>PCP-MAE: Learning to Predict Centers for Point Masked Autoencoders</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/i1xjk5a0x8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/i1xjk5a0x8/</guid><description>PCP-MAE enhances point cloud self-supervised learning by cleverly predicting masked patch centers, leading to superior 3D object classification and scene segmentation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/i1xjk5a0x8/cover.png"/></item><item><title>Peri-midFormer: Periodic Pyramid Transformer for Time Series Analysis</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/5iuxmvjvev/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/5iuxmvjvev/</guid><description>Peri-midFormer uses a novel periodic pyramid transformer to effectively model complex periodic variations in time series, achieving state-of-the-art results in forecasting, imputation, classification,&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/5iuxmvjvev/cover.png"/></item><item><title>Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/grg6szbw9p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/grg6szbw9p/</guid><description>VPL: a novel multimodal RLHF personalizes AI by inferring user-specific latent preferences, enabling accurate reward modeling and improved policy alignment for diverse populations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/grg6szbw9p/cover.png"/></item><item><title>Physically Compatible 3D Object Modeling from a Single Image</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/k29iv0xrbf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/k29iv0xrbf/</guid><description>Single image to physically compatible 3D objects: A new framework ensures 3D models maintain stability and mirror real-world equilibrium states, advancing realism in dynamic simulations and 3D printi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/k29iv0xrbf/cover.png"/></item><item><title>PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/6zbhietdp4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/6zbhietdp4/</guid><description>PiSSA, a novel parameter-efficient fine-tuning method, surpasses LoRA by initializing adapter matrices using the principal components of the original model, achieving faster convergence and enhanced p&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/6zbhietdp4/cover.png"/></item><item><title>Poisson Variational Autoencoder</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ektpecqglb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ektpecqglb/</guid><description>Poisson Variational Autoencoder (P-VAE) improves deep learning by encoding inputs as discrete spike counts, enhancing biological realism and interpretability while avoiding posterior collapse and achi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ektpecqglb/cover.png"/></item><item><title>Policy Learning from Tutorial Books via Understanding, Rehearsing and Introspecting</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/</guid><description>Researchers developed Policy Learning from tutorial Books (PLfB), a novel method that trains AI agents using knowledge from tutorial books instead of relying solely on real-world data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/cover.png"/></item><item><title>Pre-trained Text-to-Image Diffusion Models Are Versatile Representation Learners for Control</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ky07a73f3y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ky07a73f3y/</guid><description>Pre-trained text-to-image diffusion models create highly effective, versatile representations for embodied AI control, surpassing previous methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ky07a73f3y/cover.png"/></item><item><title>Principled Bayesian Optimization in Collaboration with Human Experts</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/idn9sikgly/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/idn9sikgly/</guid><description>COBOL: a novel Bayesian Optimization algorithm leverages human expert advice via binary labels, achieving both fast convergence and robustness to noisy input, while guaranteeing minimal expert effort.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/idn9sikgly/cover.png"/></item><item><title>Private Edge Density Estimation for Random Graphs: Optimal, Efficient and Robust</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/4nq24chnoi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/4nq24chnoi/</guid><description>This paper delivers a groundbreaking polynomial-time algorithm for optimally estimating edge density in random graphs while ensuring node privacy and robustness against data corruption.</description></item><item><title>Probabilistic Weather Forecasting with Hierarchical Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/wtizpqx121/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/wtizpqx121/</guid><description>Graph-EFM: a novel probabilistic weather forecasting model using hierarchical graph neural networks that efficiently generates large ensembles for improved accuracy and uncertainty quantification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/wtizpqx121/cover.png"/></item><item><title>Probablistic Emulation of a Global Climate Model with Spherical DYffusion</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ib2ihijrth/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ib2ihijrth/</guid><description>Spherical DYffusion: a novel AI model generates accurate, physically consistent global climate ensemble simulations, surpassing existing methods in efficiency and skill.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ib2ihijrth/cover.png"/></item><item><title>Procedure-Aware Surgical Video-language Pretraining with Hierarchical Knowledge Augmentation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zuwperkjnh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zuwperkjnh/</guid><description>PeskaVLP: Hierarchical knowledge augmentation boosts surgical video-language pretraining!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zuwperkjnh/cover.png"/></item><item><title>Provable Benefit of Cutout and CutMix for Feature Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/8on9diuh5v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/8on9diuh5v/</guid><description>CutMix and Cutout data augmentation methods provably improve feature learning by enabling the network to learn rarer features and noise vectors more effectively.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/8on9diuh5v/cover.png"/></item><item><title>PV-Tuning: Beyond Straight-Through Estimation for Extreme LLM Compression</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/yva8uf0i37/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/yva8uf0i37/</guid><description>PV-Tuning achieves new state-of-the-art in extreme LLM compression by going beyond traditional straight-through estimators (STE). This novel framework provides a more accurate and efficient fine-tunin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/yva8uf0i37/cover.png"/></item><item><title>QKFormer: Hierarchical Spiking Transformer using Q-K Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/avd7dpiooc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/avd7dpiooc/</guid><description>QKFormer: A groundbreaking spiking transformer achieving 85.65% ImageNet accuracy using a linear-complexity, energy-efficient Q-K attention mechanism.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/avd7dpiooc/cover.png"/></item><item><title>QTIP: Quantization with Trellises and Incoherence Processing</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7sdklvuycu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7sdklvuycu/</guid><description>QTIP: Ultra-high dimensional LLM quantization using trellis codes for faster, higher-quality inference.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7sdklvuycu/cover.png"/></item><item><title>Questioning the Survey Responses of Large Language Models</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/oo7dllgqqx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/oo7dllgqqx/</guid><description>LLM survey responses are systematically biased, often masking genuine model capabilities and leading to misleading alignment conclusions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/oo7dllgqqx/cover.png"/></item><item><title>Real-world Image Dehazing with Coherence-based Pseudo Labeling and Cooperative Unfolding Network</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/i6tbncje2f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/i6tbncje2f/</guid><description>CORUN-Colabator: a novel cooperative unfolding network and coherence-based label generator achieves state-of-the-art real-world image dehazing by effectively integrating physical knowledge and generat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/i6tbncje2f/cover.png"/></item><item><title>Reconstruct and Match: Out-of-Distribution Robustness via Topological Homogeneity</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/fkbmlfdbxm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/fkbmlfdbxm/</guid><description>Reconstruct &amp;amp; Match (REMA) enhances deep learning&amp;rsquo;s out-of-distribution robustness by leveraging object&amp;rsquo;s topological homogeneity, outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/fkbmlfdbxm/cover.png"/></item><item><title>Recurrent neural network dynamical systems for biological vision</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zz94albmok/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zz94albmok/</guid><description>CordsNet: a hybrid CNN-RNN architecture enabling biologically realistic, robust image recognition through continuous-time recurrent dynamics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zz94albmok/cover.png"/></item><item><title>Recursive PAC-Bayes: A Frequentist Approach to Sequential Prior Updates with No Information Loss</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/pqt6vg2x5u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/pqt6vg2x5u/</guid><description>Recursive PAC-Bayes: A frequentist method enabling sequential prior updates without information loss, resulting in significantly tighter generalization bounds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/pqt6vg2x5u/cover.png"/></item><item><title>ReFT: Representation Finetuning for Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fykjplmc0v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fykjplmc0v/</guid><description>ReFT: Revolutionizing language model finetuning by directly manipulating hidden representations, achieving superior efficiency and performance compared to existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fykjplmc0v/cover.png"/></item><item><title>Reinforcement Learning Gradients as Vitamin for Online Finetuning Decision Transformers</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/5l5bhyexyo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/5l5bhyexyo/</guid><description>Boost online finetuning of Decision Transformers by adding TD3 gradients, especially when pretrained with low-reward data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/5l5bhyexyo/cover.png"/></item><item><title>Reinforcement Learning Under Latent Dynamics: Toward Statistical and Algorithmic Modularity</title><link>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/qf2uzady1n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/qf2uzady1n/</guid><description>This paper pioneers a modular framework for reinforcement learning, addressing the challenge of learning under complex observations and simpler latent dynamics, offering both statistical and algorithm&amp;hellip;</description></item><item><title>Reliable Learning of Halfspaces under Gaussian Marginals</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/0lb8vzt1db/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/0lb8vzt1db/</guid><description>New algorithm reliably learns Gaussian halfspaces with significantly improved sample and computational complexity compared to existing methods, offering strong computational separation from standard a&amp;hellip;</description></item><item><title>Reparameterization invariance in approximate Bayesian inference</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/204yordhny/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/204yordhny/</guid><description>Bayesian neural networks often underfit due to their lack of reparameterization invariance; this paper introduces a Riemannian diffusion process to improve posterior sampling and enhance predictive pe&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/204yordhny/cover.png"/></item><item><title>Reproducibility of predictive networks for mouse visual cortex</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vxxj3xz1x8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vxxj3xz1x8/</guid><description>Deep learning models for neural activity lack reproducibility; this paper introduces adaptive regularization and iterative feature pruning to improve embedding consistency and predictive performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vxxj3xz1x8/cover.png"/></item><item><title>Reranking Laws for Language Generation: A Communication-Theoretic Perspective</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rhcgiznupi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rhcgiznupi/</guid><description>Boost LLM reliability by adding redundancy! This paper uses a communication theory framework to show that generating multiple LLM outputs and reranking them significantly reduces errors, even with imp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rhcgiznupi/cover.png"/></item><item><title>ResAD: A Simple Framework for Class Generalizable Anomaly Detection</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/znijzualxg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/znijzualxg/</guid><description>ResAD, a novel framework, tackles class-generalizable anomaly detection by learning residual feature distributions, achieving remarkable results on diverse datasets without retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/znijzualxg/cover.png"/></item><item><title>Resolving Discrepancies in Compute-Optimal Scaling of Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/4fssqpk1sm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/4fssqpk1sm/</guid><description>New research resolves discrepancies in language model scaling laws, revealing three key factors driving the differences and improving accuracy in predicting optimal model size based on compute budget.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/4fssqpk1sm/cover.png"/></item><item><title>Rethinking 3D Convolution in $ll_p$-norm Space</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/</guid><description>L1-norm based 3D convolution achieves competitive performance with lower energy consumption and latency compared to traditional methods, as proven through universal approximation theorem and experimen&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/cover.png"/></item><item><title>Rethinking Exploration in Reinforcement Learning with Effective Metric-Based Exploration Bonus</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/qpkwfltzki/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/qpkwfltzki/</guid><description>Effective Metric-based Exploration Bonus (EME) enhances reinforcement learning exploration by using a robust metric for state discrepancy and a dynamically adjusted scaling factor based on reward mode&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/qpkwfltzki/cover.png"/></item><item><title>Return of Unconditional Generation: A Self-supervised Representation Generation Method</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/clta4jfbml/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/clta4jfbml/</guid><description>Revolutionizing image generation, Representation-Conditioned Generation (RCG) achieves state-of-the-art results in unconditional image synthesis by leveraging self-supervised representations to condit&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/clta4jfbml/cover.png"/></item><item><title>Reverse Transition Kernel: A Flexible Framework to Accelerate Diffusion Inference</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/c2xclze1ks/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/c2xclze1ks/</guid><description>Reverse Transition Kernel (RTK) framework accelerates diffusion inference by enabling balanced subproblem decomposition, achieving superior convergence rates with RTK-MALA and RTK-ULD algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/c2xclze1ks/cover.png"/></item><item><title>Revisiting K-mer Profile for Effective and Scalable Genome Representation Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ehsd856ltb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ehsd856ltb/</guid><description>This paper proposes a lightweight and scalable k-mer based model for metagenomic binning, achieving comparable performance to computationally expensive genome foundation models while significantly imp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ehsd856ltb/cover.png"/></item><item><title>RG-SAN: Rule-Guided Spatial Awareness Network for End-to-End 3D Referring Expression Segmentation</title><link>https://deep-diver.github.io/neurips2024/oral-others/r5spnry6h3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/r5spnry6h3/</guid><description>RG-SAN achieves state-of-the-art 3D referring expression segmentation by leveraging spatial awareness and rule-guided weak supervision, significantly improving accuracy and handling of ambiguous descr&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/r5spnry6h3/cover.png"/></item><item><title>RL-GPT: Integrating Reinforcement Learning and Code-as-policy</title><link>https://deep-diver.github.io/neurips2024/oral-ai-applications/lezx6qrkrh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-applications/lezx6qrkrh/</guid><description>RL-GPT seamlessly integrates Large Language Models (LLMs) and Reinforcement Learning (RL) to create highly efficient agents mastering complex tasks in open-world environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-applications/lezx6qrkrh/cover.png"/></item><item><title>Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/jxs6cvpe7k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/jxs6cvpe7k/</guid><description>Robust Prompt Optimization (RPO) creates robust LLM defenses against jailbreaking attacks by optimizing a transferable suffix, achieving state-of-the-art robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/jxs6cvpe7k/cover.png"/></item><item><title>Rule Extrapolation in Language Modeling: A Study of Compositional Generalization on OOD Prompts</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/li2rprzwjy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/li2rprzwjy/</guid><description>LLMs struggle with out-of-distribution (OOD) generalization. This research introduces &amp;lsquo;rule extrapolation&amp;rsquo; using formal languages to rigorously evaluate OOD behavior in various LLM architectures, rev&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/li2rprzwjy/cover.png"/></item><item><title>SA3DIP: Segment Any 3D Instance with Potential 3D Priors</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/3ui4cer4iz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/3ui4cer4iz/</guid><description>SA3DIP boosts 3D instance segmentation accuracy by cleverly using 3D spatial and textural cues alongside 2D multi-view masks, overcoming limitations of previous methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/3ui4cer4iz/cover.png"/></item><item><title>Saliency-driven Experience Replay for Continual Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/8kkbxzn0km/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/8kkbxzn0km/</guid><description>Boosting AI&amp;rsquo;s continual learning via saliency-driven experience replay, achieving up to 20% accuracy improvement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/8kkbxzn0km/cover.png"/></item><item><title>Sample Complexity of Posted Pricing for a Single Item</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ek1tyhcb3w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ek1tyhcb3w/</guid><description>This paper reveals how many buyer samples are needed to set near-optimal posted prices for a single item, resolving a fundamental problem in online markets and offering both theoretical and practical &amp;hellip;</description></item><item><title>Sample Complexity Reduction via Policy Difference Estimation in Tabular Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ryq0kuzvkl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ryq0kuzvkl/</guid><description>This paper reveals that estimating only policy differences, while effective in bandits, is insufficient for tabular reinforcement learning. However, it introduces a novel algorithm achieving near-opti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ryq0kuzvkl/cover.png"/></item><item><title>Sample-Efficient Private Learning of Mixtures of Gaussians</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/74b6qx62vw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/74b6qx62vw/</guid><description>Researchers achieve a breakthrough in privacy-preserving machine learning by developing sample-efficient algorithms for learning Gaussian Mixture Models, significantly reducing the data needed while m&amp;hellip;</description></item><item><title>SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/abuqmkdvkw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/abuqmkdvkw/</guid><description>SARDet-100K: A new benchmark dataset and open-source toolkit revolutionizes large-scale SAR object detection.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/abuqmkdvkw/cover.png"/></item><item><title>Scalable and Effective Arithmetic Tree Generation for Adder and Multiplier Designs</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/5pnhgedg98/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/5pnhgedg98/</guid><description>ArithTreeRL, a novel reinforcement learning approach, generates optimized arithmetic tree structures for adders and multipliers, significantly improving computational efficiency and reducing hardware &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/5pnhgedg98/cover.png"/></item><item><title>Scale Equivariant Graph Metanetworks</title><link>https://deep-diver.github.io/neurips2024/oral-others/8fxqn1tzm1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/8fxqn1tzm1/</guid><description>ScaleGMNs, a new framework, enhances neural network processing by incorporating scaling symmetries, boosting performance across various tasks and datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/8fxqn1tzm1/cover.png"/></item><item><title>Scaling Continuous Latent Variable Models as Probabilistic Integral Circuits</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ke40kfot2e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ke40kfot2e/</guid><description>Researchers scaled continuous latent variable models by building DAG-shaped probabilistic integral circuits (PICs) and training them efficiently using tensorized architectures and neural functional sh&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ke40kfot2e/cover.png"/></item><item><title>Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/y13gsftjgr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/y13gsftjgr/</guid><description>Revolutionizing LLM training: Constant learning rate with cooldown replaces cosine schedule, enabling cost-effective scaling experiments!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/y13gsftjgr/cover.png"/></item><item><title>Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformers</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/pf7kdijhrf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/pf7kdijhrf/</guid><description>Heterogeneous Pre-trained Transformers (HPT) enables robots to learn generalizable policies from diverse data, drastically improving performance on unseen tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/pf7kdijhrf/cover.png"/></item><item><title>Scene Graph Disentanglement and Composition for Generalizable Complex Image Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zgn0ywy2he/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zgn0ywy2he/</guid><description>DisCo: a novel framework for generalizable complex image generation using scene graph disentanglement and composition, achieving superior performance over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zgn0ywy2he/cover.png"/></item><item><title>Schrodinger Bridge Flow for Unpaired Data Translation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/1f32icjffa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/1f32icjffa/</guid><description>Accelerate unpaired data translation with SchrÃ¶dinger Bridge Flow, a novel algorithm solving optimal transport problems efficiently without repeatedly training models!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/1f32icjffa/cover.png"/></item><item><title>Second-order forward-mode optimization of recurrent neural networks for neuroscience</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/pox8jnqoo5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/pox8jnqoo5/</guid><description>SOFO: a novel second-order optimizer enables efficient and memory-friendly RNN training for neuroscience tasks, surpassing Adam&amp;rsquo;s performance, especially on long time horizons.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/pox8jnqoo5/cover.png"/></item><item><title>SeeA*: Efficient Exploration-Enhanced A* Search by Selective Sampling</title><link>https://deep-diver.github.io/neurips2024/oral-ai-applications/msaqxzvzw8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-applications/msaqxzvzw8/</guid><description>SeeA* enhances A* search by selectively sampling promising nodes, improving exploration and efficiency, especially with less accurate heuristics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-applications/msaqxzvzw8/cover.png"/></item><item><title>SegVol: Universal and Interactive Volumetric Medical Image Segmentation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/105zuvpdyw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/105zuvpdyw/</guid><description>SegVol: A universal, interactive 3D medical image segmentation model achieving state-of-the-art performance across diverse anatomical categories.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/105zuvpdyw/cover.png"/></item><item><title>Selective Generation for Controllable Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/glfyoazh2f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/glfyoazh2f/</guid><description>Certified selective generation controls language model hallucinations by leveraging textual entailment and a novel semi-supervised algorithm, guaranteeing a controlled false discovery rate.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/glfyoazh2f/cover.png"/></item><item><title>Self-Consuming Generative Models with Curated Data Provably Optimize Human Preferences</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/cyv0lkiaoh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/cyv0lkiaoh/</guid><description>Curated synthetic data provably optimizes human preferences in iterative generative model training, maximizing expected reward while mitigating variance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/cyv0lkiaoh/cover.png"/></item><item><title>Semi-supervised Multi-label Learning with Balanced Binary Angular Margin Loss</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/aqcpvwwktk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/aqcpvwwktk/</guid><description>S2ML2-BBAM: A new semi-supervised multi-label learning method that balances feature angle distributions to improve accuracy and fairness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/aqcpvwwktk/cover.png"/></item><item><title>Semi-Supervised Sparse Gaussian Classification: Provable Benefits of Unlabeled Data</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/dlctmeyq6y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/dlctmeyq6y/</guid><description>This study proves that combining labeled and unlabeled data significantly improves high-dimensional sparse Gaussian classification, offering a polynomial-time SSL algorithm that outperforms supervised&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/dlctmeyq6y/cover.png"/></item><item><title>Sequoia: Scalable and Robust Speculative Decoding</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/</guid><description>SEQUOIA: A novel algorithm boosts Large Language Model (LLM) inference speed by up to 9.5x using a scalable and robust speculative decoding approach!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/cover.png"/></item><item><title>Skinned Motion Retargeting with Dense Geometric Interaction Perception</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/v1bim8wesl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/v1bim8wesl/</guid><description>MeshRet: A novel retargeting framework that uses dense geometric interaction modeling for realistic, artifact-free skinned character animation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/v1bim8wesl/cover.png"/></item><item><title>Slight Corruption in Pre-training Data Makes Better Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/</guid><description>Slightly corrupting pre-training data significantly improves diffusion models&amp;rsquo; image generation quality, diversity, and fidelity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/cover.png"/></item><item><title>Small coresets via negative dependence: DPPs, linear statistics, and concentration</title><link>https://deep-diver.github.io/neurips2024/spotlight-optimization/jd3mshmttl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-optimization/jd3mshmttl/</guid><description>DPPs create smaller, more accurate coresets than existing methods, improving machine learning efficiency without sacrificing accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-optimization/jd3mshmttl/cover.png"/></item><item><title>SocraticLM: Exploring Socratic Personalized Teaching with Large Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/qkozgjhxsa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/qkozgjhxsa/</guid><description>SocraticLM achieves a Socratic teaching paradigm, surpassing GPT-4 by 12%, through a novel multi-agent training pipeline and a comprehensive evaluation system.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/qkozgjhxsa/cover.png"/></item><item><title>Span-Based Optimal Sample Complexity for Weakly Communicating and General Average Reward MDPs</title><link>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/pgey8jq3qx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/pgey8jq3qx/</guid><description>This paper achieves minimax-optimal bounds for learning near-optimal policies in average-reward MDPs, addressing a long-standing open problem in reinforcement learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/pgey8jq3qx/cover.png"/></item><item><title>SpikeReveal: Unlocking Temporal Sequences from Real Blurry Inputs with Spike Streams</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/9fyat8hppv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/9fyat8hppv/</guid><description>SpikeReveal: Self-supervised learning unlocks sharp video sequences from blurry, real-world spike camera data, overcoming limitations of prior supervised approaches.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/9fyat8hppv/cover.png"/></item><item><title>Stabilized Proximal-Point Methods for Federated Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/wuksyfszdt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/wuksyfszdt/</guid><description>S-DANE &amp;amp; ACC-S-DANE achieve best-known communication complexity for federated learning, improving local computation efficiency via stabilized proximal-point methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/wuksyfszdt/cover.png"/></item><item><title>Stable Minima Cannot Overfit in Univariate ReLU Networks: Generalization by Large Step Sizes</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/7swrtm9qsp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/7swrtm9qsp/</guid><description>Deep ReLU networks trained with large, constant learning rates avoid overfitting in univariate regression due to minima stability, generalizing well even with noisy labels.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/7swrtm9qsp/cover.png"/></item><item><title>Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fxjdcrimyh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fxjdcrimyh/</guid><description>Stacking Your Transformers accelerates LLM pre-training by leveraging smaller, pre-trained models to efficiently train larger ones, achieving significant speedups and improved performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fxjdcrimyh/cover.png"/></item><item><title>Statistical Efficiency of Distributional Temporal Difference Learning</title><link>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/ewum5hrygh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/ewum5hrygh/</guid><description>Researchers achieve minimax optimal sample complexity bounds for distributional temporal difference learning, enhancing reinforcement learning algorithm efficiency.</description></item><item><title>Statistical Estimation in the Spiked Tensor Model via the Quantum Approximate Optimization Algorithm</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/wtlvxdzhmp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/wtlvxdzhmp/</guid><description>Quantum Approximate Optimization Algorithm (QAOA) achieves weak recovery in spiked tensor models matching classical methods, but with potential constant factor advantages for certain parameters.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/wtlvxdzhmp/cover.png"/></item><item><title>Statistical Multicriteria Benchmarking via the GSD-Front</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/jxxvskb9hd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/jxxvskb9hd/</guid><description>Researchers can now reliably benchmark classifiers using multiple quality metrics via the GSD-front, a new information-efficient technique that accounts for statistical uncertainty and deviations from&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/jxxvskb9hd/cover.png"/></item><item><title>Stochastic Taylor Derivative Estimator: Efficient amortization for arbitrary differential operators</title><link>https://deep-diver.github.io/neurips2024/oral-others/j2wi2rcg2u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/j2wi2rcg2u/</guid><description>Stochastic Taylor Derivative Estimator (STDE) drastically accelerates the optimization of neural networks involving high-dimensional, high-order differential operators by efficiently amortizing comput&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/j2wi2rcg2u/cover.png"/></item><item><title>StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vfqzxhinfu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vfqzxhinfu/</guid><description>StoryDiffusion enhances long-range image &amp;amp; video generation by introducing a simple yet effective self-attention mechanism and a semantic motion predictor, achieving high content consistency without t&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vfqzxhinfu/cover.png"/></item><item><title>Stylus: Automatic Adapter Selection for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/3odq2tgspp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/3odq2tgspp/</guid><description>Stylus: an automatic adapter selection system for diffusion models, boosts image quality and diversity by intelligently composing task-specific adapters based on prompt keywords.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/3odq2tgspp/cover.png"/></item><item><title>Symmetries in Overparametrized Neural Networks: A Mean Field View</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/l86glqncuj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/l86glqncuj/</guid><description>Overparametrized neural networks&amp;rsquo; learning dynamics are analyzed under data symmetries using mean-field theory, revealing that data augmentation, feature averaging, and equivariant architectures asymp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/l86glqncuj/cover.png"/></item><item><title>Tetrahedron Splatting for 3D Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/qvsp1uk7b5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/qvsp1uk7b5/</guid><description>TeT-Splatting: a novel 3D representation enabling fast convergence, real-time rendering, and precise mesh extraction for high-fidelity 3D generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/qvsp1uk7b5/cover.png"/></item><item><title>Text-DiFuse: An Interactive Multi-Modal Image Fusion Framework based on Text-modulated Diffusion Model</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ybrxzibyeg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ybrxzibyeg/</guid><description>Text-DiFuse: A novel interactive multi-modal image fusion framework leverages text-modulated diffusion models for superior performance in complex scenarios.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ybrxzibyeg/cover.png"/></item><item><title>Text2CAD: Generating Sequential CAD Designs from Beginner-to-Expert Level Text Prompts</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/5k9xehik3l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/5k9xehik3l/</guid><description>Text2CAD: AI generates CAD models from text prompts!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/5k9xehik3l/cover.png"/></item><item><title>TextCtrl: Diffusion-based Scene Text Editing with Prior Guidance Control</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/sqvns9hwjt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/sqvns9hwjt/</guid><description>TextCtrl: a novel diffusion-based scene text editing method using prior guidance control, achieving superior style fidelity and accuracy with a new real-world benchmark dataset, ScenePair.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/sqvns9hwjt/cover.png"/></item><item><title>TFG: Unified Training-Free Guidance for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/n8ybgx98vc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/n8ybgx98vc/</guid><description>TFG: A unified, training-free framework for boosting diffusion model performance by efficiently searching its algorithm-agnostic design space.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/n8ybgx98vc/cover.png"/></item><item><title>The ALCHEmist: Automated Labeling 500x CHEaper than LLM Data Annotators</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/t0glcbw28a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/t0glcbw28a/</guid><description>Alchemist, a novel automated labeling system, reduces data annotation costs by 500x compared to LLMs while improving accuracy by an average of 12.9%.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/t0glcbw28a/cover.png"/></item><item><title>The Collusion of Memory and Nonlinearity in Stochastic Approximation With Constant Stepsize</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/xul75cvhl5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/xul75cvhl5/</guid><description>Unlocking the mysteries of stochastic approximation with constant stepsize, this paper reveals how memory and nonlinearity interact to create bias, providing novel analysis and solutions for more accu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/xul75cvhl5/cover.png"/></item><item><title>The Power of Resets in Online Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/7saccaomgi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/7saccaomgi/</guid><description>Leveraging local simulator resets in online reinforcement learning dramatically improves sample efficiency, especially for high-dimensional problems with general function approximation.</description></item><item><title>The Road Less Scheduled</title><link>https://deep-diver.github.io/neurips2024/oral-others/0xenkkenui/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/0xenkkenui/</guid><description>Revolutionizing machine learning, Schedule-Free optimization achieves state-of-the-art results without needing learning rate schedules, simplifying training and improving efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/0xenkkenui/cover.png"/></item><item><title>The Sample-Communication Complexity Trade-off in Federated Q-Learning</title><link>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/6yipvnkjuk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/6yipvnkjuk/</guid><description>Federated Q-learning achieves optimal sample &amp;amp; communication complexities simultaneously via Fed-DVR-Q, a novel algorithm.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/6yipvnkjuk/cover.png"/></item><item><title>The Value of Reward Lookahead in Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/uryeu8mwz1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/uryeu8mwz1/</guid><description>Reinforcement learning agents can achieve significantly higher rewards by using advance knowledge of future rewards; this paper mathematically analyzes this advantage by computing the worst-case perfo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/uryeu8mwz1/cover.png"/></item><item><title>Thompson Sampling For Combinatorial Bandits: Polynomial Regret and Mismatched Sampling Paradox</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/pgoubhydbr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/pgoubhydbr/</guid><description>A novel Thompson Sampling variant achieves polynomial regret for combinatorial bandits, solving a key limitation of existing methods and offering significantly improved performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/pgoubhydbr/cover.png"/></item><item><title>Time-Reversal Provides Unsupervised Feedback to LLMs</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ny0brzdqlt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ny0brzdqlt/</guid><description>Time-reversed language models provide unsupervised feedback for improving LLMs, offering a cost-effective alternative to human feedback and enhancing LLM safety.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ny0brzdqlt/cover.png"/></item><item><title>Tolerant Algorithms for Learning with Arbitrary Covariate Shift</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/lnnfwc2ah1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/lnnfwc2ah1/</guid><description>This paper introduces efficient algorithms for learning under arbitrary covariate shift, addressing limitations of prior approaches by enabling classifiers to abstain from predictions in high-shift sc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/lnnfwc2ah1/cover.png"/></item><item><title>TOPA: Extending Large Language Models for Video Understanding via Text-Only Pre-Alignment</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5nmbqpy7bn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5nmbqpy7bn/</guid><description>TOPA: Extending LLMs for video understanding using only text data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5nmbqpy7bn/cover.png"/></item><item><title>Towards an Information Theoretic Framework of Context-Based Offline Meta-Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/qfuszvw9mx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/qfuszvw9mx/</guid><description>UNICORN: a unified framework reveals that existing offline meta-reinforcement learning algorithms optimize variations of mutual information, leading to improved generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/qfuszvw9mx/cover.png"/></item><item><title>Towards training digitally-tied analog blocks via hybrid gradient computation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/bmtn8kkrbq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/bmtn8kkrbq/</guid><description>Hybrid neural networks, combining digital feedforward and analog energy-based blocks, are trained end-to-end via a novel BP-EP gradient chaining algorithm, achieving state-of-the-art results on ImageN&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/bmtn8kkrbq/cover.png"/></item><item><title>Towards Understanding Evolving Patterns in Sequential Data</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/i2gvmvrgnk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/i2gvmvrgnk/</guid><description>EVORATE quantifies evolving patterns in sequential data, enabling better model selection and temporal analysis for improved machine learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/i2gvmvrgnk/cover.png"/></item><item><title>Towards Unified Multimodal Editing with Enhanced Knowledge Collaboration</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/kf80zs3fvy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/kf80zs3fvy/</guid><description>UniKE: A unified multimodal editing method achieves superior reliability, generality, and locality by disentangling knowledge into semantic and truthfulness spaces, enabling enhanced collaboration bet&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/kf80zs3fvy/cover.png"/></item><item><title>Towards Universal Mesh Movement Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/lcalcnf2qe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/lcalcnf2qe/</guid><description>Universal Mesh Movement Network (UM2N) revolutionizes mesh movement for PDE solvers, enabling zero-shot adaptation to diverse problems and significantly accelerating simulations with improved accuracy&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/lcalcnf2qe/cover.png"/></item><item><title>Toxicity Detection for Free</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5a27ee8lxx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5a27ee8lxx/</guid><description>Moderation Using LLM Introspection (MULI) leverages the first response token&amp;rsquo;s logits from LLMs to create a highly accurate toxicity detector, surpassing state-of-the-art methods with minimal overhead&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5a27ee8lxx/cover.png"/></item><item><title>TrackIME: Enhanced Video Point Tracking via Instance Motion Estimation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ekhqbgvl3g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ekhqbgvl3g/</guid><description>TrackIME enhances video point tracking by cleverly pruning the search space, resulting in improved accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ekhqbgvl3g/cover.png"/></item><item><title>Trading Place for Space: Increasing Location Resolution Reduces Contextual Capacity in Hippocampal Codes</title><link>https://deep-diver.github.io/neurips2024/oral-ai-theory/reik4szmjt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-theory/reik4szmjt/</guid><description>Boosting hippocampal spatial resolution surprisingly shrinks its contextual memory capacity, revealing a crucial trade-off between precision and context storage.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-theory/reik4szmjt/cover.png"/></item><item><title>Training Compute-Optimal Protein Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/uczi8gsfd4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/uczi8gsfd4/</guid><description>Compute-optimal protein language models are trained efficiently using scaling laws derived from a massive dataset, improving performance while optimizing compute budgets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/uczi8gsfd4/cover.png"/></item><item><title>Trajectory Flow Matching with Applications to Clinical Time Series Modelling</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/fnakqlti1n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/fnakqlti1n/</guid><description>Simulation-free Neural SDE training via Trajectory Flow Matching unlocks scalability and stability for modeling complex real-world time series, particularly in clinical settings.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/fnakqlti1n/cover.png"/></item><item><title>Uncovering, Explaining, and Mitigating the Superficial Safety of Backdoor Defense</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/qzfshkbwdo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/qzfshkbwdo/</guid><description>Current backdoor defenses, while effective at reducing attack success rates, are vulnerable to rapid re-learning. This work unveils this superficial safety, proposes a novel attack, and introduces a p&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/qzfshkbwdo/cover.png"/></item><item><title>Unified Gradient-Based Machine Unlearning with Remain Geometry Enhancement</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/dhedf5epbt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/dhedf5epbt/</guid><description>Enhance deep neural network privacy and trustworthiness with unified gradient-based machine unlearning, leveraging remain geometry for efficient forgetting and performance preservation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/dhedf5epbt/cover.png"/></item><item><title>Unitary Convolutions for Learning on Graphs and Groups</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/lg1veqjvuh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/lg1veqjvuh/</guid><description>Stable deep learning on graphs achieved using novel unitary group convolutions, preventing over-smoothing and enhancing model robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/lg1veqjvuh/cover.png"/></item><item><title>Unlocking the Capabilities of Thought: A Reasoning Boundary Framework to Quantify and Optimize Chain-of-Thought</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/pc44umwy2v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/pc44umwy2v/</guid><description>Reasoning Boundary Framework (RBF) quantitatively assesses and optimizes chain-of-thought (CoT) in LLMs, offering novel metrics and optimization strategies validated across various models and tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/pc44umwy2v/cover.png"/></item><item><title>Unlocking Tokens as Data Points for Generalization Bounds on Larger Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5jru8ufi8h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5jru8ufi8h/</guid><description>Unlocking tight generalization bounds for massive LLMs using a novel token-level approach.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5jru8ufi8h/cover.png"/></item><item><title>Unveiling Encoder-Free Vision-Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/sppab1tmlc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/sppab1tmlc/</guid><description>EVE, a groundbreaking encoder-free vision-language model, rivals encoder-based counterparts using a fraction of the data and resources, demonstrating efficient, transparent training for pure decoder-o&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/sppab1tmlc/cover.png"/></item><item><title>Validating Climate Models with Spherical Convolutional Wasserstein Distance</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/mmsffib6pi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/mmsffib6pi/</guid><description>Researchers developed Spherical Convolutional Wasserstein Distance (SCWD) to more accurately validate climate models by considering spatial variability and local distributional differences.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/mmsffib6pi/cover.png"/></item><item><title>Variational Delayed Policy Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/datndzhbqj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/datndzhbqj/</guid><description>VDPO: A novel framework for delayed reinforcement learning achieving 50% sample efficiency improvement without compromising performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/datndzhbqj/cover.png"/></item><item><title>VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time</title><link>https://deep-diver.github.io/neurips2024/oral-others/5zscse0k41/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/5zscse0k41/</guid><description>VASA-1: Real-time, lifelike talking faces generated from a single image and audio!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/5zscse0k41/cover.png"/></item><item><title>Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/gojl67cfs8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/gojl67cfs8/</guid><description>Visual Autoregressive Modeling (VAR) revolutionizes image generation by using a coarse-to-fine &amp;rsquo;next-scale prediction&amp;rsquo;, outperforming diffusion models and exhibiting scaling laws similar to LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/gojl67cfs8/cover.png"/></item><item><title>VLM Agents Generate Their Own Memories: Distilling Experience into Embodied Programs of Thought</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/5g7mrfpngt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/5g7mrfpngt/</guid><description>VLMs learn to generate their own memories by abstracting experiences from noisy demonstrations and human feedback, significantly boosting in-context learning performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/5g7mrfpngt/cover.png"/></item><item><title>VMamba: Visual State Space Model</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zgtlqqr1k7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zgtlqqr1k7/</guid><description>VMamba: a vision backbone achieving linear time complexity using Visual State Space (VSS) blocks and 2D Selective Scan (SS2D) for efficient visual representation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zgtlqqr1k7/cover.png"/></item><item><title>Voila-A: Aligning Vision-Language Models with User's Gaze Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zyrz5v84zi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zyrz5v84zi/</guid><description>Voila-A enhances vision-language models by aligning their attention with user gaze, improving real-world application effectiveness and interpretability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zyrz5v84zi/cover.png"/></item><item><title>Voxel Mamba: Group-Free State Space Models for Point Cloud based 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ghyhvsctdh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ghyhvsctdh/</guid><description>Voxel Mamba: a group-free 3D object detection method using state space models, achieving higher accuracy and efficiency by overcoming limitations of serialization-based Transformers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ghyhvsctdh/cover.png"/></item><item><title>Watermarking Makes Language Models Radioactive</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/qgizqb1khm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/qgizqb1khm/</guid><description>LLM watermarking leaves detectable traces in subsequently trained models, enabling detection of synthetic data usageâa phenomenon termed &amp;lsquo;radioactivity&amp;rsquo;.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/qgizqb1khm/cover.png"/></item><item><title>Weisfeiler and Leman Go Loopy: A New Hierarchy for Graph Representational Learning</title><link>https://deep-diver.github.io/neurips2024/oral-ai-theory/9o2svnehor/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-theory/9o2svnehor/</guid><description>This paper introduces r-lWL, a new graph isomorphism test hierarchy that surpasses the limitations of the Weisfeiler-Leman test by counting cycles up to length r+2, and its GNN counterpart, r-lMPNN, w&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-theory/9o2svnehor/cover.png"/></item><item><title>What type of inference is planning?</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/txsrgrzicz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/txsrgrzicz/</guid><description>Planning is redefined as a distinct inference type within a variational framework, enabling efficient approximate planning in complex environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/txsrgrzicz/cover.png"/></item><item><title>When Is Inductive Inference Possible?</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/2agcshccuv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/2agcshccuv/</guid><description>This paper provides a tight characterization of inductive inference, proving it&amp;rsquo;s possible if and only if the hypothesis class is a countable union of online learnable classes, resolving a long-standi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/2agcshccuv/cover.png"/></item><item><title>Who Evaluates the Evaluations? Objectively Scoring Text-to-Image Prompt Coherence Metrics with T2IScoreScore (TS2)</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/s4yrclbuk1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/s4yrclbuk1/</guid><description>T2IScoreScore objectively evaluates text-to-image prompt faithfulness metrics using semantic error graphs, revealing that simpler metrics surprisingly outperform complex, computationally expensive one&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/s4yrclbuk1/cover.png"/></item><item><title>Who's asking? User personas and the mechanics of latent misalignment</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eses1mic9d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eses1mic9d/</guid><description>User personas significantly impact the safety of large language models, bypassing safety filters more effectively than direct prompting methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eses1mic9d/cover.png"/></item><item><title>X-Ray: A Sequential 3D Representation For Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/36tmv15dpo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/36tmv15dpo/</guid><description>X-Ray: A novel 3D representation generating complete object surfaces from a single image!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/36tmv15dpo/cover.png"/></item><item><title>xLSTM: Extended Long Short-Term Memory</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/araxppiahq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/araxppiahq/</guid><description>XLSTM: Extended Long Short-Term Memory, introduces exponential gating and novel memory structures to overcome LSTM limitations, achieving performance comparable to state-of-the-art Transformers and St&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/araxppiahq/cover.png"/></item><item><title>You Only Cache Once: Decoder-Decoder Architectures for Language Models</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/25ioxw576r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/25ioxw576r/</guid><description>YOCO: A decoder-decoder architecture for LLMs dramatically reduces memory usage and improves inference speed by caching key-value pairs only once.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/25ioxw576r/cover.png"/></item><item><title>Zipper: Addressing Degeneracy in Algorithm-Agnostic Inference</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ahvohpkkmx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ahvohpkkmx/</guid><description>Zipper: A novel statistical device resolves the degeneracy issue in algorithm-agnostic inference, enabling reliable goodness-of-fit tests with enhanced power.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ahvohpkkmx/cover.png"/></item></channel></rss>