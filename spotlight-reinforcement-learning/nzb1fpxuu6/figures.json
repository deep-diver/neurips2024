[{"figure_path": "nZB1FpXUU6/figures/figures_2_1.jpg", "caption": "Figure 1: An illustrative example comparing the original Procgen and our C-Procgen.", "description": "This figure uses a screenshot from a Procgen game to illustrate the difference between the original Procgen and the authors' proposed C-Procgen.  The original Procgen uses a single, implicit level ID to control the generation of game levels (contexts). In contrast, C-Procgen makes numerous parameters that define the game's context explicitly controllable by the user, giving researchers more granular control over the game environment.", "section": "3 C-Procgen: Controllable Contextual Procgen"}, {"figure_path": "nZB1FpXUU6/figures/figures_4_1.jpg", "caption": "Figure 2: Dissecting the learning dynamics in Procgen with game Ninja as an example. Left: The training curve, where we mark five stages during training (T1-T5). Right: Heatmaps of three metrics at stage T1-T5, including average score (top row), loss per sample (middle row), and the number of samples (bottom row) across different contexts.", "description": "This figure analyzes the learning dynamics in the Procgen game Ninja.  The left panel shows the training curve, highlighting five stages (T1-T5). The right panel uses heatmaps to visualize three key metrics across different contexts within each stage: average score, loss per sample, and the number of samples. This provides insights into how the agent's performance, learning progress, and sampling distribution evolve across various levels of difficulty during the training process.", "section": "4.1 A Shift from Easy to Hard Contexts"}, {"figure_path": "nZB1FpXUU6/figures/figures_5_1.jpg", "caption": "Figure 3: Score, loss per sample, and sample num across different environments and contexts. Each subplot represents a different environment, with heatmaps depicting the metric values at different time points and contexts.", "description": "This figure presents a comprehensive analysis of learning dynamics across various Procgen environments and their associated contexts.  It visualizes three key metrics: average score, loss per sample, and the number of samples collected for each context at different stages of training (T1-T5). Heatmaps are used to illustrate how these metrics vary across different contexts within each environment. The figure offers insights into the learning process, revealing how the agent's focus shifts from simpler to more challenging contexts over time.", "section": "4.1 A Shift from Easy to Hard Contexts"}, {"figure_path": "nZB1FpXUU6/figures/figures_6_1.jpg", "caption": "Figure 4: Loss Production Efficiency vs. Score Improvement with Prioritized Level Replay in Procgen Games", "description": "This figure shows the relationship between Loss Production Efficiency (LPE) and the performance improvement achieved by using the Prioritized Level Replay (PLR) algorithm in different Procgen games.  The x-axis represents the LPE, a metric indicating the effectiveness of sample distribution in generating loss signals. The y-axis shows the score improvement (percentage increase) gained by employing PLR compared to using PPO alone.  Each point represents a game from the Procgen benchmark.  The figure suggests that games with lower LPE tend to see greater performance improvements when PLR is used, indicating that PLR is most beneficial in environments where the initial sample distribution is inefficient at guiding learning.", "section": "4.2 A Mismatch between Loss and Sample Distribution"}, {"figure_path": "nZB1FpXUU6/figures/figures_7_1.jpg", "caption": "Figure 5: Learning outcomes under various context settings. The leftmost panel for each game depicts the final average score and loss per sample under the original context setting after 25M training steps. Subsequent panels show the metrics under reconfigured context settings. Regions enclosed in red represent the masked contexts, where average score testing was still performed.", "description": "This figure visualizes the impact of modifying training contexts on the performance of reinforcement learning agents across nine different Procgen games. The leftmost column shows the performance under the original context settings. Subsequent columns represent three reconfigured settings where specific context groups were removed (masked, indicated by red boxes), showing how the agent's score and loss per sample varied under different context configurations.", "section": "5.1 Partially Masking the Training Contexts"}, {"figure_path": "nZB1FpXUU6/figures/figures_8_1.jpg", "caption": "Figure 6: Loss Proportion and Score curve in different expanded context settings", "description": "This figure displays the loss proportion and score curves for the game Leaper under three different context settings: Original Setting, Expanding Setting 1, and Expanding Setting 2. Each setting represents a different number of contexts (combinations of road lanes and water lanes).  The plots show how the focus of loss (and learning progress) shifts across contexts over time.  Expanding Setting 1 and 2 introduce more contexts and improved connectivity compared to the original, resulting in different learning dynamics. The heatmaps illustrate the distribution of contexts used in each setting.", "section": "5.2 Expanding the Training Contexts"}]